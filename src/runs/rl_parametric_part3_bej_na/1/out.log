Using TensorFlow backend.
[2019-03-22 23:12:36,331] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='linear', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Bej-Train-v1', eval_act_func='part3_bej_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=0.001, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[19, 1], model_type='nn', num_threads=16, output='./Part3-NA-Bej-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Bej-Test-v1', 'Part3-NA-Bej-Test-v2', 'Part3-NA-Bej-Test-v3', 'Part3-NA-Bej-Test-v4'], test_mode='Multiple', train_act_func='part3_bej_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=26)
[2019-03-22 23:12:36,331] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-22 23:12:36.369460: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-22 23:12:53,923] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-22 23:12:53,923] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Bej-Train-v1', 'Part3-NA-Bej-Test-v1', 'Part3-NA-Bej-Test-v2', 'Part3-NA-Bej-Test-v3', 'Part3-NA-Bej-Test-v4'] ...
[2019-03-22 23:12:53,936] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation worker starts!
[2019-03-22 23:12:53,938] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation worker starts!
[2019-03-22 23:12:53,942] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation worker starts!
[2019-03-22 23:12:53,945] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation worker starts!
[2019-03-22 23:12:53,951] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation worker starts!
[2019-03-22 23:12:53,951] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:12:53,951] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-22 23:12:54,008] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:54,008] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run1
[2019-03-22 23:12:54,952] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:12:54,954] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-22 23:12:55,036] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:55,037] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run1
[2019-03-22 23:12:55,259] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-22 23:12:55,259] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:12:55,260] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:12:55,260] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:55,261] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:12:55,261] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:12:55,261] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:55,262] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:12:55,262] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:55,262] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:55,262] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:55,266] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run1
[2019-03-22 23:12:55,267] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run1
[2019-03-22 23:12:55,276] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run1
[2019-03-22 23:12:55,276] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run1
[2019-03-22 23:12:55,298] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run1
[2019-03-22 23:12:55,955] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:12:55,956] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-22 23:12:56,030] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:56,031] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run1
[2019-03-22 23:12:56,959] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:12:56,963] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-22 23:12:57,043] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:57,070] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run1
[2019-03-22 23:12:57,964] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:12:57,974] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-22 23:12:58,050] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:58,064] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run1
[2019-03-22 23:12:58,969] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:12:58,971] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-22 23:12:59,047] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:59,047] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run1
[2019-03-22 23:12:59,972] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:12:59,976] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-22 23:13:00,053] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:00,053] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run1
[2019-03-22 23:13:00,977] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:13:00,982] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-22 23:13:01,042] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:01,043] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run1
[2019-03-22 23:13:01,981] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:13:01,986] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-22 23:13:02,044] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:02,046] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run1
[2019-03-22 23:13:02,986] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:13:02,991] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-22 23:13:03,050] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:03,051] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run1
[2019-03-22 23:13:03,989] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:13:03,992] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-22 23:13:04,055] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:04,056] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run1
[2019-03-22 23:13:04,992] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:13:04,995] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-22 23:13:05,060] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:05,061] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run1
[2019-03-22 23:13:05,994] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:13:05,998] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-22 23:13:06,053] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:06,054] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run1
[2019-03-22 23:13:06,998] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:13:07,003] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-22 23:13:07,065] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:07,066] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run1
[2019-03-22 23:13:08,004] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:13:08,012] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-22 23:13:08,075] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:08,076] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run1
[2019-03-22 23:13:09,009] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:13:09,013] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-22 23:13:09,104] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:09,106] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run1
[2019-03-22 23:13:12,179] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 23:13:12,179] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.24011501333333, 57.80190995333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7435522280995139, 6.911199999999999, 6.9112, 121.9260426156618, 531080.4908274694, 531080.4908274699, 128816.5463121004]
[2019-03-22 23:13:12,182] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:13:12,185] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0.309706   0.15656269 0.28052586 0.1517201  0.10148533], sampled 0.9050638408952578
[2019-03-22 23:13:21,548] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 23:13:21,550] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.6020723, 30.86774558, 1.0, 2.0, 0.559555277442978, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 715449.8229788356, 715449.8229788356, 153659.3179641138]
[2019-03-22 23:13:21,551] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:13:21,554] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.2383397  0.2463558  0.1465965  0.25871035 0.10999766], sampled 0.26894096728167727
[2019-03-22 23:13:34,949] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 23:13:34,950] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.8, 49.0, 1.0, 2.0, 0.6903617323747183, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 786811.4409156886, 786811.4409156886, 174324.2336880488]
[2019-03-22 23:13:34,951] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:13:34,954] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0.20847258 0.26835266 0.15069911 0.33175752 0.04071807], sampled 0.15707077505299238
[2019-03-22 23:13:34,956] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 786811.4409156886 W.
[2019-03-22 23:13:45,688] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 23:13:45,689] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.0, 100.0, 1.0, 2.0, 0.5329463765282144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 631303.5221515656, 631303.5221515656, 148000.7062165095]
[2019-03-22 23:13:45,690] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:13:45,693] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.2747074  0.18799286 0.16973494 0.30383563 0.06372912], sampled 0.6062481482035482
[2019-03-22 23:14:18,272] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 23:14:18,273] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.05, 97.0, 1.0, 2.0, 0.3180940382262405, 1.0, 2.0, 0.3180940382262405, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 725040.0403305569, 725040.0403305573, 184859.4341917003]
[2019-03-22 23:14:18,274] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:14:18,277] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.08621983 0.38770986 0.2809052  0.18222283 0.06294234], sampled 0.13071709164787393
[2019-03-22 23:14:24,033] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 23:14:24,035] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.922606325, 51.685823425, 1.0, 2.0, 0.4960290087226106, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 585192.0708488493, 585192.0708488493, 142025.0237120041]
[2019-03-22 23:14:24,037] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:14:24,041] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.17473514 0.25279197 0.30508003 0.19078343 0.07660947], sampled 0.450818969048963
[2019-03-22 23:14:34,157] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 23:14:34,158] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.5, 56.66666666666667, 1.0, 2.0, 0.2866445401709738, 1.0, 1.0, 0.2866445401709738, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 660606.7025403681, 660606.7025403684, 177648.2245205629]
[2019-03-22 23:14:34,158] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:14:34,161] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0.2548527  0.22993177 0.17047405 0.27247608 0.07226546], sampled 0.25603157309440705
[2019-03-22 23:14:38,462] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 23:14:38,463] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.4, 67.0, 1.0, 2.0, 0.6998231524766508, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9766869934987698, 6.911199999999999, 6.9112, 121.9260426156618, 1532741.902392242, 1532741.902392243, 313185.1135502088]
[2019-03-22 23:14:38,464] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:14:38,470] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.25528708 0.15422778 0.36233613 0.1717582  0.05639086], sampled 0.23136967937056974
[2019-03-22 23:14:38,472] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1532741.902392242 W.
[2019-03-22 23:14:50,588] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4615.4464 2360014393.6276 276.0000
[2019-03-22 23:14:50,630] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4460.3257 2419553023.9831 361.0000
[2019-03-22 23:14:50,800] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4353.0493 2645520865.5756 497.0000
[2019-03-22 23:14:50,850] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4454.7632 2395037841.5476 298.0000
[2019-03-22 23:14:50,965] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4442.3566 2459845558.5365 348.0000
[2019-03-22 23:14:51,979] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 4353.049290569168, 2645520865.575612, 497.0, 4454.763170082297, 2395037841.547604, 298.0, 4615.446386552132, 2360014393.6275587, 276.0, 4442.356564666999, 2459845558.5365148, 348.0, 4460.325691190856, 2419553023.983067, 361.0]
[2019-03-22 23:14:58,149] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2501962e-11 3.0984578e-04 4.2941068e-09 9.9882716e-01 8.6302607e-04], sum to 1.0000
[2019-03-22 23:14:58,155] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3887
[2019-03-22 23:14:58,260] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.3, 50.5, 1.0, 2.0, 0.2089654430892563, 1.0, 2.0, 0.2089654430892563, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 509659.4113895294, 509659.4113895294, 161575.4736855325], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 73800.0000, 
sim time next is 74400.0000, 
raw observation next is [27.13333333333333, 51.33333333333333, 1.0, 2.0, 0.2086779371908966, 1.0, 2.0, 0.2086779371908966, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 508903.1912247504, 508903.1912247508, 161512.3721180832], 
processed observation next is [1.0, 0.8695652173913043, 0.5604938271604937, 0.5133333333333333, 1.0, 1.0, 0.05794992522725787, 1.0, 1.0, 0.05794992522725787, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18175113972312515, 0.1817511397231253, 0.3106007156116985], 
reward next is 0.6894, 
noisyNet noise sample is [array([-1.2247863], dtype=float32), -0.7261835]. 
=============================================
[2019-03-22 23:15:01,736] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0823113e-12 5.7074340e-05 2.0451612e-09 9.9988592e-01 5.6981666e-05], sum to 1.0000
[2019-03-22 23:15:01,743] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3801
[2019-03-22 23:15:01,849] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.4, 15.0, 1.0, 2.0, 0.645663349887818, 1.0, 2.0, 0.645663349887818, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1572331.78599953, 1572331.78599953, 288310.0341351776], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 136800.0000, 
sim time next is 137400.0000, 
raw observation next is [37.4, 14.5, 1.0, 2.0, 0.7034222566604662, 1.0, 2.0, 0.7034222566604662, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1714641.260415463, 1714641.260415463, 310183.1241575367], 
processed observation next is [1.0, 0.6086956521739131, 0.9407407407407407, 0.145, 1.0, 1.0, 0.6469312579291264, 1.0, 1.0, 0.6469312579291264, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6123718787198082, 0.6123718787198082, 0.5965060079952629], 
reward next is 0.4035, 
noisyNet noise sample is [array([-0.755665], dtype=float32), 0.99727345]. 
=============================================
[2019-03-22 23:15:02,714] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0029904e-13 1.3845998e-05 2.5421854e-10 9.9995422e-01 3.1977925e-05], sum to 1.0000
[2019-03-22 23:15:02,726] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4439
[2019-03-22 23:15:02,822] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.75, 10.0, 1.0, 2.0, 0.1932196086084632, 1.0, 2.0, 0.1932196086084632, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 495983.6781783893, 495983.6781783898, 158740.3931156684], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 153000.0000, 
sim time next is 153600.0000, 
raw observation next is [34.46666666666667, 10.66666666666667, 1.0, 2.0, 0.192112336243494, 1.0, 2.0, 0.192112336243494, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 492915.3041479611, 492915.3041479616, 158509.7749939331], 
processed observation next is [1.0, 0.782608695652174, 0.8320987654320988, 0.1066666666666667, 1.0, 1.0, 0.038228971718445234, 1.0, 1.0, 0.038228971718445234, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17604118005284325, 0.17604118005284344, 0.3048264903729483], 
reward next is 0.6952, 
noisyNet noise sample is [array([-1.8389494], dtype=float32), 0.2097247]. 
=============================================
[2019-03-22 23:15:05,052] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4671079e-17 9.9998665e-01 2.2182164e-11 3.6443043e-07 1.2951473e-05], sum to 1.0000
[2019-03-22 23:15:05,059] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2889
[2019-03-22 23:15:05,169] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.98333333333333, 60.66666666666666, 1.0, 2.0, 0.2550939688492486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 328602.1487773325, 328602.1487773325, 110198.2797349269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 195000.0000, 
sim time next is 195600.0000, 
raw observation next is [21.16666666666667, 61.33333333333334, 1.0, 2.0, 0.2582619160811342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 331972.5556729705, 331972.5556729705, 110570.5709980322], 
processed observation next is [0.0, 0.2608695652173913, 0.33950617283950635, 0.6133333333333334, 1.0, 1.0, 0.11697847152515975, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11856162702606089, 0.11856162702606089, 0.21263571345775423], 
reward next is 0.7874, 
noisyNet noise sample is [array([-0.7092042], dtype=float32), -1.0994911]. 
=============================================
[2019-03-22 23:15:09,290] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.3466974e-21 9.9999118e-01 2.4933996e-12 3.1714342e-06 5.5851669e-06], sum to 1.0000
[2019-03-22 23:15:09,293] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2781
[2019-03-22 23:15:09,297] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 50.0, 1.0, 2.0, 0.262818821898978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 339017.3225872531, 339017.3225872531, 96178.00989858127], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 266400.0000, 
sim time next is 267000.0000, 
raw observation next is [20.81666666666667, 50.16666666666667, 1.0, 2.0, 0.2614181102133714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 337210.1083365334, 337210.1083365334, 95667.19530007259], 
processed observation next is [0.0, 0.08695652173913043, 0.32654320987654334, 0.5016666666666667, 1.0, 1.0, 0.12073584549210882, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12043218154876194, 0.12043218154876194, 0.18397537557706267], 
reward next is 0.8160, 
noisyNet noise sample is [array([-0.0077749], dtype=float32), -0.71969914]. 
=============================================
[2019-03-22 23:15:09,328] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[65.581406]
 [65.6956  ]
 [65.67761 ]
 [65.756905]
 [65.84205 ]], R is [[65.8319931 ]
 [65.98871613]
 [66.14265442]
 [66.29370117]
 [66.44151306]].
[2019-03-22 23:15:10,861] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7918: loss 0.0837
[2019-03-22 23:15:10,914] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 7918: learning rate 0.0010
[2019-03-22 23:15:10,938] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7936: loss 0.0582
[2019-03-22 23:15:10,940] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7936: learning rate 0.0010
[2019-03-22 23:15:10,964] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7949: loss 0.2414
[2019-03-22 23:15:10,969] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7951: learning rate 0.0010
[2019-03-22 23:15:10,975] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 7954: loss 0.1338
[2019-03-22 23:15:10,977] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 7954: learning rate 0.0010
[2019-03-22 23:15:10,980] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7956: loss 0.3039
[2019-03-22 23:15:10,983] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 7957: learning rate 0.0010
[2019-03-22 23:15:10,994] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 7962: loss 0.3695
[2019-03-22 23:15:10,999] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 7962: learning rate 0.0010
[2019-03-22 23:15:11,015] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7968: loss 0.2584
[2019-03-22 23:15:11,018] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7969: learning rate 0.0010
[2019-03-22 23:15:11,038] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 7981: loss 0.3104
[2019-03-22 23:15:11,041] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 7981: loss 0.2385
[2019-03-22 23:15:11,041] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 7981: learning rate 0.0010
[2019-03-22 23:15:11,042] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 7981: learning rate 0.0010
[2019-03-22 23:15:11,055] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 7988: loss 0.2575
[2019-03-22 23:15:11,060] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7989: loss 0.2095
[2019-03-22 23:15:11,062] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 7989: learning rate 0.0010
[2019-03-22 23:15:11,065] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7989: learning rate 0.0010
[2019-03-22 23:15:11,119] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 8017: loss 0.0968
[2019-03-22 23:15:11,122] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 8019: learning rate 0.0010
[2019-03-22 23:15:11,131] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 8024: loss 0.0311
[2019-03-22 23:15:11,133] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 8025: learning rate 0.0010
[2019-03-22 23:15:11,168] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 8042: loss 0.0002
[2019-03-22 23:15:11,169] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 8042: learning rate 0.0010
[2019-03-22 23:15:11,200] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 8054: loss 0.0003
[2019-03-22 23:15:11,201] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 8054: learning rate 0.0010
[2019-03-22 23:15:11,254] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 8079: loss 0.0241
[2019-03-22 23:15:11,255] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 8079: learning rate 0.0010
[2019-03-22 23:15:15,378] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.6962965e-21 9.9999976e-01 3.5164847e-14 2.2415830e-07 6.6391048e-10], sum to 1.0000
[2019-03-22 23:15:15,386] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5323
[2019-03-22 23:15:15,491] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 33.5, 1.0, 2.0, 0.870702272697101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.014367677136711, 6.9112, 121.9254632867497, 1168715.346787564, 1115884.526096896, 215158.7570369703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 379800.0000, 
sim time next is 380400.0000, 
raw observation next is [27.0, 33.0, 1.0, 2.0, 0.8785276766560056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.065579698004341, 6.9112, 121.9252469810476, 1204442.6346488, 1125386.946855037, 216928.3481791435], 
processed observation next is [1.0, 0.391304347826087, 0.5555555555555556, 0.33, 1.0, 1.0, 0.8553900912571495, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.015437969800434104, 0.0, 0.8094568466336993, 0.4301580838031428, 0.40192390959108465, 0.41716990034450674], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.23370446], dtype=float32), -0.020599283]. 
=============================================
[2019-03-22 23:15:15,645] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.9372374e-25 1.0000000e+00 2.3852869e-16 5.7350313e-08 1.0048891e-11], sum to 1.0000
[2019-03-22 23:15:15,656] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5208
[2019-03-22 23:15:15,755] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 34.0, 1.0, 2.0, 0.8664285141071355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.988044668033963, 6.9112, 121.9256190318753, 1150351.335440977, 1111000.133819749, 214196.4493788135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 379200.0000, 
sim time next is 379800.0000, 
raw observation next is [26.8, 33.5, 1.0, 2.0, 0.870702272697101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.014367677136711, 6.9112, 121.9254632867497, 1168715.346787564, 1115884.526096896, 215158.7570369703], 
processed observation next is [1.0, 0.391304347826087, 0.5481481481481482, 0.335, 1.0, 1.0, 0.8460741341632154, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.010316767713671116, 0.0, 0.8094582826786192, 0.4173983381384157, 0.3985301878917486, 0.4137668404557121], 
reward next is 0.0704, 
noisyNet noise sample is [array([2.1451752], dtype=float32), -2.0165272]. 
=============================================
[2019-03-22 23:15:20,308] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 8.2124813e-31 3.4776107e-30 3.5409394e-24], sum to 1.0000
[2019-03-22 23:15:20,317] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3500
[2019-03-22 23:15:20,416] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 48.0, 1.0, 2.0, 0.7383933792942095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 933654.3363187202, 933654.3363187202, 186820.4754391763], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 464400.0000, 
sim time next is 465000.0000, 
raw observation next is [25.51666666666667, 47.16666666666666, 1.0, 2.0, 0.8359322475745078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1055477.113075319, 1055477.113075319, 207317.6418971136], 
processed observation next is [1.0, 0.391304347826087, 0.5006172839506173, 0.47166666666666657, 1.0, 1.0, 0.8046812471125093, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3769561118126139, 0.3769561118126139, 0.3986877728790646], 
reward next is 0.6013, 
noisyNet noise sample is [array([-1.7872723], dtype=float32), -0.33843207]. 
=============================================
[2019-03-22 23:15:20,433] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.12359 ]
 [63.116276]
 [63.158108]
 [63.18367 ]
 [63.17661 ]], R is [[63.16847229]
 [63.17751694]
 [63.17578506]
 [63.18862152]
 [63.23982239]].
[2019-03-22 23:15:24,043] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.0763138e-31 5.1150044e-32 3.6283866e-22], sum to 1.0000
[2019-03-22 23:15:24,051] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5911
[2019-03-22 23:15:24,057] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.86666666666667, 75.0, 1.0, 2.0, 0.3293455430465352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 420313.636904403, 420313.636904403, 119278.4122688979], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 531600.0000, 
sim time next is 532200.0000, 
raw observation next is [19.78333333333333, 75.5, 1.0, 2.0, 0.3246235054713112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 414361.1856674658, 414361.1856674658, 118672.409002684], 
processed observation next is [1.0, 0.13043478260869565, 0.28827160493827153, 0.755, 1.0, 1.0, 0.19598036365632285, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14798613773838065, 0.14798613773838065, 0.2282161711590077], 
reward next is 0.7718, 
noisyNet noise sample is [array([-0.6907072], dtype=float32), -0.31383234]. 
=============================================
[2019-03-22 23:15:27,443] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15840: loss 1.7264
[2019-03-22 23:15:27,447] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 15842: learning rate 0.0010
[2019-03-22 23:15:27,523] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15884: loss 1.1138
[2019-03-22 23:15:27,525] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 15885: learning rate 0.0010
[2019-03-22 23:15:27,592] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 15916: loss 0.7144
[2019-03-22 23:15:27,594] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 15917: learning rate 0.0010
[2019-03-22 23:15:27,654] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 15941: loss 0.5912
[2019-03-22 23:15:27,658] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 15942: learning rate 0.0010
[2019-03-22 23:15:27,658] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 15943: loss 0.3356
[2019-03-22 23:15:27,664] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 15943: learning rate 0.0010
[2019-03-22 23:15:27,683] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 15957: loss 0.2910
[2019-03-22 23:15:27,685] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 15957: learning rate 0.0010
[2019-03-22 23:15:27,703] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15964: loss 0.2475
[2019-03-22 23:15:27,704] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15964: learning rate 0.0010
[2019-03-22 23:15:27,763] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15993: loss 0.3034
[2019-03-22 23:15:27,767] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15993: learning rate 0.0010
[2019-03-22 23:15:27,779] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 16000: loss 0.1235
[2019-03-22 23:15:27,781] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 16000: learning rate 0.0010
[2019-03-22 23:15:27,783] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 16000: loss 0.1507
[2019-03-22 23:15:27,783] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 16000: learning rate 0.0010
[2019-03-22 23:15:27,799] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 16007: loss 0.1683
[2019-03-22 23:15:27,801] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 16007: learning rate 0.0010
[2019-03-22 23:15:27,807] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 16008: loss 0.0582
[2019-03-22 23:15:27,808] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 16008: learning rate 0.0010
[2019-03-22 23:15:27,898] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 16050: loss 0.0445
[2019-03-22 23:15:27,903] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 16053: learning rate 0.0010
[2019-03-22 23:15:27,948] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 16075: loss 0.0005
[2019-03-22 23:15:27,952] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 16076: learning rate 0.0010
[2019-03-22 23:15:27,965] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 16082: loss 0.0009
[2019-03-22 23:15:27,969] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 16082: learning rate 0.0010
[2019-03-22 23:15:28,116] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 16151: loss 0.0483
[2019-03-22 23:15:28,118] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 16151: learning rate 0.0010
[2019-03-22 23:15:32,999] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.8586199e-37 1.0000000e+00 1.7023946e-30 8.0704379e-29 6.2018548e-22], sum to 1.0000
[2019-03-22 23:15:33,002] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3545
[2019-03-22 23:15:33,103] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 35.5, 1.0, 2.0, 0.3315409882164033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 420734.7684051611, 420734.7684051611, 119548.7886606814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 689400.0000, 
sim time next is 690000.0000, 
raw observation next is [27.66666666666666, 35.66666666666667, 1.0, 2.0, 0.329818417077115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 418860.1419106686, 418860.1419106686, 119328.9234228422], 
processed observation next is [1.0, 1.0, 0.5802469135802467, 0.3566666666666667, 1.0, 1.0, 0.20216478223466072, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1495929078252388, 0.1495929078252388, 0.22947869889008116], 
reward next is 0.7705, 
noisyNet noise sample is [array([1.6075568], dtype=float32), 1.4748105]. 
=============================================
[2019-03-22 23:15:33,135] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[87.26233 ]
 [87.21465 ]
 [87.158745]
 [87.06681 ]
 [86.979706]], R is [[87.21089172]
 [87.10887909]
 [87.00744629]
 [86.90657043]
 [86.80625916]].
[2019-03-22 23:15:33,824] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.3695983e-27 1.0000000e+00 3.8129272e-24 2.2251091e-20 1.0270017e-19], sum to 1.0000
[2019-03-22 23:15:33,831] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1509
[2019-03-22 23:15:33,843] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 43.0, 1.0, 2.0, 0.4006480586043558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513632.9194004771, 513632.9194004771, 128916.9836723836], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 702000.0000, 
sim time next is 702600.0000, 
raw observation next is [24.53333333333333, 43.83333333333334, 1.0, 2.0, 0.4276211817263025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 548200.8541776899, 548200.8541776894, 132799.4714397267], 
processed observation next is [1.0, 0.13043478260869565, 0.46419753086419746, 0.4383333333333334, 1.0, 1.0, 0.3185966449122648, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19578601934917494, 0.19578601934917478, 0.25538359892255136], 
reward next is 0.7446, 
noisyNet noise sample is [array([0.6135272], dtype=float32), -0.85310155]. 
=============================================
[2019-03-22 23:15:35,126] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.9961330e-36 1.0000000e+00 8.8769266e-32 7.6304334e-26 1.6159059e-24], sum to 1.0000
[2019-03-22 23:15:35,135] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8358
[2019-03-22 23:15:35,145] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1385270.989209614 W.
[2019-03-22 23:15:35,242] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.23333333333333, 52.83333333333334, 1.0, 2.0, 0.9512285807572877, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.324784125403762, 6.9112, 121.924400151268, 1385270.989209614, 1173481.804321464, 233129.9327234861], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 727800.0000, 
sim time next is 728400.0000, 
raw observation next is [26.36666666666667, 52.66666666666667, 1.0, 2.0, 0.5275654244676703, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8621491726156671, 6.911200000000001, 6.9112, 121.9257935624547, 1288490.246152001, 1288490.246152001, 263838.3196897332], 
processed observation next is [1.0, 0.43478260869565216, 0.5320987654320989, 0.5266666666666667, 1.0, 1.0, 0.43757788627103605, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.8276864657695839, 8.881784197001253e-17, 0.0, 0.8094604753658379, 0.4601750879114289, 0.4601750879114289, 0.5073813840187177], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2913278], dtype=float32), -1.1538241]. 
=============================================
[2019-03-22 23:15:43,322] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 9.8104543e-35 7.3680828e-31 7.9594376e-33], sum to 1.0000
[2019-03-22 23:15:43,332] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1751
[2019-03-22 23:15:43,438] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.76666666666667, 63.33333333333334, 1.0, 2.0, 0.3861053772508486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 481392.2799525632, 481392.2799525632, 126741.4162570162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 867000.0000, 
sim time next is 867600.0000, 
raw observation next is [23.6, 64.0, 1.0, 2.0, 0.3840885448886922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479198.7986880673, 479198.7986880673, 126468.4495059791], 
processed observation next is [0.0, 0.043478260869565216, 0.4296296296296297, 0.64, 1.0, 1.0, 0.2667720772484431, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1711424281028812, 0.1711424281028812, 0.2432085567422675], 
reward next is 0.7568, 
noisyNet noise sample is [array([-0.10084916], dtype=float32), -0.50409806]. 
=============================================
[2019-03-22 23:15:45,021] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23835: loss 0.0038
[2019-03-22 23:15:45,024] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 23836: learning rate 0.0010
[2019-03-22 23:15:45,096] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23864: loss 0.0054
[2019-03-22 23:15:45,101] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 23866: learning rate 0.0010
[2019-03-22 23:15:45,230] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23929: loss 0.0558
[2019-03-22 23:15:45,238] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23932: learning rate 0.0010
[2019-03-22 23:15:45,242] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23933: loss 0.0366
[2019-03-22 23:15:45,242] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 23933: loss 0.0764
[2019-03-22 23:15:45,243] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 23933: learning rate 0.0010
[2019-03-22 23:15:45,247] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 23933: learning rate 0.0010
[2019-03-22 23:15:45,253] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 23937: loss 0.0550
[2019-03-22 23:15:45,255] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 23937: learning rate 0.0010
[2019-03-22 23:15:45,339] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23979: loss 0.0015
[2019-03-22 23:15:45,341] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23979: learning rate 0.0010
[2019-03-22 23:15:45,346] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23982: loss 0.0066
[2019-03-22 23:15:45,349] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23983: learning rate 0.0010
[2019-03-22 23:15:45,369] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23992: loss 0.0007
[2019-03-22 23:15:45,374] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 23995: learning rate 0.0010
[2019-03-22 23:15:45,394] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 24000: loss 0.0078
[2019-03-22 23:15:45,398] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 24000: learning rate 0.0010
[2019-03-22 23:15:45,404] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 24005: loss 0.0017
[2019-03-22 23:15:45,407] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 24006: learning rate 0.0010
[2019-03-22 23:15:45,471] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 24035: loss 0.0759
[2019-03-22 23:15:45,473] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 24035: learning rate 0.0010
[2019-03-22 23:15:45,502] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24048: loss 0.0763
[2019-03-22 23:15:45,503] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 24049: learning rate 0.0010
[2019-03-22 23:15:45,526] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 24059: loss 0.1041
[2019-03-22 23:15:45,530] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 24060: learning rate 0.0010
[2019-03-22 23:15:45,598] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 24092: loss 0.0511
[2019-03-22 23:15:45,601] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 24093: learning rate 0.0010
[2019-03-22 23:15:45,718] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 24143: loss 0.0129
[2019-03-22 23:15:45,725] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 24145: learning rate 0.0010
[2019-03-22 23:15:46,880] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0772163e-35 3.1048971e-37], sum to 1.0000
[2019-03-22 23:15:46,887] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4581
[2019-03-22 23:15:46,894] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.96666666666667, 43.0, 1.0, 2.0, 0.3880240223850213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 482812.4040356968, 482812.4040356964, 126988.3287908639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 926400.0000, 
sim time next is 927000.0000, 
raw observation next is [27.8, 43.5, 1.0, 2.0, 0.3857729844325536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 480264.8425212643, 480264.8425212643, 126681.3181981347], 
processed observation next is [0.0, 0.7391304347826086, 0.5851851851851853, 0.435, 1.0, 1.0, 0.2687773624197067, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17152315804330867, 0.17152315804330867, 0.2436179196117975], 
reward next is 0.7564, 
noisyNet noise sample is [array([1.1691339], dtype=float32), 0.9435045]. 
=============================================
[2019-03-22 23:15:46,908] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[90.96801 ]
 [90.928856]
 [90.865295]
 [90.80778 ]
 [90.775894]], R is [[90.84682465]
 [90.6941452 ]
 [90.54303741]
 [90.39330292]
 [90.24414825]].
[2019-03-22 23:15:47,615] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-22 23:15:47,617] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:15:47,618] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:47,619] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:15:47,620] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:15:47,621] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:15:47,623] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:47,621] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:47,623] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:15:47,624] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:47,627] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:47,649] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run2
[2019-03-22 23:15:47,650] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run2
[2019-03-22 23:15:47,650] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run2
[2019-03-22 23:15:47,685] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run2
[2019-03-22 23:15:47,700] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run2
[2019-03-22 23:16:09,564] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05358668], dtype=float32), 0.16995448]
[2019-03-22 23:16:09,566] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.42642964666667, 21.02502261933333, 1.0, 2.0, 0.3562484119139931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 456725.0377882027, 456725.0377882027, 122809.8869062553]
[2019-03-22 23:16:09,567] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:16:09,570] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.9355912e-36 2.1322602e-31 3.1378653e-31], sampled 0.053723252895716
[2019-03-22 23:16:53,674] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05358668], dtype=float32), 0.16995448]
[2019-03-22 23:16:53,676] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.1, 85.0, 1.0, 2.0, 0.6313265955507101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 719496.9900452038, 719496.9900452034, 163550.6605561363]
[2019-03-22 23:16:53,678] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:16:53,681] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.2451323e-38 6.7279816e-33 9.3423332e-34], sampled 0.5886891437413931
[2019-03-22 23:16:58,096] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05358668], dtype=float32), 0.16995448]
[2019-03-22 23:16:58,099] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.5, 76.0, 1.0, 2.0, 0.5321121364491066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 648504.4763684667, 648504.4763684663, 148496.7846109266]
[2019-03-22 23:16:58,100] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:16:58,103] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.4788983e-37 7.1025637e-32 1.1577910e-32], sampled 0.4582185190899478
[2019-03-22 23:17:17,232] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05358668], dtype=float32), 0.16995448]
[2019-03-22 23:17:17,233] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.62309655166667, 59.98144514, 1.0, 2.0, 0.6956346228477598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 792824.109366317, 792824.109366317, 175321.8143336294]
[2019-03-22 23:17:17,236] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:17:17,239] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 3.1140170e-38 1.7436150e-32 1.7649146e-33], sampled 0.029304193225808906
[2019-03-22 23:17:29,364] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05358668], dtype=float32), 0.16995448]
[2019-03-22 23:17:29,487] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.84531932333333, 64.51218290333334, 1.0, 2.0, 0.3244005121079515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 409673.08895136, 409673.08895136, 118612.8456670451]
[2019-03-22 23:17:29,488] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:17:29,490] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 4.8303386e-38 9.6183635e-33 2.7097571e-33], sampled 0.42011900608052744
[2019-03-22 23:17:31,293] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05358668], dtype=float32), 0.16995448]
[2019-03-22 23:17:31,294] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.66666666666666, 79.83333333333333, 1.0, 2.0, 0.66548083181821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758440.4267257828, 758440.4267257828, 169713.8585576351]
[2019-03-22 23:17:31,296] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:17:31,298] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6020274e-33 3.7200665e-34], sampled 0.1492747634044741
[2019-03-22 23:17:40,797] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-22 23:17:40,807] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-22 23:17:40,927] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-22 23:17:40,951] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-22 23:17:41,047] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-22 23:17:42,064] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 25000, evaluation results [25000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-22 23:17:42,712] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 8.0665969e-35 4.5042694e-34 4.8240139e-34], sum to 1.0000
[2019-03-22 23:17:42,722] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2100
[2019-03-22 23:17:42,728] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 50.66666666666666, 1.0, 2.0, 0.3155582554593788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 401685.9050461983, 401685.9050461983, 117515.3837797811], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 943800.0000, 
sim time next is 944400.0000, 
raw observation next is [23.9, 50.33333333333334, 1.0, 2.0, 0.3105440754145342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 395872.7629029261, 395872.7629029261, 116886.7774657219], 
processed observation next is [0.0, 0.9565217391304348, 0.4407407407407407, 0.5033333333333334, 1.0, 1.0, 0.179219137398255, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14138312960818789, 0.14138312960818789, 0.2247822643571575], 
reward next is 0.7752, 
noisyNet noise sample is [array([0.01914995], dtype=float32), 0.8176006]. 
=============================================
[2019-03-22 23:17:45,872] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1777192e-05 2.0998558e-01 1.1150832e-11 7.8998268e-01 1.3607355e-08], sum to 1.0000
[2019-03-22 23:17:45,881] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8701
[2019-03-22 23:17:45,887] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.4, 52.5, 1.0, 2.0, 0.9319877643940766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.277537834466557, 6.9112, 121.9244095997842, 1352311.035618621, 1164715.834056748, 228955.2333611739], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 999000.0000, 
sim time next is 999600.0000, 
raw observation next is [25.43333333333334, 52.33333333333333, 1.0, 2.0, 0.5109901687658591, 1.0, 1.0, 0.5109901687658591, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9258219866142, 1252512.440277405, 1252512.440277405, 242259.4103685364], 
processed observation next is [1.0, 0.5652173913043478, 0.4975308641975311, 0.5233333333333333, 1.0, 1.0, 0.41784543900697513, 1.0, 0.5, 0.41784543900697513, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094606640726979, 0.4473258715276447, 0.4473258715276447, 0.4658834814779546], 
reward next is 0.5341, 
noisyNet noise sample is [array([-0.78716975], dtype=float32), -1.4241605]. 
=============================================
[2019-03-22 23:17:49,160] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4771372e-32 1.0000000e+00 7.4948406e-35 6.5443552e-19 2.9735007e-24], sum to 1.0000
[2019-03-22 23:17:49,167] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3264
[2019-03-22 23:17:49,174] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.86666666666667, 58.0, 1.0, 2.0, 0.5073950354691001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 644773.0474337838, 644773.0474337838, 145025.0184797199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1066800.0000, 
sim time next is 1067400.0000, 
raw observation next is [22.95, 57.5, 1.0, 2.0, 0.582992669229168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740556.7014213348, 740556.7014213348, 157668.4962910326], 
processed observation next is [1.0, 0.34782608695652173, 0.4055555555555555, 0.575, 1.0, 1.0, 0.5035627014632953, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26448453622190526, 0.26448453622190526, 0.30320864671352427], 
reward next is 0.6968, 
noisyNet noise sample is [array([-1.149884], dtype=float32), -1.9926386]. 
=============================================
[2019-03-22 23:17:51,445] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5753227e-30 1.0000000e+00 1.2973132e-31 5.4608008e-19 1.4043505e-26], sum to 1.0000
[2019-03-22 23:17:51,455] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6938
[2019-03-22 23:17:51,571] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 55.5, 1.0, 2.0, 0.3372974182459268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 425629.8820564277, 425629.8820564277, 120271.1059797575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1103400.0000, 
sim time next is 1104000.0000, 
raw observation next is [23.8, 56.66666666666666, 1.0, 2.0, 0.3361432072150966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424338.2679815418, 424338.2679815418, 120123.0199096853], 
processed observation next is [1.0, 0.782608695652174, 0.43703703703703706, 0.5666666666666665, 1.0, 1.0, 0.20969429430368644, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1515493814219792, 0.1515493814219792, 0.2310058075186256], 
reward next is 0.7690, 
noisyNet noise sample is [array([0.12518995], dtype=float32), 0.6558057]. 
=============================================
[2019-03-22 23:17:51,599] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[55.391426]
 [55.213753]
 [54.778145]
 [54.789803]
 [54.751373]], R is [[55.6150322 ]
 [55.82759476]
 [56.03778839]
 [56.24593735]
 [56.45241547]].
[2019-03-22 23:17:54,918] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.5228152e-33 1.0000000e+00 6.1200374e-32 2.8109057e-18 2.3086080e-27], sum to 1.0000
[2019-03-22 23:17:54,926] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8023
[2019-03-22 23:17:54,931] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.53333333333333, 66.66666666666667, 1.0, 2.0, 0.5398338731661454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691632.0835058815, 691632.0835058815, 150345.0981167547], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1156800.0000, 
sim time next is 1157400.0000, 
raw observation next is [20.6, 66.5, 1.0, 2.0, 0.5397508969684752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 691292.0731469521, 691292.0731469516, 150331.4407642356], 
processed observation next is [1.0, 0.391304347826087, 0.3185185185185186, 0.665, 1.0, 1.0, 0.4520844011529467, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24689002612391145, 0.24689002612391128, 0.2890989245466069], 
reward next is 0.7109, 
noisyNet noise sample is [array([-2.047042], dtype=float32), 1.6193581]. 
=============================================
[2019-03-22 23:17:56,534] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31819: loss 0.0228
[2019-03-22 23:17:56,538] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31819: learning rate 0.0010
[2019-03-22 23:17:56,646] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31871: loss 0.2877
[2019-03-22 23:17:56,651] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 31873: learning rate 0.0010
[2019-03-22 23:17:56,682] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 31887: loss 0.4127
[2019-03-22 23:17:56,684] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 31887: learning rate 0.0010
[2019-03-22 23:17:56,719] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 31901: loss 0.2083
[2019-03-22 23:17:56,721] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 31901: learning rate 0.0010
[2019-03-22 23:17:56,746] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31911: loss 0.1956
[2019-03-22 23:17:56,747] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31912: learning rate 0.0010
[2019-03-22 23:17:56,858] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 31967: loss 0.0840
[2019-03-22 23:17:56,861] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 31968: learning rate 0.0010
[2019-03-22 23:17:56,863] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31969: loss 0.0707
[2019-03-22 23:17:56,865] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31970: learning rate 0.0010
[2019-03-22 23:17:56,902] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 31984: loss 0.0066
[2019-03-22 23:17:56,904] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 31984: learning rate 0.0010
[2019-03-22 23:17:56,956] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 32007: loss 0.0046
[2019-03-22 23:17:56,959] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 32009: learning rate 0.0010
[2019-03-22 23:17:56,979] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 32022: loss 0.0037
[2019-03-22 23:17:56,982] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 32024: learning rate 0.0010
[2019-03-22 23:17:56,987] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 32025: loss 0.0086
[2019-03-22 23:17:56,987] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 32025: loss 0.0071
[2019-03-22 23:17:56,990] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 32025: learning rate 0.0010
[2019-03-22 23:17:56,991] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 32026: learning rate 0.0010
[2019-03-22 23:17:57,020] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32042: loss 0.0677
[2019-03-22 23:17:57,022] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 32043: learning rate 0.0010
[2019-03-22 23:17:57,058] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 32057: loss 0.1375
[2019-03-22 23:17:57,059] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 32057: learning rate 0.0010
[2019-03-22 23:17:57,175] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 32114: loss 0.2163
[2019-03-22 23:17:57,179] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 32115: learning rate 0.0010
[2019-03-22 23:17:57,346] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 32190: loss 0.0126
[2019-03-22 23:17:57,347] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 32191: learning rate 0.0010
[2019-03-22 23:17:57,570] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.4948515e-38 8.1564442e-30 2.7398169e-33], sum to 1.0000
[2019-03-22 23:17:57,580] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7955
[2019-03-22 23:17:57,683] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.55, 94.00000000000001, 1.0, 2.0, 0.3404153296644923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 429795.7249121654, 429795.7249121654, 120680.3698541822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1210200.0000, 
sim time next is 1210800.0000, 
raw observation next is [18.5, 94.0, 1.0, 2.0, 0.3388871369528024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428115.8957466062, 428115.8957466062, 120483.7563998804], 
processed observation next is [1.0, 0.0, 0.24074074074074073, 0.94, 1.0, 1.0, 0.2129608773247648, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1528985341952165, 0.1528985341952165, 0.23169953153823153], 
reward next is 0.7683, 
noisyNet noise sample is [array([-0.49002925], dtype=float32), -1.175441]. 
=============================================
[2019-03-22 23:17:59,423] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4851985e-34 1.0000000e+00 4.0903411e-34 1.3077279e-23 1.2973201e-28], sum to 1.0000
[2019-03-22 23:17:59,433] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5758
[2019-03-22 23:17:59,437] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 79.83333333333333, 1.0, 2.0, 0.7094311881356203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 892798.8648029665, 892798.8648029665, 180997.4508746515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1242600.0000, 
sim time next is 1243200.0000, 
raw observation next is [20.7, 78.66666666666667, 1.0, 2.0, 0.6267874899171222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 788290.6235061765, 788290.6235061765, 165368.7629141376], 
processed observation next is [1.0, 0.391304347826087, 0.3222222222222222, 0.7866666666666667, 1.0, 1.0, 0.5556993927584788, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28153236553792016, 0.28153236553792016, 0.3180168517579569], 
reward next is 0.6820, 
noisyNet noise sample is [array([-0.00143037], dtype=float32), 0.04034261]. 
=============================================
[2019-03-22 23:18:00,395] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.33370065e-35 1.00000000e+00 8.72615066e-38 1.07428005e-24
 7.49697148e-31], sum to 1.0000
[2019-03-22 23:18:00,403] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9059
[2019-03-22 23:18:00,409] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.45, 59.5, 1.0, 2.0, 0.772467980965938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 950788.594820052, 950788.5948200516, 193253.9840431349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1258200.0000, 
sim time next is 1258800.0000, 
raw observation next is [25.63333333333333, 59.0, 1.0, 2.0, 0.8955258088455921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.932903453313346, 6.9112, 121.9259655174369, 1111882.399962135, 1100768.299060907, 220000.3828075718], 
processed observation next is [1.0, 0.5652173913043478, 0.5049382716049381, 0.59, 1.0, 1.0, 0.8756259629114191, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0021703453313345555, 0.0, 0.809461616968099, 0.3971008571293339, 0.39313153537889534, 0.42307765924533036], 
reward next is 0.4684, 
noisyNet noise sample is [array([2.089887], dtype=float32), -1.0885903]. 
=============================================
[2019-03-22 23:18:04,291] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.03797095e-34 1.00000000e+00 1.39968463e-29 1.92833895e-21
 1.27879275e-26], sum to 1.0000
[2019-03-22 23:18:04,300] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0028
[2019-03-22 23:18:04,305] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 69.0, 1.0, 2.0, 0.6920993785692447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 857696.0909672761, 857696.0909672761, 177357.1961154197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1326600.0000, 
sim time next is 1327200.0000, 
raw observation next is [23.56666666666667, 67.0, 1.0, 2.0, 0.6332658917267273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 785193.8662210786, 785193.8662210786, 166330.889950004], 
processed observation next is [1.0, 0.34782608695652173, 0.4283950617283952, 0.67, 1.0, 1.0, 0.5634117758651516, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28042638079324234, 0.28042638079324234, 0.3198670960577], 
reward next is 0.6801, 
noisyNet noise sample is [array([-1.0242294], dtype=float32), 0.17051929]. 
=============================================
[2019-03-22 23:18:06,820] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 8.8455193e-33 7.1025945e-31], sum to 1.0000
[2019-03-22 23:18:06,829] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9977
[2019-03-22 23:18:06,927] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 67.0, 1.0, 2.0, 0.3135996714947867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 399236.7643035961, 399236.7643035961, 117268.5953055231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1388400.0000, 
sim time next is 1389000.0000, 
raw observation next is [21.18333333333334, 67.0, 1.0, 2.0, 0.31087256059901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396080.9093634709, 396080.9093634709, 116927.1945497177], 
processed observation next is [0.0, 0.043478260869565216, 0.34012345679012373, 0.67, 1.0, 1.0, 0.17961019118929758, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14145746762981104, 0.14145746762981104, 0.22485998951868788], 
reward next is 0.7751, 
noisyNet noise sample is [array([-0.49067697], dtype=float32), 0.36779156]. 
=============================================
[2019-03-22 23:18:06,942] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[79.556496]
 [79.83246 ]
 [80.248116]
 [80.69938 ]
 [81.2832  ]], R is [[79.3920517 ]
 [79.372612  ]
 [79.35280609]
 [79.33263397]
 [79.31208038]].
[2019-03-22 23:18:13,355] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39835: loss 0.0289
[2019-03-22 23:18:13,356] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39835: learning rate 0.0010
[2019-03-22 23:18:13,385] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39851: loss 0.0022
[2019-03-22 23:18:13,387] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 39851: learning rate 0.0010
[2019-03-22 23:18:13,444] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 39874: loss 0.0022
[2019-03-22 23:18:13,451] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39875: loss 0.0001
[2019-03-22 23:18:13,451] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 39875: learning rate 0.0010
[2019-03-22 23:18:13,453] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39875: learning rate 0.0010
[2019-03-22 23:18:13,495] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39894: loss 0.0068
[2019-03-22 23:18:13,498] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 39894: learning rate 0.0010
[2019-03-22 23:18:13,646] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 39962: loss 0.0248
[2019-03-22 23:18:13,648] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 39963: learning rate 0.0010
[2019-03-22 23:18:13,664] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39967: loss 0.0082
[2019-03-22 23:18:13,666] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39967: learning rate 0.0010
[2019-03-22 23:18:13,712] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 39990: loss 0.0068
[2019-03-22 23:18:13,714] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 39990: learning rate 0.0010
[2019-03-22 23:18:13,755] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 40015: loss 0.0002
[2019-03-22 23:18:13,759] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 40017: learning rate 0.0010
[2019-03-22 23:18:13,768] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 40025: loss 0.0024
[2019-03-22 23:18:13,769] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 40025: learning rate 0.0010
[2019-03-22 23:18:13,776] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 40029: loss 0.0016
[2019-03-22 23:18:13,780] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 40031: learning rate 0.0010
[2019-03-22 23:18:13,789] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 40035: loss 0.0281
[2019-03-22 23:18:13,792] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 40035: learning rate 0.0010
[2019-03-22 23:18:13,909] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 40089: loss 0.0745
[2019-03-22 23:18:13,911] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 40090: learning rate 0.0010
[2019-03-22 23:18:13,958] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 40111: loss 0.0914
[2019-03-22 23:18:13,965] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 40113: learning rate 0.0010
[2019-03-22 23:18:13,988] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 40121: loss 0.1131
[2019-03-22 23:18:13,992] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 40123: learning rate 0.0010
[2019-03-22 23:18:14,104] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 40171: loss 0.0002
[2019-03-22 23:18:14,109] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 40176: learning rate 0.0010
[2019-03-22 23:18:18,848] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4251904e-30 1.0000000e+00 4.9833418e-25 1.5909201e-17 6.8270579e-24], sum to 1.0000
[2019-03-22 23:18:18,856] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6459
[2019-03-22 23:18:18,862] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.41666666666666, 56.83333333333333, 1.0, 2.0, 0.903747372332612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.100682974307579, 6.9112, 121.9252580994238, 1228931.445787422, 1131899.851486251, 222420.2483603908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1588200.0000, 
sim time next is 1588800.0000, 
raw observation next is [24.53333333333333, 56.66666666666667, 1.0, 2.0, 0.9283891748720788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.26086351454961, 6.9112, 121.9244223533735, 1340678.678472953, 1161622.085949005, 228137.9952638324], 
processed observation next is [1.0, 0.391304347826087, 0.46419753086419746, 0.5666666666666668, 1.0, 1.0, 0.9147490177048557, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.034966351454960964, 0.0, 0.8094513719634957, 0.4788138137403403, 0.4148650306960732, 0.43872691396890845], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.0152016], dtype=float32), 0.45435032]. 
=============================================
[2019-03-22 23:18:25,330] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.9679196e-26 2.9846475e-10 2.0510462e-29 1.0000000e+00 1.3707670e-19], sum to 1.0000
[2019-03-22 23:18:25,344] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2852
[2019-03-22 23:18:25,353] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.1, 69.0, 1.0, 2.0, 0.3946670270315484, 1.0, 2.0, 0.3946670270315484, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 966567.9933523152, 966567.9933523147, 207364.4613690676], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1692000.0000, 
sim time next is 1692600.0000, 
raw observation next is [23.15, 69.0, 1.0, 2.0, 0.4426843350270827, 1.0, 2.0, 0.4426843350270827, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1082083.92529159, 1082083.92529159, 221115.9316356316], 
processed observation next is [1.0, 0.6086956521739131, 0.4129629629629629, 0.69, 1.0, 1.0, 0.3365289702703365, 1.0, 1.0, 0.3365289702703365, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3864585447469964, 0.3864585447469964, 0.4252229454531377], 
reward next is 0.5748, 
noisyNet noise sample is [array([-0.96953297], dtype=float32), -0.6327698]. 
=============================================
[2019-03-22 23:18:29,932] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7416684e-21 2.0228472e-05 9.7339608e-25 9.9997973e-01 1.0421186e-13], sum to 1.0000
[2019-03-22 23:18:29,940] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9824
[2019-03-22 23:18:29,948] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.2, 66.33333333333334, 1.0, 2.0, 0.4685678344223592, 1.0, 2.0, 0.4685678344223592, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1115342.965401036, 1115342.965401036, 227887.3213255785], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1772400.0000, 
sim time next is 1773000.0000, 
raw observation next is [25.25, 66.0, 1.0, 2.0, 0.4336651969018376, 1.0, 2.0, 0.4336651969018376, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1034861.060321599, 1034861.060321599, 217626.9274961613], 
processed observation next is [1.0, 0.5217391304347826, 0.49074074074074076, 0.66, 1.0, 1.0, 0.32579190107361616, 1.0, 1.0, 0.32579190107361616, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3695932358291425, 0.3695932358291425, 0.4185133221080025], 
reward next is 0.5815, 
noisyNet noise sample is [array([0.4557253], dtype=float32), 0.7852418]. 
=============================================
[2019-03-22 23:18:29,963] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[51.943676]
 [51.898705]
 [51.99476 ]
 [52.015884]
 [52.043785]], R is [[52.02357864]
 [52.06509781]
 [52.03128052]
 [52.03636551]
 [52.03760529]].
[2019-03-22 23:18:30,824] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47842: loss 0.9731
[2019-03-22 23:18:30,826] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47842: learning rate 0.0010
[2019-03-22 23:18:30,827] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 47843: loss 0.7942
[2019-03-22 23:18:30,829] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 47843: learning rate 0.0010
[2019-03-22 23:18:30,866] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 47859: loss 1.2181
[2019-03-22 23:18:30,871] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 47860: learning rate 0.0010
[2019-03-22 23:18:30,956] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 47901: loss 1.3929
[2019-03-22 23:18:30,958] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 47901: learning rate 0.0010
[2019-03-22 23:18:31,050] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 47944: loss -1.5060
[2019-03-22 23:18:31,056] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 47944: learning rate 0.0010
[2019-03-22 23:18:31,085] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 47961: loss 1.5347
[2019-03-22 23:18:31,090] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 47962: learning rate 0.0010
[2019-03-22 23:18:31,090] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47962: loss 1.6994
[2019-03-22 23:18:31,096] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 47962: learning rate 0.0010
[2019-03-22 23:18:31,096] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 47962: loss 1.6354
[2019-03-22 23:18:31,102] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 47965: learning rate 0.0010
[2019-03-22 23:18:31,111] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 47969: loss 2.2833
[2019-03-22 23:18:31,114] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 47969: learning rate 0.0010
[2019-03-22 23:18:31,115] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 47969: loss 1.9511
[2019-03-22 23:18:31,121] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 47970: learning rate 0.0010
[2019-03-22 23:18:31,234] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 48026: loss 1.6402
[2019-03-22 23:18:31,238] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 48026: learning rate 0.0010
[2019-03-22 23:18:31,337] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 48069: loss 0.8927
[2019-03-22 23:18:31,340] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 48069: learning rate 0.0010
[2019-03-22 23:18:31,367] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 48085: loss 0.3104
[2019-03-22 23:18:31,369] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 48085: learning rate 0.0010
[2019-03-22 23:18:31,458] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 48127: loss 0.3333
[2019-03-22 23:18:31,462] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 48127: learning rate 0.0010
[2019-03-22 23:18:31,508] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 48148: loss 0.4436
[2019-03-22 23:18:31,512] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 48148: learning rate 0.0010
[2019-03-22 23:18:31,519] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 48151: loss 0.4533
[2019-03-22 23:18:31,522] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 48151: learning rate 0.0010
[2019-03-22 23:18:31,660] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.8387693e-22 4.9490208e-15 4.8347027e-25 1.0000000e+00 4.6744604e-16], sum to 1.0000
[2019-03-22 23:18:31,673] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3382
[2019-03-22 23:18:31,681] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.5, 86.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 393388.49851155, 393388.4985115504, 150010.5213915214], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1805400.0000, 
sim time next is 1806000.0000, 
raw observation next is [18.53333333333333, 86.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 397169.929215304, 397169.9292153044, 150605.6971425651], 
processed observation next is [1.0, 0.9130434782608695, 0.24197530864197525, 0.8666666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14184640329117998, 0.14184640329118015, 0.289626340658779], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3197145], dtype=float32), 2.2040234]. 
=============================================
[2019-03-22 23:18:31,690] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[40.146477]
 [40.12988 ]
 [39.910225]
 [39.72057 ]
 [39.595913]], R is [[39.71141815]
 [39.31430435]
 [38.92116165]
 [38.5319519 ]
 [38.14663315]].
[2019-03-22 23:18:35,542] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-22 23:18:35,543] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:18:35,545] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:35,546] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:18:35,547] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:35,552] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:18:35,552] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:18:35,553] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:35,553] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:35,554] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:18:35,557] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:35,568] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run3
[2019-03-22 23:18:35,587] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run3
[2019-03-22 23:18:35,588] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run3
[2019-03-22 23:18:35,589] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run3
[2019-03-22 23:18:35,643] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run3
[2019-03-22 23:18:36,998] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.14570631], dtype=float32), 0.23823021]
[2019-03-22 23:18:36,999] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.91666666666667, 38.16666666666666, 1.0, 2.0, 0.3649147398759075, 1.0, 2.0, 0.3649147398759075, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 897914.8041308036, 897914.804130804, 199332.1281564926]
[2019-03-22 23:18:37,001] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:18:37,003] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.4020470e-25 3.6136669e-08 4.3039520e-30 1.0000000e+00 1.1027948e-21], sampled 0.9677408881179752
[2019-03-22 23:19:34,874] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.14570631], dtype=float32), 0.23823021]
[2019-03-22 23:19:34,876] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.90583530666667, 71.94529380333333, 1.0, 2.0, 0.3595616961086238, 1.0, 2.0, 0.3595616961086238, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 819608.8880149823, 819608.8880149828, 195368.6346700416]
[2019-03-22 23:19:34,878] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:19:34,881] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.0836035e-25 2.1806210e-07 8.7224562e-30 9.9999976e-01 2.4577885e-21], sampled 0.11733525923887134
[2019-03-22 23:19:58,664] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.14570631], dtype=float32), 0.23823021]
[2019-03-22 23:19:58,665] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.33895276, 93.88966104, 1.0, 2.0, 0.3161986551612198, 1.0, 2.0, 0.3161986551612198, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 720717.8133310755, 720717.813331076, 184394.0743992777]
[2019-03-22 23:19:58,667] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:19:58,669] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.0671263e-26 9.8242005e-08 4.4699077e-30 9.9999988e-01 1.7078594e-21], sampled 0.40528362059557044
[2019-03-22 23:20:28,289] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6906.7263 2495408102.1756 47.0000
[2019-03-22 23:20:28,435] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.3485 2410652606.9095 22.0000
[2019-03-22 23:20:28,436] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0885 2668495691.4595 68.0000
[2019-03-22 23:20:28,437] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7124.7550 2438729605.8140 34.0000
[2019-03-22 23:20:28,683] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7480.0274 2465856778.9468 46.0000
[2019-03-22 23:20:29,698] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 50000, evaluation results [50000.0, 7523.088492180975, 2668495691.4594846, 68.0, 7124.754987767942, 2438729605.814016, 34.0, 7798.348511531635, 2410652606.9095383, 22.0, 6906.726251003709, 2495408102.175574, 47.0, 7480.027397713166, 2465856778.946759, 46.0]
[2019-03-22 23:20:30,244] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2956634e-27 3.5484307e-09 5.8845435e-34 1.0000000e+00 3.1366710e-22], sum to 1.0000
[2019-03-22 23:20:30,253] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5019
[2019-03-22 23:20:30,261] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.25, 89.5, 1.0, 2.0, 0.2159443136001509, 1.0, 2.0, 0.2159443136001509, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 525022.0943225225, 525022.094322523, 163014.6894513922], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1881000.0000, 
sim time next is 1881600.0000, 
raw observation next is [21.23333333333333, 89.66666666666667, 1.0, 2.0, 0.2153569133300619, 1.0, 2.0, 0.2153569133300619, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 523570.164489428, 523570.1644894284, 162887.4170799891], 
processed observation next is [1.0, 0.782608695652174, 0.34197530864197523, 0.8966666666666667, 1.0, 1.0, 0.06590108729769274, 1.0, 1.0, 0.06590108729769274, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18698934446051, 0.18698934446051013, 0.31324503284613286], 
reward next is 0.6868, 
noisyNet noise sample is [array([0.73292965], dtype=float32), 1.0452093]. 
=============================================
[2019-03-22 23:20:30,446] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8360785e-28 1.4914971e-07 1.1283581e-34 9.9999988e-01 1.4591938e-22], sum to 1.0000
[2019-03-22 23:20:30,452] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9190
[2019-03-22 23:20:30,459] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 91.0, 1.0, 2.0, 0.2142314060169483, 1.0, 2.0, 0.2142314060169483, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 521412.1813828414, 521412.1813828419, 162665.4565919137], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1890000.0000, 
sim time next is 1890600.0000, 
raw observation next is [20.98333333333333, 91.00000000000001, 1.0, 2.0, 0.2136171878791155, 1.0, 2.0, 0.2136171878791155, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 520020.187976591, 520020.1879765915, 162537.104803295], 
processed observation next is [1.0, 0.9130434782608695, 0.33271604938271593, 0.9100000000000001, 1.0, 1.0, 0.06382998557037559, 1.0, 1.0, 0.06382998557037559, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18572149570592536, 0.18572149570592555, 0.31257135539095193], 
reward next is 0.6874, 
noisyNet noise sample is [array([-0.00281779], dtype=float32), -1.0279388]. 
=============================================
[2019-03-22 23:20:30,744] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2907724e-23 8.3120985e-06 9.2890105e-29 9.9999166e-01 1.7031749e-20], sum to 1.0000
[2019-03-22 23:20:30,755] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8521
[2019-03-22 23:20:30,759] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.91666666666667, 91.0, 1.0, 2.0, 0.2101530686924334, 1.0, 2.0, 0.2101530686924334, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 512174.6824490359, 512174.6824490363, 161815.8747386547], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1893000.0000, 
sim time next is 1893600.0000, 
raw observation next is [20.9, 91.0, 1.0, 2.0, 0.2100657427224897, 1.0, 2.0, 0.2100657427224897, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 512096.7450176506, 512096.7450176506, 161801.8118731399], 
processed observation next is [1.0, 0.9565217391304348, 0.32962962962962955, 0.91, 1.0, 1.0, 0.0596020746696306, 1.0, 1.0, 0.0596020746696306, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18289169464916094, 0.18289169464916094, 0.31115733052526906], 
reward next is 0.6888, 
noisyNet noise sample is [array([0.8891461], dtype=float32), -0.7171309]. 
=============================================
[2019-03-22 23:20:31,775] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.9372685e-25 9.9321020e-12 2.0362143e-33 1.0000000e+00 1.9825550e-24], sum to 1.0000
[2019-03-22 23:20:31,784] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6759
[2019-03-22 23:20:31,790] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.83333333333334, 92.0, 1.0, 2.0, 0.1900364062897713, 1.0, 2.0, 0.1900364062897713, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 469865.1844885262, 469865.1844885266, 157807.6909078447], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1905600.0000, 
sim time next is 1906200.0000, 
raw observation next is [19.75, 92.0, 1.0, 2.0, 0.1881379694966745, 1.0, 2.0, 0.1881379694966745, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 465733.5999808246, 465733.5999808246, 157430.3458290898], 
processed observation next is [1.0, 0.043478260869565216, 0.28703703703703703, 0.92, 1.0, 1.0, 0.0334975827341363, 1.0, 1.0, 0.0334975827341363, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16633342856458022, 0.16633342856458022, 0.30275066505594195], 
reward next is 0.6972, 
noisyNet noise sample is [array([-0.9856221], dtype=float32), -0.16778976]. 
=============================================
[2019-03-22 23:20:32,660] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6639595e-28 7.9292029e-08 2.7039241e-32 9.9999988e-01 4.3898789e-22], sum to 1.0000
[2019-03-22 23:20:32,672] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4162
[2019-03-22 23:20:32,781] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.85, 89.5, 1.0, 2.0, 0.3514659191356853, 1.0, 2.0, 0.3514659191356853, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 856109.9264352283, 856109.9264352288, 195500.3424084815], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1931400.0000, 
sim time next is 1932000.0000, 
raw observation next is [20.96666666666667, 89.33333333333333, 1.0, 2.0, 0.3646473706686884, 1.0, 2.0, 0.3646473706686884, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 886016.5895010707, 886016.5895010711, 198935.8514717846], 
processed observation next is [1.0, 0.34782608695652173, 0.3320987654320988, 0.8933333333333333, 1.0, 1.0, 0.24362782222462906, 1.0, 1.0, 0.24362782222462906, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3164344962503824, 0.31643449625038256, 0.38256894513804734], 
reward next is 0.6174, 
noisyNet noise sample is [array([-0.60498345], dtype=float32), -0.1648729]. 
=============================================
[2019-03-22 23:20:32,793] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[66.48695 ]
 [66.500496]
 [66.57892 ]
 [66.58089 ]
 [66.57011 ]], R is [[66.44394684]
 [66.40354919]
 [66.38262939]
 [66.40390015]
 [66.42752075]].
[2019-03-22 23:20:34,016] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3958011e-19 5.2245524e-24 8.3683186e-33 1.0000000e+00 2.9999462e-23], sum to 1.0000
[2019-03-22 23:20:34,025] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4244
[2019-03-22 23:20:34,029] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.5, 61.5, 1.0, 2.0, 0.6316139326592664, 1.0, 2.0, 0.6316139326592664, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1464593.500375723, 1464593.500375723, 280269.3178731541], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1953000.0000, 
sim time next is 1953600.0000, 
raw observation next is [27.6, 61.33333333333333, 1.0, 2.0, 0.6422631200473412, 1.0, 2.0, 0.6422631200473412, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1486756.433753403, 1486756.433753403, 283971.7767276752], 
processed observation next is [1.0, 0.6086956521739131, 0.5777777777777778, 0.6133333333333333, 1.0, 1.0, 0.5741227619611204, 1.0, 1.0, 0.5741227619611204, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5309844406262153, 0.5309844406262153, 0.5460995706301447], 
reward next is 0.4539, 
noisyNet noise sample is [array([-1.9216058], dtype=float32), -0.26800555]. 
=============================================
[2019-03-22 23:20:42,015] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55821: loss 0.0172
[2019-03-22 23:20:42,018] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 55821: learning rate 0.0010
[2019-03-22 23:20:42,061] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 55842: loss 0.0045
[2019-03-22 23:20:42,063] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 55842: learning rate 0.0010
[2019-03-22 23:20:42,089] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8514617e-28 3.0746822e-11 1.7957409e-32 1.0000000e+00 3.2115539e-24], sum to 1.0000
[2019-03-22 23:20:42,099] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7664
[2019-03-22 23:20:42,107] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.33333333333334, 91.66666666666667, 1.0, 2.0, 0.2189668212492716, 1.0, 2.0, 0.2189668212492716, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 529610.2540899122, 529610.2540899125, 163569.1535350121], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2095800.0000, 
sim time next is 2096400.0000, 
raw observation next is [21.46666666666667, 91.33333333333334, 1.0, 2.0, 0.2209491103056517, 1.0, 2.0, 0.2209491103056517, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 533580.4494893445, 533580.449489345, 163967.9962461549], 
processed observation next is [0.0, 0.2608695652173913, 0.35061728395061736, 0.9133333333333334, 1.0, 1.0, 0.07255846464958536, 1.0, 1.0, 0.07255846464958536, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19056444624619445, 0.19056444624619462, 0.31532306970414403], 
reward next is 0.6847, 
noisyNet noise sample is [array([0.56517655], dtype=float32), -0.561756]. 
=============================================
[2019-03-22 23:20:42,113] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 55869: loss 0.0001
[2019-03-22 23:20:42,116] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 55869: learning rate 0.0010
[2019-03-22 23:20:42,131] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 55874: loss 0.0001
[2019-03-22 23:20:42,135] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 55874: learning rate 0.0010
[2019-03-22 23:20:42,165] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 55890: loss 0.0256
[2019-03-22 23:20:42,172] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 55893: learning rate 0.0010
[2019-03-22 23:20:42,222] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 55917: loss 0.0945
[2019-03-22 23:20:42,224] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 55917: learning rate 0.0010
[2019-03-22 23:20:42,261] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 55933: loss 0.0719
[2019-03-22 23:20:42,263] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 55934: learning rate 0.0010
[2019-03-22 23:20:42,320] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 55963: loss 0.0079
[2019-03-22 23:20:42,325] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 55964: learning rate 0.0010
[2019-03-22 23:20:42,358] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 55980: loss 0.0103
[2019-03-22 23:20:42,360] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 55980: learning rate 0.0010
[2019-03-22 23:20:42,400] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55999: loss 0.0016
[2019-03-22 23:20:42,402] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 56000: learning rate 0.0010
[2019-03-22 23:20:42,527] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 56059: loss 0.0707
[2019-03-22 23:20:42,531] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 56059: learning rate 0.0010
[2019-03-22 23:20:42,547] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 56068: loss 0.1014
[2019-03-22 23:20:42,550] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 56069: learning rate 0.0010
[2019-03-22 23:20:42,633] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 56109: loss 0.0171
[2019-03-22 23:20:42,635] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 56109: learning rate 0.0010
[2019-03-22 23:20:42,639] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 56111: loss 0.0137
[2019-03-22 23:20:42,641] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 56111: learning rate 0.0010
[2019-03-22 23:20:42,738] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 56157: loss 0.0015
[2019-03-22 23:20:42,739] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 56157: learning rate 0.0010
[2019-03-22 23:20:42,830] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 56199: loss 0.0722
[2019-03-22 23:20:42,832] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 56199: learning rate 0.0010
[2019-03-22 23:20:45,950] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3222462e-36 5.6299621e-13 5.1019476e-32 1.0000000e+00 3.1836574e-24], sum to 1.0000
[2019-03-22 23:20:45,961] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1217
[2019-03-22 23:20:45,966] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.53333333333333, 80.0, 1.0, 2.0, 0.2891310735618507, 1.0, 2.0, 0.2891310735618507, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 664968.2585509312, 664968.2585509316, 178170.4710156432], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2157600.0000, 
sim time next is 2158200.0000, 
raw observation next is [25.45, 80.5, 1.0, 2.0, 0.2886471067152093, 1.0, 2.0, 0.2886471067152093, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 663989.3012820509, 663989.3012820514, 178062.3624389384], 
processed observation next is [0.0, 1.0, 0.4981481481481481, 0.805, 1.0, 1.0, 0.15315131751810634, 1.0, 1.0, 0.15315131751810634, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23713903617216103, 0.2371390361721612, 0.34242762007488153], 
reward next is 0.6576, 
noisyNet noise sample is [array([0.4304077], dtype=float32), 1.2267289]. 
=============================================
[2019-03-22 23:20:47,250] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.2261886e-31 7.2544271e-10 6.8003539e-27 1.0000000e+00 1.0358840e-23], sum to 1.0000
[2019-03-22 23:20:47,256] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3263
[2019-03-22 23:20:47,258] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.5, 88.0, 1.0, 2.0, 0.3186119314571592, 1.0, 2.0, 0.3186119314571592, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 730225.2175244257, 730225.2175244262, 185184.2673394241], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2188800.0000, 
sim time next is 2189400.0000, 
raw observation next is [24.48333333333333, 88.33333333333334, 1.0, 2.0, 0.3486215119432878, 1.0, 2.0, 0.3486215119432878, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 798308.9286987892, 798308.9286987897, 192715.5933336182], 
processed observation next is [1.0, 0.34782608695652173, 0.4623456790123456, 0.8833333333333334, 1.0, 1.0, 0.2245494189801045, 1.0, 1.0, 0.2245494189801045, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.285110331678139, 0.28511033167813915, 0.3706069102569581], 
reward next is 0.6294, 
noisyNet noise sample is [array([1.6158437], dtype=float32), 0.107292034]. 
=============================================
[2019-03-22 23:20:48,905] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.9041310e-27 2.1159557e-10 4.9640612e-34 1.0000000e+00 5.6310239e-21], sum to 1.0000
[2019-03-22 23:20:48,908] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0610
[2019-03-22 23:20:48,913] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.26666666666667, 95.33333333333333, 1.0, 2.0, 0.2796617689256577, 1.0, 2.0, 0.2796617689256577, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 645632.2590537091, 645632.2590537091, 176060.8384324051], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2223600.0000, 
sim time next is 2224200.0000, 
raw observation next is [23.23333333333333, 95.16666666666667, 1.0, 2.0, 0.2793072302994542, 1.0, 2.0, 0.2793072302994542, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 645551.7981856023, 645551.7981856028, 176013.3007287131], 
processed observation next is [1.0, 0.7391304347826086, 0.4160493827160493, 0.9516666666666667, 1.0, 1.0, 0.14203241702315977, 1.0, 1.0, 0.14203241702315977, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2305542136377151, 0.23055421363771528, 0.33848711678598675], 
reward next is 0.6615, 
noisyNet noise sample is [array([-0.7163841], dtype=float32), 0.032560073]. 
=============================================
[2019-03-22 23:20:50,139] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.6880118e-33 2.7692835e-12 2.4466666e-36 1.0000000e+00 8.7279688e-26], sum to 1.0000
[2019-03-22 23:20:50,149] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5513
[2019-03-22 23:20:50,154] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.9, 98.0, 1.0, 2.0, 0.2818196103246597, 1.0, 2.0, 0.2818196103246597, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651388.7103881632, 651388.7103881632, 176603.6900115981], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2248200.0000, 
sim time next is 2248800.0000, 
raw observation next is [22.93333333333333, 98.0, 1.0, 2.0, 0.2825660166540974, 1.0, 2.0, 0.2825660166540974, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 652647.4863142942, 652647.4863142946, 176756.7966184336], 
processed observation next is [1.0, 0.0, 0.40493827160493817, 0.98, 1.0, 1.0, 0.1459119245882112, 1.0, 1.0, 0.1459119245882112, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23308838796939077, 0.23308838796939094, 0.33991691657391077], 
reward next is 0.6601, 
noisyNet noise sample is [array([0.5582692], dtype=float32), 0.26416454]. 
=============================================
[2019-03-22 23:20:51,372] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.3661078e-34 7.8982142e-12 5.0214703e-32 1.0000000e+00 5.2430753e-26], sum to 1.0000
[2019-03-22 23:20:51,381] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6276
[2019-03-22 23:20:51,478] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.85, 96.0, 1.0, 2.0, 0.2238060689650283, 1.0, 2.0, 0.2238060689650283, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 540182.4311331592, 540182.4311331596, 164577.6257431853], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2262600.0000, 
sim time next is 2263200.0000, 
raw observation next is [20.7, 95.66666666666666, 1.0, 2.0, 0.2201127467791671, 1.0, 2.0, 0.2201127467791671, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 532996.593774164, 532996.5937741643, 163839.326782073], 
processed observation next is [1.0, 0.17391304347826086, 0.3222222222222222, 0.9566666666666666, 1.0, 1.0, 0.07156279378472273, 1.0, 1.0, 0.07156279378472273, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1903559263479157, 0.19035592634791584, 0.3150756284270635], 
reward next is 0.6849, 
noisyNet noise sample is [array([-1.2535782], dtype=float32), 0.91943526]. 
=============================================
[2019-03-22 23:20:52,795] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8106512e-28 1.3774264e-08 6.8350872e-23 1.0000000e+00 4.1310066e-24], sum to 1.0000
[2019-03-22 23:20:52,801] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7102
[2019-03-22 23:20:52,806] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.73333333333333, 89.66666666666667, 1.0, 2.0, 0.5417898423245859, 1.0, 2.0, 0.5417898423245859, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1269823.531148937, 1269823.531148937, 250203.4550486878], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2283600.0000, 
sim time next is 2284200.0000, 
raw observation next is [22.9, 89.0, 1.0, 2.0, 0.5413828253049539, 1.0, 2.0, 0.5413828253049539, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1266816.36142212, 1266816.361422121, 249982.1303693714], 
processed observation next is [1.0, 0.43478260869565216, 0.4037037037037037, 0.89, 1.0, 1.0, 0.4540271729820879, 1.0, 1.0, 0.4540271729820879, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.45243441479361424, 0.4524344147936147, 0.48073486609494503], 
reward next is 0.5193, 
noisyNet noise sample is [array([-1.080435], dtype=float32), -0.27481267]. 
=============================================
[2019-03-22 23:20:53,345] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.4210646e-32 1.0977674e-12 2.4137513e-33 1.0000000e+00 1.0968111e-23], sum to 1.0000
[2019-03-22 23:20:53,356] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6860
[2019-03-22 23:20:53,361] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.40000000000001, 77.33333333333334, 1.0, 2.0, 0.5400960306956444, 1.0, 2.0, 0.5400960306956444, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1242982.720894617, 1242982.720894618, 248618.6024392357], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2298000.0000, 
sim time next is 2298600.0000, 
raw observation next is [25.45, 76.5, 1.0, 2.0, 0.5345984593583073, 1.0, 2.0, 0.5345984593583073, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1232592.503803483, 1232592.503803483, 246947.9378782424], 
processed observation next is [1.0, 0.6086956521739131, 0.4981481481481481, 0.765, 1.0, 1.0, 0.4459505468551277, 1.0, 1.0, 0.4459505468551277, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4402116085012439, 0.4402116085012439, 0.47489988053508153], 
reward next is 0.5251, 
noisyNet noise sample is [array([0.87765497], dtype=float32), -0.7131352]. 
=============================================
[2019-03-22 23:20:58,795] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63783: loss 1.6633
[2019-03-22 23:20:58,797] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63783: learning rate 0.0010
[2019-03-22 23:20:58,959] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 63863: loss 0.6370
[2019-03-22 23:20:58,961] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 63863: learning rate 0.0010
[2019-03-22 23:20:58,963] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 63864: loss 0.8878
[2019-03-22 23:20:58,965] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 63864: learning rate 0.0010
[2019-03-22 23:20:58,977] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 63870: loss 0.5402
[2019-03-22 23:20:58,980] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 63870: learning rate 0.0010
[2019-03-22 23:20:59,063] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 63905: loss 0.0690
[2019-03-22 23:20:59,068] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 63906: learning rate 0.0010
[2019-03-22 23:20:59,105] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 63929: loss 0.0125
[2019-03-22 23:20:59,110] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 63929: learning rate 0.0010
[2019-03-22 23:20:59,173] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63955: loss 0.0626
[2019-03-22 23:20:59,174] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63955: learning rate 0.0010
[2019-03-22 23:20:59,198] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 63964: loss 0.0051
[2019-03-22 23:20:59,198] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 63964: learning rate 0.0010
[2019-03-22 23:20:59,267] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 64000: loss 0.0026
[2019-03-22 23:20:59,270] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 64000: learning rate 0.0010
[2019-03-22 23:20:59,329] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 64029: loss 0.0192
[2019-03-22 23:20:59,331] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 64029: learning rate 0.0010
[2019-03-22 23:20:59,364] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 64041: loss 0.0218
[2019-03-22 23:20:59,367] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 64041: learning rate 0.0010
[2019-03-22 23:20:59,484] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 64098: loss 0.0138
[2019-03-22 23:20:59,488] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 64099: loss 0.0537
[2019-03-22 23:20:59,488] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 64099: learning rate 0.0010
[2019-03-22 23:20:59,491] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 64101: learning rate 0.0010
[2019-03-22 23:20:59,534] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 64117: loss 0.0100
[2019-03-22 23:20:59,537] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 64117: learning rate 0.0010
[2019-03-22 23:20:59,540] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 64118: loss 0.0135
[2019-03-22 23:20:59,544] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 64120: learning rate 0.0010
[2019-03-22 23:20:59,678] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 64185: loss 0.1138
[2019-03-22 23:20:59,680] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 64185: learning rate 0.0010
[2019-03-22 23:21:01,870] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3231444e-21 9.9999619e-01 7.0831134e-16 3.7899304e-06 1.2956551e-18], sum to 1.0000
[2019-03-22 23:21:01,875] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7282
[2019-03-22 23:21:01,883] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.06666666666667, 62.83333333333334, 1.0, 2.0, 0.3540646301795466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 450508.820090913, 450508.8200909126, 122511.2322278984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2441400.0000, 
sim time next is 2442000.0000, 
raw observation next is [22.63333333333333, 60.66666666666667, 1.0, 2.0, 0.3369418937705095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 427806.3755617127, 427806.3755617127, 120250.8238425775], 
processed observation next is [1.0, 0.2608695652173913, 0.393827160493827, 0.6066666666666667, 1.0, 1.0, 0.2106451116315589, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15278799127204026, 0.15278799127204026, 0.23125158431264906], 
reward next is 0.7687, 
noisyNet noise sample is [array([1.4387227], dtype=float32), 0.067203365]. 
=============================================
[2019-03-22 23:21:01,895] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[35.12767 ]
 [35.238693]
 [35.422527]
 [35.40788 ]
 [35.660316]], R is [[35.5121994 ]
 [35.92147827]
 [36.34067154]
 [36.75676727]
 [37.16965103]].
[2019-03-22 23:21:05,971] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2502900e-28 1.0000000e+00 3.2259533e-26 2.9964237e-08 1.4242137e-20], sum to 1.0000
[2019-03-22 23:21:05,983] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0889
[2019-03-22 23:21:06,081] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 60.0, 1.0, 2.0, 0.3952608031768006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 494844.4907891487, 494844.4907891483, 128054.6425994027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2523600.0000, 
sim time next is 2524200.0000, 
raw observation next is [24.26666666666667, 59.0, 1.0, 2.0, 0.4574593701732498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 572283.6923094315, 572283.6923094315, 137117.8420197973], 
processed observation next is [1.0, 0.21739130434782608, 0.4543209876543211, 0.59, 1.0, 1.0, 0.35411829782529736, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20438703296765412, 0.20438703296765412, 0.2636881577303794], 
reward next is 0.7363, 
noisyNet noise sample is [array([-1.2945286], dtype=float32), 1.3558978]. 
=============================================
[2019-03-22 23:21:09,585] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.4493835e-26 2.4219729e-30], sum to 1.0000
[2019-03-22 23:21:09,595] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0599
[2019-03-22 23:21:09,602] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.46666666666667, 37.33333333333334, 1.0, 2.0, 0.4623482747163827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 554797.2437477419, 554797.2437477419, 137224.1581697126], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2569200.0000, 
sim time next is 2569800.0000, 
raw observation next is [32.28333333333334, 38.16666666666666, 1.0, 2.0, 0.4670424540938731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 559969.2190117496, 559969.2190117496, 137917.6810689946], 
processed observation next is [1.0, 0.7391304347826086, 0.7512345679012348, 0.3816666666666666, 1.0, 1.0, 0.36552673106413464, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19998900678991058, 0.19998900678991058, 0.26522630974806655], 
reward next is 0.7348, 
noisyNet noise sample is [array([0.1764134], dtype=float32), -0.022497274]. 
=============================================
[2019-03-22 23:21:16,272] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71797: loss 0.0152
[2019-03-22 23:21:16,276] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71797: learning rate 0.0010
[2019-03-22 23:21:16,295] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 71806: loss 0.0010
[2019-03-22 23:21:16,297] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 71809: loss 0.0290
[2019-03-22 23:21:16,298] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 71809: learning rate 0.0010
[2019-03-22 23:21:16,299] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 71809: learning rate 0.0010
[2019-03-22 23:21:16,430] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 71872: loss 0.0067
[2019-03-22 23:21:16,433] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 71872: learning rate 0.0010
[2019-03-22 23:21:16,437] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 71874: loss 0.0092
[2019-03-22 23:21:16,438] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 71874: learning rate 0.0010
[2019-03-22 23:21:16,489] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 71896: loss 0.0033
[2019-03-22 23:21:16,490] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 71896: learning rate 0.0010
[2019-03-22 23:21:16,547] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71923: loss 0.0179
[2019-03-22 23:21:16,553] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71924: learning rate 0.0010
[2019-03-22 23:21:16,589] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 71940: loss 0.0001
[2019-03-22 23:21:16,594] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 71943: learning rate 0.0010
[2019-03-22 23:21:16,820] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 72049: loss 0.0171
[2019-03-22 23:21:16,823] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 72049: learning rate 0.0010
[2019-03-22 23:21:16,827] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 72051: loss 0.0181
[2019-03-22 23:21:16,829] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 72052: learning rate 0.0010
[2019-03-22 23:21:16,888] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 72074: loss 0.0096
[2019-03-22 23:21:16,889] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 72074: learning rate 0.0010
[2019-03-22 23:21:16,944] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 72102: loss 0.0123
[2019-03-22 23:21:16,945] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 72102: loss 0.0007
[2019-03-22 23:21:16,946] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 72102: learning rate 0.0010
[2019-03-22 23:21:16,949] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 72102: learning rate 0.0010
[2019-03-22 23:21:17,044] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 72146: loss 0.0858
[2019-03-22 23:21:17,047] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 72147: learning rate 0.0010
[2019-03-22 23:21:17,059] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 72154: loss 0.0613
[2019-03-22 23:21:17,061] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 72155: learning rate 0.0010
[2019-03-22 23:21:17,179] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 72209: loss 0.0527
[2019-03-22 23:21:17,181] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 72209: learning rate 0.0010
[2019-03-22 23:21:20,785] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0965888e-28 1.0000000e+00 2.1509779e-30 7.2261683e-11 7.0455800e-22], sum to 1.0000
[2019-03-22 23:21:20,792] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1554
[2019-03-22 23:21:20,802] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 94.0, 1.0, 2.0, 0.6597399492486619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 751894.4035702609, 751894.4035702604, 168659.7031069087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2766000.0000, 
sim time next is 2766600.0000, 
raw observation next is [24.5, 94.0, 1.0, 2.0, 0.6518766736000849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 743235.5905917881, 743235.5905917881, 167246.4320610408], 
processed observation next is [1.0, 0.0, 0.46296296296296297, 0.94, 1.0, 1.0, 0.5855674685715296, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26544128235421, 0.26544128235421, 0.32162775396354], 
reward next is 0.6784, 
noisyNet noise sample is [array([-1.4074733], dtype=float32), 0.35262993]. 
=============================================
[2019-03-22 23:21:22,943] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2788620e-32 1.0000000e+00 2.4755688e-32 7.2441143e-17 1.5468755e-23], sum to 1.0000
[2019-03-22 23:21:22,950] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2087
[2019-03-22 23:21:22,958] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1891981.380130078 W.
[2019-03-22 23:21:22,963] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.1, 61.66666666666666, 1.0, 2.0, 0.8294542128828987, 1.0, 2.0, 0.8294542128828987, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1891981.380130078, 1891981.380130078, 356076.9204305527], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2812200.0000, 
sim time next is 2812800.0000, 
raw observation next is [32.2, 60.33333333333334, 1.0, 2.0, 0.6067164340767549, 1.0, 2.0, 0.6067164340767549, 1.0, 1.0, 0.9659123224249779, 6.911200000000001, 6.9112, 121.94756008, 2076089.569864243, 2076089.569864243, 399047.1978698548], 
processed observation next is [1.0, 0.5652173913043478, 0.7481481481481482, 0.6033333333333334, 1.0, 1.0, 0.5318052786628035, 1.0, 1.0, 0.5318052786628035, 1.0, 0.5, 0.9573904030312225, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7414605606658011, 0.7414605606658011, 0.7673984574420285], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.998158], dtype=float32), 1.5859716]. 
=============================================
[2019-03-22 23:21:23,262] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-22 23:21:23,263] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:21:23,265] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:21:23,265] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:21:23,266] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:21:23,266] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:21:23,268] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:21:23,267] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:21:23,269] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:21:23,269] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:21:23,271] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:21:23,286] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run4
[2019-03-22 23:21:23,287] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run4
[2019-03-22 23:21:23,287] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run4
[2019-03-22 23:21:23,305] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run4
[2019-03-22 23:21:23,340] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run4
[2019-03-22 23:21:29,111] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2953578], dtype=float32), 0.24635983]
[2019-03-22 23:21:29,115] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.85, 47.5, 1.0, 2.0, 0.279735661406253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 360843.9467084795, 360843.946708479, 111348.2660617589]
[2019-03-22 23:21:29,116] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:21:29,119] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7595680e-28 1.0000000e+00 2.9657652e-23 2.8457358e-16 1.4970002e-19], sampled 0.2549331531640876
[2019-03-22 23:21:37,933] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.2953578], dtype=float32), 0.24635983]
[2019-03-22 23:21:37,934] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.16666666666667, 39.83333333333334, 1.0, 2.0, 0.2575020535482523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 332157.5897956548, 332157.5897956548, 92253.83362996402]
[2019-03-22 23:21:37,936] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:21:37,939] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.8004882e-28 1.0000000e+00 4.6505572e-23 3.6817288e-16 1.7245886e-19], sampled 0.8998997338135947
[2019-03-22 23:22:52,596] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2953578], dtype=float32), 0.24635983]
[2019-03-22 23:22:52,597] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.36666666666667, 92.0, 1.0, 2.0, 0.5382727373956105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 632621.7370476087, 632621.7370476082, 148667.2045645312]
[2019-03-22 23:22:52,598] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:22:52,601] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.4688323e-27 1.0000000e+00 6.9415064e-23 5.7727417e-15 5.9567028e-19], sampled 0.4494548521497771
[2019-03-22 23:23:15,290] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-22 23:23:15,702] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-22 23:23:15,998] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.6619 2445343923.2757 746.0000
[2019-03-22 23:23:16,081] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-22 23:23:16,139] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7013 2248693483.9672 553.0000
[2019-03-22 23:23:17,154] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 75000, evaluation results [75000.0, 8100.661928194693, 2445343923.2757144, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8583.701325530239, 2248693483.9671583, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-22 23:23:19,529] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5176815e-31 1.0000000e+00 3.5311358e-30 6.5765989e-16 1.4289446e-25], sum to 1.0000
[2019-03-22 23:23:19,541] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6346
[2019-03-22 23:23:19,548] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1378114.35210626 W.
[2019-03-22 23:23:19,556] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.41666666666667, 92.5, 1.0, 2.0, 0.977860647871295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.316422299488847, 6.9112, 122.6799032636202, 1378114.35210626, 1169321.295599735, 238300.2825366607], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2859000.0000, 
sim time next is 2859600.0000, 
raw observation next is [22.33333333333334, 94.0, 1.0, 2.0, 0.316675067179699, 1.0, 1.0, 0.316675067179699, 1.0, 1.0, 0.5052987793129403, 6.911200000000001, 6.9112, 121.94756008, 1103981.385077797, 1103981.385077796, 262526.5288932687], 
processed observation next is [1.0, 0.08695652173913043, 0.38271604938271625, 0.94, 1.0, 1.0, 0.1865179371186893, 1.0, 0.5, 0.1865179371186893, 1.0, 0.5, 0.38162347414117537, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.39427906609921326, 0.3942790660992128, 0.5048587094101321], 
reward next is 0.4951, 
noisyNet noise sample is [array([0.12536213], dtype=float32), 0.26682568]. 
=============================================
[2019-03-22 23:23:21,263] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3028879e-38 1.0000000e+00 2.0983838e-33 1.8531566e-14 6.2784849e-28], sum to 1.0000
[2019-03-22 23:23:21,272] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0119
[2019-03-22 23:23:21,278] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.86666666666667, 91.33333333333334, 1.0, 2.0, 0.7921997963038853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 942102.4082323333, 942102.4082323333, 196202.4261232324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2881200.0000, 
sim time next is 2881800.0000, 
raw observation next is [22.9, 92.0, 1.0, 2.0, 0.8770758864645823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1040466.006340586, 1040466.006340586, 214406.7266092963], 
processed observation next is [1.0, 0.34782608695652173, 0.4037037037037037, 0.92, 1.0, 1.0, 0.8536617696006933, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.371595002264495, 0.371595002264495, 0.4123206280948006], 
reward next is 0.5877, 
noisyNet noise sample is [array([0.34993082], dtype=float32), 0.22501135]. 
=============================================
[2019-03-22 23:23:23,694] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.2541039e-30 1.0000000e+00 2.4055433e-25 8.8670196e-15 1.7813636e-19], sum to 1.0000
[2019-03-22 23:23:23,700] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4439
[2019-03-22 23:23:23,706] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.6852007309650351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 780926.4050572189, 780926.4050572184, 173360.7346072997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2929200.0000, 
sim time next is 2929800.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.6850219263724854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 780722.5168627085, 780722.516862708, 173327.3514514834], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.89, 1.0, 1.0, 0.6250261028243873, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27882947030811017, 0.27882947030811, 0.33332182971439117], 
reward next is 0.6667, 
noisyNet noise sample is [array([-1.7769026], dtype=float32), 1.6400478]. 
=============================================
[2019-03-22 23:23:25,035] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6289356e-32 1.0000000e+00 8.5051901e-26 3.7535337e-13 6.6391386e-23], sum to 1.0000
[2019-03-22 23:23:25,044] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7071
[2019-03-22 23:23:25,048] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666666, 91.33333333333334, 1.0, 2.0, 0.8376127418975647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156303, 954739.2649005976, 954739.2649005976, 203828.6191891537], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2947200.0000, 
sim time next is 2947800.0000, 
raw observation next is [25.08333333333334, 92.66666666666667, 1.0, 2.0, 0.8251272356298684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 940499.1306660377, 940499.1306660377, 201181.6076131642], 
processed observation next is [1.0, 0.08695652173913043, 0.4845679012345681, 0.9266666666666667, 1.0, 1.0, 0.7918181376546053, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.335892546666442, 0.335892546666442, 0.3868877069483927], 
reward next is 0.6131, 
noisyNet noise sample is [array([-0.09619014], dtype=float32), -0.4284204]. 
=============================================
[2019-03-22 23:23:25,090] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8790203e-34 1.0000000e+00 9.5501822e-32 4.8343353e-17 2.5716796e-26], sum to 1.0000
[2019-03-22 23:23:25,102] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5854
[2019-03-22 23:23:25,106] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 90.0, 1.0, 2.0, 0.6936515931652869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 796742.8556693759, 796742.8556693759, 175254.352029655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2955600.0000, 
sim time next is 2956200.0000, 
raw observation next is [24.75, 90.66666666666667, 1.0, 2.0, 0.7462953603057716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 855976.7169773228, 855976.7169773228, 185367.3148086843], 
processed observation next is [1.0, 0.21739130434782608, 0.4722222222222222, 0.9066666666666667, 1.0, 1.0, 0.6979706670306804, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30570597034904384, 0.30570597034904384, 0.356475605401316], 
reward next is 0.6435, 
noisyNet noise sample is [array([0.62591535], dtype=float32), -0.46083024]. 
=============================================
[2019-03-22 23:23:27,277] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79798: loss 47.4905
[2019-03-22 23:23:27,279] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 79798: learning rate 0.0010
[2019-03-22 23:23:27,468] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 79855: loss 89.3082
[2019-03-22 23:23:27,473] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 79857: learning rate 0.0010
[2019-03-22 23:23:27,564] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 79868: loss 151.6893
[2019-03-22 23:23:27,567] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 79869: learning rate 0.0010
[2019-03-22 23:23:27,661] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 79880: loss 48.4031
[2019-03-22 23:23:27,664] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 79882: learning rate 0.0010
[2019-03-22 23:23:27,765] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 79894: loss 146.7032
[2019-03-22 23:23:27,766] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 79894: learning rate 0.0010
[2019-03-22 23:23:27,883] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 79919: loss 120.4352
[2019-03-22 23:23:27,883] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 79919: learning rate 0.0010
[2019-03-22 23:23:28,005] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 79952: loss 52.7405
[2019-03-22 23:23:28,009] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 79954: learning rate 0.0010
[2019-03-22 23:23:28,131] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 79981: loss 202.3189
[2019-03-22 23:23:28,132] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 79981: learning rate 0.0010
[2019-03-22 23:23:28,323] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 80047: loss 16.7112
[2019-03-22 23:23:28,325] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 80047: learning rate 0.0010
[2019-03-22 23:23:28,419] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 80058: loss 148.4104
[2019-03-22 23:23:28,421] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 80058: loss 176.3722
[2019-03-22 23:23:28,422] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 80058: learning rate 0.0010
[2019-03-22 23:23:28,425] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 80058: learning rate 0.0010
[2019-03-22 23:23:28,590] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 80070: loss 134.3864
[2019-03-22 23:23:28,592] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 80071: learning rate 0.0010
[2019-03-22 23:23:28,689] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 80082: loss -21.8572
[2019-03-22 23:23:28,691] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 80083: learning rate 0.0010
[2019-03-22 23:23:28,837] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 80128: loss -23.5643
[2019-03-22 23:23:28,840] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 80129: learning rate 0.0010
[2019-03-22 23:23:28,935] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 80146: loss -87.2153
[2019-03-22 23:23:28,937] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 80147: learning rate 0.0010
[2019-03-22 23:23:29,036] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 80163: loss -69.5105
[2019-03-22 23:23:29,038] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 80165: learning rate 0.0010
[2019-03-22 23:23:32,060] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3878025e-36 1.0000000e+00 9.7704495e-36 1.0336062e-31 3.5948521e-30], sum to 1.0000
[2019-03-22 23:23:32,070] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6425
[2019-03-22 23:23:32,075] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2198068.335213569 W.
[2019-03-22 23:23:32,079] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.66666666666667, 84.66666666666667, 1.0, 2.0, 0.9634793322659967, 1.0, 2.0, 0.9634793322659967, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2198068.335213569, 2198068.335213569, 415938.8968026016], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3061200.0000, 
sim time next is 3061800.0000, 
raw observation next is [29.0, 82.5, 1.0, 2.0, 1.007137629871771, 1.0, 2.0, 1.007137629871771, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2297797.94260373, 2297797.94260373, 436782.65107504], 
processed observation next is [1.0, 0.43478260869565216, 0.6296296296296297, 0.825, 1.0, 1.0, 1.0084971784187748, 1.0, 1.0, 1.0084971784187748, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.820642122358475, 0.820642122358475, 0.8399666366827692], 
reward next is 0.1600, 
noisyNet noise sample is [array([0.37355563], dtype=float32), -0.87110645]. 
=============================================
[2019-03-22 23:23:45,450] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 87792: loss 0.1170
[2019-03-22 23:23:45,454] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 87794: learning rate 0.0010
[2019-03-22 23:23:45,455] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87794: loss 0.0948
[2019-03-22 23:23:45,458] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 87796: learning rate 0.0010
[2019-03-22 23:23:45,577] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 87849: loss 0.0641
[2019-03-22 23:23:45,578] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 87849: learning rate 0.0010
[2019-03-22 23:23:45,586] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 87852: loss 0.0849
[2019-03-22 23:23:45,588] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 87852: learning rate 0.0010
[2019-03-22 23:23:45,588] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 87852: loss 0.0530
[2019-03-22 23:23:45,592] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 87855: learning rate 0.0010
[2019-03-22 23:23:45,748] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 87926: loss 0.0149
[2019-03-22 23:23:45,751] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 87926: learning rate 0.0010
[2019-03-22 23:23:45,794] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87949: loss 0.0148
[2019-03-22 23:23:45,800] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 87949: learning rate 0.0010
[2019-03-22 23:23:45,881] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 87987: loss 0.0120
[2019-03-22 23:23:45,883] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 87987: learning rate 0.0010
[2019-03-22 23:23:45,992] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 88036: loss 0.0846
[2019-03-22 23:23:46,000] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 88037: learning rate 0.0010
[2019-03-22 23:23:46,024] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 88051: loss 0.0738
[2019-03-22 23:23:46,027] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 88051: learning rate 0.0010
[2019-03-22 23:23:46,038] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 88057: loss 0.0500
[2019-03-22 23:23:46,041] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 88058: learning rate 0.0010
[2019-03-22 23:23:46,062] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 88071: loss 0.0239
[2019-03-22 23:23:46,069] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 88071: learning rate 0.0010
[2019-03-22 23:23:46,178] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 88120: loss 0.0223
[2019-03-22 23:23:46,182] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 88120: learning rate 0.0010
[2019-03-22 23:23:46,241] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.4351728e-24 7.0669670e-33], sum to 1.0000
[2019-03-22 23:23:46,245] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2134
[2019-03-22 23:23:46,250] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 88151: loss 0.0125
[2019-03-22 23:23:46,253] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.73333333333333, 93.33333333333334, 1.0, 2.0, 0.5307454941935716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 629505.7521772458, 629505.7521772454, 147674.923468966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3310800.0000, 
sim time next is 3311400.0000, 
raw observation next is [22.91666666666667, 91.66666666666666, 1.0, 2.0, 0.5283611796627021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626987.9529033051, 626987.9529033051, 147300.6103292744], 
processed observation next is [0.0, 0.30434782608695654, 0.4043209876543212, 0.9166666666666665, 1.0, 1.0, 0.4385252138841692, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22392426889403752, 0.22392426889403752, 0.28327040447937385], 
reward next is 0.7167, 
noisyNet noise sample is [array([0.00075202], dtype=float32), 0.65932065]. 
=============================================
[2019-03-22 23:23:46,256] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 88153: learning rate 0.0010
[2019-03-22 23:23:46,269] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 88162: loss 0.0192
[2019-03-22 23:23:46,270] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 88162: loss 0.0251
[2019-03-22 23:23:46,271] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 88162: learning rate 0.0010
[2019-03-22 23:23:46,275] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 88163: learning rate 0.0010
[2019-03-22 23:23:50,828] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0616658e-38 1.0000000e+00 1.4665217e-36 3.4548258e-24 1.2385970e-27], sum to 1.0000
[2019-03-22 23:23:50,834] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0593
[2019-03-22 23:23:50,846] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.86666666666667, 93.0, 1.0, 2.0, 0.8933475915443487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156311, 1036939.30861082, 1036939.30861082, 216971.0269692955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3379200.0000, 
sim time next is 3379800.0000, 
raw observation next is [23.93333333333333, 93.5, 1.0, 2.0, 0.8667908510444094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1003532.633747276, 1003532.633747276, 210945.6143824158], 
processed observation next is [1.0, 0.08695652173913043, 0.4419753086419752, 0.935, 1.0, 1.0, 0.8414176798147731, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3584045120525986, 0.3584045120525986, 0.40566464304310734], 
reward next is 0.5943, 
noisyNet noise sample is [array([0.31244287], dtype=float32), -0.41982925]. 
=============================================
[2019-03-22 23:23:53,330] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.4330061e-36 1.0000000e+00 2.0818904e-30 4.2369485e-31 1.3872356e-29], sum to 1.0000
[2019-03-22 23:23:53,337] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9675
[2019-03-22 23:23:53,357] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2199187.115998302 W.
[2019-03-22 23:23:53,363] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.53333333333333, 60.66666666666667, 1.0, 2.0, 0.9639691242469322, 1.0, 2.0, 0.9639691242469322, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2199187.115998302, 2199187.115998301, 416167.9337503476], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3424800.0000, 
sim time next is 3425400.0000, 
raw observation next is [31.3, 61.5, 1.0, 2.0, 0.6514413845781235, 1.0, 2.0, 0.6390853542654965, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2186986.617252394, 2186986.617252394, 416446.4330463811], 
processed observation next is [1.0, 0.6521739130434783, 0.7148148148148148, 0.615, 1.0, 1.0, 0.5850492673549089, 1.0, 1.0, 0.5703397074589244, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.7810666490187121, 0.7810666490187121, 0.8008585250891944], 
reward next is 0.1991, 
noisyNet noise sample is [array([1.9427768], dtype=float32), -0.63388103]. 
=============================================
[2019-03-22 23:24:03,002] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 95820: loss 19.5170
[2019-03-22 23:24:03,004] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 95820: loss -92.6419
[2019-03-22 23:24:03,007] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 95820: learning rate 0.0010
[2019-03-22 23:24:03,009] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 95821: learning rate 0.0010
[2019-03-22 23:24:03,028] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 95828: loss 68.6115
[2019-03-22 23:24:03,031] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 95831: learning rate 0.0010
[2019-03-22 23:24:03,096] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 95859: loss -10.1370
[2019-03-22 23:24:03,097] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 95859: learning rate 0.0010
[2019-03-22 23:24:03,149] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 95885: loss -0.3623
[2019-03-22 23:24:03,150] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 95886: learning rate 0.0010
[2019-03-22 23:24:03,190] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 95908: loss 6.6007
[2019-03-22 23:24:03,193] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 95908: learning rate 0.0010
[2019-03-22 23:24:03,360] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 95991: loss 115.9651
[2019-03-22 23:24:03,361] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 95991: learning rate 0.0010
[2019-03-22 23:24:03,375] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 95997: loss -41.7608
[2019-03-22 23:24:03,377] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 95997: learning rate 0.0010
[2019-03-22 23:24:03,490] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 96050: loss 80.1105
[2019-03-22 23:24:03,491] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 96050: learning rate 0.0010
[2019-03-22 23:24:03,531] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 96066: loss 147.2355
[2019-03-22 23:24:03,535] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 96066: learning rate 0.0010
[2019-03-22 23:24:03,547] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 96074: loss 64.8084
[2019-03-22 23:24:03,548] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 96074: learning rate 0.0010
[2019-03-22 23:24:03,571] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 96084: loss 120.4026
[2019-03-22 23:24:03,574] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 96085: learning rate 0.0010
[2019-03-22 23:24:03,611] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 96101: loss -36.2568
[2019-03-22 23:24:03,613] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 96101: learning rate 0.0010
[2019-03-22 23:24:03,667] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 96127: loss -8.6055
[2019-03-22 23:24:03,670] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 96128: learning rate 0.0010
[2019-03-22 23:24:03,679] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 96132: loss -42.9775
[2019-03-22 23:24:03,682] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 96132: learning rate 0.0010
[2019-03-22 23:24:03,750] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 96165: loss 156.9687
[2019-03-22 23:24:03,753] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 96166: learning rate 0.0010
[2019-03-22 23:24:07,022] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3250115e-31 1.0000000e+00 7.6193168e-35 3.0305198e-15 2.5645027e-23], sum to 1.0000
[2019-03-22 23:24:07,032] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2294
[2019-03-22 23:24:07,044] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1311664.375573918 W.
[2019-03-22 23:24:07,048] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.9948315633645611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.219274587714088, 6.9112, 121.9249149824906, 1311664.375573918, 1153904.110329632, 240577.6602930193], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3669600.0000, 
sim time next is 3670200.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.5326482978874154, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8482623639695739, 6.911199999999999, 6.9112, 121.9258570985808, 1220758.022756703, 1220758.022756703, 268484.0726393379], 
processed observation next is [1.0, 0.4782608695652174, 0.4074074074074074, 1.0, 1.0, 1.0, 0.4436289260564469, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.8103279549619674, -8.881784197001253e-17, 0.0, 0.8094608971796423, 0.43598500812739394, 0.43598500812739394, 0.516315524306419], 
reward next is 0.4837, 
noisyNet noise sample is [array([1.3221284], dtype=float32), 0.793413]. 
=============================================
[2019-03-22 23:24:08,340] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.4142232e-13 8.9041627e-09 3.0593546e-19 1.0000000e+00 1.9854214e-11], sum to 1.0000
[2019-03-22 23:24:08,348] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3944
[2019-03-22 23:24:08,359] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.8039179474945768, 1.0, 1.0, 0.8039179474945768, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1833673.480129336, 1833673.480129337, 345376.8729745445], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3684600.0000, 
sim time next is 3685200.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.8546378469197417, 1.0, 2.0, 0.8546378469197417, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1949487.832271864, 1949487.832271865, 366849.7001058497], 
processed observation next is [1.0, 0.6521739130434783, 0.5555555555555556, 0.89, 1.0, 1.0, 0.8269498177615972, 1.0, 1.0, 0.8269498177615972, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6962456543828085, 0.6962456543828089, 0.7054801925112495], 
reward next is 0.2945, 
noisyNet noise sample is [array([-1.5311478], dtype=float32), 0.789482]. 
=============================================
[2019-03-22 23:24:12,105] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-22 23:24:12,107] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:24:12,107] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:24:12,109] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:24:12,110] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:24:12,110] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:24:12,111] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:24:12,111] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:24:12,113] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:24:12,114] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:24:12,113] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:24:12,133] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run5
[2019-03-22 23:24:12,133] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run5
[2019-03-22 23:24:12,134] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run5
[2019-03-22 23:24:12,151] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run5
[2019-03-22 23:24:12,211] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run5
[2019-03-22 23:24:28,201] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.20983642], dtype=float32), 0.3561968]
[2019-03-22 23:24:28,202] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.23333333333333, 50.66666666666667, 1.0, 2.0, 0.3721291835902246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 473196.1783526849, 473196.1783526849, 124944.6493532887]
[2019-03-22 23:24:28,204] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:24:28,206] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.2631681e-31 1.0000000e+00 6.8295828e-32 4.4391764e-19 2.7166682e-20], sampled 0.4169529080677936
[2019-03-22 23:24:32,784] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.20983642], dtype=float32), 0.3561968]
[2019-03-22 23:24:32,785] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.33333333333334, 22.33333333333334, 1.0, 2.0, 0.3981631001268157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 495683.2157680407, 495683.2157680407, 128410.5841005782]
[2019-03-22 23:24:32,786] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:24:32,790] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.5847525e-32 1.0000000e+00 9.0950179e-35 2.4586487e-16 1.7464691e-19], sampled 0.8013490695120024
[2019-03-22 23:24:38,640] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.20983642], dtype=float32), 0.3561968]
[2019-03-22 23:24:38,641] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.98459237, 89.36364856, 1.0, 2.0, 0.6338466422373952, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260424450388, 1437299.276311414, 1437299.276311414, 305616.1435324101]
[2019-03-22 23:24:38,642] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:24:38,647] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3539618e-24 1.0000000e+00 1.7442372e-28 1.4119426e-12 2.5001897e-15], sampled 0.337356624383782
[2019-03-22 23:24:38,648] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1437299.276311414 W.
[2019-03-22 23:25:05,053] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.20983642], dtype=float32), 0.3561968]
[2019-03-22 23:25:05,053] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.1592706, 88.28113708333333, 1.0, 2.0, 0.6076168645238932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694363.8049346871, 694363.8049346871, 159486.7115068804]
[2019-03-22 23:25:05,054] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:25:05,056] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.1443515e-29 1.0000000e+00 3.2136257e-31 9.8455277e-16 2.9642232e-18], sampled 0.7780541105467639
[2019-03-22 23:25:48,240] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.20983642], dtype=float32), 0.3561968]
[2019-03-22 23:25:48,241] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.76666666666667, 56.33333333333334, 1.0, 2.0, 0.3381966808812994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 427442.6685877579, 427442.6685877574, 120396.0520851918]
[2019-03-22 23:25:48,242] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:25:48,244] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.4627545e-32 1.0000000e+00 1.0233541e-32 1.1235182e-18 2.5205038e-20], sampled 0.01854287709628366
[2019-03-22 23:25:54,107] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.20983642], dtype=float32), 0.3561968]
[2019-03-22 23:25:54,110] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.33333333333333, 96.0, 1.0, 2.0, 0.6762571856433026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 770728.2809810749, 770728.2809810744, 171699.0749998694]
[2019-03-22 23:25:54,111] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:25:54,113] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.94788976e-29 1.00000000e+00 2.52282717e-31 1.09418644e-16
 9.50611987e-19], sampled 0.025877230524747663
[2019-03-22 23:26:04,718] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2665 2170632327.5226 493.0000
[2019-03-22 23:26:04,985] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.2011 2445377682.4312 746.0000
[2019-03-22 23:26:05,024] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.8787 2248748925.1610 553.0000
[2019-03-22 23:26:05,038] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.1625 2120466133.0938 430.0000
[2019-03-22 23:26:05,125] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.6453 2195070843.7322 572.0000
[2019-03-22 23:26:06,140] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 100000, evaluation results [100000.0, 8099.201055540698, 2445377682.4311814, 746.0, 8770.266515857684, 2170632327.522563, 493.0, 8924.162528137549, 2120466133.0938108, 430.0, 8582.878745663738, 2248748925.160952, 553.0, 8701.6453272671, 2195070843.7322125, 572.0]
[2019-03-22 23:26:06,199] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3554253e-30 1.0000000e+00 2.3033881e-30 6.9751957e-14 2.3821769e-16], sum to 1.0000
[2019-03-22 23:26:06,200] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8742
[2019-03-22 23:26:06,202] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1712089.959484428 W.
[2019-03-22 23:26:06,207] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.5, 94.0, 1.0, 2.0, 0.750664413814802, 1.0, 2.0, 0.750664413814802, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1712089.959484428, 1712089.959484428, 323790.8816009572], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3749400.0000, 
sim time next is 3750000.0000, 
raw observation next is [26.66666666666667, 94.0, 1.0, 2.0, 0.8498855444136045, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1683880.016920213, 1683880.016920213, 346363.5034785351], 
processed observation next is [1.0, 0.391304347826087, 0.5432098765432101, 0.94, 1.0, 1.0, 0.8212923147781006, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.6013857203286475, 0.6013857203286475, 0.6660836605356444], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.28687304], dtype=float32), -0.29709423]. 
=============================================
[2019-03-22 23:26:06,223] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[54.964848]
 [54.64353 ]
 [54.35414 ]
 [54.092113]
 [54.714897]], R is [[54.11031342]
 [53.94653702]
 [53.40707397]
 [53.21678925]
 [52.97883606]].
[2019-03-22 23:26:07,749] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.071686e-23 1.000000e+00 1.554277e-28 1.913007e-18 5.968037e-13], sum to 1.0000
[2019-03-22 23:26:07,758] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8731
[2019-03-22 23:26:07,765] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.75, 67.0, 1.0, 2.0, 0.7802597750347094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 889328.4867677265, 889328.4867677265, 191904.0493726349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3785400.0000, 
sim time next is 3786000.0000, 
raw observation next is [31.33333333333334, 70.66666666666667, 1.0, 2.0, 0.8065515221866764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 919313.4027274995, 919313.4027274995, 197307.5699735106], 
processed observation next is [1.0, 0.8260869565217391, 0.7160493827160496, 0.7066666666666667, 1.0, 1.0, 0.7697041930793767, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32832621525982125, 0.32832621525982125, 0.37943763456444346], 
reward next is 0.6206, 
noisyNet noise sample is [array([-0.00316017], dtype=float32), -0.04765048]. 
=============================================
[2019-03-22 23:26:07,774] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[33.232986]
 [33.152534]
 [33.407555]
 [33.384212]
 [33.527138]], R is [[33.41815186]
 [33.71492386]
 [34.02328873]
 [34.33608627]
 [34.6462326 ]].
[2019-03-22 23:26:13,494] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 103677: loss 0.0621
[2019-03-22 23:26:13,496] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 103677: learning rate 0.0010
[2019-03-22 23:26:13,793] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 103817: loss 0.0567
[2019-03-22 23:26:13,800] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 103819: learning rate 0.0010
[2019-03-22 23:26:13,858] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 103847: loss 0.0077
[2019-03-22 23:26:13,860] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 103847: learning rate 0.0010
[2019-03-22 23:26:13,871] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 103854: loss 0.0020
[2019-03-22 23:26:13,872] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 103854: learning rate 0.0010
[2019-03-22 23:26:13,912] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 103876: loss 0.0316
[2019-03-22 23:26:13,917] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 103876: learning rate 0.0010
[2019-03-22 23:26:14,015] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 103917: loss 0.0487
[2019-03-22 23:26:14,021] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 103920: learning rate 0.0010
[2019-03-22 23:26:14,139] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 103978: loss 0.0020
[2019-03-22 23:26:14,144] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 103981: learning rate 0.0010
[2019-03-22 23:26:14,221] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 104016: loss 0.0129
[2019-03-22 23:26:14,228] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 104016: learning rate 0.0010
[2019-03-22 23:26:14,256] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 104034: loss 0.0004
[2019-03-22 23:26:14,259] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 104034: learning rate 0.0010
[2019-03-22 23:26:14,308] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 104056: loss 0.0091
[2019-03-22 23:26:14,310] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 104056: learning rate 0.0010
[2019-03-22 23:26:14,412] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 104104: loss 0.2029
[2019-03-22 23:26:14,417] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 104106: learning rate 0.0010
[2019-03-22 23:26:14,440] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 104117: loss 0.2857
[2019-03-22 23:26:14,444] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 104118: learning rate 0.0010
[2019-03-22 23:26:14,462] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 104129: loss 0.2516
[2019-03-22 23:26:14,465] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 104129: learning rate 0.0010
[2019-03-22 23:26:14,465] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 104130: loss 0.2030
[2019-03-22 23:26:14,473] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 104132: learning rate 0.0010
[2019-03-22 23:26:14,476] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 104133: loss 0.3178
[2019-03-22 23:26:14,478] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 104133: learning rate 0.0010
[2019-03-22 23:26:14,481] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 104133: loss 0.2653
[2019-03-22 23:26:14,487] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 104134: learning rate 0.0010
[2019-03-22 23:26:26,166] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.3359838e-37 1.0000000e+00 1.7770306e-37 4.7638650e-20 7.7053264e-23], sum to 1.0000
[2019-03-22 23:26:26,172] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2262
[2019-03-22 23:26:26,181] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2012962.126443526 W.
[2019-03-22 23:26:26,184] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 72.0, 1.0, 2.0, 0.8824330780252014, 1.0, 2.0, 0.8824330780252014, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2012962.126443526, 2012962.126443526, 378994.6794780657], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4116600.0000, 
sim time next is 4117200.0000, 
raw observation next is [29.0, 71.33333333333333, 1.0, 2.0, 0.5889082952381927, 1.0, 2.0, 0.5889082952381927, 1.0, 1.0, 0.9375611854233947, 6.9112, 6.9112, 121.94756008, 2015084.137690608, 2015084.137690608, 389365.3869254182], 
processed observation next is [1.0, 0.6521739130434783, 0.6296296296296297, 0.7133333333333333, 1.0, 1.0, 0.5106051133788008, 1.0, 1.0, 0.5106051133788008, 1.0, 0.5, 0.9219514817792435, 0.0, 0.0, 0.8096049824067558, 0.7196729063180742, 0.7196729063180742, 0.7487795902411889], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8526825], dtype=float32), -0.22807468]. 
=============================================
[2019-03-22 23:26:28,614] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:26:28,627] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0945
[2019-03-22 23:26:28,636] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 95.0, 1.0, 2.0, 0.4421820000544093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 539714.4385544419, 539714.4385544414, 134509.891473954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4152000.0000, 
sim time next is 4152600.0000, 
raw observation next is [20.85, 95.5, 1.0, 2.0, 0.4431452631645587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 540810.4722571144, 540810.4722571144, 134650.1315303274], 
processed observation next is [1.0, 0.043478260869565216, 0.32777777777777783, 0.955, 1.0, 1.0, 0.33707769424352224, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1931465972346837, 0.1931465972346837, 0.258942560635245], 
reward next is 0.7411, 
noisyNet noise sample is [array([-1.0908439], dtype=float32), 1.0487971]. 
=============================================
[2019-03-22 23:26:29,139] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 5.407064e-37 0.000000e+00], sum to 1.0000
[2019-03-22 23:26:29,149] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7338
[2019-03-22 23:26:29,160] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 98.0, 1.0, 2.0, 0.4988975135626824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 609378.9501984813, 609378.9501984813, 143194.7498903514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4155600.0000, 
sim time next is 4156200.0000, 
raw observation next is [20.35, 98.5, 1.0, 2.0, 0.4562237125813064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 557855.4149260485, 557855.4149260485, 136632.321306606], 
processed observation next is [1.0, 0.08695652173913043, 0.3092592592592593, 0.985, 1.0, 1.0, 0.35264727688250763, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19923407675930302, 0.19923407675930302, 0.26275446405116537], 
reward next is 0.7372, 
noisyNet noise sample is [array([-0.5533017], dtype=float32), -1.6906887]. 
=============================================
[2019-03-22 23:26:31,057] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111726: loss -58.8694
[2019-03-22 23:26:31,062] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111727: learning rate 0.0010
[2019-03-22 23:26:31,372] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 111868: loss -17.9499
[2019-03-22 23:26:31,373] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 111868: learning rate 0.0010
[2019-03-22 23:26:31,401] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 111884: loss -119.7946
[2019-03-22 23:26:31,406] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 111884: learning rate 0.0010
[2019-03-22 23:26:31,411] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 111887: loss -99.9090
[2019-03-22 23:26:31,414] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 111888: learning rate 0.0010
[2019-03-22 23:26:31,421] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 111889: loss -94.4943
[2019-03-22 23:26:31,425] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 111890: learning rate 0.0010
[2019-03-22 23:26:31,442] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 111895: loss 18.8863
[2019-03-22 23:26:31,444] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 111896: learning rate 0.0010
[2019-03-22 23:26:31,565] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 111955: loss -120.1738
[2019-03-22 23:26:31,568] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 111956: learning rate 0.0010
[2019-03-22 23:26:31,638] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 111982: loss 31.4201
[2019-03-22 23:26:31,638] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 111982: learning rate 0.0010
[2019-03-22 23:26:31,733] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 112032: loss -89.8413
[2019-03-22 23:26:31,736] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 112032: learning rate 0.0010
[2019-03-22 23:26:31,742] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 112035: loss 110.9618
[2019-03-22 23:26:31,746] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 112035: learning rate 0.0010
[2019-03-22 23:26:31,763] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 112046: loss 69.1022
[2019-03-22 23:26:31,768] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 112047: learning rate 0.0010
[2019-03-22 23:26:31,827] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 112066: loss 34.4969
[2019-03-22 23:26:31,829] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 112066: learning rate 0.0010
[2019-03-22 23:26:31,968] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 112133: loss 146.3122
[2019-03-22 23:26:31,969] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 112133: learning rate 0.0010
[2019-03-22 23:26:31,981] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 112138: loss 25.1825
[2019-03-22 23:26:31,982] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 112139: learning rate 0.0010
[2019-03-22 23:26:31,994] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 112142: loss 22.6372
[2019-03-22 23:26:31,994] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 112142: loss 39.3305
[2019-03-22 23:26:31,995] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 112142: learning rate 0.0010
[2019-03-22 23:26:31,996] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 112142: learning rate 0.0010
[2019-03-22 23:26:36,393] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.0748338e-34 6.6049721e-27 4.1889437e-24], sum to 1.0000
[2019-03-22 23:26:36,402] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9807
[2019-03-22 23:26:36,407] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 38.0, 1.0, 2.0, 0.5391900760319527, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8644582863089525, 6.9112, 6.9112, 121.9260426156618, 1274691.860547329, 1274691.860547329, 269934.505187616], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4279200.0000, 
sim time next is 4279800.0000, 
raw observation next is [32.0, 38.0, 1.0, 2.0, 1.002307347612966, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.478290225010666, 6.9112, 121.9236794928802, 1492360.700393945, 1201965.447675413, 244285.5975400177], 
processed observation next is [1.0, 0.5217391304347826, 0.7407407407407407, 0.38, 1.0, 1.0, 1.0027468423963881, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.056709022501066644, 0.0, 0.8094464401423406, 0.5329859644264089, 0.42927337416979033, 0.46977999526926484], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0973588], dtype=float32), 0.8116174]. 
=============================================
[2019-03-22 23:26:37,469] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0502631e-32 1.0000000e+00 2.5614835e-29 2.8328193e-20 6.5017446e-22], sum to 1.0000
[2019-03-22 23:26:37,479] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0269
[2019-03-22 23:26:37,486] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.75, 45.33333333333334, 1.0, 2.0, 0.3707210820006003, 1.0, 2.0, 0.3707210820006003, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 851977.1471706271, 851977.1471706271, 198630.2055818937], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4295400.0000, 
sim time next is 4296000.0000, 
raw observation next is [31.6, 46.66666666666667, 1.0, 2.0, 0.5154960977240161, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 601041.8667818238, 601041.8667818233, 144793.6344586168], 
processed observation next is [1.0, 0.7391304347826086, 0.725925925925926, 0.46666666666666673, 1.0, 1.0, 0.4232096401476381, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21465780956493707, 0.2146578095649369, 0.27844929703580157], 
reward next is 0.7216, 
noisyNet noise sample is [array([-1.6239917], dtype=float32), -1.7903284]. 
=============================================
[2019-03-22 23:26:37,506] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[29.973436]
 [27.407352]
 [26.764353]
 [26.641327]
 [26.305672]], R is [[32.40868759]
 [32.70262146]
 [32.70359802]
 [32.63497925]
 [32.55926132]].
[2019-03-22 23:26:39,722] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.1967993e-38 1.0000000e+00 0.0000000e+00 1.7566277e-31 7.8663812e-32], sum to 1.0000
[2019-03-22 23:26:39,736] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7267
[2019-03-22 23:26:39,742] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.534485915371232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 638014.7373969996, 638014.7373970001, 148437.7374722651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4341600.0000, 
sim time next is 4342200.0000, 
raw observation next is [23.16666666666667, 89.0, 1.0, 2.0, 0.6571767151382696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 781976.9507730954, 781976.9507730949, 169691.6682981087], 
processed observation next is [1.0, 0.2608695652173913, 0.4135802469135804, 0.89, 1.0, 1.0, 0.5918770418312733, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2792774824189626, 0.27927748241896244, 0.32633013134251676], 
reward next is 0.6737, 
noisyNet noise sample is [array([-0.2775938], dtype=float32), -1.7531117]. 
=============================================
[2019-03-22 23:26:40,002] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.3481092e-36 7.6888230e-31 2.4623224e-28], sum to 1.0000
[2019-03-22 23:26:40,009] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8692
[2019-03-22 23:26:40,013] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 89.33333333333333, 1.0, 2.0, 0.5185622600818428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622931.4718840994, 622931.4718840994, 146001.5364854894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4340400.0000, 
sim time next is 4341000.0000, 
raw observation next is [22.8, 89.16666666666667, 1.0, 2.0, 0.5258074800207587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 629659.7422717004, 629659.7422717004, 147100.7663897566], 
processed observation next is [1.0, 0.21739130434782608, 0.4, 0.8916666666666667, 1.0, 1.0, 0.435485095262808, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22487847938275016, 0.22487847938275016, 0.2828860892110704], 
reward next is 0.7171, 
noisyNet noise sample is [array([0.45310965], dtype=float32), 1.4237987]. 
=============================================
[2019-03-22 23:26:40,026] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[53.905163]
 [54.022354]
 [54.033947]
 [53.92321 ]
 [53.721756]], R is [[53.97765732]
 [54.15710831]
 [54.33666611]
 [54.51745224]
 [54.69156265]].
[2019-03-22 23:26:40,776] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.16912886e-35 1.00000000e+00 1.22586017e-32 1.02503038e-24
 1.68960004e-27], sum to 1.0000
[2019-03-22 23:26:40,785] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2866
[2019-03-22 23:26:40,792] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1849094.399867894 W.
[2019-03-22 23:26:40,797] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.2, 76.83333333333334, 1.0, 2.0, 0.8106717862248779, 1.0, 2.0, 0.8106717862248779, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425598578, 1849094.399867894, 1849094.399867894, 348184.1731887798], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4356600.0000, 
sim time next is 4357200.0000, 
raw observation next is [28.4, 74.66666666666667, 1.0, 2.0, 0.8393520195878353, 1.0, 2.0, 0.8393520195878353, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156448, 1914582.432231892, 1914582.432231892, 360283.7399870998], 
processed observation next is [1.0, 0.43478260869565216, 0.6074074074074074, 0.7466666666666667, 1.0, 1.0, 0.8087524042712325, 1.0, 1.0, 0.8087524042712325, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288200231, 0.6837794400828185, 0.6837794400828185, 0.692853346129038], 
reward next is 0.3071, 
noisyNet noise sample is [array([-0.75284165], dtype=float32), -0.9744347]. 
=============================================
[2019-03-22 23:26:46,443] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:26:46,458] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8291
[2019-03-22 23:26:46,464] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 74.16666666666667, 1.0, 2.0, 0.6265355143520305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716766.9639965609, 716766.9639965609, 162838.1674821817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4449000.0000, 
sim time next is 4449600.0000, 
raw observation next is [27.4, 74.0, 1.0, 2.0, 0.6305876495309908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 720288.1324666169, 720288.1324666169, 163500.4237305037], 
processed observation next is [0.0, 0.5217391304347826, 0.5703703703703703, 0.74, 1.0, 1.0, 0.5602233922987986, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25724576159522033, 0.25724576159522033, 0.3144238917894302], 
reward next is 0.6856, 
noisyNet noise sample is [array([0.48807865], dtype=float32), -0.14756721]. 
=============================================
[2019-03-22 23:26:48,373] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119610: loss 0.0074
[2019-03-22 23:26:48,377] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119611: learning rate 0.0010
[2019-03-22 23:26:48,910] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 119864: loss 0.0233
[2019-03-22 23:26:48,912] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 119864: learning rate 0.0010
[2019-03-22 23:26:48,919] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 119869: loss 0.0037
[2019-03-22 23:26:48,922] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 119870: learning rate 0.0010
[2019-03-22 23:26:48,931] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 119873: loss 0.0183
[2019-03-22 23:26:48,932] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 119873: learning rate 0.0010
[2019-03-22 23:26:48,967] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 119887: loss 0.0317
[2019-03-22 23:26:48,969] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 119887: learning rate 0.0010
[2019-03-22 23:26:48,983] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 119893: loss 0.0067
[2019-03-22 23:26:48,985] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 119895: learning rate 0.0010
[2019-03-22 23:26:49,050] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 119928: loss 0.0204
[2019-03-22 23:26:49,052] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 119928: learning rate 0.0010
[2019-03-22 23:26:49,145] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 119970: loss 0.0069
[2019-03-22 23:26:49,148] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 119970: learning rate 0.0010
[2019-03-22 23:26:49,261] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 120026: loss 0.0154
[2019-03-22 23:26:49,264] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 120026: learning rate 0.0010
[2019-03-22 23:26:49,351] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 120062: loss 0.0096
[2019-03-22 23:26:49,354] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 120062: learning rate 0.0010
[2019-03-22 23:26:49,364] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 120067: loss 0.0086
[2019-03-22 23:26:49,367] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 120069: learning rate 0.0010
[2019-03-22 23:26:49,431] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 120102: loss 0.0158
[2019-03-22 23:26:49,434] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 120102: learning rate 0.0010
[2019-03-22 23:26:49,467] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 120116: loss 0.0718
[2019-03-22 23:26:49,469] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 120116: learning rate 0.0010
[2019-03-22 23:26:49,487] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 120124: loss 0.1501
[2019-03-22 23:26:49,489] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 120124: learning rate 0.0010
[2019-03-22 23:26:49,632] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 120192: loss 0.1376
[2019-03-22 23:26:49,636] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 120192: learning rate 0.0010
[2019-03-22 23:26:49,658] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 120203: loss 0.0180
[2019-03-22 23:26:49,661] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 120203: learning rate 0.0010
[2019-03-22 23:26:50,866] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.6148051e-31 5.8699137e-38], sum to 1.0000
[2019-03-22 23:26:50,879] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2484
[2019-03-22 23:26:50,883] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 91.0, 1.0, 2.0, 0.5852850402488553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 678714.2085457573, 678714.2085457573, 156125.4731403083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4525200.0000, 
sim time next is 4525800.0000, 
raw observation next is [24.33333333333334, 90.66666666666667, 1.0, 2.0, 0.5903433234599739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683202.1034655073, 683202.1034655073, 156926.7957883757], 
processed observation next is [0.0, 0.391304347826087, 0.4567901234567903, 0.9066666666666667, 1.0, 1.0, 0.5123134803094926, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24400075123768117, 0.24400075123768117, 0.30178229959303016], 
reward next is 0.6982, 
noisyNet noise sample is [array([0.5038443], dtype=float32), -0.012400673]. 
=============================================
[2019-03-22 23:26:54,047] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.5901688e-38 5.0232620e-28 5.2232956e-32], sum to 1.0000
[2019-03-22 23:26:54,056] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7862
[2019-03-22 23:26:54,062] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 98.0, 1.0, 2.0, 0.4896455103047287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 587154.631144536, 587154.631144536, 141391.2481097938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4586400.0000, 
sim time next is 4587000.0000, 
raw observation next is [21.5, 98.33333333333334, 1.0, 2.0, 0.7865505204837915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 122.2837805496811, 943407.5784880484, 943407.5784880479, 195401.7936060465], 
processed observation next is [1.0, 0.08695652173913043, 0.35185185185185186, 0.9833333333333334, 1.0, 1.0, 0.7458934767664184, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8118371366807928, 0.33693127803144585, 0.3369312780314457, 0.3757726800116279], 
reward next is 0.6242, 
noisyNet noise sample is [array([0.4093947], dtype=float32), 1.0478418]. 
=============================================
[2019-03-22 23:26:54,072] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[69.52738]
 [69.50011]
 [69.74998]
 [70.09872]
 [70.3919 ]], R is [[68.87517548]
 [68.91452026]
 [68.95409393]
 [68.99397278]
 [69.0342865 ]].
[2019-03-22 23:26:55,903] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7086351e-36 1.0000000e+00 0.0000000e+00 1.3351052e-28 3.2323218e-26], sum to 1.0000
[2019-03-22 23:26:55,911] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4245
[2019-03-22 23:26:55,924] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1604343.574349336 W.
[2019-03-22 23:26:55,930] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.83333333333333, 72.33333333333334, 1.0, 2.0, 0.7802016399361745, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1604343.574349336, 1604343.574349336, 332328.7857843452], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4618200.0000, 
sim time next is 4618800.0000, 
raw observation next is [27.0, 71.0, 1.0, 2.0, 0.4437482460475615, 1.0, 1.0, 0.4437482460475615, 1.0, 2.0, 0.7064616595791541, 6.9112, 6.9112, 121.94756008, 1517954.87341424, 1517954.87341424, 316776.1887752704], 
processed observation next is [1.0, 0.4782608695652174, 0.5555555555555556, 0.71, 1.0, 1.0, 0.33779553100900184, 1.0, 0.5, 0.33779553100900184, 1.0, 1.0, 0.6330770744739425, 0.0, 0.0, 0.8096049824067558, 0.5421267405050857, 0.5421267405050857, 0.6091849784139816], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8014177], dtype=float32), 0.36953533]. 
=============================================
[2019-03-22 23:26:56,771] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2828461e-25 1.0000000e+00 2.2565415e-26 5.3391617e-21 8.5318064e-18], sum to 1.0000
[2019-03-22 23:26:56,782] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3205
[2019-03-22 23:26:56,790] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1781072.148811923 W.
[2019-03-22 23:26:56,795] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.1, 66.5, 1.0, 2.0, 0.5205864080978982, 1.0, 2.0, 0.5205864080978982, 1.0, 1.0, 0.8287905160075233, 6.911199999999999, 6.9112, 121.94756008, 1781072.148811923, 1781072.148811924, 353807.9887183802], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4627800.0000, 
sim time next is 4628400.0000, 
raw observation next is [29.23333333333333, 65.66666666666667, 1.0, 2.0, 0.5234136407151256, 1.0, 2.0, 0.5234136407151256, 1.0, 2.0, 0.8332915624106875, 6.911199999999999, 6.9112, 121.94756008, 1790754.598929828, 1790754.598929828, 355229.3396981574], 
processed observation next is [1.0, 0.5652173913043478, 0.6382716049382715, 0.6566666666666667, 1.0, 1.0, 0.4326352865656257, 1.0, 1.0, 0.4326352865656257, 1.0, 1.0, 0.7916144530133592, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.63955521390351, 0.63955521390351, 0.6831333455733796], 
reward next is 0.3169, 
noisyNet noise sample is [array([0.10630874], dtype=float32), -1.3516729]. 
=============================================
[2019-03-22 23:27:00,161] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-22 23:27:00,162] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:27:00,163] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:27:00,163] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:27:00,165] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:27:00,163] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:27:00,166] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:27:00,165] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:27:00,166] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:27:00,175] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:27:00,176] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:27:00,183] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run6
[2019-03-22 23:27:00,201] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run6
[2019-03-22 23:27:00,201] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run6
[2019-03-22 23:27:00,202] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run6
[2019-03-22 23:27:00,201] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run6
[2019-03-22 23:27:01,279] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.24256574], dtype=float32), 0.46140707]
[2019-03-22 23:27:01,279] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.83333333333334, 62.83333333333334, 1.0, 2.0, 0.3243747833042265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 418441.7347982461, 418441.7347982461, 112363.9637197247]
[2019-03-22 23:27:01,280] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:27:01,282] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.6160633e-24 1.0000000e+00 5.8884108e-25 9.4999574e-19 3.3313784e-19], sampled 0.18940671165039147
[2019-03-22 23:27:48,731] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.24256574], dtype=float32), 0.46140707]
[2019-03-22 23:27:48,732] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.75, 55.0, 1.0, 2.0, 0.7500682991957697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 854897.4991242032, 854897.4991242032, 185845.6424008517]
[2019-03-22 23:27:48,733] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:27:48,738] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.5988304e-38 1.0000000e+00 0.0000000e+00 5.4116435e-30 2.0488544e-31], sampled 0.538106571199655
[2019-03-22 23:28:02,471] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.24256574], dtype=float32), 0.46140707]
[2019-03-22 23:28:02,471] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.66191644, 51.79968998333334, 1.0, 2.0, 0.5810204302567005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 684184.2085965589, 684184.2085965589, 155851.9635816401]
[2019-03-22 23:28:02,473] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:28:02,476] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.0308900e-38 1.0000000e+00 0.0000000e+00 1.0772936e-29 7.3312987e-31], sampled 0.7005098223872611
[2019-03-22 23:28:03,146] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.24256574], dtype=float32), 0.46140707]
[2019-03-22 23:28:03,147] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.2, 66.0, 1.0, 2.0, 0.941580008885883, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1788549.86163724, 1788549.86163724, 366095.7262207177]
[2019-03-22 23:28:03,148] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:28:03,150] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.6720607e-33 1.0000000e+00 0.0000000e+00 2.3425505e-26 3.1158305e-26], sampled 0.3870704063452416
[2019-03-22 23:28:03,155] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1788549.86163724 W.
[2019-03-22 23:28:03,898] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.24256574], dtype=float32), 0.46140707]
[2019-03-22 23:28:03,898] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.99951432, 52.03189714, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.565936163720945, 6.9112, 121.9234542653759, 1498318.993487575, 1163042.675691638, 245585.5600118369]
[2019-03-22 23:28:03,899] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:28:03,904] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.8442751e-36 1.0000000e+00 0.0000000e+00 2.8693944e-28 1.3327384e-29], sampled 0.2411221247456966
[2019-03-22 23:28:03,906] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1498318.993487575 W.
[2019-03-22 23:28:06,126] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.24256574], dtype=float32), 0.46140707]
[2019-03-22 23:28:06,126] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.3, 80.0, 1.0, 2.0, 0.6079943875315943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696438.4746594977, 696438.4746594977, 159633.3958291828]
[2019-03-22 23:28:06,128] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:28:06,132] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.7824034e-32 1.2649607e-33], sampled 0.05258227943584792
[2019-03-22 23:28:24,773] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.24256574], dtype=float32), 0.46140707]
[2019-03-22 23:28:24,775] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.45, 43.5, 1.0, 2.0, 0.9953061074093141, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.520571921998561, 6.9112, 121.9235148168019, 1521857.29750962, 1209810.877954535, 243212.7369195896]
[2019-03-22 23:28:24,776] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:28:24,779] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.04342995e-33 1.00000000e+00 0.00000000e+00 4.99756252e-25
 4.16471873e-27], sampled 0.8918938475858864
[2019-03-22 23:28:24,780] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1521857.29750962 W.
[2019-03-22 23:28:30,435] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.24256574], dtype=float32), 0.46140707]
[2019-03-22 23:28:30,436] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.06666666666666, 86.33333333333333, 1.0, 2.0, 0.603041334747646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695524.3007758564, 695524.3007758564, 159004.2824974413]
[2019-03-22 23:28:30,437] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:28:30,442] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9291751e-31 1.4957916e-32], sampled 0.7862881024408194
[2019-03-22 23:28:52,341] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0838 2170637693.1962 493.0000
[2019-03-22 23:28:52,420] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.9706 2445378853.1784 746.0000
[2019-03-22 23:28:52,506] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.6901 2195047582.3563 572.0000
[2019-03-22 23:28:52,524] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-22 23:28:52,650] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.1625 2120466133.0938 430.0000
[2019-03-22 23:28:53,665] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 125000, evaluation results [125000.0, 8099.970618414005, 2445378853.1783895, 746.0, 8771.08379319977, 2170637693.1962304, 493.0, 8924.162528137549, 2120466133.0938108, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.690060682284, 2195047582.3563175, 572.0]
[2019-03-22 23:28:59,446] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127661: loss -37.7727
[2019-03-22 23:28:59,452] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 127661: learning rate 0.0010
[2019-03-22 23:28:59,854] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 127847: loss -73.0627
[2019-03-22 23:28:59,858] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 127847: learning rate 0.0010
[2019-03-22 23:28:59,963] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 127896: loss -91.2668
[2019-03-22 23:28:59,967] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 127897: learning rate 0.0010
[2019-03-22 23:28:59,982] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 127903: loss -59.3192
[2019-03-22 23:28:59,987] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 127905: learning rate 0.0010
[2019-03-22 23:28:59,996] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 127908: loss -25.5794
[2019-03-22 23:28:59,998] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 127908: learning rate 0.0010
[2019-03-22 23:29:00,009] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 127913: loss -15.2889
[2019-03-22 23:29:00,012] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 127913: learning rate 0.0010
[2019-03-22 23:29:00,054] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 127934: loss -34.7955
[2019-03-22 23:29:00,056] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 127934: learning rate 0.0010
[2019-03-22 23:29:00,238] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 128019: loss 53.1220
[2019-03-22 23:29:00,240] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 128019: learning rate 0.0010
[2019-03-22 23:29:00,256] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 128025: loss -0.1123
[2019-03-22 23:29:00,259] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 128026: learning rate 0.0010
[2019-03-22 23:29:00,307] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 128049: loss -11.4078
[2019-03-22 23:29:00,308] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 128049: loss -13.0556
[2019-03-22 23:29:00,310] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 128049: learning rate 0.0010
[2019-03-22 23:29:00,312] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 128050: learning rate 0.0010
[2019-03-22 23:29:00,398] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 128088: loss -79.3689
[2019-03-22 23:29:00,401] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 128089: learning rate 0.0010
[2019-03-22 23:29:00,460] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 128116: loss -91.8945
[2019-03-22 23:29:00,464] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 128119: learning rate 0.0010
[2019-03-22 23:29:00,489] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 128130: loss -90.7930
[2019-03-22 23:29:00,492] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 128131: learning rate 0.0010
[2019-03-22 23:29:00,493] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 128131: loss 26.8310
[2019-03-22 23:29:00,495] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 128131: learning rate 0.0010
[2019-03-22 23:29:00,504] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 128137: loss -23.1016
[2019-03-22 23:29:00,507] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 128137: learning rate 0.0010
[2019-03-22 23:29:02,344] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.0646323e-30 1.0000000e+00 8.1810091e-35 1.1599327e-21 7.4054882e-20], sum to 1.0000
[2019-03-22 23:29:02,354] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4407
[2019-03-22 23:29:02,362] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.06666666666667, 92.33333333333333, 1.0, 2.0, 0.7102817568412787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 809526.4599810407, 809526.4599810407, 178100.9504440318], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4833600.0000, 
sim time next is 4834200.0000, 
raw observation next is [26.08333333333334, 92.16666666666667, 1.0, 2.0, 0.709582049442629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808728.5646687681, 808728.5646687681, 177967.2701681992], 
processed observation next is [1.0, 0.9565217391304348, 0.5216049382716051, 0.9216666666666667, 1.0, 1.0, 0.6542643445745584, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2888316302388457, 0.2888316302388457, 0.34224475032346], 
reward next is 0.6578, 
noisyNet noise sample is [array([-1.3158884], dtype=float32), 0.5093567]. 
=============================================
[2019-03-22 23:29:09,911] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0034736e-22 9.9999976e-01 1.3998171e-30 2.3058233e-07 3.5524162e-14], sum to 1.0000
[2019-03-22 23:29:09,919] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1503
[2019-03-22 23:29:09,930] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1405080.135948651 W.
[2019-03-22 23:29:09,935] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.6161721143090034, 1.0, 1.0, 0.6161721143090034, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9256910125804, 1405080.135948651, 1405080.135948652, 273648.6827051293], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4971600.0000, 
sim time next is 4972200.0000, 
raw observation next is [25.7, 90.0, 1.0, 2.0, 0.5885729783716014, 1.0, 2.0, 0.5885729783716014, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260425084473, 1342089.658093374, 1342089.658093373, 264134.2209460848], 
processed observation next is [1.0, 0.5652173913043478, 0.5074074074074074, 0.9, 1.0, 1.0, 0.5102059266328588, 1.0, 1.0, 0.5102059266328588, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621281083432, 0.47931773503334785, 0.4793177350333475, 0.5079504248963169], 
reward next is 0.4920, 
noisyNet noise sample is [array([0.6919358], dtype=float32), -1.2706343]. 
=============================================
[2019-03-22 23:29:11,188] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.2380370e-26 1.0000000e+00 2.1706761e-32 9.8059039e-17 1.8100345e-22], sum to 1.0000
[2019-03-22 23:29:11,196] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5837
[2019-03-22 23:29:11,202] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.6603334510250911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 752571.1394989771, 752571.1394989771, 168772.4737878468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4989600.0000, 
sim time next is 4990200.0000, 
raw observation next is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.6683032867126416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 761658.7424722443, 761658.7424722438, 170231.5408278625], 
processed observation next is [1.0, 0.782608695652174, 0.5493827160493825, 0.8483333333333333, 1.0, 1.0, 0.6051229603721924, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.272020979454373, 0.2720209794543728, 0.32736834774588947], 
reward next is 0.6726, 
noisyNet noise sample is [array([-0.8622337], dtype=float32), 0.7573254]. 
=============================================
[2019-03-22 23:29:16,907] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 135658: loss 1.2060
[2019-03-22 23:29:16,911] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 135660: learning rate 0.0010
[2019-03-22 23:29:17,310] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 135841: loss 2.5026
[2019-03-22 23:29:17,314] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 135842: learning rate 0.0010
[2019-03-22 23:29:17,363] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 135866: loss 2.1760
[2019-03-22 23:29:17,368] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 135867: learning rate 0.0010
[2019-03-22 23:29:17,388] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 135879: loss 2.0509
[2019-03-22 23:29:17,392] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 135880: learning rate 0.0010
[2019-03-22 23:29:17,444] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 135906: loss 1.8459
[2019-03-22 23:29:17,449] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 135907: learning rate 0.0010
[2019-03-22 23:29:17,453] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 135909: loss 1.4191
[2019-03-22 23:29:17,456] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 135909: learning rate 0.0010
[2019-03-22 23:29:17,509] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 135931: loss 1.4765
[2019-03-22 23:29:17,512] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 135933: learning rate 0.0010
[2019-03-22 23:29:17,604] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 135979: loss 1.6668
[2019-03-22 23:29:17,606] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 135980: learning rate 0.0010
[2019-03-22 23:29:17,780] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 136060: loss 2.1462
[2019-03-22 23:29:17,783] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 136060: learning rate 0.0010
[2019-03-22 23:29:17,787] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 136062: loss 1.6142
[2019-03-22 23:29:17,791] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 136063: learning rate 0.0010
[2019-03-22 23:29:17,797] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 136066: loss 2.0009
[2019-03-22 23:29:17,799] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 136066: learning rate 0.0010
[2019-03-22 23:29:17,866] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 136096: loss 2.0602
[2019-03-22 23:29:17,869] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 136097: learning rate 0.0010
[2019-03-22 23:29:17,894] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 136110: loss 2.4843
[2019-03-22 23:29:17,900] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 136111: learning rate 0.0010
[2019-03-22 23:29:17,913] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 136118: loss 2.4467
[2019-03-22 23:29:17,917] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 136119: learning rate 0.0010
[2019-03-22 23:29:17,935] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 136127: loss 2.3475
[2019-03-22 23:29:17,938] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 136130: learning rate 0.0010
[2019-03-22 23:29:17,985] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 136150: loss 1.7097
[2019-03-22 23:29:17,987] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 136150: learning rate 0.0010
[2019-03-22 23:29:24,527] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1561389e-24 1.0000000e+00 4.3914088e-27 1.6089122e-13 1.5528137e-20], sum to 1.0000
[2019-03-22 23:29:24,533] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8914
[2019-03-22 23:29:24,539] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1817729.675225894 W.
[2019-03-22 23:29:24,545] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5312900821113402, 1.0, 1.0, 0.5312900821113402, 1.0, 2.0, 0.845831113631249, 6.911200000000001, 6.9112, 121.94756008, 1817729.675225894, 1817729.675225894, 359211.9292433145], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5220000.0000, 
sim time next is 5220600.0000, 
raw observation next is [27.15, 82.16666666666667, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.433939010921118, 6.9112, 121.9242322253659, 2146043.1726005, 1878358.051845121, 382258.5665301372], 
processed observation next is [1.0, 0.43478260869565216, 0.561111111111111, 0.8216666666666668, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.05227390109211179, 0.0, 0.8094501097112443, 0.7664439902144642, 0.6708421613732575, 0.7351126279425716], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7016406], dtype=float32), -0.10188114]. 
=============================================
[2019-03-22 23:29:25,062] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6822739e-28 6.9635832e-20 3.0066187e-35 1.0000000e+00 1.6053435e-25], sum to 1.0000
[2019-03-22 23:29:25,074] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1673
[2019-03-22 23:29:25,084] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.75, 74.83333333333333, 1.0, 2.0, 0.8336693078042026, 1.0, 2.0, 0.8336693078042026, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1901606.228413956, 1901606.228413956, 357863.1494887609], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5223000.0000, 
sim time next is 5223600.0000, 
raw observation next is [27.9, 73.0, 1.0, 2.0, 0.8296982028494392, 1.0, 2.0, 0.8296982028494392, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1892538.509811252, 1892538.509811252, 356178.4962354809], 
processed observation next is [1.0, 0.4782608695652174, 0.5888888888888888, 0.73, 1.0, 1.0, 0.7972597652969514, 1.0, 1.0, 0.7972597652969514, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6759066106468756, 0.6759066106468756, 0.684958646606694], 
reward next is 0.3150, 
noisyNet noise sample is [array([0.8322839], dtype=float32), 0.20760836]. 
=============================================
[2019-03-22 23:29:29,404] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5406012e-37 1.0000000e+00 1.0550878e-36 1.7842157e-16 3.0497146e-29], sum to 1.0000
[2019-03-22 23:29:29,415] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1193
[2019-03-22 23:29:29,421] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.13333333333333, 92.33333333333334, 1.0, 2.0, 0.5333222047758803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640648.5271659299, 640648.5271659299, 148392.1895000489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5298000.0000, 
sim time next is 5298600.0000, 
raw observation next is [22.01666666666667, 92.66666666666666, 1.0, 2.0, 0.5058000232466445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 608460.7147585601, 608460.7147585601, 143994.0335407533], 
processed observation next is [1.0, 0.30434782608695654, 0.37098765432098774, 0.9266666666666665, 1.0, 1.0, 0.4116666943412435, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21730739812805716, 0.21730739812805716, 0.2769116029629871], 
reward next is 0.7231, 
noisyNet noise sample is [array([-1.3787941], dtype=float32), 0.26586702]. 
=============================================
[2019-03-22 23:29:32,559] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.7350712e-38 9.9980861e-01 1.3158878e-32 1.9143552e-04 9.1329683e-37], sum to 1.0000
[2019-03-22 23:29:32,571] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5679
[2019-03-22 23:29:32,578] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.48333333333333, 78.5, 1.0, 2.0, 0.6203204151498475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 711236.8510673959, 711236.8510673959, 161820.4223246805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5352600.0000, 
sim time next is 5353200.0000, 
raw observation next is [26.4, 79.0, 1.0, 2.0, 0.6190899250227945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 709921.6397188576, 709921.6397188576, 161608.8347323074], 
processed observation next is [1.0, 1.0, 0.5333333333333333, 0.79, 1.0, 1.0, 0.5465356250271363, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25354344275673485, 0.25354344275673485, 0.3107862206390527], 
reward next is 0.6892, 
noisyNet noise sample is [array([0.9699855], dtype=float32), 1.7580032]. 
=============================================
[2019-03-22 23:29:34,764] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 143813: loss -157.8498
[2019-03-22 23:29:34,765] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 143813: learning rate 0.0010
[2019-03-22 23:29:34,787] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 143821: loss -154.9092
[2019-03-22 23:29:34,790] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 143821: learning rate 0.0010
[2019-03-22 23:29:34,980] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 143906: loss 0.3865
[2019-03-22 23:29:34,983] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 143906: learning rate 0.0010
[2019-03-22 23:29:35,004] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 143915: loss -91.4211
[2019-03-22 23:29:35,006] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 143915: loss -67.8149
[2019-03-22 23:29:35,007] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 143915: learning rate 0.0010
[2019-03-22 23:29:35,008] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 143916: learning rate 0.0010
[2019-03-22 23:29:35,058] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 143938: loss -51.3743
[2019-03-22 23:29:35,061] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 143938: learning rate 0.0010
[2019-03-22 23:29:35,161] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 143986: loss -20.4313
[2019-03-22 23:29:35,164] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 143986: learning rate 0.0010
[2019-03-22 23:29:35,186] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 143996: loss -46.1104
[2019-03-22 23:29:35,188] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 143996: learning rate 0.0010
[2019-03-22 23:29:35,280] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 144040: loss 0.7121
[2019-03-22 23:29:35,284] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 144040: learning rate 0.0010
[2019-03-22 23:29:35,303] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 144049: loss -7.1948
[2019-03-22 23:29:35,306] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 144051: loss -18.0586
[2019-03-22 23:29:35,307] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 144051: learning rate 0.0010
[2019-03-22 23:29:35,308] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 144051: learning rate 0.0010
[2019-03-22 23:29:35,353] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 144071: loss -7.4242
[2019-03-22 23:29:35,354] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 144071: learning rate 0.0010
[2019-03-22 23:29:35,354] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 144071: loss -25.1194
[2019-03-22 23:29:35,357] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 144071: learning rate 0.0010
[2019-03-22 23:29:35,393] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 144088: loss 55.4624
[2019-03-22 23:29:35,395] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 144088: learning rate 0.0010
[2019-03-22 23:29:35,395] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 144088: loss 23.6484
[2019-03-22 23:29:35,399] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 144088: learning rate 0.0010
[2019-03-22 23:29:35,442] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 144108: loss 22.5107
[2019-03-22 23:29:35,444] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 144109: learning rate 0.0010
[2019-03-22 23:29:35,977] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.0555517e-35 1.0000000e+00 1.1720492e-35 2.0487893e-26 5.3601978e-30], sum to 1.0000
[2019-03-22 23:29:35,983] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9626
[2019-03-22 23:29:35,990] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.8, 73.5, 1.0, 2.0, 0.6828839023345173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.926042615639, 778284.5643275917, 778284.5643275912, 172935.9405586504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5419800.0000, 
sim time next is 5420400.0000, 
raw observation next is [29.73333333333333, 74.0, 1.0, 2.0, 0.6931546285121246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 789996.1699744429, 789996.1699744429, 174858.7836582968], 
processed observation next is [1.0, 0.7391304347826086, 0.65679012345679, 0.74, 1.0, 1.0, 0.6347078910858627, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2821414892765868, 0.2821414892765868, 0.3362668916505708], 
reward next is 0.6637, 
noisyNet noise sample is [array([-1.498666], dtype=float32), 0.75989884]. 
=============================================
[2019-03-22 23:29:38,916] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.3310563e-37 7.7439852e-31 1.4083079e-36], sum to 1.0000
[2019-03-22 23:29:38,923] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0502
[2019-03-22 23:29:38,928] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.15, 94.5, 1.0, 2.0, 0.8283836227333559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 944213.1227147543, 944213.1227147543, 201876.3314903781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5459400.0000, 
sim time next is 5460000.0000, 
raw observation next is [26.13333333333333, 94.66666666666666, 1.0, 2.0, 0.816759517126393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 930955.6181218252, 930955.6181218252, 199429.2742737081], 
processed observation next is [1.0, 0.17391304347826086, 0.5234567901234567, 0.9466666666666665, 1.0, 1.0, 0.7818565680076107, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33248414932922327, 0.33248414932922327, 0.38351783514174637], 
reward next is 0.6165, 
noisyNet noise sample is [array([0.44924334], dtype=float32), -0.74704707]. 
=============================================
[2019-03-22 23:29:38,938] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[53.72585 ]
 [53.58608 ]
 [53.261986]
 [53.555317]
 [53.75215 ]], R is [[53.73696136]
 [53.81136703]
 [53.88220978]
 [53.90912628]
 [53.93809891]].
[2019-03-22 23:29:39,195] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.3548567e-34 1.2048273e-38], sum to 1.0000
[2019-03-22 23:29:39,204] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3006
[2019-03-22 23:29:39,208] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333333, 92.16666666666667, 1.0, 2.0, 0.8877424738357537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1011916.552038062, 1011916.552038062, 214742.4420913097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5471400.0000, 
sim time next is 5472000.0000, 
raw observation next is [27.4, 92.0, 1.0, 2.0, 0.9115813774102135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1039108.376563733, 1039108.376563733, 220079.6289754228], 
processed observation next is [1.0, 0.34782608695652173, 0.5703703703703703, 0.92, 1.0, 1.0, 0.894739735012159, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3711101344870475, 0.3711101344870475, 0.4232300557219669], 
reward next is 0.5768, 
noisyNet noise sample is [array([0.3881118], dtype=float32), -0.6516819]. 
=============================================
[2019-03-22 23:29:39,222] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[55.356136]
 [55.279675]
 [55.28268 ]
 [55.43234 ]
 [55.570072]], R is [[55.3808403 ]
 [55.41406631]
 [55.44205856]
 [55.45506287]
 [55.48907471]].
[2019-03-22 23:29:40,395] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1341071e-34 1.0000000e+00 1.0951727e-37 3.2812751e-23 1.8794543e-30], sum to 1.0000
[2019-03-22 23:29:40,404] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0803
[2019-03-22 23:29:40,411] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2435520.467555193 W.
[2019-03-22 23:29:40,415] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.84999999999999, 66.0, 1.0, 2.0, 0.7964976083028803, 1.0, 2.0, 0.7116134661278748, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2435520.467555193, 2435520.467555193, 456177.1798718996], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5491800.0000, 
sim time next is 5492400.0000, 
raw observation next is [33.03333333333333, 65.0, 1.0, 2.0, 0.74073642192565, 1.0, 2.0, 0.6837328729392597, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2339973.173083852, 2339973.173083852, 440366.0204084307], 
processed observation next is [1.0, 0.5652173913043478, 0.7790123456790122, 0.65, 1.0, 1.0, 0.6913528832448215, 1.0, 1.0, 0.6234915154038805, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.8357047046728043, 0.8357047046728043, 0.8468577315546745], 
reward next is 0.1531, 
noisyNet noise sample is [array([-0.93929476], dtype=float32), 0.5110512]. 
=============================================
[2019-03-22 23:29:45,437] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.2028353e-31 1.0000000e+00 5.5064710e-32 2.3429051e-21 3.2923013e-20], sum to 1.0000
[2019-03-22 23:29:45,444] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6486
[2019-03-22 23:29:45,453] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1772286.820463446 W.
[2019-03-22 23:29:45,460] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.43333333333333, 77.33333333333334, 1.0, 2.0, 0.5180211045562495, 1.0, 2.0, 0.5180211045562495, 1.0, 2.0, 0.8247064692231149, 6.9112, 6.9112, 121.94756008, 1772286.820463446, 1772286.820463446, 352522.0645973017], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5574000.0000, 
sim time next is 5574600.0000, 
raw observation next is [28.65, 77.0, 1.0, 2.0, 0.8568698852905746, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1691852.25727054, 1691852.25727054, 347814.1377564979], 
processed observation next is [1.0, 0.5217391304347826, 0.6166666666666666, 0.77, 1.0, 1.0, 0.8296070062983031, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6042329490251929, 0.6042329490251929, 0.668873341839419], 
reward next is 0.3311, 
noisyNet noise sample is [array([0.12470724], dtype=float32), 0.91699183]. 
=============================================
[2019-03-22 23:29:45,701] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6386368e-25 1.0000000e+00 7.0460152e-28 9.5799002e-21 2.6698447e-17], sum to 1.0000
[2019-03-22 23:29:45,713] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4427
[2019-03-22 23:29:45,719] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2452486.974931376 W.
[2019-03-22 23:29:45,723] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.6, 76.5, 1.0, 2.0, 0.8063985999669381, 1.0, 2.0, 0.7165639619599038, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2452486.974931376, 2452486.974931376, 459054.8945294881], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5581800.0000, 
sim time next is 5582400.0000, 
raw observation next is [29.3, 77.33333333333333, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 7.677035782552629, 6.9112, 121.9230032847568, 2719859.827016256, 2327693.232762912, 443049.151955411], 
processed observation next is [1.0, 0.6086956521739131, 0.6407407407407407, 0.7733333333333333, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.25, 0.0765835782552629, 0.0, 0.8094419508236081, 0.9713785096486628, 0.83131901170104, 0.852017599914252], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3160534], dtype=float32), 0.6314377]. 
=============================================
[2019-03-22 23:29:48,110] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:29:48,119] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1610
[2019-03-22 23:29:48,125] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 97.33333333333333, 1.0, 2.0, 0.5982115962947225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690046.3545029548, 690046.3545029548, 158173.8431753124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5618400.0000, 
sim time next is 5619000.0000, 
raw observation next is [23.6, 97.16666666666667, 1.0, 2.0, 0.5974881480415504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 689523.9733779839, 689523.9733779839, 158063.8456803849], 
processed observation next is [0.0, 0.0, 0.4296296296296297, 0.9716666666666667, 1.0, 1.0, 0.5208192238589885, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24625856192070852, 0.24625856192070852, 0.3039689340007402], 
reward next is 0.6960, 
noisyNet noise sample is [array([-0.35767415], dtype=float32), 0.6832921]. 
=============================================
[2019-03-22 23:29:48,141] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.872  ]
 [73.74822]
 [73.6495 ]
 [73.73588]
 [74.19262]], R is [[73.97297668]
 [73.92906189]
 [73.88523865]
 [73.84136963]
 [73.79737854]].
[2019-03-22 23:29:48,375] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-22 23:29:48,377] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:29:48,379] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:29:48,380] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:29:48,381] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:29:48,382] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:29:48,383] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:29:48,384] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:29:48,384] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:29:48,382] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:29:48,388] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:29:48,400] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run7
[2019-03-22 23:29:48,417] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run7
[2019-03-22 23:29:48,433] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run7
[2019-03-22 23:29:48,451] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run7
[2019-03-22 23:29:48,472] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run7
[2019-03-22 23:29:53,421] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:29:53,423] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.6, 33.0, 1.0, 2.0, 0.2930715895212923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 378050.8289727205, 378050.8289727205, 101922.6246618581]
[2019-03-22 23:29:53,424] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:29:53,426] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.658862160006063
[2019-03-22 23:30:06,912] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:30:06,914] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.39478754666667, 91.19592807666666, 1.0, 2.0, 0.3122202638027583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396346.8772291243, 396346.8772291243, 117087.8479695335]
[2019-03-22 23:30:06,915] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:30:06,918] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4903688685527907
[2019-03-22 23:30:19,771] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:30:19,773] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.91666666666667, 45.5, 1.0, 2.0, 0.5471608350031429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639865.7078387914, 639865.7078387914, 149988.087055216]
[2019-03-22 23:30:19,773] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:30:19,775] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6714268405633366
[2019-03-22 23:30:22,076] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:30:22,079] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.39437055, 96.09727047, 1.0, 2.0, 0.4704181283130539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 566261.373452895, 566261.373452895, 138506.6665728815]
[2019-03-22 23:30:22,081] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:30:22,084] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.22686758361046744
[2019-03-22 23:30:22,801] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:30:22,802] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.73124498, 62.17211197, 1.0, 2.0, 0.5429697114093027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638800.9859060991, 638800.9859060991, 149461.5126203079]
[2019-03-22 23:30:22,802] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:30:22,804] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9975974674900285
[2019-03-22 23:30:29,463] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:30:29,466] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.26782735333333, 92.60434318666667, 1.0, 2.0, 0.6822088764280185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 785783.5183936988, 785783.5183936988, 173213.9295851691]
[2019-03-22 23:30:29,468] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:30:29,469] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8732076173526775
[2019-03-22 23:30:39,509] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:30:39,510] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.25, 72.0, 1.0, 2.0, 0.5647474334950642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652371.6480104356, 652371.6480104356, 152544.9555107396]
[2019-03-22 23:30:39,511] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:30:39,514] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.878980394452077
[2019-03-22 23:30:40,815] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:30:40,818] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.24782463666667, 78.66522575666667, 1.0, 2.0, 0.5056472667199053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602278.2067668727, 602278.2067668727, 143753.8587938268]
[2019-03-22 23:30:40,820] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:30:40,824] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6258279699133661
[2019-03-22 23:30:40,991] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:30:40,992] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.25, 52.33333333333333, 1.0, 2.0, 0.5274097096596009, 0.0, 2.0, 0.0, 1.0, 1.0, 0.839653434313172, 6.9112, 6.9112, 121.9257996526358, 1202513.048241215, 1202513.048241215, 266681.0362484108]
[2019-03-22 23:30:40,992] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:30:40,995] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.3846974e-37 2.8208174e-35 3.0226727e-35], sampled 0.873211640587039
[2019-03-22 23:31:03,044] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:31:03,045] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.1, 86.33333333333334, 1.0, 2.0, 0.7289552072607337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 830820.6085206355, 830820.608520635, 181700.0192477321]
[2019-03-22 23:31:03,047] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:31:03,049] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7762560629839654
[2019-03-22 23:31:32,652] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:31:32,652] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.12113276, 71.76201977, 1.0, 2.0, 0.5512420643115091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640594.9659184369, 640594.9659184369, 150483.9743594181]
[2019-03-22 23:31:32,653] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:31:32,658] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.48825416233761065
[2019-03-22 23:31:38,710] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2399 2120425912.2928 430.0000
[2019-03-22 23:31:39,136] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.6619 2445343923.2757 746.0000
[2019-03-22 23:31:39,284] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0845 2170631810.8436 493.0000
[2019-03-22 23:31:39,286] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7013 2248693483.9672 553.0000
[2019-03-22 23:31:39,362] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-22 23:31:40,378] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 150000, evaluation results [150000.0, 8100.661928194693, 2445343923.2757144, 746.0, 8771.084470098069, 2170631810.843588, 493.0, 8924.239875831723, 2120425912.2928398, 430.0, 8583.701325530239, 2248693483.9671583, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-22 23:31:41,146] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7529198e-38 0.0000000e+00], sum to 1.0000
[2019-03-22 23:31:41,156] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2704
[2019-03-22 23:31:41,164] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.26666666666667, 95.83333333333333, 1.0, 2.0, 0.6282126213237692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717219.674622882, 717219.674622882, 163061.7969178535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5641800.0000, 
sim time next is 5642400.0000, 
raw observation next is [24.33333333333334, 95.66666666666666, 1.0, 2.0, 0.6315028945720793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 720224.5809745941, 720224.5809745941, 163607.1322121412], 
processed observation next is [0.0, 0.30434782608695654, 0.4567901234567903, 0.9566666666666666, 1.0, 1.0, 0.5613129697286658, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2572230646337836, 0.2572230646337836, 0.3146291004079639], 
reward next is 0.6854, 
noisyNet noise sample is [array([-0.48784202], dtype=float32), -0.4308748]. 
=============================================
[2019-03-22 23:31:43,016] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4929367e-38 0.0000000e+00], sum to 1.0000
[2019-03-22 23:31:43,019] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2325
[2019-03-22 23:31:43,024] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.65, 66.0, 1.0, 2.0, 0.7188922886172006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819345.3507572464, 819345.3507572464, 179754.4587506498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5675400.0000, 
sim time next is 5676000.0000, 
raw observation next is [30.73333333333333, 65.66666666666666, 1.0, 2.0, 0.722934523462194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823954.896026817, 823954.896026817, 180534.3265788479], 
processed observation next is [0.0, 0.6956521739130435, 0.6938271604938271, 0.6566666666666666, 1.0, 1.0, 0.6701601469788023, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29426960572386324, 0.29426960572386324, 0.3471813972670152], 
reward next is 0.6528, 
noisyNet noise sample is [array([0.92258584], dtype=float32), 0.64409393]. 
=============================================
[2019-03-22 23:31:43,055] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[65.4192  ]
 [65.410515]
 [65.36268 ]
 [65.281906]
 [65.212296]], R is [[65.43283081]
 [65.43282318]
 [65.43678284]
 [65.44013214]
 [65.44015503]].
[2019-03-22 23:31:44,206] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 151752: loss 0.2335
[2019-03-22 23:31:44,208] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 151752: learning rate 0.0010
[2019-03-22 23:31:44,281] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 151786: loss 0.1079
[2019-03-22 23:31:44,283] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 151787: learning rate 0.0010
[2019-03-22 23:31:44,392] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 151836: loss 0.0011
[2019-03-22 23:31:44,393] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 151836: learning rate 0.0010
[2019-03-22 23:31:44,427] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 151853: loss 0.0013
[2019-03-22 23:31:44,429] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 151853: learning rate 0.0010
[2019-03-22 23:31:44,482] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 151876: loss 0.0538
[2019-03-22 23:31:44,485] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 151877: learning rate 0.0010
[2019-03-22 23:31:44,596] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 151928: loss 0.0612
[2019-03-22 23:31:44,599] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 151929: learning rate 0.0010
[2019-03-22 23:31:44,704] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 151975: loss 0.0070
[2019-03-22 23:31:44,710] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 151975: learning rate 0.0010
[2019-03-22 23:31:44,828] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 152034: loss 0.0012
[2019-03-22 23:31:44,833] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 152035: learning rate 0.0010
[2019-03-22 23:31:44,834] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 152035: loss 0.0041
[2019-03-22 23:31:44,838] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 152037: learning rate 0.0010
[2019-03-22 23:31:44,872] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 152052: loss 0.0170
[2019-03-22 23:31:44,874] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 152054: learning rate 0.0010
[2019-03-22 23:31:44,908] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 152070: loss 0.0112
[2019-03-22 23:31:44,913] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 152071: learning rate 0.0010
[2019-03-22 23:31:44,914] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 152072: loss 0.0079
[2019-03-22 23:31:44,919] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 152072: learning rate 0.0010
[2019-03-22 23:31:44,932] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 152081: loss 0.0082
[2019-03-22 23:31:44,935] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 152081: learning rate 0.0010
[2019-03-22 23:31:44,969] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 152096: loss 0.0018
[2019-03-22 23:31:44,971] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 152096: learning rate 0.0010
[2019-03-22 23:31:45,029] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 152123: loss 0.0056
[2019-03-22 23:31:45,031] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 152123: learning rate 0.0010
[2019-03-22 23:31:45,192] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 152195: loss 0.0525
[2019-03-22 23:31:45,196] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 152196: learning rate 0.0010
[2019-03-22 23:31:51,865] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.5201845e-32 0.0000000e+00], sum to 1.0000
[2019-03-22 23:31:51,872] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5241
[2019-03-22 23:31:51,880] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 51.66666666666667, 1.0, 2.0, 0.8038611481686216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1002318.159794572, 1002318.159794572, 200159.3302327861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5826000.0000, 
sim time next is 5826600.0000, 
raw observation next is [25.9, 50.0, 1.0, 2.0, 0.8053030910823387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1005886.322428261, 1005886.322428261, 200504.2384916426], 
processed observation next is [1.0, 0.43478260869565216, 0.5148148148148147, 0.5, 1.0, 1.0, 0.7682179655742127, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3592451151529504, 0.3592451151529504, 0.3855850740223896], 
reward next is 0.6144, 
noisyNet noise sample is [array([2.0361507], dtype=float32), -0.21695021]. 
=============================================
[2019-03-22 23:31:58,542] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.6045009e-28 9.9958140e-01 4.3427081e-32 4.1862583e-04 1.0737697e-30], sum to 1.0000
[2019-03-22 23:31:58,555] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7862
[2019-03-22 23:31:58,561] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.73333333333333, 56.33333333333334, 1.0, 2.0, 0.4740464296506099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 569902.0110335622, 569902.0110335627, 139036.682285836], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5941200.0000, 
sim time next is 5941800.0000, 
raw observation next is [27.6, 57.0, 1.0, 2.0, 0.4747518853705425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 570753.6246261043, 570753.6246261043, 139144.7125674069], 
processed observation next is [1.0, 0.782608695652174, 0.5777777777777778, 0.57, 1.0, 1.0, 0.3747046254411221, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20384058022360865, 0.20384058022360865, 0.26758598570655173], 
reward next is 0.7324, 
noisyNet noise sample is [array([-0.5502019], dtype=float32), 0.73380125]. 
=============================================
[2019-03-22 23:32:01,770] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 159774: loss -187.1606
[2019-03-22 23:32:01,772] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 159774: learning rate 0.0010
[2019-03-22 23:32:01,981] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 159871: loss -125.6740
[2019-03-22 23:32:01,983] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 159871: learning rate 0.0010
[2019-03-22 23:32:01,998] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 159876: loss -130.0235
[2019-03-22 23:32:01,999] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 159876: learning rate 0.0010
[2019-03-22 23:32:02,016] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 159884: loss -93.3094
[2019-03-22 23:32:02,017] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 159885: learning rate 0.0010
[2019-03-22 23:32:02,022] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 159885: loss -102.3933
[2019-03-22 23:32:02,024] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 159885: learning rate 0.0010
[2019-03-22 23:32:02,092] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 159913: loss 0.2254
[2019-03-22 23:32:02,094] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 159913: learning rate 0.0010
[2019-03-22 23:32:02,135] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 159935: loss 0.2084
[2019-03-22 23:32:02,136] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 159935: learning rate 0.0010
[2019-03-22 23:32:02,356] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 160037: loss 1.9106
[2019-03-22 23:32:02,358] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 160037: learning rate 0.0010
[2019-03-22 23:32:02,380] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 160043: loss -3.9681
[2019-03-22 23:32:02,383] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 160044: learning rate 0.0010
[2019-03-22 23:32:02,401] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 160050: loss -63.3220
[2019-03-22 23:32:02,404] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 160050: learning rate 0.0010
[2019-03-22 23:32:02,420] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 160056: loss -20.2292
[2019-03-22 23:32:02,423] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 160058: learning rate 0.0010
[2019-03-22 23:32:02,424] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 160059: loss 1.3411
[2019-03-22 23:32:02,427] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 160060: learning rate 0.0010
[2019-03-22 23:32:02,442] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 160063: loss 0.5983
[2019-03-22 23:32:02,445] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 160064: learning rate 0.0010
[2019-03-22 23:32:02,548] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 160116: loss 1.6884
[2019-03-22 23:32:02,548] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 160116: loss 1.3116
[2019-03-22 23:32:02,549] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 160117: learning rate 0.0010
[2019-03-22 23:32:02,551] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 160117: learning rate 0.0010
[2019-03-22 23:32:02,561] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 160120: loss -37.5306
[2019-03-22 23:32:02,564] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 160120: learning rate 0.0010
[2019-03-22 23:32:02,660] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7422441e-31 2.7649367e-05 4.5273415e-37 9.9997234e-01 1.2534838e-33], sum to 1.0000
[2019-03-22 23:32:02,667] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5439
[2019-03-22 23:32:02,674] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 59.5, 1.0, 2.0, 0.7231675266406471, 1.0, 2.0, 0.7231675266406471, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426154101, 1649318.098877519, 1649318.098877519, 313027.3471798752], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6011400.0000, 
sim time next is 6012000.0000, 
raw observation next is [29.0, 59.0, 1.0, 2.0, 0.7817021974125081, 1.0, 2.0, 0.7817021974125081, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156617, 1782950.531578745, 1782950.531578745, 336249.9283723101], 
processed observation next is [1.0, 0.6086956521739131, 0.6296296296296297, 0.59, 1.0, 1.0, 0.7401216635863191, 1.0, 1.0, 0.7401216635863191, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201352, 0.636768046992409, 0.636768046992409, 0.6466344776390579], 
reward next is 0.3534, 
noisyNet noise sample is [array([-0.92159027], dtype=float32), 1.7729465]. 
=============================================
[2019-03-22 23:32:02,694] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[64.87726 ]
 [63.439705]
 [63.011047]
 [65.115166]
 [68.48212 ]], R is [[64.93096924]
 [64.6796875 ]
 [64.03289032]
 [63.39256287]
 [62.75863647]].
[2019-03-22 23:32:05,162] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.782821e-38 1.000000e+00 0.000000e+00 1.980223e-13 0.000000e+00], sum to 1.0000
[2019-03-22 23:32:05,170] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9384
[2019-03-22 23:32:05,177] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 91.0, 1.0, 2.0, 0.4944364172215576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593097.8772030988, 593097.8772030988, 142145.2855194043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6055200.0000, 
sim time next is 6055800.0000, 
raw observation next is [22.45, 90.66666666666667, 1.0, 2.0, 0.7920870009217411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 122.280556667847, 950016.345366759, 950016.345366759, 196553.8461358111], 
processed observation next is [1.0, 0.08695652173913043, 0.387037037037037, 0.9066666666666667, 1.0, 1.0, 0.7524845249068346, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8118157334580152, 0.33929155191669963, 0.33929155191669963, 0.3779881656457906], 
reward next is 0.6220, 
noisyNet noise sample is [array([0.15863314], dtype=float32), -1.1520038]. 
=============================================
[2019-03-22 23:32:14,055] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5896019e-26 9.9999964e-01 8.0348818e-32 3.0655463e-07 5.2118056e-26], sum to 1.0000
[2019-03-22 23:32:14,065] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0955
[2019-03-22 23:32:14,070] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.41666666666667, 55.16666666666667, 1.0, 2.0, 0.5223675300161863, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 611975.0662026751, 611975.0662026746, 146013.4621743657], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6198600.0000, 
sim time next is 6199200.0000, 
raw observation next is [29.3, 56.0, 1.0, 2.0, 0.5301970273119437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622167.1396483212, 622167.1396483212, 147315.9970237608], 
processed observation next is [1.0, 0.782608695652174, 0.6407407407407407, 0.56, 1.0, 1.0, 0.440710746799933, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22220254987440044, 0.22220254987440044, 0.2832999942764631], 
reward next is 0.7167, 
noisyNet noise sample is [array([0.4364397], dtype=float32), 0.009818258]. 
=============================================
[2019-03-22 23:32:18,951] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0176290e-38 1.0000000e+00 1.0353799e-35 2.7660102e-16 1.9317422e-34], sum to 1.0000
[2019-03-22 23:32:18,961] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2507
[2019-03-22 23:32:18,967] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.18333333333333, 60.33333333333333, 1.0, 2.0, 0.6521165981723992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 743201.9880683129, 743201.9880683129, 167275.4296920089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6282600.0000, 
sim time next is 6283200.0000, 
raw observation next is [30.06666666666667, 60.66666666666667, 1.0, 2.0, 0.6413143619158926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 730885.0636366272, 730885.0636366272, 165330.2775783702], 
processed observation next is [0.0, 0.7391304347826086, 0.669135802469136, 0.6066666666666667, 1.0, 1.0, 0.5729932879951103, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.261030379870224, 0.261030379870224, 0.3179428414968658], 
reward next is 0.6821, 
noisyNet noise sample is [array([-0.30950978], dtype=float32), -0.73274976]. 
=============================================
[2019-03-22 23:32:19,461] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 167831: loss 0.1043
[2019-03-22 23:32:19,465] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 167832: learning rate 0.0010
[2019-03-22 23:32:19,492] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 167844: loss 0.1563
[2019-03-22 23:32:19,495] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 167845: learning rate 0.0010
[2019-03-22 23:32:19,519] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 167858: loss 0.1012
[2019-03-22 23:32:19,521] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 167858: learning rate 0.0010
[2019-03-22 23:32:19,569] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 167880: loss 0.0636
[2019-03-22 23:32:19,571] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 167880: learning rate 0.0010
[2019-03-22 23:32:19,651] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 167917: loss 0.0092
[2019-03-22 23:32:19,653] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 167917: learning rate 0.0010
[2019-03-22 23:32:19,700] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 167939: loss 0.0066
[2019-03-22 23:32:19,704] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 167941: learning rate 0.0010
[2019-03-22 23:32:19,715] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 167948: loss 0.0009
[2019-03-22 23:32:19,717] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 167949: learning rate 0.0010
[2019-03-22 23:32:19,738] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 167960: loss 0.0305
[2019-03-22 23:32:19,740] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 167960: learning rate 0.0010
[2019-03-22 23:32:19,840] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 168000: loss 0.0128
[2019-03-22 23:32:19,843] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 168000: learning rate 0.0010
[2019-03-22 23:32:19,913] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 168039: loss 0.0038
[2019-03-22 23:32:19,917] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 168039: learning rate 0.0010
[2019-03-22 23:32:19,937] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 168046: loss 0.0014
[2019-03-22 23:32:19,939] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 168047: learning rate 0.0010
[2019-03-22 23:32:19,946] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 168051: loss 0.0078
[2019-03-22 23:32:19,947] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 168051: learning rate 0.0010
[2019-03-22 23:32:19,973] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 168059: loss 0.0114
[2019-03-22 23:32:19,976] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 168060: learning rate 0.0010
[2019-03-22 23:32:20,097] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 168120: loss 0.0639
[2019-03-22 23:32:20,100] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 168121: learning rate 0.0010
[2019-03-22 23:32:20,126] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 168132: loss 0.0957
[2019-03-22 23:32:20,129] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 168132: learning rate 0.0010
[2019-03-22 23:32:20,278] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 168202: loss 0.0058
[2019-03-22 23:32:20,285] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 168202: learning rate 0.0010
[2019-03-22 23:32:25,648] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2507959e-33 1.0000000e+00 1.9556468e-34 1.9285163e-20 2.9646032e-36], sum to 1.0000
[2019-03-22 23:32:25,657] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3360
[2019-03-22 23:32:25,662] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.65, 82.5, 1.0, 2.0, 0.6825589677407253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777914.0476021738, 777914.0476021738, 172866.6964049963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6395400.0000, 
sim time next is 6396000.0000, 
raw observation next is [26.53333333333333, 83.0, 1.0, 2.0, 0.6792880249236382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774184.2638142337, 774184.2638142337, 172258.1782375922], 
processed observation next is [1.0, 0.0, 0.5382716049382715, 0.83, 1.0, 1.0, 0.6182000296709977, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2764943799336549, 0.2764943799336549, 0.331265727379985], 
reward next is 0.6687, 
noisyNet noise sample is [array([-0.59035283], dtype=float32), -0.024614295]. 
=============================================
[2019-03-22 23:32:25,676] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[53.07899 ]
 [53.52016 ]
 [54.15305 ]
 [54.982807]
 [56.150913]], R is [[52.88230515]
 [53.02104568]
 [53.158535  ]
 [53.29704285]
 [53.42892838]].
[2019-03-22 23:32:32,839] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2442220e-21 3.8757525e-23 1.9658594e-31 1.0000000e+00 2.2588342e-32], sum to 1.0000
[2019-03-22 23:32:32,850] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5817
[2019-03-22 23:32:32,856] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.2, 80.0, 1.0, 2.0, 0.8913299482844852, 1.0, 2.0, 0.8913299482844852, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2033280.326082734, 2033280.326082734, 382939.3162911995], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6523200.0000, 
sim time next is 6523800.0000, 
raw observation next is [28.1, 80.0, 1.0, 2.0, 0.9018274859205648, 1.0, 2.0, 0.9018274859205648, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2057254.639395896, 2057254.639395896, 387628.2970910157], 
processed observation next is [1.0, 0.5217391304347826, 0.5962962962962963, 0.8, 1.0, 1.0, 0.8831279594292438, 1.0, 1.0, 0.8831279594292438, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7347337997842486, 0.7347337997842486, 0.7454390328673378], 
reward next is 0.2546, 
noisyNet noise sample is [array([-0.81508136], dtype=float32), 0.35976067]. 
=============================================
[2019-03-22 23:32:33,539] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1618867e-15 3.2648233e-05 3.4652340e-23 9.9996734e-01 8.6079088e-22], sum to 1.0000
[2019-03-22 23:32:33,547] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3825
[2019-03-22 23:32:33,551] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.53333333333333, 79.33333333333334, 1.0, 2.0, 0.7645997379680646, 1.0, 2.0, 0.7645997379680646, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1743904.19833085, 1743904.19833085, 329343.6225649785], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6536400.0000, 
sim time next is 6537000.0000, 
raw observation next is [27.56666666666667, 79.16666666666667, 1.0, 2.0, 0.776935686102873, 1.0, 2.0, 0.776935686102873, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1772068.01940584, 1772068.019405842, 334316.0863518302], 
processed observation next is [1.0, 0.6521739130434783, 0.5765432098765433, 0.7916666666666667, 1.0, 1.0, 0.734447245360563, 1.0, 1.0, 0.734447245360563, 0.0, 1.0, -0.25, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.6328814355020858, 0.6328814355020864, 0.6429155506765966], 
reward next is 0.3571, 
noisyNet noise sample is [array([0.19622435], dtype=float32), -0.7348742]. 
=============================================
[2019-03-22 23:32:33,567] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[39.665665]
 [39.962055]
 [40.029682]
 [39.96048 ]
 [39.743088]], R is [[39.41401672]
 [39.3865242 ]
 [39.39054489]
 [39.39698792]
 [39.41317368]].
[2019-03-22 23:32:35,162] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-22 23:32:35,164] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:32:35,165] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:32:35,165] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:32:35,167] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:32:35,169] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:32:35,171] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:32:35,172] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:32:35,173] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:32:35,174] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:32:35,176] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:32:35,190] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run8
[2019-03-22 23:32:35,191] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run8
[2019-03-22 23:32:35,224] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run8
[2019-03-22 23:32:35,243] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run8
[2019-03-22 23:32:35,258] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run8
[2019-03-22 23:32:40,987] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:32:40,988] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.0, 56.0, 1.0, 2.0, 0.2348585627504608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 302943.4820554657, 302943.4820554657, 92494.09984015652]
[2019-03-22 23:32:40,989] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:32:40,995] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0070748e-37 1.0000000e+00 9.5206268e-36 2.7962602e-21 5.8616663e-35], sampled 0.7241366162474194
[2019-03-22 23:32:42,080] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:32:42,081] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 33.0, 1.0, 2.0, 0.2879252146292923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 371410.6001438839, 371410.6001438839, 103433.2498372609]
[2019-03-22 23:32:42,083] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:32:42,087] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.5295845e-37 1.0000000e+00 2.7919862e-36 2.9782522e-20 3.2617867e-35], sampled 0.5309729992547801
[2019-03-22 23:32:46,885] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:32:46,886] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.26482579666667, 27.37354179333333, 1.0, 2.0, 0.3648860816227769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 460949.2049862284, 460949.2049862284, 123935.4759661467]
[2019-03-22 23:32:46,887] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:32:46,890] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.3074640e-34 1.0000000e+00 1.3289528e-34 7.1395626e-17 5.1794628e-33], sampled 0.7342621699948233
[2019-03-22 23:33:02,462] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:33:02,463] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.4, 90.0, 1.0, 2.0, 0.3911658099881465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485332.5184709943, 485332.5184709943, 127396.2463377512]
[2019-03-22 23:33:02,464] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:33:02,471] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4243822e-35 1.0000000e+00 1.9276643e-34 3.5515020e-18 3.6722010e-33], sampled 0.13285906047530294
[2019-03-22 23:33:05,323] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:33:05,324] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.63333333333333, 61.66666666666667, 1.0, 2.0, 0.3468530352886198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434904.271987447, 434904.271987447, 121483.1534584577]
[2019-03-22 23:33:05,325] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:33:05,331] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.0599179e-36 1.0000000e+00 1.4632485e-34 1.0131765e-18 1.2201910e-33], sampled 0.39670228770876326
[2019-03-22 23:33:13,766] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:33:13,767] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.882610285, 81.255041615, 1.0, 2.0, 0.5417283917077141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 636248.1002022887, 636248.1002022887, 149213.7147122208]
[2019-03-22 23:33:13,768] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:33:13,770] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.8023727e-33 1.0000000e+00 8.1741548e-33 8.7006875e-16 8.6882457e-32], sampled 0.7412781135873105
[2019-03-22 23:33:56,251] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:33:56,251] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.35, 93.0, 1.0, 2.0, 0.5573871438875251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 653673.2517928953, 653673.2517928953, 151756.8184262488]
[2019-03-22 23:33:56,252] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:33:56,253] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.2466647e-32 1.0000000e+00 1.4488088e-32 1.6449881e-13 1.4664862e-31], sampled 0.7564521514456908
[2019-03-22 23:34:09,590] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:34:09,595] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.57869944, 55.0316562, 1.0, 2.0, 0.2693476590878491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 345029.9705561231, 345029.9705561226, 111872.910292115]
[2019-03-22 23:34:09,597] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:34:09,600] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.6942966e-36 1.0000000e+00 3.5917040e-35 1.1601779e-18 1.3865661e-33], sampled 0.9669331882385865
[2019-03-22 23:34:09,963] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:34:09,967] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.777166535, 59.43698244666666, 1.0, 2.0, 0.450779213251283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571716.6701028788, 571716.6701028788, 136213.5678339501]
[2019-03-22 23:34:09,968] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:34:09,970] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.2754093e-32 1.0000000e+00 6.4128630e-32 3.3287175e-15 2.3940302e-30], sampled 0.32979315051922875
[2019-03-22 23:34:11,711] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:34:11,712] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 66.0, 1.0, 2.0, 0.777830953485615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.926042615655, 886558.5508898029, 886558.5508898029, 191396.6258494803]
[2019-03-22 23:34:11,713] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:34:11,716] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.78153791e-24 9.99963164e-01 1.04106135e-26 3.67898792e-05
 7.79496732e-25], sampled 0.2218145823456794
[2019-03-22 23:34:26,967] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8199.7759 2429218637.5661 636.0000
[2019-03-22 23:34:27,527] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8671.5809 2234023102.0040 461.0000
[2019-03-22 23:34:27,530] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8947.3077 2116105785.6066 404.0000
[2019-03-22 23:34:27,545] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8834.8039 2162706030.2077 439.0000
[2019-03-22 23:34:27,644] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8769.5465 2186966330.4741 510.0000
[2019-03-22 23:34:28,662] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 175000, evaluation results [175000.0, 8199.775856189703, 2429218637.5661154, 636.0, 8834.803929050864, 2162706030.2077184, 439.0, 8947.307669801505, 2116105785.6066487, 404.0, 8671.580855784223, 2234023102.0039597, 461.0, 8769.546514818949, 2186966330.474065, 510.0]
[2019-03-22 23:34:29,864] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.2183758e-28 9.9999917e-01 1.4794727e-28 7.9434903e-07 2.3162175e-28], sum to 1.0000
[2019-03-22 23:34:29,873] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4023
[2019-03-22 23:34:29,876] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 46.66666666666666, 1.0, 2.0, 0.3438264218566243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434630.7926782126, 434630.7926782126, 121133.0787513559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6583200.0000, 
sim time next is 6583800.0000, 
raw observation next is [25.6, 46.33333333333334, 1.0, 2.0, 0.3412373286493937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 431649.5223090037, 431649.5223090037, 120796.8238314545], 
processed observation next is [1.0, 0.17391304347826086, 0.5037037037037038, 0.46333333333333343, 1.0, 1.0, 0.21575872458261156, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15416054368178703, 0.15416054368178703, 0.23230158429125866], 
reward next is 0.7677, 
noisyNet noise sample is [array([0.49389878], dtype=float32), 0.6696541]. 
=============================================
[2019-03-22 23:34:30,326] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 175766: loss 1.7074
[2019-03-22 23:34:30,330] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 175766: learning rate 0.0010
[2019-03-22 23:34:30,361] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 175782: loss 1.5215
[2019-03-22 23:34:30,364] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 175784: learning rate 0.0010
[2019-03-22 23:34:30,622] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 175898: loss 1.4788
[2019-03-22 23:34:30,628] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 175902: learning rate 0.0010
[2019-03-22 23:34:30,689] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 175931: loss 0.8096
[2019-03-22 23:34:30,692] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 175933: learning rate 0.0010
[2019-03-22 23:34:30,721] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 175946: loss 0.9633
[2019-03-22 23:34:30,723] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 175947: learning rate 0.0010
[2019-03-22 23:34:30,724] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 175947: loss 0.9054
[2019-03-22 23:34:30,728] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 175948: learning rate 0.0010
[2019-03-22 23:34:30,772] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 175964: loss 1.1822
[2019-03-22 23:34:30,773] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 175964: learning rate 0.0010
[2019-03-22 23:34:30,797] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 175975: loss 0.3828
[2019-03-22 23:34:30,798] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 175975: learning rate 0.0010
[2019-03-22 23:34:30,800] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 175977: loss 1.1437
[2019-03-22 23:34:30,805] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 175977: learning rate 0.0010
[2019-03-22 23:34:30,901] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 176027: loss 0.7459
[2019-03-22 23:34:30,905] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 176030: learning rate 0.0010
[2019-03-22 23:34:30,907] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 176030: loss 0.7157
[2019-03-22 23:34:30,911] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 176030: learning rate 0.0010
[2019-03-22 23:34:30,931] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 176037: loss 0.9721
[2019-03-22 23:34:30,932] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 176037: learning rate 0.0010
[2019-03-22 23:34:31,064] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 176101: loss 0.3732
[2019-03-22 23:34:31,066] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 176102: learning rate 0.0010
[2019-03-22 23:34:31,075] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 176107: loss 0.3877
[2019-03-22 23:34:31,078] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 176107: learning rate 0.0010
[2019-03-22 23:34:31,133] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 176129: loss 0.8782
[2019-03-22 23:34:31,136] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 176129: learning rate 0.0010
[2019-03-22 23:34:31,225] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 176175: loss 0.1593
[2019-03-22 23:34:31,231] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 176177: learning rate 0.0010
[2019-03-22 23:34:37,511] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.9293094e-29 3.9115221e-06 3.9940965e-33 9.9999607e-01 1.8341694e-27], sum to 1.0000
[2019-03-22 23:34:37,522] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8030
[2019-03-22 23:34:37,528] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.35, 27.5, 1.0, 2.0, 0.5245774768828138, 1.0, 2.0, 0.5245774768828138, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1302782.11592314, 1302782.11592314, 247075.2486123438], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6712200.0000, 
sim time next is 6712800.0000, 
raw observation next is [30.4, 27.33333333333334, 1.0, 2.0, 0.523074052000352, 1.0, 2.0, 0.523074052000352, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1298850.546559531, 1298850.546559531, 246580.8982433346], 
processed observation next is [1.0, 0.6956521739130435, 0.6814814814814815, 0.2733333333333334, 1.0, 1.0, 0.43223101428613325, 1.0, 1.0, 0.43223101428613325, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4638751951998325, 0.4638751951998325, 0.4741940350833358], 
reward next is 0.5258, 
noisyNet noise sample is [array([1.1155127], dtype=float32), 1.4834669]. 
=============================================
[2019-03-22 23:34:47,822] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 183772: loss 0.0109
[2019-03-22 23:34:47,825] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 183772: learning rate 0.0010
[2019-03-22 23:34:47,982] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 183843: loss 0.0040
[2019-03-22 23:34:47,987] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 183843: learning rate 0.0010
[2019-03-22 23:34:48,106] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 183900: loss -0.8097
[2019-03-22 23:34:48,109] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 183900: learning rate 0.0010
[2019-03-22 23:34:48,124] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 183907: loss -0.0002
[2019-03-22 23:34:48,127] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 183907: learning rate 0.0010
[2019-03-22 23:34:48,149] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 183918: loss 0.0062
[2019-03-22 23:34:48,151] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 183919: learning rate 0.0010
[2019-03-22 23:34:48,173] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 183930: loss 0.0020
[2019-03-22 23:34:48,175] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 183930: learning rate 0.0010
[2019-03-22 23:34:48,234] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 183955: loss 0.0748
[2019-03-22 23:34:48,236] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 183955: learning rate 0.0010
[2019-03-22 23:34:48,265] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 183966: loss 0.0282
[2019-03-22 23:34:48,270] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 183967: learning rate 0.0010
[2019-03-22 23:34:48,321] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3946671e-32 1.0000000e+00 0.0000000e+00 3.6264623e-15 0.0000000e+00], sum to 1.0000
[2019-03-22 23:34:48,327] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 183998: loss 0.0347
[2019-03-22 23:34:48,330] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 183999: learning rate 0.0010
[2019-03-22 23:34:48,331] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4130
[2019-03-22 23:34:48,335] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 60.66666666666666, 1.0, 2.0, 0.4356655855561231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 533030.0424065903, 533030.0424065898, 133585.822486131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6900000.0000, 
sim time next is 6900600.0000, 
raw observation next is [25.55, 61.33333333333334, 1.0, 2.0, 0.4349647507450312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 532394.605427117, 532394.605427117, 133489.1266679372], 
processed observation next is [0.0, 0.8695652173913043, 0.5018518518518519, 0.6133333333333334, 1.0, 1.0, 0.32733898898218006, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19014093050968464, 0.19014093050968464, 0.2567098589768023], 
reward next is 0.7433, 
noisyNet noise sample is [array([0.6750438], dtype=float32), -0.89413726]. 
=============================================
[2019-03-22 23:34:48,399] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 184028: loss 0.0199
[2019-03-22 23:34:48,401] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 184029: learning rate 0.0010
[2019-03-22 23:34:48,405] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 184029: loss 0.0805
[2019-03-22 23:34:48,408] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 184031: learning rate 0.0010
[2019-03-22 23:34:48,427] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 184039: loss 0.0014
[2019-03-22 23:34:48,433] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 184040: learning rate 0.0010
[2019-03-22 23:34:48,536] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 184091: loss 0.0088
[2019-03-22 23:34:48,541] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 184092: learning rate 0.0010
[2019-03-22 23:34:48,554] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 184097: loss 0.0723
[2019-03-22 23:34:48,558] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 184099: learning rate 0.0010
[2019-03-22 23:34:48,663] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 184151: loss 0.2237
[2019-03-22 23:34:48,665] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 184151: learning rate 0.0010
[2019-03-22 23:34:48,720] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 184173: loss 0.0268
[2019-03-22 23:34:48,722] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 184173: learning rate 0.0010
[2019-03-22 23:34:53,776] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.7608685e-31 1.0000000e+00 5.9960631e-38 4.3875330e-23 1.1655765e-33], sum to 1.0000
[2019-03-22 23:34:53,786] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5715
[2019-03-22 23:34:53,790] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 68.66666666666667, 1.0, 2.0, 0.4283219850047325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 526068.7254053593, 526068.7254053593, 132567.1146752201], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6993600.0000, 
sim time next is 6994200.0000, 
raw observation next is [23.93333333333334, 69.33333333333333, 1.0, 2.0, 0.4271844473079233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524869.5953252534, 524869.5953252534, 132406.7277104751], 
processed observation next is [0.0, 0.9565217391304348, 0.4419753086419756, 0.6933333333333332, 1.0, 1.0, 0.31807672298562306, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18745342690187622, 0.18745342690187622, 0.25462832252014445], 
reward next is 0.7454, 
noisyNet noise sample is [array([-0.27211702], dtype=float32), 0.024239583]. 
=============================================
[2019-03-22 23:35:01,310] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.64721730e-23 9.99999523e-01 1.16225094e-32 4.49264292e-07
 2.99644205e-25], sum to 1.0000
[2019-03-22 23:35:01,318] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0712
[2019-03-22 23:35:01,325] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 78.66666666666667, 1.0, 2.0, 0.655515490689397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813799.1866184906, 813799.1866184906, 170456.1721635896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7119600.0000, 
sim time next is 7120200.0000, 
raw observation next is [21.88333333333334, 78.33333333333333, 1.0, 2.0, 0.6671707762356495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 827468.4622224324, 827468.4622224324, 172621.8572284634], 
processed observation next is [1.0, 0.391304347826087, 0.36604938271604964, 0.7833333333333333, 1.0, 1.0, 0.6037747336138684, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29552445079372586, 0.29552445079372586, 0.33196511005473733], 
reward next is 0.6680, 
noisyNet noise sample is [array([0.00763657], dtype=float32), 0.074361965]. 
=============================================
[2019-03-22 23:35:02,552] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8396234e-21 1.9851430e-13 1.3107585e-32 1.0000000e+00 1.7188124e-30], sum to 1.0000
[2019-03-22 23:35:02,560] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9032
[2019-03-22 23:35:02,565] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.75, 61.66666666666667, 1.0, 2.0, 0.3852398803130151, 1.0, 2.0, 0.3852398803130151, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 949488.1165410358, 949488.1165410358, 204910.427057707], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7138200.0000, 
sim time next is 7138800.0000, 
raw observation next is [23.7, 62.0, 1.0, 2.0, 0.3837864463384478, 1.0, 2.0, 0.3837864463384478, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 945905.5276380169, 945905.5276380169, 204509.3971887501], 
processed observation next is [1.0, 0.6521739130434783, 0.4333333333333333, 0.62, 1.0, 1.0, 0.2664124361171997, 1.0, 1.0, 0.2664124361171997, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33782340272786315, 0.33782340272786315, 0.39328730228605785], 
reward next is 0.6067, 
noisyNet noise sample is [array([-0.22218764], dtype=float32), -0.12041196]. 
=============================================
[2019-03-22 23:35:05,271] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 191721: loss 0.1296
[2019-03-22 23:35:05,276] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 191723: learning rate 0.0010
[2019-03-22 23:35:05,568] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191856: loss 0.0106
[2019-03-22 23:35:05,570] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 191857: learning rate 0.0010
[2019-03-22 23:35:05,614] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 191876: loss 0.1194
[2019-03-22 23:35:05,616] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 191877: learning rate 0.0010
[2019-03-22 23:35:05,633] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 191883: loss 0.0313
[2019-03-22 23:35:05,637] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 191885: learning rate 0.0010
[2019-03-22 23:35:05,644] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 191890: loss 0.0764
[2019-03-22 23:35:05,648] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 191891: learning rate 0.0010
[2019-03-22 23:35:05,669] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 191901: loss 0.0158
[2019-03-22 23:35:05,670] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 191902: loss 0.0769
[2019-03-22 23:35:05,672] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 191902: learning rate 0.0010
[2019-03-22 23:35:05,672] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 191902: learning rate 0.0010
[2019-03-22 23:35:05,933] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 192022: loss 0.0161
[2019-03-22 23:35:05,941] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 192025: learning rate 0.0010
[2019-03-22 23:35:05,945] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 192026: loss 0.0365
[2019-03-22 23:35:05,947] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 192027: loss 0.0049
[2019-03-22 23:35:05,947] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 192026: learning rate 0.0010
[2019-03-22 23:35:05,951] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 192027: learning rate 0.0010
[2019-03-22 23:35:06,004] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 192051: loss 0.0510
[2019-03-22 23:35:06,005] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 192052: learning rate 0.0010
[2019-03-22 23:35:06,061] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 192076: loss 0.0503
[2019-03-22 23:35:06,066] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 192076: learning rate 0.0010
[2019-03-22 23:35:06,067] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 192077: loss 0.0437
[2019-03-22 23:35:06,068] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 192077: learning rate 0.0010
[2019-03-22 23:35:06,105] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 192095: loss 0.1585
[2019-03-22 23:35:06,108] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 192095: learning rate 0.0010
[2019-03-22 23:35:06,219] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 192147: loss 0.0883
[2019-03-22 23:35:06,223] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 192149: learning rate 0.0010
[2019-03-22 23:35:06,421] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 192237: loss 0.0561
[2019-03-22 23:35:06,428] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 192240: learning rate 0.0010
[2019-03-22 23:35:07,523] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4767609e-16 9.4072154e-04 1.8531119e-26 9.9905926e-01 4.3071787e-21], sum to 1.0000
[2019-03-22 23:35:07,532] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8130
[2019-03-22 23:35:07,539] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.83333333333334, 70.0, 1.0, 2.0, 0.3380731894096154, 1.0, 2.0, 0.3380731894096154, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818718.2775025856, 818718.2775025856, 191852.7827127107], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7231200.0000, 
sim time next is 7231800.0000, 
raw observation next is [23.81666666666667, 70.0, 1.0, 2.0, 0.3265483091533223, 1.0, 2.0, 0.3265483091533223, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 791788.0030559788, 791788.0030559788, 188931.2258657824], 
processed observation next is [1.0, 0.6956521739130435, 0.43765432098765444, 0.7, 1.0, 1.0, 0.19827179661109795, 1.0, 1.0, 0.19827179661109795, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2827814296628496, 0.2827814296628496, 0.36332928051112], 
reward next is 0.6367, 
noisyNet noise sample is [array([0.2720165], dtype=float32), 0.0024432319]. 
=============================================
[2019-03-22 23:35:10,308] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.0166183e-28 7.1810798e-17 1.0886047e-36 1.0000000e+00 7.1899371e-31], sum to 1.0000
[2019-03-22 23:35:10,317] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3693
[2019-03-22 23:35:10,321] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.6, 90.0, 1.0, 2.0, 0.1947034702642212, 1.0, 2.0, 0.1947034702642212, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478042.3981324756, 478042.3981324756, 158677.5049767168], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7280400.0000, 
sim time next is 7281000.0000, 
raw observation next is [20.65, 90.0, 1.0, 2.0, 0.1956324238504703, 1.0, 2.0, 0.1956324238504703, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 479969.4109619534, 479969.4109619539, 158860.0097287047], 
processed observation next is [1.0, 0.2608695652173913, 0.3203703703703703, 0.9, 1.0, 1.0, 0.04241955220294084, 1.0, 1.0, 0.04241955220294084, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1714176467721262, 0.1714176467721264, 0.30550001870904747], 
reward next is 0.6945, 
noisyNet noise sample is [array([0.69361377], dtype=float32), -1.3075519]. 
=============================================
[2019-03-22 23:35:10,331] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[64.09223]
 [64.09877]
 [64.08152]
 [64.05087]
 [64.02631]], R is [[64.17108917]
 [64.22423553]
 [64.27671051]
 [64.32853699]
 [64.3807373 ]].
[2019-03-22 23:35:21,074] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.9481541e-30 7.4854846e-08 1.8123812e-32 9.9999988e-01 2.2441176e-28], sum to 1.0000
[2019-03-22 23:35:21,081] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8527
[2019-03-22 23:35:21,087] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.8, 90.5, 1.0, 2.0, 0.2000548565859108, 1.0, 2.0, 0.2000548565859108, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 489341.5033948964, 489341.5033948969, 159738.5182914483], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7461000.0000, 
sim time next is 7461600.0000, 
raw observation next is [20.96666666666667, 90.0, 1.0, 2.0, 0.2021939559509602, 1.0, 2.0, 0.2021939559509602, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 493753.5928773807, 493753.5928773811, 160161.44097706], 
processed observation next is [0.0, 0.34782608695652173, 0.3320987654320988, 0.9, 1.0, 1.0, 0.05023089994161929, 1.0, 1.0, 0.05023089994161929, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17634056888477884, 0.17634056888477895, 0.3080027711097308], 
reward next is 0.6920, 
noisyNet noise sample is [array([0.8121675], dtype=float32), 0.2134747]. 
=============================================
[2019-03-22 23:35:22,804] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 199709: loss 0.0097
[2019-03-22 23:35:22,807] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 199711: learning rate 0.0010
[2019-03-22 23:35:23,053] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 199826: loss 0.7289
[2019-03-22 23:35:23,056] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 199826: learning rate 0.0010
[2019-03-22 23:35:23,084] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 199841: loss 0.0408
[2019-03-22 23:35:23,086] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 199841: learning rate 0.0010
[2019-03-22 23:35:23,094] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 199844: loss 0.0022
[2019-03-22 23:35:23,095] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 199844: learning rate 0.0010
[2019-03-22 23:35:23,221] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 199902: loss 0.1147
[2019-03-22 23:35:23,225] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 199904: learning rate 0.0010
[2019-03-22 23:35:23,233] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 199908: loss 0.0851
[2019-03-22 23:35:23,235] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 199908: learning rate 0.0010
[2019-03-22 23:35:23,292] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 199930: loss 0.0719
[2019-03-22 23:35:23,295] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 199932: learning rate 0.0010
[2019-03-22 23:35:23,355] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.2071258e-24 2.2667467e-05 5.2303151e-32 9.9997735e-01 1.4515735e-27], sum to 1.0000
[2019-03-22 23:35:23,363] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7074
[2019-03-22 23:35:23,366] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.65, 90.5, 1.0, 2.0, 0.2488910159884669, 1.0, 1.0, 0.2488910159884669, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589852.8944307165, 589852.8944307165, 169725.298152047], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7504200.0000, 
sim time next is 7504800.0000, 
raw observation next is [22.6, 90.66666666666667, 1.0, 2.0, 0.2481240130209718, 1.0, 2.0, 0.2481240130209718, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 587572.2678126878, 587572.2678126878, 169532.9329825081], 
processed observation next is [0.0, 0.8695652173913043, 0.39259259259259266, 0.9066666666666667, 1.0, 1.0, 0.10490953931068073, 1.0, 1.0, 0.10490953931068073, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20984723850453135, 0.20984723850453135, 0.3260248711202079], 
reward next is 0.6740, 
noisyNet noise sample is [array([-0.17614324], dtype=float32), -1.1377112]. 
=============================================
[2019-03-22 23:35:23,438] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-22 23:35:23,442] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:35:23,442] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:35:23,444] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:35:23,445] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:35:23,445] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:35:23,446] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:35:23,446] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:35:23,448] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:35:23,449] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:35:23,449] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:35:23,470] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run9
[2019-03-22 23:35:23,489] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run9
[2019-03-22 23:35:23,516] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run9
[2019-03-22 23:35:23,531] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run9
[2019-03-22 23:35:23,533] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run9
[2019-03-22 23:35:26,316] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37912035], dtype=float32), 0.25133058]
[2019-03-22 23:35:26,318] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.77189955, 34.64050563333333, 1.0, 2.0, 0.2712164242861643, 1.0, 2.0, 0.2712164242861643, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 663707.8955426173, 663707.8955426178, 175593.3984768034]
[2019-03-22 23:35:26,319] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:35:26,323] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.2677264e-27 8.9657527e-07 1.6206326e-32 9.9999905e-01 5.2637236e-29], sampled 0.807025663346013
[2019-03-22 23:35:42,392] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37912035], dtype=float32), 0.25133058]
[2019-03-22 23:35:42,393] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.98333333333333, 64.33333333333334, 1.0, 2.0, 0.3588078802395022, 1.0, 2.0, 0.3588078802395022, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 877144.3306534204, 877144.3306534209, 197537.6632466214]
[2019-03-22 23:35:42,394] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:35:42,399] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.6608320e-28 2.4145100e-07 1.2950371e-33 9.9999976e-01 2.3433507e-29], sampled 0.7645140867905948
[2019-03-22 23:35:43,010] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37912035], dtype=float32), 0.25133058]
[2019-03-22 23:35:43,012] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.6, 86.0, 1.0, 2.0, 0.1925619531817181, 1.0, 2.0, 0.1925619531817181, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 475872.3288495681, 475872.3288495686, 158324.936867255]
[2019-03-22 23:35:43,013] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:35:43,015] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.3913935e-29 1.0003049e-08 4.3645698e-35 1.0000000e+00 7.9681345e-31], sampled 0.2838726276925556
[2019-03-22 23:36:09,709] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37912035], dtype=float32), 0.25133058]
[2019-03-22 23:36:09,710] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [34.6, 32.0, 1.0, 2.0, 0.874309418427959, 1.0, 2.0, 0.874309418427959, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2019666.036309983, 2019666.036309984, 376777.5389295808]
[2019-03-22 23:36:09,712] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:36:09,716] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.6881085e-32 2.0900483e-21 0.0000000e+00 1.0000000e+00 2.4605190e-36], sampled 0.07893316782029958
[2019-03-22 23:36:15,289] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37912035], dtype=float32), 0.25133058]
[2019-03-22 23:36:15,290] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.85174759666667, 94.59866496333335, 1.0, 2.0, 0.3134622692064468, 1.0, 2.0, 0.3134622692064468, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732185.0053397705, 732185.0053397705, 184557.5408015142]
[2019-03-22 23:36:15,291] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:36:15,295] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.9785222e-28 5.5154726e-07 1.4603591e-34 9.9999940e-01 7.4475726e-30], sampled 0.668722995317512
[2019-03-22 23:36:16,905] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.37912035], dtype=float32), 0.25133058]
[2019-03-22 23:36:16,907] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.40791437666667, 89.62252359000001, 1.0, 2.0, 0.9152147724948227, 1.0, 2.0, 0.9152147724948227, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2087829.505337507, 2087829.505337507, 393666.0394335083]
[2019-03-22 23:36:16,908] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:36:16,911] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.0990420e-32 1.0978682e-19 0.0000000e+00 1.0000000e+00 2.3194208e-35], sampled 0.2114715700080293
[2019-03-22 23:36:25,355] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.37912035], dtype=float32), 0.25133058]
[2019-03-22 23:36:25,356] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.5, 78.0, 1.0, 2.0, 0.4732483873113156, 1.0, 2.0, 0.4732483873113156, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1078936.335637413, 1078936.335637413, 227235.5835232587]
[2019-03-22 23:36:25,357] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:36:25,359] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.6589103e-29 3.3351105e-07 2.0299295e-35 9.9999964e-01 1.0453634e-30], sampled 0.6983848768888318
[2019-03-22 23:36:30,924] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37912035], dtype=float32), 0.25133058]
[2019-03-22 23:36:30,926] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.87964342666667, 105.56371304, 1.0, 2.0, 0.4035227648774584, 1.0, 2.0, 0.4035227648774584, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 924617.442423335, 924617.4424233364, 207387.1975640283]
[2019-03-22 23:36:30,927] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:36:30,930] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.8341465e-28 5.7846275e-05 5.0384048e-34 9.9994218e-01 2.4228415e-29], sampled 0.2888395099462633
[2019-03-22 23:36:41,877] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37912035], dtype=float32), 0.25133058]
[2019-03-22 23:36:41,879] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.0, 67.0, 1.0, 2.0, 0.9008573461393398, 1.0, 2.0, 0.7637933350461047, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2614369.301218485, 2614369.301218485, 487574.8190363495]
[2019-03-22 23:36:41,880] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:36:41,883] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 0. 0. 1. 0.], sampled 0.5428383043221238
[2019-03-22 23:36:41,885] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 0, 0, 1, 0] has been changed to [0, 0, 0, 0, 1] for the demand 2614369.301218485 W.
[2019-03-22 23:37:15,393] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7977.0959 2357615712.4376 42.0000
[2019-03-22 23:37:15,728] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8139.3177 2379245529.6100 50.0000
[2019-03-22 23:37:15,788] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7944.6222 2596125571.8324 67.0000
[2019-03-22 23:37:15,877] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 7864.3492 2410900898.4854 49.0000
[2019-03-22 23:37:15,905] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8330.8701 2325103051.0089 36.0000
[2019-03-22 23:37:16,920] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 200000, evaluation results [200000.0, 7944.622184293238, 2596125571.8324018, 67.0, 7977.095860142422, 2357615712.4375677, 42.0, 8330.870074595641, 2325103051.0088673, 36.0, 7864.349238753188, 2410900898.4853897, 49.0, 8139.317676962071, 2379245529.610004, 50.0]
[2019-03-22 23:37:16,994] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 200039: loss -0.0936
[2019-03-22 23:37:17,000] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 200040: learning rate 0.0010
[2019-03-22 23:37:17,025] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 200055: loss 0.0634
[2019-03-22 23:37:17,030] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 200056: learning rate 0.0010
[2019-03-22 23:37:17,031] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 200058: loss -0.0722
[2019-03-22 23:37:17,036] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 200058: learning rate 0.0010
[2019-03-22 23:37:17,059] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 200068: loss -0.3574
[2019-03-22 23:37:17,063] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 200069: learning rate 0.0010
[2019-03-22 23:37:17,097] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 200088: loss 0.3246
[2019-03-22 23:37:17,099] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 200089: learning rate 0.0010
[2019-03-22 23:37:17,102] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 200089: loss 0.0101
[2019-03-22 23:37:17,105] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 200089: learning rate 0.0010
[2019-03-22 23:37:17,141] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 200106: loss 0.0386
[2019-03-22 23:37:17,144] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 200106: learning rate 0.0010
[2019-03-22 23:37:17,278] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 200169: loss 0.0699
[2019-03-22 23:37:17,280] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 200169: learning rate 0.0010
[2019-03-22 23:37:17,407] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 200232: loss 0.0628
[2019-03-22 23:37:17,409] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 200232: learning rate 0.0010
[2019-03-22 23:37:17,543] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0702323e-31 2.4143235e-17 1.0475937e-33 1.0000000e+00 1.6981954e-33], sum to 1.0000
[2019-03-22 23:37:17,553] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8293
[2019-03-22 23:37:17,559] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.8, 95.0, 1.0, 2.0, 0.2402550734095079, 1.0, 2.0, 0.2402550734095079, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571851.8609978136, 571851.8609978136, 167895.3997184242], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7513200.0000, 
sim time next is 7513800.0000, 
raw observation next is [21.75, 95.0, 1.0, 2.0, 0.2395838637183532, 1.0, 2.0, 0.2395838637183532, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 570676.8606803314, 570676.8606803318, 167763.3973516782], 
processed observation next is [0.0, 1.0, 0.3611111111111111, 0.95, 1.0, 1.0, 0.09474269490280142, 1.0, 1.0, 0.09474269490280142, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20381316452868978, 0.20381316452868994, 0.32262191798399653], 
reward next is 0.6774, 
noisyNet noise sample is [array([0.9266711], dtype=float32), 1.2890844]. 
=============================================
[2019-03-22 23:37:25,021] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.6123840e-30 2.2629800e-08 0.0000000e+00 1.0000000e+00 1.8573118e-28], sum to 1.0000
[2019-03-22 23:37:25,029] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2787
[2019-03-22 23:37:25,033] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.93333333333333, 74.66666666666667, 1.0, 2.0, 0.6116017746033401, 1.0, 2.0, 0.6116017746033401, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1401080.322035068, 1401080.322035069, 272374.5893533809], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7645200.0000, 
sim time next is 7645800.0000, 
raw observation next is [26.01666666666667, 73.83333333333333, 1.0, 2.0, 0.6115384312668918, 1.0, 2.0, 0.6115384312668918, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1402243.695427232, 1402243.695427233, 272417.0119261297], 
processed observation next is [1.0, 0.4782608695652174, 0.5191358024691359, 0.7383333333333333, 1.0, 1.0, 0.5375457515082045, 1.0, 1.0, 0.5375457515082045, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.50080131979544, 0.5008013197954403, 0.523878869088711], 
reward next is 0.4761, 
noisyNet noise sample is [array([-0.5179436], dtype=float32), 1.0870746]. 
=============================================
[2019-03-22 23:37:30,411] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.3689577e-24 1.0000000e+00 1.9742945e-28 4.0840494e-08 1.7989199e-27], sum to 1.0000
[2019-03-22 23:37:30,422] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3019
[2019-03-22 23:37:30,428] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 80.0, 1.0, 2.0, 0.7403058565986043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 917892.1952760911, 917892.1952760908, 186869.4456701014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7722000.0000, 
sim time next is 7722600.0000, 
raw observation next is [22.06666666666667, 78.5, 1.0, 2.0, 0.7258402753312223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 898031.7223312624, 898031.7223312624, 183927.2864294737], 
processed observation next is [1.0, 0.391304347826087, 0.3728395061728396, 0.785, 1.0, 1.0, 0.6736193753943123, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.320725615118308, 0.320725615118308, 0.3537063200566802], 
reward next is 0.6463, 
noisyNet noise sample is [array([-1.1657417], dtype=float32), 1.6679767]. 
=============================================
[2019-03-22 23:37:33,890] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 207766: loss 0.6129
[2019-03-22 23:37:33,893] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 207766: learning rate 0.0010
[2019-03-22 23:37:33,901] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 207772: loss 0.9090
[2019-03-22 23:37:33,902] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 207772: learning rate 0.0010
[2019-03-22 23:37:33,950] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 207798: loss 1.1577
[2019-03-22 23:37:33,952] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 207798: learning rate 0.0010
[2019-03-22 23:37:33,987] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 207811: loss 0.8304
[2019-03-22 23:37:33,995] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 207812: learning rate 0.0010
[2019-03-22 23:37:33,997] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207812: loss 0.7042
[2019-03-22 23:37:33,999] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207813: learning rate 0.0010
[2019-03-22 23:37:34,063] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9043400e-28 1.0000000e+00 1.0946832e-31 9.5686410e-12 1.7826248e-30], sum to 1.0000
[2019-03-22 23:37:34,070] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9951
[2019-03-22 23:37:34,076] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 63.16666666666667, 1.0, 2.0, 0.3347095296306536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426073.1871111949, 426073.1871111949, 119967.6076760421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7794600.0000, 
sim time next is 7795200.0000, 
raw observation next is [22.1, 62.33333333333334, 1.0, 2.0, 0.3206714923168763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407942.9510283774, 407942.9510283774, 118162.4584655707], 
processed observation next is [1.0, 0.21739130434782608, 0.3740740740740741, 0.6233333333333334, 1.0, 1.0, 0.1912755860915194, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14569391108156335, 0.14569391108156335, 0.22723549704917442], 
reward next is 0.7728, 
noisyNet noise sample is [array([0.17695282], dtype=float32), 0.26080686]. 
=============================================
[2019-03-22 23:37:34,148] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 207884: loss 0.1013
[2019-03-22 23:37:34,149] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 207884: learning rate 0.0010
[2019-03-22 23:37:34,329] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 207965: loss 0.2352
[2019-03-22 23:37:34,332] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 207966: learning rate 0.0010
[2019-03-22 23:37:34,427] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 208009: loss 0.1181
[2019-03-22 23:37:34,430] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 208010: learning rate 0.0010
[2019-03-22 23:37:34,498] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 208042: loss 0.0156
[2019-03-22 23:37:34,504] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 208042: learning rate 0.0010
[2019-03-22 23:37:34,530] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 208056: loss 0.1975
[2019-03-22 23:37:34,532] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 208056: learning rate 0.0010
[2019-03-22 23:37:34,561] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 208068: loss 0.0217
[2019-03-22 23:37:34,562] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 208068: learning rate 0.0010
[2019-03-22 23:37:34,573] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 208072: loss 0.0109
[2019-03-22 23:37:34,576] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 208072: learning rate 0.0010
[2019-03-22 23:37:34,647] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 208111: loss 0.0209
[2019-03-22 23:37:34,654] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 208112: learning rate 0.0010
[2019-03-22 23:37:34,668] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 208120: loss 0.0049
[2019-03-22 23:37:34,670] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 208121: learning rate 0.0010
[2019-03-22 23:37:34,892] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 208221: loss 0.1033
[2019-03-22 23:37:34,893] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 208221: learning rate 0.0010
[2019-03-22 23:37:35,002] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 208269: loss 0.2027
[2019-03-22 23:37:35,007] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 208271: learning rate 0.0010
[2019-03-22 23:37:43,625] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,625] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,627] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run2
[2019-03-22 23:37:43,661] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,662] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,664] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run2
[2019-03-22 23:37:43,681] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,682] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,685] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run2
[2019-03-22 23:37:43,706] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,707] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,708] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run2
[2019-03-22 23:37:43,718] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,719] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,722] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run2
[2019-03-22 23:37:43,766] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,767] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,768] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run2
[2019-03-22 23:37:43,867] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,867] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,868] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run2
[2019-03-22 23:37:43,939] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,939] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,940] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run2
[2019-03-22 23:37:43,957] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,958] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,959] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run2
[2019-03-22 23:37:43,976] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,976] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,978] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run2
[2019-03-22 23:37:43,995] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,996] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,998] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run2
[2019-03-22 23:37:44,014] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:44,014] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:44,016] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run2
[2019-03-22 23:37:44,038] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:44,038] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:44,040] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run2
[2019-03-22 23:37:44,061] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:44,061] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:44,063] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run2
[2019-03-22 23:37:44,079] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:44,097] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:44,098] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run2
[2019-03-22 23:37:44,097] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:44,148] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:44,150] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run2
[2019-03-22 23:37:49,668] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9414232e-34 3.9398315e-18 0.0000000e+00 1.0000000e+00 9.9956548e-38], sum to 1.0000
[2019-03-22 23:37:49,681] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8490
[2019-03-22 23:37:49,687] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.13333333333333, 51.33333333333333, 1.0, 2.0, 0.2086779387413868, 1.0, 2.0, 0.2086779387413868, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 508903.1912247504, 508903.1912247508, 161512.3723205253], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 74400.0000, 
sim time next is 75000.0000, 
raw observation next is [26.96666666666667, 52.16666666666667, 1.0, 2.0, 0.2089635235772831, 1.0, 2.0, 0.2089635235772831, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 509557.7743085566, 509557.7743085571, 161571.7910342314], 
processed observation next is [1.0, 0.8695652173913043, 0.554320987654321, 0.5216666666666667, 1.0, 1.0, 0.05828990902057511, 1.0, 1.0, 0.05828990902057511, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18198491939591308, 0.18198491939591324, 0.3107149827581373], 
reward next is 0.6893, 
noisyNet noise sample is [array([1.1464618], dtype=float32), -0.082458064]. 
=============================================
[2019-03-22 23:37:49,700] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[68.942764]
 [68.872955]
 [68.85746 ]
 [68.91852 ]
 [68.9911  ]], R is [[69.02679443]
 [69.02592468]
 [69.02494049]
 [69.02397156]
 [69.02323914]].
[2019-03-22 23:38:00,135] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0109819e-29 1.0000000e+00 9.4853086e-38 3.3165341e-13 1.9744296e-36], sum to 1.0000
[2019-03-22 23:38:00,144] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0923
[2019-03-22 23:38:00,153] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 45.33333333333333, 1.0, 2.0, 0.2846459512581628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 367179.4847521661, 367179.4847521666, 109864.4213241634], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 258000.0000, 
sim time next is 258600.0000, 
raw observation next is [22.95, 45.66666666666667, 1.0, 2.0, 0.2830227963042908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 365085.195363404, 365085.195363404, 108740.0173020564], 
processed observation next is [0.0, 1.0, 0.4055555555555555, 0.4566666666666667, 1.0, 1.0, 0.14645570988606046, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1303875697726443, 0.1303875697726443, 0.20911541788857], 
reward next is 0.7909, 
noisyNet noise sample is [array([0.21975625], dtype=float32), 0.7437123]. 
=============================================
[2019-03-22 23:38:07,061] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7866383e-29 3.5262908e-22 1.0075512e-37 1.0000000e+00 5.1225703e-36], sum to 1.0000
[2019-03-22 23:38:07,069] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2795
[2019-03-22 23:38:07,073] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.73333333333333, 28.33333333333334, 1.0, 2.0, 0.435940248201093, 1.0, 2.0, 0.435940248201093, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1098037.478615585, 1098037.478615585, 219844.9933212666], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 386400.0000, 
sim time next is 387000.0000, 
raw observation next is [28.85, 28.0, 1.0, 2.0, 0.446462010883909, 1.0, 2.0, 0.446462010883909, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1123959.558437327, 1123959.558437327, 222963.3769989102], 
processed observation next is [1.0, 0.4782608695652174, 0.6240740740740741, 0.28, 1.0, 1.0, 0.341026203433225, 1.0, 1.0, 0.341026203433225, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.40141412801333104, 0.40141412801333104, 0.42877572499790423], 
reward next is 0.5712, 
noisyNet noise sample is [array([0.03212444], dtype=float32), -0.80391467]. 
=============================================
[2019-03-22 23:38:07,087] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[66.48048 ]
 [66.373405]
 [66.1581  ]
 [65.91187 ]
 [65.66242 ]], R is [[66.5019989 ]
 [66.41420746]
 [66.33450317]
 [66.25866699]
 [66.17874146]].
[2019-03-22 23:38:12,257] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6399352e-07 5.2443698e-09 8.8586358e-22 9.9999988e-01 2.8971071e-23], sum to 1.0000
[2019-03-22 23:38:12,266] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5017
[2019-03-22 23:38:12,270] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.5, 75.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 331262.5588531869, 331262.5588531874, 140117.4548477911], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 451200.0000, 
sim time next is 451800.0000, 
raw observation next is [18.8, 73.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 332458.419523585, 332458.4195235855, 140333.7651408463], 
processed observation next is [1.0, 0.21739130434782608, 0.2518518518518519, 0.735, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11873514982985178, 0.11873514982985195, 0.2698726252708583], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.0922575], dtype=float32), -0.5561488]. 
=============================================
[2019-03-22 23:38:13,790] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-22 23:38:13,793] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:38:13,793] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:38:13,793] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:38:13,794] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:38:13,795] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:38:13,798] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:38:13,801] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:38:13,802] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:38:13,798] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:38:13,806] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:38:13,812] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run10
[2019-03-22 23:38:13,831] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run10
[2019-03-22 23:38:13,833] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run10
[2019-03-22 23:38:13,833] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run10
[2019-03-22 23:38:13,880] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run10
[2019-03-22 23:38:35,252] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.314468], dtype=float32), 0.22307123]
[2019-03-22 23:38:35,254] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.54807612166667, 19.959684965, 1.0, 2.0, 0.3201909623655795, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 413043.1746958577, 413043.1746958582, 105095.4599202419]
[2019-03-22 23:38:35,255] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:38:35,258] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.2987793e-26 9.9999654e-01 1.1612799e-27 3.4300328e-06 3.7017951e-25], sampled 0.2336475268265693
[2019-03-22 23:38:37,780] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.314468], dtype=float32), 0.22307123]
[2019-03-22 23:38:37,781] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.27869824333333, 34.89918486666667, 1.0, 2.0, 0.3222774051916507, 1.0, 2.0, 0.3222774051916507, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 811723.8380717163, 811723.8380717167, 188583.120610051]
[2019-03-22 23:38:37,783] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:38:37,786] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.0900056e-27 1.2009006e-10 3.8793608e-31 1.0000000e+00 9.2218341e-28], sampled 0.001901436715043725
[2019-03-22 23:38:39,725] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.314468], dtype=float32), 0.22307123]
[2019-03-22 23:38:39,727] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.12764981833333, 84.81397058333334, 1.0, 2.0, 0.3378690747534834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424901.9912757939, 424901.9912757939, 120326.7841207587]
[2019-03-22 23:38:39,728] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:38:39,732] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.1804624e-25 9.9982125e-01 3.5128864e-26 1.7876852e-04 4.7477633e-25], sampled 0.24583078366952504
[2019-03-22 23:39:07,277] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.314468], dtype=float32), 0.22307123]
[2019-03-22 23:39:07,277] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.7, 96.0, 1.0, 2.0, 0.3310011031800674, 1.0, 2.0, 0.3310011031800674, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 754473.9283978356, 754473.9283978356, 188066.7581191512]
[2019-03-22 23:39:07,278] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:39:07,282] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.0502629e-25 2.9434316e-06 8.2959691e-29 9.9999702e-01 1.5902414e-25], sampled 0.25476653460032805
[2019-03-22 23:40:05,515] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8006.0100 2408499879.1926 47.0000
[2019-03-22 23:40:05,741] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8163.6228 2361614811.2111 30.0000
[2019-03-22 23:40:05,829] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7880.1173 2621749025.3327 68.0000
[2019-03-22 23:40:05,863] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 7687.8632 2440997017.1794 47.0000
[2019-03-22 23:40:05,984] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7784.6650 2389304500.1812 34.0000
[2019-03-22 23:40:07,003] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 225000, evaluation results [225000.0, 7880.117262054836, 2621749025.3326664, 68.0, 7784.664988425718, 2389304500.1811624, 34.0, 8163.622793133269, 2361614811.211116, 30.0, 7687.863219370762, 2440997017.1793504, 47.0, 8006.0100367823725, 2408499879.192616, 47.0]
[2019-03-22 23:40:07,198] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3032953e-31 2.6616234e-28 1.2921924e-37 1.0000000e+00 7.6280997e-35], sum to 1.0000
[2019-03-22 23:40:07,209] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4265
[2019-03-22 23:40:07,214] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.35, 25.0, 1.0, 2.0, 0.562374388187307, 1.0, 2.0, 0.562374388187307, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1380303.018912247, 1380303.018912247, 259242.844336114], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 487800.0000, 
sim time next is 488400.0000, 
raw observation next is [32.4, 24.66666666666667, 1.0, 2.0, 0.5524421162751008, 1.0, 2.0, 0.5524421162751008, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1357102.465834039, 1357102.465834039, 255928.5393351554], 
processed observation next is [1.0, 0.6521739130434783, 0.7555555555555555, 0.2466666666666667, 1.0, 1.0, 0.4671929955655961, 1.0, 1.0, 0.4671929955655961, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.48467945208358537, 0.48467945208358537, 0.4921702679522219], 
reward next is 0.5078, 
noisyNet noise sample is [array([-1.030597], dtype=float32), 2.0381796]. 
=============================================
[2019-03-22 23:40:16,490] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.2011801e-26 4.1205257e-31 1.5914899e-33 1.0000000e+00 8.2041084e-34], sum to 1.0000
[2019-03-22 23:40:16,499] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3167
[2019-03-22 23:40:16,504] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.13333333333334, 34.0, 1.0, 2.0, 0.5941094851166918, 1.0, 2.0, 0.5941094851166918, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1413426.954903877, 1413426.954903877, 268654.3446761501], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 645600.0000, 
sim time next is 646200.0000, 
raw observation next is [32.35, 33.0, 1.0, 2.0, 0.5713920129562868, 1.0, 2.0, 0.5713920129562868, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1362794.976610473, 1362794.976610474, 260994.1475515534], 
processed observation next is [1.0, 0.4782608695652174, 0.7537037037037038, 0.33, 1.0, 1.0, 0.48975239637653195, 1.0, 1.0, 0.48975239637653195, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.48671249164659747, 0.48671249164659786, 0.5019118222145258], 
reward next is 0.4981, 
noisyNet noise sample is [array([-0.71568304], dtype=float32), -0.35145983]. 
=============================================
[2019-03-22 23:40:19,563] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.5591404e-24 3.4358671e-09 1.1032667e-35 1.0000000e+00 1.8358906e-28], sum to 1.0000
[2019-03-22 23:40:19,571] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7603
[2019-03-22 23:40:19,576] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.8, 35.5, 1.0, 2.0, 0.1668447185792858, 1.0, 2.0, 0.1668447185792858, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 420734.7684051606, 420734.7684051611, 153221.6373336068], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 689400.0000, 
sim time next is 690000.0000, 
raw observation next is [27.66666666666666, 35.66666666666667, 1.0, 2.0, 0.1659676312144248, 1.0, 2.0, 0.1659676312144248, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 418860.1419106681, 418860.1419106686, 153049.1007915319], 
processed observation next is [1.0, 1.0, 0.5802469135802467, 0.3566666666666667, 1.0, 1.0, 0.00710432287431522, 1.0, 1.0, 0.00710432287431522, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14959290782523862, 0.1495929078252388, 0.29432519382986905], 
reward next is 0.7057, 
noisyNet noise sample is [array([0.34702566], dtype=float32), 0.6060638]. 
=============================================
[2019-03-22 23:40:19,592] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[62.062977]
 [62.139374]
 [62.21951 ]
 [62.291737]
 [62.342968]], R is [[62.08026505]
 [62.16480255]
 [62.24814987]
 [62.33030319]
 [62.4112854 ]].
[2019-03-22 23:40:23,141] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.6265970e-24 2.9355890e-04 1.4601219e-25 9.9970645e-01 8.1285996e-26], sum to 1.0000
[2019-03-22 23:40:23,148] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5439
[2019-03-22 23:40:23,157] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.7, 29.0, 1.0, 2.0, 0.1734233060537873, 1.0, 2.0, 0.1734233060537873, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 437191.5270338318, 437191.5270338323, 154564.9986955184], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 763200.0000, 
sim time next is 763800.0000, 
raw observation next is [29.53333333333333, 29.5, 1.0, 2.0, 0.1726777930365685, 1.0, 2.0, 0.1726777930365685, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 435366.0811052372, 435366.0811052372, 154412.6304784254], 
processed observation next is [1.0, 0.8695652173913043, 0.6493827160493827, 0.295, 1.0, 1.0, 0.015092610757819633, 1.0, 1.0, 0.015092610757819633, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1554878861090133, 0.1554878861090133, 0.29694736630466423], 
reward next is 0.7031, 
noisyNet noise sample is [array([1.530871], dtype=float32), -0.6467724]. 
=============================================
[2019-03-22 23:40:38,908] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1733268e-25 1.0000000e+00 1.7909353e-28 1.0213326e-12 5.1025370e-30], sum to 1.0000
[2019-03-22 23:40:38,920] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9121
[2019-03-22 23:40:38,924] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 44.66666666666667, 1.0, 2.0, 0.2834315310021178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 364243.4703237468, 364243.4703237464, 113549.8643963362], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1023600.0000, 
sim time next is 1024200.0000, 
raw observation next is [24.0, 45.0, 1.0, 2.0, 0.2837306214167032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 364624.7804239031, 364624.7804239031, 113585.9628313754], 
processed observation next is [1.0, 0.8695652173913043, 0.4444444444444444, 0.45, 1.0, 1.0, 0.14729835882940856, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13022313586567968, 0.13022313586567968, 0.21843454390649114], 
reward next is 0.7816, 
noisyNet noise sample is [array([-0.6475543], dtype=float32), -0.7694178]. 
=============================================
[2019-03-22 23:40:44,387] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4245452e-35 1.0000000e+00 4.8326608e-38 8.9807767e-17 1.0132523e-36], sum to 1.0000
[2019-03-22 23:40:44,402] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2842
[2019-03-22 23:40:44,407] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.13333333333333, 74.0, 1.0, 2.0, 0.2752014886032156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 354000.678322728, 354000.678322728, 112561.2411828243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1129200.0000, 
sim time next is 1129800.0000, 
raw observation next is [19.11666666666667, 74.0, 1.0, 2.0, 0.2744336167775533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 353062.1117907489, 353062.1117907489, 112469.4740786382], 
processed observation next is [1.0, 0.043478260869565216, 0.2635802469135804, 0.74, 1.0, 1.0, 0.1362304961637539, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1260936113538389, 0.1260936113538389, 0.2162874501512273], 
reward next is 0.7837, 
noisyNet noise sample is [array([1.131397], dtype=float32), 0.28870407]. 
=============================================
[2019-03-22 23:40:44,605] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.2425387e-32 1.0000000e+00 2.0980317e-33 4.6305066e-13 1.9986813e-34], sum to 1.0000
[2019-03-22 23:40:44,615] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3887
[2019-03-22 23:40:44,619] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 74.0, 1.0, 2.0, 0.2755964242440173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 354409.694170025, 354409.694170025, 112608.9588846406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1128000.0000, 
sim time next is 1128600.0000, 
raw observation next is [19.15, 74.0, 1.0, 2.0, 0.2753715009133436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 354170.1565556722, 354170.1565556718, 112581.8279203153], 
processed observation next is [1.0, 0.043478260869565216, 0.2648148148148148, 0.74, 1.0, 1.0, 0.13734702489683764, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12648934162702577, 0.12648934162702566, 0.2165035152313756], 
reward next is 0.7835, 
noisyNet noise sample is [array([-0.11719304], dtype=float32), 0.57025695]. 
=============================================
[2019-03-22 23:40:47,639] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3622368e-37 1.0000000e+00 1.8940511e-37 7.8209335e-24 2.3184531e-38], sum to 1.0000
[2019-03-22 23:40:47,649] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0498
[2019-03-22 23:40:47,653] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.93333333333333, 83.66666666666667, 1.0, 2.0, 0.3451484799911345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 435069.7337082005, 435069.7337082, 121292.3125538586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1195800.0000, 
sim time next is 1196400.0000, 
raw observation next is [19.86666666666667, 84.33333333333334, 1.0, 2.0, 0.3453382961650551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 435226.7341702257, 435226.7341702253, 121316.216029151], 
processed observation next is [1.0, 0.8695652173913043, 0.2913580246913582, 0.8433333333333334, 1.0, 1.0, 0.22064082876792276, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15543811934650917, 0.15543811934650903, 0.23330041544067498], 
reward next is 0.7667, 
noisyNet noise sample is [array([-1.4970186], dtype=float32), -0.03739919]. 
=============================================
[2019-03-22 23:40:57,156] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.6348535e-31 1.3286000e-16 0.0000000e+00 1.0000000e+00 4.5940299e-37], sum to 1.0000
[2019-03-22 23:40:57,166] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1694
[2019-03-22 23:40:57,173] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.93333333333333, 29.33333333333334, 1.0, 2.0, 0.5192871062112996, 1.0, 2.0, 0.5192871062112996, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1275589.947736459, 1275589.947736459, 245005.8126965882], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1354800.0000, 
sim time next is 1355400.0000, 
raw observation next is [30.95, 29.0, 1.0, 2.0, 0.495717556349166, 1.0, 2.0, 0.495717556349166, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1220167.269304553, 1220167.269304553, 237545.4352926601], 
processed observation next is [1.0, 0.6956521739130435, 0.7018518518518518, 0.29, 1.0, 1.0, 0.39966375755853095, 1.0, 1.0, 0.39966375755853095, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4357740247516261, 0.4357740247516261, 0.45681814479357713], 
reward next is 0.5432, 
noisyNet noise sample is [array([-0.72232944], dtype=float32), -1.0008892]. 
=============================================
[2019-03-22 23:41:01,494] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-22 23:41:01,495] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:41:01,496] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:41:01,497] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:41:01,499] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:41:01,499] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:41:01,500] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:41:01,502] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:41:01,503] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:41:01,504] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:41:01,506] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:41:01,520] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run11
[2019-03-22 23:41:01,520] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run11
[2019-03-22 23:41:01,520] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run11
[2019-03-22 23:41:01,571] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run11
[2019-03-22 23:41:01,572] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run11
[2019-03-22 23:41:04,385] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37360176], dtype=float32), 0.11501284]
[2019-03-22 23:41:04,387] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [36.67072336666667, 20.12745002, 1.0, 2.0, 0.3270827787503067, 1.0, 1.0, 0.3270827787503067, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 795320.2950829077, 795320.2950829081, 189138.6627440353]
[2019-03-22 23:41:04,387] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:41:04,390] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.6488964e-35 1.0359392e-06 0.0000000e+00 9.9999893e-01 2.3892967e-34], sampled 0.5192165447649753
[2019-03-22 23:41:23,624] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.37360176], dtype=float32), 0.11501284]
[2019-03-22 23:41:23,624] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.0, 35.0, 1.0, 2.0, 0.3350743002252007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 421409.1797633227, 421409.1797633222, 119963.5560807275]
[2019-03-22 23:41:23,626] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:41:23,629] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.92783512e-37 9.99998569e-01 0.00000000e+00 1.47842763e-06
 1.16975176e-35], sampled 0.2557632342035615
[2019-03-22 23:41:28,367] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37360176], dtype=float32), 0.11501284]
[2019-03-22 23:41:28,368] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.25596505333333, 76.74068258, 1.0, 2.0, 0.3512892361079786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 440992.8869535611, 440992.8869535611, 122077.5763619248]
[2019-03-22 23:41:28,369] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:41:28,373] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.2518357e-35 1.0000000e+00 0.0000000e+00 9.0905206e-10 4.3227009e-34], sampled 0.8439103707133666
[2019-03-22 23:41:48,778] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37360176], dtype=float32), 0.11501284]
[2019-03-22 23:41:48,780] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.80137836, 90.65265356, 1.0, 2.0, 0.4232384239056237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 521555.732729984, 521555.732729984, 131873.4361228947]
[2019-03-22 23:41:48,781] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:41:48,786] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.8817552e-17 0.0000000e+00], sampled 0.8479260748258767
[2019-03-22 23:41:56,518] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37360176], dtype=float32), 0.11501284]
[2019-03-22 23:41:56,519] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.01666666666667, 52.66666666666667, 1.0, 2.0, 0.3498101940734654, 1.0, 2.0, 0.3498101940734654, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 797369.1023711537, 797369.1023711541, 192844.1895149994]
[2019-03-22 23:41:56,520] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:41:56,521] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.000000e+00 7.974901e-12 0.000000e+00 1.000000e+00 0.000000e+00], sampled 0.042409162365554476
[2019-03-22 23:42:11,184] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37360176], dtype=float32), 0.11501284]
[2019-03-22 23:42:11,186] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.09048795166667, 85.93670307333332, 1.0, 2.0, 0.5135569380187004, 1.0, 2.0, 0.5135569380187004, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1170904.093082704, 1170904.093082704, 239609.0855641287]
[2019-03-22 23:42:11,187] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:42:11,190] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.5229839e-33 1.3917808e-02 0.0000000e+00 9.8608220e-01 1.3667258e-33], sampled 0.22823109778923378
[2019-03-22 23:42:37,324] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37360176], dtype=float32), 0.11501284]
[2019-03-22 23:42:37,326] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.55, 63.0, 1.0, 2.0, 0.4833872037325196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580247.2279717482, 580247.2279717482, 140442.0014852065]
[2019-03-22 23:42:37,328] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:42:37,331] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.12927484e-35 1.00000000e+00 0.00000000e+00 2.06775708e-09
 1.32811591e-35], sampled 0.0005950928781625064
[2019-03-22 23:42:39,009] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.37360176], dtype=float32), 0.11501284]
[2019-03-22 23:42:39,011] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.7, 95.0, 1.0, 2.0, 0.2658592170861518, 1.0, 2.0, 0.2658592170861518, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 621587.7020541659, 621587.7020541664, 173231.7074044773]
[2019-03-22 23:42:39,013] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:42:39,016] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.6196976e-33 6.7897062e-03 0.0000000e+00 9.9321026e-01 1.7616668e-32], sampled 0.6981326964023971
[2019-03-22 23:42:53,615] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8382.5495 2463476086.6657 220.0000
[2019-03-22 23:42:53,815] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8843.3730 2233796470.7409 187.0000
[2019-03-22 23:42:53,830] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8880.6404 2210142003.6094 182.0000
[2019-03-22 23:42:53,893] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8953.4079 2177407849.3633 165.0000
[2019-03-22 23:42:53,977] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8774.6813 2269994657.2350 153.0000
[2019-03-22 23:42:54,993] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 250000, evaluation results [250000.0, 8382.54945126868, 2463476086.6656885, 220.0, 8880.640404943542, 2210142003.6093507, 182.0, 8953.40788786919, 2177407849.363342, 165.0, 8774.681255096357, 2269994657.235036, 153.0, 8843.373041429895, 2233796470.740854, 187.0]
[2019-03-22 23:43:00,647] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0497723e-36 1.0000000e+00 1.7369936e-35 5.8858528e-13 2.5810929e-35], sum to 1.0000
[2019-03-22 23:43:00,656] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3123
[2019-03-22 23:43:00,661] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.85, 24.5, 1.0, 2.0, 0.4105297618612624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 504312.722909889, 504312.722909889, 130006.3562935641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1515000.0000, 
sim time next is 1515600.0000, 
raw observation next is [35.0, 24.0, 1.0, 2.0, 0.4112055431347459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505403.7672326127, 505403.7672326127, 130109.4829956549], 
processed observation next is [0.0, 0.5652173913043478, 0.8518518518518519, 0.24, 1.0, 1.0, 0.2990542180175546, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1805013454402188, 0.1805013454402188, 0.25021054422241323], 
reward next is 0.7498, 
noisyNet noise sample is [array([0.7428105], dtype=float32), -1.4395666]. 
=============================================
[2019-03-22 23:43:00,855] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1892224e-30 1.0000000e+00 8.0407470e-38 2.0184921e-11 2.6156969e-34], sum to 1.0000
[2019-03-22 23:43:00,865] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1608
[2019-03-22 23:43:00,870] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.85, 24.5, 1.0, 2.0, 0.4105297618612624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 504312.722909889, 504312.722909889, 130006.3562935641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1515000.0000, 
sim time next is 1515600.0000, 
raw observation next is [35.0, 24.0, 1.0, 2.0, 0.4112055431347459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505403.7672326127, 505403.7672326127, 130109.4829956549], 
processed observation next is [0.0, 0.5652173913043478, 0.8518518518518519, 0.24, 1.0, 1.0, 0.2990542180175546, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1805013454402188, 0.1805013454402188, 0.25021054422241323], 
reward next is 0.7498, 
noisyNet noise sample is [array([-0.38788593], dtype=float32), 0.13710557]. 
=============================================
[2019-03-22 23:43:01,436] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4303280e-35 1.0000000e+00 0.0000000e+00 1.7075131e-15 3.4956357e-36], sum to 1.0000
[2019-03-22 23:43:01,441] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3586
[2019-03-22 23:43:01,448] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.2, 44.5, 1.0, 2.0, 0.569288338865246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 665300.2775014894, 665300.2775014889, 153648.2543167291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1530600.0000, 
sim time next is 1531200.0000, 
raw observation next is [31.7, 46.0, 1.0, 2.0, 0.550493483415627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 644487.091841032, 644487.091841032, 150567.7213753938], 
processed observation next is [0.0, 0.7391304347826086, 0.7296296296296296, 0.46, 1.0, 1.0, 0.46487319454241305, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23017396137179716, 0.23017396137179716, 0.28955331033729576], 
reward next is 0.7104, 
noisyNet noise sample is [array([0.2277176], dtype=float32), 1.164703]. 
=============================================
[2019-03-22 23:43:02,607] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1972091e-33 1.0000000e+00 2.8567044e-35 2.2137506e-17 5.3888254e-35], sum to 1.0000
[2019-03-22 23:43:02,624] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0399
[2019-03-22 23:43:02,629] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 66.0, 1.0, 2.0, 0.3924247107007521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489523.1114988203, 489523.1114988203, 127625.5113308267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1552800.0000, 
sim time next is 1553400.0000, 
raw observation next is [23.2, 66.5, 1.0, 2.0, 0.3907700522048922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 487579.9581589521, 487579.9581589521, 127396.8807257692], 
processed observation next is [0.0, 1.0, 0.4148148148148148, 0.665, 1.0, 1.0, 0.27472625262487166, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1741356993424829, 0.1741356993424829, 0.24499400139570998], 
reward next is 0.7550, 
noisyNet noise sample is [array([1.9259369], dtype=float32), 0.026134131]. 
=============================================
[2019-03-22 23:43:25,859] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4864969e-32 1.3232173e-25 0.0000000e+00 1.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-22 23:43:25,869] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0968
[2019-03-22 23:43:25,873] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.3, 60.0, 1.0, 2.0, 0.6395768170715964, 1.0, 2.0, 0.6395768170715964, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1468630.788324469, 1468630.788324469, 282429.8087033341], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1958400.0000, 
sim time next is 1959000.0000, 
raw observation next is [28.4, 59.66666666666666, 1.0, 2.0, 0.6135721687978049, 1.0, 2.0, 0.6135721687978049, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1409300.582680891, 1409300.582680891, 273243.8880692305], 
processed observation next is [1.0, 0.6956521739130435, 0.6074074074074074, 0.5966666666666666, 1.0, 1.0, 0.5399668676164343, 1.0, 1.0, 0.5399668676164343, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5033216366717468, 0.5033216366717468, 0.5254690155177509], 
reward next is 0.4745, 
noisyNet noise sample is [array([-1.1356138], dtype=float32), -1.6032656]. 
=============================================
[2019-03-22 23:43:25,886] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[54.26981 ]
 [53.483387]
 [53.27365 ]
 [52.7561  ]
 [52.298954]], R is [[54.4503479 ]
 [54.36271286]
 [54.25285339]
 [54.14657974]
 [54.04108429]].
[2019-03-22 23:43:30,558] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.2506476e-22 0.0000000e+00], sum to 1.0000
[2019-03-22 23:43:30,565] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4281
[2019-03-22 23:43:30,571] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.65, 64.0, 1.0, 2.0, 0.5293240005611272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 622437.6532588879, 622437.6532588875, 147228.900813311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2035800.0000, 
sim time next is 2036400.0000, 
raw observation next is [27.8, 63.66666666666667, 1.0, 2.0, 0.533749635227806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 626644.3342059597, 626644.3342059592, 147904.0501298031], 
processed observation next is [0.0, 0.5652173913043478, 0.5851851851851853, 0.6366666666666667, 1.0, 1.0, 0.44494004193786435, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2238015479306999, 0.22380154793069973, 0.28443086563423675], 
reward next is 0.7156, 
noisyNet noise sample is [array([-0.97622615], dtype=float32), 0.24980383]. 
=============================================
[2019-03-22 23:43:31,732] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9496901e-36 1.0000000e+00 1.5716136e-37 1.6629684e-11 1.2140345e-33], sum to 1.0000
[2019-03-22 23:43:31,739] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4320
[2019-03-22 23:43:31,746] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 71.0, 1.0, 2.0, 0.6056599829213591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695836.7960836872, 695836.7960836872, 159329.164863532], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2055600.0000, 
sim time next is 2056200.0000, 
raw observation next is [27.48333333333333, 71.66666666666667, 1.0, 2.0, 0.6054629135036604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695725.1395598896, 695725.1395598896, 159300.5369897904], 
processed observation next is [0.0, 0.8260869565217391, 0.5734567901234567, 0.7166666666666667, 1.0, 1.0, 0.5303129922662624, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.248473264128532, 0.248473264128532, 0.30634718651882764], 
reward next is 0.6937, 
noisyNet noise sample is [array([-1.0208043], dtype=float32), -0.14225402]. 
=============================================
[2019-03-22 23:43:49,693] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-22 23:43:49,694] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:43:49,696] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:43:49,696] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:43:49,697] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:43:49,698] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:43:49,700] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:43:49,697] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:43:49,701] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:43:49,705] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:43:49,706] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:43:49,719] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run12
[2019-03-22 23:43:49,737] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run12
[2019-03-22 23:43:49,738] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run12
[2019-03-22 23:43:49,738] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run12
[2019-03-22 23:43:49,775] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run12
[2019-03-22 23:44:04,388] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.40835056], dtype=float32), 0.124407135]
[2019-03-22 23:44:04,389] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.4, 58.0, 1.0, 2.0, 0.5572226014139381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 704395.8673465628, 704395.8673465628, 153211.1970817576]
[2019-03-22 23:44:04,390] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:44:04,393] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7259180e-34 1.0000000e+00 1.1046864e-34 1.3601232e-15 1.6064144e-34], sampled 0.8260758849152385
[2019-03-22 23:44:12,052] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.40835056], dtype=float32), 0.124407135]
[2019-03-22 23:44:12,057] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.0, 43.0, 1.0, 2.0, 0.3212199562205705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 407801.9546615694, 407801.954661569, 118226.7206014312]
[2019-03-22 23:44:12,058] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:44:12,060] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.3072790e-38 3.2434003e-19 5.9739629e-38], sampled 0.41401178318821585
[2019-03-22 23:44:18,556] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.40835056], dtype=float32), 0.124407135]
[2019-03-22 23:44:18,557] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.58586645333333, 55.183952435, 1.0, 2.0, 0.6417203851027921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 786555.2677477662, 786555.2677477662, 167641.7495291572]
[2019-03-22 23:44:18,559] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:44:18,561] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.45387414e-32 1.00000000e+00 1.44911215e-33 7.74750120e-16
 3.79592817e-34], sampled 0.17011551446616646
[2019-03-22 23:44:24,689] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.40835056], dtype=float32), 0.124407135]
[2019-03-22 23:44:24,690] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.1, 63.33333333333334, 1.0, 2.0, 0.3573889652369676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 448982.3204113223, 448982.3204113219, 122893.9134373079]
[2019-03-22 23:44:24,691] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:44:24,694] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.0171714e-36 1.0000000e+00 5.5940884e-37 1.7842617e-18 4.7536219e-37], sampled 0.2422183217338053
[2019-03-22 23:44:30,062] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.40835056], dtype=float32), 0.124407135]
[2019-03-22 23:44:30,063] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.500083, 84.7656792, 1.0, 2.0, 0.3869505163851091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482066.0675867597, 482066.0675867597, 126850.4582009228]
[2019-03-22 23:44:30,064] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:44:30,066] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.7038368e-32 1.0000000e+00 1.2360068e-33 2.8774993e-10 3.0300180e-33], sampled 0.11978263507430476
[2019-03-22 23:44:35,628] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.40835056], dtype=float32), 0.124407135]
[2019-03-22 23:44:35,632] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.0, 88.5, 1.0, 2.0, 0.511391948822418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 610313.7406566628, 610313.7406566628, 144709.9300968849]
[2019-03-22 23:44:35,635] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:44:35,636] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.5883215e-34 1.0000000e+00 5.6556948e-36 1.0906251e-13 6.2671441e-35], sampled 0.5841380045397727
[2019-03-22 23:44:42,989] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.40835056], dtype=float32), 0.124407135]
[2019-03-22 23:44:42,991] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.57628691166667, 95.13406795, 1.0, 2.0, 0.7708127908207707, 1.0, 2.0, 0.7708127908207707, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260421465616, 1758088.915862387, 1758088.915862386, 331841.7312316707]
[2019-03-22 23:44:42,992] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:44:42,996] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0. 0. 0. 1. 0.], sampled 0.026100269448171787
[2019-03-22 23:44:43,543] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.40835056], dtype=float32), 0.124407135]
[2019-03-22 23:44:43,545] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.89246234, 92.54792849, 1.0, 2.0, 0.9062865163797462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 1033832.060277103, 1033832.060277102, 218915.6398788229]
[2019-03-22 23:44:43,546] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:44:43,550] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.9824039e-26 9.9983704e-01 1.8581846e-29 1.6290204e-04 2.7540449e-29], sampled 0.9381831587039089
[2019-03-22 23:44:54,267] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.40835056], dtype=float32), 0.124407135]
[2019-03-22 23:44:54,269] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.31666666666667, 81.0, 1.0, 2.0, 0.5552302971663778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 647182.398947488, 647182.398947488, 151227.8298933918]
[2019-03-22 23:44:54,272] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:44:54,277] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.7140605e-33 1.0000000e+00 9.6993402e-35 8.7994678e-13 1.9716167e-34], sampled 0.9082154405319687
[2019-03-22 23:45:41,088] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8912.4072 2162076824.9266 300.0000
[2019-03-22 23:45:41,594] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 9015.7110 2116045999.0616 299.0000
[2019-03-22 23:45:41,705] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8353.3410 2421817657.1878 414.0000
[2019-03-22 23:45:41,883] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8844.4152 2185036919.1411 359.0000
[2019-03-22 23:45:41,884] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8767.6955 2228215946.1035 311.0000
[2019-03-22 23:45:42,897] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 275000, evaluation results [275000.0, 8353.340979177075, 2421817657.1878424, 414.0, 8912.407168105345, 2162076824.926587, 300.0, 9015.711000136205, 2116045999.0616422, 299.0, 8767.69548610562, 2228215946.1034627, 311.0, 8844.415199310673, 2185036919.141122, 359.0]
[2019-03-22 23:45:43,435] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3114132e-32 1.6291978e-13 3.7221796e-35 1.0000000e+00 1.2447252e-36], sum to 1.0000
[2019-03-22 23:45:43,443] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9465
[2019-03-22 23:45:43,451] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 41.0, 1.0, 2.0, 0.3969196178916281, 1.0, 2.0, 0.3969196178916281, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 978447.7597401028, 978447.7597401019, 208164.6676227169], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2365200.0000, 
sim time next is 2365800.0000, 
raw observation next is [28.11666666666667, 40.83333333333334, 1.0, 2.0, 0.4278742181384738, 1.0, 2.0, 0.4278742181384738, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1052717.621565977, 1052717.621565977, 216959.5380148367], 
processed observation next is [1.0, 0.391304347826087, 0.5969135802469138, 0.40833333333333344, 1.0, 1.0, 0.31889787873627834, 1.0, 1.0, 0.31889787873627834, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3759705791307061, 0.3759705791307061, 0.41722988079776285], 
reward next is 0.5828, 
noisyNet noise sample is [array([-0.51057804], dtype=float32), -0.48213834]. 
=============================================
[2019-03-22 23:45:49,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.1832922e-38 0.0000000e+00], sum to 1.0000
[2019-03-22 23:45:49,915] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1723
[2019-03-22 23:45:49,922] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.31666666666667, 31.66666666666667, 1.0, 2.0, 0.3588368611479057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 449772.2523939685, 449772.2523939681, 123071.489465042], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2490600.0000, 
sim time next is 2491200.0000, 
raw observation next is [30.1, 32.0, 1.0, 2.0, 0.3560914504609924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446806.6616443675, 446806.6616443675, 122712.3802333334], 
processed observation next is [1.0, 0.8695652173913043, 0.6703703703703704, 0.32, 1.0, 1.0, 0.23344220292975285, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15957380773013125, 0.15957380773013125, 0.23598534660256423], 
reward next is 0.7640, 
noisyNet noise sample is [array([-0.31509396], dtype=float32), -1.0152501]. 
=============================================
[2019-03-22 23:45:54,754] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6500868e-36 1.0000000e+00 1.4172557e-34 4.7926392e-38 3.4969043e-35], sum to 1.0000
[2019-03-22 23:45:54,763] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7752
[2019-03-22 23:45:54,774] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1760592.456073818 W.
[2019-03-22 23:45:54,781] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.7, 30.0, 1.0, 2.0, 0.8774883125055644, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9646175778080157, 6.9112, 6.9112, 121.9260426156618, 1760592.456073818, 1760592.456073818, 345461.7700661579], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2555400.0000, 
sim time next is 2556000.0000, 
raw observation next is [33.8, 30.0, 1.0, 2.0, 0.5067287699301963, 1.0, 1.0, 0.5067287699301963, 1.0, 2.0, 0.8090961047500829, 6.9112, 6.9112, 121.94756008, 1772827.747624072, 1772827.747624072, 347020.9779298937], 
processed observation next is [1.0, 0.6086956521739131, 0.8074074074074074, 0.3, 1.0, 1.0, 0.4127723451549956, 1.0, 0.5, 0.4127723451549956, 1.0, 1.0, 0.7613701309376036, 0.0, 0.0, 0.8096049824067558, 0.6331527670085971, 0.6331527670085971, 0.6673480344805648], 
reward next is 0.3327, 
noisyNet noise sample is [array([-0.24488418], dtype=float32), -0.75372434]. 
=============================================
[2019-03-22 23:45:54,792] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[40.112915]
 [39.853333]
 [40.34658 ]
 [40.32414 ]
 [40.925568]], R is [[39.70123672]
 [39.63987732]
 [39.58912659]
 [39.60177231]
 [39.20575333]].
[2019-03-22 23:45:59,465] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:45:59,476] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3294
[2019-03-22 23:45:59,480] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.55, 80.0, 1.0, 2.0, 0.5797547851444929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 674328.236541025, 674328.2365410255, 155276.5833222739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2662200.0000, 
sim time next is 2662800.0000, 
raw observation next is [25.4, 80.66666666666667, 1.0, 2.0, 0.576911804542468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 671703.699719032, 671703.6997190316, 154825.2118504687], 
processed observation next is [0.0, 0.8260869565217391, 0.49629629629629624, 0.8066666666666668, 1.0, 1.0, 0.4963235768362715, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23989417847108288, 0.23989417847108271, 0.29774079202013215], 
reward next is 0.7023, 
noisyNet noise sample is [array([-0.46754074], dtype=float32), -1.8415769]. 
=============================================
[2019-03-22 23:46:01,846] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:46:01,854] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5818
[2019-03-22 23:46:01,860] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 94.16666666666666, 1.0, 2.0, 0.4717347610908037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571850.9361365397, 571850.9361365397, 138838.6368055314], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2695800.0000, 
sim time next is 2696400.0000, 
raw observation next is [21.2, 93.0, 1.0, 2.0, 0.4591232413775544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 559069.157127115, 559069.157127115, 137001.5699384149], 
processed observation next is [0.0, 0.21739130434782608, 0.34074074074074073, 0.93, 1.0, 1.0, 0.356099096878041, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19966755611682677, 0.19966755611682677, 0.2634645575738748], 
reward next is 0.7365, 
noisyNet noise sample is [array([0.57089114], dtype=float32), -0.80989134]. 
=============================================
[2019-03-22 23:46:08,253] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:46:08,263] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2159
[2019-03-22 23:46:08,266] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.08333333333334, 79.83333333333334, 1.0, 2.0, 0.9510366203752069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1084115.085294425, 1084115.085294425, 229117.7701943414], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2794200.0000, 
sim time next is 2794800.0000, 
raw observation next is [27.26666666666667, 79.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 11.01698959055815, 6.9112, 121.9041889931103, 3266357.312675195, 1164202.921779141, 245584.7393572843], 
processed observation next is [1.0, 0.34782608695652173, 0.5654320987654322, 0.7966666666666667, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.41057895905581504, 0.0, 0.8093170434925596, 1.1665561830982838, 0.4157867577782647, 0.4722783449178544], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0501446], dtype=float32), 0.60973674]. 
=============================================
[2019-03-22 23:46:20,079] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:46:20,086] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5278
[2019-03-22 23:46:20,092] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1683123.450093 W.
[2019-03-22 23:46:20,097] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.6, 81.0, 1.0, 2.0, 0.7379760250560151, 1.0, 1.0, 0.7379760250560151, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1683123.450093, 1683123.450093, 318791.9912517056], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2989800.0000, 
sim time next is 2990400.0000, 
raw observation next is [26.73333333333333, 85.33333333333333, 1.0, 2.0, 0.8222318374957761, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1652315.532368609, 1652315.532368609, 340693.228278955], 
processed observation next is [1.0, 0.6086956521739131, 0.545679012345679, 0.8533333333333333, 1.0, 1.0, 0.7883712351140192, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.590112690131646, 0.590112690131646, 0.6551792851518365], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.33027175], dtype=float32), -0.33301213]. 
=============================================
[2019-03-22 23:46:23,427] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4740117e-25 1.0000000e+00 6.1449952e-33 3.4094051e-26 6.5647113e-33], sum to 1.0000
[2019-03-22 23:46:23,435] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5963
[2019-03-22 23:46:23,448] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2745667.077049398 W.
[2019-03-22 23:46:23,456] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 76.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.7273716944345, 6.9112, 121.922354758273, 2745667.077049398, 2327726.862584882, 443049.4788131016], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3063600.0000, 
sim time next is 3064200.0000, 
raw observation next is [30.16666666666666, 76.5, 1.0, 2.0, 0.6533107865882971, 1.0, 2.0, 0.6400200552705834, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2190189.140017142, 2190189.140017141, 416929.5259277736], 
processed observation next is [1.0, 0.4782608695652174, 0.6728395061728393, 0.765, 1.0, 1.0, 0.587274745938449, 1.0, 1.0, 0.5714524467506945, 1.0, 0.5, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7822104071489793, 0.7822104071489789, 0.8017875498611031], 
reward next is 0.1982, 
noisyNet noise sample is [array([-2.463908], dtype=float32), 0.6537991]. 
=============================================
[2019-03-22 23:46:27,378] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:46:27,387] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8302
[2019-03-22 23:46:27,391] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.93333333333334, 56.33333333333334, 1.0, 2.0, 0.7014058117158612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 841758.430332202, 841758.430332202, 178306.5183256296], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3136800.0000, 
sim time next is 3137400.0000, 
raw observation next is [28.4, 55.5, 1.0, 2.0, 0.7468515934358746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 892059.2560711806, 892059.2560711806, 187091.6585365566], 
processed observation next is [1.0, 0.30434782608695654, 0.6074074074074074, 0.555, 1.0, 1.0, 0.6986328493284222, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31859259145399305, 0.31859259145399305, 0.35979165103183963], 
reward next is 0.6402, 
noisyNet noise sample is [array([-1.1476232], dtype=float32), -1.2318714]. 
=============================================
[2019-03-22 23:46:34,020] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:46:34,030] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9934
[2019-03-22 23:46:34,034] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.53333333333333, 60.0, 1.0, 2.0, 0.4617443999327661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 559862.2019736118, 559862.2019736118, 137324.8504490312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3226800.0000, 
sim time next is 3227400.0000, 
raw observation next is [26.65, 60.5, 1.0, 2.0, 0.4686326684413961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 566450.8974415314, 566450.8974415314, 138313.6200174906], 
processed observation next is [0.0, 0.34782608695652173, 0.5425925925925925, 0.605, 1.0, 1.0, 0.36741984338261446, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2023038919434041, 0.2023038919434041, 0.2659877308028666], 
reward next is 0.7340, 
noisyNet noise sample is [array([0.3991158], dtype=float32), -0.9334344]. 
=============================================
[2019-03-22 23:46:37,523] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-22 23:46:37,525] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:46:37,526] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:46:37,526] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:46:37,527] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:46:37,528] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:46:37,529] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:46:37,529] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:46:37,530] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:46:37,529] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:46:37,532] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:46:37,548] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run13
[2019-03-22 23:46:37,565] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run13
[2019-03-22 23:46:37,566] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run13
[2019-03-22 23:46:37,567] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run13
[2019-03-22 23:46:37,623] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run13
[2019-03-22 23:46:48,233] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:46:48,237] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.16666666666667, 38.0, 1.0, 2.0, 0.3033982746942798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 388179.3216157662, 388179.3216157662, 115997.8619762557]
[2019-03-22 23:46:48,239] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:46:48,242] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.1537868177713303
[2019-03-22 23:46:52,576] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:46:52,581] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.33333333333334, 47.33333333333333, 1.0, 2.0, 0.2630392189351145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 339301.6817539089, 339301.6817539089, 103123.0365386632]
[2019-03-22 23:46:52,581] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:46:52,584] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5641135142450503
[2019-03-22 23:47:09,586] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:47:09,587] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.58333333333334, 32.83333333333334, 1.0, 2.0, 0.9566768104272126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.202153271477635, 6.9112, 121.9246511814457, 1299720.758489262, 1150728.378722215, 233397.6500237333]
[2019-03-22 23:47:09,589] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:47:09,591] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.361032369092285
[2019-03-22 23:47:09,594] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1299720.758489262 W.
[2019-03-22 23:47:12,739] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:47:12,739] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.544263595, 79.386728835, 1.0, 2.0, 0.2900254364218296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 369915.8833477332, 369915.8833477332, 114351.8282279932]
[2019-03-22 23:47:12,740] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:47:12,742] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5645021934227809
[2019-03-22 23:47:17,612] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:47:17,614] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.15549496666667, 93.49634345833334, 1.0, 2.0, 0.6716388925922891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 773560.246337154, 773560.246337154, 171245.46628991]
[2019-03-22 23:47:17,614] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:47:17,616] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.19469936434447332
[2019-03-22 23:47:32,192] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:47:32,193] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.66666666666667, 80.66666666666667, 1.0, 2.0, 0.8156234447714489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 929659.9191698672, 929659.9191698672, 199199.7209491604]
[2019-03-22 23:47:32,194] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:47:32,196] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.949615133152221
[2019-03-22 23:47:47,081] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:47:47,082] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.5, 66.66666666666666, 1.0, 2.0, 0.473218302407576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571636.4529930253, 571636.4529930253, 139001.3443079571]
[2019-03-22 23:47:47,083] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:47:47,086] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4092978419410358
[2019-03-22 23:47:48,483] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:47:48,483] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.08333333333334, 72.16666666666666, 1.0, 2.0, 0.4441126416193137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 540994.2899438395, 540994.28994384, 134764.2673243574]
[2019-03-22 23:47:48,483] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:47:48,487] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4310726220802762
[2019-03-22 23:47:51,694] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:47:51,695] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.91242125, 83.64071326999999, 1.0, 2.0, 0.555985020741818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 649433.4009135361, 649433.4009135365, 151413.0826524293]
[2019-03-22 23:47:51,695] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:47:51,697] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.04508034346529477
[2019-03-22 23:48:00,406] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:48:00,407] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.33333333333334, 91.33333333333334, 1.0, 2.0, 0.7161785470565237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 873590.1380051618, 873590.1380051618, 181661.4939122151]
[2019-03-22 23:48:00,407] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:48:00,409] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5004925104778009
[2019-03-22 23:48:13,270] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:48:13,271] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.33867629833334, 56.85377869166667, 1.0, 2.0, 0.3422889739065156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 430267.5960033878, 430267.5960033878, 120901.0006482615]
[2019-03-22 23:48:13,273] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:48:13,275] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8034166300803423
[2019-03-22 23:48:13,640] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:48:13,641] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.3, 76.0, 1.0, 2.0, 0.429349138884714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524915.4031054376, 524915.4031054376, 132651.3389074999]
[2019-03-22 23:48:13,643] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:48:13,646] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7649910098309334
[2019-03-22 23:48:17,922] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:48:17,922] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.08333333333334, 78.83333333333334, 1.0, 2.0, 0.3635720057266462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455387.9376790206, 455387.9376790206, 123701.958707535]
[2019-03-22 23:48:17,924] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:48:17,927] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8888199911335581
[2019-03-22 23:48:25,132] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:48:25,133] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.75, 59.0, 1.0, 2.0, 0.3558525021125046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 459059.9778118836, 459059.9778118836, 108334.583309957]
[2019-03-22 23:48:25,134] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:48:25,139] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.05743819137180195
[2019-03-22 23:48:28,451] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2619 2170662485.7283 493.0000
[2019-03-22 23:48:28,939] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.0583 2248755290.3993 553.0000
[2019-03-22 23:48:28,988] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.6001 2445376094.7952 746.0000
[2019-03-22 23:48:29,190] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.1818 2120456093.0328 430.0000
[2019-03-22 23:48:29,203] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.5254 2195133212.2000 572.0000
[2019-03-22 23:48:30,221] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 300000, evaluation results [300000.0, 8100.600059888084, 2445376094.795151, 746.0, 8770.261897406637, 2170662485.728274, 493.0, 8924.181835947267, 2120456093.0327566, 430.0, 8582.058316992165, 2248755290.399296, 553.0, 8701.52538790598, 2195133212.199995, 572.0]
[2019-03-22 23:48:35,290] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5910042e-33 0.0000000e+00], sum to 1.0000
[2019-03-22 23:48:35,298] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8282
[2019-03-22 23:48:35,302] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.18333333333333, 92.66666666666667, 1.0, 2.0, 0.6133088373476403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706990.7820918395, 706990.7820918395, 160774.188148523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3373800.0000, 
sim time next is 3374400.0000, 
raw observation next is [24.06666666666667, 92.33333333333334, 1.0, 2.0, 0.6018959295530594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696230.9142193808, 696230.9142193808, 158900.7036423538], 
processed observation next is [1.0, 0.043478260869565216, 0.4469135802469137, 0.9233333333333335, 1.0, 1.0, 0.5260665828012612, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24865389793549314, 0.24865389793549314, 0.30557827623529576], 
reward next is 0.6944, 
noisyNet noise sample is [array([0.21794878], dtype=float32), 0.428748]. 
=============================================
[2019-03-22 23:48:39,827] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.5076192e-35 1.0000000e+00 2.4232040e-36 7.2420414e-32 1.4804001e-35], sum to 1.0000
[2019-03-22 23:48:39,836] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8979
[2019-03-22 23:48:39,840] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 89.5, 1.0, 2.0, 0.6470360822556298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737409.0582130648, 737409.0582130648, 166357.5927797963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3454200.0000, 
sim time next is 3454800.0000, 
raw observation next is [25.16666666666666, 91.0, 1.0, 2.0, 0.6501290516280577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 740935.7331465431, 740935.7331465427, 166916.0643188509], 
processed observation next is [1.0, 1.0, 0.4876543209876541, 0.91, 1.0, 1.0, 0.5834869662238782, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.264619904695194, 0.2646199046951938, 0.3209924313824056], 
reward next is 0.6790, 
noisyNet noise sample is [array([0.00819715], dtype=float32), 0.5875608]. 
=============================================
[2019-03-22 23:48:42,707] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0203157e-28 1.0000000e+00 8.5075525e-35 2.1323480e-25 9.1727055e-30], sum to 1.0000
[2019-03-22 23:48:42,715] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9698
[2019-03-22 23:48:42,724] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1794903.953563946 W.
[2019-03-22 23:48:42,729] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.41666666666666, 80.66666666666667, 1.0, 2.0, 0.7869376974402963, 1.0, 2.0, 0.7869376974402963, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1794903.953563946, 1794903.953563946, 338387.4241440454], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3507000.0000, 
sim time next is 3507600.0000, 
raw observation next is [28.33333333333334, 82.33333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.562697304743433, 6.9112, 121.9239529074501, 2212046.535383204, 1878427.403231154, 381799.1864888588], 
processed observation next is [1.0, 0.6086956521739131, 0.6049382716049385, 0.8233333333333335, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.06514973047434332, 0.0, 0.8094482553307536, 0.7900166197797157, 0.6708669297254122, 0.7342292047862669], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6743243], dtype=float32), 0.30140564]. 
=============================================
[2019-03-22 23:48:46,335] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:48:46,346] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4165
[2019-03-22 23:48:46,351] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.45, 93.5, 1.0, 2.0, 0.5779806286761224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688138.9564953335, 688138.9564953335, 155635.2423156492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3569400.0000, 
sim time next is 3570000.0000, 
raw observation next is [22.26666666666667, 93.33333333333334, 1.0, 2.0, 0.5202340498488792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 621726.2726741177, 621726.2726741172, 146155.4038298317], 
processed observation next is [1.0, 0.30434782608695654, 0.38024691358024704, 0.9333333333333335, 1.0, 1.0, 0.4288500593439038, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22204509738361347, 0.2220450973836133, 0.28106808428813784], 
reward next is 0.7189, 
noisyNet noise sample is [array([0.8486159], dtype=float32), -0.6928985]. 
=============================================
[2019-03-22 23:48:46,373] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[62.829666]
 [62.683064]
 [62.58895 ]
 [62.69957 ]
 [62.644104]], R is [[63.32545471]
 [63.39290237]
 [63.45898819]
 [63.51467133]
 [63.58311844]].
[2019-03-22 23:48:48,424] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:48:48,432] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4233
[2019-03-22 23:48:48,438] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 88.0, 1.0, 2.0, 0.5457005767406324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641986.4578980857, 641986.4578980857, 149909.4450543516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3624000.0000, 
sim time next is 3624600.0000, 
raw observation next is [24.0, 85.0, 1.0, 2.0, 0.5352603653976642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 632176.4500010482, 632176.4500010482, 148302.9018014316], 
processed observation next is [1.0, 0.9565217391304348, 0.4444444444444444, 0.85, 1.0, 1.0, 0.4467385302353145, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22577730357180292, 0.22577730357180292, 0.28519788807967617], 
reward next is 0.7148, 
noisyNet noise sample is [array([0.71982443], dtype=float32), -2.3459032]. 
=============================================
[2019-03-22 23:48:54,091] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.18769885e-27
 0.00000000e+00], sum to 1.0000
[2019-03-22 23:48:54,100] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8487
[2019-03-22 23:48:54,105] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333333, 89.16666666666667, 1.0, 2.0, 0.7136999304661727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813424.3079552135, 813424.3079552135, 178757.4554525965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3694200.0000, 
sim time next is 3694800.0000, 
raw observation next is [26.86666666666667, 89.33333333333334, 1.0, 2.0, 0.7178856394877438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818197.4270262625, 818197.4270262625, 179560.9438940632], 
processed observation next is [1.0, 0.782608695652174, 0.5506172839506175, 0.8933333333333334, 1.0, 1.0, 0.6641495708187426, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29221336679509374, 0.29221336679509374, 0.3453095074885831], 
reward next is 0.6547, 
noisyNet noise sample is [array([-2.0626922], dtype=float32), -0.07461649]. 
=============================================
[2019-03-22 23:48:57,204] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.8966717e-36 1.0000000e+00 5.8013947e-38 2.8298715e-27 3.1506242e-33], sum to 1.0000
[2019-03-22 23:48:57,212] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3028
[2019-03-22 23:48:57,218] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1626292.498127237 W.
[2019-03-22 23:48:57,223] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.33333333333334, 94.0, 1.0, 2.0, 0.7994322712529766, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1626292.498127237, 1626292.498127237, 336122.9585953369], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3748800.0000, 
sim time next is 3749400.0000, 
raw observation next is [26.5, 94.0, 1.0, 2.0, 0.8746302202997778, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1712125.021768921, 1712125.021768921, 351545.9980795279], 
processed observation next is [1.0, 0.391304347826087, 0.5370370370370371, 0.94, 1.0, 1.0, 0.8507502622616402, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.611473222060329, 0.611473222060329, 0.6760499963067845], 
reward next is 0.3240, 
noisyNet noise sample is [array([-0.6326358], dtype=float32), -0.6373581]. 
=============================================
[2019-03-22 23:49:05,551] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 4.958676e-38 0.000000e+00], sum to 1.0000
[2019-03-22 23:49:05,561] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5190
[2019-03-22 23:49:05,569] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 94.66666666666666, 1.0, 2.0, 0.7161467662111348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816214.5217972418, 816214.5217972418, 179224.1990219064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3908400.0000, 
sim time next is 3909000.0000, 
raw observation next is [25.85, 94.33333333333334, 1.0, 2.0, 0.72122255099944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 822002.6521444863, 822002.6521444863, 180201.9914481305], 
processed observation next is [0.0, 0.21739130434782608, 0.5129629629629631, 0.9433333333333335, 1.0, 1.0, 0.6681220845231428, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29357237576588796, 0.29357237576588796, 0.3465422912464048], 
reward next is 0.6535, 
noisyNet noise sample is [array([-1.5199486], dtype=float32), -1.7620249]. 
=============================================
[2019-03-22 23:49:05,582] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[66.07444 ]
 [66.097496]
 [66.10339 ]
 [66.09768 ]
 [66.079056]], R is [[66.02039337]
 [66.01552582]
 [66.01232147]
 [66.01055145]
 [66.00994873]].
[2019-03-22 23:49:05,598] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:49:05,609] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0312
[2019-03-22 23:49:05,613] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.7523220758437918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 857467.6995142838, 857467.6995142838, 186289.07030845], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3898800.0000, 
sim time next is 3899400.0000, 
raw observation next is [26.83333333333333, 89.83333333333334, 1.0, 2.0, 0.7320571778248739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 834357.9779134631, 834357.9779134627, 182304.895869205], 
processed observation next is [0.0, 0.13043478260869565, 0.5493827160493825, 0.8983333333333334, 1.0, 1.0, 0.6810204497915165, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2979849921119511, 0.29798499211195095, 0.3505863382100096], 
reward next is 0.6494, 
noisyNet noise sample is [array([0.03974203], dtype=float32), 1.4233412]. 
=============================================
[2019-03-22 23:49:05,883] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 7.435057e-38 0.000000e+00], sum to 1.0000
[2019-03-22 23:49:05,889] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1844
[2019-03-22 23:49:05,900] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.98333333333333, 69.0, 1.0, 2.0, 0.7889111893861713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 899195.0249574006, 899195.0249574002, 193666.3760483042], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3946200.0000, 
sim time next is 3946800.0000, 
raw observation next is [30.96666666666667, 68.0, 1.0, 2.0, 0.7560300405303179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 861696.2705053339, 861696.2705053339, 187028.6312551579], 
processed observation next is [0.0, 0.6956521739130435, 0.7024691358024692, 0.68, 1.0, 1.0, 0.7095595720599022, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30774866803761924, 0.30774866803761924, 0.3596704447214575], 
reward next is 0.6403, 
noisyNet noise sample is [array([-1.6761496], dtype=float32), -3.2845023]. 
=============================================
[2019-03-22 23:49:06,178] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.00000e+00 1.00000e+00 0.00000e+00 8.08628e-36 0.00000e+00], sum to 1.0000
[2019-03-22 23:49:06,186] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4942
[2019-03-22 23:49:06,191] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.771609890515014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 879463.8202674534, 879463.8202674534, 190152.0553008922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3931800.0000, 
sim time next is 3932400.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.7640533583523271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 870846.159454618, 870846.159454618, 188632.9325222276], 
processed observation next is [0.0, 0.5217391304347826, 0.7037037037037037, 0.7, 1.0, 1.0, 0.7191111408956276, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31101648551950645, 0.31101648551950645, 0.36275563946582234], 
reward next is 0.6372, 
noisyNet noise sample is [array([-0.04745125], dtype=float32), 0.4276308]. 
=============================================
[2019-03-22 23:49:08,405] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:49:08,415] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8464
[2019-03-22 23:49:08,420] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 83.33333333333334, 1.0, 2.0, 0.670689513351238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 764379.6577056436, 764379.6577056436, 170666.5187426556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3972000.0000, 
sim time next is 3972600.0000, 
raw observation next is [26.15, 83.5, 1.0, 2.0, 0.6720911132061906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 765977.848371696, 765977.8483716955, 170924.7473890713], 
processed observation next is [0.0, 1.0, 0.524074074074074, 0.835, 1.0, 1.0, 0.6096322776264174, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2735635172756057, 0.2735635172756055, 0.32870143728667556], 
reward next is 0.6713, 
noisyNet noise sample is [array([-0.8422942], dtype=float32), 1.1634495]. 
=============================================
[2019-03-22 23:49:08,429] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:49:08,444] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5702
[2019-03-22 23:49:08,451] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.86666666666667, 69.0, 1.0, 2.0, 0.7825174332047576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 891903.2293104073, 891903.2293104068, 192360.5748182968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3940800.0000, 
sim time next is 3941400.0000, 
raw observation next is [30.93333333333333, 69.5, 1.0, 2.0, 0.7975348792874495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 909030.0711087177, 909030.0711087177, 195438.1921746335], 
processed observation next is [0.0, 0.6086956521739131, 0.7012345679012344, 0.695, 1.0, 1.0, 0.7589700943898208, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32465359682454203, 0.32465359682454203, 0.3758426772589106], 
reward next is 0.6242, 
noisyNet noise sample is [array([0.27481243], dtype=float32), 0.07556962]. 
=============================================
[2019-03-22 23:49:16,515] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5210820e-38 1.0000000e+00 7.5735236e-37 2.7375721e-32 3.0009322e-37], sum to 1.0000
[2019-03-22 23:49:16,525] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8297
[2019-03-22 23:49:16,537] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1566657.108176137 W.
[2019-03-22 23:49:16,543] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.18333333333333, 77.16666666666667, 1.0, 2.0, 0.6869563277456541, 1.0, 1.0, 0.6869563277456541, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1566657.108176137, 1566657.108176138, 299255.7398050202], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4097400.0000, 
sim time next is 4098000.0000, 
raw observation next is [26.36666666666667, 75.33333333333334, 1.0, 2.0, 0.4395710630757359, 1.0, 2.0, 0.4395710630757359, 1.0, 1.0, 0.6998114482466559, 6.9112, 6.9112, 121.94756008, 1503651.719465036, 1503651.719465036, 314850.0255269858], 
processed observation next is [1.0, 0.43478260869565216, 0.5320987654320989, 0.7533333333333334, 1.0, 1.0, 0.3328226941377808, 1.0, 1.0, 0.3328226941377808, 1.0, 0.5, 0.6247643103083198, 0.0, 0.0, 0.8096049824067558, 0.5370184712375128, 0.5370184712375128, 0.6054808183211265], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7944912], dtype=float32), 1.0318336]. 
=============================================
[2019-03-22 23:49:16,561] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[53.703026]
 [54.96821 ]
 [54.761963]
 [55.12027 ]
 [54.42335 ]], R is [[53.19065475]
 [53.08325577]
 [52.92108917]
 [52.80417633]
 [52.74340439]].
[2019-03-22 23:49:19,309] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:49:19,322] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2262
[2019-03-22 23:49:19,327] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4371810224377863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 536156.916280609, 536156.916280609, 133843.2625761271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4158000.0000, 
sim time next is 4158600.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.5320810840414871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652639.5659251582, 652639.5659251582, 148610.7641838634], 
processed observation next is [1.0, 0.13043478260869565, 0.2962962962962963, 1.0, 1.0, 1.0, 0.44295367147796083, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23308555925898508, 0.23308555925898508, 0.2857899311228142], 
reward next is 0.7142, 
noisyNet noise sample is [array([0.24184194], dtype=float32), 0.7274714]. 
=============================================
[2019-03-22 23:49:21,549] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.43318e-38 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-22 23:49:21,556] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3410
[2019-03-22 23:49:21,563] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1552082.367846295 W.
[2019-03-22 23:49:21,571] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.66666666666667, 39.33333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.5946078580368, 6.9112, 121.923296466213, 1552082.367846295, 1202124.344538702, 247692.2941082155], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4192800.0000, 
sim time next is 4193400.0000, 
raw observation next is [32.83333333333333, 37.66666666666666, 1.0, 2.0, 0.5905961257414273, 1.0, 1.0, 0.5905961257414273, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9256310787604, 1377697.731610505, 1377697.731610505, 266291.3118349276], 
processed observation next is [1.0, 0.5217391304347826, 0.7716049382716048, 0.3766666666666666, 1.0, 1.0, 0.512614435406461, 1.0, 0.5, 0.512614435406461, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094593966430789, 0.4920349041466089, 0.4920349041466089, 0.51209867660563], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.34789422], dtype=float32), 1.3329719]. 
=============================================
[2019-03-22 23:49:24,672] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-22 23:49:24,674] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:49:24,674] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:49:24,674] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:49:24,676] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:49:24,678] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:49:24,680] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:49:24,681] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:49:24,681] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:49:24,683] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:49:24,684] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:49:24,697] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run14
[2019-03-22 23:49:24,713] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run14
[2019-03-22 23:49:24,732] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run14
[2019-03-22 23:49:24,749] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run14
[2019-03-22 23:49:24,771] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run14
[2019-03-22 23:49:26,918] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:49:26,920] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.91000622666667, 51.42661338666667, 1.0, 2.0, 0.4272701324373909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520681.6220780967, 520681.6220780967, 132300.4984586983]
[2019-03-22 23:49:26,922] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:49:26,925] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.11596197645068218
[2019-03-22 23:49:40,813] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:49:40,818] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.0, 64.0, 1.0, 2.0, 0.2158471413212797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 278416.2454673357, 278416.2454673357, 91109.72325395783]
[2019-03-22 23:49:40,819] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:49:40,823] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9133335733710914
[2019-03-22 23:49:47,455] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:49:47,456] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.2, 72.66666666666667, 1.0, 2.0, 0.3849462546928865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 480692.9358286054, 480692.9358286054, 126595.0632859914]
[2019-03-22 23:49:47,458] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:49:47,462] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.26951612599002306
[2019-03-22 23:49:50,029] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:49:50,030] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.8, 89.0, 1.0, 2.0, 0.3603857028667307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 451356.6497012962, 451356.6497012962, 123273.1118447614]
[2019-03-22 23:49:50,032] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:49:50,034] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.038915118834457085
[2019-03-22 23:49:57,939] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:49:57,940] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.838693455, 90.604370975, 1.0, 2.0, 0.3684019966841644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 461751.1667734474, 461751.166773447, 124360.5974220193]
[2019-03-22 23:49:57,941] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:49:57,944] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.12459045792069245
[2019-03-22 23:50:11,992] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:50:11,994] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.79625225666667, 65.37085884333334, 1.0, 2.0, 0.5134986926318875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 609873.7382143426, 609873.7382143422, 144934.6475036736]
[2019-03-22 23:50:11,996] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:50:11,999] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4528559080098311
[2019-03-22 23:50:37,978] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:50:37,979] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.15306951, 88.47168745, 1.0, 2.0, 0.7690232055993762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 876513.8883175642, 876513.8883175642, 189626.3131783268]
[2019-03-22 23:50:37,981] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:50:37,986] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7379689011108277
[2019-03-22 23:50:45,186] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:50:45,188] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.51666666666667, 85.00000000000001, 1.0, 2.0, 0.5057010167719389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 602931.3516543022, 602931.3516543019, 143785.2787860151]
[2019-03-22 23:50:45,191] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:50:45,195] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.30587082663968146
[2019-03-22 23:51:04,346] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:51:04,347] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 89.0, 1.0, 2.0, 0.9081432224687004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260371162602, 1035186.58861679, 1035186.588616789, 219299.1677427193]
[2019-03-22 23:51:04,349] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:51:04,351] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.2421188e-34 1.0000000e+00 0.0000000e+00 8.1500454e-28 1.0565906e-35], sampled 0.18925235343470914
[2019-03-22 23:51:05,205] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:51:05,207] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.27323550666667, 70.80952332333334, 1.0, 2.0, 0.2718714992297884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 350531.0210831255, 350531.0210831255, 112158.5279750311]
[2019-03-22 23:51:05,208] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:51:05,211] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6227606766574072
[2019-03-22 23:51:15,817] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2619 2170662485.7283 493.0000
[2019-03-22 23:51:15,944] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.6001 2445376094.7952 746.0000
[2019-03-22 23:51:16,258] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.1199 2120488280.6681 430.0000
[2019-03-22 23:51:16,294] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.6068 2195090877.2100 572.0000
[2019-03-22 23:51:16,396] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.9180 2248703752.9508 553.0000
[2019-03-22 23:51:17,412] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 325000, evaluation results [325000.0, 8100.600059888084, 2445376094.795151, 746.0, 8770.261897406637, 2170662485.728274, 493.0, 8924.119936648443, 2120488280.668146, 430.0, 8582.91798649268, 2248703752.950837, 553.0, 8701.60680134833, 2195090877.2099733, 572.0]
[2019-03-22 23:51:19,284] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.8037296e-31 1.0000000e+00 1.9278809e-38 3.1156768e-33 2.2654466e-30], sum to 1.0000
[2019-03-22 23:51:19,291] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0237
[2019-03-22 23:51:19,311] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1725305.011650544 W.
[2019-03-22 23:51:19,317] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.4, 58.5, 1.0, 2.0, 0.4959624737517165, 1.0, 1.0, 0.4959624737517165, 1.0, 1.0, 0.7910006443540933, 6.911200000000001, 6.9112, 121.94756008, 1725305.011650544, 1725305.011650543, 341730.8337357916], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4264200.0000, 
sim time next is 4264800.0000, 
raw observation next is [27.26666666666667, 61.0, 1.0, 2.0, 0.478293924046866, 1.0, 2.0, 0.478293924046866, 1.0, 2.0, 0.7616783729357554, 6.911200000000001, 6.9112, 121.94756008, 1644109.265236971, 1644109.26523697, 333115.6241916368], 
processed observation next is [1.0, 0.34782608695652173, 0.5654320987654322, 0.61, 1.0, 1.0, 0.3789213381510309, 1.0, 1.0, 0.3789213381510309, 1.0, 1.0, 0.7020979661696941, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5871818804417753, 0.587181880441775, 0.6406069695993015], 
reward next is 0.3594, 
noisyNet noise sample is [array([0.8412293], dtype=float32), -1.5293285]. 
=============================================
[2019-03-22 23:51:23,010] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6027725e-38 1.0000000e+00 1.6757516e-38 0.0000000e+00 2.7000432e-36], sum to 1.0000
[2019-03-22 23:51:23,017] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6558
[2019-03-22 23:51:23,028] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 94.00000000000001, 1.0, 2.0, 0.9597197647220109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.984473841780147, 6.9112, 121.9257823224725, 1147859.752896813, 1110337.07686898, 232045.8052751591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4331400.0000, 
sim time next is 4332000.0000, 
raw observation next is [23.66666666666666, 94.0, 1.0, 2.0, 0.8555025522257342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9259984914974, 992974.2783576988, 992974.2783576988, 208606.1592582218], 
processed observation next is [1.0, 0.13043478260869565, 0.4320987654320985, 0.94, 1.0, 1.0, 0.8279792288401598, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094618358815702, 0.3546336708420353, 0.3546336708420353, 0.40116569088119575], 
reward next is 0.5988, 
noisyNet noise sample is [array([0.11616179], dtype=float32), 0.799371]. 
=============================================
[2019-03-22 23:51:23,039] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[50.64942 ]
 [51.757633]
 [52.207233]
 [52.19822 ]
 [52.0222  ]], R is [[50.66424942]
 [50.34499741]
 [50.45399857]
 [50.58709717]
 [50.71203613]].
[2019-03-22 23:51:24,755] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.2717299e-37 1.0000000e+00 5.5256977e-34 0.0000000e+00 4.5494240e-35], sum to 1.0000
[2019-03-22 23:51:24,763] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3058
[2019-03-22 23:51:24,770] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.46666666666667, 67.16666666666667, 1.0, 2.0, 0.7111352833115415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 810499.7604745197, 810499.7604745197, 178266.1745469242], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4389000.0000, 
sim time next is 4389600.0000, 
raw observation next is [29.93333333333333, 68.33333333333334, 1.0, 2.0, 0.7042118283258065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 802604.7836199184, 802604.7836199179, 176944.8273086768], 
processed observation next is [1.0, 0.8260869565217391, 0.6641975308641974, 0.6833333333333335, 1.0, 1.0, 0.6478712241973887, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2866445655785423, 0.2866445655785421, 0.3402785140551477], 
reward next is 0.6597, 
noisyNet noise sample is [array([-0.03602312], dtype=float32), -0.91303086]. 
=============================================
[2019-03-22 23:51:28,306] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:51:28,318] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9910
[2019-03-22 23:51:28,328] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4921303015996781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 590800.471093143, 590800.471093143, 141801.5276767784], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4420200.0000, 
sim time next is 4420800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.4917546613566779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 590350.1716416434, 590350.1716416434, 141742.9510794396], 
processed observation next is [0.0, 0.17391304347826086, 0.37037037037037035, 0.94, 1.0, 1.0, 0.39494602542461654, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21083934701487264, 0.21083934701487264, 0.27258259822969155], 
reward next is 0.7274, 
noisyNet noise sample is [array([0.12682989], dtype=float32), 0.3482277]. 
=============================================
[2019-03-22 23:51:49,851] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.5630571e-29 1.0000000e+00 5.1526055e-32 1.1437938e-21 1.1176056e-27], sum to 1.0000
[2019-03-22 23:51:49,857] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3427
[2019-03-22 23:51:49,867] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.95, 93.5, 1.0, 2.0, 0.7403494323221568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 856215.0477920956, 856215.0477920956, 184546.8872942495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4779000.0000, 
sim time next is 4779600.0000, 
raw observation next is [23.93333333333333, 93.33333333333334, 1.0, 2.0, 0.6723871681430491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 778241.8569937038, 778241.8569937033, 171567.5850664831], 
processed observation next is [1.0, 0.30434782608695654, 0.4419753086419752, 0.9333333333333335, 1.0, 1.0, 0.6099847239798204, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2779435203548942, 0.27794352035489406, 0.3299376635893906], 
reward next is 0.6701, 
noisyNet noise sample is [array([-0.38098404], dtype=float32), -1.9148338]. 
=============================================
[2019-03-22 23:51:51,682] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1467666e-17 4.3455303e-02 1.9127714e-24 9.5654470e-01 1.0218938e-16], sum to 1.0000
[2019-03-22 23:51:51,689] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1752
[2019-03-22 23:51:51,697] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.13333333333333, 94.33333333333334, 1.0, 2.0, 0.4620127694410426, 1.0, 2.0, 0.4620127694410426, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426155264, 1053303.181812323, 1053303.181812323, 223885.0971977349], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4848000.0000, 
sim time next is 4848600.0000, 
raw observation next is [25.06666666666667, 94.16666666666667, 1.0, 2.0, 0.4429468464461952, 1.0, 2.0, 0.4429468464461952, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1009807.781989348, 1009807.781989348, 218302.6417642855], 
processed observation next is [1.0, 0.08695652173913043, 0.4839506172839507, 0.9416666666666668, 1.0, 1.0, 0.33684148386451807, 1.0, 1.0, 0.33684148386451807, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.36064563642476716, 0.36064563642476716, 0.419812772623626], 
reward next is 0.5802, 
noisyNet noise sample is [array([-0.36010295], dtype=float32), 1.1746808]. 
=============================================
[2019-03-22 23:51:53,150] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1351204e-28 1.0000000e+00 1.3217435e-26 1.0728999e-09 8.3261803e-28], sum to 1.0000
[2019-03-22 23:51:53,157] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7375
[2019-03-22 23:51:53,163] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.26666666666667, 96.66666666666666, 1.0, 2.0, 0.6993869146389343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 797102.8703321803, 797102.8703321803, 176028.4099266914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4844400.0000, 
sim time next is 4845000.0000, 
raw observation next is [25.33333333333334, 95.83333333333334, 1.0, 2.0, 0.6979603191189947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 795476.1120403366, 795476.1120403371, 175758.5047773202], 
processed observation next is [1.0, 0.043478260869565216, 0.49382716049382736, 0.9583333333333335, 1.0, 1.0, 0.6404289513321365, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2840986114429774, 0.28409861144297754, 0.3379971245717696], 
reward next is 0.6620, 
noisyNet noise sample is [array([-1.3180957], dtype=float32), -0.19336201]. 
=============================================
[2019-03-22 23:51:53,176] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[50.246487]
 [50.39858 ]
 [50.561253]
 [50.71551 ]
 [50.931156]], R is [[50.33218384]
 [50.490345  ]
 [50.6462059 ]
 [50.79986572]
 [50.95142746]].
[2019-03-22 23:51:54,529] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7599576e-20 9.3737328e-01 2.1215513e-24 6.2626652e-02 1.6312104e-17], sum to 1.0000
[2019-03-22 23:51:54,536] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7168
[2019-03-22 23:51:54,546] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1982272.471613995 W.
[2019-03-22 23:51:54,556] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.65, 91.5, 1.0, 2.0, 0.8689944033313322, 1.0, 2.0, 0.8689944033313322, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1982272.471613995, 1982272.471613995, 373089.5949457923], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4872600.0000, 
sim time next is 4873200.0000, 
raw observation next is [26.86666666666667, 90.66666666666666, 1.0, 2.0, 0.5928327629675643, 1.0, 2.0, 0.5928327629675643, 1.0, 1.0, 0.9438090658595453, 6.911199999999999, 6.9112, 121.94756008, 2028527.848880925, 2028527.848880925, 391484.343671935], 
processed observation next is [1.0, 0.391304347826087, 0.5506172839506175, 0.9066666666666666, 1.0, 1.0, 0.5152770987709098, 1.0, 1.0, 0.5152770987709098, 1.0, 0.5, 0.9297613323244316, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7244742317431875, 0.7244742317431875, 0.7528545070614135], 
reward next is 0.2471, 
noisyNet noise sample is [array([-0.41184923], dtype=float32), -1.1771369]. 
=============================================
[2019-03-22 23:52:12,092] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-22 23:52:12,094] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:52:12,096] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:52:12,097] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:52:12,097] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:52:12,098] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:52:12,099] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:52:12,101] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:52:12,103] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:52:12,100] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:52:12,105] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:52:12,126] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run15
[2019-03-22 23:52:12,142] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run15
[2019-03-22 23:52:12,144] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run15
[2019-03-22 23:52:12,179] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run15
[2019-03-22 23:52:12,180] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run15
[2019-03-22 23:52:23,408] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.29774055], dtype=float32), 0.11320754]
[2019-03-22 23:52:23,410] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [37.93333333333334, 14.33333333333334, 1.0, 2.0, 0.5707503634775449, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9362067674051199, 6.911199999999999, 6.9112, 121.9260426156618, 1399904.960191221, 1399904.960191221, 279278.9226427369]
[2019-03-22 23:52:23,412] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:52:23,414] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.7763622e-29 0.0000000e+00], sampled 0.07029362950296647
[2019-03-22 23:52:23,415] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1399904.960191221 W.
[2019-03-22 23:52:32,098] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.29774055], dtype=float32), 0.11320754]
[2019-03-22 23:52:32,099] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.97882698, 39.01840554, 1.0, 2.0, 0.394145458799961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489473.1264798331, 489473.1264798331, 127821.2586146563]
[2019-03-22 23:52:32,100] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:52:32,101] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.07172201667978406
[2019-03-22 23:52:34,296] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.29774055], dtype=float32), 0.11320754]
[2019-03-22 23:52:34,299] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [34.86842642000001, 19.489125865, 1.0, 2.0, 0.3939484213853752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 493137.0012434031, 493137.0012434031, 127869.4221799428]
[2019-03-22 23:52:34,300] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:52:34,303] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5395723774654398
[2019-03-22 23:52:43,535] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.29774055], dtype=float32), 0.11320754]
[2019-03-22 23:52:43,537] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.84506479666667, 85.53559905333334, 1.0, 2.0, 0.4516843314359695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 546829.3324412127, 546829.3324412127, 135788.3723743958]
[2019-03-22 23:52:43,539] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:52:43,542] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5806268411757608
[2019-03-22 23:53:35,654] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.29774055], dtype=float32), 0.11320754]
[2019-03-22 23:53:35,657] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.62851149, 65.66917886, 1.0, 2.0, 0.6946395575353725, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426155949, 1506683.090403135, 1506683.090403134, 316265.1894482803]
[2019-03-22 23:53:35,658] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:53:35,660] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7713068e-35 0.0000000e+00], sampled 0.9647639351658749
[2019-03-22 23:53:35,662] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1506683.090403135 W.
[2019-03-22 23:53:47,748] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.29774055], dtype=float32), 0.11320754]
[2019-03-22 23:53:47,750] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.3, 79.33333333333334, 1.0, 2.0, 0.4179620621306175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 514719.3723218975, 514719.3723218971, 131103.194473719]
[2019-03-22 23:53:47,752] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:53:47,755] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.374669733689026
[2019-03-22 23:54:02,235] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.5061 2195143254.2709 572.0000
[2019-03-22 23:54:02,271] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.5862 2248694038.7053 551.0000
[2019-03-22 23:54:02,360] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.1199 2120488280.6681 430.0000
[2019-03-22 23:54:02,411] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8101.0198 2445313766.5296 745.0000
[2019-03-22 23:54:02,480] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2619 2170662485.7283 493.0000
[2019-03-22 23:54:03,494] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 350000, evaluation results [350000.0, 8101.019752766, 2445313766.529631, 745.0, 8770.261897406637, 2170662485.728274, 493.0, 8924.119936648443, 2120488280.668146, 430.0, 8583.586166792616, 2248694038.705321, 551.0, 8701.506076231219, 2195143254.27087, 572.0]
[2019-03-22 23:54:04,024] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5945956e-35 1.0000000e+00 0.0000000e+00 1.9106065e-34 1.7982951e-35], sum to 1.0000
[2019-03-22 23:54:04,032] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6574
[2019-03-22 23:54:04,039] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 93.66666666666667, 1.0, 2.0, 0.9623863264738182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.978461711434527, 6.9112, 121.9254907807397, 1143666.421620131, 1109222.569475021, 232448.0796094096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5194200.0000, 
sim time next is 5194800.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.9135093414925953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.92600208384, 1053599.239415883, 1053599.239415883, 221175.2313743659], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.8970349303483278, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094618597309894, 0.3762854426485297, 0.3762854426485297, 0.4253369834122421], 
reward next is 0.5747, 
noisyNet noise sample is [array([-0.06157962], dtype=float32), -1.8234673]. 
=============================================
[2019-03-22 23:54:08,933] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:54:08,943] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5598
[2019-03-22 23:54:08,946] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 87.33333333333334, 1.0, 2.0, 0.7171056983264646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 817308.0289711765, 817308.0289711765, 179408.9724934152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5258400.0000, 
sim time next is 5259000.0000, 
raw observation next is [26.7, 87.66666666666667, 1.0, 2.0, 0.7154332503669486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 815400.8732488728, 815400.8732488728, 179087.401297078], 
processed observation next is [1.0, 0.8695652173913043, 0.5444444444444444, 0.8766666666666667, 1.0, 1.0, 0.6612300599606531, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29121459758888313, 0.29121459758888313, 0.34439884864822695], 
reward next is 0.6556, 
noisyNet noise sample is [array([-0.55901796], dtype=float32), 1.7806386]. 
=============================================
[2019-03-22 23:54:08,960] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[57.20597 ]
 [57.47936 ]
 [58.000736]
 [58.645924]
 [59.23003 ]], R is [[57.09360123]
 [57.17765045]
 [57.2598381 ]
 [57.33982086]
 [57.41699982]].
[2019-03-22 23:54:26,096] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0279821e-33 1.0000000e+00 0.0000000e+00 4.4866498e-30 2.5247501e-33], sum to 1.0000
[2019-03-22 23:54:26,100] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3307
[2019-03-22 23:54:26,106] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1581517.151966297 W.
[2019-03-22 23:54:26,111] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.6, 78.33333333333334, 1.0, 2.0, 0.693465518380481, 1.0, 2.0, 0.693465518380481, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1581517.151966297, 1581517.151966298, 301699.0796921269], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5571600.0000, 
sim time next is 5572200.0000, 
raw observation next is [27.8, 78.16666666666666, 1.0, 2.0, 0.690089454006023, 1.0, 2.0, 0.690089454006023, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1573809.788397176, 1573809.788397177, 300430.7858739935], 
processed observation next is [1.0, 0.4782608695652174, 0.5851851851851853, 0.7816666666666666, 1.0, 1.0, 0.631058873816694, 1.0, 1.0, 0.631058873816694, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5620749244275628, 0.5620749244275631, 0.5777515112961413], 
reward next is 0.4222, 
noisyNet noise sample is [array([-0.6626796], dtype=float32), -1.1849662]. 
=============================================
[2019-03-22 23:54:26,124] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:54:26,139] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4856
[2019-03-22 23:54:26,145] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.36666666666667, 93.0, 1.0, 2.0, 0.7687934814458343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 876251.9046503331, 876251.9046503326, 189573.8803037528], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5545200.0000, 
sim time next is 5545800.0000, 
raw observation next is [25.35, 93.0, 1.0, 2.0, 0.7548191582407742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 860315.3751440179, 860315.3751440179, 186779.0651612997], 
processed observation next is [1.0, 0.17391304347826086, 0.4944444444444445, 0.93, 1.0, 1.0, 0.7081180455247311, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30725549112286354, 0.30725549112286354, 0.35919050992557633], 
reward next is 0.6408, 
noisyNet noise sample is [array([1.2363955], dtype=float32), -1.7792274]. 
=============================================
[2019-03-22 23:54:28,089] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:54:28,097] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9516
[2019-03-22 23:54:28,101] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.15, 91.0, 1.0, 2.0, 0.602117982255403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686194.2345030855, 686194.2345030855, 158442.910105232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5592600.0000, 
sim time next is 5593200.0000, 
raw observation next is [25.2, 91.0, 1.0, 2.0, 0.6112221192546315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696574.3341255849, 696574.3341255849, 160019.1779613907], 
processed observation next is [1.0, 0.7391304347826086, 0.4888888888888889, 0.91, 1.0, 1.0, 0.5371691895888471, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2487765479019946, 0.2487765479019946, 0.3077291883872898], 
reward next is 0.6923, 
noisyNet noise sample is [array([0.08813997], dtype=float32), 1.9613875]. 
=============================================
[2019-03-22 23:54:31,730] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:54:31,740] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5507
[2019-03-22 23:54:31,743] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 88.0, 1.0, 2.0, 0.6648728857664028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 757747.2155204386, 757747.2155204382, 169600.2777525396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5650200.0000, 
sim time next is 5650800.0000, 
raw observation next is [26.16666666666666, 87.33333333333333, 1.0, 2.0, 0.6696131503582464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763152.3244464057, 763152.3244464057, 170470.9689689021], 
processed observation next is [0.0, 0.391304347826087, 0.5246913580246911, 0.8733333333333333, 1.0, 1.0, 0.6066823218550552, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27255440158800204, 0.27255440158800204, 0.3278287864786579], 
reward next is 0.6722, 
noisyNet noise sample is [array([1.0231936], dtype=float32), 1.3012017]. 
=============================================
[2019-03-22 23:54:32,439] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:54:32,449] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6261
[2019-03-22 23:54:32,456] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.98333333333333, 69.5, 1.0, 2.0, 0.7192870570345481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819795.5220172087, 819795.5220172087, 179830.4203672784], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5670600.0000, 
sim time next is 5671200.0000, 
raw observation next is [30.06666666666667, 69.0, 1.0, 2.0, 0.7192478798165262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819750.8465530908, 819750.8465530908, 179822.8324850003], 
processed observation next is [0.0, 0.6521739130434783, 0.669135802469136, 0.69, 1.0, 1.0, 0.6657712854958645, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29276815948324675, 0.29276815948324675, 0.34581313939423136], 
reward next is 0.6542, 
noisyNet noise sample is [array([-1.0796083], dtype=float32), 1.6902761]. 
=============================================
[2019-03-22 23:54:36,520] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:54:36,528] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2670
[2019-03-22 23:54:36,531] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.46666666666667, 87.5, 1.0, 2.0, 0.4278328193513551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524921.4351576674, 524921.4351576674, 132481.4344130966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5730600.0000, 
sim time next is 5731200.0000, 
raw observation next is [21.5, 87.0, 1.0, 2.0, 0.4261064130373477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 523040.1732337791, 523040.1732337791, 132236.7576461], 
processed observation next is [0.0, 0.34782608695652173, 0.35185185185185186, 0.87, 1.0, 1.0, 0.3167933488539854, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1868000618692068, 0.1868000618692068, 0.2543014570117308], 
reward next is 0.7457, 
noisyNet noise sample is [array([0.304961], dtype=float32), -1.9607122]. 
=============================================
[2019-03-22 23:54:39,002] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.1520843e-38 3.2278821e-36 0.0000000e+00], sum to 1.0000
[2019-03-22 23:54:39,012] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9905
[2019-03-22 23:54:39,016] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 56.83333333333334, 1.0, 2.0, 0.7863179035871862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 974632.6391731332, 974632.6391731336, 196316.1019288553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5824200.0000, 
sim time next is 5824800.0000, 
raw observation next is [25.4, 55.0, 1.0, 2.0, 0.778697062789079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 967391.6115246387, 967391.6115246387, 194777.6837357856], 
processed observation next is [1.0, 0.43478260869565216, 0.49629629629629624, 0.55, 1.0, 1.0, 0.7365441223679512, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3454970041159424, 0.3454970041159424, 0.3745724687226646], 
reward next is 0.6254, 
noisyNet noise sample is [array([0.6465717], dtype=float32), 0.12445821]. 
=============================================
[2019-03-22 23:54:39,622] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:54:39,632] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6774
[2019-03-22 23:54:39,642] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.76666666666667, 85.83333333333334, 1.0, 2.0, 0.474446681659799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 572085.8254121001, 572085.8254120996, 139155.3377407427], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5791800.0000, 
sim time next is 5792400.0000, 
raw observation next is [22.7, 86.0, 1.0, 2.0, 0.4723425346162108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 569976.4211514171, 569976.4211514171, 138847.7436294369], 
processed observation next is [1.0, 0.043478260869565216, 0.39629629629629626, 0.86, 1.0, 1.0, 0.37183635073358423, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20356300755407752, 0.20356300755407752, 0.26701489159507097], 
reward next is 0.7330, 
noisyNet noise sample is [array([-1.8739182], dtype=float32), 0.013952097]. 
=============================================
[2019-03-22 23:54:51,688] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9697287e-20 1.3441074e-16 3.5313784e-30 1.0000000e+00 1.7744006e-24], sum to 1.0000
[2019-03-22 23:54:51,690] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3555
[2019-03-22 23:54:51,696] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.36666666666667, 71.83333333333333, 1.0, 2.0, 0.5609588891694782, 1.0, 2.0, 0.5609588891694782, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1334005.725217789, 1334005.725217789, 257323.8361656522], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5994600.0000, 
sim time next is 5995200.0000, 
raw observation next is [24.53333333333333, 71.66666666666667, 1.0, 2.0, 0.5734454652597131, 1.0, 2.0, 0.5734454652597131, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1358990.437255907, 1358990.437255908, 261351.5718349575], 
processed observation next is [1.0, 0.391304347826087, 0.46419753086419746, 0.7166666666666667, 1.0, 1.0, 0.49219698245203936, 1.0, 1.0, 0.49219698245203936, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4853537275913954, 0.4853537275913957, 0.5025991766056874], 
reward next is 0.4974, 
noisyNet noise sample is [array([-1.1193373], dtype=float32), -0.22619513]. 
=============================================
[2019-03-22 23:54:56,312] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.3851854e-36 0.0000000e+00], sum to 1.0000
[2019-03-22 23:54:56,321] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2290
[2019-03-22 23:54:56,327] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.51666666666667, 75.16666666666667, 1.0, 2.0, 0.765114182874309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 904267.3072916633, 904267.3072916628, 190386.7198491396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6077400.0000, 
sim time next is 6078000.0000, 
raw observation next is [26.53333333333333, 70.33333333333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.497077956287765, 6.9112, 121.9239894088543, 1499979.059207733, 1199962.232711029, 247589.6578655135], 
processed observation next is [1.0, 0.34782608695652173, 0.5382716049382715, 0.7033333333333335, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.05858779562877654, 0.0, 0.8094484976621187, 0.5357068068599047, 0.42855794025393895, 0.4761339574336798], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.55533266], dtype=float32), 1.3564954]. 
=============================================
[2019-03-22 23:54:56,338] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[68.24914 ]
 [69.23869 ]
 [69.40856 ]
 [69.428276]
 [69.47674 ]], R is [[64.77428436]
 [64.76041412]
 [64.80487061]
 [64.85905457]
 [64.91371155]].
[2019-03-22 23:54:58,068] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-22 23:54:58,069] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:54:58,070] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:54:58,070] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:54:58,072] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:54:58,072] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:54:58,074] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:54:58,075] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:54:58,076] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:54:58,074] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:54:58,082] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:54:58,106] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run16
[2019-03-22 23:54:58,106] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run16
[2019-03-22 23:54:58,141] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run16
[2019-03-22 23:54:58,143] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run16
[2019-03-22 23:54:58,158] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run16
[2019-03-22 23:55:17,275] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3521504], dtype=float32), 0.08852717]
[2019-03-22 23:55:17,277] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.26666666666667, 63.33333333333334, 1.0, 2.0, 0.31315786207366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 397091.5086924711, 397091.5086924711, 117202.2562815193]
[2019-03-22 23:55:17,278] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:55:17,283] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0147054e-31 0.0000000e+00], sampled 0.6354172230949032
[2019-03-22 23:55:21,054] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3521504], dtype=float32), 0.08852717]
[2019-03-22 23:55:21,054] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 48.66666666666667, 1.0, 2.0, 0.9113406274732245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.937518459396486, 6.9112, 121.9258953717727, 1115102.166582407, 1101624.779330174, 223000.4958345299]
[2019-03-22 23:55:21,055] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:55:21,059] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1806879e-27 1.0000000e+00 6.6099711e-32 1.5275084e-14 7.3603933e-29], sampled 0.00045661731067658806
[2019-03-22 23:56:09,563] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3521504], dtype=float32), 0.08852717]
[2019-03-22 23:56:09,565] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.0, 94.0, 1.0, 2.0, 0.7941470671413676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 905166.363229948, 905166.363229948, 194740.476244479]
[2019-03-22 23:56:09,566] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:56:09,569] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0025393e-24 1.0000000e+00 9.1341168e-31 3.2500118e-09 7.8643871e-28], sampled 0.6401181697301581
[2019-03-22 23:56:20,030] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.3521504], dtype=float32), 0.08852717]
[2019-03-22 23:56:20,033] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.55418471, 66.27883852333335, 1.0, 2.0, 0.4840398797324084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 595068.2174134871, 595068.2174134871, 140973.1559814862]
[2019-03-22 23:56:20,037] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:56:20,039] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.5887169e-34 1.0000000e+00 1.1042677e-37 4.3248175e-24 6.4275239e-35], sampled 0.331473428290067
[2019-03-22 23:56:47,054] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8887.8219 2158652431.5132 361.0000
[2019-03-22 23:56:47,210] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8743.5960 2226891980.3075 377.0000
[2019-03-22 23:56:47,322] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8996.0235 2112297488.1121 342.0000
[2019-03-22 23:56:47,348] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8826.5245 2181326046.1543 419.0000
[2019-03-22 23:56:47,358] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8311.3449 2420420506.0261 495.0000
[2019-03-22 23:56:48,372] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 375000, evaluation results [375000.0, 8311.344867807718, 2420420506.02613, 495.0, 8887.82185406877, 2158652431.5132093, 361.0, 8996.023515037501, 2112297488.1120796, 342.0, 8743.595970819073, 2226891980.3075, 377.0, 8826.524485702983, 2181326046.15435, 419.0]
[2019-03-22 23:56:59,974] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:56:59,982] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7942
[2019-03-22 23:56:59,986] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 88.0, 1.0, 2.0, 0.5645186784039304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 661283.4324323619, 661283.4324323619, 152915.1870700168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6322800.0000, 
sim time next is 6323400.0000, 
raw observation next is [24.05, 88.0, 1.0, 2.0, 0.5628992067007859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 659604.4912601669, 659604.4912601664, 152653.4927059588], 
processed observation next is [0.0, 0.17391304347826086, 0.4462962962962963, 0.88, 1.0, 1.0, 0.4796419127390308, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23557303259291673, 0.23557303259291656, 0.29356440904992076], 
reward next is 0.7064, 
noisyNet noise sample is [array([1.0487374], dtype=float32), -0.90954447]. 
=============================================
[2019-03-22 23:57:00,728] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:57:00,734] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6759
[2019-03-22 23:57:00,737] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.06666666666667, 58.83333333333334, 1.0, 2.0, 0.6959674657849765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 793203.6512101679, 793203.6512101679, 175380.8629196532], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6354600.0000, 
sim time next is 6355200.0000, 
raw observation next is [31.13333333333333, 58.66666666666667, 1.0, 2.0, 0.6691222757995607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 762592.6006602708, 762592.6006602708, 170380.8899595532], 
processed observation next is [0.0, 0.5652173913043478, 0.7086419753086418, 0.5866666666666667, 1.0, 1.0, 0.6060979473804294, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.272354500235811, 0.272354500235811, 0.32765555761452536], 
reward next is 0.6723, 
noisyNet noise sample is [array([-0.09417789], dtype=float32), -0.78803915]. 
=============================================
[2019-03-22 23:57:07,075] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:57:07,081] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9071
[2019-03-22 23:57:07,085] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.13333333333333, 57.0, 1.0, 2.0, 0.6090587893400922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694107.7965572923, 694107.7965572923, 159644.2931438035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6457200.0000, 
sim time next is 6457800.0000, 
raw observation next is [31.06666666666667, 57.5, 1.0, 2.0, 0.6195895679794394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706114.621125785, 706114.621125785, 161481.4263387153], 
processed observation next is [1.0, 0.7391304347826086, 0.7061728395061729, 0.575, 1.0, 1.0, 0.5471304380707612, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2521837932592089, 0.2521837932592089, 0.3105412044975294], 
reward next is 0.6895, 
noisyNet noise sample is [array([-0.59146696], dtype=float32), 1.0556552]. 
=============================================
[2019-03-22 23:57:07,412] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.60536184e-31 1.00000000e+00 1.11681685e-35 3.34902244e-36
 0.00000000e+00], sum to 1.0000
[2019-03-22 23:57:07,423] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5837
[2019-03-22 23:57:07,428] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 55.5, 1.0, 2.0, 0.4334784570936808, 1.0, 2.0, 0.4334784570936808, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 988208.3090289363, 988208.3090289363, 215577.1170200618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6455400.0000, 
sim time next is 6456000.0000, 
raw observation next is [31.26666666666667, 56.0, 1.0, 2.0, 0.6054827917286754, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690030.612237212, 690030.612237212, 159024.5303081149], 
processed observation next is [1.0, 0.7391304347826086, 0.7135802469135804, 0.56, 1.0, 1.0, 0.5303366568198516, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24643950437043285, 0.24643950437043285, 0.30581640443868247], 
reward next is 0.6942, 
noisyNet noise sample is [array([-1.1575516], dtype=float32), -1.0840797]. 
=============================================
[2019-03-22 23:57:07,441] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[48.90672 ]
 [44.742805]
 [45.290085]
 [45.53575 ]
 [46.017624]], R is [[51.25430298]
 [51.3271904 ]
 [51.04101944]
 [50.76311493]
 [50.25548553]].
[2019-03-22 23:57:07,537] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:57:07,545] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6689
[2019-03-22 23:57:07,549] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.2, 64.0, 1.0, 2.0, 0.6890457452515938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 785310.8302891499, 785310.8302891499, 174080.4375662615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6465600.0000, 
sim time next is 6466200.0000, 
raw observation next is [30.08333333333334, 64.5, 1.0, 2.0, 0.6781439054198352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 772879.653919917, 772879.653919917, 172047.8202711437], 
processed observation next is [1.0, 0.8695652173913043, 0.6697530864197533, 0.645, 1.0, 1.0, 0.6168379826426609, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27602844782854175, 0.27602844782854175, 0.33086119282912246], 
reward next is 0.6691, 
noisyNet noise sample is [array([-0.27442083], dtype=float32), 0.8712677]. 
=============================================
[2019-03-22 23:57:07,862] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:57:07,869] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3722
[2019-03-22 23:57:07,873] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.26666666666667, 56.0, 1.0, 2.0, 0.605467257317639, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 690012.9006795381, 690012.9006795377, 159021.8469552816], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6456000.0000, 
sim time next is 6456600.0000, 
raw observation next is [31.2, 56.5, 1.0, 2.0, 0.5990299636640046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 682673.4559827371, 682673.4559827371, 157912.5861463695], 
processed observation next is [1.0, 0.7391304347826086, 0.7111111111111111, 0.565, 1.0, 1.0, 0.5226547186476246, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24381194856526325, 0.24381194856526325, 0.30367805028147976], 
reward next is 0.6963, 
noisyNet noise sample is [array([-0.5069241], dtype=float32), 0.6338648]. 
=============================================
[2019-03-22 23:57:11,508] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.51208692e-16 1.00000000e+00 9.59277317e-21 1.01490465e-20
 7.55376747e-20], sum to 1.0000
[2019-03-22 23:57:11,516] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4188
[2019-03-22 23:57:11,522] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1993823.971765656 W.
[2019-03-22 23:57:11,527] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.35, 80.5, 1.0, 2.0, 0.582701939355965, 1.0, 1.0, 0.582701939355965, 1.0, 2.0, 0.9276804647319885, 6.911200000000001, 6.9112, 121.94756008, 1993823.971765656, 1993823.971765655, 386031.3002838116], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6528600.0000, 
sim time next is 6529200.0000, 
raw observation next is [27.26666666666667, 80.66666666666667, 1.0, 2.0, 0.5674481032002626, 1.0, 2.0, 0.5674481032002626, 1.0, 2.0, 0.9033958607893489, 6.911200000000001, 6.9112, 121.94756008, 1941573.383965977, 1941573.383965977, 377925.1152748806], 
processed observation next is [1.0, 0.5652173913043478, 0.5654320987654322, 0.8066666666666668, 1.0, 1.0, 0.48505726571459834, 1.0, 1.0, 0.48505726571459834, 1.0, 1.0, 0.8792448259866861, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6934190657021346, 0.6934190657021346, 0.7267790678363089], 
reward next is 0.2732, 
noisyNet noise sample is [array([-0.36868912], dtype=float32), 0.7759733]. 
=============================================
[2019-03-22 23:57:13,775] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:57:13,783] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7723
[2019-03-22 23:57:13,789] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.46666666666667, 41.16666666666666, 1.0, 2.0, 0.737784928338689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 934630.6456138123, 934630.6456138123, 186717.379517668], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6603000.0000, 
sim time next is 6603600.0000, 
raw observation next is [26.63333333333333, 40.33333333333334, 1.0, 2.0, 0.8054625884842693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1020327.648662016, 1020327.648662016, 200767.763243668], 
processed observation next is [1.0, 0.43478260869565216, 0.5419753086419752, 0.40333333333333343, 1.0, 1.0, 0.768407843433654, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3644027316650057, 0.3644027316650057, 0.38609185239166927], 
reward next is 0.6139, 
noisyNet noise sample is [array([-0.1834802], dtype=float32), -0.5613611]. 
=============================================
[2019-03-22 23:57:15,324] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3864741e-36], sum to 1.0000
[2019-03-22 23:57:15,336] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7164
[2019-03-22 23:57:15,345] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.96666666666667, 43.66666666666667, 1.0, 2.0, 0.5777301983110922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 731495.7052364501, 731495.7052364501, 156734.0499765849], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6601200.0000, 
sim time next is 6601800.0000, 
raw observation next is [26.13333333333333, 42.83333333333333, 1.0, 2.0, 0.5558606954304491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 704049.6869426618, 704049.6869426613, 152995.0829216214], 
processed observation next is [1.0, 0.391304347826087, 0.5234567901234567, 0.4283333333333333, 1.0, 1.0, 0.47126273265529656, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2514463167652363, 0.25144631676523616, 0.29422131331081036], 
reward next is 0.7058, 
noisyNet noise sample is [array([1.826129], dtype=float32), 0.1175554]. 
=============================================
[2019-03-22 23:57:16,890] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.8048516e-33 1.0000000e+00 5.6396602e-38 1.0830153e-32 1.5723345e-28], sum to 1.0000
[2019-03-22 23:57:16,899] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0078
[2019-03-22 23:57:16,905] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.43333333333333, 44.0, 1.0, 2.0, 0.3597413219394566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 449124.5917373403, 449124.5917373403, 123161.4285585821], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6632400.0000, 
sim time next is 6633000.0000, 
raw observation next is [27.15, 45.0, 1.0, 2.0, 0.3597305585898989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 449362.2901478652, 449362.2901478652, 123164.6250285196], 
processed observation next is [1.0, 0.782608695652174, 0.561111111111111, 0.45, 1.0, 1.0, 0.2377744745117844, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16048653219566614, 0.16048653219566614, 0.23685504813176847], 
reward next is 0.7631, 
noisyNet noise sample is [array([0.01112455], dtype=float32), -0.033782303]. 
=============================================
[2019-03-22 23:57:16,930] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[61.564106]
 [60.61723 ]
 [59.629356]
 [58.806026]
 [57.74893 ]], R is [[62.39551163]
 [62.53470612]
 [62.67276764]
 [62.81111526]
 [62.95149612]].
[2019-03-22 23:57:19,005] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.2704899e-38 1.0262391e-32], sum to 1.0000
[2019-03-22 23:57:19,012] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4227
[2019-03-22 23:57:19,016] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 44.50000000000001, 1.0, 2.0, 0.3192187026086005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 411788.6324863221, 411788.6324863221, 111290.2608871726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6671400.0000, 
sim time next is 6672000.0000, 
raw observation next is [22.9, 45.0, 1.0, 2.0, 0.2896552188353633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 373642.7715324259, 373642.7715324259, 108164.4186723898], 
processed observation next is [1.0, 0.21739130434782608, 0.4037037037037037, 0.45, 1.0, 1.0, 0.15435145099448014, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1334438469758664, 0.1334438469758664, 0.20800849744690347], 
reward next is 0.7920, 
noisyNet noise sample is [array([-1.6142558], dtype=float32), 0.095339976]. 
=============================================
[2019-03-22 23:57:19,031] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[75.87033]
 [75.96698]
 [75.92679]
 [75.87355]
 [75.86362]], R is [[75.99866486]
 [76.0246582 ]
 [76.06031799]
 [76.09425354]
 [76.12586212]].
[2019-03-22 23:57:25,441] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.7717595e-27 4.3453022e-26 0.0000000e+00 1.0000000e+00 4.6460250e-20], sum to 1.0000
[2019-03-22 23:57:25,454] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7594
[2019-03-22 23:57:25,458] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.25, 50.5, 1.0, 2.0, 0.447833210074338, 1.0, 2.0, 0.447833210074338, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1095821.410229771, 1095821.410229771, 222677.6862584314], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6780600.0000, 
sim time next is 6781200.0000, 
raw observation next is [26.36666666666667, 50.33333333333333, 1.0, 2.0, 0.4065879733255375, 1.0, 2.0, 0.4065879733255375, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 994643.3431781204, 994643.3431781204, 210685.1552623363], 
processed observation next is [1.0, 0.4782608695652174, 0.5320987654320989, 0.5033333333333333, 1.0, 1.0, 0.29355711110183036, 1.0, 1.0, 0.29355711110183036, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3552297654207573, 0.3552297654207573, 0.40516376011987754], 
reward next is 0.5948, 
noisyNet noise sample is [array([-1.2795873], dtype=float32), 1.2576845]. 
=============================================
[2019-03-22 23:57:25,651] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0206481e-21 5.6943641e-06 1.5893342e-24 9.9999428e-01 3.8153419e-13], sum to 1.0000
[2019-03-22 23:57:25,662] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4507
[2019-03-22 23:57:25,669] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.2, 49.0, 1.0, 2.0, 0.3700897112551894, 1.0, 2.0, 0.3700897112551894, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 900330.7852720452, 900330.7852720456, 200433.1014667407], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6786000.0000, 
sim time next is 6786600.0000, 
raw observation next is [27.31666666666667, 48.83333333333334, 1.0, 2.0, 0.4031155530313377, 1.0, 2.0, 0.4031155530313377, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 979964.4742924831, 979964.4742924835, 209519.6222801738], 
processed observation next is [1.0, 0.5652173913043478, 0.5672839506172841, 0.48833333333333345, 1.0, 1.0, 0.2894232774182592, 1.0, 1.0, 0.2894232774182592, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3499873122473154, 0.34998731224731555, 0.40292235053879577], 
reward next is 0.5971, 
noisyNet noise sample is [array([-0.02965715], dtype=float32), -1.6215478]. 
=============================================
[2019-03-22 23:57:27,337] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5064561e-13 9.9999976e-01 6.3023577e-21 2.8418185e-07 2.5156710e-13], sum to 1.0000
[2019-03-22 23:57:27,345] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6397
[2019-03-22 23:57:27,350] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 65.83333333333334, 1.0, 2.0, 0.4718105653884278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 568422.0054060986, 568422.0054060986, 138736.1647661685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6808200.0000, 
sim time next is 6808800.0000, 
raw observation next is [25.66666666666667, 66.66666666666667, 1.0, 2.0, 0.4718307700383521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 568668.5849233386, 568668.5849233386, 138746.6887793381], 
processed observation next is [1.0, 0.8260869565217391, 0.506172839506173, 0.6666666666666667, 1.0, 1.0, 0.3712271071885145, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20309592318690664, 0.20309592318690664, 0.2668205553448809], 
reward next is 0.7332, 
noisyNet noise sample is [array([1.0549898], dtype=float32), 1.0897607]. 
=============================================
[2019-03-22 23:57:28,877] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6089979e-20 3.6099885e-07 3.0144100e-31 9.9999964e-01 8.0206092e-10], sum to 1.0000
[2019-03-22 23:57:28,882] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7129
[2019-03-22 23:57:28,887] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.7, 49.33333333333333, 1.0, 2.0, 0.2498694910960415, 1.0, 2.0, 0.2498694910960415, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 590381.864098681, 590381.8640986815, 169869.8217976366], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6871200.0000, 
sim time next is 6871800.0000, 
raw observation next is [29.85, 49.16666666666667, 1.0, 2.0, 0.2522280355037523, 1.0, 2.0, 0.2522280355037523, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 594869.1208354981, 594869.1208354981, 170355.7457806278], 
processed observation next is [0.0, 0.5217391304347826, 0.6611111111111112, 0.4916666666666667, 1.0, 1.0, 0.10979528036160986, 1.0, 1.0, 0.10979528036160986, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21245325744124932, 0.21245325744124932, 0.32760720342428423], 
reward next is 0.6724, 
noisyNet noise sample is [array([-0.4524014], dtype=float32), -0.86290246]. 
=============================================
[2019-03-22 23:57:31,411] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1217092e-25 1.0000000e+00 1.0870846e-31 6.2540728e-15 2.9687768e-15], sum to 1.0000
[2019-03-22 23:57:31,419] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8352
[2019-03-22 23:57:31,424] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 72.0, 1.0, 2.0, 0.4740147274291922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571511.0733360492, 571511.0733360492, 139087.5552182269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6944400.0000, 
sim time next is 6945000.0000, 
raw observation next is [25.06666666666667, 70.83333333333333, 1.0, 2.0, 0.4777515650307663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 575316.5880734181, 575316.5880734178, 139637.1830764656], 
processed observation next is [0.0, 0.391304347826087, 0.4839506172839507, 0.7083333333333333, 1.0, 1.0, 0.3782756726556742, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20547021002622076, 0.20547021002622062, 0.26853304437781844], 
reward next is 0.7315, 
noisyNet noise sample is [array([0.71286744], dtype=float32), -0.97568005]. 
=============================================
[2019-03-22 23:57:31,435] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[61.77311 ]
 [61.789127]
 [61.813377]
 [61.771465]
 [61.71872 ]], R is [[61.89765549]
 [62.01120377]
 [62.12443542]
 [62.23741913]
 [62.35020447]].
[2019-03-22 23:57:39,916] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-22 23:57:39,916] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:57:39,917] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:57:39,917] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:57:39,918] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:57:39,919] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:57:39,919] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:57:39,920] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:57:39,920] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:57:39,921] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:57:39,926] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:57:39,947] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run17
[2019-03-22 23:57:39,966] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run17
[2019-03-22 23:57:39,966] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run17
[2019-03-22 23:57:40,002] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run17
[2019-03-22 23:57:40,023] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run17
[2019-03-22 23:58:14,172] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3104717], dtype=float32), 0.08359038]
[2019-03-22 23:58:14,174] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.93344128333334, 58.29744845666667, 1.0, 2.0, 0.2590689450962318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 332707.9823376202, 332707.9823376202, 110666.3535860111]
[2019-03-22 23:58:14,176] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:58:14,180] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3141804e-36 1.0000000e+00 0.0000000e+00 1.6457088e-33 6.0667875e-31], sampled 0.8584246767226209
[2019-03-22 23:58:17,196] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3104717], dtype=float32), 0.08359038]
[2019-03-22 23:58:17,197] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.0, 69.0, 1.0, 2.0, 0.568017753725415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664264.8316299624, 664264.8316299624, 153454.0959966837]
[2019-03-22 23:58:17,199] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:58:17,203] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.6856483e-26 1.0000000e+00 7.6292790e-31 3.2563290e-20 1.9770730e-23], sampled 0.2131054897561776
[2019-03-22 23:58:21,096] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3104717], dtype=float32), 0.08359038]
[2019-03-22 23:58:21,097] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.66666666666667, 79.33333333333334, 1.0, 2.0, 0.6633306690244939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 755988.7038668932, 755988.7038668932, 169319.762526092]
[2019-03-22 23:58:21,097] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:58:21,099] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.66287324e-20 1.00000000e+00 1.03749985e-26 5.91895917e-14
 4.85151149e-19], sampled 0.5778094804478608
[2019-03-22 23:58:25,496] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3104717], dtype=float32), 0.08359038]
[2019-03-22 23:58:25,519] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.5, 42.5, 1.0, 2.0, 0.5378371488195902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 631953.3831294867, 631953.3831294867, 148590.0775396554]
[2019-03-22 23:58:25,524] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:58:25,526] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3994117e-30 1.0000000e+00 5.5842439e-35 1.0271166e-24 1.9554820e-27], sampled 0.1540596230133625
[2019-03-22 23:59:05,504] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3104717], dtype=float32), 0.08359038]
[2019-03-22 23:59:05,505] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.5, 62.5, 1.0, 2.0, 0.755923474042412, 1.0, 2.0, 0.755923474042412, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1724096.220793693, 1724096.220793693, 325876.4681635748]
[2019-03-22 23:59:05,506] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:59:05,510] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.2370577e-12 4.5026846e-02 1.1910257e-21 9.5497310e-01 1.2729546e-11], sampled 0.12170103140688027
[2019-03-22 23:59:09,458] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3104717], dtype=float32), 0.08359038]
[2019-03-22 23:59:09,462] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.7, 57.0, 1.0, 2.0, 0.6859660741915264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 781799.1150698224, 781799.1150698224, 173504.4712722531]
[2019-03-22 23:59:09,463] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:59:09,466] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.368038e-24 1.000000e+00 7.084333e-30 5.160653e-16 6.676960e-22], sampled 0.10287911648480064
[2019-03-22 23:59:09,811] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3104717], dtype=float32), 0.08359038]
[2019-03-22 23:59:09,814] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 62.0, 1.0, 2.0, 0.6712248139226913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 764990.0400644573, 764990.0400644573, 170766.0116627313]
[2019-03-22 23:59:09,817] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:59:09,821] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.8143897e-22 1.0000000e+00 1.2336500e-28 2.5783602e-14 4.0210141e-20], sampled 0.796767882582135
[2019-03-22 23:59:31,270] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8893.4189 2156759422.5655 358.0000
[2019-03-22 23:59:31,502] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8748.2142 2225304597.3519 355.0000
[2019-03-22 23:59:31,606] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 9002.5504 2111713629.6129 334.0000
[2019-03-22 23:59:31,668] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8830.7455 2180447470.3217 413.0000
[2019-03-22 23:59:31,761] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8322.7646 2418970357.0031 475.0000
[2019-03-22 23:59:32,775] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 400000, evaluation results [400000.0, 8322.764625869138, 2418970357.0030904, 475.0, 8893.418929807456, 2156759422.565471, 358.0, 9002.550435357572, 2111713629.6128871, 334.0, 8748.21422268147, 2225304597.3518906, 355.0, 8830.745482425866, 2180447470.3216853, 413.0]
[2019-03-22 23:59:36,816] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.8143331e-32 1.0000000e+00 2.5023575e-36 3.9921542e-22 3.5723427e-27], sum to 1.0000
[2019-03-22 23:59:36,826] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8082
[2019-03-22 23:59:36,830] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.93333333333333, 85.33333333333334, 1.0, 2.0, 0.399734527495231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 496111.1239663675, 496111.1239663675, 128599.9512600095], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7105200.0000, 
sim time next is 7105800.0000, 
raw observation next is [20.91666666666667, 85.16666666666667, 1.0, 2.0, 0.3943889358150593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 489743.1032359584, 489743.1032359579, 127855.1367226138], 
processed observation next is [1.0, 0.21739130434782608, 0.3302469135802471, 0.8516666666666667, 1.0, 1.0, 0.2790344473988801, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1749082511556994, 0.17490825115569925, 0.24587526292810347], 
reward next is 0.7541, 
noisyNet noise sample is [array([-0.86214757], dtype=float32), 0.21404618]. 
=============================================
[2019-03-22 23:59:40,585] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.2351012e-33 1.0000000e+00 0.0000000e+00 6.0958676e-27 1.8252689e-21], sum to 1.0000
[2019-03-22 23:59:40,592] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3372
[2019-03-22 23:59:40,596] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 90.33333333333334, 1.0, 2.0, 0.3645360983655273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455727.6475576625, 455727.6475576625, 123816.8826646867], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7170000.0000, 
sim time next is 7170600.0000, 
raw observation next is [19.8, 90.66666666666667, 1.0, 2.0, 0.3666914998481327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 458186.806812319, 458186.806812319, 124103.5866547838], 
processed observation next is [1.0, 1.0, 0.2888888888888889, 0.9066666666666667, 1.0, 1.0, 0.24606130934301512, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16363814529011392, 0.16363814529011392, 0.2386607435668919], 
reward next is 0.7613, 
noisyNet noise sample is [array([-0.01073118], dtype=float32), -0.05024502]. 
=============================================
[2019-03-22 23:59:47,897] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.2693108e-20 1.0000000e+00 1.3663760e-27 4.7991606e-12 2.5927112e-25], sum to 1.0000
[2019-03-22 23:59:47,907] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8331
[2019-03-22 23:59:47,912] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 68.66666666666667, 1.0, 2.0, 0.6220488173526221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156553, 751438.2528803647, 751438.2528803647, 163724.6807120238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7303200.0000, 
sim time next is 7303800.0000, 
raw observation next is [25.4, 67.83333333333333, 1.0, 2.0, 0.6485898456884778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 782688.7223008012, 782688.7223008007, 168516.6636223778], 
processed observation next is [1.0, 0.5217391304347826, 0.49629629629629624, 0.6783333333333332, 1.0, 1.0, 0.5816545782005688, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2795316865360004, 0.27953168653600025, 0.3240705069661111], 
reward next is 0.6759, 
noisyNet noise sample is [array([-0.4456852], dtype=float32), 0.27452737]. 
=============================================
[2019-03-22 23:59:49,823] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.0426943e-27 1.0000000e+00 2.5460835e-35 7.2359669e-17 5.5732745e-31], sum to 1.0000
[2019-03-22 23:59:49,831] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5736
[2019-03-22 23:59:49,836] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 86.33333333333333, 1.0, 2.0, 0.4053860645967617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 501325.623466861, 501325.623466861, 129358.4618981326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7342800.0000, 
sim time next is 7343400.0000, 
raw observation next is [21.03333333333333, 86.16666666666667, 1.0, 2.0, 0.4032714623294372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 499091.1192894863, 499091.1192894863, 129067.8589649362], 
processed observation next is [1.0, 1.0, 0.3345679012345678, 0.8616666666666667, 1.0, 1.0, 0.2896088837255205, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1782468283176737, 0.1782468283176737, 0.24820742108641577], 
reward next is 0.7518, 
noisyNet noise sample is [array([-0.63559043], dtype=float32), -0.55458325]. 
=============================================
[2019-03-22 23:59:52,141] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0634339e-24 9.9999964e-01 6.8446717e-35 3.0206340e-07 7.7593318e-23], sum to 1.0000
[2019-03-22 23:59:52,148] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7568
[2019-03-22 23:59:52,156] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.28333333333333, 96.0, 1.0, 2.0, 0.3912562723295974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 488080.5384705743, 488080.5384705738, 127462.6740672026], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7366200.0000, 
sim time next is 7366800.0000, 
raw observation next is [19.26666666666667, 96.0, 1.0, 2.0, 0.3710361548472507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 462983.9629358673, 462983.9629358673, 124680.7498241881], 
processed observation next is [1.0, 0.2608695652173913, 0.2691358024691359, 0.96, 1.0, 1.0, 0.2512335176752985, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16535141533423833, 0.16535141533423833, 0.23977067273882327], 
reward next is 0.7602, 
noisyNet noise sample is [array([0.44799998], dtype=float32), 0.20488359]. 
=============================================
[2019-03-22 23:59:52,915] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.2228827e-20 6.9767809e-01 4.2831918e-25 3.0232188e-01 1.1405930e-13], sum to 1.0000
[2019-03-22 23:59:52,921] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0922
[2019-03-22 23:59:52,926] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.96666666666667, 92.66666666666667, 1.0, 2.0, 0.4112136055955675, 1.0, 2.0, 0.4112136055955675, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 991793.8625786415, 991793.862578642, 211557.5820919012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7392000.0000, 
sim time next is 7392600.0000, 
raw observation next is [21.05, 92.5, 1.0, 2.0, 0.8533229462045899, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1039262.091460317, 1039262.091460317, 210204.7934858037], 
processed observation next is [1.0, 0.5652173913043478, 0.3351851851851852, 0.925, 1.0, 1.0, 0.825384459767369, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.37116503266439893, 0.37116503266439893, 0.40423998747269946], 
reward next is 0.5958, 
noisyNet noise sample is [array([0.4762581], dtype=float32), -0.58671814]. 
=============================================
[2019-03-22 23:59:53,942] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.2846345e-24 6.2319934e-08 1.6194809e-29 9.9999988e-01 7.2240655e-28], sum to 1.0000
[2019-03-22 23:59:53,949] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7285
[2019-03-22 23:59:53,956] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.3, 91.16666666666667, 1.0, 2.0, 0.3704879065319603, 1.0, 2.0, 0.3704879065319603, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 891360.1030494439, 891360.1030494444, 200215.0584397641], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7397400.0000, 
sim time next is 7398000.0000, 
raw observation next is [21.3, 91.0, 1.0, 2.0, 0.4041961607245662, 1.0, 2.0, 0.4041961607245662, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 972304.9031433752, 972304.9031433756, 209486.9281724183], 
processed observation next is [1.0, 0.6521739130434783, 0.3444444444444445, 0.91, 1.0, 1.0, 0.29070971514829314, 1.0, 1.0, 0.29070971514829314, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.347251751122634, 0.3472517511226342, 0.40285947725465054], 
reward next is 0.5971, 
noisyNet noise sample is [array([-2.2724078], dtype=float32), 0.41207424]. 
=============================================
[2019-03-22 23:59:53,970] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.88809 ]
 [71.74771 ]
 [71.50723 ]
 [71.531685]
 [71.56968 ]], R is [[71.65107727]
 [71.54953766]
 [71.44278717]
 [71.32023621]
 [71.20417023]].
[2019-03-22 23:59:54,125] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2878861e-24 3.9416777e-12 2.3687759e-30 1.0000000e+00 1.1677263e-25], sum to 1.0000
[2019-03-22 23:59:54,134] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9390
[2019-03-22 23:59:54,142] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.23333333333333, 90.33333333333334, 1.0, 2.0, 0.4648789531177886, 1.0, 2.0, 0.4648789531177886, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1117957.814353401, 1117957.814353401, 227186.302771832], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7400400.0000, 
sim time next is 7401000.0000, 
raw observation next is [21.21666666666667, 90.16666666666666, 1.0, 2.0, 0.4666937946566289, 1.0, 2.0, 0.4666937946566289, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1122653.534768328, 1122653.534768328, 227747.4094781604], 
processed observation next is [1.0, 0.6521739130434783, 0.3413580246913581, 0.9016666666666666, 1.0, 1.0, 0.3651116603055107, 1.0, 1.0, 0.3651116603055107, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4009476909886886, 0.4009476909886886, 0.4379757874580008], 
reward next is 0.5620, 
noisyNet noise sample is [array([0.76908696], dtype=float32), -1.2964842]. 
=============================================
[2019-03-22 23:59:54,156] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[72.46969]
 [72.49462]
 [72.34349]
 [72.19111]
 [72.79148]], R is [[72.38221741]
 [72.22149658]
 [72.0728302 ]
 [71.91616058]
 [71.74025726]].
[2019-03-22 23:59:59,185] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.2368973e-35 1.0000000e+00 0.0000000e+00 5.6204699e-27 6.9104659e-37], sum to 1.0000
[2019-03-22 23:59:59,191] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8885
[2019-03-22 23:59:59,196] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 77.66666666666667, 1.0, 2.0, 0.5177964101676649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 613220.9373760974, 613220.9373760974, 145552.7265890935], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7490400.0000, 
sim time next is 7491000.0000, 
raw observation next is [24.93333333333333, 77.83333333333333, 1.0, 2.0, 0.518771437906411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 614468.15821595, 614468.15821595, 145712.3284286327], 
processed observation next is [0.0, 0.6956521739130435, 0.47901234567901224, 0.7783333333333333, 1.0, 1.0, 0.42710885465048926, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21945291364855357, 0.21945291364855357, 0.280216016208909], 
reward next is 0.7198, 
noisyNet noise sample is [array([-1.3452727], dtype=float32), 1.0610453]. 
=============================================
[2019-03-22 23:59:59,214] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.50162 ]
 [72.47254 ]
 [72.444725]
 [72.42366 ]
 [72.42201 ]], R is [[72.51039124]
 [72.50537872]
 [72.50019836]
 [72.49493408]
 [72.48963928]].
[2019-03-23 00:00:14,308] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5993163e-33 1.0000000e+00 9.6701120e-36 3.0952976e-20 1.9740655e-31], sum to 1.0000
[2019-03-23 00:00:14,317] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5527
[2019-03-23 00:00:14,324] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 69.66666666666667, 1.0, 2.0, 0.3855723254357057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479693.6041783362, 479693.6041783362, 126646.9819300293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7766400.0000, 
sim time next is 7767000.0000, 
raw observation next is [22.8, 70.0, 1.0, 2.0, 0.3817335993185477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 475407.2878146591, 475407.2878146591, 126126.8009116573], 
processed observation next is [1.0, 0.9130434782608695, 0.4, 0.7, 1.0, 1.0, 0.2639685706173187, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16978831707666397, 0.16978831707666397, 0.24255154021472555], 
reward next is 0.7574, 
noisyNet noise sample is [array([1.1593227], dtype=float32), 0.89874667]. 
=============================================
[2019-03-23 00:00:14,340] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[70.66376 ]
 [70.4083  ]
 [70.23948 ]
 [70.088356]
 [69.950005]], R is [[70.8650589 ]
 [70.91285706]
 [70.95895386]
 [71.00389862]
 [71.04853058]].
[2019-03-23 00:00:23,831] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:00:23,831] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:23,858] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run3
[2019-03-23 00:00:24,882] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:00:24,883] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:24,884] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run3
[2019-03-23 00:00:25,027] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:00:25,028] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:25,031] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run3
[2019-03-23 00:00:25,190] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0981176e-30 2.2315124e-14 1.7280582e-35 1.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:00:25,190] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5688
[2019-03-23 00:00:25,191] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.46666666666667, 61.0, 1.0, 2.0, 0.2132544292429453, 1.0, 2.0, 0.2132544292429453, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 518637.7785320054, 518637.7785320059, 162442.059686386], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 80400.0000, 
sim time next is 81000.0000, 
raw observation next is [25.3, 62.0, 1.0, 2.0, 0.213576424107767, 1.0, 2.0, 0.213576424107767, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 519330.9272859807, 519330.9272859811, 162508.0025736791], 
processed observation next is [1.0, 0.9565217391304348, 0.49259259259259264, 0.62, 1.0, 1.0, 0.0637814572711512, 1.0, 1.0, 0.0637814572711512, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18547533117356454, 0.18547533117356466, 0.31251538956476754], 
reward next is 0.6875, 
noisyNet noise sample is [array([1.0566547], dtype=float32), 1.4535803]. 
=============================================
[2019-03-23 00:00:25,193] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[69.78282 ]
 [69.729576]
 [69.731834]
 [69.695816]
 [69.796936]], R is [[69.78929138]
 [69.77901459]
 [69.76907349]
 [69.75934601]
 [69.74960327]].
[2019-03-23 00:00:25,288] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:00:25,289] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:25,290] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run3
[2019-03-23 00:00:25,321] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:00:25,321] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:25,324] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run3
[2019-03-23 00:00:25,349] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:00:25,349] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:25,352] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run3
[2019-03-23 00:00:25,410] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:00:25,411] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:25,412] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run3
[2019-03-23 00:00:25,466] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:00:25,466] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:25,468] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run3
[2019-03-23 00:00:25,484] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:00:25,484] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:25,486] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run3
[2019-03-23 00:00:25,596] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:00:25,596] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:25,597] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run3
[2019-03-23 00:00:25,617] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:00:25,618] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:25,620] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run3
[2019-03-23 00:00:25,634] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:00:25,635] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:25,636] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run3
[2019-03-23 00:00:25,668] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:00:25,668] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:25,670] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run3
[2019-03-23 00:00:25,695] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:00:25,695] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:25,699] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run3
[2019-03-23 00:00:25,730] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:00:25,730] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:25,731] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run3
[2019-03-23 00:00:25,766] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:00:25,766] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:25,768] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run3
[2019-03-23 00:00:27,820] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 00:00:27,823] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:00:27,824] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:27,826] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:00:27,827] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:27,828] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:00:27,829] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:00:27,832] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:27,833] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:27,831] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:00:27,836] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:00:27,849] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run18
[2019-03-23 00:00:27,866] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run18
[2019-03-23 00:00:27,888] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run18
[2019-03-23 00:00:27,889] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run18
[2019-03-23 00:00:27,889] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run18
[2019-03-23 00:00:56,437] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3272761], dtype=float32), -0.07229892]
[2019-03-23 00:00:56,438] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.83244354333333, 87.92584121833333, 1.0, 2.0, 0.4530988509520846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 551983.2944756269, 551983.2944756264, 136103.8649391662]
[2019-03-23 00:00:56,438] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:00:56,441] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 5.062714e-22 0.000000e+00], sampled 0.49194593116153884
[2019-03-23 00:00:58,997] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3272761], dtype=float32), -0.07229892]
[2019-03-23 00:00:58,998] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.33333333333334, 47.66666666666667, 1.0, 2.0, 0.6233822553127112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 752493.539551788, 752493.539551788, 163945.0135904758]
[2019-03-23 00:00:58,998] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:00:59,003] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.0720352e-37 9.9999833e-01 5.5109953e-34 1.7217180e-06 6.0884394e-36], sampled 0.8037600633852893
[2019-03-23 00:01:09,484] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3272761], dtype=float32), -0.07229892]
[2019-03-23 00:01:09,485] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.0, 89.0, 1.0, 2.0, 0.5891511232316211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 674969.0508324446, 674969.0508324441, 156397.521387709]
[2019-03-23 00:01:09,486] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:01:09,488] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.1111109e-35 8.6933154e-01 4.3022513e-33 1.3066843e-01 9.8924462e-35], sampled 0.9074612412617488
[2019-03-23 00:01:27,637] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3272761], dtype=float32), -0.07229892]
[2019-03-23 00:01:27,638] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.09257766833334, 84.29446785166667, 1.0, 2.0, 0.4158497028537805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 509540.2272941553, 509540.2272941548, 130732.5534972409]
[2019-03-23 00:01:27,639] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:01:27,643] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.8202064e-13 0.0000000e+00], sampled 0.603632547636118
[2019-03-23 00:01:39,963] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3272761], dtype=float32), -0.07229892]
[2019-03-23 00:01:39,964] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.46666666666667, 86.0, 1.0, 2.0, 0.3737650683205926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 466463.3491664723, 466463.3491664723, 125053.7686255861]
[2019-03-23 00:01:39,966] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:01:39,969] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.000000e+00 1.000000e+00 0.000000e+00 5.603476e-18 0.000000e+00], sampled 0.30353397561470663
[2019-03-23 00:01:54,264] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3272761], dtype=float32), -0.07229892]
[2019-03-23 00:01:54,265] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.54973009, 68.62989766, 1.0, 2.0, 0.530183232802184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 617678.7299558058, 617678.7299558063, 147123.2236092256]
[2019-03-23 00:01:54,266] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:01:54,269] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.3630984e-38 6.4445166e-19 0.0000000e+00], sampled 0.3654241251655882
[2019-03-23 00:02:04,296] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3272761], dtype=float32), -0.07229892]
[2019-03-23 00:02:04,297] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.86666666666667, 90.0, 1.0, 2.0, 0.5555032486122875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 649932.2323875384, 649932.2323875384, 151378.616992121]
[2019-03-23 00:02:04,298] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:02:04,300] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.0592927e-33 9.9936861e-01 2.1477766e-29 6.3142157e-04 1.5621925e-34], sampled 0.22135969657846855
[2019-03-23 00:02:12,509] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3272761], dtype=float32), -0.07229892]
[2019-03-23 00:02:12,511] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.0, 23.5, 1.0, 2.0, 0.4812788738465911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607855.691555713, 607855.691555713, 140858.334578017]
[2019-03-23 00:02:12,513] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:02:12,515] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.4611992e-37 2.4485359e-12 0.0000000e+00], sampled 0.9139876314737768
[2019-03-23 00:02:12,707] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3272761], dtype=float32), -0.07229892]
[2019-03-23 00:02:12,709] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.31666666666667, 81.33333333333334, 1.0, 2.0, 0.5125409392975605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 608200.827888743, 608200.8278887435, 144761.6225266075]
[2019-03-23 00:02:12,710] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:02:12,715] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7729063e-38 1.0000000e+00 1.9753205e-34 2.1296991e-09 2.2791850e-38], sampled 0.9590306604705275
[2019-03-23 00:02:19,160] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8441.1190 2429995239.6339 253.0000
[2019-03-23 00:02:20,131] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8923.5649 2195382751.4501 211.0000
[2019-03-23 00:02:20,133] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8946.9078 2171825807.1055 208.0000
[2019-03-23 00:02:20,208] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 9048.4622 2131123039.5405 191.0000
[2019-03-23 00:02:20,215] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8848.6219 2233255462.0272 182.0000
[2019-03-23 00:02:21,232] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 425000, evaluation results [425000.0, 8441.11896531459, 2429995239.6338677, 253.0, 8946.90775117063, 2171825807.105488, 208.0, 9048.462244008348, 2131123039.5405498, 191.0, 8848.621870351124, 2233255462.027162, 182.0, 8923.564912719588, 2195382751.450123, 211.0]
[2019-03-23 00:02:22,565] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4428834e-27 2.1699408e-08 7.2170813e-25 1.0000000e+00 1.4638798e-26], sum to 1.0000
[2019-03-23 00:02:22,575] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0298
[2019-03-23 00:02:22,581] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.5, 47.0, 1.0, 2.0, 0.2717951904570061, 1.0, 1.0, 0.2717951904570061, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 694242.1632680318, 694242.1632680323, 176265.4164493366], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 30600.0000, 
sim time next is 31200.0000, 
raw observation next is [23.73333333333333, 46.66666666666666, 1.0, 2.0, 0.3044729613069702, 1.0, 2.0, 0.3044729613069702, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 774765.7108139023, 774765.7108139028, 184188.0281215314], 
processed observation next is [1.0, 0.34782608695652173, 0.4345679012345678, 0.46666666666666656, 1.0, 1.0, 0.17199162060353598, 1.0, 1.0, 0.17199162060353598, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27670203957639367, 0.27670203957639383, 0.35420774638756036], 
reward next is 0.6458, 
noisyNet noise sample is [array([-0.92248124], dtype=float32), 0.085382715]. 
=============================================
[2019-03-23 00:02:23,250] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5817927e-27 1.4837104e-16 8.4036289e-27 1.0000000e+00 5.4994823e-24], sum to 1.0000
[2019-03-23 00:02:23,264] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3403
[2019-03-23 00:02:23,271] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.03333333333333, 36.83333333333334, 1.0, 2.0, 0.6059535597779, 1.0, 2.0, 0.6059535597779, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1465399.252876255, 1465399.252876256, 273660.0696970102], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 53400.0000, 
sim time next is 54000.0000, 
raw observation next is [30.0, 37.0, 1.0, 2.0, 0.6148425903258832, 1.0, 2.0, 0.6148425903258832, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1486019.685195649, 1486019.685195649, 276780.5247266053], 
processed observation next is [1.0, 0.6521739130434783, 0.6666666666666666, 0.37, 1.0, 1.0, 0.54147927419748, 1.0, 1.0, 0.54147927419748, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5307213161413032, 0.5307213161413032, 0.5322702398588564], 
reward next is 0.4677, 
noisyNet noise sample is [array([-0.33407363], dtype=float32), -0.42152384]. 
=============================================
[2019-03-23 00:02:23,287] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[59.826626]
 [60.03196 ]
 [60.401093]
 [60.360073]
 [60.44194 ]], R is [[59.58968735]
 [59.46752167]
 [59.35657883]
 [59.28350067]
 [59.20484543]].
[2019-03-23 00:02:27,391] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7392298e-17 1.1663661e-06 2.2350727e-16 9.9999881e-01 1.6530517e-23], sum to 1.0000
[2019-03-23 00:02:27,400] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4388
[2019-03-23 00:02:27,405] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.85, 31.5, 1.0, 2.0, 0.1705107891190356, 1.0, 2.0, 0.1705107891190356, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 430147.4844558142, 430147.4844558146, 153972.3682807724], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 414600.0000, 
sim time next is 415200.0000, 
raw observation next is [28.7, 32.0, 1.0, 2.0, 0.1697576127314115, 1.0, 2.0, 0.1697576127314115, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 428288.7450780167, 428288.7450780172, 153818.9840165661], 
processed observation next is [1.0, 0.8260869565217391, 0.6185185185185185, 0.32, 1.0, 1.0, 0.011616205632632721, 1.0, 1.0, 0.011616205632632721, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15296026609929167, 0.15296026609929184, 0.29580573849339636], 
reward next is 0.7042, 
noisyNet noise sample is [array([-0.1804594], dtype=float32), -0.7681182]. 
=============================================
[2019-03-23 00:02:28,128] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 0. 0. 1. 0.], sum to 1.0000
[2019-03-23 00:02:28,139] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6273
[2019-03-23 00:02:28,144] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.4, 15.0, 1.0, 2.0, 0.645663349887818, 1.0, 2.0, 0.645663349887818, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1572331.78599953, 1572331.78599953, 288310.0341351776], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 136800.0000, 
sim time next is 137400.0000, 
raw observation next is [37.4, 14.5, 1.0, 2.0, 0.7034222566604662, 1.0, 2.0, 0.7034222566604662, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1714641.260415463, 1714641.260415463, 310183.1241575367], 
processed observation next is [1.0, 0.6086956521739131, 0.9407407407407407, 0.145, 1.0, 1.0, 0.6469312579291264, 1.0, 1.0, 0.6469312579291264, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6123718787198082, 0.6123718787198082, 0.5965060079952629], 
reward next is 0.4035, 
noisyNet noise sample is [array([-0.6568531], dtype=float32), -1.8535889]. 
=============================================
[2019-03-23 00:02:29,302] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1399392e-19 3.0313313e-01 1.2645533e-20 6.9686687e-01 1.0454040e-28], sum to 1.0000
[2019-03-23 00:02:29,312] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3207
[2019-03-23 00:02:29,317] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.93333333333334, 14.33333333333333, 1.0, 2.0, 0.1818195843265601, 1.0, 2.0, 0.1818195843265601, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 467989.592787864, 467989.592787864, 156374.1055150606], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 160800.0000, 
sim time next is 161400.0000, 
raw observation next is [31.86666666666667, 14.16666666666667, 1.0, 2.0, 0.1821585381918186, 1.0, 2.0, 0.1821585381918186, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 469186.2173744583, 469186.2173744587, 156441.0463436729], 
processed observation next is [1.0, 0.8695652173913043, 0.7358024691358026, 0.1416666666666667, 1.0, 1.0, 0.026379212133117374, 1.0, 1.0, 0.026379212133117374, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1675665062051637, 0.1675665062051638, 0.30084816604552483], 
reward next is 0.6992, 
noisyNet noise sample is [array([-0.51500756], dtype=float32), 1.1435828]. 
=============================================
[2019-03-23 00:02:29,987] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.7783809e-31 1.0000000e+00 6.0904578e-25 1.8605658e-14 1.3601847e-31], sum to 1.0000
[2019-03-23 00:02:29,997] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1485
[2019-03-23 00:02:30,003] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.55, 13.0, 1.0, 2.0, 0.3593985123188697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 463635.8160297155, 463635.8160297155, 113185.8445341904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 163800.0000, 
sim time next is 164400.0000, 
raw observation next is [31.46666666666667, 12.66666666666667, 1.0, 2.0, 0.3579073524266116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 461711.5919513475, 461711.5919513475, 111986.5870965032], 
processed observation next is [1.0, 0.9130434782608695, 0.7209876543209878, 0.1266666666666667, 1.0, 1.0, 0.23560399098406143, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16489699712548125, 0.16489699712548125, 0.2153588213394292], 
reward next is 0.7846, 
noisyNet noise sample is [array([0.08172911], dtype=float32), 1.0267321]. 
=============================================
[2019-03-23 00:02:38,433] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 2.266605e-30 0.000000e+00], sum to 1.0000
[2019-03-23 00:02:38,445] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6757
[2019-03-23 00:02:38,451] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 30.0, 1.0, 2.0, 0.314258748872469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 405388.6552993165, 405388.655299316, 113466.7596223942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 302400.0000, 
sim time next is 303000.0000, 
raw observation next is [26.7, 30.16666666666666, 1.0, 2.0, 0.3195674631771831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 412238.6507264663, 412238.6507264663, 115532.5916176425], 
processed observation next is [0.0, 0.5217391304347826, 0.5444444444444444, 0.3016666666666666, 1.0, 1.0, 0.18996126568712274, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14722808954516656, 0.14722808954516656, 0.22217806080315863], 
reward next is 0.7778, 
noisyNet noise sample is [array([-1.1389571], dtype=float32), 0.7239323]. 
=============================================
[2019-03-23 00:02:38,476] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[87.50539]
 [87.49761]
 [87.37194]
 [87.32083]
 [87.11187]], R is [[87.50100708]
 [87.40779114]
 [87.31785583]
 [87.23110199]
 [87.14743805]].
[2019-03-23 00:02:44,428] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7130033e-26 1.0000000e+00 2.0861745e-31 5.8843222e-18 5.0560518e-31], sum to 1.0000
[2019-03-23 00:02:44,438] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0939
[2019-03-23 00:02:44,444] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 38.0, 1.0, 2.0, 0.3136754477819499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 400519.385772969, 400519.385772969, 117282.5242185253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 424800.0000, 
sim time next is 425400.0000, 
raw observation next is [26.25, 38.33333333333334, 1.0, 2.0, 0.311753491638161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 398265.748650837, 398265.748650837, 117041.0589012262], 
processed observation next is [1.0, 0.9565217391304348, 0.5277777777777778, 0.3833333333333334, 1.0, 1.0, 0.18065891861685834, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14223776737529892, 0.14223776737529892, 0.22507895942543502], 
reward next is 0.7749, 
noisyNet noise sample is [array([-0.89750993], dtype=float32), 1.5672388]. 
=============================================
[2019-03-23 00:02:45,952] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6321871e-23 1.5599525e-17 9.1699278e-33 1.0000000e+00 4.0882142e-29], sum to 1.0000
[2019-03-23 00:02:45,962] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2148
[2019-03-23 00:02:45,968] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.8, 46.5, 1.0, 2.0, 0.544495855896356, 1.0, 2.0, 0.544495855896356, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1315978.376363218, 1315978.376363219, 252615.8819835623], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 732600.0000, 
sim time next is 733200.0000, 
raw observation next is [28.1, 44.66666666666667, 1.0, 2.0, 0.5655995086809508, 1.0, 2.0, 0.5655995086809508, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1368416.158527795, 1368416.158527796, 259729.4848441482], 
processed observation next is [1.0, 0.4782608695652174, 0.5962962962962963, 0.4466666666666667, 1.0, 1.0, 0.4828565579535128, 1.0, 1.0, 0.4828565579535128, 0.0, 1.0, -0.25, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.48872005661706963, 0.48872005661706996, 0.4994797785464388], 
reward next is 0.5005, 
noisyNet noise sample is [array([1.9584159], dtype=float32), 0.897339]. 
=============================================
[2019-03-23 00:02:59,521] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2214593e-23 2.5620405e-14 7.4372265e-27 1.0000000e+00 4.4048992e-34], sum to 1.0000
[2019-03-23 00:02:59,527] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1871
[2019-03-23 00:02:59,532] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.60000000000001, 17.66666666666667, 1.0, 2.0, 0.6551335308237641, 1.0, 2.0, 0.6551335308237641, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1601462.720245872, 1601462.720245872, 291995.6185300456], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 663600.0000, 
sim time next is 664200.0000, 
raw observation next is [35.6, 17.5, 1.0, 2.0, 0.6624084384526311, 1.0, 2.0, 0.6624084384526311, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1619142.046871172, 1619142.046871172, 294702.6876266095], 
processed observation next is [1.0, 0.6956521739130435, 0.8740740740740741, 0.175, 1.0, 1.0, 0.5981052838721799, 1.0, 1.0, 0.5981052838721799, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5782650167397043, 0.5782650167397043, 0.5667359377434799], 
reward next is 0.4333, 
noisyNet noise sample is [array([-1.4117708], dtype=float32), 0.45745927]. 
=============================================
[2019-03-23 00:03:05,236] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2225433e-34 1.0000000e+00 7.2130225e-36 3.8725153e-16 9.2817840e-38], sum to 1.0000
[2019-03-23 00:03:05,239] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3467
[2019-03-23 00:03:05,244] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.46666666666667, 47.33333333333334, 1.0, 2.0, 0.2998614427290731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 382578.1213842436, 382578.1213842436, 115558.1620484562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 782400.0000, 
sim time next is 783000.0000, 
raw observation next is [24.3, 48.0, 1.0, 2.0, 0.2999448921115587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 382784.5362341509, 382784.5362341509, 115568.7550491971], 
processed observation next is [0.0, 0.043478260869565216, 0.4555555555555556, 0.48, 1.0, 1.0, 0.1666010620375699, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13670876294076817, 0.13670876294076817, 0.2222476058638406], 
reward next is 0.7778, 
noisyNet noise sample is [array([-0.64303786], dtype=float32), -0.69612926]. 
=============================================
[2019-03-23 00:03:05,272] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[78.857895]
 [78.89227 ]
 [78.99037 ]
 [79.005424]
 [78.91121 ]], R is [[78.83380127]
 [78.82323456]
 [78.81311798]
 [78.80303955]
 [78.79302216]].
[2019-03-23 00:03:10,028] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7024967e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 00:03:10,038] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9472
[2019-03-23 00:03:10,041] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 41.0, 1.0, 2.0, 0.3844425982907185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478574.355408374, 478574.355408374, 126496.4939385611], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 849600.0000, 
sim time next is 850200.0000, 
raw observation next is [28.23333333333333, 41.83333333333334, 1.0, 2.0, 0.3835154952163944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477469.0954631955, 477469.0954631955, 126369.5200253271], 
processed observation next is [0.0, 0.8695652173913043, 0.6012345679012344, 0.41833333333333345, 1.0, 1.0, 0.26608987525761235, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17052467695114126, 0.17052467695114126, 0.24301830774101366], 
reward next is 0.7570, 
noisyNet noise sample is [array([-0.27282164], dtype=float32), 1.4723793]. 
=============================================
[2019-03-23 00:03:15,354] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 00:03:15,357] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:03:15,357] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:03:15,357] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:03:15,358] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:03:15,358] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:03:15,359] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:03:15,359] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:03:15,360] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:03:15,360] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:03:15,360] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:03:15,383] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run19
[2019-03-23 00:03:15,400] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run19
[2019-03-23 00:03:15,419] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run19
[2019-03-23 00:03:15,442] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run19
[2019-03-23 00:03:15,464] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run19
[2019-03-23 00:03:25,308] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.25390667], dtype=float32), -0.09516915]
[2019-03-23 00:03:25,310] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.36666666666667, 19.33333333333334, 1.0, 2.0, 0.5432272260907862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688074.8207142466, 688074.8207142466, 150872.8350182961]
[2019-03-23 00:03:25,311] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:03:25,313] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.0208736e-28 1.0000000e+00 5.0687757e-32 3.4574656e-11 2.1767314e-30], sampled 0.5975591426492162
[2019-03-23 00:03:26,356] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.25390667], dtype=float32), -0.09516915]
[2019-03-23 00:03:26,357] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.9, 52.0, 1.0, 2.0, 0.5589732634616651, 1.0, 2.0, 0.5589732634616651, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1346708.108182974, 1346708.108182974, 257300.3670021586]
[2019-03-23 00:03:26,358] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:03:26,361] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.84966350e-27 2.06352115e-17 8.05900376e-34 1.00000000e+00
 1.09801705e-30], sampled 0.13713929244714584
[2019-03-23 00:03:33,792] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.25390667], dtype=float32), -0.09516915]
[2019-03-23 00:03:33,794] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [38.23333333333333, 17.0, 1.0, 2.0, 0.6637035537925844, 1.0, 2.0, 0.6637035537925844, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1588040.959016452, 1588040.959016452, 294005.9888482906]
[2019-03-23 00:03:33,796] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:03:33,798] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.47593222e-28 2.57611505e-13 1.08036615e-32 1.00000000e+00
 3.55199157e-32], sampled 0.22863941426692658
[2019-03-23 00:03:42,823] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.25390667], dtype=float32), -0.09516915]
[2019-03-23 00:03:42,825] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.66666666666667, 95.66666666666667, 1.0, 2.0, 0.3354422168742052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 422118.4421393214, 422118.4421393214, 120014.8295307615]
[2019-03-23 00:03:42,826] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:03:42,829] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.8519658e-29 1.0000000e+00 5.3421649e-33 1.2942660e-12 2.3619930e-28], sampled 0.6380035700791461
[2019-03-23 00:03:44,597] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.25390667], dtype=float32), -0.09516915]
[2019-03-23 00:03:44,600] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.8, 78.0, 1.0, 2.0, 0.5207823362725307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 617626.6837530661, 617626.6837530661, 146064.6595756334]
[2019-03-23 00:03:44,601] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:03:44,604] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.9811219e-24 1.0000000e+00 1.2592834e-27 9.1278629e-09 4.7514159e-27], sampled 0.17207252934998662
[2019-03-23 00:05:02,254] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.25390667], dtype=float32), -0.09516915]
[2019-03-23 00:05:02,255] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.0, 99.00000000000001, 1.0, 2.0, 0.2946659450655418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 376164.6217577424, 376164.6217577424, 114919.2443265536]
[2019-03-23 00:05:02,255] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:05:02,258] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.2837525e-32 1.0000000e+00 7.1158996e-34 1.1261597e-21 7.9390943e-32], sampled 0.3557754734220011
[2019-03-23 00:05:06,362] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.25390667], dtype=float32), -0.09516915]
[2019-03-23 00:05:06,364] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.87226234666667, 52.74791718333333, 1.0, 2.0, 0.3672741231937405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457455.0138099652, 457455.0138099652, 124154.7622154095]
[2019-03-23 00:05:06,366] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:05:06,368] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.6396736e-34 1.0000000e+00 4.2411076e-37 1.7821588e-19 1.8130235e-33], sampled 0.40809349101428327
[2019-03-23 00:05:06,569] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8470.9533 2438791895.2573 175.0000
[2019-03-23 00:05:06,945] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8972.0976 2176953089.1029 148.0000
[2019-03-23 00:05:07,211] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8932.7474 2203833853.8153 160.0000
[2019-03-23 00:05:07,234] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8865.3133 2240881537.5911 126.0000
[2019-03-23 00:05:07,410] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 9052.6416 2142606095.2013 143.0000
[2019-03-23 00:05:08,425] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 450000, evaluation results [450000.0, 8470.95331605651, 2438791895.2573433, 175.0, 8972.097637735304, 2176953089.102858, 148.0, 9052.641598014605, 2142606095.2012515, 143.0, 8865.313318561335, 2240881537.591122, 126.0, 8932.747434517125, 2203833853.815297, 160.0]
[2019-03-23 00:05:09,805] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.0077837e-23 9.9999988e-01 8.2723548e-29 9.5293906e-08 2.0721157e-20], sum to 1.0000
[2019-03-23 00:05:09,807] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6433
[2019-03-23 00:05:09,813] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.98333333333333, 60.16666666666666, 1.0, 2.0, 0.2841926275513607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 366104.5798217494, 366104.5798217494, 113635.5158058753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 971400.0000, 
sim time next is 972000.0000, 
raw observation next is [21.1, 60.0, 1.0, 2.0, 0.2722196607955395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 350437.1718881113, 350437.1718881113, 112204.8749784155], 
processed observation next is [1.0, 0.2608695652173913, 0.3370370370370371, 0.6, 1.0, 1.0, 0.13359483428040417, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1251561328171826, 0.1251561328171826, 0.2157786057277221], 
reward next is 0.7842, 
noisyNet noise sample is [array([0.37834328], dtype=float32), -0.93976766]. 
=============================================
[2019-03-23 00:05:09,846] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[70.26288 ]
 [70.33558 ]
 [70.472404]
 [70.51207 ]
 [70.53568 ]], R is [[70.30963898]
 [70.38801575]
 [70.4678421 ]
 [70.55025482]
 [70.63426208]].
[2019-03-23 00:05:10,427] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5831507e-25 9.9999833e-01 1.6512525e-33 1.6369818e-06 3.4737752e-29], sum to 1.0000
[2019-03-23 00:05:10,433] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8631
[2019-03-23 00:05:10,440] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.86666666666667, 58.0, 1.0, 2.0, 0.4618963434807709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 587209.8712836981, 587209.8712836981, 137907.457497546], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 980400.0000, 
sim time next is 981000.0000, 
raw observation next is [23.0, 58.0, 1.0, 2.0, 0.5249566502123452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666343.8320234707, 666343.8320234707, 147866.2089718646], 
processed observation next is [1.0, 0.34782608695652173, 0.4074074074074074, 0.58, 1.0, 1.0, 0.4344722026337442, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23797994000838238, 0.23797994000838238, 0.2843580941766627], 
reward next is 0.7156, 
noisyNet noise sample is [array([-0.409371], dtype=float32), -1.405161]. 
=============================================
[2019-03-23 00:05:10,452] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.86333]
 [72.46869]
 [72.35468]
 [72.29381]
 [72.28264]], R is [[71.42407227]
 [71.44462585]
 [71.49765778]
 [71.54800415]
 [71.59507751]].
[2019-03-23 00:05:10,703] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9284468e-22 3.9186515e-02 1.5956114e-24 9.6081352e-01 1.8508338e-26], sum to 1.0000
[2019-03-23 00:05:10,711] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5235
[2019-03-23 00:05:10,715] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.28333333333333, 53.33333333333334, 1.0, 2.0, 0.3529950253769948, 1.0, 2.0, 0.3529950253769948, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 870666.5193776597, 870666.5193776601, 196206.5082876731], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 996600.0000, 
sim time next is 997200.0000, 
raw observation next is [25.3, 53.0, 1.0, 2.0, 0.379126198945928, 1.0, 2.0, 0.379126198945928, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 935030.0220706499, 935030.0220706504, 203244.1607152802], 
processed observation next is [1.0, 0.5652173913043478, 0.49259259259259264, 0.53, 1.0, 1.0, 0.2608645225546762, 1.0, 1.0, 0.2608645225546762, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3339392935966607, 0.33393929359666086, 0.39085415522169265], 
reward next is 0.6091, 
noisyNet noise sample is [array([0.18927334], dtype=float32), 1.5067822]. 
=============================================
[2019-03-23 00:05:14,084] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.3269047e-37 1.0000000e+00 1.6554597e-36 1.2351876e-24 1.0946679e-36], sum to 1.0000
[2019-03-23 00:05:14,086] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7625
[2019-03-23 00:05:14,092] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 63.33333333333333, 1.0, 2.0, 0.2963253524574443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 378461.6701397922, 378461.6701397922, 115123.4635584812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1042800.0000, 
sim time next is 1043400.0000, 
raw observation next is [21.4, 64.16666666666667, 1.0, 2.0, 0.2974432789275849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 379786.1452795098, 379786.1452795098, 115260.7638705559], 
processed observation next is [1.0, 0.043478260869565216, 0.3481481481481481, 0.6416666666666667, 1.0, 1.0, 0.16362295110426772, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13563790902839634, 0.13563790902839634, 0.2216553151356844], 
reward next is 0.7783, 
noisyNet noise sample is [array([-0.16622071], dtype=float32), 1.1928375]. 
=============================================
[2019-03-23 00:05:14,316] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3140306e-20 1.0299535e-01 2.3951873e-21 8.9700466e-01 3.6446531e-21], sum to 1.0000
[2019-03-23 00:05:14,321] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4483
[2019-03-23 00:05:14,324] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.88333333333333, 30.33333333333333, 1.0, 2.0, 0.49120139860705, 1.0, 2.0, 0.49120139860705, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1205553.643861787, 1205553.643861787, 236031.2810797171], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1353000.0000, 
sim time next is 1353600.0000, 
raw observation next is [30.9, 30.0, 1.0, 2.0, 0.5020833545069063, 1.0, 2.0, 0.5020833545069063, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1233162.926803434, 1233162.926803434, 239488.2474131285], 
processed observation next is [1.0, 0.6956521739130435, 0.7, 0.3, 1.0, 1.0, 0.407242088698698, 1.0, 1.0, 0.407242088698698, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.44041533100122643, 0.44041533100122643, 0.460554321948324], 
reward next is 0.5394, 
noisyNet noise sample is [array([0.28965768], dtype=float32), 0.2994834]. 
=============================================
[2019-03-23 00:05:15,468] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5942630e-20 9.9922454e-01 9.3037851e-23 7.7550637e-04 2.1674267e-27], sum to 1.0000
[2019-03-23 00:05:15,477] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1574
[2019-03-23 00:05:15,482] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.45, 41.5, 1.0, 2.0, 0.8007193382535303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1013692.551218674, 1013692.551218674, 199749.4693671814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1085400.0000, 
sim time next is 1086000.0000, 
raw observation next is [26.6, 41.0, 1.0, 2.0, 0.7445403944136331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 942144.800179556, 942144.800179556, 188071.7267327866], 
processed observation next is [1.0, 0.5652173913043478, 0.5407407407407407, 0.41, 1.0, 1.0, 0.6958814219209918, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3364802857784129, 0.3364802857784129, 0.36167639756305114], 
reward next is 0.6383, 
noisyNet noise sample is [array([0.5784851], dtype=float32), -0.06095946]. 
=============================================
[2019-03-23 00:05:15,494] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[69.20809 ]
 [70.05337 ]
 [71.09922 ]
 [70.944336]
 [70.3441  ]], R is [[68.98258972]
 [68.90863037]
 [68.86886597]
 [68.90576935]
 [68.93273926]].
[2019-03-23 00:05:19,272] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.1473134e-34 1.0000000e+00 1.1314987e-37 2.7990315e-16 6.9168392e-32], sum to 1.0000
[2019-03-23 00:05:19,283] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1351
[2019-03-23 00:05:19,290] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.8, 76.0, 1.0, 2.0, 0.2753330341213774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 354384.7653625085, 354384.7653625085, 112575.3639457074], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1137600.0000, 
sim time next is 1138200.0000, 
raw observation next is [18.78333333333333, 76.16666666666667, 1.0, 2.0, 0.3070924769596058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 395241.6124165848, 395241.6124165848, 116449.8029586527], 
processed observation next is [1.0, 0.17391304347826086, 0.2512345679012345, 0.7616666666666667, 1.0, 1.0, 0.17511009161857832, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14115771872020885, 0.14115771872020885, 0.2239419287666398], 
reward next is 0.7761, 
noisyNet noise sample is [array([-0.6889095], dtype=float32), 0.71928394]. 
=============================================
[2019-03-23 00:05:19,606] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.2511985e-30 1.0000000e+00 3.5700238e-36 4.3337919e-21 7.0014172e-32], sum to 1.0000
[2019-03-23 00:05:19,618] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7589
[2019-03-23 00:05:19,623] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 87.0, 1.0, 2.0, 0.3496685356910281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 440360.8727622697, 440360.8727622697, 121883.1472581562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1198800.0000, 
sim time next is 1199400.0000, 
raw observation next is [19.53333333333333, 87.5, 1.0, 2.0, 0.3486061527907757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 439025.5540117469, 439025.5540117469, 121742.7293303875], 
processed observation next is [1.0, 0.9130434782608695, 0.2790123456790123, 0.875, 1.0, 1.0, 0.224531134274733, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15679484071848104, 0.15679484071848104, 0.23412063332766828], 
reward next is 0.7659, 
noisyNet noise sample is [array([0.58236885], dtype=float32), 0.21329042]. 
=============================================
[2019-03-23 00:05:27,957] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.6337449e-26 1.0000000e+00 3.4132336e-32 7.6304735e-12 4.2396702e-21], sum to 1.0000
[2019-03-23 00:05:27,965] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2196
[2019-03-23 00:05:27,971] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 86.0, 1.0, 2.0, 0.3398071593900392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428952.4487423316, 428952.4487423316, 120600.0294985825], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1303200.0000, 
sim time next is 1303800.0000, 
raw observation next is [19.43333333333333, 86.33333333333334, 1.0, 2.0, 0.4261812072597121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 538146.7482948789, 538146.7482948793, 132544.0164826782], 
processed observation next is [1.0, 0.08695652173913043, 0.2753086419753085, 0.8633333333333334, 1.0, 1.0, 0.31688238959489534, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19219526724817101, 0.19219526724817118, 0.2548923393897658], 
reward next is 0.7451, 
noisyNet noise sample is [array([-0.6983676], dtype=float32), -0.75578624]. 
=============================================
[2019-03-23 00:05:29,795] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4490971e-16 1.1136839e-08 3.3820558e-21 1.0000000e+00 6.3166948e-24], sum to 1.0000
[2019-03-23 00:05:29,803] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6049
[2019-03-23 00:05:29,808] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.71666666666667, 32.83333333333334, 1.0, 2.0, 0.4588788625056869, 1.0, 2.0, 0.4588788625056869, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1118785.988859834, 1118785.988859834, 225870.9474517092], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1347000.0000, 
sim time next is 1347600.0000, 
raw observation next is [30.73333333333333, 32.66666666666667, 1.0, 2.0, 0.4501375456122958, 1.0, 2.0, 0.4501375456122958, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1100014.66990259, 1100014.669902591, 223323.499456283], 
processed observation next is [1.0, 0.6086956521739131, 0.6938271604938271, 0.3266666666666667, 1.0, 1.0, 0.3454018400146378, 1.0, 1.0, 0.3454018400146378, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3928623821080679, 0.39286238210806823, 0.4294682681851596], 
reward next is 0.5705, 
noisyNet noise sample is [array([-0.5237064], dtype=float32), -1.8460637]. 
=============================================
[2019-03-23 00:05:31,104] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.5365156e-34 1.0000000e+00 5.0166948e-35 1.0452556e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 00:05:31,115] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8914
[2019-03-23 00:05:31,119] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.85, 51.0, 1.0, 2.0, 0.3670156442483364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 458734.3650415058, 458734.3650415058, 124149.9368718211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1369800.0000, 
sim time next is 1370400.0000, 
raw observation next is [25.63333333333333, 52.0, 1.0, 2.0, 0.3660819398289551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457642.9523512966, 457642.9523512966, 124025.1034194327], 
processed observation next is [1.0, 0.8695652173913043, 0.5049382716049381, 0.52, 1.0, 1.0, 0.24533564265351798, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1634439115540345, 0.1634439115540345, 0.2385098142681398], 
reward next is 0.7615, 
noisyNet noise sample is [array([0.3911422], dtype=float32), 0.8094335]. 
=============================================
[2019-03-23 00:05:39,535] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.1652917e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 00:05:39,544] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9456
[2019-03-23 00:05:39,549] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.7, 25.0, 1.0, 2.0, 0.4115146387352607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505273.9342128329, 505273.9342128329, 130140.2626642844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1514400.0000, 
sim time next is 1515000.0000, 
raw observation next is [34.85, 24.5, 1.0, 2.0, 0.4105297618612624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 504312.722909889, 504312.722909889, 130006.3562935641], 
processed observation next is [0.0, 0.5217391304347826, 0.8462962962962963, 0.245, 1.0, 1.0, 0.2982497165015029, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18011168675353179, 0.18011168675353179, 0.2500122236414694], 
reward next is 0.7500, 
noisyNet noise sample is [array([0.62703437], dtype=float32), -0.022808954]. 
=============================================
[2019-03-23 00:05:39,562] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[77.865425]
 [77.777084]
 [77.680595]
 [77.59302 ]
 [77.52484 ]], R is [[77.91885376]
 [77.88939667]
 [77.86006165]
 [77.83054352]
 [77.8008194 ]].
[2019-03-23 00:05:41,754] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.1711617e-33 1.0000000e+00 6.7684708e-34 1.2462655e-27 3.8090613e-31], sum to 1.0000
[2019-03-23 00:05:41,760] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0074
[2019-03-23 00:05:41,763] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 69.33333333333334, 1.0, 2.0, 0.3871088853160263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 483393.1992034506, 483393.1992034501, 126894.7890214228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1556400.0000, 
sim time next is 1557000.0000, 
raw observation next is [22.6, 70.0, 1.0, 2.0, 0.3867182427415263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 482894.4651534687, 482894.4651534682, 126840.3839731678], 
processed observation next is [1.0, 0.0, 0.39259259259259266, 0.7, 1.0, 1.0, 0.2699026699303884, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1724623089833817, 0.1724623089833815, 0.243923815333015], 
reward next is 0.7561, 
noisyNet noise sample is [array([1.9994103], dtype=float32), -0.6711813]. 
=============================================
[2019-03-23 00:05:41,784] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.22173 ]
 [70.158295]
 [70.09571 ]
 [70.08823 ]
 [70.0572  ]], R is [[70.34838104]
 [70.40087128]
 [70.45289612]
 [70.5043869 ]
 [70.55509949]].
[2019-03-23 00:05:41,949] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.9145790e-37 1.0000000e+00 7.9918540e-37 2.0536684e-37 1.2653291e-38], sum to 1.0000
[2019-03-23 00:05:41,955] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3270
[2019-03-23 00:05:41,959] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.53333333333333, 66.66666666666666, 1.0, 2.0, 0.4107015315999783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 509926.3337581342, 509926.3337581342, 130159.9861910687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1550400.0000, 
sim time next is 1551000.0000, 
raw observation next is [23.51666666666667, 65.83333333333334, 1.0, 2.0, 0.4043397779871119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 502972.4453399435, 502972.4453399435, 129274.6892694533], 
processed observation next is [0.0, 0.9565217391304348, 0.4265432098765433, 0.6583333333333334, 1.0, 1.0, 0.29088068807989514, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17963301619283698, 0.17963301619283698, 0.2486051716720256], 
reward next is 0.7514, 
noisyNet noise sample is [array([-1.3620294], dtype=float32), -1.3931546]. 
=============================================
[2019-03-23 00:05:41,982] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.07328]
 [70.02249]
 [69.96409]
 [69.94143]
 [69.93352]], R is [[70.17836761]
 [70.22628021]
 [70.27218628]
 [70.31629181]
 [70.35923004]].
[2019-03-23 00:05:43,523] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.7055351e-16 1.5897065e-01 1.5855614e-23 8.4102929e-01 3.5152648e-24], sum to 1.0000
[2019-03-23 00:05:43,533] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5391
[2019-03-23 00:05:43,540] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.78333333333333, 77.83333333333333, 1.0, 2.0, 0.2134362070682361, 1.0, 2.0, 0.2134362070682361, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 532924.2704693057, 532924.2704693062, 162875.9690583362], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1576200.0000, 
sim time next is 1576800.0000, 
raw observation next is [21.0, 76.0, 1.0, 2.0, 0.2142755617324988, 1.0, 2.0, 0.2142755617324988, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 535229.6307789717, 535229.6307789722, 163061.6519859281], 
processed observation next is [1.0, 0.2608695652173913, 0.3333333333333333, 0.76, 1.0, 1.0, 0.06461376396726046, 1.0, 1.0, 0.06461376396726046, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19115343956391848, 0.19115343956391864, 0.3135800999729386], 
reward next is 0.6864, 
noisyNet noise sample is [array([0.9603973], dtype=float32), -0.34583828]. 
=============================================
[2019-03-23 00:05:46,305] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0803378e-31 1.0000000e+00 4.4788724e-36 1.6482807e-23 8.0252413e-38], sum to 1.0000
[2019-03-23 00:05:46,315] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1535
[2019-03-23 00:05:46,320] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.85, 54.5, 1.0, 2.0, 0.3309206549759604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 419189.0513183299, 419189.0513183303, 119462.2402617422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1635000.0000, 
sim time next is 1635600.0000, 
raw observation next is [23.7, 55.00000000000001, 1.0, 2.0, 0.32819657635965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 415974.3328118966, 415974.3328118966, 119113.5745425654], 
processed observation next is [1.0, 0.9565217391304348, 0.4333333333333333, 0.55, 1.0, 1.0, 0.2002340194757738, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14856226171853448, 0.14856226171853448, 0.2290645664280104], 
reward next is 0.7709, 
noisyNet noise sample is [array([1.5875167], dtype=float32), -0.7401026]. 
=============================================
[2019-03-23 00:05:48,166] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9651361e-27 1.0000000e+00 3.9512043e-36 3.9966759e-09 3.9888215e-29], sum to 1.0000
[2019-03-23 00:05:48,176] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8233
[2019-03-23 00:05:48,181] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.0, 84.0, 1.0, 2.0, 0.5715101313666584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 726911.3091917833, 726911.3091917833, 155688.7209153823], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1674000.0000, 
sim time next is 1674600.0000, 
raw observation next is [19.08333333333334, 83.66666666666667, 1.0, 2.0, 0.5860402130521467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745032.0166138805, 745032.0166138805, 158204.0265371219], 
processed observation next is [1.0, 0.391304347826087, 0.2623456790123459, 0.8366666666666667, 1.0, 1.0, 0.5071907298239842, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2660828630763859, 0.2660828630763859, 0.3042385125713883], 
reward next is 0.6958, 
noisyNet noise sample is [array([0.24985793], dtype=float32), 1.8684196]. 
=============================================
[2019-03-23 00:05:54,042] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.06572445e-17 1.00000000e+00 1.03228642e-23 2.74386669e-09
 2.29334563e-18], sum to 1.0000
[2019-03-23 00:05:54,052] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4509
[2019-03-23 00:05:54,058] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.6, 87.0, 1.0, 2.0, 0.3132636691544545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 398973.90683122, 398973.90683122, 117227.2071874473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1807200.0000, 
sim time next is 1807800.0000, 
raw observation next is [18.61666666666667, 87.16666666666667, 1.0, 2.0, 0.3135322777752999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 399148.0137608356, 399148.0137608361, 117260.2011405063], 
processed observation next is [1.0, 0.9565217391304348, 0.24506172839506188, 0.8716666666666667, 1.0, 1.0, 0.18277652116107132, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14255286205744128, 0.14255286205744147, 0.22550038680866596], 
reward next is 0.7745, 
noisyNet noise sample is [array([-0.12761281], dtype=float32), -0.49098125]. 
=============================================
[2019-03-23 00:05:58,240] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1408284e-20 9.9328572e-01 2.3866147e-24 6.7142248e-03 5.4242776e-20], sum to 1.0000
[2019-03-23 00:05:58,247] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2997
[2019-03-23 00:05:58,252] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.91666666666666, 79.66666666666667, 1.0, 2.0, 0.8017647072103068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 991123.2525348304, 991123.2525348304, 199506.059313524], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1857000.0000, 
sim time next is 1857600.0000, 
raw observation next is [21.9, 80.0, 1.0, 2.0, 0.8048721451304749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 994570.7589350571, 994570.7589350566, 200155.8101046014], 
processed observation next is [1.0, 0.5217391304347826, 0.36666666666666664, 0.8, 1.0, 1.0, 0.7677049346791368, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3552038424768061, 0.3552038424768059, 0.3849150194319258], 
reward next is 0.6151, 
noisyNet noise sample is [array([-0.5130874], dtype=float32), 0.66808724]. 
=============================================
[2019-03-23 00:05:59,889] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.9770519e-15 4.5022935e-07 4.1005732e-26 9.9999952e-01 2.9010725e-18], sum to 1.0000
[2019-03-23 00:05:59,894] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2708
[2019-03-23 00:05:59,899] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.23333333333333, 89.66666666666667, 1.0, 2.0, 0.2153569112792913, 1.0, 2.0, 0.2153569112792913, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 523570.164489428, 523570.1644894284, 162887.4168121659], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1881600.0000, 
sim time next is 1882200.0000, 
raw observation next is [21.21666666666667, 89.83333333333333, 1.0, 2.0, 0.2150296027630103, 1.0, 2.0, 0.2150296027630103, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 522750.7584975074, 522750.7584975074, 162816.1907539231], 
processed observation next is [1.0, 0.782608695652174, 0.3413580246913581, 0.8983333333333333, 1.0, 1.0, 0.06551143186072655, 1.0, 1.0, 0.06551143186072655, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1866966994633955, 0.1866966994633955, 0.3131080591421598], 
reward next is 0.6869, 
noisyNet noise sample is [array([1.5261077], dtype=float32), -0.051529456]. 
=============================================
[2019-03-23 00:06:00,140] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 00:06:00,143] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:06:00,144] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:06:00,144] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:06:00,145] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:06:00,146] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:06:00,147] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:06:00,148] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:06:00,149] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:06:00,147] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:06:00,152] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:06:00,174] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run20
[2019-03-23 00:06:00,175] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run20
[2019-03-23 00:06:00,215] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run20
[2019-03-23 00:06:00,235] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run20
[2019-03-23 00:06:00,236] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run20
[2019-03-23 00:06:16,136] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.20757808], dtype=float32), -0.14711417]
[2019-03-23 00:06:16,138] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [15.43775668333333, 80.52036396, 1.0, 2.0, 0.1895421164217582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 244480.5935197397, 244480.5935197397, 79457.73794040419]
[2019-03-23 00:06:16,139] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:06:16,141] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5578987980031139
[2019-03-23 00:06:18,914] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.20757808], dtype=float32), -0.14711417]
[2019-03-23 00:06:18,915] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.82515175333333, 33.20232239, 1.0, 2.0, 0.7046461711256936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 873756.7300384906, 873756.7300384906, 179802.4940624689]
[2019-03-23 00:06:18,918] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:06:18,919] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.0639937e-25 1.0000000e+00 3.5093662e-31 3.2218273e-11 3.4605432e-28], sampled 0.8796996453640006
[2019-03-23 00:06:33,595] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.20757808], dtype=float32), -0.14711417]
[2019-03-23 00:06:33,596] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.0, 79.0, 1.0, 2.0, 0.592960433128064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686448.0837574254, 686448.0837574254, 157385.7478393544]
[2019-03-23 00:06:33,598] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:06:33,601] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2615502e-31 1.0000000e+00 7.9822265e-37 1.7219411e-17 1.0978280e-31], sampled 0.05856321060595604
[2019-03-23 00:06:37,165] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.20757808], dtype=float32), -0.14711417]
[2019-03-23 00:06:37,166] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.840594025, 50.31138751166667, 1.0, 2.0, 0.4187558040089207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 516703.2289631919, 516703.2289631914, 131241.7511348873]
[2019-03-23 00:06:37,166] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:06:37,169] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.2910775e-36 1.0000000e+00 0.0000000e+00 7.6592832e-24 1.3204877e-35], sampled 0.4278224859571703
[2019-03-23 00:06:46,911] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.20757808], dtype=float32), -0.14711417]
[2019-03-23 00:06:46,913] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.0, 100.0, 1.0, 2.0, 0.3603888730232253, 1.0, 2.0, 0.3603888730232253, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 821495.4206475148, 821495.4206475148, 195583.6567477293]
[2019-03-23 00:06:46,913] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:06:46,916] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3753279e-23 5.8240863e-04 4.4046232e-32 9.9941766e-01 7.2811891e-25], sampled 0.8477194018684512
[2019-03-23 00:07:44,054] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.20757808], dtype=float32), -0.14711417]
[2019-03-23 00:07:44,056] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.02458895333334, 87.90736835000001, 1.0, 2.0, 0.5500960373601866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 644237.2425650501, 644237.2425650501, 150511.1301012157]
[2019-03-23 00:07:44,057] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:07:44,061] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.6277467e-35 1.0000000e+00 0.0000000e+00 1.9635261e-26 1.3201351e-35], sampled 0.5560135372903325
[2019-03-23 00:07:49,424] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8478.5824 2418431127.1131 227.0000
[2019-03-23 00:07:49,425] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8944.7328 2182954058.4953 206.0000
[2019-03-23 00:07:49,769] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 9016.9869 2156378380.1539 150.0000
[2019-03-23 00:07:49,883] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 9079.1465 2116580125.3701 193.0000
[2019-03-23 00:07:50,073] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8883.5217 2220474514.8244 172.0000
[2019-03-23 00:07:51,089] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 475000, evaluation results [475000.0, 8478.582379464344, 2418431127.1130857, 227.0, 9016.98687642842, 2156378380.153885, 150.0, 9079.14653352163, 2116580125.3700602, 193.0, 8883.52174449559, 2220474514.8243527, 172.0, 8944.732751512844, 2182954058.4952564, 206.0]
[2019-03-23 00:07:53,746] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.9461432e-20 7.1084763e-16 1.3619365e-28 1.0000000e+00 7.2541114e-28], sum to 1.0000
[2019-03-23 00:07:53,756] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1807
[2019-03-23 00:07:53,767] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.13333333333333, 86.66666666666667, 1.0, 2.0, 0.3926108763782523, 1.0, 2.0, 0.3926108763782523, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 939902.2312866339, 939902.2312866343, 206093.030958616], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1938000.0000, 
sim time next is 1938600.0000, 
raw observation next is [22.25, 86.5, 1.0, 2.0, 0.3857787995903602, 1.0, 2.0, 0.3857787995903602, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 922777.8427031696, 922777.84270317, 204183.1234151651], 
processed observation next is [1.0, 0.43478260869565216, 0.37962962962962965, 0.865, 1.0, 1.0, 0.2687842852266193, 1.0, 1.0, 0.2687842852266193, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.329563515251132, 0.32956351525113214, 0.3926598527214713], 
reward next is 0.6073, 
noisyNet noise sample is [array([0.9641529], dtype=float32), 0.7253702]. 
=============================================
[2019-03-23 00:07:58,779] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:07:58,790] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4981
[2019-03-23 00:07:58,795] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.91666666666667, 83.16666666666667, 1.0, 2.0, 0.373120185447367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 465047.9171999443, 465047.9171999443, 124954.0982908087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2013000.0000, 
sim time next is 2013600.0000, 
raw observation next is [21.03333333333333, 82.33333333333334, 1.0, 2.0, 0.3741105527758791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 466228.4825172589, 466228.4825172589, 125088.0725862518], 
processed observation next is [0.0, 0.30434782608695654, 0.3345679012345678, 0.8233333333333335, 1.0, 1.0, 0.2548935152093799, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16651017232759247, 0.16651017232759247, 0.24055398574279194], 
reward next is 0.7594, 
noisyNet noise sample is [array([-0.32319263], dtype=float32), 0.84349716]. 
=============================================
[2019-03-23 00:08:08,477] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4962071e-16 2.6064005e-04 4.4636795e-24 9.9973935e-01 3.8967130e-29], sum to 1.0000
[2019-03-23 00:08:08,485] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0455
[2019-03-23 00:08:08,491] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.96666666666667, 90.33333333333333, 1.0, 2.0, 0.6235294030845786, 1.0, 2.0, 0.6235294030845786, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1421872.804601049, 1421872.804601049, 276228.8155775483], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2202000.0000, 
sim time next is 2202600.0000, 
raw observation next is [25.13333333333333, 89.66666666666667, 1.0, 2.0, 0.6456988378576985, 1.0, 2.0, 0.6456988378576985, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1472475.743699699, 1472475.7436997, 284119.1119841717], 
processed observation next is [1.0, 0.4782608695652174, 0.4864197530864196, 0.8966666666666667, 1.0, 1.0, 0.5782129022115459, 1.0, 1.0, 0.5782129022115459, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5258841941784639, 0.5258841941784643, 0.5463829076618686], 
reward next is 0.4536, 
noisyNet noise sample is [array([0.47009537], dtype=float32), 0.80079335]. 
=============================================
[2019-03-23 00:08:11,638] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.0488611e-19 1.3066904e-06 2.2648305e-22 9.9999869e-01 3.4944921e-24], sum to 1.0000
[2019-03-23 00:08:11,646] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4331
[2019-03-23 00:08:11,653] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.3, 30.0, 1.0, 2.0, 0.6315655057391174, 1.0, 2.0, 0.6315655057391174, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1522313.219350318, 1522313.219350318, 282638.1377043027], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2547000.0000, 
sim time next is 2547600.0000, 
raw observation next is [32.40000000000001, 30.0, 1.0, 2.0, 0.6411474018577803, 1.0, 2.0, 0.6411474018577803, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1543250.778940829, 1543250.778940829, 286041.6413705513], 
processed observation next is [1.0, 0.4782608695652174, 0.755555555555556, 0.3, 1.0, 1.0, 0.572794526021167, 1.0, 1.0, 0.572794526021167, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5511609924788675, 0.5511609924788675, 0.5500800795587525], 
reward next is 0.4499, 
noisyNet noise sample is [array([-1.1463531], dtype=float32), -0.6280389]. 
=============================================
[2019-03-23 00:08:13,656] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9841041e-26 4.8162090e-15 6.9525216e-33 1.0000000e+00 9.0830677e-25], sum to 1.0000
[2019-03-23 00:08:13,664] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9394
[2019-03-23 00:08:13,670] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.9, 89.0, 1.0, 2.0, 0.5440883583061129, 1.0, 2.0, 0.5440883583061129, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260425343961, 1270264.754937073, 1270264.754937073, 250741.5668619429], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2284200.0000, 
sim time next is 2284800.0000, 
raw observation next is [23.06666666666666, 88.33333333333334, 1.0, 2.0, 0.5092294587148251, 1.0, 2.0, 0.5092294587148251, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.926042615637, 1190452.236918793, 1190452.236918792, 239611.8897290223], 
processed observation next is [1.0, 0.43478260869565216, 0.40987654320987627, 0.8833333333333334, 1.0, 1.0, 0.41574935561288695, 1.0, 1.0, 0.41574935561288695, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288199713, 0.4251615131852832, 0.42516151318528284, 0.4607920956327352], 
reward next is 0.5392, 
noisyNet noise sample is [array([-1.910891], dtype=float32), 0.039432466]. 
=============================================
[2019-03-23 00:08:21,245] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:08:21,254] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9590
[2019-03-23 00:08:21,259] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.23333333333333, 56.0, 1.0, 2.0, 0.3869122539924047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 481629.5203158821, 481629.5203158816, 126838.1179632973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2411400.0000, 
sim time next is 2412000.0000, 
raw observation next is [25.0, 57.0, 1.0, 2.0, 0.3829191010739168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 476915.524316926, 476915.524316926, 126290.9165637756], 
processed observation next is [1.0, 0.9565217391304348, 0.48148148148148145, 0.57, 1.0, 1.0, 0.26537988223085335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17032697297033073, 0.17032697297033073, 0.24286714723803], 
reward next is 0.7571, 
noisyNet noise sample is [array([0.88337433], dtype=float32), 0.48986918]. 
=============================================
[2019-03-23 00:08:21,277] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[71.887634]
 [71.922035]
 [71.92601 ]
 [71.79343 ]
 [71.71527 ]], R is [[71.9135437 ]
 [71.95049286]
 [71.9863739 ]
 [72.02248383]
 [72.058815  ]].
[2019-03-23 00:08:26,269] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:08:26,280] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2922
[2019-03-23 00:08:26,287] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.43333333333334, 39.66666666666666, 1.0, 2.0, 0.3697827605569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 462118.4389293519, 462118.4389293519, 124523.4841514573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2497200.0000, 
sim time next is 2497800.0000, 
raw observation next is [28.26666666666667, 40.33333333333334, 1.0, 2.0, 0.3699542867771821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 462322.4798551129, 462322.4798551129, 124546.5778991389], 
processed observation next is [1.0, 0.9130434782608695, 0.6024691358024692, 0.40333333333333343, 1.0, 1.0, 0.2499455794966454, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16511517137682605, 0.16511517137682605, 0.23951264980603634], 
reward next is 0.7605, 
noisyNet noise sample is [array([-1.1360832], dtype=float32), -0.40993026]. 
=============================================
[2019-03-23 00:08:27,418] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:08:27,425] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5574
[2019-03-23 00:08:27,429] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.98333333333333, 43.16666666666667, 1.0, 2.0, 0.7023929538189873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 863249.8164328455, 863249.8164328451, 179162.8733011923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2535000.0000, 
sim time next is 2535600.0000, 
raw observation next is [29.16666666666667, 42.33333333333334, 1.0, 2.0, 0.9531561111735141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.313769355286299, 6.9112, 121.924612594192, 1377586.490080958, 1171437.416801541, 233457.10539172], 
processed observation next is [1.0, 0.34782608695652173, 0.6358024691358026, 0.42333333333333345, 1.0, 1.0, 0.9442334656827548, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.04025693552862988, 0.0, 0.809452634964694, 0.49199517502891355, 0.4183705060005504, 0.4489559719071538], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.801657], dtype=float32), -1.0232399]. 
=============================================
[2019-03-23 00:08:30,803] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:08:30,809] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1137
[2019-03-23 00:08:30,813] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 94.0, 1.0, 2.0, 0.4550775290019933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 553714.780050567, 553714.7800505675, 136380.4962952487], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2602800.0000, 
sim time next is 2603400.0000, 
raw observation next is [21.15, 94.33333333333334, 1.0, 2.0, 0.4550233947722571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 553771.4441294904, 553771.44412949, 136376.0596533666], 
processed observation next is [0.0, 0.13043478260869565, 0.33888888888888885, 0.9433333333333335, 1.0, 1.0, 0.3512183271098299, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1977755157605323, 0.19777551576053212, 0.26226165317955114], 
reward next is 0.7377, 
noisyNet noise sample is [array([-0.74928147], dtype=float32), -0.546254]. 
=============================================
[2019-03-23 00:08:35,918] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:08:35,927] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9887
[2019-03-23 00:08:35,931] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.46666666666667, 95.33333333333334, 1.0, 2.0, 0.4842654496531326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 584328.6873916087, 584328.6873916087, 140680.2616861837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2695200.0000, 
sim time next is 2695800.0000, 
raw observation next is [21.33333333333334, 94.16666666666666, 1.0, 2.0, 0.4717347610908037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571850.9361365397, 571850.9361365397, 138838.6368055314], 
processed observation next is [0.0, 0.17391304347826086, 0.3456790123456792, 0.9416666666666665, 1.0, 1.0, 0.37111281082238534, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20423247719162133, 0.20423247719162133, 0.26699737847217575], 
reward next is 0.7330, 
noisyNet noise sample is [array([-1.0180084], dtype=float32), -2.1911747]. 
=============================================
[2019-03-23 00:08:39,917] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:08:39,930] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4782
[2019-03-23 00:08:39,935] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 73.16666666666667, 1.0, 2.0, 0.6812687336407329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 776442.820011903, 776442.820011903, 172627.4468370141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2751000.0000, 
sim time next is 2751600.0000, 
raw observation next is [28.06666666666667, 74.33333333333334, 1.0, 2.0, 0.6791635286374988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774042.3038097556, 774042.3038097556, 172235.8611192517], 
processed observation next is [0.0, 0.8695652173913043, 0.5950617283950619, 0.7433333333333334, 1.0, 1.0, 0.6180518198065462, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2764436799320556, 0.2764436799320556, 0.3312228098447148], 
reward next is 0.6688, 
noisyNet noise sample is [array([-0.42901206], dtype=float32), 0.77687305]. 
=============================================
[2019-03-23 00:08:43,751] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 00:08:43,753] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:08:43,754] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:08:43,754] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:08:43,755] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:08:43,755] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:08:43,756] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:08:43,756] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:08:43,757] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:08:43,757] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:08:43,757] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:08:43,763] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run21
[2019-03-23 00:08:43,781] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run21
[2019-03-23 00:08:43,783] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run21
[2019-03-23 00:08:43,783] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run21
[2019-03-23 00:08:43,838] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run21
[2019-03-23 00:08:51,387] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.39142346], dtype=float32), 0.0074376822]
[2019-03-23 00:08:51,389] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.0, 31.0, 1.0, 2.0, 0.4877335684667963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 619115.529287315, 619115.529287315, 141898.3020346587]
[2019-03-23 00:08:51,391] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:08:51,394] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.44169488883331043
[2019-03-23 00:09:05,399] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.39142346], dtype=float32), 0.0074376822]
[2019-03-23 00:09:05,401] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.83333333333334, 25.0, 1.0, 2.0, 0.4152438894605373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 509004.1191074305, 509004.11910743, 130650.742656712]
[2019-03-23 00:09:05,402] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:09:05,404] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.3267011564540351
[2019-03-23 00:09:33,663] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.39142346], dtype=float32), 0.0074376822]
[2019-03-23 00:09:33,665] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.40000000000001, 48.66666666666667, 1.0, 2.0, 0.6575460075238416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 752230.0808892944, 752230.0808892944, 168403.2072312309]
[2019-03-23 00:09:33,666] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:09:33,669] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.13964208651918142
[2019-03-23 00:10:23,884] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.39142346], dtype=float32), 0.0074376822]
[2019-03-23 00:10:23,886] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.02865378, 83.53964644, 1.0, 2.0, 0.2842079750021341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 362772.1609438303, 362772.1609438303, 113647.482129055]
[2019-03-23 00:10:23,890] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:10:23,892] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8278838378791183
[2019-03-23 00:10:34,084] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.1818 2120456093.0328 430.0000
[2019-03-23 00:10:34,318] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.6001 2445376094.7952 746.0000
[2019-03-23 00:10:34,356] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.5701 2195109950.8241 572.0000
[2019-03-23 00:10:34,442] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0845 2170631810.8436 493.0000
[2019-03-23 00:10:34,512] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.9156 2248669569.0284 552.0000
[2019-03-23 00:10:35,530] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 500000, evaluation results [500000.0, 8100.600059888084, 2445376094.795151, 746.0, 8771.084470098069, 2170631810.843588, 493.0, 8924.181835947267, 2120456093.0327566, 430.0, 8583.915582893851, 2248669569.028412, 552.0, 8701.570121321163, 2195109950.8240995, 572.0]
[2019-03-23 00:10:45,221] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3684656e-25 1.0000000e+00 1.4835851e-32 1.8562885e-24 8.6527886e-32], sum to 1.0000
[2019-03-23 00:10:45,229] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8253
[2019-03-23 00:10:45,235] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.13333333333333, 90.66666666666667, 1.0, 2.0, 0.6600397220615077, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 752236.2171867354, 752236.2171867354, 168719.3283238531], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3000000.0000, 
sim time next is 3000600.0000, 
raw observation next is [25.85, 93.0, 1.0, 2.0, 0.655156587998168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 746668.2805612627, 746668.2805612627, 167831.0941159531], 
processed observation next is [1.0, 0.7391304347826086, 0.5129629629629631, 0.93, 1.0, 1.0, 0.5894721285692476, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2666672430575938, 0.2666672430575938, 0.32275210406914057], 
reward next is 0.6772, 
noisyNet noise sample is [array([-0.78567046], dtype=float32), -0.35742724]. 
=============================================
[2019-03-23 00:10:50,788] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:10:50,797] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4405
[2019-03-23 00:10:50,802] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.8, 53.0, 1.0, 2.0, 0.7683047974111977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 904770.4721861077, 904770.4721861081, 190892.8004210711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3139200.0000, 
sim time next is 3139800.0000, 
raw observation next is [29.83333333333334, 52.83333333333334, 1.0, 2.0, 0.9076732211415287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 1067460.5900199, 1067460.590019901, 220887.0691472804], 
processed observation next is [1.0, 0.34782608695652173, 0.6604938271604941, 0.5283333333333334, 1.0, 1.0, 0.8900871680256294, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.3812359250071071, 0.3812359250071075, 0.4247828252832315], 
reward next is 0.5752, 
noisyNet noise sample is [array([1.3134779], dtype=float32), -0.43764025]. 
=============================================
[2019-03-23 00:10:52,628] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.2191529e-36 1.3335015e-36], sum to 1.0000
[2019-03-23 00:10:52,635] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6193
[2019-03-23 00:10:52,640] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.58333333333334, 32.0, 1.0, 2.0, 0.342500217279781, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5477970530759008, 6.9112, 6.9112, 121.9260426156618, 803576.7127699904, 803576.7127699904, 206452.3171698897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3172200.0000, 
sim time next is 3172800.0000, 
raw observation next is [34.46666666666667, 32.0, 1.0, 2.0, 0.4762799018664256, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 566871.6387385902, 566871.6387385902, 139172.6504571852], 
processed observation next is [1.0, 0.7391304347826086, 0.8320987654320988, 0.32, 1.0, 1.0, 0.37652369269812574, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20245415669235364, 0.20245415669235364, 0.2676397124176638], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.7583919], dtype=float32), 1.091735]. 
=============================================
[2019-03-23 00:10:55,469] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.0865306e-20 1.0000000e+00 3.2223930e-22 1.3033068e-10 4.0722011e-20], sum to 1.0000
[2019-03-23 00:10:55,478] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1763
[2019-03-23 00:10:55,495] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1965411.359114008 W.
[2019-03-23 00:10:55,504] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.86666666666667, 32.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9845463448772026, 7.047647937619699, 6.9112, 121.9252952068799, 1965411.359114008, 1895538.24780047, 381727.1503327897], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3166800.0000, 
sim time next is 3167400.0000, 
raw observation next is [34.93333333333334, 32.0, 1.0, 2.0, 0.5586290395641048, 1.0, 1.0, 0.5586290395641048, 1.0, 2.0, 0.8893556242637346, 6.911199999999999, 6.9112, 121.94756008, 1911365.901370159, 1911365.90137016, 373295.7730707012], 
processed observation next is [1.0, 0.6521739130434783, 0.8493827160493829, 0.32, 1.0, 1.0, 0.4745583804334581, 1.0, 0.5, 0.4745583804334581, 1.0, 1.0, 0.8616945303296683, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.682630679060771, 0.6826306790607715, 0.7178764866744254], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.5617607], dtype=float32), -0.45899656]. 
=============================================
[2019-03-23 00:10:57,688] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:10:57,698] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6833
[2019-03-23 00:10:57,706] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 79.66666666666667, 1.0, 2.0, 0.4768913652870718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 574877.5705442546, 574877.5705442551, 139525.0800512155], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3220800.0000, 
sim time next is 3221400.0000, 
raw observation next is [23.83333333333333, 78.83333333333333, 1.0, 2.0, 0.4789178140511588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 576868.1971106707, 576868.1971106703, 139821.3974757766], 
processed observation next is [0.0, 0.2608695652173913, 0.43827160493827144, 0.7883333333333333, 1.0, 1.0, 0.37966406434661765, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20602435611095382, 0.20602435611095365, 0.26888730283803197], 
reward next is 0.7311, 
noisyNet noise sample is [array([0.09976709], dtype=float32), 0.5990492]. 
=============================================
[2019-03-23 00:11:01,347] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:11:01,356] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0390
[2019-03-23 00:11:01,371] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.5501435661690033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 648204.8920767662, 648204.8920767662, 150682.7896811417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3285600.0000, 
sim time next is 3286200.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.5498874623133837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 647904.5717958449, 647904.5717958449, 150640.5228167373], 
processed observation next is [0.0, 0.0, 0.4074074074074074, 0.94, 1.0, 1.0, 0.4641517408492663, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23139448992708747, 0.23139448992708747, 0.2896933131091102], 
reward next is 0.7103, 
noisyNet noise sample is [array([0.0855033], dtype=float32), 0.8972082]. 
=============================================
[2019-03-23 00:11:05,508] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:11:05,517] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7391
[2019-03-23 00:11:05,521] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666666, 85.66666666666667, 1.0, 2.0, 0.6082598380911403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702074.0059086432, 702074.0059086432, 159936.0031114781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3366600.0000, 
sim time next is 3367200.0000, 
raw observation next is [25.13333333333333, 87.33333333333334, 1.0, 2.0, 0.6164311141475769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 708538.1212883389, 708538.1212883389, 161223.5610658968], 
processed observation next is [0.0, 1.0, 0.4864197530864196, 0.8733333333333334, 1.0, 1.0, 0.5433703739852106, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2530493290315496, 0.2530493290315496, 0.3100453097421092], 
reward next is 0.6900, 
noisyNet noise sample is [array([0.896233], dtype=float32), -0.2537167]. 
=============================================
[2019-03-23 00:11:06,728] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:11:06,736] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4273
[2019-03-23 00:11:06,740] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 84.0, 1.0, 2.0, 0.6069522121642174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 701743.0764262204, 701743.0764262204, 159763.0549890244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3366000.0000, 
sim time next is 3366600.0000, 
raw observation next is [25.16666666666666, 85.66666666666667, 1.0, 2.0, 0.6082598380911403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702074.0059086432, 702074.0059086432, 159936.0031114781], 
processed observation next is [0.0, 1.0, 0.4876543209876541, 0.8566666666666667, 1.0, 1.0, 0.5336426643942146, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25074071639594403, 0.25074071639594403, 0.3075692367528425], 
reward next is 0.6924, 
noisyNet noise sample is [array([-0.5938992], dtype=float32), 0.80463606]. 
=============================================
[2019-03-23 00:11:07,270] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:11:07,277] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5832
[2019-03-23 00:11:07,282] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.7505275597444007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 866011.312407829, 866011.312407829, 186466.9267887911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3384000.0000, 
sim time next is 3384600.0000, 
raw observation next is [23.81666666666667, 94.00000000000001, 1.0, 2.0, 0.7282028666344137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 842697.089597497, 842697.0895974966, 182188.3509094192], 
processed observation next is [1.0, 0.17391304347826086, 0.43765432098765444, 0.9400000000000002, 1.0, 1.0, 0.6764319840885877, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30096324628482035, 0.3009632462848202, 0.3503622132873446], 
reward next is 0.6496, 
noisyNet noise sample is [array([0.89244974], dtype=float32), -0.6919493]. 
=============================================
[2019-03-23 00:11:12,056] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7792081e-13 9.9999774e-01 1.6165867e-24 2.2683248e-06 1.2954909e-15], sum to 1.0000
[2019-03-23 00:11:12,068] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5935
[2019-03-23 00:11:12,078] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1766171.917124447 W.
[2019-03-23 00:11:12,084] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.9219770455937705, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1766171.917124447, 1766171.917124447, 361758.1026804814], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3491400.0000, 
sim time next is 3492000.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.5604262933012208, 1.0, 1.0, 0.5604262933012208, 1.0, 2.0, 0.8922169107456912, 6.9112, 6.9112, 121.94756008, 1917521.858774637, 1917521.858774637, 374235.7887316439], 
processed observation next is [1.0, 0.43478260869565216, 0.5555555555555556, 0.89, 1.0, 1.0, 0.47669796821573907, 1.0, 0.5, 0.47669796821573907, 1.0, 1.0, 0.865271138432114, 0.0, 0.0, 0.8096049824067558, 0.6848292352766561, 0.6848292352766561, 0.7196842090993152], 
reward next is 0.2803, 
noisyNet noise sample is [array([1.3884667], dtype=float32), 1.4733633]. 
=============================================
[2019-03-23 00:11:12,095] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[44.730526]
 [43.454273]
 [43.751953]
 [43.37679 ]
 [44.051483]], R is [[43.43751526]
 [43.30744934]
 [42.87437439]
 [42.44563293]
 [42.02117538]].
[2019-03-23 00:11:12,967] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3097549e-38 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.0777351e-35], sum to 1.0000
[2019-03-23 00:11:12,978] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5391
[2019-03-23 00:11:12,982] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.25, 83.16666666666667, 1.0, 2.0, 0.4427962534010315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 542147.8418780201, 542147.8418780196, 134648.4820437976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3539400.0000, 
sim time next is 3540000.0000, 
raw observation next is [22.4, 84.33333333333334, 1.0, 2.0, 0.4501612423858461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 548721.7756624161, 548721.7756624161, 135674.6588262256], 
processed observation next is [1.0, 1.0, 0.38518518518518513, 0.8433333333333334, 1.0, 1.0, 0.34543005045934055, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1959720627365772, 0.1959720627365772, 0.26091280543504924], 
reward next is 0.7391, 
noisyNet noise sample is [array([0.50041735], dtype=float32), 0.4758803]. 
=============================================
[2019-03-23 00:11:12,998] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[53.2355  ]
 [53.054245]
 [52.66089 ]
 [52.276974]
 [51.898663]], R is [[53.50004196]
 [53.70610428]
 [53.90895462]
 [54.10050583]
 [54.28012848]].
[2019-03-23 00:11:20,878] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4740579e-25 1.0048935e-25 1.1702312e-27 1.0000000e+00 5.2765545e-29], sum to 1.0000
[2019-03-23 00:11:20,886] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3263
[2019-03-23 00:11:20,892] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.8723578389472333, 1.0, 2.0, 0.8723578389472333, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1989953.388869985, 1989953.388869985, 374561.7916440305], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3686400.0000, 
sim time next is 3687000.0000, 
raw observation next is [26.98333333333333, 88.16666666666667, 1.0, 2.0, 0.7832068751864967, 1.0, 2.0, 0.7832068751864967, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1786385.917412097, 1786385.917412097, 336864.8207284604], 
processed observation next is [1.0, 0.6956521739130435, 0.5549382716049381, 0.8816666666666667, 1.0, 1.0, 0.7419129466505913, 1.0, 1.0, 0.7419129466505913, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6379949705043204, 0.6379949705043204, 0.6478169629393469], 
reward next is 0.3522, 
noisyNet noise sample is [array([-1.2632077], dtype=float32), -0.3486989]. 
=============================================
[2019-03-23 00:11:20,914] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[64.01699 ]
 [63.787937]
 [64.07133 ]
 [64.17202 ]
 [64.36906 ]], R is [[64.81080627]
 [64.44238281]
 [64.0790329 ]
 [63.7327652 ]
 [63.43125534]].
[2019-03-23 00:11:21,791] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0608900e-31 1.0000000e+00 7.1673817e-36 4.6087240e-21 2.0831435e-32], sum to 1.0000
[2019-03-23 00:11:21,799] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8032
[2019-03-23 00:11:21,805] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 99.5, 1.0, 2.0, 0.5732787669761643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679696.7373171429, 679696.7373171429, 154724.3203862602], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3652200.0000, 
sim time next is 3652800.0000, 
raw observation next is [22.0, 99.33333333333334, 1.0, 2.0, 0.5972612417000993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 708399.9173478782, 708399.9173478782, 158855.1147576839], 
processed observation next is [1.0, 0.2608695652173913, 0.37037037037037035, 0.9933333333333334, 1.0, 1.0, 0.5205490972620229, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25299997048138506, 0.25299997048138506, 0.3054906053032383], 
reward next is 0.6945, 
noisyNet noise sample is [array([2.8182995], dtype=float32), -1.4015688]. 
=============================================
[2019-03-23 00:11:24,931] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 0. 0. 1. 0.], sum to 1.0000
[2019-03-23 00:11:24,942] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0650
[2019-03-23 00:11:24,948] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.38333333333333, 91.16666666666667, 1.0, 2.0, 0.8789097991982694, 1.0, 2.0, 0.8789097991982694, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2004915.977222125, 2004915.977222125, 377441.500421572], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3751800.0000, 
sim time next is 3752400.0000, 
raw observation next is [27.76666666666667, 88.33333333333334, 1.0, 2.0, 0.897638098410687, 1.0, 2.0, 0.897638098410687, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2047686.824311777, 2047686.824311776, 385753.193899884], 
processed observation next is [1.0, 0.43478260869565216, 0.5839506172839507, 0.8833333333333334, 1.0, 1.0, 0.8781405933460559, 1.0, 1.0, 0.8781405933460559, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7313167229684918, 0.7313167229684915, 0.7418330651920846], 
reward next is 0.2582, 
noisyNet noise sample is [array([-0.5023013], dtype=float32), -0.20213181]. 
=============================================
[2019-03-23 00:11:27,132] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.5014753e-24 0.0000000e+00 1.2376984e-29 1.0000000e+00 3.0471933e-35], sum to 1.0000
[2019-03-23 00:11:27,141] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8087
[2019-03-23 00:11:27,145] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.8197640216869119, 1.0, 2.0, 0.8197640216869119, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1869854.959721041, 1869854.95972104, 351989.4400835217], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3747600.0000, 
sim time next is 3748200.0000, 
raw observation next is [26.16666666666667, 94.00000000000001, 1.0, 2.0, 0.7258248004320756, 1.0, 2.0, 0.7258248004320756, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1655384.121012981, 1655384.121012981, 314058.0370955348], 
processed observation next is [1.0, 0.391304347826087, 0.5246913580246916, 0.9400000000000002, 1.0, 1.0, 0.6736009528953282, 1.0, 1.0, 0.6736009528953282, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5912086146474932, 0.5912086146474932, 0.6039577636452592], 
reward next is 0.3960, 
noisyNet noise sample is [array([0.4706964], dtype=float32), 1.1657004]. 
=============================================
[2019-03-23 00:11:28,119] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 00:11:28,121] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:11:28,122] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:11:28,123] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:11:28,125] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:11:28,127] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:11:28,127] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:11:28,128] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:11:28,126] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:11:28,129] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:11:28,130] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:11:28,149] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run22
[2019-03-23 00:11:28,168] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run22
[2019-03-23 00:11:28,169] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run22
[2019-03-23 00:11:28,217] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run22
[2019-03-23 00:11:28,217] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run22
[2019-03-23 00:11:43,956] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.12898843], dtype=float32), 0.09031507]
[2019-03-23 00:11:43,959] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.15375759, 82.26880691, 1.0, 2.0, 0.3718021589039474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477975.5703114835, 477975.5703114835, 124904.0020701871]
[2019-03-23 00:11:43,959] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:11:43,962] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4369069e-20 1.0000000e+00 5.4113768e-22 2.4693185e-11 1.2583454e-22], sampled 0.5653403252341327
[2019-03-23 00:12:01,254] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.12898843], dtype=float32), 0.09031507]
[2019-03-23 00:12:01,255] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.53377485333333, 81.46842128166666, 1.0, 2.0, 0.5028036913076422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 596294.7638335624, 596294.7638335624, 143208.4060610177]
[2019-03-23 00:12:01,256] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:12:01,257] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.3310352e-15 9.9999964e-01 9.0438640e-16 3.2081093e-07 2.3674502e-20], sampled 0.6283344281977373
[2019-03-23 00:12:31,457] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.12898843], dtype=float32), 0.09031507]
[2019-03-23 00:12:31,459] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.08333333333334, 83.33333333333333, 1.0, 2.0, 0.3067150814146188, 1.0, 2.0, 0.3067150814146188, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 699091.8605081228, 699091.8605081233, 182080.2319843846]
[2019-03-23 00:12:31,459] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:12:31,462] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3976725e-15 1.1629857e-13 3.7663142e-20 1.0000000e+00 4.0187427e-21], sampled 0.09478641158308831
[2019-03-23 00:12:55,861] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.12898843], dtype=float32), 0.09031507]
[2019-03-23 00:12:55,863] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.40497778, 72.12388919333333, 1.0, 2.0, 0.392292244005, 1.0, 2.0, 0.392292244005, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 894260.6061450246, 894260.6061450251, 204085.118513572]
[2019-03-23 00:12:55,865] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:12:55,867] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.3536079e-15 2.8012230e-11 4.5344072e-18 1.0000000e+00 4.6038195e-22], sampled 0.3612658008790255
[2019-03-23 00:13:17,860] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8865.3630 2260751979.4233 65.0000
[2019-03-23 00:13:18,210] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8956.8484 2206959858.4025 67.0000
[2019-03-23 00:13:18,374] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8414.6568 2494262722.4275 94.0000
[2019-03-23 00:13:18,381] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8882.4614 2238324270.1904 73.0000
[2019-03-23 00:13:18,404] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8787.0872 2296655655.4405 70.0000
[2019-03-23 00:13:19,420] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 525000, evaluation results [525000.0, 8414.656842191496, 2494262722.427512, 94.0, 8882.46144208626, 2238324270.1904335, 73.0, 8956.848424236841, 2206959858.4024677, 67.0, 8787.087210886362, 2296655655.4404554, 70.0, 8865.3629848866, 2260751979.423271, 65.0]
[2019-03-23 00:13:19,965] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.6893841e-27 0.0000000e+00 1.1949859e-31 1.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:13:19,979] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7808
[2019-03-23 00:13:19,982] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.2, 59.0, 1.0, 2.0, 0.3697693463531971, 1.0, 2.0, 0.3697693463531971, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 842889.6804479638, 842889.6804479638, 198048.4022711239], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3778200.0000, 
sim time next is 3778800.0000, 
raw observation next is [33.46666666666667, 55.0, 1.0, 2.0, 0.3625258017220997, 1.0, 2.0, 0.3625258017220997, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 826369.1102190007, 826369.1102190012, 196143.706162956], 
processed observation next is [1.0, 0.7391304347826086, 0.7950617283950618, 0.55, 1.0, 1.0, 0.24110214490726153, 1.0, 1.0, 0.24110214490726153, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29513182507821456, 0.2951318250782147, 0.3771994349287615], 
reward next is 0.6228, 
noisyNet noise sample is [array([-0.68131787], dtype=float32), 0.52141345]. 
=============================================
[2019-03-23 00:13:23,167] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999225e-01 8.4271951e-11 1.1205020e-23 7.7620798e-06 3.7199320e-15], sum to 1.0000
[2019-03-23 00:13:23,174] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4742
[2019-03-23 00:13:23,184] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 714206.8511385453 W.
[2019-03-23 00:13:23,194] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.16666666666666, 59.66666666666667, 1.0, 2.0, 0.3133434477230591, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4988529736587623, 6.911199999999999, 6.9112, 121.9260426156618, 714206.8511385453, 714206.8511385458, 198865.2452744673], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3834600.0000, 
sim time next is 3835200.0000, 
raw observation next is [30.33333333333334, 60.33333333333334, 1.0, 2.0, 0.3180862720860312, 1.0, 1.0, 0.3180862720860312, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 725022.3303933097, 725022.3303933102, 184857.8823915079], 
processed observation next is [0.0, 0.391304347826087, 0.6790123456790126, 0.6033333333333334, 1.0, 1.0, 0.18819794295956094, 1.0, 0.5, 0.18819794295956094, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2589365465690392, 0.25893654656903936, 0.35549592767597676], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.35598108], dtype=float32), -1.301691]. 
=============================================
[2019-03-23 00:13:42,690] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.1063599e-29 4.0393091e-35 1.8580432e-19 9.8597821e-29], sum to 1.0000
[2019-03-23 00:13:42,698] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1170
[2019-03-23 00:13:42,706] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1690519.28026229 W.
[2019-03-23 00:13:42,711] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.53333333333333, 75.33333333333334, 1.0, 1.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.857306429398387, 6.9112, 121.9218459256474, 1690519.28026229, 1206044.902541917, 247880.1012409916], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4177200.0000, 
sim time next is 4177800.0000, 
raw observation next is [25.9, 75.0, 1.0, 2.0, 0.6646058573628183, 1.0, 1.0, 0.6646058573628183, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9254727451952, 1527083.141437658, 1527083.141437658, 291559.4305352088], 
processed observation next is [1.0, 0.34782608695652173, 0.5148148148148147, 0.75, 1.0, 1.0, 0.6007212587652598, 1.0, 0.5, 0.6007212587652598, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094583454728612, 0.545386836227735, 0.545386836227735, 0.5606912125677092], 
reward next is 0.4393, 
noisyNet noise sample is [array([-0.57205695], dtype=float32), -2.3197935]. 
=============================================
[2019-03-23 00:13:50,656] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.7957378e-13 9.9706570e-26], sum to 1.0000
[2019-03-23 00:13:50,663] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4571
[2019-03-23 00:13:50,667] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 701706.5081563261 W.
[2019-03-23 00:13:50,670] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.3078616903744829, 1.0, 1.0, 0.3078616903744829, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 701706.5081563261, 701706.5081563266, 182357.8477663157], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4309800.0000, 
sim time next is 4310400.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.3076047191681349, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4897407146858654, 6.911199999999999, 6.9112, 121.9260426156618, 701868.0557538342, 701868.0557538347, 197287.8542308099], 
processed observation next is [1.0, 0.9130434782608695, 0.5555555555555556, 0.74, 1.0, 1.0, 0.1757199037715892, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.3621758933573317, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2506671627692265, 0.2506671627692267, 0.37939971967463443], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.12157419], dtype=float32), 0.93360764]. 
=============================================
[2019-03-23 00:13:57,807] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.4843670e-33 1.2844007e-33 5.0702451e-32 4.0780503e-33], sum to 1.0000
[2019-03-23 00:13:57,814] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9253
[2019-03-23 00:13:57,822] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 731009.9949536968 W.
[2019-03-23 00:13:57,825] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 65.0, 1.0, 2.0, 0.6414239305296024, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 731009.9949536968, 731009.9949536968, 165348.8397923834], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4456800.0000, 
sim time next is 4457400.0000, 
raw observation next is [29.16666666666667, 65.83333333333334, 1.0, 2.0, 0.3205736018916622, 1.0, 1.0, 0.3205736018916622, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 730694.4681672167, 730694.4681672167, 185471.3480421856], 
processed observation next is [0.0, 0.6086956521739131, 0.6358024691358026, 0.6583333333333334, 1.0, 1.0, 0.1911590498710264, 1.0, 0.5, 0.1911590498710264, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26096231005972026, 0.26096231005972026, 0.35667566931189537], 
reward next is 0.6433, 
noisyNet noise sample is [array([-0.60362554], dtype=float32), 0.038303845]. 
=============================================
[2019-03-23 00:14:00,252] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.0039796e-34 3.2257016e-37 8.3786210e-29], sum to 1.0000
[2019-03-23 00:14:00,258] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1784
[2019-03-23 00:14:00,269] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 731993.8838087041 W.
[2019-03-23 00:14:00,274] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.33333333333334, 94.0, 1.0, 2.0, 0.3211434153705349, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5112707761807556, 6.911200000000001, 6.9112, 121.9260426156618, 731993.8838087041, 731993.8838087036, 201012.3669437296], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4495200.0000, 
sim time next is 4495800.0000, 
raw observation next is [24.16666666666666, 94.0, 1.0, 2.0, 0.2113081415723817, 1.0, 1.0, 0.2113081415723817, 1.0, 2.0, 0.3364094432089574, 6.9112, 6.9112, 121.94756008, 722458.9643310818, 722458.9643310818, 224324.0336769338], 
processed observation next is [0.0, 0.0, 0.45061728395061706, 0.94, 1.0, 1.0, 0.061081120919502026, 1.0, 0.5, 0.061081120919502026, 1.0, 1.0, 0.1705118040111967, 0.0, 0.0, 0.8096049824067558, 0.25802105868967207, 0.25802105868967207, 0.4313923724556419], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.632383], dtype=float32), 0.3155202]. 
=============================================
[2019-03-23 00:14:01,735] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 6.7680286e-20 2.5851697e-37 3.1207513e-36 1.0150095e-27], sum to 1.0000
[2019-03-23 00:14:01,742] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2961
[2019-03-23 00:14:01,749] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.1, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9023438580771966, 6.9112, 6.9112, 121.9260426156618, 660526.4577357398, 660526.4577357398, 176227.1870549693], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4566600.0000, 
sim time next is 4567200.0000, 
raw observation next is [23.06666666666667, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9084574075077532, 6.9112, 6.9112, 121.9260426156618, 664080.0430902912, 664080.0430902912, 177226.6191519344], 
processed observation next is [0.0, 0.8695652173913043, 0.40987654320987665, 0.98, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8855717593846915, 0.0, 0.0, 0.8094621288201359, 0.2371714439608183, 0.2371714439608183, 0.3408204214460277], 
reward next is 0.6592, 
noisyNet noise sample is [array([0.4105425], dtype=float32), 0.29443866]. 
=============================================
[2019-03-23 00:14:02,088] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.1362920e-27 1.3733173e-32 8.0995752e-16 3.3109103e-31], sum to 1.0000
[2019-03-23 00:14:02,098] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8809
[2019-03-23 00:14:02,107] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 699672.1545011316 W.
[2019-03-23 00:14:02,115] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.85, 87.5, 1.0, 2.0, 0.306940134640511, 1.0, 1.0, 0.306940134640511, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 699672.1545011316, 699672.1545011321, 182137.6465760973], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4530600.0000, 
sim time next is 4531200.0000, 
raw observation next is [24.8, 87.0, 1.0, 2.0, 0.3025458955096906, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4818317109129006, 6.911199999999999, 6.9112, 121.9260426156618, 693435.0974518303, 693435.0974518307, 195865.1457661357], 
processed observation next is [0.0, 0.43478260869565216, 0.4740740740740741, 0.87, 1.0, 1.0, 0.16969749465439354, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.3522896386411257, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24765539194708225, 0.24765539194708241, 0.3766637418579533], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.27396673], dtype=float32), -1.363744]. 
=============================================
[2019-03-23 00:14:08,289] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2102207e-09 0.0000000e+00], sum to 1.0000
[2019-03-23 00:14:08,297] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2529
[2019-03-23 00:14:08,304] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1933955.755885905 W.
[2019-03-23 00:14:08,308] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.6, 65.0, 1.0, 2.0, 0.565224167554164, 1.0, 2.0, 0.565224167554164, 1.0, 2.0, 0.8998552828122325, 6.911199999999999, 6.9112, 121.94756008, 1933955.755885905, 1933955.755885906, 376753.7581049638], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4640400.0000, 
sim time next is 4641000.0000, 
raw observation next is [29.33333333333334, 67.33333333333334, 1.0, 2.0, 0.4290110523133421, 1.0, 2.0, 0.4290110523133421, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 978017.390214019, 978017.3902140195, 214302.2338494968], 
processed observation next is [1.0, 0.7391304347826086, 0.6419753086419755, 0.6733333333333335, 1.0, 1.0, 0.3202512527539787, 1.0, 1.0, 0.3202512527539787, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.34929192507643536, 0.3492919250764355, 0.4121196804798016], 
reward next is 0.5879, 
noisyNet noise sample is [array([0.93475974], dtype=float32), -1.4136477]. 
=============================================
[2019-03-23 00:14:08,318] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[36.221756]
 [36.080914]
 [35.264263]
 [34.208584]
 [33.684013]], R is [[39.82803345]
 [39.7052269 ]
 [39.62519455]
 [39.552742  ]
 [39.41770554]].
[2019-03-23 00:14:11,396] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 00:14:11,397] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:14:11,398] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:14:11,398] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:14:11,399] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:14:11,400] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:14:11,401] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:14:11,402] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:14:11,403] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:14:11,402] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:14:11,404] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:14:11,419] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run23
[2019-03-23 00:14:11,441] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run23
[2019-03-23 00:14:11,442] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run23
[2019-03-23 00:14:11,443] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run23
[2019-03-23 00:14:11,511] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run23
[2019-03-23 00:14:20,353] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08583806], dtype=float32), 0.10764312]
[2019-03-23 00:14:20,353] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.55, 25.5, 1.0, 2.0, 0.6017548308260228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 765149.4299476336, 765149.4299476336, 160970.4474779612]
[2019-03-23 00:14:20,354] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:14:20,358] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.0980207e-31 1.0858973e-27 3.2318411e-26 8.0095114e-33], sampled 0.8161757758916751
[2019-03-23 00:14:20,359] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 765149.4299476336 W.
[2019-03-23 00:14:23,337] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08583806], dtype=float32), 0.10764312]
[2019-03-23 00:14:23,339] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.0759777, 34.4283774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.676895121327874, 6.9112, 6.9112, 121.9260426156618, 505544.4931171818, 505544.4931171818, 141090.9045430461]
[2019-03-23 00:14:23,341] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:14:23,343] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.6341858e-34 9.6991600e-34 6.8834893e-17 1.1442773e-30], sampled 0.7137515769573836
[2019-03-23 00:14:24,749] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08583806], dtype=float32), 0.10764312]
[2019-03-23 00:14:24,750] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.89697046833333, 76.91088452333334, 1.0, 2.0, 0.630976382185908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426064272, 770498.1390222294, 770498.1390222294, 165595.7627001438]
[2019-03-23 00:14:24,751] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:14:24,756] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.6993918e-36 1.1038415e-31 1.4732963e-12 2.1021147e-28], sampled 0.9242981689307274
[2019-03-23 00:14:24,757] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 770498.1390222294 W.
[2019-03-23 00:14:26,428] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08583806], dtype=float32), 0.10764312]
[2019-03-23 00:14:26,430] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.16666666666667, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4939936800975059, 6.911199999999999, 6.9112, 121.9260426156618, 354409.694170025, 354409.6941700254, 115241.7152390262]
[2019-03-23 00:14:26,432] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:14:26,435] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.4938102e-28 4.7516265e-30 5.3853841e-16 2.2694399e-25], sampled 0.49561270417080105
[2019-03-23 00:14:27,333] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08583806], dtype=float32), 0.10764312]
[2019-03-23 00:14:27,336] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.66666666666667, 35.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9659030585549898, 7.02523077205611, 6.9112, 121.9256770850111, 772676.2063510666, 714282.4341669017, 168316.6827327763]
[2019-03-23 00:14:27,336] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:14:27,339] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.5684426e-33 1.0117215e-31 9.6906044e-14 8.0318446e-26], sampled 0.9685509049784388
[2019-03-23 00:14:27,341] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 772676.2063510666 W.
[2019-03-23 00:14:35,506] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08583806], dtype=float32), 0.10764312]
[2019-03-23 00:14:35,507] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.86666666666667, 57.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6686238749619464, 6.911200000000001, 6.9112, 121.9260426156618, 499555.0723651726, 499555.0723651721, 140734.1346922934]
[2019-03-23 00:14:35,509] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:14:35,513] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 8.9988616e-37 1.9179547e-32 3.3032511e-32], sampled 0.3473577931607126
[2019-03-23 00:14:54,455] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08583806], dtype=float32), 0.10764312]
[2019-03-23 00:14:54,457] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.0, 53.0, 1.0, 2.0, 0.5288388016603898, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8419285953207049, 6.911200000000001, 6.9112, 121.9258038396226, 1205773.993502351, 1205773.993502351, 267197.9371107919]
[2019-03-23 00:14:54,458] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:14:54,461] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 6.8284142e-31 0.0000000e+00], sampled 0.46832825020317337
[2019-03-23 00:14:54,462] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1205773.993502351 W.
[2019-03-23 00:15:07,579] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08583806], dtype=float32), 0.10764312]
[2019-03-23 00:15:07,580] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.69734635, 100.93952714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8697601180476423, 6.9112, 6.9112, 121.9260426156618, 637482.2106579664, 637482.2106579664, 171768.2475769107]
[2019-03-23 00:15:07,580] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:15:07,582] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.6400692e-37 2.5136218e-33 2.1443329e-12 1.3522416e-26], sampled 0.8406273132600267
[2019-03-23 00:15:26,771] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08583806], dtype=float32), 0.10764312]
[2019-03-23 00:15:26,771] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.80885429833333, 77.14135826666667, 1.0, 2.0, 0.9747122522515697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.988861622028534, 6.9112, 121.9255133109956, 1150921.576734184, 1111152.057586532, 234689.4404296742]
[2019-03-23 00:15:26,772] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:15:26,777] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 4.0692779e-37 1.7275380e-27 2.5583872e-37], sampled 0.8766047227216605
[2019-03-23 00:15:26,779] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1150921.576734184 W.
[2019-03-23 00:15:35,885] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08583806], dtype=float32), 0.10764312]
[2019-03-23 00:15:35,886] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.9, 53.16666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9914689168121854, 7.05992971636572, 6.9112, 121.9253415593187, 1962263.995973383, 1886101.525808157, 382731.7446448728]
[2019-03-23 00:15:35,887] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:15:35,890] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 4.086862e-12 0.000000e+00], sampled 0.7332773268333564
[2019-03-23 00:15:35,891] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1962263.995973383 W.
[2019-03-23 00:15:57,731] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08583806], dtype=float32), 0.10764312]
[2019-03-23 00:15:57,733] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.79567098666666, 74.51948454333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6175645172021809, 6.911199999999999, 6.9112, 121.9260426156618, 460161.7166494877, 460161.7166494882, 133524.8146541255]
[2019-03-23 00:15:57,734] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:15:57,741] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 2.3297248e-35 6.1857818e-24 4.5477132e-32], sampled 0.6533556012570753
[2019-03-23 00:16:01,169] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.4519 2529808370.8593 831.0000
[2019-03-23 00:16:01,405] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.0986 2258060319.5562 535.0000
[2019-03-23 00:16:01,471] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.1873 2293006997.0031 697.0000
[2019-03-23 00:16:01,473] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8361.8429 2339487239.9260 616.0000
[2019-03-23 00:16:01,594] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8634.1095 2219133127.1668 543.0000
[2019-03-23 00:16:02,612] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 550000, evaluation results [550000.0, 7841.4518751717205, 2529808370.8593388, 831.0, 8560.09864046889, 2258060319.556207, 535.0, 8634.109513107329, 2219133127.166827, 543.0, 8361.842897159899, 2339487239.9260297, 616.0, 8404.187265183537, 2293006997.003067, 697.0]
[2019-03-23 00:16:04,533] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 8.2311140e-38 5.0383385e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 00:16:04,542] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4770
[2019-03-23 00:16:04,548] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 769606.8698848773 W.
[2019-03-23 00:16:04,554] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.11666666666667, 87.83333333333334, 1.0, 2.0, 0.3376368619433016, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5375288802786543, 6.911199999999999, 6.9112, 121.9260426156618, 769606.8698848773, 769606.8698848778, 205637.1248205205], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4740600.0000, 
sim time next is 4741200.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.3392633794127958, 1.0, 1.0, 0.3392633794127958, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 773316.2115144168, 773316.2115144173, 190150.243684823], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.89, 1.0, 1.0, 0.21340878501523305, 1.0, 0.5, 0.21340878501523305, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2761843612551489, 0.27618436125514906, 0.36567354554773657], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.02998151], dtype=float32), 1.3566453]. 
=============================================
[2019-03-23 00:16:09,877] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999952e-01 4.6417003e-35 5.9620485e-17 4.9149759e-07 4.1032509e-25], sum to 1.0000
[2019-03-23 00:16:09,882] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8958
[2019-03-23 00:16:09,890] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 811916.8021170964 W.
[2019-03-23 00:16:09,895] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.01666666666667, 92.83333333333333, 1.0, 2.0, 0.7123779423603508, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 811916.8021170964, 811916.8021170964, 178501.9138391115], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4831800.0000, 
sim time next is 4832400.0000, 
raw observation next is [26.03333333333333, 92.66666666666667, 1.0, 2.0, 0.3567377191626041, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5679380670432745, 6.911199999999999, 6.9112, 121.9260426156618, 813168.3120896538, 813168.3120896543, 211128.3876662945], 
processed observation next is [1.0, 0.9565217391304348, 0.519753086419753, 0.9266666666666667, 1.0, 1.0, 0.23421157043167157, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.4599225838040931, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2904172543177335, 0.2904172543177337, 0.40601613012748944], 
reward next is 0.5940, 
noisyNet noise sample is [array([-0.6474864], dtype=float32), -1.6391532]. 
=============================================
[2019-03-23 00:16:11,125] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9961152e-23 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:16:11,131] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4142
[2019-03-23 00:16:11,146] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 2667765.501500607 W.
[2019-03-23 00:16:11,153] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.83333333333334, 80.66666666666667, 1.0, 2.0, 0.9320104068336367, 1.0, 2.0, 0.779369865393253, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2667765.501500607, 2667765.501500607, 497403.8592739782], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4893000.0000, 
sim time next is 4893600.0000, 
raw observation next is [30.66666666666667, 82.33333333333334, 1.0, 2.0, 0.8850554340819382, 1.0, 2.0, 0.7558923790174038, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2587286.118906113, 2587286.118906113, 482669.3936260822], 
processed observation next is [1.0, 0.6521739130434783, 0.6913580246913582, 0.8233333333333335, 1.0, 1.0, 0.8631612310499265, 1.0, 1.0, 0.709395689306433, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.9240307567521832, 0.9240307567521832, 0.9282103723578504], 
reward next is 0.0718, 
noisyNet noise sample is [array([-0.8149178], dtype=float32), 1.3434359]. 
=============================================
[2019-03-23 00:16:11,379] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.4098692e-25 1.0613831e-25 4.2327020e-15 4.8440400e-19], sum to 1.0000
[2019-03-23 00:16:11,388] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9575
[2019-03-23 00:16:11,398] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 793981.7440389142 W.
[2019-03-23 00:16:11,403] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 95.0, 1.0, 2.0, 0.232216628343283, 1.0, 2.0, 0.232216628343283, 1.0, 1.0, 0.3696964350901074, 6.9112, 6.9112, 121.94756008, 793981.7440389142, 793981.7440389142, 231407.9745713395], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4845600.0000, 
sim time next is 4846200.0000, 
raw observation next is [25.33333333333334, 94.83333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 9.332474462414757, 6.9112, 123.4746652416103, 2419288.558548049, 1163631.132988216, 245820.9099358841], 
processed observation next is [1.0, 0.08695652173913043, 0.49382716049382736, 0.9483333333333335, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.24212744624147567, 0.0, 0.8197433726024079, 0.8640316280528747, 0.4155825474957914, 0.4727325191074694], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7102331], dtype=float32), -0.62421423]. 
=============================================
[2019-03-23 00:16:17,334] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 5.7142214e-30 1.1378699e-30 9.5571406e-10 2.0538772e-17], sum to 1.0000
[2019-03-23 00:16:17,342] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0221
[2019-03-23 00:16:17,351] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 771108.2569717622 W.
[2019-03-23 00:16:17,357] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.58333333333334, 78.83333333333333, 1.0, 1.0, 0.6480738480806927, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260110749353, 771108.2569717622, 771108.2569717622, 168016.8571548006], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4954200.0000, 
sim time next is 4954800.0000, 
raw observation next is [24.66666666666667, 79.66666666666667, 1.0, 2.0, 0.417161000278171, 1.0, 1.0, 0.417161000278171, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426060443, 975271.4707164097, 975271.4707164094, 212066.8102443909], 
processed observation next is [1.0, 0.34782608695652173, 0.469135802469136, 0.7966666666666667, 1.0, 1.0, 0.3061440479502036, 1.0, 0.5, 0.3061440479502036, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621287562858, 0.3483112395415749, 0.3483112395415748, 0.40782078893152096], 
reward next is 0.5922, 
noisyNet noise sample is [array([0.941647], dtype=float32), -0.68932706]. 
=============================================
[2019-03-23 00:16:21,946] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.0963111e-12 2.0749319e-35], sum to 1.0000
[2019-03-23 00:16:21,953] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8486
[2019-03-23 00:16:21,960] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1802160.377841863 W.
[2019-03-23 00:16:21,963] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.4, 66.0, 1.0, 2.0, 0.5267440384127926, 1.0, 1.0, 0.5267440384127926, 1.0, 2.0, 0.838593664008854, 6.9112, 6.9112, 121.94756008, 1802160.377841863, 1802160.377841863, 356909.2014320269], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5328000.0000, 
sim time next is 5328600.0000, 
raw observation next is [28.41666666666667, 66.16666666666667, 1.0, 2.0, 0.5223219273705598, 1.0, 2.0, 0.5223219273705598, 1.0, 2.0, 0.8315535192115173, 6.911200000000001, 6.9112, 121.94756008, 1787015.785540621, 1787015.78554062, 354679.9833664122], 
processed observation next is [1.0, 0.6956521739130435, 0.6080246913580248, 0.6616666666666667, 1.0, 1.0, 0.431335627822095, 1.0, 1.0, 0.431335627822095, 1.0, 1.0, 0.7894418990143967, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6382199234073647, 0.6382199234073643, 0.6820768910892543], 
reward next is 0.3179, 
noisyNet noise sample is [array([-1.1437074], dtype=float32), -0.2105261]. 
=============================================
[2019-03-23 00:16:24,092] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.9133095e-38 1.5231567e-28], sum to 1.0000
[2019-03-23 00:16:24,096] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6874
[2019-03-23 00:16:24,105] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 985902.1304927894 W.
[2019-03-23 00:16:24,113] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.5, 73.0, 1.0, 2.0, 0.4324675001623439, 1.0, 1.0, 0.4324675001623439, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 985902.1304927894, 985902.1304927899, 215290.967609127], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5067000.0000, 
sim time next is 5067600.0000, 
raw observation next is [31.33333333333333, 73.66666666666667, 1.0, 2.0, 0.4394321027770264, 1.0, 2.0, 0.4394321027770264, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1001789.809682202, 1001789.809682202, 217290.2081460031], 
processed observation next is [0.0, 0.6521739130434783, 0.7160493827160492, 0.7366666666666667, 1.0, 1.0, 0.3326572652107457, 1.0, 1.0, 0.3326572652107457, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3577820748865007, 0.3577820748865007, 0.41786578489615983], 
reward next is 0.5821, 
noisyNet noise sample is [array([0.14856322], dtype=float32), 1.4427686]. 
=============================================
[2019-03-23 00:16:36,531] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.1530886e-31 4.4381492e-24 2.7013372e-24], sum to 1.0000
[2019-03-23 00:16:36,547] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0091
[2019-03-23 00:16:36,553] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1026124.607918933 W.
[2019-03-23 00:16:36,576] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333334, 87.66666666666667, 1.0, 2.0, 0.4357970086677009, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6977544768830243, 6.911199999999999, 6.9112, 121.9260426156618, 1026124.607918933, 1026124.607918933, 234649.7842998531], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5304000.0000, 
sim time next is 5304600.0000, 
raw observation next is [23.3, 87.0, 1.0, 2.0, 0.8671853688937198, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1030005.444205106, 1030005.444205106, 212263.4498177093], 
processed observation next is [1.0, 0.391304347826087, 0.41851851851851857, 0.87, 1.0, 1.0, 0.841887343921095, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.36785908721610927, 0.36785908721610927, 0.4081989419571333], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7129393], dtype=float32), 0.4058584]. 
=============================================
[2019-03-23 00:16:40,045] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 3.1222856e-37 2.2059741e-28 8.5737988e-25 2.0214490e-13], sum to 1.0000
[2019-03-23 00:16:40,053] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4979
[2019-03-23 00:16:40,060] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 850735.153682801 W.
[2019-03-23 00:16:40,066] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 89.33333333333334, 1.0, 2.0, 0.2488061491484121, 1.0, 1.0, 0.2488061491484121, 1.0, 1.0, 0.3961074924948465, 6.9112, 6.9112, 121.94756008, 850735.153682801, 850735.153682801, 237202.5155541978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5370000.0000, 
sim time next is 5370600.0000, 
raw observation next is [24.45, 89.66666666666666, 1.0, 2.0, 0.7203362236802908, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 827988.5052643642, 827988.5052643642, 180380.6120055785], 
processed observation next is [1.0, 0.13043478260869565, 0.4611111111111111, 0.8966666666666666, 1.0, 1.0, 0.6670669329527271, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2957101804515586, 0.2957101804515586, 0.3468857923184202], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2275083], dtype=float32), 0.6436728]. 
=============================================
[2019-03-23 00:16:42,877] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9298183e-01 0.0000000e+00 5.9400891e-25 6.0701817e-01 3.2983253e-23], sum to 1.0000
[2019-03-23 00:16:42,884] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5743
[2019-03-23 00:16:42,889] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.9, 71.0, 1.0, 2.0, 0.5803507051446338, 1.0, 2.0, 0.5803507051446338, 1.0, 1.0, 0.9239372232931968, 6.911200000000001, 6.9112, 121.94756008, 1985769.839820419, 1985769.839820419, 384773.6280095789], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5488800.0000, 
sim time next is 5489400.0000, 
raw observation next is [32.09999999999999, 70.0, 1.0, 2.0, 0.7795236566742898, 1.0, 2.0, 0.7795236566742898, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.926042484081, 1777976.647543816, 1777976.647543817, 335368.5242011338], 
processed observation next is [1.0, 0.5217391304347826, 0.744444444444444, 0.7, 1.0, 1.0, 0.7375281627074879, 1.0, 1.0, 0.7375281627074879, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621279465762, 0.6349916598370771, 0.6349916598370775, 0.644939469617565], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05282997], dtype=float32), -2.3382163]. 
=============================================
[2019-03-23 00:16:43,018] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.00000000e+00 8.27269078e-32 2.22315262e-17 1.14441494e-11
 1.01674508e-13], sum to 1.0000
[2019-03-23 00:16:43,025] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3995
[2019-03-23 00:16:43,030] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 874956.2254423847 W.
[2019-03-23 00:16:43,034] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.33333333333333, 89.16666666666667, 1.0, 2.0, 0.3838286726541526, 1.0, 2.0, 0.3838286726541526, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 874956.2254423847, 874956.2254423852, 201795.6221744593], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5440200.0000, 
sim time next is 5440800.0000, 
raw observation next is [27.26666666666667, 89.33333333333334, 1.0, 2.0, 0.254864255417124, 1.0, 2.0, 0.254864255417124, 1.0, 1.0, 0.4057521949733828, 6.9112, 6.9112, 121.94756008, 871461.2232606694, 871461.2232606694, 239356.8738659534], 
processed observation next is [1.0, 1.0, 0.5654320987654322, 0.8933333333333334, 1.0, 1.0, 0.11293363740133808, 1.0, 1.0, 0.11293363740133808, 1.0, 0.5, 0.25719024371672844, 0.0, 0.0, 0.8096049824067558, 0.3112361511645248, 0.3112361511645248, 0.4603016805114489], 
reward next is 0.5397, 
noisyNet noise sample is [array([-1.5145285], dtype=float32), 0.47571692]. 
=============================================
[2019-03-23 00:16:47,466] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.7503977e-21 1.3312201e-20 5.5458424e-12 1.0000000e+00 6.9132944e-20], sum to 1.0000
[2019-03-23 00:16:47,476] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8377
[2019-03-23 00:16:47,482] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 82.5, 1.0, 2.0, 0.3271878227363662, 1.0, 2.0, 0.3271878227363662, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745777.8237121577, 745777.8237121577, 187113.2477135537], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5517000.0000, 
sim time next is 5517600.0000, 
raw observation next is [26.46666666666667, 83.0, 1.0, 2.0, 0.3293657297806714, 1.0, 2.0, 0.3293657297806714, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 750744.4821731109, 750744.4821731109, 187657.2190241019], 
processed observation next is [1.0, 0.8695652173913043, 0.5358024691358025, 0.83, 1.0, 1.0, 0.2016258687865136, 1.0, 1.0, 0.2016258687865136, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2681230293475396, 0.2681230293475396, 0.36087926735404213], 
reward next is 0.6391, 
noisyNet noise sample is [array([-0.5930856], dtype=float32), 1.1880177]. 
=============================================
[2019-03-23 00:16:47,704] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0646288e-09 7.1066652e-16 1.8521367e-01 6.0261065e-08 8.1478631e-01], sum to 1.0000
[2019-03-23 00:16:47,715] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2470
[2019-03-23 00:16:47,722] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.76666666666667, 91.16666666666667, 1.0, 2.0, 0.3432843600763136, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5465198812325831, 6.911199999999999, 6.9112, 121.9260426156618, 782486.3044003986, 782486.3044003991, 207245.2418953434], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5530200.0000, 
sim time next is 5530800.0000, 
raw observation next is [25.73333333333333, 91.33333333333334, 1.0, 2.0, 0.2286851144295805, 1.0, 1.0, 0.2286851144295805, 1.0, 2.0, 0.3640741499261143, 6.9112, 6.9112, 121.94756008, 781900.8370494677, 781900.8370494677, 230194.3129425631], 
processed observation next is [1.0, 0.0, 0.5086419753086419, 0.9133333333333334, 1.0, 1.0, 0.08176799336854822, 1.0, 0.5, 0.08176799336854822, 1.0, 1.0, 0.20509268740764286, 0.0, 0.0, 0.8096049824067558, 0.2792502989462385, 0.2792502989462385, 0.44268137104339056], 
reward next is 0.5573, 
noisyNet noise sample is [array([-0.6407723], dtype=float32), 1.4401745]. 
=============================================
[2019-03-23 00:16:48,200] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.8267731e-19 6.7619005e-31 9.0069023e-21 1.0000000e+00 2.4557942e-20], sum to 1.0000
[2019-03-23 00:16:48,209] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9380
[2019-03-23 00:16:48,213] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.38333333333333, 87.5, 1.0, 2.0, 0.3225289072711996, 1.0, 2.0, 0.3225289072711996, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 735153.4002993043, 735153.4002993047, 185954.8797964502], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5554200.0000, 
sim time next is 5554800.0000, 
raw observation next is [25.4, 87.0, 1.0, 2.0, 0.3276419965305445, 1.0, 2.0, 0.3276419965305445, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 746813.552183487, 746813.552183487, 187226.1887273273], 
processed observation next is [1.0, 0.30434782608695654, 0.49629629629629624, 0.87, 1.0, 1.0, 0.19957380539350536, 1.0, 1.0, 0.19957380539350536, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26671912577981677, 0.26671912577981677, 0.3600503629371679], 
reward next is 0.6399, 
noisyNet noise sample is [array([1.7228509], dtype=float32), -0.7949243]. 
=============================================
[2019-03-23 00:16:51,009] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1364021e-15 3.4524702e-27 6.6888274e-04 9.9933112e-01 1.7453825e-17], sum to 1.0000
[2019-03-23 00:16:51,019] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5584
[2019-03-23 00:16:51,024] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.43333333333334, 91.66666666666666, 1.0, 2.0, 0.3259610596732791, 1.0, 2.0, 0.3259610596732791, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742980.2376970996, 742980.2376970996, 186807.7689419561], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5596800.0000, 
sim time next is 5597400.0000, 
raw observation next is [25.46666666666667, 91.83333333333333, 1.0, 2.0, 0.3322738308359883, 1.0, 2.0, 0.3322738308359883, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 757376.3786191127, 757376.3786191131, 188386.2860099478], 
processed observation next is [1.0, 0.782608695652174, 0.4987654320987655, 0.9183333333333333, 1.0, 1.0, 0.20508789385236706, 1.0, 1.0, 0.20508789385236706, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27049156379254025, 0.2704915637925404, 0.3622813192498996], 
reward next is 0.6377, 
noisyNet noise sample is [array([-2.0643067], dtype=float32), 0.2368495]. 
=============================================
[2019-03-23 00:16:53,748] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3170822e-05 1.5176406e-14 9.9941862e-01 5.6820462e-04 1.2693194e-13], sum to 1.0000
[2019-03-23 00:16:53,758] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0845
[2019-03-23 00:16:53,767] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.95, 96.0, 1.0, 2.0, 0.304014761787199, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4840014018347825, 6.911199999999999, 6.9112, 121.9260426156618, 692934.2739085577, 692934.2739085582, 196327.2586202319], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5638200.0000, 
sim time next is 5638800.0000, 
raw observation next is [24.0, 96.0, 1.0, 2.0, 0.3053442939026078, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4861180602623513, 6.9112, 6.9112, 121.9260426156618, 695966.023321951, 695966.023321951, 196686.8110500471], 
processed observation next is [0.0, 0.2608695652173913, 0.4444444444444444, 0.96, 1.0, 1.0, 0.17302892131262834, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3576475753279391, 0.0, 0.0, 0.8094621288201359, 0.24855929404355395, 0.24855929404355395, 0.37824386740393673], 
reward next is 0.6218, 
noisyNet noise sample is [array([-2.033365], dtype=float32), 1.158104]. 
=============================================
[2019-03-23 00:16:53,845] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 00:16:53,847] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:16:53,848] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:53,849] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:16:53,849] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:16:53,850] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:53,850] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:16:53,851] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:16:53,852] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:53,854] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:53,852] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:16:53,870] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run24
[2019-03-23 00:16:53,891] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run24
[2019-03-23 00:16:53,892] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run24
[2019-03-23 00:16:53,893] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run24
[2019-03-23 00:16:53,933] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run24
[2019-03-23 00:17:15,052] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01860683], dtype=float32), 0.04087851]
[2019-03-23 00:17:15,055] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.82096207666667, 69.57872166333334, 1.0, 2.0, 0.1665386494341354, 1.0, 2.0, 0.1665386494341354, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 418670.6636675787, 418670.6636675792, 153135.8689331663]
[2019-03-23 00:17:15,057] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:17:15,060] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.0838225e-12 1.7506496e-08 3.4769077e-02 9.6523094e-01 1.5082787e-09], sampled 0.29733429526594257
[2019-03-23 00:17:43,424] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01860683], dtype=float32), 0.04087851]
[2019-03-23 00:17:43,426] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.16666666666667, 93.16666666666667, 1.0, 2.0, 0.24884126518736, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4001079482290411, 6.911199999999999, 6.9112, 121.9260426156618, 592168.9973603486, 592168.997360349, 181101.7837322542]
[2019-03-23 00:17:43,427] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:17:43,430] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.8635291e-14 5.9499072e-11 6.5652233e-01 3.4347761e-01 4.4920050e-11], sampled 0.09496247531924129
[2019-03-23 00:17:59,428] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01860683], dtype=float32), 0.04087851]
[2019-03-23 00:17:59,431] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.0, 94.0, 1.0, 2.0, 0.332198642741717, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5288710581992969, 6.911199999999999, 6.9112, 121.9260426156618, 757204.9121717567, 757204.9121717572, 204100.28180353]
[2019-03-23 00:17:59,432] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:17:59,438] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.0921177e-17 5.2384852e-18 1.8689924e-01 8.1310081e-01 8.4615539e-13], sampled 0.07359144572099663
[2019-03-23 00:18:41,023] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01860683], dtype=float32), 0.04087851]
[2019-03-23 00:18:41,023] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.0, 88.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 314832.2514506207, 314832.2514506212, 137710.6838087077]
[2019-03-23 00:18:41,025] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:18:41,030] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2763010e-09 5.7397767e-07 9.2583820e-02 9.0741539e-01 2.3043063e-07], sampled 0.6514786469169366
[2019-03-23 00:18:42,377] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7732.0627 2435326796.5557 33.0000
[2019-03-23 00:18:42,585] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7875.7956 2431648118.6489 24.0000
[2019-03-23 00:18:42,611] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 7679.6771 2484337756.4727 48.0000
[2019-03-23 00:18:42,757] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7706.5303 2478260688.0427 46.0000
[2019-03-23 00:18:42,811] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7623.7470 2685889742.5808 66.0000
[2019-03-23 00:18:43,825] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 575000, evaluation results [575000.0, 7623.746988256139, 2685889742.5808325, 66.0, 7732.062696862465, 2435326796.5556717, 33.0, 7875.79558953547, 2431648118.6489305, 24.0, 7679.67712804651, 2484337756.472728, 48.0, 7706.530336882743, 2478260688.042722, 46.0]
[2019-03-23 00:18:48,859] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7774865e-24 2.5071203e-25 1.0000000e+00 3.3083600e-31 1.4642659e-25], sum to 1.0000
[2019-03-23 00:18:48,868] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0510
[2019-03-23 00:18:48,879] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.3, 78.33333333333333, 1.0, 2.0, 0.2769840358843543, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4422121253018884, 6.911199999999999, 6.9112, 121.9260426156618, 645248.5802993366, 645248.580299337, 188827.4390110568], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5775000.0000, 
sim time next is 5775600.0000, 
raw observation next is [25.2, 78.66666666666667, 1.0, 2.0, 0.2753417750553008, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4396900140377797, 6.911199999999999, 6.9112, 121.9260426156618, 642061.3050683182, 642061.3050683186, 188380.6881778302], 
processed observation next is [0.0, 0.8695652173913043, 0.4888888888888889, 0.7866666666666667, 1.0, 1.0, 0.13731163697059617, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.29961251754722457, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22930760895297078, 0.22930760895297092, 0.362270554188135], 
reward next is 0.6377, 
noisyNet noise sample is [array([1.8183858], dtype=float32), -0.5150262]. 
=============================================
[2019-03-23 00:18:51,907] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2564778e-17 9.7093079e-18 1.0000000e+00 3.8253311e-21 4.5449823e-28], sum to 1.0000
[2019-03-23 00:18:51,918] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3779
[2019-03-23 00:18:51,924] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.9, 79.66666666666667, 1.0, 2.0, 0.271476490665395, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4338328812500484, 6.911199999999999, 6.9112, 121.9260426156618, 634914.955542841, 634914.9555428415, 187316.7382432554], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5777400.0000, 
sim time next is 5778000.0000, 
raw observation next is [24.8, 80.0, 1.0, 2.0, 0.2699616691097969, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4315256019277842, 6.911199999999999, 6.9112, 121.9260426156618, 631996.4142400585, 631996.414240059, 186904.2563395734], 
processed observation next is [0.0, 0.9130434782608695, 0.4740740740740741, 0.8, 1.0, 1.0, 0.1309067489402344, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.2894070024097302, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2257130050857352, 0.22571300508573536, 0.3594312621914873], 
reward next is 0.6406, 
noisyNet noise sample is [array([-0.07648335], dtype=float32), 1.4727381]. 
=============================================
[2019-03-23 00:18:51,950] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[63.84878 ]
 [63.885895]
 [64.073555]
 [63.87704 ]
 [63.53466 ]], R is [[64.06843567]
 [64.06752777]
 [64.06589508]
 [64.06365204]
 [63.42301559]].
[2019-03-23 00:18:52,639] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.8491610e-24 2.9188544e-30 6.3185321e-06 9.9999368e-01 1.6045469e-21], sum to 1.0000
[2019-03-23 00:18:52,649] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9013
[2019-03-23 00:18:52,657] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.05, 87.5, 1.0, 2.0, 0.2826703810474374, 1.0, 2.0, 0.2826703810474374, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 678957.2955178521, 678957.2955178525, 177887.6528481188], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5797800.0000, 
sim time next is 5798400.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.2783255790859278, 1.0, 2.0, 0.2783255790859278, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668893.4249924573, 668893.4249924573, 176869.7588824823], 
processed observation next is [1.0, 0.08695652173913043, 0.37037037037037035, 0.88, 1.0, 1.0, 0.14086378462610455, 1.0, 1.0, 0.14086378462610455, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2388905089258776, 0.2388905089258776, 0.34013415169708133], 
reward next is 0.6599, 
noisyNet noise sample is [array([0.05724199], dtype=float32), 0.1628445]. 
=============================================
[2019-03-23 00:19:00,258] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8559925e-29 1.0747822e-34 5.8291903e-07 9.9999940e-01 2.7275254e-37], sum to 1.0000
[2019-03-23 00:19:00,261] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4518
[2019-03-23 00:19:00,269] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.4, 53.0, 1.0, 2.0, 0.2243014649732838, 1.0, 2.0, 0.2243014649732838, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 534113.6094914566, 534113.609491457, 164398.5372998525], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5938200.0000, 
sim time next is 5938800.0000, 
raw observation next is [28.26666666666667, 53.66666666666667, 1.0, 2.0, 0.2273225989809972, 1.0, 2.0, 0.2273225989809972, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541382.421572309, 541382.421572309, 165058.9404389764], 
processed observation next is [1.0, 0.7391304347826086, 0.6024691358024692, 0.5366666666666667, 1.0, 1.0, 0.0801459511678538, 1.0, 1.0, 0.0801459511678538, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19335086484725322, 0.19335086484725322, 0.31742103930572385], 
reward next is 0.6826, 
noisyNet noise sample is [array([-0.11727011], dtype=float32), 0.42609382]. 
=============================================
[2019-03-23 00:19:01,717] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.2757517e-29 8.3789869e-33 1.8005857e-11 1.0000000e+00 9.5937418e-25], sum to 1.0000
[2019-03-23 00:19:01,729] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5216
[2019-03-23 00:19:01,739] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.6, 82.5, 1.0, 2.0, 0.2278095861314352, 1.0, 2.0, 0.2278095861314352, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 549577.7700985556, 549577.7700985556, 165442.2319889992], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5963400.0000, 
sim time next is 5964000.0000, 
raw observation next is [22.6, 82.0, 1.0, 2.0, 0.2259012219292868, 1.0, 2.0, 0.2259012219292868, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 545593.1030755366, 545593.103075537, 165047.6274372566], 
processed observation next is [1.0, 0.0, 0.39259259259259266, 0.82, 1.0, 1.0, 0.07845383563010333, 1.0, 1.0, 0.07845383563010333, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19485467966983447, 0.19485467966983464, 0.31739928353318575], 
reward next is 0.6826, 
noisyNet noise sample is [array([0.56272274], dtype=float32), -1.8369471]. 
=============================================
[2019-03-23 00:19:01,750] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[61.487823]
 [61.86862 ]
 [62.307304]
 [62.953465]
 [63.415707]], R is [[61.13280106]
 [61.20331573]
 [61.27244186]
 [61.34031677]
 [61.40687943]].
[2019-03-23 00:19:06,559] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.000000e+00 0.000000e+00 5.944187e-22 1.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 00:19:06,569] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1546
[2019-03-23 00:19:06,576] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.1, 54.0, 1.0, 2.0, 0.7725257590112857, 1.0, 2.0, 0.7725257590112857, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1761999.749482667, 1761999.749482667, 332530.9109729691], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6105600.0000, 
sim time next is 6106200.0000, 
raw observation next is [30.06666666666667, 54.16666666666666, 1.0, 2.0, 0.7782582137860473, 1.0, 2.0, 0.7782582137860473, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1775087.494097109, 1775087.494097109, 334850.7636018132], 
processed observation next is [1.0, 0.6956521739130435, 0.669135802469136, 0.5416666666666665, 1.0, 1.0, 0.7360216830786277, 1.0, 1.0, 0.7360216830786277, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.633959819320396, 0.633959819320396, 0.643943776157333], 
reward next is 0.3561, 
noisyNet noise sample is [array([0.3884996], dtype=float32), -1.4502542]. 
=============================================
[2019-03-23 00:19:07,840] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.3584577e-28 3.3950200e-29 4.7331766e-10 1.0000000e+00 1.3562435e-21], sum to 1.0000
[2019-03-23 00:19:07,849] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1475
[2019-03-23 00:19:07,855] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.4, 80.66666666666666, 1.0, 2.0, 0.2886112227292958, 1.0, 1.0, 0.2886112227292958, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 677258.641321697, 677258.641321697, 178669.6997823581], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6075600.0000, 
sim time next is 6076200.0000, 
raw observation next is [24.45, 80.33333333333334, 1.0, 2.0, 0.290366031650317, 1.0, 2.0, 0.290366031650317, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 680945.3485733623, 680945.3485733623, 179069.9788898757], 
processed observation next is [1.0, 0.30434782608695654, 0.4611111111111111, 0.8033333333333335, 1.0, 1.0, 0.15519765672656785, 1.0, 1.0, 0.15519765672656785, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2431947673476294, 0.2431947673476294, 0.3443653440189917], 
reward next is 0.6556, 
noisyNet noise sample is [array([0.41837826], dtype=float32), -2.0475252]. 
=============================================
[2019-03-23 00:19:09,199] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2130497e-32 0.0000000e+00 3.4202668e-20 1.0000000e+00 7.3888494e-25], sum to 1.0000
[2019-03-23 00:19:09,209] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2726
[2019-03-23 00:19:09,212] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.6, 87.0, 1.0, 2.0, 0.2820583946866068, 1.0, 2.0, 0.2820583946866068, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 660944.4424432805, 660944.442443281, 177073.2054012252], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6159600.0000, 
sim time next is 6160200.0000, 
raw observation next is [23.7, 86.66666666666667, 1.0, 2.0, 0.3150344778735343, 1.0, 2.0, 0.3150344778735343, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 736830.3048751539, 736830.3048751544, 184988.6303584927], 
processed observation next is [1.0, 0.30434782608695654, 0.4333333333333333, 0.8666666666666667, 1.0, 1.0, 0.18456485461135033, 1.0, 1.0, 0.18456485461135033, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.263153680312555, 0.26315368031255515, 0.3557473660740244], 
reward next is 0.6443, 
noisyNet noise sample is [array([0.63787484], dtype=float32), -1.5903496]. 
=============================================
[2019-03-23 00:19:09,540] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 0.0000000e+00 3.0226087e-24 1.0000000e+00 2.7656219e-37], sum to 1.0000
[2019-03-23 00:19:09,549] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8733
[2019-03-23 00:19:09,554] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.43333333333333, 52.66666666666667, 1.0, 2.0, 0.8793549688147437, 1.0, 2.0, 0.8793549688147437, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 2005932.611794998, 2005932.611794997, 377634.7505327138], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6101400.0000, 
sim time next is 6102000.0000, 
raw observation next is [30.4, 53.0, 1.0, 2.0, 0.8897936637065712, 1.0, 2.0, 0.8897936637065712, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2029771.807959272, 2029771.807959272, 382254.1362465245], 
processed observation next is [1.0, 0.6521739130434783, 0.6814814814814815, 0.53, 1.0, 1.0, 0.8688019806030609, 1.0, 1.0, 0.8688019806030609, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7249185028425972, 0.7249185028425972, 0.7351041081663933], 
reward next is 0.2649, 
noisyNet noise sample is [array([1.8394899], dtype=float32), -0.013042857]. 
=============================================
[2019-03-23 00:19:09,572] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[52.99075 ]
 [53.154   ]
 [53.338707]
 [53.508205]
 [53.752792]], R is [[52.57126617]
 [52.31933594]
 [52.07009125]
 [51.82227325]
 [51.58825302]].
[2019-03-23 00:19:10,374] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.2447787e-31 8.5653272e-26 7.6043871e-10 1.0000000e+00 1.4331072e-36], sum to 1.0000
[2019-03-23 00:19:10,386] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0278
[2019-03-23 00:19:10,392] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.23333333333333, 77.16666666666666, 1.0, 2.0, 0.2702423096078113, 1.0, 2.0, 0.2702423096078113, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630514.3072786106, 630514.3072786106, 174184.2684592581], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6133800.0000, 
sim time next is 6134400.0000, 
raw observation next is [25.1, 78.0, 1.0, 2.0, 0.2700796339944462, 1.0, 2.0, 0.2700796339944462, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 630228.9520058807, 630228.9520058811, 174150.8984056655], 
processed observation next is [1.0, 0.0, 0.4851851851851852, 0.78, 1.0, 1.0, 0.13104718332672163, 1.0, 1.0, 0.13104718332672163, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2250817685735288, 0.22508176857352896, 0.33490557385704905], 
reward next is 0.6651, 
noisyNet noise sample is [array([-2.5030146], dtype=float32), 1.0562397]. 
=============================================
[2019-03-23 00:19:10,716] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.0000000e+00 0.0000000e+00 1.8036993e-38 1.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:19:10,727] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7969
[2019-03-23 00:19:10,732] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.85, 54.5, 1.0, 2.0, 0.7902480201814122, 1.0, 2.0, 0.7902480201814122, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1802461.993215753, 1802461.993215754, 339739.6260801735], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6186600.0000, 
sim time next is 6187200.0000, 
raw observation next is [29.86666666666667, 54.33333333333334, 1.0, 2.0, 0.788993150486277, 1.0, 2.0, 0.788993150486277, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1799596.901026718, 1799596.901026718, 339225.5981408911], 
processed observation next is [1.0, 0.6086956521739131, 0.6617283950617285, 0.5433333333333334, 1.0, 1.0, 0.7488013696265203, 1.0, 1.0, 0.7488013696265203, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6427131789381136, 0.6427131789381136, 0.6523569195017137], 
reward next is 0.3476, 
noisyNet noise sample is [array([0.64121276], dtype=float32), -2.9107604]. 
=============================================
[2019-03-23 00:19:19,698] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3633279e-23 6.4549138e-22 1.8395605e-13 1.0000000e+00 1.1492620e-34], sum to 1.0000
[2019-03-23 00:19:19,707] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1606
[2019-03-23 00:19:19,712] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.5, 86.0, 1.0, 2.0, 0.2897365555586024, 1.0, 2.0, 0.2897365555586024, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 668652.0172703079, 668652.0172703083, 178424.5957290646], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6310800.0000, 
sim time next is 6311400.0000, 
raw observation next is [24.46666666666667, 86.33333333333334, 1.0, 2.0, 0.2902021673017138, 1.0, 2.0, 0.2902021673017138, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 669545.532335665, 669545.5323356654, 178526.5418892747], 
processed observation next is [0.0, 0.043478260869565216, 0.46172839506172847, 0.8633333333333334, 1.0, 1.0, 0.15500258012108784, 1.0, 1.0, 0.15500258012108784, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23912340440559463, 0.2391234044055948, 0.3433202728639898], 
reward next is 0.6567, 
noisyNet noise sample is [array([2.3053157], dtype=float32), -0.5201911]. 
=============================================
[2019-03-23 00:19:23,792] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 0. 0. 1. 0.], sum to 1.0000
[2019-03-23 00:19:23,798] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7995
[2019-03-23 00:19:23,803] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.68333333333333, 81.0, 1.0, 2.0, 0.9506543866929255, 1.0, 2.0, 0.9506543866929255, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2168774.147359445, 2168774.147359445, 409940.0785519322], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6429000.0000, 
sim time next is 6429600.0000, 
raw observation next is [27.9, 80.0, 1.0, 2.0, 0.9709610058225866, 1.0, 2.0, 0.9709610058225866, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2215158.095364781, 2215158.095364781, 419462.704609469], 
processed observation next is [1.0, 0.43478260869565216, 0.5888888888888888, 0.8, 1.0, 1.0, 0.9654297688364126, 1.0, 1.0, 0.9654297688364126, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7911278912017076, 0.7911278912017076, 0.8066590473259019], 
reward next is 0.1933, 
noisyNet noise sample is [array([-0.5315752], dtype=float32), 1.078338]. 
=============================================
[2019-03-23 00:19:25,940] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.000000e+00 0.000000e+00 8.313854e-31 1.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 00:19:25,952] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1625
[2019-03-23 00:19:25,960] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.43333333333333, 90.16666666666667, 1.0, 2.0, 0.4561931067643321, 1.0, 2.0, 0.4561931067643321, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1040026.429018072, 1040026.429018072, 222167.5142328854], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6423000.0000, 
sim time next is 6423600.0000, 
raw observation next is [25.66666666666667, 89.33333333333334, 1.0, 2.0, 0.6684263016887321, 1.0, 2.0, 0.6684263016887321, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1524355.88571731, 1524355.88571731, 292385.1325609552], 
processed observation next is [1.0, 0.34782608695652173, 0.506172839506173, 0.8933333333333334, 1.0, 1.0, 0.6052694067723001, 1.0, 1.0, 0.6052694067723001, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5444128163276107, 0.5444128163276107, 0.56227910107876], 
reward next is 0.4377, 
noisyNet noise sample is [array([0.01376679], dtype=float32), 0.8500172]. 
=============================================
[2019-03-23 00:19:27,827] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.3460761e-19 0.0000000e+00 2.0199317e-23 1.0000000e+00 3.7940240e-23], sum to 1.0000
[2019-03-23 00:19:27,833] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8539
[2019-03-23 00:19:27,836] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.75, 82.0, 1.0, 2.0, 0.1681831591746162, 1.0, 2.0, 0.1681831591746162, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 427600.2872453319, 427600.2872453324, 153540.9940231965], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6751800.0000, 
sim time next is 6752400.0000, 
raw observation next is [18.66666666666666, 82.33333333333333, 1.0, 2.0, 0.1672776699911061, 1.0, 2.0, 0.1672776699911061, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 425457.434209568, 425457.4342095685, 153357.7378242308], 
processed observation next is [1.0, 0.13043478260869565, 0.24691358024691337, 0.8233333333333333, 1.0, 1.0, 0.008663892846554881, 1.0, 1.0, 0.008663892846554881, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1519490836462743, 0.15194908364627446, 0.29491872658505924], 
reward next is 0.7051, 
noisyNet noise sample is [array([0.55447567], dtype=float32), 2.2029145]. 
=============================================
[2019-03-23 00:19:28,589] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.2678100e-11 3.3319589e-16 5.8791204e-03 9.9412090e-01 6.2546136e-12], sum to 1.0000
[2019-03-23 00:19:28,596] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3797
[2019-03-23 00:19:28,604] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.78333333333333, 59.5, 1.0, 2.0, 0.2206925724389326, 1.0, 2.0, 0.2206925724389326, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 556217.6738634731, 556217.6738634736, 164545.5863630252], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6768600.0000, 
sim time next is 6769200.0000, 
raw observation next is [22.96666666666667, 59.00000000000001, 1.0, 2.0, 0.3380931094136613, 1.0, 2.0, 0.3380931094136613, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 848536.4016444868, 848536.4016444873, 192610.7773276072], 
processed observation next is [1.0, 0.34782608695652173, 0.4061728395061729, 0.5900000000000001, 1.0, 1.0, 0.21201560644483486, 1.0, 1.0, 0.21201560644483486, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30304871487303103, 0.3030487148730312, 0.37040534101462924], 
reward next is 0.6296, 
noisyNet noise sample is [array([-0.56177855], dtype=float32), -0.7362606]. 
=============================================
[2019-03-23 00:19:33,371] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.8746699e-24 0.0000000e+00 2.3253186e-22 1.0000000e+00 8.3721585e-31], sum to 1.0000
[2019-03-23 00:19:33,378] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8439
[2019-03-23 00:19:33,387] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.65, 38.5, 1.0, 2.0, 0.4775863436201391, 1.0, 2.0, 0.4775863436201391, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1184779.651485537, 1184779.651485538, 232113.1148042365], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6607800.0000, 
sim time next is 6608400.0000, 
raw observation next is [27.76666666666667, 39.0, 1.0, 2.0, 0.4750418766085447, 1.0, 2.0, 0.4750418766085447, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1175141.156244112, 1175141.156244113, 231249.5371320433], 
processed observation next is [1.0, 0.4782608695652174, 0.5839506172839507, 0.39, 1.0, 1.0, 0.37504985310541034, 1.0, 1.0, 0.37504985310541034, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4196932700871828, 0.41969327008718327, 0.4447106483308525], 
reward next is 0.5553, 
noisyNet noise sample is [array([0.6341531], dtype=float32), 0.8294116]. 
=============================================
[2019-03-23 00:19:34,441] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 00:19:34,442] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:19:34,443] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:19:34,447] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:19:34,448] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:19:34,449] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:19:34,449] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:19:34,450] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:19:34,452] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:19:34,453] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:19:34,453] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:19:34,473] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run25
[2019-03-23 00:19:34,496] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run25
[2019-03-23 00:19:34,497] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run25
[2019-03-23 00:19:34,538] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run25
[2019-03-23 00:19:34,562] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run25
[2019-03-23 00:20:15,312] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01549301], dtype=float32), -0.0006035094]
[2019-03-23 00:20:15,313] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.8, 65.0, 1.0, 2.0, 0.3510721600522767, 1.0, 2.0, 0.3510721600522767, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 800247.171644771, 800247.1716447715, 193169.4304314668]
[2019-03-23 00:20:15,314] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:20:15,317] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4673745e-18 3.6813128e-28 5.9331845e-12 1.0000000e+00 5.5765309e-30], sampled 0.7146680828354082
[2019-03-23 00:20:18,921] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01549301], dtype=float32), -0.0006035094]
[2019-03-23 00:20:18,922] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.33333333333333, 64.66666666666666, 1.0, 2.0, 0.2632714414787904, 1.0, 2.0, 0.2632714414787904, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 614575.3237347879, 614575.3237347883, 172593.1744618518]
[2019-03-23 00:20:18,926] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:20:18,928] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.0517312e-12 5.2799831e-16 1.7541341e-06 9.9999821e-01 1.7066323e-21], sampled 0.21988271280432703
[2019-03-23 00:20:25,397] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01549301], dtype=float32), -0.0006035094]
[2019-03-23 00:20:25,398] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.13333333333334, 68.33333333333334, 1.0, 2.0, 0.4102092167298306, 1.0, 2.0, 0.4102092167298306, 0.0, 2.0, 0.0, 6.9112, 6.9112, 122.2973727499453, 962167.3319571167, 962167.3319571167, 210293.9708463649]
[2019-03-23 00:20:25,399] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:20:25,403] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3734038e-13 2.4586767e-16 5.9605888e-08 9.9999988e-01 8.0313960e-23], sampled 0.4743194161758144
[2019-03-23 00:21:03,924] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01549301], dtype=float32), -0.0006035094]
[2019-03-23 00:21:03,925] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.8, 71.0, 1.0, 2.0, 1.00860360711783, 1.0, 2.0, 1.00860360711783, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2301146.899932845, 2301146.899932845, 437493.0890404149]
[2019-03-23 00:21:03,926] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:21:03,931] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 0. 0. 1. 0.], sampled 0.45901546379233715
[2019-03-23 00:21:24,419] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7585.4255 2467702995.9969 46.0000
[2019-03-23 00:21:24,802] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7860.0435 2414640425.7747 22.0000
[2019-03-23 00:21:25,063] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7374.0810 2433961803.0990 33.0000
[2019-03-23 00:21:25,100] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 7286.3673 2486227341.1365 47.0000
[2019-03-23 00:21:25,121] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7563.9701 2671380280.9906 68.0000
[2019-03-23 00:21:26,135] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 600000, evaluation results [600000.0, 7563.970122743262, 2671380280.9906406, 68.0, 7374.081008942685, 2433961803.099016, 33.0, 7860.0435175566545, 2414640425.7747407, 22.0, 7286.367274423286, 2486227341.136463, 47.0, 7585.4255037156, 2467702995.996916, 46.0]
[2019-03-23 00:21:33,696] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 6.3080407e-27 1.7807792e-19 3.4201076e-29], sum to 1.0000
[2019-03-23 00:21:33,706] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5549
[2019-03-23 00:21:33,715] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 971647.9364054189 W.
[2019-03-23 00:21:33,722] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.55, 29.33333333333333, 1.0, 2.0, 0.3873963458125229, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6533409212769431, 6.911199999999999, 6.9112, 121.9260426156618, 971647.9364054189, 971647.9364054194, 215458.6557632006], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6702600.0000, 
sim time next is 6703200.0000, 
raw observation next is [29.7, 29.0, 1.0, 2.0, 0.268946527151265, 1.0, 1.0, 0.268946527151265, 1.0, 2.0, 0.4480877776701226, 6.9112, 6.9112, 121.94756008, 1003297.653643247, 1003297.653643247, 242064.4881950978], 
processed observation next is [1.0, 0.6086956521739131, 0.6555555555555556, 0.29, 1.0, 1.0, 0.1296982466086488, 1.0, 0.5, 0.1296982466086488, 1.0, 1.0, 0.3101097220876532, 0.0, 0.0, 0.8096049824067558, 0.35832059058687393, 0.35832059058687393, 0.46550863114441887], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9298592], dtype=float32), -1.701841]. 
=============================================
[2019-03-23 00:21:34,488] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 4.9266272e-29 5.8346842e-31 5.5694628e-26], sum to 1.0000
[2019-03-23 00:21:34,498] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4600
[2019-03-23 00:21:34,503] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 44.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5570961287736922, 6.9112, 6.9112, 121.9260426156618, 410125.1578786338, 410125.1578786338, 124420.9364337554], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6724800.0000, 
sim time next is 6725400.0000, 
raw observation next is [25.71666666666667, 45.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5662383311579743, 6.911200000000001, 6.9112, 121.9260426156618, 416937.2491633606, 416937.2491633601, 125265.5522535818], 
processed observation next is [1.0, 0.8695652173913043, 0.5080246913580247, 0.455, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4577979139474678, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14890616041548593, 0.14890616041548574, 0.24089529279534963], 
reward next is 0.7591, 
noisyNet noise sample is [array([0.24979647], dtype=float32), -1.0799619]. 
=============================================
[2019-03-23 00:21:35,967] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 5.6270602e-33 1.0333041e-28 6.5160151e-24], sum to 1.0000
[2019-03-23 00:21:35,973] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4552
[2019-03-23 00:21:35,978] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.75, 80.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5086696597067933, 6.9112, 6.9112, 121.9260426156618, 367655.3017869951, 367655.3017869951, 117340.465974814], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6759000.0000, 
sim time next is 6759600.0000, 
raw observation next is [19.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5084053942754054, 6.911200000000001, 6.9112, 121.9260426156618, 367883.4379565189, 367883.4379565184, 117477.2154248307], 
processed observation next is [1.0, 0.21739130434782608, 0.25925925925925924, 0.79, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.38550674284425673, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13138694212732818, 0.131386942127328, 0.22591772197082827], 
reward next is 0.7741, 
noisyNet noise sample is [array([-1.043373], dtype=float32), 0.41788355]. 
=============================================
[2019-03-23 00:21:39,208] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.0856342e-31 0.0000000e+00 3.7896913e-27], sum to 1.0000
[2019-03-23 00:21:39,216] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0508
[2019-03-23 00:21:39,221] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.764354133043981, 6.9112, 6.9112, 121.9260426156618, 569136.8154963773, 569136.8154963773, 155146.8093024365], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6807600.0000, 
sim time next is 6808200.0000, 
raw observation next is [25.83333333333334, 65.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7632290559468508, 6.9112, 6.9112, 121.9260426156618, 568422.0054060986, 568422.0054060986, 154926.7951063794], 
processed observation next is [1.0, 0.8260869565217391, 0.5123456790123458, 0.6583333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7040363199335633, 0.0, 0.0, 0.8094621288201359, 0.20300785907360663, 0.20300785907360663, 0.297936144435345], 
reward next is 0.7021, 
noisyNet noise sample is [array([-0.67569286], dtype=float32), 1.5915387]. 
=============================================
[2019-03-23 00:21:42,128] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.4112457e-34 1.3227271e-26 3.2742415e-27 4.8753154e-26], sum to 1.0000
[2019-03-23 00:21:42,138] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9178
[2019-03-23 00:21:42,143] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.05, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6848190678125544, 6.9112, 6.9112, 121.9260426156618, 511755.8165295028, 511755.8165295028, 143148.332701798], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6852600.0000, 
sim time next is 6853200.0000, 
raw observation next is [23.13333333333333, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6896038645625567, 6.9112, 6.9112, 121.9260426156618, 515324.5426450467, 515324.5426450467, 143869.4107719073], 
processed observation next is [0.0, 0.30434782608695654, 0.41234567901234553, 0.76, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6120048307031959, 0.0, 0.0, 0.8094621288201359, 0.18404447951608813, 0.18404447951608813, 0.27667194379212945], 
reward next is 0.7233, 
noisyNet noise sample is [array([0.11373216], dtype=float32), -0.2518402]. 
=============================================
[2019-03-23 00:21:43,401] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.2160631e-28 9.6758807e-26 3.8128335e-20 1.9142712e-24], sum to 1.0000
[2019-03-23 00:21:43,409] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3419
[2019-03-23 00:21:43,414] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.55, 61.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7124820758212475, 6.911199999999999, 6.9112, 121.9260426156618, 532394.6054271165, 532394.605427117, 146627.9892694213], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6900600.0000, 
sim time next is 6901200.0000, 
raw observation next is [25.4, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7118995152564724, 6.9112, 6.9112, 121.9260426156618, 531971.3705828723, 531971.3705828723, 146490.3563729688], 
processed observation next is [0.0, 0.9130434782608695, 0.49629629629629624, 0.62, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6398743940705905, 0.0, 0.0, 0.8094621288201359, 0.18998977520816868, 0.18998977520816868, 0.28171222379417077], 
reward next is 0.7183, 
noisyNet noise sample is [array([0.50915885], dtype=float32), -0.7574185]. 
=============================================
[2019-03-23 00:21:43,703] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.5342741e-25 9.6331641e-25 7.3647800e-20 1.1751882e-19], sum to 1.0000
[2019-03-23 00:21:43,714] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8848
[2019-03-23 00:21:43,718] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.8, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8219590207203451, 6.9112, 6.9112, 121.9260426156618, 608463.372543937, 608463.372543937, 163962.7002248305], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6881400.0000, 
sim time next is 6882000.0000, 
raw observation next is [29.66666666666666, 50.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8186370994994645, 6.911200000000001, 6.9112, 121.9260426156618, 606300.4927374483, 606300.4927374478, 163427.565695052], 
processed observation next is [0.0, 0.6521739130434783, 0.6543209876543208, 0.5033333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7732963743743306, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2165358902633744, 0.21653589026337422, 0.3142837801827923], 
reward next is 0.6857, 
noisyNet noise sample is [array([0.41125405], dtype=float32), -0.5067892]. 
=============================================
[2019-03-23 00:21:43,730] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[74.18279 ]
 [74.109184]
 [74.0342  ]
 [73.97119 ]
 [73.865585]], R is [[74.19361877]
 [74.1363678 ]
 [74.07875061]
 [74.02084351]
 [73.96234131]].
[2019-03-23 00:21:47,871] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.3184787e-21 1.3001408e-18 2.8856704e-15 2.8868471e-16], sum to 1.0000
[2019-03-23 00:21:47,881] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8790
[2019-03-23 00:21:47,885] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.0, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8596272679086703, 6.9112, 6.9112, 121.9260426156618, 632607.0959418337, 632607.0959418337, 169848.8558312177], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6958800.0000, 
sim time next is 6959400.0000, 
raw observation next is [30.16666666666666, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8630791304127021, 6.911200000000001, 6.9112, 121.9260426156618, 634757.7788137669, 634757.7788137665, 170392.7839648295], 
processed observation next is [0.0, 0.5652173913043478, 0.6728395061728393, 0.515, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8288489130158777, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22669920671920246, 0.22669920671920235, 0.3276784307015952], 
reward next is 0.6723, 
noisyNet noise sample is [array([-0.8844661], dtype=float32), -1.1038417]. 
=============================================
[2019-03-23 00:21:54,040] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.1118702e-30 0.0000000e+00 3.1682333e-25], sum to 1.0000
[2019-03-23 00:21:54,048] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0715
[2019-03-23 00:21:54,055] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 711715.7157281288 W.
[2019-03-23 00:21:54,063] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.86666666666667, 78.16666666666667, 1.0, 2.0, 0.2989434323404317, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4807472008389542, 6.9112, 6.9112, 121.9260426156618, 711715.7157281288, 711715.7157281288, 193950.0937200272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7060200.0000, 
sim time next is 7060800.0000, 
raw observation next is [23.83333333333333, 78.33333333333334, 1.0, 2.0, 0.4687326337735325, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 563570.3522126428, 563570.3522126423, 138227.8457860138], 
processed observation next is [1.0, 0.7391304347826086, 0.43827160493827144, 0.7833333333333334, 1.0, 1.0, 0.3675388497303959, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20127512579022958, 0.2012751257902294, 0.26582278035771884], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2733661], dtype=float32), -0.008278522]. 
=============================================
[2019-03-23 00:21:56,005] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 3.4193621e-15 4.3927827e-27 0.0000000e+00 3.4170924e-23], sum to 1.0000
[2019-03-23 00:21:56,012] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1584
[2019-03-23 00:21:56,019] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.63333333333333, 76.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6891132645399681, 6.911199999999999, 6.9112, 121.9260426156618, 514864.6776825231, 514864.6776825236, 142904.0277291929], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7095000.0000, 
sim time next is 7095600.0000, 
raw observation next is [22.5, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6866958287817744, 6.911199999999999, 6.9112, 121.9260426156618, 513007.2668829451, 513007.2668829456, 142480.5174137918], 
processed observation next is [1.0, 0.13043478260869565, 0.3888888888888889, 0.77, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6083697859772179, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18321688102962325, 0.18321688102962344, 0.2740009950265227], 
reward next is 0.7260, 
noisyNet noise sample is [array([-1.8800784], dtype=float32), -2.0675533]. 
=============================================
[2019-03-23 00:21:59,884] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.1504008e-25 4.8743669e-26 5.4467109e-36 7.0992792e-19], sum to 1.0000
[2019-03-23 00:21:59,893] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3030
[2019-03-23 00:21:59,899] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.68333333333333, 92.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6900014539892436, 6.911200000000001, 6.9112, 121.9260426156618, 513956.2273574842, 513956.2273574837, 140666.5391298032], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7186200.0000, 
sim time next is 7186800.0000, 
raw observation next is [19.66666666666667, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6564337706556401, 6.9112, 6.9112, 121.9260426156618, 488842.5039301991, 488842.5039301991, 137119.8045373621], 
processed observation next is [1.0, 0.17391304347826086, 0.28395061728395077, 0.9266666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5705422133195501, 0.0, 0.0, 0.8094621288201359, 0.17458660854649968, 0.17458660854649968, 0.2636919318026194], 
reward next is 0.7363, 
noisyNet noise sample is [array([0.82210416], dtype=float32), -0.76781684]. 
=============================================
[2019-03-23 00:22:01,045] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.2615145e-19 6.8301841e-24 2.8120842e-34 6.3863203e-19], sum to 1.0000
[2019-03-23 00:22:01,055] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7536
[2019-03-23 00:22:01,060] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.76666666666667, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6127669245450887, 6.911199999999999, 6.9112, 121.9260426156618, 455962.9837958098, 455962.9837958103, 132472.1668789812], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7190400.0000, 
sim time next is 7191000.0000, 
raw observation next is [19.85, 90.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6133221966070712, 6.911199999999999, 6.9112, 121.9260426156618, 456447.7302453273, 456447.7302453278, 132588.0504277539], 
processed observation next is [1.0, 0.21739130434782608, 0.2907407407407408, 0.905, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.516652745758839, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1630170465161883, 0.1630170465161885, 0.25497702005337286], 
reward next is 0.7450, 
noisyNet noise sample is [array([-1.0360643], dtype=float32), 1.3289422]. 
=============================================
[2019-03-23 00:22:01,073] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[70.88337]
 [70.86671]
 [70.85863]
 [70.82748]
 [70.78136]], R is [[70.94635773]
 [70.98213959]
 [71.01542664]
 [71.04872131]
 [71.08055878]].
[2019-03-23 00:22:01,565] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 8.9670591e-30 4.5622314e-28 0.0000000e+00 7.4754465e-29], sum to 1.0000
[2019-03-23 00:22:01,574] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6619
[2019-03-23 00:22:01,584] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 747210.4875091633 W.
[2019-03-23 00:22:01,593] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.58333333333334, 70.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9558091515677405, 6.975524647331577, 6.9112, 121.9258364193609, 747210.4875091633, 714270.574510375, 174372.9814698111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7218600.0000, 
sim time next is 7219200.0000, 
raw observation next is [23.66666666666667, 70.33333333333334, 1.0, 1.0, 0.7485465843310661, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.92600388054, 921226.4362716555, 921226.4362716555, 188354.7750012767], 
processed observation next is [1.0, 0.5652173913043478, 0.43209876543209896, 0.7033333333333335, 1.0, 0.5, 0.7006506956322216, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094618716592088, 0.32900944152559125, 0.32900944152559125, 0.36222072115630133], 
reward next is 0.6378, 
noisyNet noise sample is [array([0.20788443], dtype=float32), -1.0819857]. 
=============================================
[2019-03-23 00:22:01,940] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.00000000e+00 2.72320556e-12 1.18420865e-23 0.00000000e+00
 3.50522033e-15], sum to 1.0000
[2019-03-23 00:22:01,948] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9367
[2019-03-23 00:22:01,952] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.98333333333333, 80.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6189874090925973, 6.9112, 6.9112, 121.9260426156618, 460427.2170760704, 460427.2170760704, 132935.5070615728], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7253400.0000, 
sim time next is 7254000.0000, 
raw observation next is [20.9, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6174770818624168, 6.911200000000001, 6.9112, 121.9260426156618, 459180.6708072195, 459180.670807219, 132688.1018884638], 
processed observation next is [1.0, 1.0, 0.32962962962962955, 0.81, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5218463523280209, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1639930967168641, 0.16399309671686393, 0.2551694267085842], 
reward next is 0.7448, 
noisyNet noise sample is [array([0.12958793], dtype=float32), 0.5608608]. 
=============================================
[2019-03-23 00:22:01,967] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[70.47267 ]
 [70.46358 ]
 [70.45004 ]
 [70.438576]
 [70.43508 ]], R is [[70.53011322]
 [70.56916809]
 [70.60735321]
 [70.6446228 ]
 [70.68095398]].
[2019-03-23 00:22:03,311] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 6.5473830e-32 2.0683747e-33 0.0000000e+00 1.0188072e-27], sum to 1.0000
[2019-03-23 00:22:03,321] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6781
[2019-03-23 00:22:03,325] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.46666666666667, 71.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6848158166028175, 6.9112, 6.9112, 121.9260426156618, 511706.453580138, 511706.453580138, 142670.3107931954], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7235400.0000, 
sim time next is 7236000.0000, 
raw observation next is [23.4, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6872058911460756, 6.911200000000001, 6.9112, 121.9260426156618, 513485.3730679289, 513485.3730679285, 142889.4275569505], 
processed observation next is [1.0, 0.782608695652174, 0.42222222222222217, 0.72, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6090073639325944, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18338763323854604, 0.18338763323854587, 0.27478736068644327], 
reward next is 0.7252, 
noisyNet noise sample is [array([0.16029768], dtype=float32), -0.03751012]. 
=============================================
[2019-03-23 00:22:03,342] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[70.104904]
 [68.974   ]
 [67.206985]
 [65.02565 ]
 [62.072544]], R is [[70.94786835]
 [70.96401978]
 [70.98036957]
 [70.99730682]
 [70.28733063]].
[2019-03-23 00:22:03,956] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 7.1024096e-11 1.8522002e-24 0.0000000e+00 5.2987531e-25], sum to 1.0000
[2019-03-23 00:22:03,965] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0138
[2019-03-23 00:22:03,973] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.9, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6174770818624168, 6.911200000000001, 6.9112, 121.9260426156618, 459180.6708072195, 459180.670807219, 132688.1018884638], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7254000.0000, 
sim time next is 7254600.0000, 
raw observation next is [20.88333333333333, 81.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6152415203793438, 6.911200000000001, 6.9112, 121.9260426156618, 457482.9436839242, 457482.9436839237, 132443.7261126269], 
processed observation next is [1.0, 1.0, 0.3290123456790122, 0.8116666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5190519004741797, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1633867656014015, 0.1633867656014013, 0.2546994732935133], 
reward next is 0.7453, 
noisyNet noise sample is [array([0.01259185], dtype=float32), -0.34142613]. 
=============================================
[2019-03-23 00:22:09,118] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999619e-01 3.7884379e-06 4.0986417e-23 0.0000000e+00 4.2143059e-21], sum to 1.0000
[2019-03-23 00:22:09,126] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6610
[2019-03-23 00:22:09,131] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.9, 85.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6503612998320834, 6.911199999999999, 6.9112, 121.9260426156618, 485211.8978875168, 485211.8978875172, 137486.2918048624], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7345800.0000, 
sim time next is 7346400.0000, 
raw observation next is [20.86666666666667, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6473025623607008, 6.9112, 6.9112, 121.9260426156618, 482818.7871124611, 482818.7871124611, 137032.8231757597], 
processed observation next is [1.0, 0.0, 0.3283950617283952, 0.8533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.559128202950876, 0.0, 0.0, 0.8094621288201359, 0.17243528111159326, 0.17243528111159326, 0.26352465995338403], 
reward next is 0.7365, 
noisyNet noise sample is [array([2.8468275], dtype=float32), -0.99078983]. 
=============================================
[2019-03-23 00:22:10,817] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.8420681e-16 4.8546226e-26 1.1967809e-35 5.0400237e-26], sum to 1.0000
[2019-03-23 00:22:10,821] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0355
[2019-03-23 00:22:10,827] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.2, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6301438244939338, 6.9112, 6.9112, 121.9260426156618, 468979.2119544517, 468979.2119544517, 134238.4447895345], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7369200.0000, 
sim time next is 7369800.0000, 
raw observation next is [19.16666666666667, 95.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7425278383758144, 6.9112, 6.9112, 121.9260426156618, 552510.2683927509, 552510.2683927509, 145735.8353498216], 
processed observation next is [1.0, 0.30434782608695654, 0.2654320987654323, 0.9583333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6781597979697679, 0.0, 0.0, 0.8094621288201359, 0.19732509585455388, 0.19732509585455388, 0.28026122182658003], 
reward next is 0.7197, 
noisyNet noise sample is [array([-0.32986516], dtype=float32), -0.46776822]. 
=============================================
[2019-03-23 00:22:15,504] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6956928e-15 1.0000000e+00 4.3419077e-25 0.0000000e+00 8.1419224e-31], sum to 1.0000
[2019-03-23 00:22:15,512] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4469
[2019-03-23 00:22:15,518] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.36666666666667, 85.33333333333334, 1.0, 2.0, 0.4400593312918535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 535067.9468030133, 535067.9468030129, 134135.8638018272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7467000.0000, 
sim time next is 7467600.0000, 
raw observation next is [22.53333333333333, 84.66666666666667, 1.0, 2.0, 0.4436110662242431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 538709.4833001998, 538709.4833001994, 134639.7756225197], 
processed observation next is [0.0, 0.43478260869565216, 0.3901234567901234, 0.8466666666666667, 1.0, 1.0, 0.3376322216955276, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19239624403578567, 0.1923962440357855, 0.2589226454279225], 
reward next is 0.7411, 
noisyNet noise sample is [array([0.60450715], dtype=float32), -1.9322822]. 
=============================================
[2019-03-23 00:22:16,080] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1363609e-14 1.0000000e+00 5.9492818e-25 0.0000000e+00 7.1170321e-36], sum to 1.0000
[2019-03-23 00:22:16,087] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8199
[2019-03-23 00:22:16,092] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.36666666666667, 74.16666666666667, 1.0, 2.0, 0.5090661693607053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 604370.9376977647, 604370.9376977647, 144221.2705981578], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7481400.0000, 
sim time next is 7482000.0000, 
raw observation next is [25.33333333333333, 74.33333333333334, 1.0, 2.0, 0.509598815871246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 605074.1236647009, 605074.1236647009, 144308.425016194], 
processed observation next is [0.0, 0.6086956521739131, 0.49382716049382697, 0.7433333333333334, 1.0, 1.0, 0.41618906651338805, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21609790130882175, 0.21609790130882175, 0.2775162019542192], 
reward next is 0.7225, 
noisyNet noise sample is [array([-1.404822], dtype=float32), 0.37599698]. 
=============================================
[2019-03-23 00:22:16,103] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[73.22361 ]
 [73.22675 ]
 [73.21327 ]
 [73.208405]
 [73.202126]], R is [[73.24198914]
 [73.23221588]
 [73.22289276]
 [73.21439362]
 [73.20667267]].
[2019-03-23 00:22:16,725] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.5074396e-12 1.0000000e+00 4.8472726e-20 0.0000000e+00 7.3097306e-26], sum to 1.0000
[2019-03-23 00:22:16,734] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1112
[2019-03-23 00:22:16,740] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 82.0, 1.0, 2.0, 0.5123105542447376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 608163.4927548313, 608163.4927548313, 144734.068027918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7495200.0000, 
sim time next is 7495800.0000, 
raw observation next is [24.08333333333334, 82.66666666666667, 1.0, 2.0, 0.51140342111289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607331.1756889792, 607331.1756889792, 144599.2489999989], 
processed observation next is [0.0, 0.782608695652174, 0.4475308641975311, 0.8266666666666667, 1.0, 1.0, 0.41833740608677383, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21690399131749258, 0.21690399131749258, 0.27807547884615175], 
reward next is 0.7219, 
noisyNet noise sample is [array([0.24172707], dtype=float32), 0.25692216]. 
=============================================
[2019-03-23 00:22:17,048] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.6471656e-17 1.0000000e+00 1.2040509e-23 0.0000000e+00 8.4685118e-33], sum to 1.0000
[2019-03-23 00:22:17,055] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2303
[2019-03-23 00:22:17,058] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 82.0, 1.0, 2.0, 0.5123105542447376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 608163.4927548313, 608163.4927548313, 144734.068027918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7495200.0000, 
sim time next is 7495800.0000, 
raw observation next is [24.08333333333334, 82.66666666666667, 1.0, 2.0, 0.51140342111289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607331.1756889792, 607331.1756889792, 144599.2489999989], 
processed observation next is [0.0, 0.782608695652174, 0.4475308641975311, 0.8266666666666667, 1.0, 1.0, 0.41833740608677383, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21690399131749258, 0.21690399131749258, 0.27807547884615175], 
reward next is 0.7219, 
noisyNet noise sample is [array([-0.53236914], dtype=float32), -1.1424925]. 
=============================================
[2019-03-23 00:22:18,114] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.4714261e-11 1.0000000e+00 8.8073959e-20 1.9353270e-34 9.4815126e-30], sum to 1.0000
[2019-03-23 00:22:18,127] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2851
[2019-03-23 00:22:18,132] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.75, 95.0, 1.0, 2.0, 0.4744063520471548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 570676.8606803314, 570676.8606803314, 139103.3526541013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7513800.0000, 
sim time next is 7514400.0000, 
raw observation next is [21.7, 95.0, 1.0, 2.0, 0.4728920929622356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 569347.5924265018, 569347.5924265018, 138888.5736388958], 
processed observation next is [0.0, 1.0, 0.3592592592592592, 0.95, 1.0, 1.0, 0.37249058685980435, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20333842586660777, 0.20333842586660777, 0.2670934108440304], 
reward next is 0.7329, 
noisyNet noise sample is [array([0.16336642], dtype=float32), 0.6606881]. 
=============================================
[2019-03-23 00:22:18,643] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 00:22:18,647] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:22:18,650] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:22:18,650] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:22:18,651] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:22:18,652] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:22:18,653] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:22:18,652] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:22:18,653] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:22:18,655] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:22:18,655] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:22:18,673] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run26
[2019-03-23 00:22:18,694] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run26
[2019-03-23 00:22:18,713] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run26
[2019-03-23 00:22:18,734] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run26
[2019-03-23 00:22:18,751] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run26
[2019-03-23 00:22:53,500] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01506769], dtype=float32), -0.03779801]
[2019-03-23 00:22:53,501] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.05, 37.0, 1.0, 2.0, 0.5919037695320739, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9570079444892378, 6.911199999999999, 6.9112, 121.9260426156618, 1424367.605513856, 1424367.605513857, 288702.7309873728]
[2019-03-23 00:22:53,502] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:22:53,504] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.3591252e-33 7.4917318e-18 7.5035884e-14 6.2175129e-22], sampled 0.30951883518777235
[2019-03-23 00:22:53,505] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1424367.605513856 W.
[2019-03-23 00:23:52,544] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01506769], dtype=float32), -0.03779801]
[2019-03-23 00:23:52,546] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.3, 88.83333333333334, 1.0, 2.0, 0.8275059340343895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 943212.0947301729, 943212.0947301724, 201687.2666632207]
[2019-03-23 00:23:52,549] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:23:52,552] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.0713684e-20 5.2326715e-16 5.5414639e-20 2.0080377e-24], sampled 0.5656103487741163
[2019-03-23 00:23:52,552] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 943212.0947301729 W.
[2019-03-23 00:23:55,592] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01506769], dtype=float32), -0.03779801]
[2019-03-23 00:23:55,593] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.90261646833333, 74.10257566666667, 1.0, 2.0, 0.3445909671958827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 435172.8002841814, 435172.8002841818, 121228.4518706373]
[2019-03-23 00:23:55,595] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:23:55,599] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9019269e-16 1.0000000e+00 2.0250381e-24 0.0000000e+00 2.0632142e-32], sampled 0.013986436797405744
[2019-03-23 00:24:01,514] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01506769], dtype=float32), -0.03779801]
[2019-03-23 00:24:01,515] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.56666666666666, 80.0, 1.0, 2.0, 0.8321729648125065, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1663662.402064355, 1663662.402064355, 342718.101471904]
[2019-03-23 00:24:01,516] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:24:01,518] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.99999881e-01 1.53796948e-20 8.97494969e-14 8.42328731e-08
 1.05433976e-20], sampled 0.7468189874722193
[2019-03-23 00:24:01,522] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1663662.402064355 W.
[2019-03-23 00:24:10,602] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01506769], dtype=float32), -0.03779801]
[2019-03-23 00:24:10,604] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [15.43333333333333, 95.66666666666667, 1.0, 2.0, 0.2289509958392137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 295321.8589843307, 295321.8589843307, 95094.60162926829]
[2019-03-23 00:24:10,605] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:24:10,608] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1136061e-18 1.0000000e+00 5.5367501e-28 0.0000000e+00 1.1832493e-34], sampled 0.38204580956322787
[2019-03-23 00:24:12,324] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8648.6880 2193366778.9046 508.0000
[2019-03-23 00:24:12,725] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8501.6715 2265012492.5481 542.0000
[2019-03-23 00:24:12,733] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8786.6147 2149455848.8038 477.0000
[2019-03-23 00:24:12,779] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8006.0455 2461618793.1525 721.0000
[2019-03-23 00:24:12,882] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8555.1074 2222914381.2092 600.0000
[2019-03-23 00:24:13,898] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 625000, evaluation results [625000.0, 8006.045542919512, 2461618793.1525235, 721.0, 8648.687974562434, 2193366778.9045973, 508.0, 8786.61467754885, 2149455848.80379, 477.0, 8501.671526364464, 2265012492.548107, 542.0, 8555.107416417848, 2222914381.2092156, 600.0]
[2019-03-23 00:24:21,029] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 6.2257972e-29 5.6820484e-16 4.7267599e-26], sum to 1.0000
[2019-03-23 00:24:21,039] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5500
[2019-03-23 00:24:21,046] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1071317.423637538 W.
[2019-03-23 00:24:21,051] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 84.66666666666667, 1.0, 2.0, 0.4507284162248179, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7242343084667067, 6.911199999999999, 6.9112, 121.9260426156618, 1071317.423637538, 1071317.423637539, 239132.9594579267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7636800.0000, 
sim time next is 7637400.0000, 
raw observation next is [23.2, 84.0, 1.0, 2.0, 0.9182686215245573, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.93263213229279, 6.9112, 121.9258898098437, 1111693.360383721, 1100718.206822374, 224233.1943145928], 
processed observation next is [1.0, 0.391304347826087, 0.4148148148148148, 0.84, 1.0, 1.0, 0.9027007399101873, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0021432132292789952, 0.0, 0.8094611143484106, 0.3970333429941861, 0.39311364529370496, 0.43121768137421695], 
reward next is 0.4616, 
noisyNet noise sample is [array([0.19432394], dtype=float32), -1.3114765]. 
=============================================
[2019-03-23 00:24:22,687] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 5.5487612e-20 2.1616514e-18 2.3113740e-09 1.3205991e-19], sum to 1.0000
[2019-03-23 00:24:22,694] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4695
[2019-03-23 00:24:22,705] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 853579.8010113713 W.
[2019-03-23 00:24:22,709] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.33333333333333, 81.66666666666667, 1.0, 2.0, 0.3462800627940086, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5710310826634338, 6.9112, 6.9112, 121.9260426120255, 853579.8010113713, 853579.8010113713, 205055.4753346195], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7721400.0000, 
sim time next is 7722000.0000, 
raw observation next is [21.7, 80.0, 1.0, 2.0, 0.3750096871446549, 1.0, 1.0, 0.3750096871446549, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156607, 917892.2925000658, 917892.2925000662, 201931.2795122791], 
processed observation next is [1.0, 0.391304347826087, 0.3592592592592592, 0.8, 1.0, 1.0, 0.2559639132674463, 1.0, 0.5, 0.2559639132674463, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201287, 0.3278186758928806, 0.3278186758928808, 0.38832938367745984], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0131397], dtype=float32), -1.7253203]. 
=============================================
[2019-03-23 00:24:22,722] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[69.06215 ]
 [70.58723 ]
 [74.451324]
 [74.78792 ]
 [74.79417 ]], R is [[66.14109802]
 [65.47969055]
 [65.49645996]
 [65.41375732]
 [65.45559692]].
[2019-03-23 00:24:22,877] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:24:22,878] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:22,915] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run4
[2019-03-23 00:24:23,200] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 8.6400945e-16 5.5887906e-25 5.0529887e-30 5.4441860e-25], sum to 1.0000
[2019-03-23 00:24:23,206] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5120
[2019-03-23 00:24:23,210] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.68333333333333, 82.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5688873564338912, 6.911199999999999, 6.9112, 121.9260426156618, 418815.8914944857, 418815.8914944861, 125463.0768633914], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7683000.0000, 
sim time next is 7683600.0000, 
raw observation next is [19.66666666666667, 83.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5767138385210777, 6.911200000000001, 6.9112, 121.9260426156618, 424924.0551804684, 424924.0551804679, 126335.37490638], 
processed observation next is [1.0, 0.9565217391304348, 0.28395061728395077, 0.8333333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4708922981513471, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15175859113588158, 0.1517585911358814, 0.24295264405073078], 
reward next is 0.7570, 
noisyNet noise sample is [array([0.6631136], dtype=float32), 0.5161289]. 
=============================================
[2019-03-23 00:24:23,830] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.3373552e-10 3.3378592e-23 5.5277205e-27 2.8417971e-24], sum to 1.0000
[2019-03-23 00:24:23,835] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4340
[2019-03-23 00:24:23,840] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.45, 65.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4496653189194373, 6.9112, 6.9112, 121.9260426156618, 321057.8696436525, 321057.8696436525, 103819.526317961], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7698600.0000, 
sim time next is 7699200.0000, 
raw observation next is [19.36666666666667, 67.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4508753873579843, 6.911200000000001, 6.9112, 121.9260426156618, 321922.0313063022, 321922.0313063017, 105532.7242377677], 
processed observation next is [1.0, 0.08695652173913043, 0.27283950617283964, 0.6733333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3135942341974804, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11497215403796507, 0.1149721540379649, 0.20294754661109174], 
reward next is 0.7971, 
noisyNet noise sample is [array([1.0989628], dtype=float32), 0.9263529]. 
=============================================
[2019-03-23 00:24:28,549] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9998295e-01 1.7045983e-05 4.7045057e-16 2.3445655e-12 2.1859673e-12], sum to 1.0000
[2019-03-23 00:24:28,556] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9458
[2019-03-23 00:24:28,561] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.33333333333334, 73.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5882159233752197, 6.9112, 6.9112, 121.9260426156618, 435395.7419680901, 435395.7419680901, 128486.6039794474], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7777200.0000, 
sim time next is 7777800.0000, 
raw observation next is [21.3, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5843813755265275, 6.911200000000001, 6.9112, 121.9260426156618, 432321.34006836, 432321.3400683595, 127991.836575819], 
processed observation next is [1.0, 0.0, 0.3444444444444445, 0.735, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4804767194081593, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15440047859584285, 0.1544004785958427, 0.2461381472611904], 
reward next is 0.7539, 
noisyNet noise sample is [array([0.7201671], dtype=float32), -0.5475865]. 
=============================================
[2019-03-23 00:24:34,522] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5875474e-05 2.2276141e-37 1.5527163e-25 9.9997413e-01 8.8512379e-24], sum to 1.0000
[2019-03-23 00:24:34,526] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1355
[2019-03-23 00:24:34,534] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 67.0, 1.0, 2.0, 0.4780828612322566, 1.0, 2.0, 0.4780828612322566, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260425975101, 1155979.806118498, 1155979.806118498, 231423.848171472], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7894800.0000, 
sim time next is 7895400.0000, 
raw observation next is [24.26666666666667, 66.0, 1.0, 2.0, 0.451848626758855, 1.0, 2.0, 0.451848626758855, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156563, 1093247.133192594, 1093247.133192593, 223497.1792294857], 
processed observation next is [1.0, 0.391304347826087, 0.4543209876543211, 0.66, 1.0, 1.0, 0.34743884137958936, 1.0, 1.0, 0.34743884137958936, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288200994, 0.3904454047116407, 0.39044540471164035, 0.4298022677490109], 
reward next is 0.5702, 
noisyNet noise sample is [array([-0.7727363], dtype=float32), -0.19557936]. 
=============================================
[2019-03-23 00:24:35,727] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.5402981e-36 7.6465666e-21 5.1902510e-11 4.9028317e-23], sum to 1.0000
[2019-03-23 00:24:35,737] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2632
[2019-03-23 00:24:35,744] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1126839.430612686 W.
[2019-03-23 00:24:35,748] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.2, 49.0, 1.0, 2.0, 0.4761053018568405, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7636731310360565, 6.9112, 6.9112, 121.9260426156618, 1126839.430612686, 1126839.430612686, 247759.2593473594], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7909200.0000, 
sim time next is 7909800.0000, 
raw observation next is [29.35, 48.5, 1.0, 2.0, 0.469151752962902, 1.0, 1.0, 0.469151752962902, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1108046.518372171, 1108046.518372171, 227725.2303040957], 
processed observation next is [1.0, 0.5652173913043478, 0.6425925925925926, 0.485, 1.0, 1.0, 0.3680378011463119, 1.0, 0.5, 0.3680378011463119, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.39573089941863254, 0.39573089941863254, 0.437933135200184], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.1705585], dtype=float32), 0.19115433]. 
=============================================
[2019-03-23 00:24:35,768] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6153656e-04 0.0000000e+00 1.0581354e-25 9.9983847e-01 1.3383162e-35], sum to 1.0000
[2019-03-23 00:24:35,777] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6278
[2019-03-23 00:24:35,783] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.1, 48.33333333333333, 1.0, 2.0, 0.7271393892279759, 1.0, 2.0, 0.7271393892279759, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1683775.062893478, 1683775.062893478, 315850.2095372924], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7920600.0000, 
sim time next is 7921200.0000, 
raw observation next is [30.1, 48.66666666666666, 1.0, 2.0, 0.7475812176339561, 1.0, 2.0, 0.7475812176339561, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1728023.403080371, 1728023.403080371, 323745.23097705], 
processed observation next is [1.0, 0.6956521739130435, 0.6703703703703704, 0.4866666666666666, 1.0, 1.0, 0.6995014495642334, 1.0, 1.0, 0.6995014495642334, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6171512153858468, 0.6171512153858468, 0.6225869826481731], 
reward next is 0.3774, 
noisyNet noise sample is [array([1.0299375], dtype=float32), -1.659005]. 
=============================================
[2019-03-23 00:24:36,202] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 5.6786933e-11 1.0899230e-19 1.3548490e-26 6.9994232e-22], sum to 1.0000
[2019-03-23 00:24:36,207] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7762
[2019-03-23 00:24:36,214] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.31666666666666, 13.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6785436207884727, 6.911199999999999, 6.9112, 121.9260426156618, 484528.4114386844, 484528.4114386849, 128488.3426262418], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 223800.0000, 
sim time next is 224400.0000, 
raw observation next is [33.33333333333333, 13.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6802914535857653, 6.9112, 6.9112, 121.9260426156618, 485775.5694201395, 485775.5694201395, 129200.7419352658], 
processed observation next is [0.0, 0.6086956521739131, 0.7901234567901233, 0.1333333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6003643169822065, 0.0, 0.0, 0.8094621288201359, 0.17349127479290696, 0.17349127479290696, 0.24846296526012654], 
reward next is 0.7515, 
noisyNet noise sample is [array([-1.1820347], dtype=float32), 1.3121177]. 
=============================================
[2019-03-23 00:24:36,336] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:24:36,337] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:36,366] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run4
[2019-03-23 00:24:36,442] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:24:36,442] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:36,470] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run4
[2019-03-23 00:24:37,242] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:24:37,243] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:37,262] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run4
[2019-03-23 00:24:37,930] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:24:37,931] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:37,948] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run4
[2019-03-23 00:24:38,098] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:24:38,098] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:38,106] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:24:38,107] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:38,118] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run4
[2019-03-23 00:24:38,146] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run4
[2019-03-23 00:24:38,166] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:24:38,167] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:38,179] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run4
[2019-03-23 00:24:38,241] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:24:38,241] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:38,247] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run4
[2019-03-23 00:24:38,280] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:24:38,281] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:38,285] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run4
[2019-03-23 00:24:38,305] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:24:38,306] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:38,319] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run4
[2019-03-23 00:24:38,372] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:24:38,372] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:38,374] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run4
[2019-03-23 00:24:38,375] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:24:38,394] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:38,398] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run4
[2019-03-23 00:24:38,417] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:24:38,417] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:38,417] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:24:38,423] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:38,422] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:24:38,425] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:24:38,426] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run4
[2019-03-23 00:24:38,419] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run4
[2019-03-23 00:24:38,503] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run4
[2019-03-23 00:24:38,852] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.1431886e-19 1.1343110e-24 1.0300595e-24 4.3776893e-29], sum to 1.0000
[2019-03-23 00:24:38,852] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9849
[2019-03-23 00:24:38,869] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.03333333333333, 76.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6936669431431579, 6.911200000000001, 6.9112, 121.9260426156618, 517322.1323777926, 517322.1323777921, 141725.9366712717], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 98400.0000, 
sim time next is 99000.0000, 
raw observation next is [21.95, 76.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6795845716704726, 6.9112, 6.9112, 121.9260426156618, 506676.9649014154, 506676.9649014154, 140086.8188057356], 
processed observation next is [1.0, 0.13043478260869565, 0.36851851851851847, 0.765, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5994807145880907, 0.0, 0.0, 0.8094621288201359, 0.18095605889336264, 0.18095605889336264, 0.26939772847256843], 
reward next is 0.7306, 
noisyNet noise sample is [array([-0.3027502], dtype=float32), -0.5866543]. 
=============================================
[2019-03-23 00:24:38,915] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[63.36478 ]
 [63.33379 ]
 [62.7721  ]
 [61.972786]
 [61.99553 ]], R is [[63.24602127]
 [63.34101486]
 [63.42177963]
 [63.49718857]
 [63.56652069]].
[2019-03-23 00:24:48,142] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.00000000e+00 1.12859004e-20 4.78946472e-13 1.19190710e-33
 1.75401636e-31], sum to 1.0000
[2019-03-23 00:24:48,151] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2452
[2019-03-23 00:24:48,159] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.9, 12.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.682006113738896, 6.9112, 6.9112, 121.9260426156618, 487000.2339408462, 487000.2339408462, 128512.990409716], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 154800.0000, 
sim time next is 155400.0000, 
raw observation next is [33.61666666666667, 12.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6860617504090599, 6.9112, 6.9112, 121.9260426156618, 489897.1683008014, 489897.1683008014, 128775.1949119824], 
processed observation next is [1.0, 0.8260869565217391, 0.8006172839506173, 0.125, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6075771880113249, 0.0, 0.0, 0.8094621288201359, 0.17496327439314335, 0.17496327439314335, 0.24764460559996615], 
reward next is 0.7524, 
noisyNet noise sample is [array([1.3675103], dtype=float32), -0.37235492]. 
=============================================
[2019-03-23 00:25:06,376] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 00:25:06,377] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:25:06,377] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:25:06,380] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:25:06,381] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:25:06,382] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:25:06,383] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:25:06,382] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:25:06,383] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:25:06,384] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:25:06,387] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:25:06,402] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run27
[2019-03-23 00:25:06,402] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run27
[2019-03-23 00:25:06,423] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run27
[2019-03-23 00:25:06,424] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run27
[2019-03-23 00:25:06,482] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run27
[2019-03-23 00:25:40,831] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02796227], dtype=float32), -0.14593254]
[2019-03-23 00:25:40,832] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.19446998, 105.3478739966667, 1.0, 1.0, 0.6040127904637204, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 699442.6508702767, 699442.6508702767, 159303.8979832585]
[2019-03-23 00:25:40,833] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:25:40,835] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.3052449e-17 4.2795310e-20 2.6968778e-25 1.7213290e-26], sampled 0.38615255733800147
[2019-03-23 00:25:40,837] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 699442.6508702767 W.
[2019-03-23 00:26:01,602] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02796227], dtype=float32), -0.14593254]
[2019-03-23 00:26:01,604] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.96666666666667, 70.66666666666667, 1.0, 2.0, 0.754705162892527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 860185.3744876343, 860185.3744876338, 186773.1492876511]
[2019-03-23 00:26:01,606] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:26:01,610] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 8.2489385e-30 3.1649782e-21 1.0837192e-37 6.4759307e-36], sampled 0.26637383489426714
[2019-03-23 00:26:01,612] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 860185.3744876343 W.
[2019-03-23 00:26:06,601] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02796227], dtype=float32), -0.14593254]
[2019-03-23 00:26:06,604] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.23333333333333, 91.0, 1.0, 2.0, 0.8289494501293275, 1.0, 2.0, 0.8289494501293275, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425681962, 1890828.799773608, 1890828.799773608, 355862.4108027963]
[2019-03-23 00:26:06,606] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:26:06,608] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 3.2905946e-27 2.1061082e-09 8.2656878e-32], sampled 0.73543822802779
[2019-03-23 00:26:06,609] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1890828.799773608 W.
[2019-03-23 00:26:47,004] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02796227], dtype=float32), -0.14593254]
[2019-03-23 00:26:47,006] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.69838487, 51.42000638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8088973311419086, 6.911200000000001, 6.9112, 121.9260426156618, 601139.6383137803, 601139.6383137798, 161280.705137233]
[2019-03-23 00:26:47,008] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:26:47,010] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.0518384e-14 1.6251760e-20 1.7079683e-31 9.6356490e-28], sampled 0.6849700658591031
[2019-03-23 00:26:52,635] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02796227], dtype=float32), -0.14593254]
[2019-03-23 00:26:52,637] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.85575882, 99.67557684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6456397916598868, 6.911199999999999, 6.9112, 121.9260426156618, 480404.0592594657, 480404.0592594661, 135677.5761494956]
[2019-03-23 00:26:52,638] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:26:52,640] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.6645397e-20 1.2450516e-23 1.8285899e-32 2.5839407e-27], sampled 0.6171620060027437
[2019-03-23 00:27:00,102] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7861.1795 2526878724.5136 798.0000
[2019-03-23 00:27:00,294] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8407.9549 2291855625.2639 689.0000
[2019-03-23 00:27:00,314] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8637.7564 2218602686.0562 543.0000
[2019-03-23 00:27:00,363] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8562.2981 2257546866.6368 531.0000
[2019-03-23 00:27:00,409] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8369.7691 2337290492.9507 603.0000
[2019-03-23 00:27:01,427] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 650000, evaluation results [650000.0, 7861.179477237552, 2526878724.5135612, 798.0, 8562.298072174577, 2257546866.6367908, 531.0, 8637.756356605249, 2218602686.05622, 543.0, 8369.769091839551, 2337290492.9506855, 603.0, 8407.954894073571, 2291855625.2638707, 689.0]
[2019-03-23 00:27:02,181] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.8166942e-31 1.1762825e-34 7.8679323e-27], sum to 1.0000
[2019-03-23 00:27:02,188] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8362
[2019-03-23 00:27:02,193] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 964179.754125898 W.
[2019-03-23 00:27:02,197] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.46666666666667, 28.0, 1.0, 2.0, 0.2686321624659022, 1.0, 1.0, 0.2686321624659022, 1.0, 2.0, 0.4330332528569019, 6.9112, 6.9112, 121.94756008, 964179.754125898, 964179.754125898, 243829.6477124121], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 649200.0000, 
sim time next is 649800.0000, 
raw observation next is [33.7, 27.0, 1.0, 2.0, 0.365642255732323, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5944751926660179, 6.911199999999999, 6.9112, 121.9260426156618, 886995.9321009504, 886995.9321009509, 211706.5621840111], 
processed observation next is [1.0, 0.5217391304347826, 0.8037037037037038, 0.27, 1.0, 1.0, 0.24481220920514643, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.4930939908325223, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3167842614646251, 0.3167842614646253, 0.4071280042000213], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.08424411], dtype=float32), -0.3715118]. 
=============================================
[2019-03-23 00:27:05,579] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.0738741e-32 6.2807351e-21 1.3121492e-32], sum to 1.0000
[2019-03-23 00:27:05,591] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9365
[2019-03-23 00:27:05,602] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1359438.416655476 W.
[2019-03-23 00:27:05,606] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 37.33333333333334, 1.0, 2.0, 0.3791758598431709, 1.0, 2.0, 0.3791758598431709, 1.0, 2.0, 0.6108021774635055, 6.911200000000001, 6.9112, 121.94756008, 1359438.416655476, 1359438.416655476, 287726.9438073127], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 552000.0000, 
sim time next is 552600.0000, 
raw observation next is [29.7, 38.5, 1.0, 2.0, 0.5464095375322815, 0.0, 1.0, 0.0, 1.0, 2.0, 0.888086469209573, 6.911199999999999, 6.9112, 121.9260426156618, 1325300.710628523, 1325300.710628524, 271147.1371161029], 
processed observation next is [1.0, 0.391304347826087, 0.6555555555555556, 0.385, 1.0, 1.0, 0.460011354205097, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8601080865119661, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.47332168236732963, 0.47332168236732997, 0.5214368021463518], 
reward next is 0.4786, 
noisyNet noise sample is [array([0.5835999], dtype=float32), 1.0859139]. 
=============================================
[2019-03-23 00:27:07,811] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.00000000e+00 1.18876252e-22 1.37717145e-27 0.00000000e+00
 3.66913251e-34], sum to 1.0000
[2019-03-23 00:27:07,822] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7854
[2019-03-23 00:27:07,829] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.95, 36.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6391258800016318, 6.9112, 6.9112, 121.9260426156618, 476751.3385225848, 476751.3385225848, 136247.6025683654], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 588600.0000, 
sim time next is 589200.0000, 
raw observation next is [29.8, 36.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6371360257318646, 6.9112, 6.9112, 121.9260426156618, 475173.9947923815, 475173.9947923815, 135932.2522781985], 
processed observation next is [1.0, 0.8260869565217391, 0.6592592592592593, 0.3633333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5464200321648307, 0.0, 0.0, 0.8094621288201359, 0.16970499814013623, 0.16970499814013623, 0.26140817745807404], 
reward next is 0.7386, 
noisyNet noise sample is [array([0.4456959], dtype=float32), -1.0775927]. 
=============================================
[2019-03-23 00:27:13,006] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 5.8106912e-25 1.4034622e-25 0.0000000e+00 8.0038831e-35], sum to 1.0000
[2019-03-23 00:27:13,014] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6093
[2019-03-23 00:27:13,018] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.11666666666667, 21.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6565393699397813, 6.911200000000001, 6.9112, 121.9260426156618, 485226.297368306, 485226.2973683055, 134535.3002100427], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 672600.0000, 
sim time next is 673200.0000, 
raw observation next is [32.9, 22.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6520688667014396, 6.911200000000001, 6.9112, 121.9260426156618, 481869.7909527862, 481869.7909527858, 134071.9127953861], 
processed observation next is [1.0, 0.8260869565217391, 0.774074074074074, 0.22, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5650860833767994, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17209635391170935, 0.17209635391170922, 0.25783060152958864], 
reward next is 0.7422, 
noisyNet noise sample is [array([-0.6814095], dtype=float32), -1.3618369]. 
=============================================
[2019-03-23 00:27:23,262] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.2840062e-37 2.2070455e-26 1.4385516e-36 1.2950219e-34], sum to 1.0000
[2019-03-23 00:27:23,272] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1653
[2019-03-23 00:27:23,279] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.83333333333334, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6648145834398751, 6.911200000000001, 6.9112, 121.9260426156618, 496280.7489411772, 496280.7489411767, 139380.9350701708], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 859200.0000, 
sim time next is 859800.0000, 
raw observation next is [25.66666666666666, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.668228170334305, 6.911199999999999, 6.9112, 121.9260426156618, 498866.4382114497, 498866.4382114502, 139796.4640094068], 
processed observation next is [0.0, 0.9565217391304348, 0.5061728395061726, 0.56, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5852852129178813, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17816658507551775, 0.1781665850755179, 0.26883935386424385], 
reward next is 0.7312, 
noisyNet noise sample is [array([0.4795699], dtype=float32), -2.1623986]. 
=============================================
[2019-03-23 00:27:23,850] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.3997130e-26 6.8004055e-27 8.3602123e-26 8.7102984e-28], sum to 1.0000
[2019-03-23 00:27:23,857] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8731
[2019-03-23 00:27:23,860] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.93333333333334, 66.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5961274164887905, 6.9112, 6.9112, 121.9260426156618, 439434.6684181796, 439434.6684181796, 128193.3073959972], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 876000.0000, 
sim time next is 876600.0000, 
raw observation next is [21.85, 66.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5899010870219247, 6.9112, 6.9112, 121.9260426156618, 434309.4052427977, 434309.4052427977, 127351.4356959273], 
processed observation next is [0.0, 0.13043478260869565, 0.36481481481481487, 0.665, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4873763587774058, 0.0, 0.0, 0.8094621288201359, 0.15511050187242775, 0.15511050187242775, 0.2449066071075525], 
reward next is 0.7551, 
noisyNet noise sample is [array([-0.8234788], dtype=float32), -0.13167904]. 
=============================================
[2019-03-23 00:27:33,112] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.00000000e+00 2.86762549e-18 1.09738525e-29 0.00000000e+00
 1.07895293e-33], sum to 1.0000
[2019-03-23 00:27:33,118] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9454
[2019-03-23 00:27:33,122] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.6, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5603500051701533, 6.9112, 6.9112, 121.9260426156618, 408312.2866161738, 408312.2866161738, 122796.7006341653], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1051200.0000, 
sim time next is 1051800.0000, 
raw observation next is [20.53333333333333, 70.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6193922297384217, 6.911200000000001, 6.9112, 121.9260426156618, 451267.209296388, 451267.2092963876, 127913.7503708655], 
processed observation next is [1.0, 0.17391304347826086, 0.3160493827160493, 0.7033333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5242402871730271, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16116686046299572, 0.16116686046299558, 0.24598798148243364], 
reward next is 0.7540, 
noisyNet noise sample is [array([-1.3280361], dtype=float32), -0.97085404]. 
=============================================
[2019-03-23 00:27:36,327] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.1525521e-31 4.4049059e-16 6.9517103e-30], sum to 1.0000
[2019-03-23 00:27:36,335] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0416
[2019-03-23 00:27:36,343] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1252689.400967645 W.
[2019-03-23 00:27:36,353] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.66666666666666, 42.33333333333334, 1.0, 2.0, 0.5050815342189445, 1.0, 2.0, 0.5050815342189445, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1252689.400967645, 1252689.400967645, 240746.7086311756], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1091400.0000, 
sim time next is 1092000.0000, 
raw observation next is [26.63333333333333, 42.66666666666667, 1.0, 2.0, 0.4782946811403178, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7970312243529052, 6.911199999999999, 6.9112, 121.9260426156618, 1189829.639604285, 1189829.639604285, 245148.8353838129], 
processed observation next is [1.0, 0.6521739130434783, 0.5419753086419752, 0.4266666666666667, 1.0, 1.0, 0.37892223945275927, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.7462890304411315, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.42493915700153034, 0.42493915700153034, 0.471440068045794], 
reward next is 0.5286, 
noisyNet noise sample is [array([0.04063909], dtype=float32), 1.7292877]. 
=============================================
[2019-03-23 00:27:36,366] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[43.49693]
 [44.10182]
 [43.22193]
 [44.17399]
 [43.79256]], R is [[44.32648087]
 [44.42024231]
 [44.55369568]
 [44.10815811]
 [43.66707611]].
[2019-03-23 00:27:37,593] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 4.7211757e-10 2.0986571e-17 3.7354575e-24 1.5462434e-24], sum to 1.0000
[2019-03-23 00:27:37,603] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5964
[2019-03-23 00:27:37,607] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.55, 70.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5391159073191698, 6.9112, 6.9112, 121.9260426156618, 393141.887761579, 393141.887761579, 121140.2711974617], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1114200.0000, 
sim time next is 1114800.0000, 
raw observation next is [20.4, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5368767696392858, 6.9112, 6.9112, 121.9260426156618, 391037.2732534704, 391037.2732534704, 120758.3621770627], 
processed observation next is [1.0, 0.9130434782608695, 0.31111111111111106, 0.71, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.42109596204910715, 0.0, 0.0, 0.8094621288201359, 0.13965616901909658, 0.13965616901909658, 0.23222761957127444], 
reward next is 0.7678, 
noisyNet noise sample is [array([-0.18131079], dtype=float32), -0.8912435]. 
=============================================
[2019-03-23 00:27:39,748] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.4517809e-25 5.2155064e-26 8.8485542e-26 9.5968574e-24], sum to 1.0000
[2019-03-23 00:27:39,758] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5314
[2019-03-23 00:27:39,766] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 756459.5592681746 W.
[2019-03-23 00:27:39,771] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.46666666666667, 66.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9896723392143817, 6.993577777441908, 6.9112, 121.9257315850007, 756459.5592681746, 714274.8819881802, 163379.8465230733], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1156200.0000, 
sim time next is 1156800.0000, 
raw observation next is [20.53333333333333, 66.66666666666667, 1.0, 1.0, 0.2748394493835954, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4781134130092523, 6.911200000000001, 6.9112, 121.9259930092721, 700232.1855019631, 700232.1855019627, 182624.2075764737], 
processed observation next is [1.0, 0.391304347826087, 0.3160493827160493, 0.6666666666666667, 1.0, 0.5, 0.13671363021856595, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.34764176626156534, 8.881784197001253e-17, 0.0, 0.8094617994852954, 0.25008292339355825, 0.2500829233935581, 0.35120039918552637], 
reward next is 0.6488, 
noisyNet noise sample is [array([-1.4755386], dtype=float32), -0.67182845]. 
=============================================
[2019-03-23 00:27:42,126] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.3215664e-17 1.2499069e-21 2.2547748e-21 1.1364656e-28], sum to 1.0000
[2019-03-23 00:27:42,133] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6979
[2019-03-23 00:27:42,137] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.1, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5483867546076082, 6.9112, 6.9112, 121.9260426156618, 402066.5628595116, 402066.5628595116, 122864.3166326156], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1216800.0000, 
sim time next is 1217400.0000, 
raw observation next is [18.08333333333334, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6458480720631884, 6.911200000000001, 6.9112, 121.9260426156618, 473355.4792855986, 473355.4792855981, 131508.2321109315], 
processed observation next is [1.0, 0.08695652173913043, 0.22530864197530887, 0.93, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5573100900789855, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16905552831628523, 0.16905552831628504, 0.25290044636717596], 
reward next is 0.7471, 
noisyNet noise sample is [array([1.0232726], dtype=float32), -1.291541]. 
=============================================
[2019-03-23 00:27:46,142] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.6762311e-08 9.7226783e-20 1.5120062e-14 2.1026300e-26], sum to 1.0000
[2019-03-23 00:27:46,149] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0655
[2019-03-23 00:27:46,154] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.45, 22.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6521600155536517, 6.9112, 6.9112, 121.9260426156618, 484215.8251909763, 484215.8251909763, 135518.8276278271], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1431000.0000, 
sim time next is 1431600.0000, 
raw observation next is [33.6, 22.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6541321068079433, 6.9112, 6.9112, 121.9260426156618, 485543.6507286868, 485543.6507286868, 135617.2176192739], 
processed observation next is [0.0, 0.5652173913043478, 0.8, 0.22, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5676651335099291, 0.0, 0.0, 0.8094621288201359, 0.17340844668881672, 0.17340844668881672, 0.26080234157552673], 
reward next is 0.7392, 
noisyNet noise sample is [array([0.74919206], dtype=float32), -0.6500771]. 
=============================================
[2019-03-23 00:27:52,307] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.5039162e-13 3.3690470e-23 1.3510038e-34 7.7667985e-30], sum to 1.0000
[2019-03-23 00:27:52,317] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4529
[2019-03-23 00:27:52,323] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.33333333333334, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5943642516962632, 6.9112, 6.9112, 121.9260426156618, 440010.9513108922, 440010.9513108922, 129093.1719259554], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1380000.0000, 
sim time next is 1380600.0000, 
raw observation next is [22.25, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5924457535958306, 6.911199999999999, 6.9112, 121.9260426156618, 438251.7122242575, 438251.712224258, 128710.9653240101], 
processed observation next is [1.0, 1.0, 0.37962962962962965, 0.67, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.49055719199478826, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15651846865152055, 0.15651846865152072, 0.24752108716155788], 
reward next is 0.7525, 
noisyNet noise sample is [array([2.0092916], dtype=float32), 0.8016906]. 
=============================================
[2019-03-23 00:27:52,756] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 4.0461378e-14 1.6028433e-22 8.5061423e-31 1.3972596e-26], sum to 1.0000
[2019-03-23 00:27:52,767] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2154
[2019-03-23 00:27:52,775] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.16666666666667, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5904679802642704, 6.9112, 6.9112, 121.9260426156618, 436437.0426920403, 436437.0426920403, 128323.3472877696], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1381200.0000, 
sim time next is 1381800.0000, 
raw observation next is [22.08333333333334, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5864569798268535, 6.911199999999999, 6.9112, 121.9260426156618, 433109.2388413184, 433109.2388413188, 127750.6080911557], 
processed observation next is [1.0, 1.0, 0.373456790123457, 0.67, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.48307122478356684, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15468187101475658, 0.15468187101475672, 0.24567424632914556], 
reward next is 0.7543, 
noisyNet noise sample is [array([0.48864546], dtype=float32), -1.2278651]. 
=============================================
[2019-03-23 00:27:54,062] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.4738961e-11 4.0207432e-25 1.5061061e-36 1.3333252e-26], sum to 1.0000
[2019-03-23 00:27:54,068] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7409
[2019-03-23 00:27:54,073] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.15, 47.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5400445485598647, 6.9112, 6.9112, 121.9260426156618, 396351.6650192451, 396351.6650192451, 122341.860840488], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1408200.0000, 
sim time next is 1408800.0000, 
raw observation next is [25.5, 46.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5474881852203336, 6.9112, 6.9112, 121.9260426156618, 402611.0206456096, 402611.0206456096, 123362.813634825], 
processed observation next is [0.0, 0.30434782608695654, 0.5, 0.46333333333333326, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.434360231525417, 0.0, 0.0, 0.8094621288201359, 0.14378965023057486, 0.14378965023057486, 0.23723618006697114], 
reward next is 0.7628, 
noisyNet noise sample is [array([0.85998315], dtype=float32), -0.60417676]. 
=============================================
[2019-03-23 00:27:54,551] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 00:27:54,553] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:27:54,554] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:27:54,556] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:27:54,558] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:27:54,558] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:27:54,559] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:27:54,559] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:27:54,562] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:27:54,563] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:27:54,564] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:27:54,588] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run28
[2019-03-23 00:27:54,607] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run28
[2019-03-23 00:27:54,636] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run28
[2019-03-23 00:27:54,637] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run28
[2019-03-23 00:27:54,681] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run28
[2019-03-23 00:27:59,493] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06404103], dtype=float32), -0.21021248]
[2019-03-23 00:27:59,495] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.236023325, 35.88909776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4716896817736217, 6.9112, 6.9112, 121.9260426156618, 336786.5622204347, 336786.5622204347, 90803.08076414868]
[2019-03-23 00:27:59,496] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:27:59,501] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9999988e-01 6.5368063e-08 1.8726100e-25 4.5375538e-34 4.9250479e-29], sampled 0.1125625179956189
[2019-03-23 00:28:34,687] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06404103], dtype=float32), -0.21021248]
[2019-03-23 00:28:34,688] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.381883935, 57.72969826666667, 1.0, 1.0, 0.6476710333689146, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260033188836, 738133.042891267, 738133.0428912665, 166475.3833307405]
[2019-03-23 00:28:34,690] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:28:34,692] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.4841531e-22 5.7272674e-24 1.9434773e-14 6.7491254e-29], sampled 0.6457198869812124
[2019-03-23 00:28:34,694] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 738133.042891267 W.
[2019-03-23 00:28:45,364] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06404103], dtype=float32), -0.21021248]
[2019-03-23 00:28:45,366] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.53333333333333, 50.33333333333334, 1.0, 2.0, 0.6943378559322173, 1.0, 2.0, 0.6943378559322173, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1583508.400775642, 1583508.400775642, 302026.3690213796]
[2019-03-23 00:28:45,368] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:28:45,373] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.5404694e-09 1.2520957e-31 2.9601077e-27 1.0000000e+00 9.4803140e-31], sampled 0.22094491618134715
[2019-03-23 00:28:49,038] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06404103], dtype=float32), -0.21021248]
[2019-03-23 00:28:49,040] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 83.0, 1.0, 2.0, 0.5517905640210191, 1.0, 2.0, 0.5517905640210191, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1259806.314169632, 1259806.314169633, 251945.2106132123]
[2019-03-23 00:28:49,041] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:28:49,044] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.9381893e-01 3.5981142e-15 7.0261938e-15 3.0618110e-01 3.7601178e-23], sampled 0.04645098635926492
[2019-03-23 00:28:49,045] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1259806.314169632 W.
[2019-03-23 00:28:51,209] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06404103], dtype=float32), -0.21021248]
[2019-03-23 00:28:51,211] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.75, 70.0, 1.0, 2.0, 0.7166831249538088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816826.1521088869, 816826.1521088869, 179328.6432743666]
[2019-03-23 00:28:51,212] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:28:51,215] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 9.2702296e-27 2.9827870e-21 2.2125355e-09 6.4663722e-30], sampled 0.08681618400317692
[2019-03-23 00:28:51,217] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 816826.1521088869 W.
[2019-03-23 00:28:56,443] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06404103], dtype=float32), -0.21021248]
[2019-03-23 00:28:56,444] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.86666666666667, 34.0, 1.0, 2.0, 0.7874464751043689, 1.0, 2.0, 0.7874464751043689, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1824725.050394645, 1824725.050394644, 340074.0716919093]
[2019-03-23 00:28:56,445] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:28:56,448] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.7777496e-22 0.0000000e+00 4.7197654e-35 1.0000000e+00 0.0000000e+00], sampled 0.08038495870344331
[2019-03-23 00:29:09,951] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06404103], dtype=float32), -0.21021248]
[2019-03-23 00:29:09,953] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.6221722165896927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745226.9910215329, 745226.9910215329, 163521.7346120966]
[2019-03-23 00:29:09,956] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:29:09,960] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 5.0884756e-18 2.3833810e-20 2.9441219e-16 5.5158167e-28], sampled 0.5869681056616821
[2019-03-23 00:29:09,961] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 745226.9910215329 W.
[2019-03-23 00:29:15,626] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06404103], dtype=float32), -0.21021248]
[2019-03-23 00:29:15,627] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.0, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8278969084611978, 6.911200000000001, 6.9112, 121.9260426156618, 613075.3813814291, 613075.3813814287, 164621.093704406]
[2019-03-23 00:29:15,628] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:29:15,631] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 4.2334470e-14 5.7355417e-28 3.0072863e-26 5.3113477e-30], sampled 0.4594055764227586
[2019-03-23 00:29:31,588] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06404103], dtype=float32), -0.21021248]
[2019-03-23 00:29:31,589] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.16666666666667, 93.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8666041005439205, 6.911199999999999, 6.9112, 121.9260426156618, 637525.9254303271, 637525.9254303274, 170802.0693483893]
[2019-03-23 00:29:31,590] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:29:31,592] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.8784003e-17 4.3874761e-26 3.7513920e-25 2.1320255e-30], sampled 0.5176574308607954
[2019-03-23 00:29:48,385] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8735.7493 2242420683.5557 348.0000
[2019-03-23 00:29:48,402] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8753.2073 2209417558.9897 399.0000
[2019-03-23 00:29:48,409] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8128.0985 2499473301.9506 511.0000
[2019-03-23 00:29:48,427] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.5564 2311073002.3893 385.0000
[2019-03-23 00:29:48,454] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8571.7807 2276928083.9546 494.0000
[2019-03-23 00:29:49,470] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 675000, evaluation results [675000.0, 8128.098462074856, 2499473301.9506173, 511.0, 8735.749333238966, 2242420683.555707, 348.0, 8753.207341887899, 2209417558.989653, 399.0, 8583.556394400965, 2311073002.389262, 385.0, 8571.780693636163, 2276928083.954598, 494.0]
[2019-03-23 00:29:51,755] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 7.1871856e-11 1.4952633e-29 0.0000000e+00 4.9072977e-33], sum to 1.0000
[2019-03-23 00:29:51,764] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7748
[2019-03-23 00:29:51,779] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.23333333333333, 30.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6138298125765845, 6.9112, 6.9112, 121.9260426156618, 454609.2521585502, 454609.2521585502, 131027.4901944807], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1456800.0000, 
sim time next is 1457400.0000, 
raw observation next is [30.06666666666667, 31.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6111102045198479, 6.911199999999999, 6.9112, 121.9260426156618, 452717.871639772, 452717.8716397724, 130848.2212341535], 
processed observation next is [0.0, 0.8695652173913043, 0.669135802469136, 0.3133333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5138877556498098, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16168495415706144, 0.16168495415706155, 0.25163119468106443], 
reward next is 0.7484, 
noisyNet noise sample is [array([-0.51912546], dtype=float32), -0.09373021]. 
=============================================
[2019-03-23 00:29:51,861] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.3805912e-11 2.0329033e-30 0.0000000e+00 4.3537269e-28], sum to 1.0000
[2019-03-23 00:29:51,868] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9562
[2019-03-23 00:29:51,873] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.75, 32.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6081681514654229, 6.9112, 6.9112, 121.9260426156618, 450683.9714171498, 450683.9714171498, 130664.0738090644], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1458600.0000, 
sim time next is 1459200.0000, 
raw observation next is [29.6, 33.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6028289172097997, 6.9112, 6.9112, 121.9260426156618, 446719.8110126802, 446719.8110126802, 130157.6300160431], 
processed observation next is [0.0, 0.9130434782608695, 0.6518518518518519, 0.33, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5035361465122495, 0.0, 0.0, 0.8094621288201359, 0.15954278964738577, 0.15954278964738577, 0.2503031346462367], 
reward next is 0.7497, 
noisyNet noise sample is [array([0.6769924], dtype=float32), -3.2042036]. 
=============================================
[2019-03-23 00:29:54,648] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.8046637e-22 3.9159927e-33 2.9365060e-31 2.3904323e-32], sum to 1.0000
[2019-03-23 00:29:54,659] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4187
[2019-03-23 00:29:54,663] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.9, 35.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7231696598711544, 6.911200000000001, 6.9112, 121.9260426156618, 540202.225389618, 540202.2253896175, 148409.698802928], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1506000.0000, 
sim time next is 1506600.0000, 
raw observation next is [32.25, 34.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7210333913608912, 6.9112, 6.9112, 121.9260426156618, 538562.0845029608, 538562.0845029608, 148263.0248607234], 
processed observation next is [0.0, 0.43478260869565216, 0.75, 0.34, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6512917392011138, 0.0, 0.0, 0.8094621288201359, 0.19234360160820027, 0.19234360160820027, 0.2851212016552373], 
reward next is 0.7149, 
noisyNet noise sample is [array([-2.3745973], dtype=float32), 0.48715952]. 
=============================================
[2019-03-23 00:29:59,484] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 3.1181436e-37 5.6465158e-27 5.5390458e-08 4.8567689e-27], sum to 1.0000
[2019-03-23 00:29:59,493] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7197
[2019-03-23 00:29:59,501] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1263999.914958307 W.
[2019-03-23 00:29:59,505] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666666, 54.33333333333333, 1.0, 2.0, 0.3481473378770499, 1.0, 1.0, 0.3481473378770499, 1.0, 1.0, 0.5650344902413608, 6.911199999999999, 6.9112, 121.94756008, 1263999.914958307, 1263999.914958308, 274302.7684555294], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1594200.0000, 
sim time next is 1594800.0000, 
raw observation next is [25.8, 54.0, 1.0, 2.0, 0.9592381760285583, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.366634749926112, 6.9112, 121.9241282239829, 1414467.236742191, 1181247.600382065, 234982.1185080425], 
processed observation next is [1.0, 0.4782608695652174, 0.5111111111111112, 0.54, 1.0, 1.0, 0.951474019081617, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.045543474992611174, 0.0, 0.8094494192502151, 0.5051668702650682, 0.4218741429935946, 0.45188868943854327], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7348885], dtype=float32), -0.15240754]. 
=============================================
[2019-03-23 00:30:17,113] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.1097651e-16 9.8016557e-29 0.0000000e+00 4.3014013e-33], sum to 1.0000
[2019-03-23 00:30:17,121] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5647
[2019-03-23 00:30:17,129] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.4, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6667520463740918, 6.911200000000001, 6.9112, 121.9260426156618, 497956.1227372261, 497956.1227372256, 140001.3599243416], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1900800.0000, 
sim time next is 1901400.0000, 
raw observation next is [20.33333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6630060697359724, 6.9112, 6.9112, 121.9260426156618, 495060.8493275923, 495060.8493275923, 139418.5760044546], 
processed observation next is [1.0, 0.0, 0.3086419753086418, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5787575871699655, 0.0, 0.0, 0.8094621288201359, 0.1768074461884258, 0.1768074461884258, 0.2681126461624127], 
reward next is 0.7319, 
noisyNet noise sample is [array([-0.08255888], dtype=float32), -1.1196307]. 
=============================================
[2019-03-23 00:30:21,418] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 9.2726079e-14 2.1839436e-29 0.0000000e+00 8.3588216e-38], sum to 1.0000
[2019-03-23 00:30:21,428] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8018
[2019-03-23 00:30:21,431] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.25, 49.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8983416244186505, 6.9112, 6.9112, 121.9260426156618, 655526.4354074282, 655526.4354074282, 176093.6610347616], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2129400.0000, 
sim time next is 2130000.0000, 
raw observation next is [31.33333333333334, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8954346180696335, 6.911200000000001, 6.9112, 121.9260426156618, 653718.6226257801, 653718.6226257796, 175649.706615868], 
processed observation next is [0.0, 0.6521739130434783, 0.7160493827160496, 0.49, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8692932725870419, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2334709366520643, 0.23347093665206414, 0.3377878973382077], 
reward next is 0.6622, 
noisyNet noise sample is [array([-0.34218323], dtype=float32), 0.3149599]. 
=============================================
[2019-03-23 00:30:21,452] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[70.338234]
 [70.22839 ]
 [70.12177 ]
 [70.03342 ]
 [69.91706 ]], R is [[70.40435791]
 [70.36167908]
 [70.31868744]
 [70.27529907]
 [70.23126984]].
[2019-03-23 00:30:21,617] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.2660755e-09 8.2245285e-29 0.0000000e+00 7.1909170e-33], sum to 1.0000
[2019-03-23 00:30:21,628] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8611
[2019-03-23 00:30:21,631] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.83333333333334, 81.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.891313330118351, 6.9112, 6.9112, 121.9260426156618, 654040.2037317922, 654040.2037317922, 174420.4904886011], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1975200.0000, 
sim time next is 1975800.0000, 
raw observation next is [24.46666666666667, 82.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.870165216669719, 6.911199999999999, 6.9112, 121.9260426156618, 640757.7284141644, 640757.7284141649, 171100.1753247507], 
processed observation next is [1.0, 0.8695652173913043, 0.46172839506172847, 0.8233333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8377065208371487, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22884204586220158, 0.22884204586220172, 0.32903879870144365], 
reward next is 0.6710, 
noisyNet noise sample is [array([0.3449357], dtype=float32), 0.066031784]. 
=============================================
[2019-03-23 00:30:24,645] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.1304598e-13 2.3025663e-19 1.1959299e-16 6.6477382e-28], sum to 1.0000
[2019-03-23 00:30:24,656] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8055
[2019-03-23 00:30:24,663] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.4, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8932522353392259, 6.911200000000001, 6.9112, 121.9260426156618, 652087.342275512, 652087.3422755116, 175366.9069686049], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2041200.0000, 
sim time next is 2041800.0000, 
raw observation next is [28.46666666666667, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8998577417493949, 6.911200000000001, 6.9112, 121.9260426156618, 656329.5663150832, 656329.5663150827, 176349.9554814312], 
processed observation next is [0.0, 0.6521739130434783, 0.6098765432098766, 0.63, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8748221771867437, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23440341654110114, 0.23440341654110097, 0.3391345297719831], 
reward next is 0.6609, 
noisyNet noise sample is [array([1.5817599], dtype=float32), 0.047583293]. 
=============================================
[2019-03-23 00:30:24,856] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 6.2166011e-14 2.7606469e-22 1.0783763e-19 6.8708952e-25], sum to 1.0000
[2019-03-23 00:30:24,872] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0281
[2019-03-23 00:30:24,877] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.73333333333333, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9214979042779328, 6.911200000000001, 6.9112, 121.9260426156618, 669375.1672235616, 669375.1672235611, 179708.342441067], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2044200.0000, 
sim time next is 2044800.0000, 
raw observation next is [28.8, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9253921813841605, 6.911199999999999, 6.9112, 121.9260426156618, 671481.7807071855, 671481.780707186, 180346.0207537509], 
processed observation next is [0.0, 0.6956521739130435, 0.6222222222222222, 0.63, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9067402267302005, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2398149216811377, 0.23981492168113785, 0.34681927068029017], 
reward next is 0.6532, 
noisyNet noise sample is [array([-0.43211764], dtype=float32), 0.7891024]. 
=============================================
[2019-03-23 00:30:27,456] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.1083504e-17 5.6242874e-27 1.4184545e-29 8.8700098e-27], sum to 1.0000
[2019-03-23 00:30:27,463] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3849
[2019-03-23 00:30:27,467] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.85, 79.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.835910535718713, 6.911199999999999, 6.9112, 121.9260426156618, 616866.1303252892, 616866.1303252896, 166348.2324329888], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2107800.0000, 
sim time next is 2108400.0000, 
raw observation next is [25.1, 78.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8456548517276642, 6.9112, 6.9112, 121.9260426156618, 623145.9660635698, 623145.9660635698, 167842.4881727618], 
processed observation next is [0.0, 0.391304347826087, 0.4851851851851852, 0.7866666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8070685646595801, 0.0, 0.0, 0.8094621288201359, 0.2225521307369892, 0.2225521307369892, 0.3227740157168496], 
reward next is 0.6772, 
noisyNet noise sample is [array([1.7704258], dtype=float32), -1.5795158]. 
=============================================
[2019-03-23 00:30:29,359] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 6.7896086e-16 8.5928196e-33 1.2329204e-21 1.6856336e-28], sum to 1.0000
[2019-03-23 00:30:29,365] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5158
[2019-03-23 00:30:29,371] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.4, 95.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6781874902623505, 6.911200000000001, 6.9112, 121.9260426156618, 506789.5223158078, 506789.5223158073, 142229.2880852231], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2266800.0000, 
sim time next is 2267400.0000, 
raw observation next is [20.4, 95.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6793168598786307, 6.9112, 6.9112, 121.9260426156618, 507637.5437539917, 507637.5437539917, 142400.8041351167], 
processed observation next is [1.0, 0.21739130434782608, 0.31111111111111106, 0.9583333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5991460748482883, 0.0, 0.0, 0.8094621288201359, 0.18129912276928276, 0.18129912276928276, 0.2738477002598398], 
reward next is 0.7262, 
noisyNet noise sample is [array([-0.4479992], dtype=float32), -0.65070415]. 
=============================================
[2019-03-23 00:30:30,778] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.9497471e-13 4.0273471e-16 2.6195952e-16 2.0395695e-21], sum to 1.0000
[2019-03-23 00:30:30,786] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0101
[2019-03-23 00:30:30,797] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 745596.4595783921 W.
[2019-03-23 00:30:30,801] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.36666666666667, 71.0, 1.0, 2.0, 0.32710829329942, 1.0, 2.0, 0.32710829329942, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 745596.4595783921, 745596.4595783926, 187093.4395582463], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2146800.0000, 
sim time next is 2147400.0000, 
raw observation next is [28.2, 71.5, 1.0, 2.0, 0.2174487299100208, 1.0, 2.0, 0.2174487299100208, 1.0, 1.0, 0.3461854598274794, 6.9112, 6.9112, 121.94756008, 743463.7114552063, 743463.7114552063, 226379.1453391921], 
processed observation next is [0.0, 0.8695652173913043, 0.6, 0.715, 1.0, 1.0, 0.06839134513097712, 1.0, 1.0, 0.06839134513097712, 1.0, 0.5, 0.1827318247843492, 0.0, 0.0, 0.8096049824067558, 0.2655227540911451, 0.2655227540911451, 0.4353445102676771], 
reward next is 0.5647, 
noisyNet noise sample is [array([-1.0528077], dtype=float32), -2.3660767]. 
=============================================
[2019-03-23 00:30:31,379] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.00000000e+00 2.83930780e-22 1.05605874e-20 1.54695057e-25
 1.85229009e-26], sum to 1.0000
[2019-03-23 00:30:31,389] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7257
[2019-03-23 00:30:31,394] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.28333333333333, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9068360558883306, 6.911200000000001, 6.9112, 121.9260426156618, 662337.8966197888, 662337.8966197884, 177115.8184008262], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2159400.0000, 
sim time next is 2160000.0000, 
raw observation next is [25.2, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.906437093211484, 6.911200000000001, 6.9112, 121.9260426156618, 662149.905620034, 662149.9056200335, 177042.9876863456], 
processed observation next is [1.0, 0.0, 0.4888888888888889, 0.82, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8830463665143551, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23648210915001214, 0.23648210915001197, 0.34046728401220305], 
reward next is 0.6595, 
noisyNet noise sample is [array([1.8307614], dtype=float32), -0.29336616]. 
=============================================
[2019-03-23 00:30:31,407] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[62.6007 ]
 [63.2634 ]
 [63.7976 ]
 [64.01126]
 [64.0627 ]], R is [[61.24620438]
 [61.2931366 ]
 [61.33932877]
 [61.38460922]
 [61.42902374]].
[2019-03-23 00:30:33,569] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.4276300e-15 4.2503804e-33 3.2011352e-30 1.0000000e+00 7.2443606e-25], sum to 1.0000
[2019-03-23 00:30:33,571] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6106
[2019-03-23 00:30:33,575] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.4, 90.83333333333334, 1.0, 2.0, 0.6265292551553503, 1.0, 2.0, 0.6265292551553503, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1428719.934297132, 1428719.934297132, 277286.1412981232], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2195400.0000, 
sim time next is 2196000.0000, 
raw observation next is [24.4, 91.0, 1.0, 2.0, 0.5885209161140984, 1.0, 2.0, 0.5885209161140984, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1341970.839474673, 1341970.839474673, 264115.5561967973], 
processed observation next is [1.0, 0.43478260869565216, 0.4592592592592592, 0.91, 1.0, 1.0, 0.510143947754879, 1.0, 1.0, 0.510143947754879, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4792752998123832, 0.4792752998123832, 0.5079145311476871], 
reward next is 0.4921, 
noisyNet noise sample is [array([-0.6292852], dtype=float32), -1.2257708]. 
=============================================
[2019-03-23 00:30:33,600] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[60.188015]
 [59.879807]
 [59.40701 ]
 [59.17876 ]
 [59.31226 ]], R is [[60.98507309]
 [60.84197998]
 [60.70450974]
 [60.57697296]
 [60.44312286]].
[2019-03-23 00:30:33,768] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9465138e-01 4.5895434e-24 2.7977952e-23 5.3486312e-03 5.7110847e-23], sum to 1.0000
[2019-03-23 00:30:33,780] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8597
[2019-03-23 00:30:33,785] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.55, 85.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7710599631621736, 6.9112, 6.9112, 121.9260426156618, 575107.6568329857, 575107.6568329857, 155165.5299588853], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2352600.0000, 
sim time next is 2353200.0000, 
raw observation next is [22.86666666666667, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7663879186300717, 6.911199999999999, 6.9112, 121.9260426156618, 571972.70555177, 571972.7055517705, 154227.7290078343], 
processed observation next is [1.0, 0.21739130434782608, 0.4024691358024693, 0.82, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7079848982875897, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20427596626848932, 0.20427596626848946, 0.2965917865535275], 
reward next is 0.7034, 
noisyNet noise sample is [array([1.7862718], dtype=float32), -0.7962391]. 
=============================================
[2019-03-23 00:30:34,019] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0508028e-27 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:30:34,029] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9782
[2019-03-23 00:30:34,038] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.96666666666667, 82.33333333333334, 1.0, 2.0, 0.6782915623020234, 1.0, 2.0, 0.6782915623020234, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1546876.479727288, 1546876.479727288, 296028.9989141924], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2209200.0000, 
sim time next is 2209800.0000, 
raw observation next is [27.13333333333333, 81.66666666666666, 1.0, 2.0, 0.6775658326765903, 1.0, 2.0, 0.6775658326765903, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1545219.74854136, 1545219.748541361, 295759.8689744696], 
processed observation next is [1.0, 0.5652173913043478, 0.5604938271604937, 0.8166666666666665, 1.0, 1.0, 0.6161498008054647, 1.0, 1.0, 0.6161498008054647, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5518641959076286, 0.5518641959076289, 0.5687689787970569], 
reward next is 0.4312, 
noisyNet noise sample is [array([-1.5112852], dtype=float32), -1.4106271]. 
=============================================
[2019-03-23 00:30:36,858] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.8841829e-17 8.4843926e-32 1.2464246e-31 6.8804584e-28], sum to 1.0000
[2019-03-23 00:30:36,869] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8781
[2019-03-23 00:30:36,878] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.9, 97.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8004461723865816, 6.911200000000001, 6.9112, 121.9260426156618, 593336.343823263, 593336.3438232625, 160925.7945259291], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2258400.0000, 
sim time next is 2259000.0000, 
raw observation next is [21.75, 97.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7878765978516722, 6.9112, 6.9112, 121.9260426156618, 584911.1993700694, 584911.1993700694, 158968.8688227274], 
processed observation next is [1.0, 0.13043478260869565, 0.3611111111111111, 0.975, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7348457473145903, 0.0, 0.0, 0.8094621288201359, 0.20889685691788193, 0.20889685691788193, 0.30570936312062963], 
reward next is 0.6943, 
noisyNet noise sample is [array([0.17632167], dtype=float32), -1.2718092]. 
=============================================
[2019-03-23 00:30:36,905] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[63.57054 ]
 [63.425705]
 [63.356846]
 [63.319103]
 [62.8701  ]], R is [[63.56924438]
 [63.62408066]
 [63.67217636]
 [63.71793365]
 [63.75934219]].
[2019-03-23 00:30:42,745] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 00:30:42,747] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:30:42,748] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:30:42,748] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:30:42,749] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:30:42,751] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:30:42,751] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:30:42,753] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:30:42,754] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:30:42,756] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:30:42,758] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:30:42,776] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run29
[2019-03-23 00:30:42,776] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run29
[2019-03-23 00:30:42,812] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run29
[2019-03-23 00:30:42,832] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run29
[2019-03-23 00:30:42,850] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run29
[2019-03-23 00:31:20,545] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02290261], dtype=float32), -0.18761429]
[2019-03-23 00:31:20,547] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.63333333333334, 74.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7906219527569417, 6.911199999999999, 6.9112, 121.9260426156618, 588035.9275519631, 588035.9275519636, 158745.7123741029]
[2019-03-23 00:31:20,548] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:31:20,551] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9999988e-01 1.0811012e-07 4.5231932e-26 0.0000000e+00 2.1568442e-30], sampled 0.6329816147631901
[2019-03-23 00:31:31,684] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02290261], dtype=float32), -0.18761429]
[2019-03-23 00:31:31,685] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.274614425, 65.526097625, 1.0, 2.0, 0.6012260960212225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693755.8999258118, 693755.8999258118, 158705.0255322077]
[2019-03-23 00:31:31,685] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:31:31,689] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.7063577e-11 1.6635690e-21 9.9732996e-30 8.3107460e-31], sampled 0.8053042793871921
[2019-03-23 00:31:31,692] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 693755.8999258118 W.
[2019-03-23 00:32:08,714] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02290261], dtype=float32), -0.18761429]
[2019-03-23 00:32:08,715] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [34.0, 43.16666666666667, 1.0, 2.0, 0.955477924102548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9259806631227, 1090364.436123771, 1090364.436123772, 230218.6493051678]
[2019-03-23 00:32:08,718] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:32:08,723] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.5599369e-19 2.2524364e-21 1.3916903e-18 2.6553332e-30], sampled 0.6344876230870643
[2019-03-23 00:32:08,725] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1090364.436123771 W.
[2019-03-23 00:32:20,469] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02290261], dtype=float32), -0.18761429]
[2019-03-23 00:32:20,471] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.20352773, 59.88449134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8427084298108011, 6.911199999999999, 6.9112, 121.9260426156618, 621879.6177718756, 621879.617771876, 167204.7459763907]
[2019-03-23 00:32:20,471] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:32:20,476] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.6506219e-14 7.5041230e-24 2.9373253e-30 4.2047226e-27], sampled 0.2657824022731532
[2019-03-23 00:32:30,427] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02290261], dtype=float32), -0.18761429]
[2019-03-23 00:32:30,428] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7168068109186296, 6.9112, 6.9112, 121.9260426156618, 535349.2350271012, 535349.2350271012, 147893.363717773]
[2019-03-23 00:32:30,429] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:32:30,432] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.0094237e-09 1.1468830e-28 2.8846130e-38 7.2406675e-30], sampled 0.6917993511972855
[2019-03-23 00:32:36,255] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7980.8766 2509786240.4873 678.0000
[2019-03-23 00:32:36,276] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8464.4848 2283528495.4977 636.0000
[2019-03-23 00:32:36,355] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8660.5503 2213856887.5844 514.0000
[2019-03-23 00:32:36,415] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8452.1637 2322536444.7147 533.0000
[2019-03-23 00:32:36,484] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8607.7395 2249237254.5188 484.0000
[2019-03-23 00:32:37,501] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 700000, evaluation results [700000.0, 7980.876596467039, 2509786240.487348, 678.0, 8607.739545691538, 2249237254.5187593, 484.0, 8660.550251687548, 2213856887.584444, 514.0, 8452.163695309097, 2322536444.7146525, 533.0, 8464.484804601121, 2283528495.497717, 636.0]
[2019-03-23 00:32:46,640] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.3758913e-18 4.9402059e-25 2.4815785e-20 1.2573268e-24], sum to 1.0000
[2019-03-23 00:32:46,653] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9281
[2019-03-23 00:32:46,661] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.9, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7939133114091613, 6.911200000000001, 6.9112, 121.9260426156618, 590928.737555058, 590928.7375550575, 151559.5686123313], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2516400.0000, 
sim time next is 2517000.0000, 
raw observation next is [24.83333333333333, 56.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8888200637252891, 6.9112, 6.9112, 121.9260426156618, 661419.0203207305, 661419.0203207305, 162238.3797497583], 
processed observation next is [1.0, 0.13043478260869565, 0.4753086419753085, 0.5633333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8610250796566112, 0.0, 0.0, 0.8094621288201359, 0.2362210786859752, 0.2362210786859752, 0.31199688413415055], 
reward next is 0.6880, 
noisyNet noise sample is [array([-0.36373144], dtype=float32), 0.9175759]. 
=============================================
[2019-03-23 00:32:46,669] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[65.62601 ]
 [64.39311 ]
 [62.940796]
 [62.952194]
 [64.01707 ]], R is [[66.19948578]
 [66.24603271]
 [66.27962494]
 [66.20943451]
 [65.54734039]].
[2019-03-23 00:32:47,307] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.00000000e+00 1.26461335e-33 1.36266539e-26 3.35158364e-18
 5.24672849e-29], sum to 1.0000
[2019-03-23 00:32:47,315] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1357
[2019-03-23 00:32:47,324] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.93333333333333, 89.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9011709023610132, 6.9112, 6.9112, 121.9260426156618, 660690.7425127267, 660690.7425127267, 175853.7562231598], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2672400.0000, 
sim time next is 2673000.0000, 
raw observation next is [23.9, 89.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9001600166443021, 6.911200000000001, 6.9112, 121.9260426156618, 660055.7744158946, 660055.7744158942, 175696.204521304], 
processed observation next is [0.0, 0.9565217391304348, 0.4407407407407407, 0.895, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8752000208053775, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2357342051485338, 0.23573420514853363, 0.3378773163871231], 
reward next is 0.6621, 
noisyNet noise sample is [array([1.2169509], dtype=float32), 0.35229096]. 
=============================================
[2019-03-23 00:32:47,338] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[80.27369 ]
 [79.81648 ]
 [79.628784]
 [79.49817 ]
 [79.26606 ]], R is [[80.49434662]
 [80.35122681]
 [80.2091217 ]
 [80.06799316]
 [79.927948  ]].
[2019-03-23 00:32:52,462] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 5.7216071e-18 1.6708561e-30 1.7007667e-36 4.9459634e-30], sum to 1.0000
[2019-03-23 00:32:52,469] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8322
[2019-03-23 00:32:52,477] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.88333333333333, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7586226862307396, 6.9112, 6.9112, 121.9260426156618, 565766.5096172723, 565766.5096172723, 153746.7499056627], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2616600.0000, 
sim time next is 2617200.0000, 
raw observation next is [21.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7656635252902894, 6.9112, 6.9112, 121.9260426156618, 570680.1405569023, 570680.1405569023, 154881.0447752434], 
processed observation next is [0.0, 0.30434782608695654, 0.3333333333333333, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7070794066128616, 0.0, 0.0, 0.8094621288201359, 0.20381433591317938, 0.20381433591317938, 0.2978481630293143], 
reward next is 0.7022, 
noisyNet noise sample is [array([0.0350033], dtype=float32), -1.3959769]. 
=============================================
[2019-03-23 00:32:54,630] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 5.3700105e-19 1.1433098e-28 1.3037471e-32 4.4389967e-31], sum to 1.0000
[2019-03-23 00:32:54,638] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4764
[2019-03-23 00:32:54,643] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8985084662063139, 6.9112, 6.9112, 121.9260426156618, 658571.8013575623, 658571.8013575623, 175537.1673692648], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2669400.0000, 
sim time next is 2670000.0000, 
raw observation next is [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9046883340227069, 6.9112, 6.9112, 121.9260426156618, 663101.7677438912, 663101.7677438912, 176357.8887978343], 
processed observation next is [0.0, 0.9130434782608695, 0.4444444444444444, 0.89, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8808604175283835, 0.0, 0.0, 0.8094621288201359, 0.23682205990853258, 0.23682205990853258, 0.3391497861496814], 
reward next is 0.6609, 
noisyNet noise sample is [array([0.5964465], dtype=float32), -0.19575757]. 
=============================================
[2019-03-23 00:32:54,658] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[68.17879 ]
 [67.75834 ]
 [67.51493 ]
 [67.02374 ]
 [66.288635]], R is [[68.29136658]
 [68.27088165]
 [68.25055695]
 [68.23007202]
 [68.20886993]].
[2019-03-23 00:32:57,231] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.3537658e-18 5.7409152e-32 0.0000000e+00 1.9686666e-38], sum to 1.0000
[2019-03-23 00:32:57,239] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7442
[2019-03-23 00:32:57,246] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 771290.270275518 W.
[2019-03-23 00:32:57,250] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 72.0, 1.0, 2.0, 0.2255833672853408, 1.0, 1.0, 0.2255833672853408, 1.0, 2.0, 0.3591360674556325, 6.911200000000001, 6.9112, 121.94756008, 771290.270275518, 771290.2702755175, 229134.09961856], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2842200.0000, 
sim time next is 2842800.0000, 
raw observation next is [28.33333333333333, 72.66666666666666, 1.0, 2.0, 0.6756061274592526, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769985.8992388219, 769985.8992388219, 171576.377790436], 
processed observation next is [1.0, 0.9130434782608695, 0.6049382716049381, 0.7266666666666666, 1.0, 1.0, 0.6138168184038721, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.274994964013865, 0.274994964013865, 0.32995457267391537], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8492556], dtype=float32), -0.20586202]. 
=============================================
[2019-03-23 00:32:57,268] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.1942463e-16 5.0157483e-31 0.0000000e+00 8.4505803e-38], sum to 1.0000
[2019-03-23 00:32:57,279] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1519
[2019-03-23 00:32:57,287] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 769985.8992388219 W.
[2019-03-23 00:32:57,298] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333333, 72.66666666666666, 1.0, 2.0, 0.6756061274592526, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769985.8992388219, 769985.8992388219, 171576.377790436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2842800.0000, 
sim time next is 2843400.0000, 
raw observation next is [28.16666666666667, 73.33333333333334, 1.0, 2.0, 0.6741603232016959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768337.2954182478, 768337.2954182478, 171308.7809573533], 
processed observation next is [1.0, 0.9130434782608695, 0.5987654320987656, 0.7333333333333334, 1.0, 1.0, 0.6120956228591619, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2744061769350885, 0.2744061769350885, 0.3294399633795256], 
reward next is 0.6706, 
noisyNet noise sample is [array([-0.8492556], dtype=float32), -0.20586202]. 
=============================================
[2019-03-23 00:32:57,473] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.2483246e-21 6.9538940e-35 0.0000000e+00 8.1244160e-33], sum to 1.0000
[2019-03-23 00:32:57,486] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9770
[2019-03-23 00:32:57,491] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.26666666666667, 70.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8522574935314307, 6.911199999999999, 6.9112, 121.9260426156618, 628720.6490832512, 628720.6490832517, 168475.6747476785], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2709600.0000, 
sim time next is 2710200.0000, 
raw observation next is [26.63333333333333, 68.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.855691123419159, 6.911200000000001, 6.9112, 121.9260426156618, 631212.5666158797, 631212.5666158792, 168924.8748291254], 
processed observation next is [0.0, 0.34782608695652173, 0.5419753086419752, 0.6816666666666665, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8196139042739486, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2254330595056713, 0.22543305950567114, 0.32485552851754884], 
reward next is 0.6751, 
noisyNet noise sample is [array([-1.4785677], dtype=float32), -0.41561323]. 
=============================================
[2019-03-23 00:32:58,272] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.2488561e-17 4.0897875e-30 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:32:58,281] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6200
[2019-03-23 00:32:58,289] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 688361.7865677486 W.
[2019-03-23 00:32:58,294] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 49.0, 1.0, 2.0, 0.2013397161060644, 1.0, 2.0, 0.2013397161060644, 1.0, 1.0, 0.3205393852176278, 6.9112, 6.9112, 121.94756008, 688361.7865677486, 688361.7865677486, 221032.7673286816], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2734800.0000, 
sim time next is 2735400.0000, 
raw observation next is [32.0, 49.0, 1.0, 2.0, 0.2011316200383514, 1.0, 2.0, 0.2011316200383514, 1.0, 2.0, 0.320208089500613, 6.9112, 6.9112, 121.94756008, 687650.0064003615, 687650.0064003615, 220964.6531430909], 
processed observation next is [0.0, 0.6521739130434783, 0.7407407407407407, 0.49, 1.0, 1.0, 0.048966214331370696, 1.0, 1.0, 0.048966214331370696, 1.0, 1.0, 0.15026011187576627, 0.0, 0.0, 0.8096049824067558, 0.2455892880001291, 0.2455892880001291, 0.4249320252751748], 
reward next is 0.5751, 
noisyNet noise sample is [array([0.26227933], dtype=float32), -0.23210616]. 
=============================================
[2019-03-23 00:32:59,175] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 7.3377989e-21 2.1882071e-27 0.0000000e+00 1.1078442e-32], sum to 1.0000
[2019-03-23 00:32:59,184] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1029
[2019-03-23 00:32:59,193] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 719912.9796798103 W.
[2019-03-23 00:32:59,197] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.25, 54.83333333333334, 1.0, 2.0, 0.3158457183130516, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5028366699312942, 6.911199999999999, 6.9112, 121.9260426156618, 719912.9796798103, 719912.9796798108, 199551.7585600085], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2739000.0000, 
sim time next is 2739600.0000, 
raw observation next is [31.1, 56.0, 1.0, 2.0, 0.318992088433641, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5078457936333937, 6.911200000000001, 6.9112, 121.9260426156618, 727087.960380671, 727087.9603806705, 200418.666309764], 
processed observation next is [0.0, 0.7391304347826086, 0.7074074074074075, 0.56, 1.0, 1.0, 0.18927629575433455, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.38480724204174205, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2596742715645253, 0.25967427156452516, 0.3854205121341615], 
reward next is 0.6146, 
noisyNet noise sample is [array([0.72674066], dtype=float32), -0.7028439]. 
=============================================
[2019-03-23 00:33:00,364] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.2228166e-22 1.0060037e-29 0.0000000e+00 1.7495582e-32], sum to 1.0000
[2019-03-23 00:33:00,373] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2095
[2019-03-23 00:33:00,377] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 759011.6110655193 W.
[2019-03-23 00:33:00,382] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.3329908799632935, 1.0, 1.0, 0.3329908799632935, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 759011.6110655193, 759011.6110655193, 188566.2135764674], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2754000.0000, 
sim time next is 2754600.0000, 
raw observation next is [26.83333333333333, 79.83333333333334, 1.0, 2.0, 0.3264555130804402, 1.0, 2.0, 0.3264555130804402, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 744107.8184596474, 744107.8184596477, 186930.6740370102], 
processed observation next is [0.0, 0.9130434782608695, 0.5493827160493825, 0.7983333333333335, 1.0, 1.0, 0.19816132509576212, 1.0, 1.0, 0.19816132509576212, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2657527923070169, 0.26575279230701704, 0.35948206545578887], 
reward next is 0.6405, 
noisyNet noise sample is [array([0.7811953], dtype=float32), -0.8188695]. 
=============================================
[2019-03-23 00:33:03,852] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 9.0956494e-26 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:33:03,860] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8159
[2019-03-23 00:33:03,869] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.86275164818427, 6.911199999999999, 6.9112, 121.9260426156618, 634558.8154451692, 634558.8154451697, 170339.9746436141], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3247200.0000, 
sim time next is 3247800.0000, 
raw observation next is [31.16666666666667, 46.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8610632686700641, 6.911200000000001, 6.9112, 121.9260426156618, 633627.7652831445, 633627.7652831441, 170042.592931743], 
processed observation next is [0.0, 0.6086956521739131, 0.7098765432098767, 0.46833333333333343, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8263290858375801, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2262956304582659, 0.22629563045826576, 0.3270049864071981], 
reward next is 0.6730, 
noisyNet noise sample is [array([0.07336006], dtype=float32), 1.3766122]. 
=============================================
[2019-03-23 00:33:07,102] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 3.7125388e-19 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:33:07,109] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6167
[2019-03-23 00:33:07,116] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 736858.5745181032 W.
[2019-03-23 00:33:07,121] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.08333333333334, 91.50000000000001, 1.0, 2.0, 0.3232766474966011, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5146669511999731, 6.911199999999999, 6.9112, 121.9260426156618, 736858.5745181032, 736858.5745181036, 201605.1696618753], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2938200.0000, 
sim time next is 2938800.0000, 
raw observation next is [25.06666666666667, 92.0, 1.0, 2.0, 0.2161276820031903, 1.0, 1.0, 0.2161276820031903, 1.0, 2.0, 0.3440823085362785, 6.9112, 6.9112, 121.94756008, 738944.8324759601, 738944.8324759601, 225935.2402941763], 
processed observation next is [1.0, 0.0, 0.4839506172839507, 0.92, 1.0, 1.0, 0.06681866905141702, 1.0, 0.5, 0.06681866905141702, 1.0, 1.0, 0.18010288567034813, 0.0, 0.0, 0.8096049824067558, 0.26390886874141434, 0.26390886874141434, 0.4344908467195698], 
reward next is 0.5655, 
noisyNet noise sample is [array([-1.3473529], dtype=float32), 1.2944164]. 
=============================================
[2019-03-23 00:33:17,424] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 4.4348341e-38 2.9242840e-26 2.6700906e-16 1.7391696e-26], sum to 1.0000
[2019-03-23 00:33:17,433] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8957
[2019-03-23 00:33:17,440] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2198074.928587575 W.
[2019-03-23 00:33:17,445] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.66666666666667, 84.66666666666667, 1.0, 2.0, 0.6579139131121546, 1.0, 2.0, 0.6423216185325121, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2198074.928587575, 2198074.928587575, 418122.2914313344], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3061200.0000, 
sim time next is 3061800.0000, 
raw observation next is [29.0, 82.5, 1.0, 2.0, 0.7161241025323297, 1.0, 2.0, 0.6714267132425994, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2297802.994854932, 2297802.994854932, 433600.9964291549], 
processed observation next is [1.0, 0.43478260869565216, 0.6296296296296297, 0.825, 1.0, 1.0, 0.6620525030146782, 1.0, 1.0, 0.6088413252888087, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.8206439267339044, 0.8206439267339044, 0.8338480700560671], 
reward next is 0.1662, 
noisyNet noise sample is [array([0.27580068], dtype=float32), -1.834793]. 
=============================================
[2019-03-23 00:33:22,933] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 3.8835234e-30 2.7235671e-36 1.3979118e-31], sum to 1.0000
[2019-03-23 00:33:22,940] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3629
[2019-03-23 00:33:22,947] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1404792.367322334 W.
[2019-03-23 00:33:22,952] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.33333333333334, 49.0, 1.0, 2.0, 0.6078008415533017, 1.0, 1.0, 0.6078008415533017, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1404792.367322334, 1404792.367322334, 271652.1858369485], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3144000.0000, 
sim time next is 3144600.0000, 
raw observation next is [30.5, 47.5, 1.0, 2.0, 0.6132618965824363, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9790196781594848, 6.911199999999998, 6.9112, 121.9260426156618, 1428902.870906348, 1428902.870906349, 298527.0689950187], 
processed observation next is [1.0, 0.391304347826087, 0.6851851851851852, 0.475, 1.0, 1.0, 0.5395974959314719, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9737745976993558, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.5103224538951243, 0.5103224538951247, 0.5740905172981129], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.53582484], dtype=float32), 0.7350171]. 
=============================================
[2019-03-23 00:33:27,029] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.0035994e-26 1.0193278e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:33:27,040] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7901
[2019-03-23 00:33:27,046] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7925722646377307, 6.911200000000001, 6.9112, 121.9260426156618, 588867.9253580329, 588867.9253580325, 159320.7567128834], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3229200.0000, 
sim time next is 3229800.0000, 
raw observation next is [27.16666666666666, 61.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7988176601831184, 6.9112, 6.9112, 121.9260426156618, 593063.2576918281, 593063.2576918281, 160313.1878503846], 
processed observation next is [0.0, 0.391304347826087, 0.5617283950617282, 0.6133333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7485220752288979, 0.0, 0.0, 0.8094621288201359, 0.21180830631851003, 0.21180830631851003, 0.3082945920199704], 
reward next is 0.6917, 
noisyNet noise sample is [array([-1.1000338], dtype=float32), 0.20260833]. 
=============================================
[2019-03-23 00:33:30,720] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 00:33:30,723] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:33:30,724] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:33:30,725] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:33:30,727] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:33:30,729] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:33:30,729] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:33:30,730] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:33:30,732] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:33:30,733] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:33:30,733] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:33:30,754] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run30
[2019-03-23 00:33:30,754] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run30
[2019-03-23 00:33:30,795] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run30
[2019-03-23 00:33:30,813] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run30
[2019-03-23 00:33:30,835] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run30
[2019-03-23 00:33:51,866] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.15542555], dtype=float32), -0.16854775]
[2019-03-23 00:33:51,867] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.35650464166667, 17.86928589833333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5730305133607964, 6.911200000000001, 6.9112, 121.9260426156618, 409163.2460524448, 409163.2460524444, 106192.6494736805]
[2019-03-23 00:33:51,868] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:33:51,871] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.9786694e-22 1.5945108e-32 0.0000000e+00 1.3006931e-38], sampled 0.2696451514115019
[2019-03-23 00:33:55,702] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.15542555], dtype=float32), -0.16854775]
[2019-03-23 00:33:55,703] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.16666666666667, 75.5, 1.0, 2.0, 0.7576697669486225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 952374.5999458665, 952374.5999458665, 190659.8362673431]
[2019-03-23 00:33:55,704] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:33:55,708] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.00000000e+00 1.89024805e-21 6.37527762e-24 0.00000000e+00
 1.21134215e-33], sampled 0.8769965175228869
[2019-03-23 00:33:55,709] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 952374.5999458665 W.
[2019-03-23 00:34:25,905] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.15542555], dtype=float32), -0.16854775]
[2019-03-23 00:34:25,905] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [36.079152505, 49.360391245, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.91693652876414, 6.9112, 121.9258726923001, 1881017.240165625, 1878079.628807297, 384118.1723221884]
[2019-03-23 00:34:25,907] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:34:25,908] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 9.2860006e-30 1.6932375e-14 5.9693080e-33], sampled 0.29403707202210205
[2019-03-23 00:34:25,910] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1881017.240165625 W.
[2019-03-23 00:34:27,142] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.15542555], dtype=float32), -0.16854775]
[2019-03-23 00:34:27,145] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [35.51981148833333, 58.38851363000001, 1.0, 2.0, 0.9609606308975842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9259305900799, 1095435.849375081, 1095435.849375081, 231459.0392322545]
[2019-03-23 00:34:27,145] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:34:27,150] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.3774996e-31 1.7715460e-32 0.0000000e+00 0.0000000e+00], sampled 0.3507437861390066
[2019-03-23 00:34:27,152] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1095435.849375081 W.
[2019-03-23 00:35:13,536] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.15542555], dtype=float32), -0.16854775]
[2019-03-23 00:35:13,538] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.25688342333333, 76.35539465666668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5119983164334245, 6.911199999999999, 6.9112, 121.9260426156618, 368502.0298906096, 368502.02989061, 117035.6440105032]
[2019-03-23 00:35:13,539] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:35:13,541] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.1343505e-23 7.6901313e-34 0.0000000e+00 0.0000000e+00], sampled 0.4607564406022039
[2019-03-23 00:35:23,871] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.2402 2292979445.9673 697.0000
[2019-03-23 00:35:24,032] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5008 2529782916.7115 831.0000
[2019-03-23 00:35:24,157] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8362.8332 2339455255.0445 615.0000
[2019-03-23 00:35:24,200] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8636.2623 2219126457.1969 543.0000
[2019-03-23 00:35:24,213] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8558.6925 2258281932.5947 536.0000
[2019-03-23 00:35:25,230] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 725000, evaluation results [725000.0, 7841.500825456038, 2529782916.711494, 831.0, 8558.692516993873, 2258281932.5946884, 536.0, 8636.262268021734, 2219126457.196872, 543.0, 8362.833232666982, 2339455255.0444665, 615.0, 8404.240247944708, 2292979445.967258, 697.0]
[2019-03-23 00:35:27,211] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.00000000e+00 1.26903035e-14 1.47925595e-25 0.00000000e+00
 0.00000000e+00], sum to 1.0000
[2019-03-23 00:35:27,222] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1274
[2019-03-23 00:35:27,229] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 800879.6268972837 W.
[2019-03-23 00:35:27,233] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.68333333333333, 74.66666666666667, 1.0, 2.0, 0.7026989524696257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 800879.6268972837, 800879.6268972832, 176656.8618621984], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3336600.0000, 
sim time next is 3337200.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.2372324426831696, 1.0, 1.0, 0.2372324426831696, 1.0, 1.0, 0.3776817748728757, 6.9112, 6.9112, 121.94756008, 811140.6010056864, 811140.6010056864, 233143.7233327701], 
processed observation next is [0.0, 0.6521739130434783, 0.6296296296296297, 0.74, 1.0, 1.0, 0.09194338414663046, 1.0, 0.5, 0.09194338414663046, 1.0, 0.5, 0.22210221859109458, 0.0, 0.0, 0.8096049824067558, 0.28969307178774517, 0.28969307178774517, 0.448353314101481], 
reward next is 0.5516, 
noisyNet noise sample is [array([-1.1913702], dtype=float32), 0.4558619]. 
=============================================
[2019-03-23 00:35:29,569] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 9.5582199e-28 3.9101978e-27 0.0000000e+00 1.8725012e-27], sum to 1.0000
[2019-03-23 00:35:29,577] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9263
[2019-03-23 00:35:29,585] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 907457.1967108215 W.
[2019-03-23 00:35:29,589] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.2653852740552513, 1.0, 1.0, 0.2653852740552513, 1.0, 2.0, 0.4225019992909371, 6.9112, 6.9112, 121.94756008, 907457.1967108215, 907457.1967108215, 243147.0146572392], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3381600.0000, 
sim time next is 3382200.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.3911225225089527, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6226797938055268, 6.911199999999999, 6.9112, 121.9260426156618, 891592.5841923524, 891592.5841923528, 221374.1145150232], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.2751458601297056, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.5283497422569086, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31842592292584015, 0.3184259229258403, 0.42571945099042924], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.18889606], dtype=float32), -0.5050601]. 
=============================================
[2019-03-23 00:35:33,218] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:35:33,229] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6561
[2019-03-23 00:35:33,238] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.88333333333333, 66.5, 1.0, 2.0, 0.6535634602602314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 744851.7440011454, 744851.7440011458, 167541.3913701282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3433800.0000, 
sim time next is 3434400.0000, 
raw observation next is [30.0, 66.0, 1.0, 2.0, 0.6669696433266434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 760138.0484584371, 760138.0484584371, 169986.7446000577], 
processed observation next is [1.0, 0.782608695652174, 0.6666666666666666, 0.66, 1.0, 1.0, 0.6035352896745755, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2714778744494418, 0.2714778744494418, 0.3268975857693417], 
reward next is 0.6731, 
noisyNet noise sample is [array([-0.24148947], dtype=float32), 0.25814417]. 
=============================================
[2019-03-23 00:35:42,969] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.7895689e-21 1.6717338e-25 0.0000000e+00 6.8793436e-24], sum to 1.0000
[2019-03-23 00:35:42,976] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8581
[2019-03-23 00:35:42,983] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.1, 81.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8711638485951911, 6.911200000000001, 6.9112, 121.9260426156618, 637941.6087005262, 637941.6087005257, 172071.6510769745], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3606000.0000, 
sim time next is 3606600.0000, 
raw observation next is [25.05, 82.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8782290531230695, 6.911200000000001, 6.9112, 121.9260426156618, 642702.2026959194, 642702.202695919, 173078.8390102265], 
processed observation next is [1.0, 0.7391304347826086, 0.48333333333333334, 0.8233333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8477863164038368, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22953650096282838, 0.2295365009628282, 0.3328439211735125], 
reward next is 0.6672, 
noisyNet noise sample is [array([0.4985733], dtype=float32), -0.91263455]. 
=============================================
[2019-03-23 00:35:46,088] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.3021950e-34 2.5464525e-35 0.0000000e+00 2.1317122e-34], sum to 1.0000
[2019-03-23 00:35:46,097] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1824
[2019-03-23 00:35:46,103] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.08333333333334, 98.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8350871041940063, 6.9112, 6.9112, 121.9260426156618, 617919.5490133062, 617919.5490133062, 165693.5010745804], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3657000.0000, 
sim time next is 3657600.0000, 
raw observation next is [22.1, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8374969342772332, 6.9112, 6.9112, 121.9260426156618, 619724.8761716713, 619724.8761716713, 165986.4555150453], 
processed observation next is [1.0, 0.34782608695652173, 0.3740740740740741, 0.98, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7968711678465414, 0.0, 0.0, 0.8094621288201359, 0.22133031291845404, 0.22133031291845404, 0.3192047221443179], 
reward next is 0.6808, 
noisyNet noise sample is [array([-1.0696254], dtype=float32), 1.4913707]. 
=============================================
[2019-03-23 00:35:48,999] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.1504191e-13 4.2129441e-19 1.1202645e-35 1.6414589e-17], sum to 1.0000
[2019-03-23 00:35:49,005] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9625
[2019-03-23 00:35:49,013] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 822520.70344684 W.
[2019-03-23 00:35:49,017] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.01666666666667, 55.16666666666667, 1.0, 2.0, 0.721676843827157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 822520.70344684, 822520.70344684, 180291.7779604249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3849000.0000, 
sim time next is 3849600.0000, 
raw observation next is [33.03333333333334, 54.33333333333334, 1.0, 2.0, 0.7205202628059687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 821201.8008476344, 821201.8008476344, 180067.7562941509], 
processed observation next is [0.0, 0.5652173913043478, 0.7790123456790126, 0.5433333333333334, 1.0, 1.0, 0.6672860271499628, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29328635744558373, 0.29328635744558373, 0.34628414671952096], 
reward next is 0.6537, 
noisyNet noise sample is [array([-0.5630297], dtype=float32), 0.8211629]. 
=============================================
[2019-03-23 00:35:51,249] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.823918e-28 0.000000e+00 0.000000e+00 1.000000e+00 6.093454e-33], sum to 1.0000
[2019-03-23 00:35:51,255] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0471
[2019-03-23 00:35:51,258] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.76666666666667, 88.33333333333334, 1.0, 2.0, 0.897638098410687, 1.0, 2.0, 0.897638098410687, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2047686.824311777, 2047686.824311776, 385753.1939005981], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3752400.0000, 
sim time next is 3753000.0000, 
raw observation next is [28.15, 85.5, 1.0, 2.0, 0.9176393742864799, 1.0, 2.0, 0.9176393742864799, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2093367.10053014, 2093367.10053014, 394764.0400401409], 
processed observation next is [1.0, 0.43478260869565216, 0.5981481481481481, 0.855, 1.0, 1.0, 0.9019516360553332, 1.0, 1.0, 0.9019516360553332, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7476311073321928, 0.7476311073321928, 0.7591616154618095], 
reward next is 0.2408, 
noisyNet noise sample is [array([0.25337455], dtype=float32), 0.5199326]. 
=============================================
[2019-03-23 00:35:51,274] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[49.03259 ]
 [48.075264]
 [47.51025 ]
 [47.63865 ]
 [46.627483]], R is [[49.4310379 ]
 [49.1948967 ]
 [48.97710037]
 [48.79842377]
 [48.68738937]].
[2019-03-23 00:36:02,175] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.4844675e-20 5.3445220e-28 0.0000000e+00 2.1729124e-25], sum to 1.0000
[2019-03-23 00:36:02,183] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3691
[2019-03-23 00:36:02,190] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 880267.5618502926 W.
[2019-03-23 00:36:02,196] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.3, 76.33333333333333, 1.0, 2.0, 0.2574382459719485, 1.0, 2.0, 0.2574382459719485, 1.0, 2.0, 0.4098500717656833, 6.911199999999999, 6.9112, 121.94756008, 880267.5618502926, 880267.5618502931, 240278.4298658172], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3955200.0000, 
sim time next is 3955800.0000, 
raw observation next is [29.15, 77.66666666666667, 1.0, 2.0, 0.3895901923434922, 1.0, 2.0, 0.3895901923434922, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 888097.5008793481, 888097.5008793481, 203351.2822320188], 
processed observation next is [0.0, 0.782608695652174, 0.6351851851851852, 0.7766666666666667, 1.0, 1.0, 0.2733216575517764, 1.0, 1.0, 0.2733216575517764, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3171776788854815, 0.3171776788854815, 0.3910601581384977], 
reward next is 0.6089, 
noisyNet noise sample is [array([0.7420196], dtype=float32), -0.16337498]. 
=============================================
[2019-03-23 00:36:04,443] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.4598182e-26], sum to 1.0000
[2019-03-23 00:36:04,449] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0500
[2019-03-23 00:36:04,455] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1053852.998441075 W.
[2019-03-23 00:36:04,457] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.85, 91.5, 1.0, 2.0, 0.4622537710242943, 1.0, 1.0, 0.4622537710242943, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1053852.998441075, 1053852.998441075, 223955.9240492382], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3990600.0000, 
sim time next is 3991200.0000, 
raw observation next is [24.8, 91.66666666666666, 1.0, 2.0, 0.3117752395872014, 1.0, 2.0, 0.3117752395872014, 1.0, 1.0, 0.4963563352335036, 6.9112, 6.9112, 121.94756008, 1066193.167146924, 1066193.167146924, 260595.0959938964], 
processed observation next is [1.0, 0.17391304347826086, 0.4740740740740741, 0.9166666666666665, 1.0, 1.0, 0.1806848090323826, 1.0, 1.0, 0.1806848090323826, 1.0, 0.5, 0.37044541904187944, 0.0, 0.0, 0.8096049824067558, 0.3807832739810443, 0.3807832739810443, 0.5011444153728777], 
reward next is 0.4989, 
noisyNet noise sample is [array([-1.5738338], dtype=float32), -0.33828458]. 
=============================================
[2019-03-23 00:36:12,638] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 4.409203e-34 5.828417e-29], sum to 1.0000
[2019-03-23 00:36:12,647] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5616
[2019-03-23 00:36:12,656] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1898769.175410061 W.
[2019-03-23 00:36:12,666] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.93333333333334, 68.0, 1.0, 2.0, 0.8324268568155386, 1.0, 2.0, 0.8324268568155386, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1898769.175410061, 1898769.175410061, 357335.4948015903], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4108800.0000, 
sim time next is 4109400.0000, 
raw observation next is [28.9, 67.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.368796196146286, 6.9112, 121.924193911514, 2112649.568569841, 1878322.969690975, 382490.4017513145], 
processed observation next is [1.0, 0.5652173913043478, 0.6259259259259259, 0.67, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.04575961961462856, 0.0, 0.8094498553471113, 0.7545177030606575, 0.6708296320324911, 0.7355584649063741], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.38515893], dtype=float32), -0.59627736]. 
=============================================
[2019-03-23 00:36:17,443] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.1167717e-32 2.2573405e-35 5.0676967e-23], sum to 1.0000
[2019-03-23 00:36:17,448] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7080
[2019-03-23 00:36:17,457] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1979368.959174887 W.
[2019-03-23 00:36:17,462] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.16666666666667, 30.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9706301243149001, 7.030818697581063, 6.9112, 121.9255040513286, 1979368.959174887, 1918113.765189442, 379169.4021945031], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4206000.0000, 
sim time next is 4206600.0000, 
raw observation next is [34.25, 29.0, 1.0, 2.0, 0.8147078600549135, 1.0, 1.0, 0.8147078600549135, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9259705834587, 1917340.666728618, 1917340.666728618, 352826.6267719176], 
processed observation next is [1.0, 0.6956521739130435, 0.8240740740740741, 0.29, 1.0, 1.0, 0.7794141191129922, 1.0, 0.5, 0.7794141191129922, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094616506012157, 0.6847645238316493, 0.6847645238316493, 0.6785127437921493], 
reward next is 0.3215, 
noisyNet noise sample is [array([-0.876486], dtype=float32), 0.24987805]. 
=============================================
[2019-03-23 00:36:19,038] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 00:36:19,040] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:36:19,041] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:36:19,042] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:36:19,043] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:36:19,045] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:36:19,044] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:36:19,045] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:36:19,047] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:36:19,050] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:36:19,048] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:36:19,070] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run31
[2019-03-23 00:36:19,091] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run31
[2019-03-23 00:36:19,114] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run31
[2019-03-23 00:36:19,114] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run31
[2019-03-23 00:36:19,148] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run31
[2019-03-23 00:36:31,402] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.15932696], dtype=float32), -0.15548883]
[2019-03-23 00:36:31,404] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.94100999166666, 49.677570965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7177349017607698, 6.911200000000001, 6.9112, 121.9260426156618, 536194.0236827593, 536194.0236827589, 147666.7297428292]
[2019-03-23 00:36:31,405] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:36:31,408] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.0823130e-36 0.0000000e+00 0.0000000e+00 5.1765293e-37], sampled 0.29143326012083515
[2019-03-23 00:37:02,533] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.15932696], dtype=float32), -0.15548883]
[2019-03-23 00:37:02,534] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.24768787, 72.96288253833333, 1.0, 2.0, 0.7363566317256915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 839260.9388095251, 839260.9388095251, 183143.0156453956]
[2019-03-23 00:37:02,537] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:37:02,542] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 2.1775531e-38 0.0000000e+00 2.2265164e-37], sampled 0.5407464108237582
[2019-03-23 00:37:02,543] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 839260.9388095251 W.
[2019-03-23 00:37:03,109] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.15932696], dtype=float32), -0.15548883]
[2019-03-23 00:37:03,111] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.16666666666666, 75.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.900927668018632, 6.9112, 6.9112, 121.9260426156618, 657759.207862058, 657759.207862058, 176375.4314690411]
[2019-03-23 00:37:03,112] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:37:03,116] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3789711495255558
[2019-03-23 00:37:04,696] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.15932696], dtype=float32), -0.15548883]
[2019-03-23 00:37:04,699] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.66666666666667, 68.16666666666666, 1.0, 2.0, 0.9731809977334969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.075063384239068, 6.9112, 121.9253986750579, 1211058.265024149, 1127146.00952746, 235296.8757633923]
[2019-03-23 00:37:04,700] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:37:04,703] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 8.9579282e-38 0.0000000e+00 6.9433904e-37], sampled 0.5790988433665416
[2019-03-23 00:37:04,704] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1211058.265024149 W.
[2019-03-23 00:37:10,751] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.15932696], dtype=float32), -0.15548883]
[2019-03-23 00:37:10,751] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [34.16666666666667, 66.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.490130868709462, 6.9112, 121.9241607074367, 2174848.089434612, 1878388.316279492, 382068.3238743254]
[2019-03-23 00:37:10,752] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:37:10,755] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.6967955e-19 5.4259894e-30], sampled 0.9209323021816184
[2019-03-23 00:37:10,757] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2174848.089434612 W.
[2019-03-23 00:37:33,840] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.15932696], dtype=float32), -0.15548883]
[2019-03-23 00:37:33,842] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.25, 63.5, 1.0, 2.0, 0.8463343292191028, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1679826.527691903, 1679826.527691903, 345627.2970240199]
[2019-03-23 00:37:33,844] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:37:33,846] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 1.7550476e-38 4.7802910e-25 4.3133206e-30], sampled 0.3279804928477623
[2019-03-23 00:37:33,847] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1679826.527691903 W.
[2019-03-23 00:37:45,578] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.15932696], dtype=float32), -0.15548883]
[2019-03-23 00:37:45,581] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.33333333333334, 90.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.832269085838243, 6.911200000000001, 6.9112, 121.9260426156618, 613745.1195484265, 613745.119548426, 166021.17399317]
[2019-03-23 00:37:45,581] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:37:45,583] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.5494334e-37], sampled 0.7902567563223872
[2019-03-23 00:37:51,591] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.15932696], dtype=float32), -0.15548883]
[2019-03-23 00:37:51,592] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.4, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8887335599210623, 6.9112, 6.9112, 121.9260426156618, 649262.2715653051, 649262.2715653051, 174680.1404581237]
[2019-03-23 00:37:51,594] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:37:51,597] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.3857292e-34], sampled 0.34990934531001805
[2019-03-23 00:37:56,915] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.15932696], dtype=float32), -0.15548883]
[2019-03-23 00:37:56,916] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.33333333333333, 96.0, 1.0, 2.0, 0.6685686439592838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 761961.3178538262, 761961.3178538262, 170280.5249656292]
[2019-03-23 00:37:56,919] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:37:56,920] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 7.6605006e-34 2.4945231e-36 0.0000000e+00 1.6963956e-33], sampled 0.1179580152590558
[2019-03-23 00:37:56,921] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 761961.3178538262 W.
[2019-03-23 00:38:02,929] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.15932696], dtype=float32), -0.15548883]
[2019-03-23 00:38:02,931] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.99904836, 85.07112499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7165286717305602, 6.9112, 6.9112, 121.9260426156618, 535261.7895645441, 535261.7895645441, 147608.4012474158]
[2019-03-23 00:38:02,932] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:38:02,938] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.8169498e-36 0.0000000e+00 0.0000000e+00 2.7184988e-38], sampled 0.9817803639683954
[2019-03-23 00:38:06,981] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8558.6925 2258281932.5947 536.0000
[2019-03-23 00:38:07,102] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8362.8332 2339455255.0445 615.0000
[2019-03-23 00:38:07,269] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5008 2529782916.7115 831.0000
[2019-03-23 00:38:07,350] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.2402 2292979445.9673 697.0000
[2019-03-23 00:38:07,394] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8636.2623 2219126457.1969 543.0000
[2019-03-23 00:38:08,410] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 750000, evaluation results [750000.0, 7841.500825456038, 2529782916.711494, 831.0, 8558.692516993873, 2258281932.5946884, 536.0, 8636.262268021734, 2219126457.196872, 543.0, 8362.833232666982, 2339455255.0444665, 615.0, 8404.240247944708, 2292979445.967258, 697.0]
[2019-03-23 00:38:13,235] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 8.4889622e-31 3.3086965e-26 0.0000000e+00 9.7244955e-20], sum to 1.0000
[2019-03-23 00:38:13,246] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1553
[2019-03-23 00:38:13,251] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 738744.3100887135 W.
[2019-03-23 00:38:13,255] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 74.0, 1.0, 2.0, 0.3241035641965883, 1.0, 2.0, 0.3241035641965883, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 738744.3100887135, 738744.310088714, 186345.6551953653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4451400.0000, 
sim time next is 4452000.0000, 
raw observation next is [27.8, 74.0, 1.0, 2.0, 0.6540173298111303, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745369.2605282244, 745369.2605282244, 167620.1923934367], 
processed observation next is [0.0, 0.5217391304347826, 0.5851851851851853, 0.74, 1.0, 1.0, 0.5881158688227741, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2662033073315087, 0.2662033073315087, 0.32234652383353213], 
reward next is 0.6777, 
noisyNet noise sample is [array([1.4680743], dtype=float32), 0.48148248]. 
=============================================
[2019-03-23 00:38:13,266] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[37.801666]
 [37.854034]
 [38.17894 ]
 [39.473114]
 [39.519665]], R is [[37.85421371]
 [38.1173172 ]
 [38.30309677]
 [37.92006683]
 [37.54086685]].
[2019-03-23 00:38:13,862] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.1708163e-38], sum to 1.0000
[2019-03-23 00:38:13,867] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0648
[2019-03-23 00:38:13,872] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 985558.8552075608 W.
[2019-03-23 00:38:13,875] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.66666666666666, 94.0, 1.0, 2.0, 0.2882113784789115, 1.0, 2.0, 0.2882113784789115, 1.0, 1.0, 0.4588419009277263, 6.9112, 6.9112, 121.94756008, 985558.8552075608, 985558.8552075608, 251582.3807981428], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4332000.0000, 
sim time next is 4332600.0000, 
raw observation next is [23.5, 94.0, 1.0, 2.0, 0.3996092841398672, 1.0, 2.0, 0.3996092841398672, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 914745.961347492, 914745.961347492, 206265.1155301155], 
processed observation next is [1.0, 0.13043478260869565, 0.42592592592592593, 0.94, 1.0, 1.0, 0.28524914778555616, 1.0, 1.0, 0.28524914778555616, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32669498619553283, 0.32669498619553283, 0.3966636837117606], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.53329563], dtype=float32), 0.28841174]. 
=============================================
[2019-03-23 00:38:21,195] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.3578211e-38 2.4811620e-20 6.3836589e-21 1.0655982e-25], sum to 1.0000
[2019-03-23 00:38:21,203] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1249
[2019-03-23 00:38:21,209] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 816494.9529109616 W.
[2019-03-23 00:38:21,213] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.3581963427669798, 1.0, 2.0, 0.3581963427669798, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816494.9529109616, 816494.9529109616, 195013.62698408], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4471200.0000, 
sim time next is 4471800.0000, 
raw observation next is [28.83333333333334, 75.66666666666667, 1.0, 2.0, 0.3560452768986266, 1.0, 2.0, 0.3560452768986266, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 811589.0840263691, 811589.0840263691, 194454.9977950294], 
processed observation next is [0.0, 0.782608695652174, 0.623456790123457, 0.7566666666666667, 1.0, 1.0, 0.2333872344031269, 1.0, 1.0, 0.2333872344031269, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2898532442951318, 0.2898532442951318, 0.373951918836595], 
reward next is 0.6260, 
noisyNet noise sample is [array([-1.6327163], dtype=float32), -1.6994661]. 
=============================================
[2019-03-23 00:38:23,728] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 3.0430013e-34 0.0000000e+00 1.4127323e-34], sum to 1.0000
[2019-03-23 00:38:23,729] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2297
[2019-03-23 00:38:23,762] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.1, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9219425743908238, 6.9112, 6.9112, 121.9260426156618, 673776.0495860911, 673776.0495860911, 179071.4014374191], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4508400.0000, 
sim time next is 4509000.0000, 
raw observation next is [23.15, 95.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9113394233232893, 6.911199999999999, 6.9112, 121.9260426156618, 667570.9845747751, 667570.9845747756, 177332.220009334], 
processed observation next is [0.0, 0.17391304347826086, 0.4129629629629629, 0.955, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8891742791541115, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2384182087767054, 0.23841820877670555, 0.34102350001795], 
reward next is 0.6590, 
noisyNet noise sample is [array([-0.26441148], dtype=float32), 1.6413507]. 
=============================================
[2019-03-23 00:38:23,776] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[60.72397 ]
 [59.093983]
 [56.942078]
 [57.403336]
 [57.83762 ]], R is [[62.2834549 ]
 [62.31625366]
 [61.69309235]
 [61.07616043]
 [61.04055405]].
[2019-03-23 00:38:23,865] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 8.5628187e-32 3.0130814e-36], sum to 1.0000
[2019-03-23 00:38:23,876] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0786
[2019-03-23 00:38:23,887] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.16666666666667, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8812884859125337, 6.911200000000001, 6.9112, 121.9260426156618, 648126.4586611082, 648126.4586611077, 172757.5525190296], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4536600.0000, 
sim time next is 4537200.0000, 
raw observation next is [23.33333333333334, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8908545627100508, 6.9112, 6.9112, 121.9260426156618, 653740.0916136788, 653740.0916136788, 174351.790702393], 
processed observation next is [0.0, 0.5217391304347826, 0.4197530864197533, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8635682033875636, 0.0, 0.0, 0.8094621288201359, 0.23347860414774244, 0.23347860414774244, 0.3352919051969096], 
reward next is 0.6647, 
noisyNet noise sample is [array([0.38203424], dtype=float32), 0.7205686]. 
=============================================
[2019-03-23 00:38:24,374] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.8937537e-23 2.6058544e-36], sum to 1.0000
[2019-03-23 00:38:24,384] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4361
[2019-03-23 00:38:24,409] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1451278.256843212 W.
[2019-03-23 00:38:24,423] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.08333333333334, 83.0, 1.0, 2.0, 0.6364122768678508, 1.0, 2.0, 0.6364122768678508, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1451278.256843212, 1451278.256843212, 280792.5058539822], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4963800.0000, 
sim time next is 4964400.0000, 
raw observation next is [25.1, 83.0, 1.0, 2.0, 0.5829954981959433, 1.0, 2.0, 0.5829954981959433, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1329360.609045722, 1329360.609045723, 262242.2702654946], 
processed observation next is [1.0, 0.4782608695652174, 0.4851851851851852, 0.83, 1.0, 1.0, 0.5035660692808849, 1.0, 1.0, 0.5035660692808849, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4747716460877579, 0.47477164608775824, 0.5043120582028742], 
reward next is 0.4957, 
noisyNet noise sample is [array([1.9888284], dtype=float32), -1.5470372]. 
=============================================
[2019-03-23 00:38:25,541] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.1950383e-34 1.3709022e-35 3.8924650e-31], sum to 1.0000
[2019-03-23 00:38:25,548] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7877
[2019-03-23 00:38:25,554] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 693774.0457470677 W.
[2019-03-23 00:38:25,564] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.6, 96.66666666666666, 1.0, 1.0, 0.3036806297545181, 1.0, 1.0, 0.3036806297545181, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 693774.0457470677, 693774.0457470681, 181426.539462392], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4552800.0000, 
sim time next is 4553400.0000, 
raw observation next is [23.75, 95.83333333333334, 1.0, 2.0, 0.3057239168359041, 1.0, 2.0, 0.3057239168359041, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 697144.6726107671, 697144.6726107671, 181855.4982769004], 
processed observation next is [0.0, 0.6956521739130435, 0.4351851851851852, 0.9583333333333335, 1.0, 1.0, 0.17348085337607633, 1.0, 1.0, 0.17348085337607633, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2489802402181311, 0.2489802402181311, 0.3497221120709623], 
reward next is 0.6503, 
noisyNet noise sample is [array([0.71756697], dtype=float32), -0.22462747]. 
=============================================
[2019-03-23 00:38:25,669] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.9681880e-36 0.0000000e+00 2.0627105e-32], sum to 1.0000
[2019-03-23 00:38:25,677] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4111
[2019-03-23 00:38:25,685] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 777484.4975719814 W.
[2019-03-23 00:38:25,692] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.6821822621081782, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777484.4975719814, 777484.4975719814, 172797.8890279637], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4993200.0000, 
sim time next is 4993800.0000, 
raw observation next is [25.8, 89.33333333333334, 1.0, 2.0, 0.6763030309023185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 770780.5569553862, 770780.5569553862, 171705.4841166484], 
processed observation next is [1.0, 0.8260869565217391, 0.5111111111111112, 0.8933333333333334, 1.0, 1.0, 0.614646465359903, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27527877034120934, 0.27527877034120934, 0.3302028540704777], 
reward next is 0.6698, 
noisyNet noise sample is [array([-0.15649204], dtype=float32), -0.6519765]. 
=============================================
[2019-03-23 00:38:27,939] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 5.5486244e-31 6.2768306e-36], sum to 1.0000
[2019-03-23 00:38:27,951] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3708
[2019-03-23 00:38:27,957] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.26666666666667, 99.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.798695216805911, 6.911199999999999, 6.9112, 121.9260426156618, 594381.4311792044, 594381.4311792048, 159538.5885695427], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4598400.0000, 
sim time next is 4599000.0000, 
raw observation next is [21.2, 99.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7945441120530343, 6.911199999999999, 6.9112, 121.9260426156618, 591479.1175363577, 591479.1175363582, 158906.6490675669], 
processed observation next is [1.0, 0.21739130434782608, 0.34074074074074073, 0.995, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.743180140066293, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2112425419772706, 0.21124254197727077, 0.30558970974532096], 
reward next is 0.6944, 
noisyNet noise sample is [array([-1.0595435], dtype=float32), 1.2040257]. 
=============================================
[2019-03-23 00:38:27,967] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[61.085827]
 [60.921947]
 [60.98513 ]
 [61.21813 ]
 [61.486565]], R is [[61.21198654]
 [61.29306412]
 [61.36015701]
 [61.4390564 ]
 [61.50907516]].
[2019-03-23 00:38:31,456] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.3101157e-29 4.5562276e-37 5.5628113e-28], sum to 1.0000
[2019-03-23 00:38:31,463] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5300
[2019-03-23 00:38:31,469] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 722853.1352365459 W.
[2019-03-23 00:38:31,474] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.2082826179602791, 1.0, 1.0, 0.2082826179602791, 1.0, 1.0, 0.3320900491033558, 6.9112, 6.9112, 121.94756008, 722853.1352365459, 722853.1352365459, 223309.3368795554], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4680000.0000, 
sim time next is 4680600.0000, 
raw observation next is [23.11666666666667, 94.16666666666667, 1.0, 2.0, 0.664438486145116, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777008.9329500648, 777008.9329500648, 170463.1859709019], 
processed observation next is [1.0, 0.17391304347826086, 0.41172839506172854, 0.9416666666666668, 1.0, 1.0, 0.6005220073156143, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27750319033930887, 0.27750319033930887, 0.32781381917481134], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9101007], dtype=float32), 0.4621541]. 
=============================================
[2019-03-23 00:38:33,559] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 3.9207299e-26 1.1051127e-33 4.1488639e-26], sum to 1.0000
[2019-03-23 00:38:33,568] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7690
[2019-03-23 00:38:33,576] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 851273.0914597898 W.
[2019-03-23 00:38:33,580] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.6, 92.0, 1.0, 2.0, 0.3734450442503311, 1.0, 1.0, 0.3734450442503311, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 851273.0914597898, 851273.0914597902, 199020.7646399613], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4825800.0000, 
sim time next is 4826400.0000, 
raw observation next is [26.4, 92.66666666666667, 1.0, 2.0, 0.3711144851322695, 1.0, 2.0, 0.3711144851322695, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 845957.6181469194, 845957.6181469194, 198403.0541083117], 
processed observation next is [1.0, 0.8695652173913043, 0.5333333333333333, 0.9266666666666667, 1.0, 1.0, 0.25132676801460657, 1.0, 1.0, 0.25132676801460657, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3021277207667569, 0.3021277207667569, 0.3815443348236764], 
reward next is 0.6185, 
noisyNet noise sample is [array([0.8405288], dtype=float32), 0.14226544]. 
=============================================
[2019-03-23 00:38:34,190] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.5259744e-17 1.1156055e-16 2.6771148e-18], sum to 1.0000
[2019-03-23 00:38:34,199] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1065
[2019-03-23 00:38:34,207] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 805868.3101729306 W.
[2019-03-23 00:38:34,211] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 100.0, 1.0, 2.0, 0.2356912778493861, 1.0, 1.0, 0.2356912778493861, 1.0, 2.0, 0.3752281902652577, 6.9112, 6.9112, 121.94756008, 805868.3101729306, 805868.3101729306, 232608.8985414745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4839000.0000, 
sim time next is 4839600.0000, 
raw observation next is [25.0, 100.0, 1.0, 2.0, 0.7078211444564666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806720.5606591181, 806720.5606591181, 177630.9349910886], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 1.0, 1.0, 1.0, 0.6521680291148412, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28811448594968503, 0.28811448594968503, 0.3415979519059396], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.13804242], dtype=float32), -1.4964575]. 
=============================================
[2019-03-23 00:38:37,858] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.0713629e-30 1.1199213e-30 8.7312184e-29], sum to 1.0000
[2019-03-23 00:38:37,862] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4105
[2019-03-23 00:38:37,870] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 735633.4693217777 W.
[2019-03-23 00:38:37,886] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.3227394237110855, 1.0, 1.0, 0.3227394237110855, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 735633.4693217777, 735633.4693217782, 186006.6269051732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4764600.0000, 
sim time next is 4765200.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.6283833088488915, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 722817.5014605881, 722817.5014605881, 163356.9777077341], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.5575991772010612, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2581491076644957, 0.2581491076644957, 0.3141480340533348], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.24199133], dtype=float32), -0.87416726]. 
=============================================
[2019-03-23 00:38:44,949] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:38:44,959] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1624
[2019-03-23 00:38:44,968] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 736733.6754373403 W.
[2019-03-23 00:38:44,973] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 87.0, 1.0, 2.0, 0.6273016967630692, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.926042615649, 736733.6754373403, 736733.6754373403, 163856.7094014617], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4948800.0000, 
sim time next is 4949400.0000, 
raw observation next is [24.0, 88.0, 1.0, 2.0, 0.2168553625435175, 1.0, 1.0, 0.2168553625435175, 1.0, 1.0, 0.3455760639785896, 6.911200000000001, 6.9112, 121.94756008, 749899.721086637, 749899.7210866365, 226185.9969780704], 
processed observation next is [1.0, 0.2608695652173913, 0.4444444444444444, 0.88, 1.0, 1.0, 0.06768495540894941, 1.0, 0.5, 0.06768495540894941, 1.0, 0.5, 0.18197007997323697, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2678213289595132, 0.26782132895951305, 0.4349730711116739], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.31701338], dtype=float32), -0.2115605]. 
=============================================
[2019-03-23 00:38:48,484] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 9.6245516e-36 2.3453539e-22 1.6267220e-33], sum to 1.0000
[2019-03-23 00:38:48,491] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3250
[2019-03-23 00:38:48,503] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1719963.092335287 W.
[2019-03-23 00:38:48,511] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.55, 83.5, 1.0, 2.0, 0.5027421268917058, 1.0, 1.0, 0.5027421268917058, 1.0, 2.0, 0.8003818391795982, 6.9112, 6.9112, 121.94756008, 1719963.092335287, 1719963.092335287, 344936.9470799404], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4966200.0000, 
sim time next is 4966800.0000, 
raw observation next is [25.7, 83.66666666666667, 1.0, 2.0, 0.5070476607488327, 1.0, 2.0, 0.5070476607488327, 1.0, 2.0, 0.8072363893015925, 6.9112, 6.9112, 121.94756008, 1734707.327857919, 1734707.327857919, 347061.5887012983], 
processed observation next is [1.0, 0.4782608695652174, 0.5074074074074074, 0.8366666666666667, 1.0, 1.0, 0.4131519770819436, 1.0, 1.0, 0.4131519770819436, 1.0, 1.0, 0.7590454866269905, 0.0, 0.0, 0.8096049824067558, 0.6195383313778282, 0.6195383313778282, 0.6674261321178813], 
reward next is 0.3326, 
noisyNet noise sample is [array([-1.2806256], dtype=float32), -1.8902414]. 
=============================================
[2019-03-23 00:38:52,758] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.3603862e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 00:38:52,764] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1672
[2019-03-23 00:38:52,775] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 715262.5636989137 W.
[2019-03-23 00:38:52,783] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.66666666666667, 86.33333333333334, 1.0, 2.0, 0.3138064037334575, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4995900147047413, 6.911199999999999, 6.9112, 121.9260426156618, 715262.5636989137, 715262.5636989141, 198992.0753471096], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5041200.0000, 
sim time next is 5041800.0000, 
raw observation next is [25.75, 87.0, 1.0, 2.0, 0.3183499228477781, 1.0, 1.0, 0.3183499228477781, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 725623.5608755087, 725623.5608755087, 184922.7405941006], 
processed observation next is [0.0, 0.34782608695652173, 0.5092592592592593, 0.87, 1.0, 1.0, 0.18851181291402153, 1.0, 0.5, 0.18851181291402153, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25915127174125313, 0.25915127174125313, 0.355620654988655], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8766123], dtype=float32), 2.1870172]. 
=============================================
[2019-03-23 00:38:55,387] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.7865957e-33 3.4828646e-32 0.0000000e+00 2.6415700e-32], sum to 1.0000
[2019-03-23 00:38:55,395] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9531
[2019-03-23 00:38:55,400] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 931209.0393253277 W.
[2019-03-23 00:38:55,405] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.26666666666667, 86.66666666666666, 1.0, 2.0, 0.2723272682768309, 1.0, 2.0, 0.2723272682768309, 1.0, 2.0, 0.4335538801766599, 6.911199999999999, 6.9112, 121.94756008, 931209.0393253277, 931209.0393253282, 245681.664658504], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5085600.0000, 
sim time next is 5086200.0000, 
raw observation next is [28.13333333333333, 87.83333333333334, 1.0, 2.0, 0.4102825937373923, 1.0, 2.0, 0.4102825937373923, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 935296.0293579962, 935296.0293579967, 209033.6323468269], 
processed observation next is [0.0, 0.8695652173913043, 0.5975308641975308, 0.8783333333333334, 1.0, 1.0, 0.2979554687349908, 1.0, 1.0, 0.2979554687349908, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3340342961992844, 0.33403429619928454, 0.4019877545131286], 
reward next is 0.5980, 
noisyNet noise sample is [array([0.29982138], dtype=float32), -0.696127]. 
=============================================
[2019-03-23 00:38:59,292] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.4463740e-24 8.3877845e-25 0.0000000e+00 1.1263083e-24], sum to 1.0000
[2019-03-23 00:38:59,300] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5938
[2019-03-23 00:38:59,305] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 887788.2168310974 W.
[2019-03-23 00:38:59,311] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.83333333333334, 76.66666666666667, 1.0, 2.0, 0.7789091886034157, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 887788.2168310974, 887788.2168310974, 191628.9149226598], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5138400.0000, 
sim time next is 5139000.0000, 
raw observation next is [29.95, 76.5, 1.0, 2.0, 0.8098522915317596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 923077.9099004904, 923077.9099004904, 197992.371281971], 
processed observation next is [0.0, 0.4782608695652174, 0.6648148148148147, 0.765, 1.0, 1.0, 0.773633680394952, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32967068210731804, 0.32967068210731804, 0.38075456015763653], 
reward next is 0.6192, 
noisyNet noise sample is [array([-0.6491818], dtype=float32), 1.012546]. 
=============================================
[2019-03-23 00:38:59,326] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[23.472246]
 [23.104227]
 [23.30725 ]
 [23.565678]
 [23.673893]], R is [[24.38582802]
 [24.77345276]
 [25.13569641]
 [25.41234589]
 [25.1582222 ]].
[2019-03-23 00:39:00,925] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 00:39:00,926] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:39:00,927] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:39:00,928] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:39:00,929] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:39:00,930] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:39:00,931] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:39:00,931] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:39:00,935] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:39:00,938] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:39:00,938] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:39:00,960] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run32
[2019-03-23 00:39:00,981] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run32
[2019-03-23 00:39:01,000] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run32
[2019-03-23 00:39:01,022] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run32
[2019-03-23 00:39:01,040] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run32
[2019-03-23 00:39:12,166] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.12913163], dtype=float32), -0.14467536]
[2019-03-23 00:39:12,168] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.82950742666667, 50.63655414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4253816503868845, 6.9112, 6.9112, 121.9260426156618, 303716.0684333735, 303716.0684333735, 94701.20321308966]
[2019-03-23 00:39:12,169] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:39:12,173] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.000000e+00 7.600763e-36 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.590663664981644
[2019-03-23 00:39:16,779] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.12913163], dtype=float32), -0.14467536]
[2019-03-23 00:39:16,780] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.25, 48.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4380036623418085, 6.911199999999999, 6.9112, 121.9260426156618, 312729.8314693778, 312729.8314693783, 96724.5265634283]
[2019-03-23 00:39:16,782] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:39:16,785] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.7509385e-37 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.950878549320936
[2019-03-23 00:39:30,656] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.12913163], dtype=float32), -0.14467536]
[2019-03-23 00:39:30,660] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.44468182, 75.2931082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6264734703630912, 6.9112, 6.9112, 121.9260426156618, 467467.3596560545, 467467.3596560545, 135187.6407067625]
[2019-03-23 00:39:30,661] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:39:30,663] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.17073498471029913
[2019-03-23 00:39:57,135] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.12913163], dtype=float32), -0.14467536]
[2019-03-23 00:39:57,135] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 94.0, 1.0, 2.0, 0.6640492211562842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 756808.0319736323, 756808.0319736318, 169448.5529869056]
[2019-03-23 00:39:57,135] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:39:57,138] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 1.7636188e-37 0.0000000e+00 0.0000000e+00], sampled 0.9932741118767132
[2019-03-23 00:39:57,139] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 756808.0319736323 W.
[2019-03-23 00:39:57,655] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.12913163], dtype=float32), -0.14467536]
[2019-03-23 00:39:57,657] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.25, 95.66666666666666, 1.0, 2.0, 0.7087103723454543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 807734.5688099293, 807734.5688099293, 177798.9833638772]
[2019-03-23 00:39:57,658] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:39:57,664] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.000000e+00 0.000000e+00 8.663567e-37 0.000000e+00 0.000000e+00], sampled 0.11781751413892994
[2019-03-23 00:39:57,664] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 807734.5688099293 W.
[2019-03-23 00:39:58,320] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.12913163], dtype=float32), -0.14467536]
[2019-03-23 00:39:58,322] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.73333333333333, 65.16666666666667, 1.0, 2.0, 0.7266218687749892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 828159.7687100349, 828159.7687100335, 181247.5627870167]
[2019-03-23 00:39:58,323] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:39:58,325] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.000000e+00 0.000000e+00 4.036167e-35 0.000000e+00 0.000000e+00], sampled 0.5969774096528576
[2019-03-23 00:39:58,329] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 828159.7687100349 W.
[2019-03-23 00:40:06,637] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.12913163], dtype=float32), -0.14467536]
[2019-03-23 00:40:06,638] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.0, 70.0, 1.0, 2.0, 0.6082723194250006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695612.9663644867, 695612.9663644867, 159625.4159616537]
[2019-03-23 00:40:06,638] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:40:06,641] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 1.8028816e-37 0.0000000e+00 0.0000000e+00], sampled 0.5459351607763416
[2019-03-23 00:40:06,642] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 695612.9663644867 W.
[2019-03-23 00:40:20,599] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.12913163], dtype=float32), -0.14467536]
[2019-03-23 00:40:20,600] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.4, 93.0, 1.0, 2.0, 0.7252402691630628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 826584.255721865, 826584.2557218645, 180975.4199472289]
[2019-03-23 00:40:20,601] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:40:20,604] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 1.2178687e-36 0.0000000e+00 0.0000000e+00], sampled 0.007095653714872419
[2019-03-23 00:40:20,607] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 826584.255721865 W.
[2019-03-23 00:40:46,111] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.12913163], dtype=float32), -0.14467536]
[2019-03-23 00:40:46,113] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.41666666666667, 22.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6097260902986372, 6.9112, 6.9112, 121.9260426156618, 435399.8277551144, 435399.8277551144, 122340.8900372291]
[2019-03-23 00:40:46,114] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:40:46,116] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 3.4873776e-36 0.0000000e+00 0.0000000e+00], sampled 0.5919385288445682
[2019-03-23 00:40:53,243] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8558.6925 2258281932.5947 536.0000
[2019-03-23 00:40:53,244] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.2402 2292979445.9673 697.0000
[2019-03-23 00:40:53,359] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8362.8332 2339455255.0445 615.0000
[2019-03-23 00:40:53,385] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5008 2529782916.7115 831.0000
[2019-03-23 00:40:53,408] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8636.2623 2219126457.1969 543.0000
[2019-03-23 00:40:54,423] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 775000, evaluation results [775000.0, 7841.500825456038, 2529782916.711494, 831.0, 8558.692516993873, 2258281932.5946884, 536.0, 8636.262268021734, 2219126457.196872, 543.0, 8362.833232666982, 2339455255.0444665, 615.0, 8404.240247944708, 2292979445.967258, 697.0]
[2019-03-23 00:41:00,797] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 4.4072424e-31 3.6111043e-19 6.2561612e-26 1.0753800e-22], sum to 1.0000
[2019-03-23 00:41:00,810] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2332
[2019-03-23 00:41:00,814] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.3, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9523500422814765, 6.911199999999999, 6.9112, 121.9260426156618, 685651.4561927243, 685651.4561927248, 184746.3489887538], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5335200.0000, 
sim time next is 5335800.0000, 
raw observation next is [28.26666666666667, 68.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9551034722274947, 6.9112, 6.9112, 121.9260426156618, 687437.7210783295, 687437.7210783295, 185152.9992650774], 
processed observation next is [1.0, 0.782608695652174, 0.6024691358024692, 0.6833333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9438793402843684, 0.0, 0.0, 0.8094621288201359, 0.2455134718136891, 0.2455134718136891, 0.35606346012514883], 
reward next is 0.6439, 
noisyNet noise sample is [array([-0.6548116], dtype=float32), -0.13629414]. 
=============================================
[2019-03-23 00:41:01,193] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 4.4969990e-30 8.7560806e-11 1.4156789e-25], sum to 1.0000
[2019-03-23 00:41:01,199] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5335
[2019-03-23 00:41:01,204] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 88.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9160861044020102, 6.9112, 6.9112, 121.9260425833843, 675646.5327605804, 675646.5327605804, 176818.5387360691], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5290200.0000, 
sim time next is 5290800.0000, 
raw observation next is [23.5, 88.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9038389417177753, 6.911200000000001, 6.9112, 121.926042615652, 667302.0285639882, 667302.0285639877, 174987.890442632], 
processed observation next is [1.0, 0.21739130434782608, 0.42592592592592593, 0.8833333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.879798677147219, 8.881784197001253e-17, 0.0, 0.8094621288200708, 0.2383221530585672, 0.23832215305856702, 0.33651517392813846], 
reward next is 0.6635, 
noisyNet noise sample is [array([0.36812416], dtype=float32), 0.37190044]. 
=============================================
[2019-03-23 00:41:06,914] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.9601242e-31 1.6826877e-17 1.8940462e-27], sum to 1.0000
[2019-03-23 00:41:06,922] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3031
[2019-03-23 00:41:06,926] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1886597.093037504 W.
[2019-03-23 00:41:06,929] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5513975723889014, 1.0, 2.0, 0.5513975723889014, 1.0, 1.0, 0.8778428930083668, 6.911199999999999, 6.9112, 121.94756008, 1886597.093037504, 1886597.093037504, 369531.1389991636], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5400000.0000, 
sim time next is 5400600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.7933009267972795, 1.0, 2.0, 0.7933009267972795, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1809432.363995866, 1809432.363995866, 340994.2241946894], 
processed observation next is [1.0, 0.5217391304347826, 0.5555555555555556, 0.84, 1.0, 1.0, 0.753929674758666, 1.0, 1.0, 0.753929674758666, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6462258442842378, 0.6462258442842378, 0.6557581234513258], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3126521], dtype=float32), 0.5223518]. 
=============================================
[2019-03-23 00:41:07,936] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.8179672e-01 0.0000000e+00 1.3925357e-16 1.1820327e-01 4.3826198e-13], sum to 1.0000
[2019-03-23 00:41:07,941] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2808
[2019-03-23 00:41:07,948] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2409892.061688357 W.
[2019-03-23 00:41:07,954] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.33333333333334, 76.66666666666667, 1.0, 2.0, 0.7815415138828926, 1.0, 1.0, 0.7041354189178809, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2409892.061688357, 2409892.061688358, 451870.3900966303], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5415600.0000, 
sim time next is 5416200.0000, 
raw observation next is [29.5, 75.5, 1.0, 2.0, 0.7522237614048427, 1.0, 2.0, 0.689476542678856, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2359655.996355444, 2359655.996355445, 443568.2948032787], 
processed observation next is [1.0, 0.6956521739130435, 0.6481481481481481, 0.755, 1.0, 1.0, 0.7050282873867175, 1.0, 1.0, 0.6303292174748286, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.8427342844126586, 0.842734284412659, 0.8530159515447667], 
reward next is 0.1470, 
noisyNet noise sample is [array([-1.1488979], dtype=float32), -0.10154568]. 
=============================================
[2019-03-23 00:41:22,410] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.1880164e-34 1.2358194e-31 3.8256248e-35 3.1661799e-32], sum to 1.0000
[2019-03-23 00:41:22,416] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6578
[2019-03-23 00:41:22,425] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 808274.1982654055 W.
[2019-03-23 00:41:22,429] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.3, 77.66666666666667, 1.0, 2.0, 0.2363945541237375, 1.0, 2.0, 0.2363945541237375, 1.0, 1.0, 0.3763478289981343, 6.9112, 6.9112, 121.94756008, 808274.1982654055, 808274.1982654055, 232852.7892521019], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5660400.0000, 
sim time next is 5661000.0000, 
raw observation next is [28.4, 77.0, 1.0, 2.0, 0.3545588959482252, 1.0, 2.0, 0.3545588959482252, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808199.1596635312, 808199.1596635312, 194069.6659301305], 
processed observation next is [0.0, 0.5217391304347826, 0.6074074074074074, 0.77, 1.0, 1.0, 0.23161773327169669, 1.0, 1.0, 0.23161773327169669, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2886425570226897, 0.2886425570226897, 0.3732108960194817], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4538116], dtype=float32), 1.415993]. 
=============================================
[2019-03-23 00:41:22,441] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[47.413395]
 [47.340355]
 [47.651947]
 [48.170975]
 [48.631233]], R is [[46.81190491]
 [46.89599609]
 [46.42703629]
 [45.96276474]
 [45.50313568]].
[2019-03-23 00:41:24,184] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 7.1283413e-27 7.3342827e-26 1.0162485e-36 4.7973775e-30], sum to 1.0000
[2019-03-23 00:41:24,190] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1598
[2019-03-23 00:41:24,195] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.51666666666667, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.899642066938128, 6.911200000000001, 6.9112, 121.9260426156618, 659640.1778693502, 659640.1778693497, 175635.4369981318], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5699400.0000, 
sim time next is 5700000.0000, 
raw observation next is [23.43333333333334, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8940146440939464, 6.911200000000001, 6.9112, 121.9260426156618, 655945.5405948694, 655945.540594869, 174794.1142481751], 
processed observation next is [0.0, 1.0, 0.42345679012345705, 0.9266666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8675183051174329, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23426626449816765, 0.23426626449816748, 0.33614252740033673], 
reward next is 0.6639, 
noisyNet noise sample is [array([1.3062919], dtype=float32), -1.3971299]. 
=============================================
[2019-03-23 00:41:24,210] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[49.260387]
 [47.884563]
 [45.918907]
 [43.065613]
 [43.19982 ]], R is [[50.30542755]
 [50.46461105]
 [50.61949158]
 [50.11329651]
 [50.26523209]].
[2019-03-23 00:41:33,709] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.8039703e-35 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:41:33,714] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8675
[2019-03-23 00:41:33,717] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6037885376042476, 6.911199999999999, 6.9112, 121.9260426156618, 447672.2012988198, 447672.2012988203, 130404.9410512376], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5882400.0000, 
sim time next is 5883000.0000, 
raw observation next is [19.93333333333333, 85.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8160526579088763, 6.9112, 6.9112, 121.9260426156618, 604783.5024734009, 604783.5024734009, 152128.9699587497], 
processed observation next is [1.0, 0.08695652173913043, 0.293827160493827, 0.8500000000000001, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7700658223860953, 0.0, 0.0, 0.8094621288201359, 0.2159941080262146, 0.2159941080262146, 0.292555711459134], 
reward next is 0.7074, 
noisyNet noise sample is [array([0.11336736], dtype=float32), -0.99958205]. 
=============================================
[2019-03-23 00:41:33,734] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[61.173203]
 [61.327785]
 [61.553738]
 [61.78374 ]
 [62.007744]], R is [[61.33315277]
 [61.46904373]
 [61.6028862 ]
 [61.7346344 ]
 [61.86417389]].
[2019-03-23 00:41:42,333] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.6263292e-31 1.2953981e-18 3.6488691e-32], sum to 1.0000
[2019-03-23 00:41:42,344] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0910
[2019-03-23 00:41:42,350] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.9, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.814364910358952, 6.9112, 6.9112, 121.9260426156618, 604064.9989276461, 604064.9989276461, 162507.3508649186], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6048000.0000, 
sim time next is 6048600.0000, 
raw observation next is [23.78333333333333, 82.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8122842537090035, 6.911199999999999, 6.9112, 121.9260426156618, 602594.4370065748, 602594.4370065753, 162212.6663027556], 
processed observation next is [1.0, 0.0, 0.43641975308641967, 0.8283333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7653553171362543, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2152122989309196, 0.21521229893091975, 0.3119474351976069], 
reward next is 0.6881, 
noisyNet noise sample is [array([-0.64677036], dtype=float32), -0.03753813]. 
=============================================
[2019-03-23 00:41:46,103] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 00:41:46,106] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:41:46,107] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:41:46,108] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:41:46,109] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:41:46,110] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:41:46,111] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:41:46,115] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:41:46,118] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:41:46,113] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:41:46,120] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:41:46,134] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run33
[2019-03-23 00:41:46,135] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run33
[2019-03-23 00:41:46,177] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run33
[2019-03-23 00:41:46,202] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run33
[2019-03-23 00:41:46,221] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run33
[2019-03-23 00:42:11,910] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.03037575], dtype=float32), -0.19363736]
[2019-03-23 00:42:11,912] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.33333333333333, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6332158797375899, 6.9112, 6.9112, 121.9260426156618, 471938.9603949608, 471938.9603949608, 135187.200112147]
[2019-03-23 00:42:11,916] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:42:11,919] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 1.0746025e-34 2.9271024e-37 8.0721912e-37], sampled 0.11813913364536832
[2019-03-23 00:42:29,980] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.03037575], dtype=float32), -0.19363736]
[2019-03-23 00:42:29,980] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.26789102333333, 91.95757158999999, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.325184895118394, 6.9112, 121.9242814709981, 1374943.281902103, 1162949.076218045, 245582.5222092825]
[2019-03-23 00:42:29,981] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:42:29,985] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9970192e-01 0.0000000e+00 1.0222043e-21 2.9804566e-04 2.1441089e-25], sampled 0.5540379319146871
[2019-03-23 00:42:29,986] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1374943.281902103 W.
[2019-03-23 00:42:48,513] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.03037575], dtype=float32), -0.19363736]
[2019-03-23 00:42:48,515] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.14240765666667, 84.18388373666666, 1.0, 1.0, 0.6468079283198698, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737148.912481939, 737148.912481939, 166321.9881293999]
[2019-03-23 00:42:48,517] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:42:48,520] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.00000000e+00 0.00000000e+00 9.75504902e-25 1.01334614e-19
 2.65918906e-27], sampled 0.011357947909583
[2019-03-23 00:42:48,522] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 737148.912481939 W.
[2019-03-23 00:42:55,398] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.03037575], dtype=float32), -0.19363736]
[2019-03-23 00:42:55,400] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.22298677333333, 94.83688091500001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8371524086482004, 6.9112, 6.9112, 121.9260426156618, 620135.0031500271, 620135.0031500271, 165692.0988244394]
[2019-03-23 00:42:55,401] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:42:55,404] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 8.8430992e-31 2.8262309e-38 2.3260206e-36], sampled 0.047032854643098254
[2019-03-23 00:43:14,027] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.03037575], dtype=float32), -0.19363736]
[2019-03-23 00:43:14,028] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.01666666666667, 79.16666666666667, 1.0, 2.0, 0.7215770499638214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 822406.9038194909, 822406.9038194909, 180265.4168703502]
[2019-03-23 00:43:14,029] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:43:14,031] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.000000e+00 0.000000e+00 1.594400e-26 4.263700e-24 7.442904e-34], sampled 0.6847888959779684
[2019-03-23 00:43:14,032] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 822406.9038194909 W.
[2019-03-23 00:43:16,323] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.03037575], dtype=float32), -0.19363736]
[2019-03-23 00:43:16,324] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.505604795, 73.75515060000001, 1.0, 2.0, 0.7424677840517128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 846229.9571161974, 846229.9571161979, 184343.6141875935]
[2019-03-23 00:43:16,326] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:43:16,333] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.7073797e-26 4.6628498e-23 4.3650638e-30 2.6443933e-32], sampled 0.6432301461556559
[2019-03-23 00:43:16,334] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 846229.9571161974 W.
[2019-03-23 00:43:38,180] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8621.2731 2248942396.7045 504.0000
[2019-03-23 00:43:38,284] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8673.1167 2212997765.3236 513.0000
[2019-03-23 00:43:38,677] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7967.4408 2508459531.7578 706.0000
[2019-03-23 00:43:38,683] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8472.4544 2282091815.2477 630.0000
[2019-03-23 00:43:38,753] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8455.7022 2321800989.8085 539.0000
[2019-03-23 00:43:39,770] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 800000, evaluation results [800000.0, 7967.44080212859, 2508459531.757834, 706.0, 8621.273089485843, 2248942396.704546, 504.0, 8673.116662019465, 2212997765.323591, 513.0, 8455.702244495713, 2321800989.8084936, 539.0, 8472.454443570265, 2282091815.2477183, 630.0]
[2019-03-23 00:43:40,683] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:43:40,691] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8635
[2019-03-23 00:43:40,698] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.73333333333333, 68.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8679666239752695, 6.9112, 6.9112, 121.9260426156618, 638755.6873130946, 638755.6873130946, 170918.7310213436], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6124800.0000, 
sim time next is 6125400.0000, 
raw observation next is [26.65, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8672323497423071, 6.911200000000001, 6.9112, 121.9260426156618, 638415.0841002644, 638415.0841002639, 170771.143843975], 
processed observation next is [1.0, 0.9130434782608695, 0.5425925925925925, 0.69, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8340404371778839, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22800538717866584, 0.22800538717866567, 0.32840604585379807], 
reward next is 0.6716, 
noisyNet noise sample is [array([0.6423612], dtype=float32), -0.46955958]. 
=============================================
[2019-03-23 00:43:47,714] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.9013470e-28 2.0330069e-20 1.0657714e-28], sum to 1.0000
[2019-03-23 00:43:47,722] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7928
[2019-03-23 00:43:47,727] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.6, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9422197960068958, 6.9112, 6.9112, 121.9260426156618, 683784.4718009151, 683784.4718009151, 182640.8262141464], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6259200.0000, 
sim time next is 6259800.0000, 
raw observation next is [26.75, 75.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9497850299368978, 6.9112, 6.9112, 121.9260426156618, 688115.8434852562, 688115.8434852562, 183852.4836865061], 
processed observation next is [0.0, 0.43478260869565216, 0.5462962962962963, 0.7533333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9372312874211222, 0.0, 0.0, 0.8094621288201359, 0.2457556583875915, 0.2457556583875915, 0.35356246862789636], 
reward next is 0.6464, 
noisyNet noise sample is [array([0.64960736], dtype=float32), -0.05446813]. 
=============================================
[2019-03-23 00:43:49,830] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 8.5556421e-23 3.6713204e-32 0.0000000e+00 3.6304588e-32], sum to 1.0000
[2019-03-23 00:43:49,837] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7091
[2019-03-23 00:43:49,842] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.5, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.937622904085973, 6.9112, 6.9112, 121.9260426156618, 684091.9976131736, 684091.9976131736, 181414.5453865994], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6298200.0000, 
sim time next is 6298800.0000, 
raw observation next is [26.33333333333334, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.933617601075254, 6.9112, 6.9112, 121.9260426156618, 681230.2373316189, 681230.2373316189, 180856.3938942499], 
processed observation next is [0.0, 0.9130434782608695, 0.5308641975308644, 0.75, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9170220013440674, 0.0, 0.0, 0.8094621288201359, 0.24329651333272104, 0.24329651333272104, 0.3478007574889421], 
reward next is 0.6522, 
noisyNet noise sample is [array([-0.5884622], dtype=float32), 2.1774883]. 
=============================================
[2019-03-23 00:43:52,427] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 9.0792410e-21 1.5225012e-27 0.0000000e+00 3.2576162e-38], sum to 1.0000
[2019-03-23 00:43:52,441] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0133
[2019-03-23 00:43:52,446] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 781525.507356986 W.
[2019-03-23 00:43:52,452] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.35, 68.0, 1.0, 2.0, 0.6857261276744999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 781525.507356986, 781525.5073569865, 173458.9173446072], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6381000.0000, 
sim time next is 6381600.0000, 
raw observation next is [29.23333333333333, 68.66666666666667, 1.0, 2.0, 0.3433825173585107, 1.0, 1.0, 0.3433825173585107, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 782710.159471152, 782710.159471152, 191197.6878191262], 
processed observation next is [0.0, 0.8695652173913043, 0.6382716049382715, 0.6866666666666668, 1.0, 1.0, 0.2183125206648937, 1.0, 0.5, 0.2183125206648937, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2795393426682686, 0.2795393426682686, 0.3676878611906273], 
reward next is 0.6323, 
noisyNet noise sample is [array([-0.8639547], dtype=float32), -0.69115484]. 
=============================================
[2019-03-23 00:43:52,499] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 3.5311124e-28 2.8599348e-33 0.0000000e+00 6.3069226e-38], sum to 1.0000
[2019-03-23 00:43:52,504] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6860
[2019-03-23 00:43:52,515] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 725457.4409165928 W.
[2019-03-23 00:43:52,519] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.36666666666667, 81.0, 1.0, 2.0, 0.2121847351566652, 1.0, 2.0, 0.2121847351566652, 1.0, 1.0, 0.3378050087437968, 6.911199999999999, 6.9112, 121.94756008, 725457.4409165928, 725457.4409165933, 224616.1181428207], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6339000.0000, 
sim time next is 6339600.0000, 
raw observation next is [26.6, 80.0, 1.0, 2.0, 0.3205433235880257, 1.0, 2.0, 0.3205433235880257, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 730625.4208952887, 730625.4208952887, 185463.708084053], 
processed observation next is [0.0, 0.391304347826087, 0.5407407407407407, 0.8, 1.0, 1.0, 0.19112300427145915, 1.0, 1.0, 0.19112300427145915, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.260937650319746, 0.260937650319746, 0.35666097708471733], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6845501], dtype=float32), 1.823361]. 
=============================================
[2019-03-23 00:43:52,998] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 5.0934835e-19 1.4705722e-28 0.0000000e+00 2.6971459e-32], sum to 1.0000
[2019-03-23 00:43:53,003] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5967
[2019-03-23 00:43:53,011] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 745514.7845746785 W.
[2019-03-23 00:43:53,015] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.1, 78.0, 1.0, 2.0, 0.3270724782347899, 1.0, 2.0, 0.3270724782347899, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 745514.7845746785, 745514.784574679, 187084.4189626348], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6340800.0000, 
sim time next is 6341400.0000, 
raw observation next is [27.35, 77.0, 1.0, 2.0, 0.3301608970335794, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5256269006671974, 6.911199999999999, 6.9112, 121.9260426156618, 752557.8477347742, 752557.8477347747, 203527.4752425467], 
processed observation next is [0.0, 0.391304347826087, 0.5685185185185185, 0.77, 1.0, 1.0, 0.20257249646854694, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4070336258339967, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2687706599052765, 0.26877065990527665, 0.39139899085105134], 
reward next is 0.6086, 
noisyNet noise sample is [array([-1.3980514], dtype=float32), 0.115581825]. 
=============================================
[2019-03-23 00:44:04,573] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.9726418e-17 4.3785624e-27 0.0000000e+00 2.0796869e-27], sum to 1.0000
[2019-03-23 00:44:04,584] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6024
[2019-03-23 00:44:04,590] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1664432.119726808 W.
[2019-03-23 00:44:04,596] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.3, 80.33333333333333, 1.0, 2.0, 0.4865256275561187, 1.0, 2.0, 0.4865256275561187, 1.0, 1.0, 0.7745646441028311, 6.9112, 6.9112, 121.94756008, 1664432.119726808, 1664432.119726808, 337024.8857908999], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6532800.0000, 
sim time next is 6533400.0000, 
raw observation next is [27.35, 80.16666666666667, 1.0, 2.0, 0.7244231496189916, 1.0, 2.0, 0.7244231496189916, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1652184.428709704, 1652184.428709705, 313514.492317136], 
processed observation next is [1.0, 0.6086956521739131, 0.5685185185185185, 0.8016666666666667, 1.0, 1.0, 0.67193232097499, 1.0, 1.0, 0.67193232097499, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5900658673963228, 0.5900658673963232, 0.6029124852252616], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1170843], dtype=float32), -0.38725656]. 
=============================================
[2019-03-23 00:44:13,579] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:44:13,589] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1393
[2019-03-23 00:44:13,596] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.06666666666667, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7287838521620836, 6.9112, 6.9112, 121.9260426156618, 544338.124545585, 544338.124545585, 149173.3698149614], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6826800.0000, 
sim time next is 6827400.0000, 
raw observation next is [23.0, 78.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7219102108017817, 6.911199999999999, 6.9112, 121.9260426156618, 539301.0913668656, 539301.091366866, 148171.4325393511], 
processed observation next is [0.0, 0.0, 0.4074074074074074, 0.785, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.652387763502227, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19260753263102343, 0.1926075326310236, 0.2849450625756752], 
reward next is 0.7151, 
noisyNet noise sample is [array([1.4508213], dtype=float32), -0.81147015]. 
=============================================
[2019-03-23 00:44:14,291] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 9.1391967e-33 8.5200505e-29 0.0000000e+00 9.8613419e-33], sum to 1.0000
[2019-03-23 00:44:14,301] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1082
[2019-03-23 00:44:14,313] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1062988.979320028 W.
[2019-03-23 00:44:14,319] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.75, 28.83333333333334, 1.0, 2.0, 0.4263314746132149, 1.0, 2.0, 0.4263314746132149, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1062988.979320028, 1062988.979320027, 216837.5955011708], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6703800.0000, 
sim time next is 6704400.0000, 
raw observation next is [29.8, 28.66666666666667, 1.0, 2.0, 0.7938734296583143, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1001886.121544577, 1001886.121544577, 198256.1367126052], 
processed observation next is [1.0, 0.6086956521739131, 0.6592592592592593, 0.28666666666666674, 1.0, 1.0, 0.7546112257837075, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.35781647198020605, 0.35781647198020605, 0.3812618013703946], 
reward next is 0.6187, 
noisyNet noise sample is [array([-0.3105663], dtype=float32), -0.24493013]. 
=============================================
[2019-03-23 00:44:21,628] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.00000000e+00 1.72924123e-32 1.19832866e-29 0.00000000e+00
 2.93043189e-37], sum to 1.0000
[2019-03-23 00:44:21,639] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9370
[2019-03-23 00:44:21,643] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.33333333333333, 79.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7559671889548732, 6.9112, 6.9112, 121.9260426156618, 563879.1305644412, 563879.1305644412, 153341.7281422713], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6824400.0000, 
sim time next is 6825000.0000, 
raw observation next is [23.26666666666667, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7493014617395346, 6.911200000000001, 6.9112, 121.9260426156618, 559160.787415791, 559160.7874157905, 152283.4879882669], 
processed observation next is [1.0, 1.0, 0.41728395061728407, 0.7933333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6866268271744183, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19970028121992534, 0.19970028121992517, 0.29285286151589784], 
reward next is 0.7071, 
noisyNet noise sample is [array([0.72802454], dtype=float32), 0.88107365]. 
=============================================
[2019-03-23 00:44:21,652] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[66.78232]
 [66.81506]
 [66.83817]
 [66.86725]
 [66.92845]], R is [[66.78847504]
 [66.82569885]
 [66.8604126 ]
 [66.89253998]
 [66.92216492]].
[2019-03-23 00:44:33,626] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 00:44:33,628] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:44:33,628] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:44:33,628] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:44:33,629] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:44:33,630] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:44:33,632] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:44:33,632] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:44:33,634] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:44:33,636] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:44:33,637] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:44:33,650] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run34
[2019-03-23 00:44:33,668] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run34
[2019-03-23 00:44:33,669] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run34
[2019-03-23 00:44:33,705] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run34
[2019-03-23 00:44:33,706] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run34
[2019-03-23 00:44:36,218] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.18576966], dtype=float32), -0.2403967]
[2019-03-23 00:44:36,219] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.33333333333333, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3882563255650938, 6.9112, 6.9112, 121.9260426156618, 277204.3576301316, 277204.3576301316, 81783.51226686881]
[2019-03-23 00:44:36,220] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:44:36,221] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 6.5344931e-29 1.2696197e-35 0.0000000e+00 7.4119815e-37], sampled 0.2489343925965236
[2019-03-23 00:45:27,381] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.18576966], dtype=float32), -0.2403967]
[2019-03-23 00:45:27,382] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.9, 83.33333333333334, 1.0, 2.0, 0.6134319767216819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 701627.1312042129, 701627.1312042129, 160529.1661581931]
[2019-03-23 00:45:27,384] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:45:27,388] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.7093535e-27 8.5599160e-31 2.2136649e-33 2.0015216e-32], sampled 0.14645845853309358
[2019-03-23 00:45:27,390] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 701627.1312042129 W.
[2019-03-23 00:45:32,262] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.18576966], dtype=float32), -0.2403967]
[2019-03-23 00:45:32,263] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.5, 84.83333333333334, 1.0, 2.0, 0.3576632064444101, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5694114729369263, 6.911199999999999, 6.9112, 121.9260424439572, 815279.0425898699, 815279.0425898704, 211399.1802624108]
[2019-03-23 00:45:32,264] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:45:32,268] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.2213767e-36 2.1026713e-25 6.8141097e-14 9.7571429e-23], sampled 0.7824266946368778
[2019-03-23 00:45:32,269] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 815279.0425898699 W.
[2019-03-23 00:46:13,491] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.18576966], dtype=float32), -0.2403967]
[2019-03-23 00:46:13,495] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.88333333333334, 78.33333333333333, 1.0, 2.0, 0.6671707764151199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 827468.4622224324, 827468.4622224324, 172621.857257017]
[2019-03-23 00:46:13,497] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:46:13,500] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 3.4131822e-24 2.3570424e-28 0.0000000e+00 3.3753733e-32], sampled 0.01447868411127018
[2019-03-23 00:46:13,500] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 827468.4622224324 W.
[2019-03-23 00:46:23,842] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8564.9159 2256240425.5778 530.0000
[2019-03-23 00:46:24,349] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8416.7003 2290082003.2169 683.0000
[2019-03-23 00:46:24,363] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8379.7432 2333643495.5150 594.0000
[2019-03-23 00:46:24,367] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7870.9909 2521820052.9524 787.0000
[2019-03-23 00:46:24,391] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8640.5084 2217668163.0673 539.0000
[2019-03-23 00:46:25,406] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 825000, evaluation results [825000.0, 7870.990867061403, 2521820052.952385, 787.0, 8564.915855027202, 2256240425.577767, 530.0, 8640.50842696807, 2217668163.0672545, 539.0, 8379.743222757672, 2333643495.5149636, 594.0, 8416.700267324875, 2290082003.216856, 683.0]
[2019-03-23 00:46:25,931] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.4566378e-19 6.6815601e-18 6.5559492e-19 2.5106457e-11], sum to 1.0000
[2019-03-23 00:46:25,939] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2282
[2019-03-23 00:46:25,949] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1691096.670307568 W.
[2019-03-23 00:46:25,953] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.75, 61.0, 1.0, 2.0, 0.7359441513202352, 1.0, 2.0, 0.7359441513202352, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1691096.670307568, 1691096.670307568, 318647.2117748771], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7050600.0000, 
sim time next is 7051200.0000, 
raw observation next is [27.5, 62.0, 1.0, 2.0, 0.6924913147667183, 1.0, 2.0, 0.6924913147667183, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1597262.577677133, 1597262.577677134, 302237.7858171407], 
processed observation next is [1.0, 0.6086956521739131, 0.5740740740740741, 0.62, 1.0, 1.0, 0.6339182318651408, 1.0, 1.0, 0.6339182318651408, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5704509205989761, 0.5704509205989764, 0.581226511186809], 
reward next is 0.4188, 
noisyNet noise sample is [array([-0.7325392], dtype=float32), -0.33244607]. 
=============================================
[2019-03-23 00:46:33,541] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.4865688e-27 2.8422880e-37 0.0000000e+00 2.9132790e-29], sum to 1.0000
[2019-03-23 00:46:33,551] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3535
[2019-03-23 00:46:33,555] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.91666666666666, 84.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6297077814907452, 6.911199999999999, 6.9112, 121.9260426156618, 469443.0186964705, 469443.018696471, 134968.2302470271], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7199400.0000, 
sim time next is 7200000.0000, 
raw observation next is [21.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6487173385604351, 6.9112, 6.9112, 121.9260426156618, 483713.2282040767, 483713.2282040767, 136983.1820175337], 
processed observation next is [1.0, 0.34782608695652173, 0.3333333333333333, 0.84, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5608966732005438, 0.0, 0.0, 0.8094621288201359, 0.17275472435859882, 0.17275472435859882, 0.2634291961875648], 
reward next is 0.7366, 
noisyNet noise sample is [array([-0.6716901], dtype=float32), -0.24197471]. 
=============================================
[2019-03-23 00:46:33,581] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[70.59749 ]
 [70.595726]
 [70.60356 ]
 [70.638916]
 [70.68396 ]], R is [[70.58644104]
 [70.62102509]
 [70.6555481 ]
 [70.68917847]
 [70.72376251]].
[2019-03-23 00:46:36,285] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.000000e+00 2.872106e-16 2.129009e-31 0.000000e+00 8.237771e-31], sum to 1.0000
[2019-03-23 00:46:36,293] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6089
[2019-03-23 00:46:36,299] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 818718.2775026092 W.
[2019-03-23 00:46:36,303] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333334, 70.0, 1.0, 2.0, 0.3369688014022005, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5485133675319589, 6.9112, 6.9112, 121.9260426156618, 818718.2775026092, 818718.2775026092, 203393.2756912334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7231200.0000, 
sim time next is 7231800.0000, 
raw observation next is [23.81666666666667, 70.0, 1.0, 2.0, 0.6461847873023068, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 791788.0030559788, 791788.0030559783, 168454.6326947838], 
processed observation next is [1.0, 0.6956521739130435, 0.43765432098765444, 0.7, 1.0, 1.0, 0.5787914134551271, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2827814296628496, 0.2827814296628494, 0.32395121672073807], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.20281814], dtype=float32), -0.28881526]. 
=============================================
[2019-03-23 00:46:38,971] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.5194202e-32 1.6327669e-38 0.0000000e+00 3.5320717e-34], sum to 1.0000
[2019-03-23 00:46:38,981] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4792
[2019-03-23 00:46:38,990] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 897042.1154510339 W.
[2019-03-23 00:46:38,993] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.23333333333333, 83.33333333333334, 1.0, 2.0, 0.2495536114024961, 1.0, 1.0, 0.2495536114024961, 1.0, 2.0, 0.4026075163675531, 6.911200000000001, 6.9112, 121.94756008, 897042.1154510339, 897042.1154510335, 236909.1757867779], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7292400.0000, 
sim time next is 7293000.0000, 
raw observation next is [22.36666666666667, 82.66666666666667, 1.0, 2.0, 0.2510916238117408, 1.0, 2.0, 0.2510916238117408, 1.0, 2.0, 0.4044201919171008, 6.9112, 6.9112, 121.94756008, 899709.81956559, 899709.81956559, 237545.8345171062], 
processed observation next is [1.0, 0.391304347826087, 0.38395061728395075, 0.8266666666666667, 1.0, 1.0, 0.10844240929969146, 1.0, 1.0, 0.10844240929969146, 1.0, 1.0, 0.255525239896376, 0.0, 0.0, 0.8096049824067558, 0.32132493555913927, 0.32132493555913927, 0.4568189125328966], 
reward next is 0.5432, 
noisyNet noise sample is [array([1.1487172], dtype=float32), 0.82612175]. 
=============================================
[2019-03-23 00:46:39,007] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[62.65586 ]
 [63.148064]
 [63.095592]
 [63.32033 ]
 [63.775726]], R is [[63.1126976 ]
 [63.02597809]
 [62.98542023]
 [63.01037979]
 [63.04031372]].
[2019-03-23 00:46:40,071] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 8.2609443e-28 3.5933368e-34 0.0000000e+00 4.1498844e-30], sum to 1.0000
[2019-03-23 00:46:40,079] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6262
[2019-03-23 00:46:40,087] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1320066.582390248 W.
[2019-03-23 00:46:40,091] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.8, 62.0, 1.0, 2.0, 0.3794409161431169, 1.0, 2.0, 0.3794409161431169, 1.0, 1.0, 0.6051982832550716, 6.911199999999999, 6.9112, 121.94756008, 1320066.582390248, 1320066.582390249, 288257.3890023648], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7308600.0000, 
sim time next is 7309200.0000, 
raw observation next is [26.8, 62.0, 1.0, 2.0, 0.5655411954157039, 1.0, 2.0, 0.5655411954157039, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1323938.293016298, 1323938.293016298, 258000.714570574], 
processed observation next is [1.0, 0.6086956521739131, 0.5481481481481482, 0.62, 1.0, 1.0, 0.4827871373996475, 1.0, 1.0, 0.4827871373996475, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.47283510464867784, 0.47283510464867784, 0.4961552203280269], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9110872], dtype=float32), 0.14202103]. 
=============================================
[2019-03-23 00:46:41,195] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.6976211e-15 1.5787188e-26 7.1675439e-29 2.5468431e-26], sum to 1.0000
[2019-03-23 00:46:41,202] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7336
[2019-03-23 00:46:41,212] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1294907.267464025 W.
[2019-03-23 00:46:41,218] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.9, 61.0, 1.0, 2.0, 0.5510608742232034, 1.0, 2.0, 0.5510608742232034, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1294907.267464025, 1294907.267464025, 253392.3903301871], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7317600.0000, 
sim time next is 7318200.0000, 
raw observation next is [26.9, 61.0, 1.0, 2.0, 0.5523833850738724, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8853999028568492, 6.9112, 6.9112, 121.9260426156618, 1305058.974232873, 1305058.974232873, 274791.9657269837], 
processed observation next is [1.0, 0.6956521739130435, 0.5518518518518518, 0.61, 1.0, 1.0, 0.4671230774688957, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.8567498785710614, 0.0, 0.0, 0.8094621288201359, 0.46609249079745463, 0.46609249079745463, 0.528446087936507], 
reward next is 0.4716, 
noisyNet noise sample is [array([1.1220412], dtype=float32), 0.8464607]. 
=============================================
[2019-03-23 00:46:41,658] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.2626055e-22 0.0000000e+00 0.0000000e+00 1.4859009e-33], sum to 1.0000
[2019-03-23 00:46:41,666] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1254
[2019-03-23 00:46:41,671] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.4, 63.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7373770790346923, 6.9112, 6.9112, 121.9260426156618, 548827.9773185698, 548827.9773185698, 152090.2448803099], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7320600.0000, 
sim time next is 7321200.0000, 
raw observation next is [26.23333333333333, 63.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7418953195014922, 6.9112, 6.9112, 121.9260426156618, 552468.9068548613, 552468.9068548613, 152438.0699833741], 
processed observation next is [1.0, 0.7391304347826086, 0.5271604938271603, 0.6366666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6773691493768652, 0.0, 0.0, 0.8094621288201359, 0.19731032387673617, 0.19731032387673617, 0.2931501345834117], 
reward next is 0.7068, 
noisyNet noise sample is [array([1.0634565], dtype=float32), 0.9425888]. 
=============================================
[2019-03-23 00:46:45,063] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.8852873e-35 1.3536185e-35 4.6429670e-32 1.1152295e-34], sum to 1.0000
[2019-03-23 00:46:45,069] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0676
[2019-03-23 00:46:45,081] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 828088.5566921727 W.
[2019-03-23 00:46:45,089] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.1, 95.0, 1.0, 1.0, 0.3342574858130777, 1.0, 1.0, 0.3342574858130777, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260057803166, 828088.5566921727, 828088.5566921727, 191397.0653198826], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7374600.0000, 
sim time next is 7375200.0000, 
raw observation next is [19.13333333333333, 95.0, 1.0, 2.0, 0.3293740480607327, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5464733165630973, 6.911200000000001, 6.9112, 121.9260426044298, 816297.6259285231, 816297.6259285227, 199893.3570297957], 
processed observation next is [1.0, 0.34782608695652173, 0.2641975308641974, 0.95, 1.0, 1.0, 0.2016357715008723, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.43309164570387154, 8.881784197001253e-17, 0.0, 0.8094621287455671, 0.291534866403044, 0.2915348664030438, 0.38441030198037635], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0265651], dtype=float32), 0.26523405]. 
=============================================
[2019-03-23 00:46:46,560] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.0433974e-32 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:46:46,568] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9283
[2019-03-23 00:46:46,576] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.18333333333333, 90.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6399576178290964, 6.911200000000001, 6.9112, 121.9260426156618, 477107.5915609545, 477107.591560954, 136016.5344047993], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7419000.0000, 
sim time next is 7419600.0000, 
raw observation next is [20.2, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6392625058418745, 6.911200000000001, 6.9112, 121.9260426156618, 476581.1530218248, 476581.1530218244, 135937.6897934691], 
processed observation next is [1.0, 0.9130434782608695, 0.3037037037037037, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.549078132302343, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1702075546506517, 0.17020755465065157, 0.2614186342182098], 
reward next is 0.7386, 
noisyNet noise sample is [array([-0.04805569], dtype=float32), -0.33085817]. 
=============================================
[2019-03-23 00:46:50,321] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 4.2849446e-32 3.0689012e-36 0.0000000e+00 9.0018116e-30], sum to 1.0000
[2019-03-23 00:46:50,327] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7777
[2019-03-23 00:46:50,331] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.96666666666667, 77.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8300555148664095, 6.911200000000001, 6.9112, 121.9260426156618, 613220.9373760984, 613220.9373760979, 165401.7282060475], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7490400.0000, 
sim time next is 7491000.0000, 
raw observation next is [24.93333333333333, 77.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8316696749318367, 6.911200000000001, 6.9112, 121.9260426156618, 614468.15821595, 614468.1582159495, 165585.343814843], 
processed observation next is [0.0, 0.6956521739130435, 0.47901234567901224, 0.7783333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7895870936647958, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21945291364855357, 0.2194529136485534, 0.3184333534900827], 
reward next is 0.6816, 
noisyNet noise sample is [array([0.5978744], dtype=float32), -0.69249874]. 
=============================================
[2019-03-23 00:46:50,346] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[70.67567]
 [70.64192]
 [70.60346]
 [70.56843]
 [70.5589 ]], R is [[70.67746735]
 [70.65261841]
 [70.62770844]
 [70.60284424]
 [70.57810974]].
[2019-03-23 00:46:51,332] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:46:51,332] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:46:51,373] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run5
[2019-03-23 00:46:51,462] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.4484346e-30 2.4903941e-38 0.0000000e+00 1.8472195e-38], sum to 1.0000
[2019-03-23 00:46:51,470] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7652
[2019-03-23 00:46:51,478] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.73333333333333, 84.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.813883302120185, 6.9112, 6.9112, 121.9260426156618, 602630.3224555094, 602630.3224555094, 162879.3208889768], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7497600.0000, 
sim time next is 7498200.0000, 
raw observation next is [23.61666666666667, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8117724969253383, 6.911199999999999, 6.9112, 121.9260426156618, 601213.419354731, 601213.4193547314, 162556.3344246314], 
processed observation next is [0.0, 0.782608695652174, 0.4302469135802471, 0.8533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7647156211566727, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21471907834097534, 0.2147190783409755, 0.31260833543198346], 
reward next is 0.6874, 
noisyNet noise sample is [array([0.24844977], dtype=float32), -0.8458709]. 
=============================================
[2019-03-23 00:46:55,224] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.000000e+00 2.501019e-38 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 00:46:55,233] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6316
[2019-03-23 00:46:55,238] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.03333333333333, 83.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.807350827285757, 6.9112, 6.9112, 121.9260426156618, 597374.8280936889, 597374.8280936889, 162204.1242159927], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7555200.0000, 
sim time next is 7555800.0000, 
raw observation next is [24.21666666666667, 82.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8138646583775603, 6.911200000000001, 6.9112, 121.9260426156618, 601638.3601569431, 601638.3601569426, 163221.9459786762], 
processed observation next is [0.0, 0.43478260869565216, 0.4524691358024692, 0.8266666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7673308229719502, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21487084291319397, 0.2148708429131938, 0.3138883576513004], 
reward next is 0.6861, 
noisyNet noise sample is [array([0.27732524], dtype=float32), -0.39721328]. 
=============================================
[2019-03-23 00:46:55,720] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 4.9840921e-29 1.9039608e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:46:55,733] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8525
[2019-03-23 00:46:55,737] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.5, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8628785788432882, 6.911200000000001, 6.9112, 121.9260426156618, 633328.8675052646, 633328.8675052641, 170677.2274688228], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7569000.0000, 
sim time next is 7569600.0000, 
raw observation next is [27.66666666666666, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8750607866716414, 6.911200000000001, 6.9112, 121.9260426156618, 640866.6289445808, 640866.6289445803, 172564.9047060434], 
processed observation next is [0.0, 0.6086956521739131, 0.5802469135802467, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8438259833395517, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22888093890877886, 0.2288809389087787, 0.3318555859731604], 
reward next is 0.6681, 
noisyNet noise sample is [array([0.3941774], dtype=float32), 0.08957804]. 
=============================================
[2019-03-23 00:47:10,571] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:47:10,571] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:10,594] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:47:10,595] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:10,602] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run5
[2019-03-23 00:47:10,652] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run5
[2019-03-23 00:47:12,848] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 6.9598985e-33 7.7899946e-32 5.9069245e-33 1.6050473e-28], sum to 1.0000
[2019-03-23 00:47:12,857] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0727
[2019-03-23 00:47:12,866] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4477364392698718, 6.9112, 6.9112, 121.9260426156618, 319680.3761426546, 319680.3761426546, 101146.9658234531], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 19800.0000, 
sim time next is 20400.0000, 
raw observation next is [18.0, 73.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4455843010247363, 6.911199999999999, 6.9112, 121.9260426156618, 318143.4472765018, 318143.4472765023, 100604.9996416259], 
processed observation next is [1.0, 0.21739130434782608, 0.2222222222222222, 0.7366666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.30698037628092034, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11362265974160779, 0.11362265974160797, 0.19347115315697289], 
reward next is 0.8065, 
noisyNet noise sample is [array([0.0677484], dtype=float32), 1.5833024]. 
=============================================
[2019-03-23 00:47:13,107] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.8838043e-33 8.8795976e-33 6.9328174e-33 8.1480476e-30], sum to 1.0000
[2019-03-23 00:47:13,122] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5544
[2019-03-23 00:47:13,128] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.2, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6417955152880428, 6.911200000000001, 6.9112, 121.9260426156618, 477012.9666297468, 477012.9666297464, 134865.196372713], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7882200.0000, 
sim time next is 7882800.0000, 
raw observation next is [20.33333333333334, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6315435452943309, 6.9112, 6.9112, 121.9260426156618, 469420.3639292245, 469420.3639292245, 133881.1993404438], 
processed observation next is [1.0, 0.21739130434782608, 0.3086419753086422, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5394294316179136, 0.0, 0.0, 0.8094621288201359, 0.16765012997472303, 0.16765012997472303, 0.25746384488546886], 
reward next is 0.7425, 
noisyNet noise sample is [array([-0.13276103], dtype=float32), 1.5348552]. 
=============================================
[2019-03-23 00:47:14,476] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:47:14,477] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:14,516] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run5
[2019-03-23 00:47:16,065] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 5.6262158e-28 9.5475086e-35 0.0000000e+00 4.3869428e-25], sum to 1.0000
[2019-03-23 00:47:16,070] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2346
[2019-03-23 00:47:16,076] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.2, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5004984244561627, 6.911200000000001, 6.9112, 121.9260426156618, 360207.8975131399, 360207.8975131395, 116135.9243928478], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 435600.0000, 
sim time next is 436200.0000, 
raw observation next is [21.93333333333333, 56.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.501489069501265, 6.911200000000001, 6.9112, 121.9260426156618, 360887.1799558208, 360887.1799558203, 116200.4767859805], 
processed observation next is [1.0, 0.043478260869565216, 0.36790123456790114, 0.5666666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.37686133687658124, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12888827855565027, 0.1288882785556501, 0.2234624553576548], 
reward next is 0.7765, 
noisyNet noise sample is [array([1.2877016], dtype=float32), 0.742133]. 
=============================================
[2019-03-23 00:47:16,579] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:47:16,580] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:16,608] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run5
[2019-03-23 00:47:16,680] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:47:16,681] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:16,697] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run5
[2019-03-23 00:47:16,814] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:47:16,814] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:16,822] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:47:16,824] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:16,837] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run5
[2019-03-23 00:47:16,868] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run5
[2019-03-23 00:47:16,888] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:47:16,889] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:16,906] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run5
[2019-03-23 00:47:17,027] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:47:17,027] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:17,039] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run5
[2019-03-23 00:47:17,060] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:47:17,061] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:17,074] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run5
[2019-03-23 00:47:17,142] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:47:17,143] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:17,150] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run5
[2019-03-23 00:47:17,184] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:47:17,185] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:17,188] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run5
[2019-03-23 00:47:17,233] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:47:17,233] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:17,240] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run5
[2019-03-23 00:47:17,267] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:47:17,269] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:17,282] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run5
[2019-03-23 00:47:17,362] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 00:47:17,363] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:17,365] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run5
[2019-03-23 00:47:18,878] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 00:47:18,879] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:47:18,879] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:18,880] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:47:18,881] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:18,882] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:47:18,883] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:18,885] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:47:18,885] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:18,885] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:47:18,888] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:47:18,901] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run35
[2019-03-23 00:47:18,901] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run35
[2019-03-23 00:47:18,901] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run35
[2019-03-23 00:47:18,914] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run35
[2019-03-23 00:47:18,931] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run35
[2019-03-23 00:47:25,595] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13585487], dtype=float32), -0.21847129]
[2019-03-23 00:47:25,596] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 33.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5208761513277584, 6.911200000000001, 6.9112, 121.9260426156618, 371914.2303617734, 371914.230361773, 106923.7960811759]
[2019-03-23 00:47:25,597] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:47:25,601] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.3584186e-28 3.5574663e-34 0.0000000e+00 6.6995530e-33], sampled 0.8162439554244365
[2019-03-23 00:47:54,715] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13585487], dtype=float32), -0.21847129]
[2019-03-23 00:47:54,715] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.83333333333333, 44.83333333333334, 1.0, 2.0, 0.2595265114327995, 1.0, 2.0, 0.2595265114327995, 1.0, 2.0, 0.4131746583894162, 6.911199999999999, 6.9112, 121.94756008, 887412.1739468209, 887412.1739468214, 241028.8017253171]
[2019-03-23 00:47:54,716] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:47:54,719] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9844283e-01 4.0266263e-19 8.5663819e-20 2.2902677e-22 1.5571766e-03], sampled 0.08338267200199534
[2019-03-23 00:47:54,720] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 887412.1739468209 W.
[2019-03-23 00:48:03,755] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.13585487], dtype=float32), -0.21847129]
[2019-03-23 00:48:03,756] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.16666666666667, 98.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6537178310750767, 6.9112, 6.9112, 121.9260426156618, 487175.5029406055, 487175.5029406055, 137197.7144125847]
[2019-03-23 00:48:03,757] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:48:03,760] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.3263200e-38 7.8658510e-37 0.0000000e+00 2.1139244e-31], sampled 0.35142692280027676
[2019-03-23 00:48:08,618] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13585487], dtype=float32), -0.21847129]
[2019-03-23 00:48:08,620] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.0, 79.0, 1.0, 2.0, 0.6478974133235341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 738391.1661097357, 738391.1661097357, 166513.8502533782]
[2019-03-23 00:48:08,620] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:48:08,623] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.6561405e-15 5.7524913e-24 0.0000000e+00 1.4079426e-21], sampled 0.7101362066871805
[2019-03-23 00:48:08,625] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 738391.1661097357 W.
[2019-03-23 00:48:19,034] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.13585487], dtype=float32), -0.21847129]
[2019-03-23 00:48:19,075] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.16666666666667, 84.83333333333333, 1.0, 2.0, 0.8638655818713842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 984682.3632936644, 984682.3632936644, 209499.9853729091]
[2019-03-23 00:48:19,075] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:48:19,078] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.9272304e-19 3.0607389e-22 0.0000000e+00 5.5173600e-18], sampled 0.9558648736092282
[2019-03-23 00:48:19,080] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 984682.3632936644 W.
[2019-03-23 00:48:32,613] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13585487], dtype=float32), -0.21847129]
[2019-03-23 00:48:32,614] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.71666666666667, 89.16666666666667, 1.0, 2.0, 0.6723716593830729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 766297.744839073, 766297.744839073, 170978.3061268118]
[2019-03-23 00:48:32,615] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:48:32,617] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 4.0562407e-31 9.0935676e-26 0.0000000e+00 1.4146669e-21], sampled 0.01953698552970895
[2019-03-23 00:48:32,619] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 766297.744839073 W.
[2019-03-23 00:48:48,234] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13585487], dtype=float32), -0.21847129]
[2019-03-23 00:48:48,236] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.21200653666667, 87.20660289666668, 1.0, 2.0, 0.6737541577594893, 1.0, 1.0, 0.6737541577594893, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1536518.328930722, 1536518.328930722, 294348.1113598539]
[2019-03-23 00:48:48,237] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:48:48,238] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.2539733e-14 0.0000000e+00 7.5886778e-22 1.0000000e+00 1.7364410e-08], sampled 0.13404325256624494
[2019-03-23 00:49:04,470] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.13585487], dtype=float32), -0.21847129]
[2019-03-23 00:49:04,471] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.41666666666666, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8242344502305092, 6.911199999999999, 6.9112, 121.9260426156618, 609676.6512104865, 609676.651210487, 164420.3829775096]
[2019-03-23 00:49:04,472] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:49:04,475] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.8325502e-31 1.7183723e-31 6.2639141e-36 9.5762076e-29], sampled 0.7188472617313973
[2019-03-23 00:49:04,772] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.13585487], dtype=float32), -0.21847129]
[2019-03-23 00:49:04,773] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.30858574, 84.602841745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8771883399577333, 6.911200000000001, 6.9112, 121.9260426156618, 651282.1081575169, 651282.1081575166, 170108.1301490887]
[2019-03-23 00:49:04,774] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:49:04,776] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.1266108e-36 3.4982190e-31 2.7441502e-31 1.1392969e-26], sampled 0.11854497142488496
[2019-03-23 00:49:08,332] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8442.0580 2328141997.1551 525.0000
[2019-03-23 00:49:08,736] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8665.9579 2214890719.1971 509.0000
[2019-03-23 00:49:08,780] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8461.1052 2285494153.0272 639.0000
[2019-03-23 00:49:08,841] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8601.1107 2252463929.0575 507.0000
[2019-03-23 00:49:08,899] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7963.1944 2518005144.6779 657.0000
[2019-03-23 00:49:09,913] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 850000, evaluation results [850000.0, 7963.194414634945, 2518005144.6778746, 657.0, 8601.11068495798, 2252463929.0574703, 507.0, 8665.957891665343, 2214890719.197086, 509.0, 8442.05798350486, 2328141997.155136, 525.0, 8461.105152445449, 2285494153.02724, 639.0]
[2019-03-23 00:49:10,746] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.8307649e-29 3.9416835e-24 2.7012857e-24 4.0168830e-16], sum to 1.0000
[2019-03-23 00:49:10,756] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3424
[2019-03-23 00:49:10,765] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1148665.324106442 W.
[2019-03-23 00:49:10,770] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.66666666666667, 40.0, 1.0, 2.0, 0.4748198464850456, 1.0, 1.0, 0.4748198464850456, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9259924974677, 1148665.324106442, 1148665.324106441, 230440.9307030912], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 564600.0000, 
sim time next is 565200.0000, 
raw observation next is [29.8, 39.0, 1.0, 2.0, 0.429778527367275, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6995123070161076, 6.9112, 6.9112, 121.9260426003795, 1044218.66516558, 1044218.66516558, 231193.143405794], 
processed observation next is [1.0, 0.5652173913043478, 0.6592592592592593, 0.39, 1.0, 1.0, 0.3211649135324703, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.6243903837701344, 0.0, 0.0, 0.8094621287186774, 0.3729352375591357, 0.3729352375591357, 0.4446021988572961], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5136111], dtype=float32), -0.7462575]. 
=============================================
[2019-03-23 00:49:14,691] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.5719459e-34 0.0000000e+00 0.0000000e+00 1.6635445e-35], sum to 1.0000
[2019-03-23 00:49:14,697] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2871
[2019-03-23 00:49:14,706] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.3, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6949535888976526, 6.911200000000001, 6.9112, 121.9260426156618, 519330.9272859811, 519330.9272859807, 144318.379549501], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 81000.0000, 
sim time next is 81600.0000, 
raw observation next is [25.13333333333333, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.695029579998132, 6.911200000000001, 6.9112, 121.9260426156618, 519387.063862282, 519387.0638622815, 144348.4327000333], 
processed observation next is [1.0, 0.9565217391304348, 0.4864197530864196, 0.63, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6187869749976649, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.185495379950815, 0.18549537995081483, 0.27759313980775635], 
reward next is 0.7224, 
noisyNet noise sample is [array([-0.02657739], dtype=float32), -1.0218817]. 
=============================================
[2019-03-23 00:49:15,290] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.3100126e-31 6.8772778e-37 0.0000000e+00 2.5477378e-33], sum to 1.0000
[2019-03-23 00:49:15,298] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7592
[2019-03-23 00:49:15,305] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.15, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6831529759925791, 6.911200000000001, 6.9112, 121.9260426156618, 510445.712716537, 510445.7127165366, 142406.388924179], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 91800.0000, 
sim time next is 92400.0000, 
raw observation next is [23.03333333333333, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6827196278914246, 6.911200000000001, 6.9112, 121.9260426156618, 510096.2735931953, 510096.2735931948, 142255.711130704], 
processed observation next is [1.0, 0.043478260869565216, 0.4086419753086419, 0.74, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6033995348642807, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1821772405689983, 0.18217724056899814, 0.27356867525135387], 
reward next is 0.7264, 
noisyNet noise sample is [array([0.20337656], dtype=float32), -1.543154]. 
=============================================
[2019-03-23 00:49:16,359] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 3.0395342e-33 6.5140586e-37 0.0000000e+00 2.0740160e-33], sum to 1.0000
[2019-03-23 00:49:16,366] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1920
[2019-03-23 00:49:16,370] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.3, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6906445803454697, 6.911200000000001, 6.9112, 121.9260426156618, 514799.7847577648, 514799.7847577643, 141104.3286450605], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 111600.0000, 
sim time next is 112200.0000, 
raw observation next is [22.4, 73.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6885595844768184, 6.9112, 6.9112, 121.9260426156618, 513406.875236488, 513406.875236488, 141065.3449193286], 
processed observation next is [1.0, 0.30434782608695654, 0.38518518518518513, 0.7383333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.610699480596023, 0.0, 0.0, 0.8094621288201359, 0.1833595982987457, 0.1833595982987457, 0.2712795094602473], 
reward next is 0.7287, 
noisyNet noise sample is [array([-2.0912995], dtype=float32), 0.50783545]. 
=============================================
[2019-03-23 00:49:32,889] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:49:32,900] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3062
[2019-03-23 00:49:32,904] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.91666666666666, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5019448079236557, 6.911200000000001, 6.9112, 121.9260426156618, 361761.0121232748, 361761.0121232743, 116431.8546249511], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 949800.0000, 
sim time next is 950400.0000, 
raw observation next is [22.8, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4999962773617797, 6.911199999999999, 6.9112, 121.9260426156618, 360203.8783045569, 360203.8783045574, 116225.4293405314], 
processed observation next is [1.0, 0.0, 0.4, 0.52, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3749953467022246, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12864424225162746, 0.12864424225162766, 0.22351044103948345], 
reward next is 0.7765, 
noisyNet noise sample is [array([-0.6064705], dtype=float32), -0.2270567]. 
=============================================
[2019-03-23 00:49:51,359] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.5671382e-36], sum to 1.0000
[2019-03-23 00:49:51,367] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9864
[2019-03-23 00:49:51,375] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.8, 53.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7178286820686832, 6.911199999999999, 6.9112, 121.9260426156618, 518465.1525894078, 518465.1525894083, 135390.9439516395], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 709800.0000, 
sim time next is 710400.0000, 
raw observation next is [22.9, 53.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6548755663199427, 6.9112, 6.9112, 121.9260426156618, 473982.5027584839, 473982.5027584839, 129928.6076803625], 
processed observation next is [1.0, 0.21739130434782608, 0.4037037037037037, 0.5333333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5685944578999284, 0.0, 0.0, 0.8094621288201359, 0.1692794652708871, 0.1692794652708871, 0.2498627070776202], 
reward next is 0.7501, 
noisyNet noise sample is [array([0.4084292], dtype=float32), -0.6515314]. 
=============================================
[2019-03-23 00:49:56,575] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:49:56,588] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6446
[2019-03-23 00:49:56,595] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.73333333333333, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5345132533057391, 6.9112, 6.9112, 121.9260426156618, 390675.5552164813, 390675.5552164813, 121138.1645633142], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 796800.0000, 
sim time next is 797400.0000, 
raw observation next is [22.8, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5362945897475738, 6.9112, 6.9112, 121.9260426156618, 392328.7442588927, 392328.7442588927, 121441.3699956082], 
processed observation next is [0.0, 0.21739130434782608, 0.4, 0.58, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.42036823718446725, 0.0, 0.0, 0.8094621288201359, 0.14011740866389025, 0.14011740866389025, 0.2335410961454004], 
reward next is 0.7665, 
noisyNet noise sample is [array([1.4543592], dtype=float32), -1.9798336]. 
=============================================
[2019-03-23 00:49:58,617] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.0020872e-23 2.7218429e-36 0.0000000e+00 5.4112734e-37], sum to 1.0000
[2019-03-23 00:49:58,629] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0086
[2019-03-23 00:49:58,635] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.2, 36.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7076606528478664, 6.911200000000001, 6.9112, 121.9260426156618, 528740.574143094, 528740.5741430935, 146309.3733230445], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 840600.0000, 
sim time next is 841200.0000, 
raw observation next is [31.13333333333333, 36.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7040923759505604, 6.911200000000001, 6.9112, 121.9260426156618, 526124.9856398134, 526124.9856398129, 145687.892451637], 
processed observation next is [0.0, 0.7391304347826086, 0.7086419753086418, 0.36333333333333345, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6301154699382006, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18790178058564763, 0.18790178058564747, 0.28016902394545573], 
reward next is 0.7198, 
noisyNet noise sample is [array([-1.4688017], dtype=float32), 1.8169451]. 
=============================================
[2019-03-23 00:50:04,290] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.8493370e-28 2.5988624e-31 0.0000000e+00 3.3297463e-30], sum to 1.0000
[2019-03-23 00:50:04,300] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2646
[2019-03-23 00:50:04,306] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.2, 56.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6725034784574359, 6.911199999999999, 6.9112, 121.9260426156618, 480212.5606241075, 480212.5606241079, 126993.8658345812], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 958800.0000, 
sim time next is 959400.0000, 
raw observation next is [21.15, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5611000999246739, 6.9112, 6.9112, 121.9260426156618, 400642.3004280109, 400642.3004280109, 117175.9524611506], 
processed observation next is [1.0, 0.08695652173913043, 0.33888888888888885, 0.57, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45137512490584236, 0.0, 0.0, 0.8094621288201359, 0.14308653586714673, 0.14308653586714673, 0.22533837011759733], 
reward next is 0.7747, 
noisyNet noise sample is [array([0.11522962], dtype=float32), 0.24339071]. 
=============================================
[2019-03-23 00:50:04,376] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 00:50:04,377] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:50:04,378] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:50:04,380] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:50:04,381] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:50:04,382] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:50:04,383] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:50:04,384] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:50:04,382] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:50:04,384] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:50:04,384] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:50:04,413] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run36
[2019-03-23 00:50:04,434] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run36
[2019-03-23 00:50:04,435] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run36
[2019-03-23 00:50:04,455] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run36
[2019-03-23 00:50:04,495] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run36
[2019-03-23 00:50:34,374] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.20722331], dtype=float32), -0.16555856]
[2019-03-23 00:50:34,375] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.11969445, 56.18331966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.668738757032122, 6.911200000000001, 6.9112, 121.9260426156618, 499087.0646064252, 499087.0646064247, 139598.7014499984]
[2019-03-23 00:50:34,376] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:50:34,379] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.2752587e-37 1.4023680e-36 0.0000000e+00 2.1887387e-37], sampled 0.7100201635297089
[2019-03-23 00:50:44,260] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.20722331], dtype=float32), -0.16555856]
[2019-03-23 00:50:44,262] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.5, 89.0, 1.0, 2.0, 0.6587284075184734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 750741.0021109901, 750741.0021109901, 168476.170627899]
[2019-03-23 00:50:44,262] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:50:44,265] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.3463292e-37 2.3032702e-33 0.0000000e+00 0.0000000e+00], sampled 0.38399801826240243
[2019-03-23 00:50:44,268] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 750741.0021109901 W.
[2019-03-23 00:50:50,260] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.20722331], dtype=float32), -0.16555856]
[2019-03-23 00:50:50,261] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.694888465, 38.77296371, 1.0, 2.0, 0.4886525312944267, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7800760231536263, 6.911199999999999, 6.9112, 121.9260426156618, 1138243.327400063, 1138243.327400063, 252586.1341254506]
[2019-03-23 00:50:50,263] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:50:50,266] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 2.0217325e-26 5.8720567e-18 4.2981995e-27], sampled 0.05922738514255921
[2019-03-23 00:50:50,267] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1138243.327400063 W.
[2019-03-23 00:51:01,738] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.20722331], dtype=float32), -0.16555856]
[2019-03-23 00:51:01,740] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.30941947333334, 57.69589439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8485527456168569, 6.911200000000001, 6.9112, 121.9260426156618, 628361.5435531627, 628361.5435531622, 167203.983738475]
[2019-03-23 00:51:01,741] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:51:01,745] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8667467843676632
[2019-03-23 00:51:02,595] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.20722331], dtype=float32), -0.16555856]
[2019-03-23 00:51:02,596] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.66179378166667, 83.71654068833332, 1.0, 2.0, 0.6572825138556301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 749092.3377378345, 749092.3377378345, 168214.9306660606]
[2019-03-23 00:51:02,596] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:51:02,600] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 5.0602916e-33 1.2188710e-31 0.0000000e+00 0.0000000e+00], sampled 0.9647170903774707
[2019-03-23 00:51:02,601] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 749092.3377378345 W.
[2019-03-23 00:51:04,279] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.20722331], dtype=float32), -0.16555856]
[2019-03-23 00:51:04,281] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.21666666666667, 34.5, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.642706913165207, 6.9112, 121.9231312316195, 1594285.716446727, 1219697.740289878, 248509.3613333991]
[2019-03-23 00:51:04,282] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:51:04,286] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.4741062e-34 1.5349278e-20 1.3417334e-19 3.4468107e-23], sampled 0.9192629655397743
[2019-03-23 00:51:04,288] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1594285.716446727 W.
[2019-03-23 00:51:04,761] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.20722331], dtype=float32), -0.16555856]
[2019-03-23 00:51:04,762] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.0, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7290368759962289, 6.9112, 6.9112, 121.9260426156618, 544772.4093939225, 544772.4093939225, 148467.6861208703]
[2019-03-23 00:51:04,763] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:51:04,764] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 3.4608609e-35 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9852308295171225
[2019-03-23 00:51:10,595] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.20722331], dtype=float32), -0.16555856]
[2019-03-23 00:51:10,597] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.66666666666667, 79.33333333333334, 1.0, 2.0, 0.6264778792255284, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9973731866871628, 6.911200000000001, 6.9112, 121.9255332258009, 1428602.674348134, 1428602.674348134, 304305.2161307273]
[2019-03-23 00:51:10,598] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:51:10,600] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.00000000e+00 1.11161036e-27 1.68496070e-18 4.59905183e-19
 1.08304165e-14], sampled 0.661085916008922
[2019-03-23 00:51:10,603] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1428602.674348134 W.
[2019-03-23 00:51:16,449] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.20722331], dtype=float32), -0.16555856]
[2019-03-23 00:51:16,451] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.66666666666667, 53.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.798648491188599, 6.9112, 6.9112, 121.9260426156618, 592917.3297811192, 592917.3297811192, 160301.6459950247]
[2019-03-23 00:51:16,452] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:51:16,455] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.000000e+00 7.886797e-36 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.37610996457561063
[2019-03-23 00:51:27,096] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.20722331], dtype=float32), -0.16555856]
[2019-03-23 00:51:27,097] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.35, 44.0, 1.0, 2.0, 0.7342013008986046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 885183.3191167756, 885183.3191167756, 184878.0060463907]
[2019-03-23 00:51:27,098] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:51:27,101] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 6.8368871e-23 4.5081602e-24 1.2149043e-35 1.3076275e-24], sampled 0.9317085392685471
[2019-03-23 00:51:27,101] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 885183.3191167756 W.
[2019-03-23 00:51:34,408] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.20722331], dtype=float32), -0.16555856]
[2019-03-23 00:51:34,413] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.73223094, 87.5485068, 1.0, 2.0, 0.6320743030143732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 720349.5219122153, 720349.5219122153, 163683.3227516674]
[2019-03-23 00:51:34,413] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:51:34,419] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7845674973581336
[2019-03-23 00:51:34,420] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 720349.5219122153 W.
[2019-03-23 00:51:47,210] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.20722331], dtype=float32), -0.16555856]
[2019-03-23 00:51:47,210] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.0, 24.0, 1.0, 2.0, 0.8652507273720245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.920312802979542, 6.9112, 121.9258550622754, 1103099.200750055, 1098432.638309817, 213884.2869071323]
[2019-03-23 00:51:47,212] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:51:47,217] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 4.2606639e-37 7.5635978e-28 0.0000000e+00 5.8160562e-33], sampled 0.6241942176312645
[2019-03-23 00:51:47,218] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1103099.200750055 W.
[2019-03-23 00:51:55,095] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.20722331], dtype=float32), -0.16555856]
[2019-03-23 00:51:55,096] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.16666666666666, 86.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6509621244765397, 6.9112, 6.9112, 121.9260426156618, 486183.2815779187, 486183.2815779187, 138410.0406190475]
[2019-03-23 00:51:55,098] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:51:55,101] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 4.9567144e-36 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.12441002567786197
[2019-03-23 00:51:55,574] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8562.8762 2257451433.6375 532.0000
[2019-03-23 00:51:55,712] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7858.3668 2524200015.2122 793.0000
[2019-03-23 00:51:55,981] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8374.3400 2335765189.4037 598.0000
[2019-03-23 00:51:56,015] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8412.8844 2290771058.0224 686.0000
[2019-03-23 00:51:56,127] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8638.8020 2218116122.2656 541.0000
[2019-03-23 00:51:57,143] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 875000, evaluation results [875000.0, 7858.366842616562, 2524200015.2122264, 793.0, 8562.876207421688, 2257451433.637491, 532.0, 8638.802037681113, 2218116122.2656264, 541.0, 8374.339968387327, 2335765189.403681, 598.0, 8412.884358336098, 2290771058.022366, 686.0]
[2019-03-23 00:51:57,574] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:51:57,577] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5871
[2019-03-23 00:51:57,582] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.13333333333334, 53.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4912053098638681, 6.9112, 6.9112, 121.9260426156618, 351664.6980579814, 351664.6980579814, 114773.8825281213], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 953400.0000, 
sim time next is 954000.0000, 
raw observation next is [22.0, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.487974220505944, 6.9112, 6.9112, 121.9260426156618, 348855.4065712512, 348855.4065712512, 114362.3873634205], 
processed observation next is [1.0, 0.043478260869565216, 0.37037037037037035, 0.54, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.35996777563243, 0.0, 0.0, 0.8094621288201359, 0.12459121663258972, 0.12459121663258972, 0.21992766800657787], 
reward next is 0.7801, 
noisyNet noise sample is [array([0.9414533], dtype=float32), -0.6986015]. 
=============================================
[2019-03-23 00:51:57,604] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.92167 ]
 [67.950226]
 [68.00671 ]
 [68.201515]
 [68.62156 ]], R is [[68.04525757]
 [68.14408875]
 [68.24118805]
 [68.33670044]
 [68.4307251 ]].
[2019-03-23 00:52:05,151] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1396746e-08 2.0087283e-23 1.7670716e-09 1.6954549e-21 1.0000000e+00], sum to 1.0000
[2019-03-23 00:52:05,159] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3088
[2019-03-23 00:52:05,165] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 43.0, 1.0, 2.0, 0.1768780151904076, 1.0, 1.0, 0.1768780151904076, 1.0, 1.0, 0.297316070021257, 6.911199999999999, 6.9112, 121.94756008, 663893.6694537939, 663893.6694537943, 210395.1995350549], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1083600.0000, 
sim time next is 1084200.0000, 
raw observation next is [26.15, 42.5, 1.0, 2.0, 0.1666315159481461, 1.0, 2.0, 0.1666315159481461, 1.0, 2.0, 0.2796021557082431, 6.9112, 6.9112, 121.94756008, 624679.5682844768, 624679.5682844768, 207314.2438087614], 
processed observation next is [1.0, 0.5652173913043478, 0.524074074074074, 0.425, 1.0, 1.0, 0.007894661843031064, 1.0, 1.0, 0.007894661843031064, 1.0, 1.0, 0.09950269463530385, 0.0, 0.0, 0.8096049824067558, 0.22309984581588455, 0.22309984581588455, 0.39868123809377193], 
reward next is 0.6013, 
noisyNet noise sample is [array([0.31073305], dtype=float32), -0.19313788]. 
=============================================
[2019-03-23 00:52:14,860] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 7.2781946e-29 2.8440342e-22 5.5317805e-16 2.0614486e-09], sum to 1.0000
[2019-03-23 00:52:14,868] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4020
[2019-03-23 00:52:14,871] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.3, 86.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6153685809885292, 6.911200000000001, 6.9112, 121.9260426156618, 453787.9137586775, 453787.9137586771, 130051.4239977722], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1239000.0000, 
sim time next is 1239600.0000, 
raw observation next is [19.5, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8505929404986011, 6.911200000000001, 6.9112, 121.9260426156618, 627773.3200402112, 627773.3200402107, 154419.7989850546], 
processed observation next is [1.0, 0.34782608695652173, 0.2777777777777778, 0.8566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8132411756232513, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2242047571572183, 0.22420475715721813, 0.29696115189433575], 
reward next is 0.7030, 
noisyNet noise sample is [array([-0.97659624], dtype=float32), 0.67760736]. 
=============================================
[2019-03-23 00:52:18,400] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.3473130e-35 1.1997063e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:52:18,408] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1116
[2019-03-23 00:52:18,417] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [35.3, 23.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.682939524529749, 6.911200000000001, 6.9112, 121.9260426156618, 510323.920576083, 510323.9205760826, 142586.4413951468], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1521000.0000, 
sim time next is 1521600.0000, 
raw observation next is [35.13333333333333, 24.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6808046415787998, 6.9112, 6.9112, 121.9260426156618, 508747.9055829988, 508747.9055829988, 142902.4478697619], 
processed observation next is [0.0, 0.6086956521739131, 0.8567901234567901, 0.2466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6010058019734997, 0.0, 0.0, 0.8094621288201359, 0.18169568056535673, 0.18169568056535673, 0.27481239974954214], 
reward next is 0.7252, 
noisyNet noise sample is [array([-0.78332597], dtype=float32), -0.92436224]. 
=============================================
[2019-03-23 00:52:22,748] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.99999762e-01 1.32404275e-36 3.46282505e-29 2.77879792e-07
 2.28482908e-20], sum to 1.0000
[2019-03-23 00:52:22,763] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1921
[2019-03-23 00:52:22,769] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 978820.8496947055 W.
[2019-03-23 00:52:22,774] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 57.16666666666666, 1.0, 2.0, 0.3939427343774608, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6555772053132335, 6.911200000000001, 6.9112, 121.9260426156238, 978820.8496947055, 978820.849694705, 218353.7665201281], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1587000.0000, 
sim time next is 1587600.0000, 
raw observation next is [24.3, 57.0, 1.0, 2.0, 0.8676587478218799, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1085102.505479392, 1085102.505479392, 214173.6780613917], 
processed observation next is [1.0, 0.391304347826087, 0.4555555555555556, 0.57, 1.0, 1.0, 0.8424508902641428, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3875366090997828, 0.3875366090997828, 0.41187245781036863], 
reward next is 0.5881, 
noisyNet noise sample is [array([2.3864045], dtype=float32), 0.32710302]. 
=============================================
[2019-03-23 00:52:24,626] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:52:24,633] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3225
[2019-03-23 00:52:24,638] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.7, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5927253813601991, 6.911200000000001, 6.9112, 121.9260426156618, 439350.7593225838, 439350.7593225833, 129291.7415755577], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1627200.0000, 
sim time next is 1627800.0000, 
raw observation next is [25.55, 49.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5895278884251131, 6.9112, 6.9112, 121.9260426156618, 436763.761748965, 436763.761748965, 128854.9242735935], 
processed observation next is [1.0, 0.8695652173913043, 0.5018518518518519, 0.4933333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4869098605313913, 0.0, 0.0, 0.8094621288201359, 0.1559870577674875, 0.1559870577674875, 0.24779793129537211], 
reward next is 0.7522, 
noisyNet noise sample is [array([2.3458614], dtype=float32), -1.1521645]. 
=============================================
[2019-03-23 00:52:26,607] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:52:26,620] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2357
[2019-03-23 00:52:26,624] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.55, 25.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6523622227017472, 6.911200000000001, 6.9112, 121.9260426156618, 484795.6218310964, 484795.621831096, 135856.1465475032], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1447800.0000, 
sim time next is 1448400.0000, 
raw observation next is [32.40000000000001, 25.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6418467530715259, 6.911199999999999, 6.9112, 121.9260426156618, 476910.4753062477, 476910.4753062482, 134762.8403380717], 
processed observation next is [0.0, 0.782608695652174, 0.755555555555556, 0.2566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5523084413394074, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17032516975223133, 0.1703251697522315, 0.25915930834244555], 
reward next is 0.7408, 
noisyNet noise sample is [array([1.6410323], dtype=float32), -0.07315717]. 
=============================================
[2019-03-23 00:52:28,724] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:52:28,737] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6531
[2019-03-23 00:52:28,743] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.25, 69.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6120125455047615, 6.9112, 6.9112, 121.9260426156618, 453988.197053726, 453988.197053726, 131327.4011754673], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1488600.0000, 
sim time next is 1489200.0000, 
raw observation next is [22.56666666666667, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.615146533777418, 6.9112, 6.9112, 121.9260426156618, 456639.400630095, 456639.400630095, 131851.7627709577], 
processed observation next is [0.0, 0.21739130434782608, 0.39135802469135816, 0.68, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5189331672217725, 0.0, 0.0, 0.8094621288201359, 0.16308550022503393, 0.16308550022503393, 0.2535610822518417], 
reward next is 0.7464, 
noisyNet noise sample is [array([0.8176421], dtype=float32), -3.2411637]. 
=============================================
[2019-03-23 00:52:30,228] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:52:30,236] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2926
[2019-03-23 00:52:30,241] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.96666666666667, 27.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6900113404551871, 6.9112, 6.9112, 121.9260426156618, 515594.0870352512, 515594.0870352512, 144169.6928298044], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1511400.0000, 
sim time next is 1512000.0000, 
raw observation next is [34.1, 27.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6838808550268088, 6.9112, 6.9112, 121.9260426156618, 511041.1909135991, 511041.1909135991, 143303.6000659147], 
processed observation next is [0.0, 0.5217391304347826, 0.8185185185185185, 0.27, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.604851068783511, 0.0, 0.0, 0.8094621288201359, 0.1825147110405711, 0.1825147110405711, 0.2755838462806052], 
reward next is 0.7244, 
noisyNet noise sample is [array([-0.5524674], dtype=float32), 1.2939947]. 
=============================================
[2019-03-23 00:52:30,258] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[85.10938]
 [84.96556]
 [84.81914]
 [84.67225]
 [84.48179]], R is [[85.11415863]
 [84.98576355]
 [84.85692596]
 [84.72762299]
 [84.59707642]].
[2019-03-23 00:52:30,611] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.5088689e-32 1.6672204e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:52:30,619] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2636
[2019-03-23 00:52:30,624] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 70.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7185560398714496, 6.911200000000001, 6.9112, 121.9260426156618, 536948.8313363072, 536948.8313363068, 146481.2321822412], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1547400.0000, 
sim time next is 1548000.0000, 
raw observation next is [23.6, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7100166384482116, 6.9112, 6.9112, 121.9260426156618, 530499.3643040359, 530499.3643040359, 145214.3225826177], 
processed observation next is [0.0, 0.9565217391304348, 0.4296296296296297, 0.7, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6375207980602645, 0.0, 0.0, 0.8094621288201359, 0.18946405868001281, 0.18946405868001281, 0.2792583126588802], 
reward next is 0.7207, 
noisyNet noise sample is [array([-0.72068137], dtype=float32), 0.23919323]. 
=============================================
[2019-03-23 00:52:30,647] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[77.53348]
 [77.67335]
 [77.83393]
 [77.99552]
 [78.17363]], R is [[77.34841919]
 [77.29324341]
 [77.23628235]
 [77.1778717 ]
 [77.11804199]].
[2019-03-23 00:52:31,461] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.000000e+00 8.727662e-35 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 00:52:31,473] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3757
[2019-03-23 00:52:31,479] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.7, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8790082446266918, 6.9112, 6.9112, 121.9260426156618, 644487.091841032, 644487.091841032, 172924.3218375299], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1531200.0000, 
sim time next is 1531800.0000, 
raw observation next is [31.2, 47.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8691981117524397, 6.911199999999999, 6.9112, 121.9260426156618, 638204.9573580298, 638204.9573580301, 171439.358644786], 
processed observation next is [0.0, 0.7391304347826086, 0.7111111111111111, 0.475, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8364976396905496, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22793034191358208, 0.2279303419135822, 0.32969107431689615], 
reward next is 0.6703, 
noisyNet noise sample is [array([-0.19094859], dtype=float32), 0.3326589]. 
=============================================
[2019-03-23 00:52:31,647] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.2493487e-29 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:52:31,656] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8300
[2019-03-23 00:52:31,661] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.7, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8085021231563295, 6.911199999999999, 6.9112, 121.9260426156618, 601367.0922144965, 601367.0922144969, 160944.3007887581], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1539600.0000, 
sim time next is 1540200.0000, 
raw observation next is [24.2, 76.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8018801787174478, 6.911200000000001, 6.9112, 121.9260426156618, 596880.7825688256, 596880.7825688252, 159851.0637980191], 
processed observation next is [0.0, 0.8260869565217391, 0.45185185185185184, 0.765, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7523502233968096, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21317170806029487, 0.2131717080602947, 0.30740589191926754], 
reward next is 0.6926, 
noisyNet noise sample is [array([0.9725144], dtype=float32), -0.15677842]. 
=============================================
[2019-03-23 00:52:37,561] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.7511300e-29 3.7793286e-33 2.0229487e-36 3.2022134e-28], sum to 1.0000
[2019-03-23 00:52:37,568] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7494
[2019-03-23 00:52:37,574] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.4, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5620092785303086, 6.911200000000001, 6.9112, 121.9260426156618, 412749.6168986285, 412749.616898628, 124362.61880305], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1636800.0000, 
sim time next is 1637400.0000, 
raw observation next is [23.25, 56.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5610503684866834, 6.911200000000001, 6.9112, 121.9260426156618, 411743.4396051399, 411743.4396051394, 124135.9686781757], 
processed observation next is [1.0, 0.9565217391304348, 0.4166666666666667, 0.565, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45131296060835424, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1470512284304071, 0.14705122843040694, 0.23872301668879944], 
reward next is 0.7613, 
noisyNet noise sample is [array([-0.40352145], dtype=float32), -0.6797049]. 
=============================================
[2019-03-23 00:52:38,186] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.7896796e-26 4.1958310e-19 1.1649395e-09 5.2219170e-11], sum to 1.0000
[2019-03-23 00:52:38,194] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9055
[2019-03-23 00:52:38,204] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 698175.4724615563 W.
[2019-03-23 00:52:38,214] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.33333333333334, 82.66666666666667, 1.0, 2.0, 0.2779277065190608, 1.0, 2.0, 0.2779277065190608, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 698175.4724615563, 698175.4724615568, 177605.3639778543], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1676400.0000, 
sim time next is 1677000.0000, 
raw observation next is [19.41666666666666, 82.33333333333334, 1.0, 2.0, 0.2742495653281278, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4660595636863902, 6.911199999999999, 6.9112, 121.9260426156618, 690867.2824568982, 690867.2824568987, 183789.6922973456], 
processed observation next is [1.0, 0.391304347826087, 0.27469135802469113, 0.8233333333333335, 1.0, 1.0, 0.13601138729539022, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.3325744546079877, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24673831516317796, 0.24673831516317812, 0.35344171595643387], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.03504523], dtype=float32), -0.08931232]. 
=============================================
[2019-03-23 00:52:38,224] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[50.629368]
 [51.066833]
 [52.936825]
 [54.218407]
 [59.41992 ]], R is [[50.48879242]
 [50.64235687]
 [50.13593292]
 [49.63457489]
 [49.78615952]].
[2019-03-23 00:52:43,020] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.00000000e+00 0.00000000e+00 4.84031987e-37 2.26747019e-37
 1.01403085e-26], sum to 1.0000
[2019-03-23 00:52:43,026] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5151
[2019-03-23 00:52:43,032] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.38333333333333, 80.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6338686310606348, 6.911199999999999, 6.9112, 121.9260426156618, 472385.686931045, 472385.6869310454, 135210.0964830338], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1728600.0000, 
sim time next is 1729200.0000, 
raw observation next is [21.36666666666667, 80.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6344186441512687, 6.9112, 6.9112, 121.9260426156618, 472808.4343856871, 472808.4343856871, 135278.2915844449], 
processed observation next is [1.0, 0.0, 0.3469135802469137, 0.8033333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5430233051890858, 0.0, 0.0, 0.8094621288201359, 0.1688601551377454, 0.1688601551377454, 0.26015056073931714], 
reward next is 0.7398, 
noisyNet noise sample is [array([1.2477288], dtype=float32), -1.3642772]. 
=============================================
[2019-03-23 00:52:46,240] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9723959e-01 1.7072306e-28 1.0259449e-21 2.7603563e-03 7.2021520e-19], sum to 1.0000
[2019-03-23 00:52:46,249] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3955
[2019-03-23 00:52:46,258] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1467569.871402685 W.
[2019-03-23 00:52:46,266] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.33333333333334, 63.33333333333334, 1.0, 2.0, 0.6350400392643715, 1.0, 2.0, 0.6350400392643715, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1467569.871402685, 1467569.871402685, 281260.0557789141], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1784400.0000, 
sim time next is 1785000.0000, 
raw observation next is [27.16666666666666, 64.66666666666666, 1.0, 2.0, 0.6526760535660925, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9816307892782299, 6.911199999999999, 6.9112, 121.9260426156618, 1472636.083450748, 1472636.083450749, 305830.503724887], 
processed observation next is [1.0, 0.6521739130434783, 0.5617283950617282, 0.6466666666666666, 1.0, 1.0, 0.5865191113882053, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9770384865977874, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5259414583752671, 0.5259414583752675, 0.5881355840863212], 
reward next is 0.4119, 
noisyNet noise sample is [array([-0.5627909], dtype=float32), -0.14308602]. 
=============================================
[2019-03-23 00:52:46,277] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[69.64567]
 [69.15698]
 [68.49284]
 [68.73601]
 [67.5494 ]], R is [[66.91957092]
 [66.70948792]
 [66.04239655]
 [65.78875732]
 [65.59574127]].
[2019-03-23 00:52:47,814] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 8.7445491e-22 9.1576836e-35], sum to 1.0000
[2019-03-23 00:52:47,821] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0401
[2019-03-23 00:52:47,829] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.3, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5485337557566811, 6.9112, 6.9112, 121.9260426156618, 402263.365647319, 402263.365647319, 122918.1044487839], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1819800.0000, 
sim time next is 1820400.0000, 
raw observation next is [18.26666666666667, 91.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5466412491347723, 6.911200000000001, 6.9112, 121.9260426156618, 400792.4425301914, 400792.442530191, 122717.8215840767], 
processed observation next is [1.0, 0.043478260869565216, 0.23209876543209887, 0.9166666666666665, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4333015614184653, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14314015804649693, 0.14314015804649677, 0.23599581073860904], 
reward next is 0.7640, 
noisyNet noise sample is [array([0.07841054], dtype=float32), -0.17174396]. 
=============================================
[2019-03-23 00:52:51,816] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 00:52:51,820] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:52:51,821] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:52:51,821] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:52:51,822] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:52:51,823] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:52:51,825] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:52:51,827] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:52:51,822] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:52:51,828] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:52:51,828] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:52:51,851] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run37
[2019-03-23 00:52:51,873] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run37
[2019-03-23 00:52:51,874] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run37
[2019-03-23 00:52:51,874] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run37
[2019-03-23 00:52:51,934] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run37
[2019-03-23 00:52:55,759] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21376109], dtype=float32), -0.10861168]
[2019-03-23 00:52:55,761] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.76361092, 62.95535143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5055357581187322, 6.911200000000001, 6.9112, 121.9260426156618, 369829.3943811791, 369829.3943811786, 118899.9205534266]
[2019-03-23 00:52:55,762] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:52:55,766] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.893166716012572
[2019-03-23 00:52:57,279] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21376109], dtype=float32), -0.10861168]
[2019-03-23 00:52:57,281] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.7, 26.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5875044784637992, 6.9112, 6.9112, 121.9260426156618, 431298.6781917604, 431298.6781917604, 126527.2284389125]
[2019-03-23 00:52:57,283] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:52:57,287] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.2798342e-38 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.24508076232300458
[2019-03-23 00:53:23,574] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21376109], dtype=float32), -0.10861168]
[2019-03-23 00:53:23,575] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.41666666666667, 82.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6330516606964933, 6.9112, 6.9112, 121.9260426156618, 472363.7497512125, 472363.7497512125, 135828.6216426758]
[2019-03-23 00:53:23,577] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:53:23,582] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.2748330324409113
[2019-03-23 00:54:09,550] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21376109], dtype=float32), -0.10861168]
[2019-03-23 00:54:09,551] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.04852228, 82.0914275, 1.0, 2.0, 0.752626067678968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426154993, 857814.3715861704, 857814.3715861704, 186344.3018621009]
[2019-03-23 00:54:09,553] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:54:09,557] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 1.6706144e-37 3.7056707e-22 1.8372380e-33], sampled 0.985400022924011
[2019-03-23 00:54:09,557] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 857814.3715861704 W.
[2019-03-23 00:54:35,488] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21376109], dtype=float32), -0.10861168]
[2019-03-23 00:54:35,490] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.95, 94.5, 1.0, 2.0, 0.7595991487531061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 940575.6110362775, 940575.6110362775, 190757.2646820705]
[2019-03-23 00:54:35,491] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:54:35,493] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.4930798e-37 1.8899611e-27 3.2049566e-17 1.5857727e-21], sampled 0.7088987705838219
[2019-03-23 00:54:35,495] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 940575.6110362775 W.
[2019-03-23 00:54:43,229] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8445.6212 2325621792.2087 548.0000
[2019-03-23 00:54:43,462] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7952.0920 2512648218.4596 726.0000
[2019-03-23 00:54:43,474] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8612.9595 2251532756.5995 510.0000
[2019-03-23 00:54:43,605] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8669.2135 2214258643.4391 518.0000
[2019-03-23 00:54:43,714] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8463.7134 2283975080.4011 638.0000
[2019-03-23 00:54:44,729] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 900000, evaluation results [900000.0, 7952.092014242833, 2512648218.4596486, 726.0, 8612.959523532627, 2251532756.599498, 510.0, 8669.213516267762, 2214258643.439097, 518.0, 8445.621217982027, 2325621792.2087355, 548.0, 8463.713422920437, 2283975080.401052, 638.0]
[2019-03-23 00:54:48,955] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1007358e-28 7.7697308e-38], sum to 1.0000
[2019-03-23 00:54:48,965] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0053
[2019-03-23 00:54:48,969] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.96666666666667, 89.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.644078238095228, 6.911199999999999, 6.9112, 121.9260426156618, 479720.6134049642, 479720.6134049647, 135955.1916308055], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1983000.0000, 
sim time next is 1983600.0000, 
raw observation next is [19.6, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6279351791922019, 6.911200000000001, 6.9112, 121.9260426156618, 466739.9671854268, 466739.9671854263, 133530.7739535875], 
processed observation next is [1.0, 1.0, 0.28148148148148155, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5349189739902523, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1666928454233667, 0.16669284542336654, 0.25678994991074516], 
reward next is 0.7432, 
noisyNet noise sample is [array([-0.4209552], dtype=float32), 0.548997]. 
=============================================
[2019-03-23 00:54:51,793] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9999857e-01 4.1985162e-26 9.9523724e-17 1.4707255e-06 4.5061801e-15], sum to 1.0000
[2019-03-23 00:54:51,805] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9336
[2019-03-23 00:54:51,814] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1234458.049476094 W.
[2019-03-23 00:54:51,818] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.31666666666667, 92.66666666666666, 1.0, 2.0, 0.5414091760016444, 1.0, 2.0, 0.5414091760016444, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1234458.049476094, 1234458.049476094, 248485.3508237945], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2199000.0000, 
sim time next is 2199600.0000, 
raw observation next is [24.3, 93.0, 1.0, 2.0, 0.6214832252472653, 1.0, 2.0, 0.6214832252472653, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1417202.461079473, 1417202.461079474, 275508.9039342371], 
processed observation next is [1.0, 0.4782608695652174, 0.4555555555555556, 0.93, 1.0, 1.0, 0.5493847919610301, 1.0, 1.0, 0.5493847919610301, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5061437360998118, 0.5061437360998121, 0.5298248152581483], 
reward next is 0.4702, 
noisyNet noise sample is [array([-0.3561387], dtype=float32), -0.37563366]. 
=============================================
[2019-03-23 00:54:52,244] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.6973721e-34 3.5105721e-38 8.3351109e-28 6.2364745e-35], sum to 1.0000
[2019-03-23 00:54:52,253] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2659
[2019-03-23 00:54:52,260] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 740561.9811512533 W.
[2019-03-23 00:54:52,265] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.03333333333333, 72.0, 1.0, 2.0, 0.3249006319028108, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5172523872641387, 6.911199999999999, 6.9112, 121.9260426156618, 740561.9811512533, 740561.9811512538, 202056.9405366525], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2148000.0000, 
sim time next is 2148600.0000, 
raw observation next is [27.86666666666666, 72.5, 1.0, 2.0, 0.3232194722887003, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5145759264069285, 6.911199999999999, 6.9112, 121.9260426156618, 736728.1899442888, 736728.1899442893, 201589.1229605158], 
processed observation next is [0.0, 0.8695652173913043, 0.587654320987654, 0.725, 1.0, 1.0, 0.19430889558178607, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3932199080086606, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26311721069438887, 0.26311721069438904, 0.3876713903086842], 
reward next is 0.6123, 
noisyNet noise sample is [array([-1.7442573], dtype=float32), -0.9672001]. 
=============================================
[2019-03-23 00:54:52,481] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:54:52,489] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9493
[2019-03-23 00:54:52,494] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.15, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6253198690438605, 6.911199999999999, 6.9112, 121.9260426156618, 465872.1061336468, 465872.1061336472, 134217.3145386188], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2014200.0000, 
sim time next is 2014800.0000, 
raw observation next is [21.26666666666667, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6237087199387505, 6.9112, 6.9112, 121.9260426156618, 464687.5560470919, 464687.5560470919, 134074.6687321322], 
processed observation next is [0.0, 0.30434782608695654, 0.34320987654320995, 0.8066666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5296358999234382, 0.0, 0.0, 0.8094621288201359, 0.16595984144538997, 0.16595984144538997, 0.25783590140794654], 
reward next is 0.7422, 
noisyNet noise sample is [array([1.4436709], dtype=float32), 0.98635745]. 
=============================================
[2019-03-23 00:54:53,054] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 4.497554e-35 0.000000e+00], sum to 1.0000
[2019-03-23 00:54:53,065] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5338
[2019-03-23 00:54:53,071] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.06666666666667, 83.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9107927981251023, 6.9112, 6.9112, 121.9260426156618, 664882.7597820151, 664882.7597820151, 177710.1723428056], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2161200.0000, 
sim time next is 2161800.0000, 
raw observation next is [25.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.912595444990592, 6.9112, 6.9112, 121.9260426156618, 665898.4107619887, 665898.4107619887, 178007.034714891], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.84, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.89074430623824, 0.0, 0.0, 0.8094621288201359, 0.23782086098642455, 0.23782086098642455, 0.3423212206055596], 
reward next is 0.6577, 
noisyNet noise sample is [array([-1.8566691], dtype=float32), 0.41649973]. 
=============================================
[2019-03-23 00:55:02,242] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.1008211e-33 4.1471360e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:55:02,249] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5573
[2019-03-23 00:55:02,254] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.2, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.929897893471868, 6.911199999999999, 6.9112, 121.9260426156618, 679689.7339543964, 679689.7339543969, 180130.1081395233], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2185200.0000, 
sim time next is 2185800.0000, 
raw observation next is [24.25, 88.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9775964442019491, 7.09061965653655, 6.9112, 121.925320728994, 806176.39316657, 714298.0366596899, 186770.2649929563], 
processed observation next is [1.0, 0.30434782608695654, 0.4537037037037037, 0.8883333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9719955552524364, 0.017941965653654978, 0.0, 0.8094573362433709, 0.28792014041663216, 0.25510644166417495, 0.359173586524916], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.32798696], dtype=float32), -0.34178206]. 
=============================================
[2019-03-23 00:55:23,888] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.5101380e-13 5.1618346e-31 5.4809820e-19 1.0000000e+00 6.3879169e-30], sum to 1.0000
[2019-03-23 00:55:23,896] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6251
[2019-03-23 00:55:23,904] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.23333333333333, 33.83333333333334, 1.0, 2.0, 0.7550886073979006, 1.0, 2.0, 0.7550886073979006, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1766218.63896597, 1766218.63896597, 327737.0375964897], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2566200.0000, 
sim time next is 2566800.0000, 
raw observation next is [33.2, 34.0, 1.0, 2.0, 0.7543686053969131, 1.0, 2.0, 0.7543686053969131, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1763856.034165013, 1763856.034165012, 327416.6613701419], 
processed observation next is [1.0, 0.7391304347826086, 0.7851851851851853, 0.34, 1.0, 1.0, 0.7075816730915632, 1.0, 1.0, 0.7075816730915632, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6299485836303619, 0.6299485836303614, 0.6296474257118113], 
reward next is 0.3704, 
noisyNet noise sample is [array([0.12140054], dtype=float32), 1.148251]. 
=============================================
[2019-03-23 00:55:30,170] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.2652384e-35 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:55:30,180] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9218
[2019-03-23 00:55:30,183] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.36666666666667, 86.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9124179448208928, 6.9112, 6.9112, 121.9260426156618, 668196.9893764633, 668196.9893764633, 177511.1644413668], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2666400.0000, 
sim time next is 2667000.0000, 
raw observation next is [24.18333333333333, 87.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9091111634134076, 6.911199999999999, 6.9112, 121.9260426156618, 666001.9788128743, 666001.9788128748, 177020.8953669446], 
processed observation next is [0.0, 0.8695652173913043, 0.45123456790123445, 0.8783333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8863889542667593, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23785784957602654, 0.2378578495760267, 0.3404247987825858], 
reward next is 0.6596, 
noisyNet noise sample is [array([-1.329665], dtype=float32), 0.30525452]. 
=============================================
[2019-03-23 00:55:30,200] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[71.53525 ]
 [71.078445]
 [70.92295 ]
 [70.910614]
 [70.51165 ]], R is [[71.95674133]
 [71.89580536]
 [71.83589935]
 [71.77707672]
 [71.71863556]].
[2019-03-23 00:55:34,339] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.7374302e-21 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:55:34,347] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8794
[2019-03-23 00:55:34,352] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.0, 44.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.914837810173937, 6.9112, 6.9112, 121.9260426156618, 665325.7281161534, 665325.7281161534, 178682.7106105325], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3254400.0000, 
sim time next is 3255000.0000, 
raw observation next is [32.41666666666666, 47.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9335834874657354, 6.9112, 6.9112, 121.9260426156618, 676364.577180131, 676364.577180131, 181617.3476970602], 
processed observation next is [0.0, 0.6956521739130435, 0.7561728395061725, 0.47166666666666673, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9169793593321692, 0.0, 0.0, 0.8094621288201359, 0.2415587775643325, 0.2415587775643325, 0.34926413018665425], 
reward next is 0.6507, 
noisyNet noise sample is [array([-0.55520195], dtype=float32), -0.3259721]. 
=============================================
[2019-03-23 00:55:34,369] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[55.290337]
 [55.29771 ]
 [55.30922 ]
 [55.316463]
 [55.321663]], R is [[55.38326263]
 [55.48580933]
 [55.59327316]
 [55.70529938]
 [55.82146835]].
[2019-03-23 00:55:39,317] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 00:55:39,319] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:55:39,320] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:55:39,321] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:55:39,320] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:55:39,322] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:55:39,323] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:55:39,324] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:55:39,326] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:55:39,322] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:55:39,328] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:55:39,348] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run38
[2019-03-23 00:55:39,349] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run38
[2019-03-23 00:55:39,386] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run38
[2019-03-23 00:55:39,406] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run38
[2019-03-23 00:55:39,407] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run38
[2019-03-23 00:56:13,556] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.28524062], dtype=float32), -0.069125794]
[2019-03-23 00:56:13,557] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.1775109, 76.19746185999999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7730504530598686, 6.911200000000001, 6.9112, 121.9260426156618, 575013.1472699471, 575013.1472699466, 156570.3606070781]
[2019-03-23 00:56:13,562] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:56:13,564] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.3074536e-08 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.14194693874474296
[2019-03-23 00:56:19,738] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.28524062], dtype=float32), -0.069125794]
[2019-03-23 00:56:19,738] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.5309759, 81.26169181, 1.0, 2.0, 0.8821833002652093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 1026720.430135713, 1026720.430135714, 214616.8711229449]
[2019-03-23 00:56:19,739] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:56:19,742] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9983513e-01 1.6486096e-04 1.0471416e-25 0.0000000e+00 8.6080230e-36], sampled 0.816753257979189
[2019-03-23 00:56:19,745] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1026720.430135713 W.
[2019-03-23 00:56:54,070] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.28524062], dtype=float32), -0.069125794]
[2019-03-23 00:56:54,071] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.16666666666666, 62.66666666666667, 1.0, 2.0, 0.611237522936178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 701003.1081666526, 701003.1081666526, 160238.9474004098]
[2019-03-23 00:56:54,072] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:56:54,074] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9318779e-01 6.8122274e-03 2.3041148e-33 0.0000000e+00 0.0000000e+00], sampled 0.5630513093891012
[2019-03-23 00:56:54,079] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 701003.1081666526 W.
[2019-03-23 00:57:01,504] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.28524062], dtype=float32), -0.069125794]
[2019-03-23 00:57:01,510] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.73333333333333, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7941923521515319, 6.9112, 6.9112, 121.9260426156618, 592744.4441281222, 592744.4441281222, 157542.8736397064]
[2019-03-23 00:57:01,510] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:57:01,513] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.1653035e-21 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.02862705134827015
[2019-03-23 00:57:04,912] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.28524062], dtype=float32), -0.069125794]
[2019-03-23 00:57:04,913] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.2, 87.33333333333334, 1.0, 1.0, 0.6204289545094096, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9258348548666, 740238.7394508221, 740238.7394508226, 163101.7516694643]
[2019-03-23 00:57:04,915] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:57:04,917] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 6.6501258e-12 7.4020432e-35 0.0000000e+00 0.0000000e+00], sampled 0.1167733654024733
[2019-03-23 00:57:04,920] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 740238.7394508221 W.
[2019-03-23 00:57:09,476] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.28524062], dtype=float32), -0.069125794]
[2019-03-23 00:57:09,478] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7653105297218542, 6.9112, 6.9112, 121.9260426156618, 570547.5745665233, 570547.5745665233, 154728.7318317106]
[2019-03-23 00:57:09,481] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:57:09,484] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.000000e+00 1.901188e-15 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7846934224727015
[2019-03-23 00:57:15,307] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.28524062], dtype=float32), -0.069125794]
[2019-03-23 00:57:15,311] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.78022753, 62.92730978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8492635902880699, 6.911199999999999, 6.9112, 121.9260426156618, 624912.5686961189, 624912.5686961194, 168541.9162386828]
[2019-03-23 00:57:15,313] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:57:15,315] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.5121322e-12 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.3875041057174361
[2019-03-23 00:57:31,227] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8655.4836 2214548469.9307 536.0000
[2019-03-23 00:57:31,294] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7848.7826 2527418474.7961 831.0000
[2019-03-23 00:57:31,300] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8565.1008 2256649305.4764 534.0000
[2019-03-23 00:57:31,415] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8414.2188 2288200715.0550 694.0000
[2019-03-23 00:57:31,457] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8370.7224 2336509815.1926 615.0000
[2019-03-23 00:57:32,474] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 925000, evaluation results [925000.0, 7848.782554932628, 2527418474.79613, 831.0, 8565.10084109378, 2256649305.476396, 534.0, 8655.483593353018, 2214548469.930661, 536.0, 8370.72235101856, 2336509815.1926217, 615.0, 8414.218826077888, 2288200715.0549774, 694.0]
[2019-03-23 00:57:32,629] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.606355e-36 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 00:57:32,639] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5407
[2019-03-23 00:57:32,642] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.34999999999999, 53.5, 1.0, 2.0, 0.6304006364285946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 718441.2179485972, 718441.2179485972, 163388.9648176426], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2827800.0000, 
sim time next is 2828400.0000, 
raw observation next is [32.2, 54.0, 1.0, 2.0, 0.6315777933158605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719783.4042259388, 719783.4042259388, 163597.5495490072], 
processed observation next is [1.0, 0.7391304347826086, 0.7481481481481482, 0.54, 1.0, 1.0, 0.5614021348998339, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2570655015092639, 0.2570655015092639, 0.31461067220962924], 
reward next is 0.6854, 
noisyNet noise sample is [array([0.03925737], dtype=float32), 2.1949487]. 
=============================================
[2019-03-23 00:57:34,766] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.000000e+00 3.685858e-32 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 00:57:34,776] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4508
[2019-03-23 00:57:34,784] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.4, 92.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9221225625811896, 6.911200000000001, 6.9112, 121.9260426156618, 682547.871348886, 682547.8713488856, 176809.222955609], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2878200.0000, 
sim time next is 2878800.0000, 
raw observation next is [22.53333333333333, 91.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.878627669419392, 6.911200000000001, 6.9112, 121.9260426156618, 652429.3592620777, 652429.3592620774, 170253.7520450126], 
processed observation next is [1.0, 0.30434782608695654, 0.3901234567901234, 0.9133333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.84828458677424, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23301048545074204, 0.2330104854507419, 0.32741106162502426], 
reward next is 0.6726, 
noisyNet noise sample is [array([0.5200941], dtype=float32), 0.44999233]. 
=============================================
[2019-03-23 00:57:34,971] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 8.1145433e-16 6.0303871e-28 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:57:34,982] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3128
[2019-03-23 00:57:34,989] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2481472.788726474 W.
[2019-03-23 00:57:34,997] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.6, 73.5, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 7.212107527477285, 6.9112, 121.9248398713901, 2481472.788726474, 2327382.759890665, 443048.7858432331], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2986200.0000, 
sim time next is 2986800.0000, 
raw observation next is [29.8, 71.66666666666666, 1.0, 2.0, 0.6939319667749728, 1.0, 2.0, 0.660330645363921, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2259781.21068252, 2259781.210682521, 427613.4700889285], 
processed observation next is [1.0, 0.5652173913043478, 0.6592592592592593, 0.7166666666666666, 1.0, 1.0, 0.6356332937797295, 1.0, 1.0, 0.5956317206713345, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.8070647181009001, 0.8070647181009004, 0.8223335963248625], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1726632], dtype=float32), -2.143844]. 
=============================================
[2019-03-23 00:57:35,406] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 00:57:35,413] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1324
[2019-03-23 00:57:35,424] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 688030.6495149547 W.
[2019-03-23 00:57:35,428] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.13333333333334, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9252281277870053, 6.911200000000001, 6.9112, 121.9260426156618, 688030.6495149547, 688030.6495149542, 175767.0847915488], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2877000.0000, 
sim time next is 2877600.0000, 
raw observation next is [22.26666666666667, 92.66666666666667, 1.0, 1.0, 0.2852396463141309, 1.0, 1.0, 0.2852396463141309, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 676104.622080691, 676104.6220806915, 178152.4675598311], 
processed observation next is [1.0, 0.30434782608695654, 0.38024691358024704, 0.9266666666666667, 1.0, 0.5, 0.14909481704063202, 1.0, 0.5, 0.14909481704063202, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24146593645738965, 0.2414659364573898, 0.3426008991535213], 
reward next is 0.6574, 
noisyNet noise sample is [array([0.00435952], dtype=float32), 0.2513265]. 
=============================================
[2019-03-23 00:57:38,399] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.1614871e-13 3.0510620e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:57:38,407] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9856
[2019-03-23 00:57:38,415] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 779876.0153621056 W.
[2019-03-23 00:57:38,420] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.342139783138324, 1.0, 1.0, 0.342139783138324, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 779876.0153621056, 779876.0153621056, 190881.0553972747], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2928000.0000, 
sim time next is 2928600.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.6852241463638109, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 780953.1052891882, 780953.1052891882, 173365.0859740796], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.89, 1.0, 1.0, 0.6252668409092986, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2789118233175672, 0.2789118233175672, 0.3333943961039992], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.25758523], dtype=float32), 1.2428114]. 
=============================================
[2019-03-23 00:57:51,624] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.5915825e-26 3.5503109e-25 3.8067247e-30 7.1058087e-34], sum to 1.0000
[2019-03-23 00:57:51,630] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7963
[2019-03-23 00:57:51,639] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1802306.546795579 W.
[2019-03-23 00:57:51,643] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.98333333333333, 37.0, 1.0, 2.0, 0.933554135063038, 0.0, 1.0, 0.0, 1.0, 2.0, 0.979401279295216, 6.911199999999999, 6.9112, 121.9260426156618, 1802306.546795579, 1802306.546795579, 361329.2497939679], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3153000.0000, 
sim time next is 3153600.0000, 
raw observation next is [33.0, 38.0, 1.0, 2.0, 0.7501578609369677, 1.0, 1.0, 0.7501578609369677, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1733379.554902347, 1733379.554902347, 324739.5129784261], 
processed observation next is [1.0, 0.5217391304347826, 0.7777777777777778, 0.38, 1.0, 1.0, 0.7025688820678186, 1.0, 0.5, 0.7025688820678186, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6190641267508382, 0.6190641267508382, 0.6244990634200502], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9067029], dtype=float32), 0.2720186]. 
=============================================
[2019-03-23 00:57:54,921] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.0775908e-34 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:57:54,931] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9736
[2019-03-23 00:57:54,935] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.75, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7993159795317779, 6.911200000000001, 6.9112, 121.9260426156618, 593939.5730822767, 593939.5730822763, 160126.2476406116], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3235800.0000, 
sim time next is 3236400.0000, 
raw observation next is [30.1, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7913834830199886, 6.911200000000001, 6.9112, 121.9260426156618, 588478.5271636195, 588478.5271636191, 158909.9330193475], 
processed observation next is [0.0, 0.4782608695652174, 0.6703703703703704, 0.46, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7392293537749858, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21017090255843554, 0.21017090255843537, 0.30559602503720673], 
reward next is 0.6944, 
noisyNet noise sample is [array([1.4153503], dtype=float32), 0.6558369]. 
=============================================
[2019-03-23 00:58:01,703] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.0022323e-24 2.5303792e-27 6.8345818e-26 4.5146436e-26], sum to 1.0000
[2019-03-23 00:58:01,710] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3763
[2019-03-23 00:58:01,716] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 750072.9934555707 W.
[2019-03-23 00:58:01,721] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.05, 78.5, 1.0, 2.0, 0.3290712791108117, 1.0, 2.0, 0.3290712791108117, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 750072.9934555707, 750072.9934555711, 187583.5101914344], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3331800.0000, 
sim time next is 3332400.0000, 
raw observation next is [27.06666666666667, 78.33333333333334, 1.0, 2.0, 0.2192287171688452, 1.0, 2.0, 0.2192287171688452, 1.0, 1.0, 0.3490192575136657, 6.9112, 6.9112, 121.94756008, 749552.5161164525, 749552.5161164525, 226978.8094314855], 
processed observation next is [0.0, 0.5652173913043478, 0.5580246913580248, 0.7833333333333334, 1.0, 1.0, 0.07051037758195858, 1.0, 1.0, 0.07051037758195858, 1.0, 0.5, 0.1862740718920821, 0.0, 0.0, 0.8096049824067558, 0.26769732718444733, 0.26769732718444733, 0.43649771044516444], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.11799876], dtype=float32), 0.08099742]. 
=============================================
[2019-03-23 00:58:02,727] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.7462365e-29 1.0216755e-27 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 00:58:02,734] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6769
[2019-03-23 00:58:02,742] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 792237.599589814 W.
[2019-03-23 00:58:02,749] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.86666666666667, 74.0, 1.0, 2.0, 0.3475601385154095, 0.0, 2.0, 0.0, 1.0, 2.0, 0.553327059760006, 6.911199999999998, 6.9112, 121.9260426156618, 792237.599589814, 792237.5995898149, 208472.5147974573], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3345600.0000, 
sim time next is 3346200.0000, 
raw observation next is [28.9, 74.0, 1.0, 2.0, 0.3497241071024862, 1.0, 1.0, 0.3497241071024862, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 797172.7707954254, 797172.7707954259, 192822.178221797], 
processed observation next is [0.0, 0.7391304347826086, 0.6259259259259259, 0.74, 1.0, 1.0, 0.2258620322648645, 1.0, 0.5, 0.2258620322648645, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2847045609983662, 0.2847045609983664, 0.3708118811957634], 
reward next is 0.6292, 
noisyNet noise sample is [array([1.3633868], dtype=float32), -0.8902427]. 
=============================================
[2019-03-23 00:58:10,896] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.9730050e-30 1.9118650e-22 1.3642626e-18 1.4343195e-16], sum to 1.0000
[2019-03-23 00:58:10,902] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5895
[2019-03-23 00:58:10,911] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 850086.1821643873 W.
[2019-03-23 00:58:10,918] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3729246475391463, 1.0, 2.0, 0.3729246475391463, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 850086.1821643873, 850086.1821643878, 198881.4221027391], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3480600.0000, 
sim time next is 3481200.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3579740541333388, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5699063525813032, 6.911199999999999, 6.9112, 121.9260426156618, 815987.9846973947, 815987.9846973951, 211486.136374021], 
processed observation next is [1.0, 0.30434782608695654, 0.48148148148148145, 0.94, 1.0, 1.0, 0.23568339777778433, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.46238294072662894, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2914242802490695, 0.2914242802490697, 0.40670410841157884], 
reward next is 0.5933, 
noisyNet noise sample is [array([-0.49524724], dtype=float32), 0.7880444]. 
=============================================
[2019-03-23 00:58:27,343] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 00:58:27,345] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 00:58:27,346] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:58:27,346] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 00:58:27,347] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 00:58:27,347] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:58:27,350] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 00:58:27,350] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:58:27,352] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:58:27,348] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 00:58:27,355] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 00:58:27,369] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run39
[2019-03-23 00:58:27,390] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run39
[2019-03-23 00:58:27,419] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run39
[2019-03-23 00:58:27,419] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run39
[2019-03-23 00:58:27,436] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run39
[2019-03-23 00:58:42,227] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.44717887], dtype=float32), -0.098697074]
[2019-03-23 00:58:42,229] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 36.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5772059529415863, 6.9112, 6.9112, 121.9260426156618, 412147.1064713951, 412147.1064713951, 116156.3160821566]
[2019-03-23 00:58:42,230] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:58:42,233] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.6959825e-37 0.0000000e+00 9.8719808e-28 1.2258992e-37], sampled 0.35958503731062974
[2019-03-23 00:58:59,225] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.44717887], dtype=float32), -0.098697074]
[2019-03-23 00:58:59,226] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.685910975, 102.203373715, 1.0, 2.0, 0.3942835715991412, 1.0, 2.0, 0.3942835715991412, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 898802.6537570405, 898802.653757041, 204627.7464778736]
[2019-03-23 00:58:59,228] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:58:59,232] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.0833787e-01 6.6460184e-31 4.7278523e-26 6.9166207e-01 1.9604817e-21], sampled 0.10962668285323285
[2019-03-23 00:58:59,232] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 898802.6537570405 W.
[2019-03-23 00:59:21,048] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.44717887], dtype=float32), -0.098697074]
[2019-03-23 00:59:21,049] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.83333333333334, 84.33333333333334, 1.0, 2.0, 0.6277413236092428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716717.5415059496, 716717.5415059496, 162980.2724042506]
[2019-03-23 00:59:21,050] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 00:59:21,056] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 9.3604032e-30 3.4051213e-23 2.7478155e-09 1.5302133e-23], sampled 0.15728801665206615
[2019-03-23 00:59:21,057] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 716717.5415059496 W.
[2019-03-23 00:59:24,968] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.44717887], dtype=float32), -0.098697074]
[2019-03-23 00:59:24,969] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.0, 89.0, 1.0, 2.0, 0.6840344934773469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 779596.562922302, 779596.562922302, 173143.0645488075]
[2019-03-23 00:59:24,970] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 00:59:24,971] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 5.3520250e-30 6.1107570e-23 6.6872343e-14 1.5379415e-26], sampled 0.07484595888624634
[2019-03-23 00:59:24,975] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 779596.562922302 W.
[2019-03-23 00:59:27,690] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.44717887], dtype=float32), -0.098697074]
[2019-03-23 00:59:27,691] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.28333333333333, 77.16666666666667, 1.0, 2.0, 0.3756456377253475, 1.0, 2.0, 0.3756456377253475, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 856292.1766490014, 856292.1766490014, 199606.0544535259]
[2019-03-23 00:59:27,692] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:59:27,693] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7383417e-02 7.9310902e-35 1.5166371e-24 9.8261660e-01 7.4407311e-23], sampled 0.28687573199831296
[2019-03-23 00:59:32,594] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.44717887], dtype=float32), -0.098697074]
[2019-03-23 00:59:32,597] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.81095732, 105.1921288833333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8505864755642957, 6.911199999999999, 6.9112, 121.9260426156618, 630385.1692610114, 630385.1692610119, 167255.3109387649]
[2019-03-23 00:59:32,598] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:59:32,600] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 5.8608748e-38 1.3175994e-35 1.4386954e-12 7.7547201e-30], sampled 0.4636868372761378
[2019-03-23 00:59:33,096] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.44717887], dtype=float32), -0.098697074]
[2019-03-23 00:59:33,098] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 84.0, 1.0, 2.0, 0.9806654815574845, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.025541474334178, 6.9112, 121.9255837518603, 1176510.10696643, 1117957.272744409, 236093.2936736725]
[2019-03-23 00:59:33,100] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 00:59:33,102] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.2032627e-06 4.8088433e-27 1.0065812e-21 9.9999380e-01 2.7761488e-18], sampled 0.6688478969794772
[2019-03-23 00:59:40,370] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.44717887], dtype=float32), -0.098697074]
[2019-03-23 00:59:40,374] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.52001606333333, 75.33921625666666, 1.0, 2.0, 0.8074872777536278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 920380.6243284299, 920380.6243284299, 197502.2035662763]
[2019-03-23 00:59:40,375] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:59:40,377] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.4112897e-01 1.7147358e-29 3.9639367e-21 5.8871068e-02 1.0788705e-21], sampled 0.8559246314143436
[2019-03-23 00:59:40,378] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 920380.6243284299 W.
[2019-03-23 00:59:51,383] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.44717887], dtype=float32), -0.098697074]
[2019-03-23 00:59:51,384] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.84616168333333, 64.003287135, 1.0, 2.0, 0.5716318314129935, 1.0, 2.0, 0.5716318314129935, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1303426.851036152, 1303426.851036152, 258424.0000517141]
[2019-03-23 00:59:51,386] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 00:59:51,387] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.6172745e-15 2.1163292e-38 3.1896530e-30 1.0000000e+00 1.3362740e-25], sampled 0.0608955017385463
[2019-03-23 00:59:54,305] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.44717887], dtype=float32), -0.098697074]
[2019-03-23 00:59:54,306] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.73070846, 83.72927554333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8936428160512115, 6.9112, 6.9112, 121.9260426156618, 654380.7137641408, 654380.7137641408, 175026.2252752298]
[2019-03-23 00:59:54,306] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 00:59:54,309] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 1.6863985e-36 2.4609126e-14 6.0110333e-33], sampled 0.9058201869485556
[2019-03-23 01:00:04,140] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.44717887], dtype=float32), -0.098697074]
[2019-03-23 01:00:04,141] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.8, 94.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8368511307556336, 6.911199999999999, 6.9112, 121.9260426156618, 617280.8016009254, 617280.8016009259, 166550.4433071842]
[2019-03-23 01:00:04,142] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:00:04,146] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 5.7737837e-35 2.6810905e-33 1.5219727e-12 5.5652918e-29], sampled 0.06183600143250223
[2019-03-23 01:00:18,047] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8694.3065 2257500552.4680 230.0000
[2019-03-23 01:00:18,620] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8189.8170 2508968374.8110 290.0000
[2019-03-23 01:00:18,664] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8598.9015 2321683062.7230 235.0000
[2019-03-23 01:00:18,681] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8642.9583 2285238461.1033 280.0000
[2019-03-23 01:00:18,682] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8771.3501 2223223952.6403 246.0000
[2019-03-23 01:00:19,699] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 950000, evaluation results [950000.0, 8189.817049340737, 2508968374.810964, 290.0, 8694.306484529377, 2257500552.468042, 230.0, 8771.350094486543, 2223223952.6403227, 246.0, 8598.901501646842, 2321683062.7229714, 235.0, 8642.958284471988, 2285238461.1032767, 280.0]
[2019-03-23 01:00:31,848] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.000000e+00 7.530268e-26 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 01:00:31,858] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6636
[2019-03-23 01:00:31,868] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 761374.5993375876 W.
[2019-03-23 01:00:31,874] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.05, 83.83333333333333, 1.0, 2.0, 0.3340270471840756, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5317819376185074, 6.911199999999999, 6.9112, 121.9260426156618, 761374.5993375876, 761374.599337588, 204614.5540240438], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3973800.0000, 
sim time next is 3974400.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.3321814406742929, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5288436719477256, 6.911199999999999, 6.9112, 121.9260426156618, 757165.6828627606, 757165.6828627611, 204094.4330651498], 
processed observation next is [1.0, 0.0, 0.5185185185185185, 0.84, 1.0, 1.0, 0.2049779055646344, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.411054589934657, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2704163153081288, 0.270416315308129, 0.3924892943560573], 
reward next is 0.6075, 
noisyNet noise sample is [array([-0.7143744], dtype=float32), 0.6037208]. 
=============================================
[2019-03-23 01:00:32,581] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.3086618e-37 1.2705929e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 01:00:32,590] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9196
[2019-03-23 01:00:32,601] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1134462.817625505 W.
[2019-03-23 01:00:32,608] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 92.33333333333334, 1.0, 2.0, 0.4975856692628217, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7921725907003137, 6.9112, 6.9112, 121.9260426156618, 1134462.817625505, 1134462.817625505, 256127.0296650022], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3993600.0000, 
sim time next is 3994200.0000, 
raw observation next is [24.65, 92.5, 1.0, 2.0, 0.9790716178640381, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.015720524447785, 6.9112, 121.9255371114944, 1169658.912297471, 1116135.283751091, 235708.7284401711], 
processed observation next is [1.0, 0.21739130434782608, 0.46851851851851845, 0.925, 1.0, 1.0, 0.9750852593619501, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.010452052444778471, 0.0, 0.8094587727981517, 0.41773532582052536, 0.3986197441968182, 0.45328601623109827], 
reward next is 0.0241, 
noisyNet noise sample is [array([-0.27074426], dtype=float32), 0.91136384]. 
=============================================
[2019-03-23 01:00:36,489] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.000000e+00 6.387033e-32 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 01:00:36,495] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5031
[2019-03-23 01:00:36,499] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.75, 90.0, 1.0, 2.0, 0.1935099140924639, 1.0, 1.0, 0.1935099140924639, 1.0, 2.0, 0.3082671219117806, 6.9112, 6.9112, 121.94756008, 667198.5384654709, 667198.5384654709, 218493.0612337754], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4057800.0000, 
sim time next is 4058400.0000, 
raw observation next is [23.0, 92.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8802855767727188, 6.911199999999999, 6.9112, 121.9260426156618, 645752.8521085132, 645752.8521085137, 173017.8602507865], 
processed observation next is [1.0, 1.0, 0.4074074074074074, 0.92, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8503569709658984, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2306260186101833, 0.23062601861018348, 0.33272665432843557], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7307905], dtype=float32), -1.490471]. 
=============================================
[2019-03-23 01:00:44,499] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.7395097e-30 2.5928779e-26 1.2696493e-19 1.4943369e-25], sum to 1.0000
[2019-03-23 01:00:44,507] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0921
[2019-03-23 01:00:44,517] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1299189.893143793 W.
[2019-03-23 01:00:44,524] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.66666666666667, 39.33333333333334, 1.0, 2.0, 0.5564797343675695, 0.0, 2.0, 0.0, 1.0, 2.0, 0.888796620163673, 6.911199999999999, 6.9112, 121.9260426156618, 1299189.893143793, 1299189.893143794, 276751.5589294935], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4192800.0000, 
sim time next is 4193400.0000, 
raw observation next is [32.83333333333333, 37.66666666666666, 1.0, 2.0, 0.5561580673110381, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8893040321793746, 6.9112, 6.9112, 121.9260426156618, 1304170.82805423, 1304170.82805423, 276481.3953158288], 
processed observation next is [1.0, 0.5217391304347826, 0.7716049382716048, 0.3766666666666666, 1.0, 1.0, 0.4716167467988549, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8616300402242183, 0.0, 0.0, 0.8094621288201359, 0.46577529573365356, 0.46577529573365356, 0.5316949909919785], 
reward next is 0.4683, 
noisyNet noise sample is [array([-0.2726061], dtype=float32), 0.2710477]. 
=============================================
[2019-03-23 01:00:53,074] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 5.9910057e-32 2.0571046e-35 5.3001348e-30 2.2265667e-30], sum to 1.0000
[2019-03-23 01:00:53,081] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8889
[2019-03-23 01:00:53,084] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.2, 91.33333333333334, 1.0, 2.0, 0.1854177968936577, 1.0, 2.0, 0.1854177968936577, 1.0, 2.0, 0.2970528141044871, 6.911200000000001, 6.9112, 121.94756008, 655899.1073208423, 655899.1073208419, 215662.024260192], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4336800.0000, 
sim time next is 4337400.0000, 
raw observation next is [22.0, 90.66666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8509574500111752, 6.9112, 6.9112, 121.9260426156618, 632537.2711815442, 632537.2711815442, 166422.8254766473], 
processed observation next is [1.0, 0.17391304347826086, 0.37037037037037035, 0.9066666666666666, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.813696812513969, 0.0, 0.0, 0.8094621288201359, 0.2259061682791229, 0.2259061682791229, 0.32004389514739867], 
reward next is 0.6800, 
noisyNet noise sample is [array([-0.76991713], dtype=float32), -0.6200455]. 
=============================================
[2019-03-23 01:01:03,548] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:01:03,553] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1669
[2019-03-23 01:01:03,557] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.26666666666667, 94.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9085396123378756, 6.911200000000001, 6.9112, 121.9260426156618, 665548.6027897947, 665548.6027897942, 176951.9104823075], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4520400.0000, 
sim time next is 4521000.0000, 
raw observation next is [23.33333333333333, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9002739061657757, 6.911199999999999, 6.9112, 121.9260426156618, 660463.8643817212, 660463.8643817217, 175638.6366253741], 
processed observation next is [0.0, 0.30434782608695654, 0.4197530864197529, 0.9333333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8753423827072195, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23587995156490044, 0.2358799515649006, 0.3377666088949502], 
reward next is 0.6622, 
noisyNet noise sample is [array([1.6123997], dtype=float32), -1.2785653]. 
=============================================
[2019-03-23 01:01:03,577] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[60.909435]
 [60.63761 ]
 [60.367554]
 [60.09333 ]
 [59.476364]], R is [[61.0657692 ]
 [61.11481857]
 [61.16120529]
 [61.20501328]
 [61.24617767]].
[2019-03-23 01:01:04,089] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:01:04,100] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4770
[2019-03-23 01:01:04,107] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.53333333333333, 91.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8921738634253058, 6.911200000000001, 6.9112, 121.9260426156618, 655157.0146453024, 655157.014645302, 174421.0268472541], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4522200.0000, 
sim time next is 4522800.0000, 
raw observation next is [23.66666666666667, 91.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8972770602187237, 6.9112, 6.9112, 121.9260426156618, 657924.6977061607, 657924.6977061607, 175318.0551362948], 
processed observation next is [0.0, 0.34782608695652173, 0.43209876543209896, 0.9166666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8715963252734046, 0.0, 0.0, 0.8094621288201359, 0.23497310632362883, 0.23497310632362883, 0.33715010603133616], 
reward next is 0.6628, 
noisyNet noise sample is [array([0.647494], dtype=float32), -0.26572323]. 
=============================================
[2019-03-23 01:01:14,411] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 01:01:14,412] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:01:14,413] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:01:14,414] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:01:14,414] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:01:14,416] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:01:14,415] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:01:14,417] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:01:14,417] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:01:14,419] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:01:14,421] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:01:14,440] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run40
[2019-03-23 01:01:14,440] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run40
[2019-03-23 01:01:14,440] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run40
[2019-03-23 01:01:14,506] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run40
[2019-03-23 01:01:14,528] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run40
[2019-03-23 01:01:30,323] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.19057181], dtype=float32), -0.10105503]
[2019-03-23 01:01:30,324] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.89179363333334, 65.34356267166666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5974680430513574, 6.911200000000001, 6.9112, 121.9260426156618, 443692.3812683266, 443692.3812683261, 130302.9504652117]
[2019-03-23 01:01:30,326] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:01:30,332] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8262627458721103
[2019-03-23 01:01:43,428] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.19057181], dtype=float32), -0.10105503]
[2019-03-23 01:01:43,429] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.90001271333333, 64.54626389666666, 1.0, 2.0, 0.8720305643170936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156337, 1034083.59888491, 1034083.59888491, 213265.3483475684]
[2019-03-23 01:01:43,430] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:01:43,432] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.4786272e-33 2.6194473e-22 2.1653433e-08 2.0629592e-20], sampled 0.5834442339937876
[2019-03-23 01:01:43,433] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1034083.59888491 W.
[2019-03-23 01:01:50,279] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.19057181], dtype=float32), -0.10105503]
[2019-03-23 01:01:50,280] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.95866083, 33.48882425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.609073078728449, 6.911200000000001, 6.9112, 121.9260426156618, 453230.2624368996, 453230.2624368991, 132129.6661171591]
[2019-03-23 01:01:50,280] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:01:50,282] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.687122166492725
[2019-03-23 01:02:39,092] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.19057181], dtype=float32), -0.10105503]
[2019-03-23 01:02:39,093] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.95287723166667, 60.672818565, 1.0, 2.0, 0.6333608029394969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 721816.3841486626, 721816.3841486626, 163910.7212090848]
[2019-03-23 01:02:39,095] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:02:39,097] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.0728792e-31 7.3571607e-30 3.9687352e-32 1.9121771e-31], sampled 0.7815587548475735
[2019-03-23 01:02:39,100] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 721816.3841486626 W.
[2019-03-23 01:02:55,487] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.19057181], dtype=float32), -0.10105503]
[2019-03-23 01:02:55,488] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.86666666666667, 29.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.674029155282302, 6.911200000000001, 6.9112, 121.9260426156618, 499915.0124453721, 499915.0124453717, 137329.4951935249]
[2019-03-23 01:02:55,489] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:02:55,491] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.12034850582745893
[2019-03-23 01:03:03,970] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8685.5785 2211407115.0073 494.0000
[2019-03-23 01:03:04,049] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8494.9625 2316871892.4108 479.0000
[2019-03-23 01:03:04,355] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8650.5670 2246514934.9140 459.0000
[2019-03-23 01:03:04,377] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8024.7295 2504410463.7799 627.0000
[2019-03-23 01:03:04,401] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8496.4792 2278546374.1126 594.0000
[2019-03-23 01:03:05,416] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 975000, evaluation results [975000.0, 8024.729453615338, 2504410463.7798576, 627.0, 8650.567003615066, 2246514934.9139943, 459.0, 8685.578464602338, 2211407115.0072703, 494.0, 8494.962544589705, 2316871892.410844, 479.0, 8496.47922346278, 2278546374.112553, 594.0]
[2019-03-23 01:03:12,044] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.9433626e-28 2.1554708e-15 3.0208637e-27], sum to 1.0000
[2019-03-23 01:03:12,050] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8927
[2019-03-23 01:03:12,058] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 889795.7696772176 W.
[2019-03-23 01:03:12,063] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.46666666666667, 88.0, 1.0, 2.0, 0.3903347558704718, 1.0, 2.0, 0.3903347558704718, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 889795.7696772176, 889795.7696772179, 203553.0917688936], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4922400.0000, 
sim time next is 4923000.0000, 
raw observation next is [27.35, 87.0, 1.0, 2.0, 0.382005271222254, 1.0, 2.0, 0.382005271222254, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 870797.3313841652, 870797.3313841657, 201305.4302645328], 
processed observation next is [1.0, 1.0, 0.5685185185185185, 0.87, 1.0, 1.0, 0.26429198955030236, 1.0, 1.0, 0.26429198955030236, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31099904692291613, 0.3109990469229163, 0.38712582743179386], 
reward next is 0.6129, 
noisyNet noise sample is [array([-0.78321123], dtype=float32), -1.5648507]. 
=============================================
[2019-03-23 01:03:12,079] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[36.29077 ]
 [36.732365]
 [36.933094]
 [36.722862]
 [37.323444]], R is [[36.24917221]
 [36.49523163]
 [36.73495102]
 [36.98790741]
 [37.23838425]].
[2019-03-23 01:03:14,896] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.9532381e-35 5.4545637e-31 3.5612564e-33 2.8421440e-24], sum to 1.0000
[2019-03-23 01:03:14,905] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5461
[2019-03-23 01:03:14,916] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 942918.879396657 W.
[2019-03-23 01:03:14,922] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.83333333333333, 93.16666666666667, 1.0, 2.0, 0.4136244231573465, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6585035524735119, 6.911200000000001, 6.9112, 121.9260426156618, 942918.879396657, 942918.8793966565, 228344.2980393003], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4867800.0000, 
sim time next is 4868400.0000, 
raw observation next is [25.86666666666667, 93.33333333333334, 1.0, 2.0, 0.3731223596780394, 1.0, 1.0, 0.3731223596780394, 1.0, 2.0, 0.5940229483543358, 6.9112, 6.9112, 121.94756008, 1276159.641650771, 1276159.641650771, 285508.5104970537], 
processed observation next is [1.0, 0.34782608695652173, 0.5135802469135804, 0.9333333333333335, 1.0, 1.0, 0.2537170948548088, 1.0, 0.5, 0.2537170948548088, 1.0, 1.0, 0.49252868544291967, 0.0, 0.0, 0.8096049824067558, 0.45577130058956106, 0.45577130058956106, 0.5490548278789493], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.11622862], dtype=float32), 0.045047414]. 
=============================================
[2019-03-23 01:03:17,755] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 5.9106617e-27 0.0000000e+00 0.0000000e+00 2.1147244e-37], sum to 1.0000
[2019-03-23 01:03:17,763] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8414
[2019-03-23 01:03:17,771] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 694801.2615501422 W.
[2019-03-23 01:03:17,774] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.16666666666666, 85.66666666666667, 1.0, 2.0, 0.5930281742366763, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694801.2615501422, 694801.2615501422, 157765.2366974612], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4940400.0000, 
sim time next is 4941000.0000, 
raw observation next is [24.25, 84.0, 1.0, 2.0, 0.2909860064382044, 1.0, 1.0, 0.2909860064382044, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 678662.7470945648, 678662.7470945648, 179052.676954922], 
processed observation next is [1.0, 0.17391304347826086, 0.4537037037037037, 0.84, 1.0, 1.0, 0.1559357219502433, 1.0, 0.5, 0.1559357219502433, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24237955253377316, 0.24237955253377316, 0.3443320710671577], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1347535], dtype=float32), -1.1439755]. 
=============================================
[2019-03-23 01:03:17,789] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[33.12695 ]
 [32.803642]
 [32.418983]
 [32.01496 ]
 [32.476418]], R is [[32.62726974]
 [32.99760437]
 [33.30635834]
 [33.6058197 ]
 [33.26976013]].
[2019-03-23 01:03:25,696] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.8967710e-28 1.0464605e-31 0.0000000e+00 1.2824380e-32], sum to 1.0000
[2019-03-23 01:03:25,702] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1817
[2019-03-23 01:03:25,714] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 933757.7426857741 W.
[2019-03-23 01:03:25,720] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 79.0, 1.0, 2.0, 0.2730721696614846, 1.0, 2.0, 0.2730721696614846, 1.0, 1.0, 0.434739787440773, 6.9112, 6.9112, 121.94756008, 933757.7426857741, 933757.7426857741, 245955.239468101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5054400.0000, 
sim time next is 5055000.0000, 
raw observation next is [30.0, 78.33333333333334, 1.0, 2.0, 0.7992137977933682, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 910944.839352963, 910944.8393529635, 195787.9717913476], 
processed observation next is [0.0, 0.5217391304347826, 0.6666666666666666, 0.7833333333333334, 1.0, 1.0, 0.7609688068968669, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32533744262605824, 0.3253374426260584, 0.3765153303679762], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.009462], dtype=float32), 1.888615]. 
=============================================
[2019-03-23 01:03:25,733] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[39.096855]
 [39.026913]
 [39.21986 ]
 [39.21602 ]
 [38.920547]], R is [[38.45801544]
 [38.07343674]
 [38.29750061]
 [37.91452408]
 [37.5353775 ]].
[2019-03-23 01:03:28,236] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.0185582e-20 2.7643887e-29 0.0000000e+00 8.0670731e-24], sum to 1.0000
[2019-03-23 01:03:28,248] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5407
[2019-03-23 01:03:28,254] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 864086.638173435 W.
[2019-03-23 01:03:28,263] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.65, 93.0, 1.0, 2.0, 0.7581261057606093, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 864086.638173435, 864086.6381734345, 187444.3854290889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5092200.0000, 
sim time next is 5092800.0000, 
raw observation next is [26.53333333333333, 92.66666666666666, 1.0, 2.0, 0.758087054202816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 864042.1034315537, 864042.1034315537, 187435.6914136538], 
processed observation next is [0.0, 0.9565217391304348, 0.5382716049382715, 0.9266666666666665, 1.0, 1.0, 0.7120083978604952, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30858646551126917, 0.30858646551126917, 0.36045325271856504], 
reward next is 0.6395, 
noisyNet noise sample is [array([1.8188325], dtype=float32), -1.0809652]. 
=============================================
[2019-03-23 01:03:44,790] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.1399327e-24 6.9186042e-33 0.0000000e+00 4.7063590e-25], sum to 1.0000
[2019-03-23 01:03:44,798] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4722
[2019-03-23 01:03:44,806] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 688110.7512944147 W.
[2019-03-23 01:03:44,814] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.2, 91.0, 1.0, 2.0, 0.3006261880387391, 1.0, 2.0, 0.3006261880387391, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688110.7512944147, 688110.7512944147, 180756.0972773635], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5376000.0000, 
sim time next is 5376600.0000, 
raw observation next is [24.25, 91.0, 1.0, 2.0, 0.2007275185954248, 1.0, 2.0, 0.2007275185954248, 1.0, 1.0, 0.3195647468428086, 6.9112, 6.9112, 121.94756008, 686267.8034443966, 686267.8034443966, 220832.4515599638], 
processed observation next is [1.0, 0.21739130434782608, 0.4537037037037037, 0.91, 1.0, 1.0, 0.04848514118502951, 1.0, 1.0, 0.04848514118502951, 1.0, 0.5, 0.14945593355351075, 0.0, 0.0, 0.8096049824067558, 0.2450956440872845, 0.2450956440872845, 0.4246777914614689], 
reward next is 0.5753, 
noisyNet noise sample is [array([-0.11013021], dtype=float32), -1.5303448]. 
=============================================
[2019-03-23 01:03:45,489] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 6.017477e-34], sum to 1.0000
[2019-03-23 01:03:45,498] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8273
[2019-03-23 01:03:45,507] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 866042.909086407 W.
[2019-03-23 01:03:45,510] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.85, 70.5, 1.0, 1.0, 0.3519340394765617, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5793281146088839, 6.911199999999999, 6.9112, 121.9259905344015, 866042.909086407, 866042.9090864075, 206793.8030629888], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5905800.0000, 
sim time next is 5906400.0000, 
raw observation next is [23.1, 69.66666666666666, 1.0, 2.0, 0.3391560526113312, 1.0, 1.0, 0.3391560526113312, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260425997809, 831305.1546546012, 831305.1546546008, 192436.2595828536], 
processed observation next is [1.0, 0.34782608695652173, 0.41111111111111115, 0.6966666666666665, 1.0, 1.0, 0.21328101501348953, 1.0, 0.5, 0.21328101501348953, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621287147032, 0.296894698090929, 0.29689469809092883, 0.3700697299670262], 
reward next is 0.6299, 
noisyNet noise sample is [array([-0.8161226], dtype=float32), -2.080413]. 
=============================================
[2019-03-23 01:03:46,381] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.9446283e-35 1.4899278e-37 0.0000000e+00 3.2651581e-29], sum to 1.0000
[2019-03-23 01:03:46,389] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0477
[2019-03-23 01:03:46,395] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 762429.7198128704 W.
[2019-03-23 01:03:46,400] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.48333333333333, 84.66666666666667, 1.0, 2.0, 0.22299316294571, 1.0, 2.0, 0.22299316294571, 1.0, 2.0, 0.3550123777898743, 6.911199999999999, 6.9112, 121.94756008, 762429.7198128704, 762429.7198128708, 228252.8599511227], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5559000.0000, 
sim time next is 5559600.0000, 
raw observation next is [25.56666666666667, 84.33333333333334, 1.0, 2.0, 0.3005495414177581, 1.0, 2.0, 0.3005495414177581, 1.0, 2.0, 0.478484658152284, 6.9112, 6.9112, 121.94756008, 1027778.351466024, 1027778.351466024, 256262.9008590478], 
processed observation next is [1.0, 0.34782608695652173, 0.5024691358024692, 0.8433333333333334, 1.0, 1.0, 0.16732088264018818, 1.0, 1.0, 0.16732088264018818, 1.0, 1.0, 0.348105822690355, 0.0, 0.0, 0.8096049824067558, 0.3670636969521514, 0.3670636969521514, 0.49281327088278426], 
reward next is 0.5072, 
noisyNet noise sample is [array([-1.3102973], dtype=float32), 0.5922247]. 
=============================================
[2019-03-23 01:03:47,054] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 4.8726885e-28 2.2176499e-37 0.0000000e+00 6.3365055e-25], sum to 1.0000
[2019-03-23 01:03:47,060] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9902
[2019-03-23 01:03:47,070] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 880514.2891935039 W.
[2019-03-23 01:03:47,077] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.65, 87.5, 1.0, 2.0, 0.257510361084758, 1.0, 1.0, 0.257510361084758, 1.0, 1.0, 0.4099648813739013, 6.911200000000001, 6.9112, 121.94756008, 880514.2891935039, 880514.2891935034, 240304.3022411272], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5437800.0000, 
sim time next is 5438400.0000, 
raw observation next is [27.56666666666667, 88.0, 1.0, 2.0, 0.2576396600394358, 1.0, 2.0, 0.2576396600394358, 1.0, 2.0, 0.4101707295207215, 6.9112, 6.9112, 121.94756008, 880956.659740595, 880956.659740595, 240350.6974456133], 
processed observation next is [1.0, 0.9565217391304348, 0.5765432098765433, 0.88, 1.0, 1.0, 0.11623769052313783, 1.0, 1.0, 0.11623769052313783, 1.0, 1.0, 0.2627134119009018, 0.0, 0.0, 0.8096049824067558, 0.3146273784787839, 0.3146273784787839, 0.4622128797031025], 
reward next is 0.5378, 
noisyNet noise sample is [array([-0.6727551], dtype=float32), -0.5161556]. 
=============================================
[2019-03-23 01:03:52,502] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.00000000e+00 5.28745969e-35 0.00000000e+00 0.00000000e+00
 1.03939025e-32], sum to 1.0000
[2019-03-23 01:03:52,511] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8838
[2019-03-23 01:03:52,515] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.58333333333333, 68.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8509231618119151, 6.9112, 6.9112, 121.9260426156618, 627501.3068747489, 627501.3068747489, 168375.7374586675], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6034200.0000, 
sim time next is 6034800.0000, 
raw observation next is [26.46666666666667, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8502326670584043, 6.9112, 6.9112, 121.9260426156618, 627201.4769939929, 627201.4769939929, 168226.1128006725], 
processed observation next is [1.0, 0.8695652173913043, 0.5358024691358025, 0.69, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8127908338230052, 0.0, 0.0, 0.8094621288201359, 0.22400052749785462, 0.22400052749785462, 0.32351175538590865], 
reward next is 0.6765, 
noisyNet noise sample is [array([-1.3982396], dtype=float32), -2.163304]. 
=============================================
[2019-03-23 01:03:57,998] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 4.6414194e-35 0.0000000e+00 0.0000000e+00 9.4874486e-22], sum to 1.0000
[2019-03-23 01:03:58,005] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4141
[2019-03-23 01:03:58,011] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.51666666666667, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9383916822482372, 6.911199999999999, 6.9112, 121.9260426156618, 681378.8775573076, 681378.8775573081, 182058.1125249989], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5622600.0000, 
sim time next is 5623200.0000, 
raw observation next is [23.5, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9357678288660825, 6.911200000000001, 6.9112, 121.9260426156618, 679982.2836435045, 679982.283643504, 181620.2541519322], 
processed observation next is [0.0, 0.08695652173913043, 0.42592592592592593, 0.97, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9197097860826031, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2428508155869659, 0.24285081558696572, 0.34926971952294655], 
reward next is 0.6507, 
noisyNet noise sample is [array([1.1763445], dtype=float32), 0.1736536]. 
=============================================
[2019-03-23 01:04:00,358] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 01:04:00,360] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:04:00,361] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:04:00,361] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:04:00,363] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:04:00,364] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:04:00,365] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:04:00,366] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:04:00,364] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:04:00,367] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:04:00,371] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:04:00,667] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run41
[2019-03-23 01:04:00,837] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run41
[2019-03-23 01:04:00,857] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run41
[2019-03-23 01:04:00,945] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run41
[2019-03-23 01:04:00,978] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run41
[2019-03-23 01:04:05,952] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.12878755], dtype=float32), -0.16800132]
[2019-03-23 01:04:05,954] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.5, 40.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4455592895367946, 6.9112, 6.9112, 121.9260426156618, 318125.5855806163, 318125.5855806163, 91263.22594023097]
[2019-03-23 01:04:05,955] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:04:05,960] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3773232143744437
[2019-03-23 01:04:18,112] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.12878755], dtype=float32), -0.16800132]
[2019-03-23 01:04:18,113] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 55.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5468203591813718, 6.911200000000001, 6.9112, 121.9260426156618, 403430.6804601671, 403430.6804601667, 123985.1692028901]
[2019-03-23 01:04:18,114] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:04:18,118] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.581829376077791
[2019-03-23 01:04:29,469] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.12878755], dtype=float32), -0.16800132]
[2019-03-23 01:04:29,470] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.16666666666666, 91.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6842273199115965, 6.9112, 6.9112, 121.9260426156618, 510354.5611187294, 510354.5611187294, 140824.3219061376]
[2019-03-23 01:04:29,471] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:04:29,474] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3469994949380435
[2019-03-23 01:05:07,603] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.12878755], dtype=float32), -0.16800132]
[2019-03-23 01:05:07,604] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.0, 66.0, 1.0, 2.0, 0.8282658784510378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 959489.6910910389, 959489.6910910389, 202648.9827404498]
[2019-03-23 01:05:07,605] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:05:07,608] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 1.1005677e-28 9.1103245e-29 3.4424946e-19], sampled 0.6819903670768926
[2019-03-23 01:05:07,609] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 959489.6910910389 W.
[2019-03-23 01:05:26,383] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.12878755], dtype=float32), -0.16800132]
[2019-03-23 01:05:26,386] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.740308355, 81.73747646000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6994252158963208, 6.911200000000001, 6.9112, 121.9260426156618, 522323.8238188853, 522323.8238188848, 146017.1831481233]
[2019-03-23 01:05:26,386] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:05:26,390] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9796623682180827
[2019-03-23 01:05:47,620] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.12878755], dtype=float32), -0.16800132]
[2019-03-23 01:05:47,621] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.46682471, 104.398538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7244875730799669, 6.9112, 6.9112, 121.9260426156618, 540979.6062768482, 540979.6062768482, 148949.7325455298]
[2019-03-23 01:05:47,622] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:05:47,626] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 3.2926894861007305e-05
[2019-03-23 01:05:52,804] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8586.6552 2253409150.2519 519.0000
[2019-03-23 01:05:52,868] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7915.4049 2516110050.9569 718.0000
[2019-03-23 01:05:53,093] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8439.2657 2286186780.5609 650.0000
[2019-03-23 01:05:53,103] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8411.5553 2326518489.0048 564.0000
[2019-03-23 01:05:53,188] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8640.9206 2215950560.0158 531.0000
[2019-03-23 01:05:54,205] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1000000, evaluation results [1000000.0, 7915.404898464732, 2516110050.9568515, 718.0, 8586.655211439824, 2253409150.2519455, 519.0, 8640.92060084992, 2215950560.0157547, 531.0, 8411.555309608646, 2326518489.004762, 564.0, 8439.26574537923, 2286186780.560886, 650.0]
[2019-03-23 01:05:56,335] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.5561734e-29 3.9551200e-31 0.0000000e+00 9.1627903e-19], sum to 1.0000
[2019-03-23 01:05:56,342] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7467
[2019-03-23 01:05:56,350] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 819345.3452196408 W.
[2019-03-23 01:05:56,355] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.65, 66.0, 1.0, 2.0, 0.71889228376111, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819345.3452196408, 819345.3452196408, 179754.4380511123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5675400.0000, 
sim time next is 5676000.0000, 
raw observation next is [30.73333333333333, 65.66666666666666, 1.0, 2.0, 0.7229345234606313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823954.8960250351, 823954.8960250351, 180534.3279157767], 
processed observation next is [0.0, 0.6956521739130435, 0.6938271604938271, 0.6566666666666666, 1.0, 1.0, 0.6701601469769419, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2942696057232268, 0.2942696057232268, 0.3471813998380321], 
reward next is 0.6528, 
noisyNet noise sample is [array([-0.09375902], dtype=float32), 0.29162315]. 
=============================================
[2019-03-23 01:05:56,368] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[43.800877]
 [44.40142 ]
 [44.56892 ]
 [44.13199 ]
 [43.30384 ]], R is [[44.03368378]
 [44.24766541]
 [44.43222809]
 [43.98790741]
 [43.54802704]].
[2019-03-23 01:05:56,471] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.9377644e-36 1.2191568e-35 0.0000000e+00 2.9719489e-23], sum to 1.0000
[2019-03-23 01:05:56,479] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8998
[2019-03-23 01:05:56,488] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 807071.2659015554 W.
[2019-03-23 01:05:56,494] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.56666666666667, 66.33333333333334, 1.0, 2.0, 0.708128693283446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 807071.2659015554, 807071.265901555, 177691.8125693499], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5674800.0000, 
sim time next is 5675400.0000, 
raw observation next is [30.65, 66.0, 1.0, 2.0, 0.3594461443086003, 1.0, 1.0, 0.3594461443086003, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819345.3507572464, 819345.3507572464, 195339.2291260446], 
processed observation next is [0.0, 0.6956521739130435, 0.6907407407407407, 0.66, 1.0, 1.0, 0.237435886081667, 1.0, 0.5, 0.237435886081667, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29262333955615943, 0.29262333955615943, 0.37565236370393196], 
reward next is 0.6243, 
noisyNet noise sample is [array([1.4341588], dtype=float32), -1.2903926]. 
=============================================
[2019-03-23 01:05:57,407] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:05:57,415] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1436
[2019-03-23 01:05:57,421] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.43333333333333, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7700317095044205, 6.9112, 6.9112, 121.9260426156618, 573824.6437426492, 573824.6437426492, 155493.9114911964], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6240000.0000, 
sim time next is 6240600.0000, 
raw observation next is [22.55, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7730070740996569, 6.9112, 6.9112, 121.9260426156618, 575805.1345575597, 575805.1345575597, 156030.8443371563], 
processed observation next is [0.0, 0.21739130434782608, 0.3907407407407408, 0.88, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7162588426245711, 0.0, 0.0, 0.8094621288201359, 0.2056446909134142, 0.2056446909134142, 0.3000593160329929], 
reward next is 0.6999, 
noisyNet noise sample is [array([0.97155595], dtype=float32), 0.5295806]. 
=============================================
[2019-03-23 01:05:59,764] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:05:59,772] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8965
[2019-03-23 01:05:59,779] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.33333333333334, 79.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5977218859263451, 6.911200000000001, 6.9112, 121.9260426156618, 441425.5885179161, 441425.5885179156, 128779.2029517705], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5898000.0000, 
sim time next is 5898600.0000, 
raw observation next is [20.5, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5885121212611947, 6.9112, 6.9112, 121.9260426156618, 434984.5085578357, 434984.5085578357, 128140.3424965213], 
processed observation next is [1.0, 0.2608695652173913, 0.3148148148148148, 0.79, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4856401515764933, 0.0, 0.0, 0.8094621288201359, 0.15535161019922705, 0.15535161019922705, 0.24642373557023328], 
reward next is 0.7536, 
noisyNet noise sample is [array([0.12157967], dtype=float32), 2.1345243]. 
=============================================
[2019-03-23 01:06:00,361] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:06:00,376] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4805
[2019-03-23 01:06:00,386] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.43333333333333, 73.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.755623676955788, 6.911200000000001, 6.9112, 121.9260426156618, 563414.9664360848, 563414.9664360844, 153497.8299447771], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5739600.0000, 
sim time next is 5740200.0000, 
raw observation next is [24.65, 72.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7591235809970189, 6.9112, 6.9112, 121.9260426156618, 565786.5446030266, 565786.5446030266, 154116.4428580125], 
processed observation next is [0.0, 0.43478260869565216, 0.46851851851851845, 0.725, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6989044762462737, 0.0, 0.0, 0.8094621288201359, 0.2020666230725095, 0.2020666230725095, 0.29637777472694715], 
reward next is 0.7036, 
noisyNet noise sample is [array([0.74836355], dtype=float32), 1.64836]. 
=============================================
[2019-03-23 01:06:01,395] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:06:01,407] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5755
[2019-03-23 01:06:01,417] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.1, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9108043457061774, 6.911200000000001, 6.9112, 121.9260426156618, 664339.838057829, 664339.8380578285, 177811.2810193662], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5760000.0000, 
sim time next is 5760600.0000, 
raw observation next is [28.13333333333333, 65.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9193371805370663, 6.9112, 6.9112, 121.9260426156618, 669562.6594582637, 669562.6594582637, 179134.3431396093], 
processed observation next is [0.0, 0.6956521739130435, 0.5975308641975308, 0.6533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8991714756713328, 0.0, 0.0, 0.8094621288201359, 0.23912952123509418, 0.23912952123509418, 0.3444891214223256], 
reward next is 0.6555, 
noisyNet noise sample is [array([-1.5330342], dtype=float32), -0.7635418]. 
=============================================
[2019-03-23 01:06:20,845] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9163052e-04 1.1453258e-15 1.0289476e-18 9.9950838e-01 1.3345639e-16], sum to 1.0000
[2019-03-23 01:06:20,854] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2128
[2019-03-23 01:06:20,860] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.35, 53.16666666666667, 1.0, 2.0, 0.8056376609005373, 1.0, 2.0, 0.8056376609005373, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1837600.045868593, 1837600.045868593, 346088.0564270664], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6102600.0000, 
sim time next is 6103200.0000, 
raw observation next is [30.3, 53.33333333333334, 1.0, 2.0, 0.7902696168064741, 1.0, 2.0, 0.7902696168064741, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1802511.302257927, 1802511.302257927, 339748.6103667893], 
processed observation next is [1.0, 0.6521739130434783, 0.6777777777777778, 0.5333333333333334, 1.0, 1.0, 0.7503209723886597, 1.0, 1.0, 0.7503209723886597, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6437540365206882, 0.6437540365206882, 0.6533627122438256], 
reward next is 0.3466, 
noisyNet noise sample is [array([0.64985245], dtype=float32), -0.8432378]. 
=============================================
[2019-03-23 01:06:30,198] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 9.3526554e-23 3.2404801e-35 0.0000000e+00 1.4588989e-22], sum to 1.0000
[2019-03-23 01:06:30,207] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3620
[2019-03-23 01:06:30,214] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 703637.4515437416 W.
[2019-03-23 01:06:30,223] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 73.0, 1.0, 2.0, 0.205805663342742, 1.0, 1.0, 0.205805663342742, 1.0, 1.0, 0.3276493186641659, 6.911200000000001, 6.9112, 121.94756008, 703637.4515437416, 703637.4515437412, 222500.4078880795], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6262200.0000, 
sim time next is 6262800.0000, 
raw observation next is [27.43333333333333, 72.33333333333333, 1.0, 2.0, 0.6189220042392621, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706377.9081737171, 706377.9081737171, 161412.4304221126], 
processed observation next is [0.0, 0.4782608695652174, 0.5716049382716049, 0.7233333333333333, 1.0, 1.0, 0.546335719332455, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2522778243477561, 0.2522778243477561, 0.3104085200425242], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.153405], dtype=float32), -1.081974]. 
=============================================
[2019-03-23 01:06:30,796] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 6.3410308e-24 3.6858506e-36 0.0000000e+00 1.2539860e-35], sum to 1.0000
[2019-03-23 01:06:30,802] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8198
[2019-03-23 01:06:30,815] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 716864.0955803882 W.
[2019-03-23 01:06:30,819] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.45, 67.66666666666667, 1.0, 2.0, 0.3145087137685301, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5007081151532179, 6.911199999999999, 6.9112, 121.9260426156618, 716864.0955803882, 716864.0955803887, 199184.2103722933], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6267000.0000, 
sim time next is 6267600.0000, 
raw observation next is [28.6, 67.0, 1.0, 2.0, 0.3152479232411142, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5018849607079436, 6.911199999999999, 6.9112, 121.9260426156618, 718549.7757169019, 718549.7757169023, 199387.0691092385], 
processed observation next is [0.0, 0.5652173913043478, 0.6148148148148148, 0.67, 1.0, 1.0, 0.1848189562394217, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3773562008849295, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2566249198988935, 0.2566249198988937, 0.38343667136392023], 
reward next is 0.6166, 
noisyNet noise sample is [array([-1.9413844], dtype=float32), -0.17031854]. 
=============================================
[2019-03-23 01:06:45,242] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.2522024e-38], sum to 1.0000
[2019-03-23 01:06:45,252] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6032
[2019-03-23 01:06:45,260] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1961310.573513509 W.
[2019-03-23 01:06:45,265] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.96666666666667, 85.66666666666667, 1.0, 2.0, 0.5732102074692244, 1.0, 1.0, 0.5732102074692244, 1.0, 2.0, 0.9125693184441708, 6.9112, 6.9112, 121.94756008, 1961310.573513509, 1961310.573513509, 380972.4585030935], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6511800.0000, 
sim time next is 6512400.0000, 
raw observation next is [27.1, 85.0, 1.0, 2.0, 0.8425266034148657, 1.0, 2.0, 0.8425266034148657, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260425951094, 1921831.526464773, 1921831.526464774, 361640.8417964735], 
processed observation next is [1.0, 0.391304347826087, 0.5592592592592593, 0.85, 1.0, 1.0, 0.8125316707319831, 1.0, 1.0, 0.8125316707319831, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621286836894, 0.6863684023088475, 0.6863684023088479, 0.6954631573009106], 
reward next is 0.3045, 
noisyNet noise sample is [array([0.22570595], dtype=float32), 0.67255]. 
=============================================
[2019-03-23 01:06:46,299] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:06:46,307] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4818
[2019-03-23 01:06:46,312] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.16666666666666, 56.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6298002917745945, 6.9112, 6.9112, 121.9260426156618, 469456.1042201903, 469456.1042201903, 134915.8477074955], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6637200.0000, 
sim time next is 6637800.0000, 
raw observation next is [24.88333333333334, 58.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6393021395243887, 6.911199999999999, 6.9112, 121.9260426156618, 476779.2690698266, 476779.269069827, 136137.2758961895], 
processed observation next is [1.0, 0.8260869565217391, 0.47716049382716075, 0.5883333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5491276744054859, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1702783103820809, 0.17027831038208108, 0.2618024536465183], 
reward next is 0.7382, 
noisyNet noise sample is [array([-0.614758], dtype=float32), 0.95202243]. 
=============================================
[2019-03-23 01:06:48,868] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 01:06:48,869] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:06:48,871] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:06:48,871] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:06:48,872] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:06:48,872] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:06:48,873] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:06:48,874] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:06:48,875] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:06:48,876] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:06:48,873] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:06:48,899] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run42
[2019-03-23 01:06:48,926] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run42
[2019-03-23 01:06:48,927] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run42
[2019-03-23 01:06:48,928] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run42
[2019-03-23 01:06:48,995] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run42
[2019-03-23 01:07:09,754] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21535021], dtype=float32), -0.2167077]
[2019-03-23 01:07:09,756] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.83333333333333, 38.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6401895160449885, 6.911200000000001, 6.9112, 121.9260426156618, 478034.9039277361, 478034.9039277357, 137097.8052809449]
[2019-03-23 01:07:09,757] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:07:09,760] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8653776639425721
[2019-03-23 01:07:22,417] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21535021], dtype=float32), -0.2167077]
[2019-03-23 01:07:22,417] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.193760355, 70.017389365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7104534390509131, 6.911199999999999, 6.9112, 121.9260426156618, 530898.8093523101, 530898.8093523106, 146269.7364974302]
[2019-03-23 01:07:22,419] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:07:22,424] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.24632880638323917
[2019-03-23 01:07:32,685] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21535021], dtype=float32), -0.2167077]
[2019-03-23 01:07:32,688] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.77905759666667, 62.50061810666666, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 1.0, 2.0, 0.9977734948820727, 57.13124485389731, 6.9112, 121.94756008, 28765579.50202326, 3043889.366451319, 511720.5706722371]
[2019-03-23 01:07:32,688] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:07:32,691] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4602602427522041
[2019-03-23 01:07:32,691] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 28765579.50202326 W.
[2019-03-23 01:07:46,354] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21535021], dtype=float32), -0.2167077]
[2019-03-23 01:07:46,355] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.0, 81.0, 1.0, 2.0, 1.02, 1.0, 1.0, 1.02, 1.0, 1.0, 0.9977734948820727, 13.56024752560916, 6.9112, 135.6138403062026, 6834661.242368491, 3047509.191197981, 543709.9908524997]
[2019-03-23 01:07:46,355] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:07:46,359] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.5430205e-05 0.0000000e+00 5.6953232e-30 9.9991453e-01 4.2686052e-18], sampled 0.15131449110352002
[2019-03-23 01:07:46,362] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 0, 0, 1, 0] has been changed to [0, 0, 0, 0, 1] for the demand 6834661.242368491 W.
[2019-03-23 01:07:57,775] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21535021], dtype=float32), -0.2167077]
[2019-03-23 01:07:57,777] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.0, 83.0, 1.0, 2.0, 0.5703131683354119, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9083735709137057, 6.9112, 6.9112, 121.9260426156618, 1309272.54522867, 1309272.54522867, 282364.9874283178]
[2019-03-23 01:07:57,778] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:07:57,782] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5702804769248746
[2019-03-23 01:07:57,784] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1309272.54522867 W.
[2019-03-23 01:08:21,393] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21535021], dtype=float32), -0.2167077]
[2019-03-23 01:08:21,395] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.71666666666667, 88.33333333333334, 1.0, 2.0, 0.975904954145623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.069373602197598, 6.9112, 121.9251452291411, 1207089.620940454, 1126091.195379148, 235718.6435635525]
[2019-03-23 01:08:21,396] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:08:21,398] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8986229068735964
[2019-03-23 01:08:21,400] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1207089.620940454 W.
[2019-03-23 01:08:40,408] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5008 2529782916.7115 831.0000
[2019-03-23 01:08:40,623] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.2402 2292979445.9673 697.0000
[2019-03-23 01:08:40,781] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8558.6925 2258281932.5947 536.0000
[2019-03-23 01:08:40,887] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.7427 2219188629.1108 543.0000
[2019-03-23 01:08:40,946] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8362.6582 2339458764.4987 616.0000
[2019-03-23 01:08:41,961] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1025000, evaluation results [1025000.0, 7841.500825456038, 2529782916.711494, 831.0, 8558.692516993873, 2258281932.5946884, 536.0, 8633.742656024266, 2219188629.1107655, 543.0, 8362.658216619719, 2339458764.498721, 616.0, 8404.240247944708, 2292979445.967258, 697.0]
[2019-03-23 01:08:44,012] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:08:44,022] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9016
[2019-03-23 01:08:44,029] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.15, 45.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6038343301686608, 6.911200000000001, 6.9112, 121.9260426156618, 449362.2901478652, 449362.2901478648, 131652.8788333559], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6633000.0000, 
sim time next is 6633600.0000, 
raw observation next is [26.86666666666667, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6030704071718785, 6.9112, 6.9112, 121.9260426156618, 448650.6400469536, 448650.6400469536, 131456.6763313177], 
processed observation next is [1.0, 0.782608695652174, 0.5506172839506175, 0.46, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5038380089648481, 0.0, 0.0, 0.8094621288201359, 0.16023237144534055, 0.16023237144534055, 0.2528013006371494], 
reward next is 0.7472, 
noisyNet noise sample is [array([0.88299453], dtype=float32), -0.57288426]. 
=============================================
[2019-03-23 01:08:44,939] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:08:44,946] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9565
[2019-03-23 01:08:44,950] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.93333333333333, 43.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5338525306899464, 6.9112, 6.9112, 121.9260426156618, 387655.9611142322, 387655.9611142322, 120034.7311700924], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6646800.0000, 
sim time next is 6647400.0000, 
raw observation next is [24.95, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5265666174376736, 6.9112, 6.9112, 121.9260426156618, 380831.146496664, 380831.146496664, 118852.2770342155], 
processed observation next is [1.0, 0.9565217391304348, 0.47962962962962963, 0.42, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.408208271797092, 0.0, 0.0, 0.8094621288201359, 0.13601112374880855, 0.13601112374880855, 0.2285620712196452], 
reward next is 0.7714, 
noisyNet noise sample is [array([-1.6134814], dtype=float32), -0.46707603]. 
=============================================
[2019-03-23 01:08:46,816] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:08:46,827] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3784
[2019-03-23 01:08:46,833] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 78.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7219102108017817, 6.911199999999999, 6.9112, 121.9260426156618, 539301.0913668656, 539301.091366866, 148171.4325393511], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6827400.0000, 
sim time next is 6828000.0000, 
raw observation next is [22.93333333333333, 78.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7155354422280391, 6.911200000000001, 6.9112, 121.9260426156618, 534613.8740519426, 534613.8740519423, 147231.7774783407], 
processed observation next is [0.0, 0.0, 0.40493827160493817, 0.7833333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6444193027850489, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19093352644712236, 0.19093352644712225, 0.28313803361219364], 
reward next is 0.7169, 
noisyNet noise sample is [array([0.7067986], dtype=float32), 1.1606067]. 
=============================================
[2019-03-23 01:08:46,852] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[73.00768]
 [72.93907]
 [72.7696 ]
 [72.47671]
 [71.90684]], R is [[73.08329773]
 [73.06752014]
 [73.04997253]
 [73.0306015 ]
 [73.00944519]].
[2019-03-23 01:09:00,551] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:09:00,559] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1023
[2019-03-23 01:09:00,567] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.63333333333333, 79.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7783248078020643, 6.9112, 6.9112, 121.9260426156618, 579848.195135524, 579848.195135524, 156613.6090512715], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7065600.0000, 
sim time next is 7066200.0000, 
raw observation next is [23.61666666666667, 79.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7777119034017366, 6.9112, 6.9112, 121.9260426156618, 579368.7097897033, 579368.7097897033, 156556.3975865308], 
processed observation next is [1.0, 0.782608695652174, 0.4302469135802471, 0.7983333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7221398792521707, 0.0, 0.0, 0.8094621288201359, 0.20691739635346545, 0.20691739635346545, 0.3010699953587131], 
reward next is 0.6989, 
noisyNet noise sample is [array([-1.3669955], dtype=float32), 0.20004816]. 
=============================================
[2019-03-23 01:09:02,120] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:09:02,127] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8811
[2019-03-23 01:09:02,132] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.15, 83.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7091648725423294, 6.9112, 6.9112, 121.9260426156618, 529925.8610422555, 529925.8610422555, 146195.1755452865], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6935400.0000, 
sim time next is 6936000.0000, 
raw observation next is [22.26666666666667, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7125525000689199, 6.9112, 6.9112, 121.9260426156618, 532434.9523691798, 532434.9523691798, 146698.3509184303], 
processed observation next is [0.0, 0.2608695652173913, 0.38024691358024704, 0.83, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6406906250861499, 0.0, 0.0, 0.8094621288201359, 0.19015534013184993, 0.19015534013184993, 0.2821122133046737], 
reward next is 0.7179, 
noisyNet noise sample is [array([0.14415875], dtype=float32), 1.0511523]. 
=============================================
[2019-03-23 01:09:02,150] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[65.80793 ]
 [65.88244 ]
 [65.962166]
 [66.07007 ]
 [66.13927 ]], R is [[65.79225159]
 [65.85318756]
 [65.91442108]
 [65.97583771]
 [66.03764343]].
[2019-03-23 01:09:05,134] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:09:05,144] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0409
[2019-03-23 01:09:05,151] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.13333333333333, 45.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8498496932324406, 6.911199999999999, 6.9112, 121.9260426156618, 627150.8974876625, 627150.897487663, 168107.5052430508], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6972000.0000, 
sim time next is 6972600.0000, 
raw observation next is [31.16666666666666, 44.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8380358035684536, 6.911199999999999, 6.9112, 121.9260426156618, 619433.0178980189, 619433.0178980194, 166295.3246385647], 
processed observation next is [0.0, 0.6956521739130435, 0.7098765432098764, 0.4483333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.797544754460567, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22122607782072104, 0.2212260778207212, 0.319798701228009], 
reward next is 0.6802, 
noisyNet noise sample is [array([0.4912795], dtype=float32), 0.6369991]. 
=============================================
[2019-03-23 01:09:10,098] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.6889650e-33 2.4507898e-33], sum to 1.0000
[2019-03-23 01:09:10,105] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8577
[2019-03-23 01:09:10,114] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1627853.187234782 W.
[2019-03-23 01:09:10,123] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.25, 59.0, 1.0, 2.0, 0.7896832562052752, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9852456184836946, 6.911199999999999, 6.9112, 121.9260426156618, 1627853.187234782, 1627853.187234782, 332074.4455242097], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7049400.0000, 
sim time next is 7050000.0000, 
raw observation next is [28.0, 60.0, 1.0, 2.0, 0.7770371279106251, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9821506353010645, 6.9112, 6.9112, 121.9260426156618, 1616628.680533994, 1616628.680533994, 328992.4701462861], 
processed observation next is [1.0, 0.6086956521739131, 0.5925925925925926, 0.6, 1.0, 1.0, 0.7345680094174107, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9776882941263306, 0.0, 0.0, 0.8094621288201359, 0.5773673859049978, 0.5773673859049978, 0.6326778272043964], 
reward next is 0.3673, 
noisyNet noise sample is [array([0.7989978], dtype=float32), -0.1853488]. 
=============================================
[2019-03-23 01:09:10,136] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[45.552246]
 [46.61317 ]
 [45.583256]
 [46.33472 ]
 [46.159477]], R is [[45.4710083 ]
 [45.37769699]
 [44.92391968]
 [44.91490936]
 [44.46575928]].
[2019-03-23 01:09:23,605] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.7364755e-01 0.0000000e+00 1.8983176e-28 2.2635247e-01 1.5510175e-13], sum to 1.0000
[2019-03-23 01:09:23,612] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7052
[2019-03-23 01:09:23,624] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 900084.9612374539 W.
[2019-03-23 01:09:23,630] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.1, 84.0, 1.0, 2.0, 0.3731890327683963, 1.0, 2.0, 0.3731890327683963, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 900084.9612374539, 900084.9612374535, 201019.8942336502], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7291800.0000, 
sim time next is 7292400.0000, 
raw observation next is [22.23333333333333, 83.33333333333334, 1.0, 2.0, 0.3722693254794586, 1.0, 2.0, 0.3722693254794586, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 897019.9074671158, 897019.9074671149, 200742.5616824789], 
processed observation next is [1.0, 0.391304347826087, 0.37901234567901226, 0.8333333333333335, 1.0, 1.0, 0.2527015779517365, 1.0, 1.0, 0.2527015779517365, 0.0, 1.0, -0.25, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.32036425266682705, 0.3203642526668267, 0.38604338785092096], 
reward next is 0.6140, 
noisyNet noise sample is [array([0.09918689], dtype=float32), -1.1623095]. 
=============================================
[2019-03-23 01:09:30,302] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 5.082401e-34], sum to 1.0000
[2019-03-23 01:09:30,311] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6474
[2019-03-23 01:09:30,316] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.16666666666666, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8556433424841623, 6.9112, 6.9112, 121.9260426156618, 629577.981908564, 629577.981908564, 169363.8732740527], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7566600.0000, 
sim time next is 7567200.0000, 
raw observation next is [27.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8431492236789868, 6.9112, 6.9112, 121.9260426156618, 621568.7504674372, 621568.7504674372, 167448.6546310794], 
processed observation next is [0.0, 0.6086956521739131, 0.5555555555555556, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8039365295987335, 0.0, 0.0, 0.8094621288201359, 0.22198883945265616, 0.22198883945265616, 0.32201664352130654], 
reward next is 0.6780, 
noisyNet noise sample is [array([0.27491942], dtype=float32), -0.29323548]. 
=============================================
[2019-03-23 01:09:30,673] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:09:30,673] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:09:30,736] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run6
[2019-03-23 01:09:30,955] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 7.1567557e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 01:09:30,965] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7714
[2019-03-23 01:09:30,970] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.65, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.678064430953504, 6.9112, 6.9112, 121.9260426156618, 506402.0382317566, 506402.0382317566, 141180.3324451757], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7410600.0000, 
sim time next is 7411200.0000, 
raw observation next is [20.6, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6734955381853212, 6.9112, 6.9112, 121.9260426156618, 502922.4981816666, 502922.4981816666, 140565.6417086352], 
processed observation next is [1.0, 0.782608695652174, 0.3185185185185186, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5918694227316514, 0.0, 0.0, 0.8094621288201359, 0.17961517792202378, 0.17961517792202378, 0.2703185417473754], 
reward next is 0.7297, 
noisyNet noise sample is [array([2.5637505], dtype=float32), -0.82151604]. 
=============================================
[2019-03-23 01:09:32,449] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.1902105e-22 1.1563356e-30], sum to 1.0000
[2019-03-23 01:09:32,462] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0069
[2019-03-23 01:09:32,474] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.1, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6385967664185866, 6.9112, 6.9112, 121.9260426156618, 476140.5873112579, 476140.5873112579, 135934.1647078572], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7430400.0000, 
sim time next is 7431000.0000, 
raw observation next is [20.08333333333334, 91.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6377745375465509, 6.911200000000001, 6.9112, 121.9260426156618, 475520.8360949864, 475520.8360949859, 135844.1761282082], 
processed observation next is [0.0, 0.0, 0.29938271604938294, 0.9116666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5472181719331886, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16982887003392372, 0.16982887003392352, 0.2612388002465542], 
reward next is 0.7388, 
noisyNet noise sample is [array([0.0464449], dtype=float32), -0.7362496]. 
=============================================
[2019-03-23 01:09:32,497] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[71.28951 ]
 [70.37608 ]
 [70.349655]
 [70.33069 ]
 [70.310234]], R is [[71.79273224]
 [71.81339264]
 [71.83361053]
 [71.85348511]
 [71.87319183]].
[2019-03-23 01:09:36,684] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 01:09:36,687] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:09:36,689] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:09:36,689] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:09:36,690] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:09:36,691] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:09:36,691] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:09:36,691] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:09:36,692] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:09:36,697] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:09:36,698] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:09:36,720] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run43
[2019-03-23 01:09:36,721] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run43
[2019-03-23 01:09:36,774] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run43
[2019-03-23 01:09:36,793] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run43
[2019-03-23 01:09:36,795] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run43
[2019-03-23 01:10:01,554] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.1999833], dtype=float32), -0.23046023]
[2019-03-23 01:10:01,556] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.15, 69.0, 1.0, 2.0, 0.8716805066612843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1082083.92529159, 1082083.92529159, 214894.0712606461]
[2019-03-23 01:10:01,557] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:10:01,558] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 1.0717695e-34 6.7846309e-18 7.9229447e-23], sampled 0.6641877929349165
[2019-03-23 01:10:01,559] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1082083.92529159 W.
[2019-03-23 01:10:02,376] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.1999833], dtype=float32), -0.23046023]
[2019-03-23 01:10:02,378] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.98333333333333, 43.33333333333334, 1.0, 2.0, 0.7905587940750928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 945929.7210552831, 945929.7210552831, 196095.4012870469]
[2019-03-23 01:10:02,379] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:10:02,384] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 7.8629196e-35 8.5494559e-35 2.5562079e-25 6.9338476e-26], sampled 0.779102654887178
[2019-03-23 01:10:02,385] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 945929.7210552831 W.
[2019-03-23 01:10:40,147] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.1999833], dtype=float32), -0.23046023]
[2019-03-23 01:10:40,149] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7787798980080992, 6.911199999999999, 6.9112, 121.9260426156618, 580309.507824069, 580309.5078240695, 156575.6099988146]
[2019-03-23 01:10:40,149] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:10:40,152] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.48874816848606606
[2019-03-23 01:10:41,643] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.1999833], dtype=float32), -0.23046023]
[2019-03-23 01:10:41,645] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.7, 95.0, 1.0, 2.0, 0.6177783609722018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716224.4410683787, 716224.4410683787, 161749.789697329]
[2019-03-23 01:10:41,647] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:10:41,650] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3183321690892854
[2019-03-23 01:10:41,652] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 716224.4410683787 W.
[2019-03-23 01:11:28,170] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8609.3445 2251103636.3416 507.0000
[2019-03-23 01:11:28,197] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8669.3098 2214020198.1040 519.0000
[2019-03-23 01:11:28,425] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7947.6491 2511486153.5958 729.0000
[2019-03-23 01:11:28,445] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8466.3888 2283364708.7796 640.0000
[2019-03-23 01:11:28,513] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8441.7310 2323551313.5074 554.0000
[2019-03-23 01:11:29,530] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1050000, evaluation results [1050000.0, 7947.649070601346, 2511486153.595758, 729.0, 8609.34445082937, 2251103636.3416214, 507.0, 8669.309778959117, 2214020198.104023, 519.0, 8441.731034148615, 2323551313.5074058, 554.0, 8466.38878633566, 2283364708.7796183, 640.0]
[2019-03-23 01:11:31,316] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:11:31,325] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3972
[2019-03-23 01:11:31,332] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.51666666666667, 93.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5574878659831611, 6.911199999999999, 6.9112, 121.9260426156618, 410851.1282702397, 410851.1282702402, 124681.3058713408], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7710600.0000, 
sim time next is 7711200.0000, 
raw observation next is [18.6, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5587398496090833, 6.9112, 6.9112, 121.9260426156618, 412094.8561481747, 412094.8561481747, 124961.7835381518], 
processed observation next is [1.0, 0.2608695652173913, 0.2444444444444445, 0.93, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4484248120113541, 0.0, 0.0, 0.8094621288201359, 0.14717673433863382, 0.14717673433863382, 0.24031112218875345], 
reward next is 0.7597, 
noisyNet noise sample is [array([0.6716543], dtype=float32), -0.03219781]. 
=============================================
[2019-03-23 01:11:34,211] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1052150: loss 0.5150
[2019-03-23 01:11:34,215] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1052151: learning rate 0.0010
[2019-03-23 01:11:40,370] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:11:40,380] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5123
[2019-03-23 01:11:40,383] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.56666666666666, 50.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4660825844520031, 6.911200000000001, 6.9112, 121.9260426156618, 332782.2246281187, 332782.2246281183, 97304.66878640045], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 268800.0000, 
sim time next is 269400.0000, 
raw observation next is [20.48333333333333, 50.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4645115221558071, 6.9112, 6.9112, 121.9260426156618, 331660.2461021968, 331660.2461021968, 96901.22036178183], 
processed observation next is [0.0, 0.08695652173913043, 0.31419753086419744, 0.5083333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.33063940269475883, 0.0, 0.0, 0.8094621288201359, 0.11845008789364171, 0.11845008789364171, 0.18634850069573428], 
reward next is 0.8137, 
noisyNet noise sample is [array([0.5487947], dtype=float32), -1.4464492]. 
=============================================
[2019-03-23 01:11:43,758] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:11:43,767] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9858
[2019-03-23 01:11:43,775] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.06666666666667, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6672051165844451, 6.9112, 6.9112, 121.9260426156618, 491238.85314851, 491238.85314851, 134579.6510345273], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7784400.0000, 
sim time next is 7785000.0000, 
raw observation next is [21.1, 71.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6226744746749479, 6.911200000000001, 6.9112, 121.9260426156618, 458227.8575588133, 458227.8575588129, 130246.4453063506], 
processed observation next is [1.0, 0.08695652173913043, 0.3370370370370371, 0.715, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5283430933436848, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16365280627100476, 0.1636528062710046, 0.25047393328144346], 
reward next is 0.7495, 
noisyNet noise sample is [array([0.42713115], dtype=float32), 0.6170286]. 
=============================================
[2019-03-23 01:11:43,796] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[69.63027 ]
 [69.4662  ]
 [69.468735]
 [69.48685 ]
 [69.53988 ]], R is [[69.59773254]
 [69.64295197]
 [69.66731262]
 [69.73002625]
 [69.79154968]].
[2019-03-23 01:11:45,671] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:11:45,672] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:11:45,750] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run6
[2019-03-23 01:11:46,465] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:11:46,466] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:11:46,528] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run6
[2019-03-23 01:11:48,685] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:11:48,685] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:11:48,756] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run6
[2019-03-23 01:11:49,694] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1059540: loss 0.0419
[2019-03-23 01:11:49,696] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1059540: learning rate 0.0010
[2019-03-23 01:11:53,077] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:11:53,078] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:11:53,129] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:11:53,129] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:11:53,130] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run6
[2019-03-23 01:11:53,217] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run6
[2019-03-23 01:11:53,539] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1061384: loss 0.0256
[2019-03-23 01:11:53,540] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1061384: learning rate 0.0010
[2019-03-23 01:11:53,555] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:11:53,556] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:11:53,597] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run6
[2019-03-23 01:11:53,626] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:11:53,627] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:11:53,667] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run6
[2019-03-23 01:11:53,816] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1061529: loss 1.9267
[2019-03-23 01:11:53,818] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1061529: learning rate 0.0010
[2019-03-23 01:11:53,940] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:11:53,941] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:11:53,971] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run6
[2019-03-23 01:11:54,079] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:11:54,079] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:11:54,084] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:11:54,084] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:11:54,092] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:11:54,092] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:11:54,101] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run6
[2019-03-23 01:11:54,123] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:11:54,125] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:11:54,135] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run6
[2019-03-23 01:11:54,167] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run6
[2019-03-23 01:11:54,167] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run6
[2019-03-23 01:11:54,323] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:11:54,324] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:11:54,331] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run6
[2019-03-23 01:11:54,353] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:11:54,357] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:11:54,366] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run6
[2019-03-23 01:11:54,390] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:11:54,390] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:11:54,401] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run6
[2019-03-23 01:11:54,764] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1061901: loss 0.6453
[2019-03-23 01:11:54,768] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1061902: learning rate 0.0010
[2019-03-23 01:11:57,046] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:11:57,056] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3087
[2019-03-23 01:11:57,065] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 774765.733141737 W.
[2019-03-23 01:11:57,069] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.73333333333333, 46.66666666666666, 1.0, 1.0, 0.3034830678237214, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5305157087488142, 6.9112, 6.9112, 121.9260426156618, 774765.733141737, 774765.733141737, 189731.2733439264], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 31200.0000, 
sim time next is 31800.0000, 
raw observation next is [23.96666666666667, 46.33333333333334, 1.0, 2.0, 0.3181471672090165, 1.0, 1.0, 0.3181471672090165, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 807996.6316624141, 807996.6316624145, 187610.2034820462], 
processed observation next is [1.0, 0.34782608695652173, 0.4432098765432099, 0.46333333333333343, 1.0, 1.0, 0.18827043715359104, 1.0, 0.5, 0.18827043715359104, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2885702255937193, 0.2885702255937195, 0.3607888528500888], 
reward next is 0.6392, 
noisyNet noise sample is [array([-0.11574544], dtype=float32), -1.705441]. 
=============================================
[2019-03-23 01:11:57,383] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:11:57,395] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6169
[2019-03-23 01:11:57,399] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.38333333333334, 72.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.68687518296278, 6.9112, 6.9112, 121.9260426156618, 513265.2796244831, 513265.2796244831, 143006.4348990882], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 90600.0000, 
sim time next is 91200.0000, 
raw observation next is [23.26666666666667, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6842518368584068, 6.911200000000001, 6.9112, 121.9260426156618, 511288.0635719898, 511288.0635719893, 142626.4560313753], 
processed observation next is [1.0, 0.043478260869565216, 0.41728395061728407, 0.73, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6053147960730085, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18260287984713922, 0.18260287984713905, 0.2742816462141833], 
reward next is 0.7257, 
noisyNet noise sample is [array([-0.3857753], dtype=float32), 1.7663299]. 
=============================================
[2019-03-23 01:11:58,199] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:11:58,206] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3098
[2019-03-23 01:11:58,215] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.1, 37.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4995754547466827, 6.911200000000001, 6.9112, 121.9260426156618, 356701.6419694376, 356701.6419694371, 100338.4218269122], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 286200.0000, 
sim time next is 286800.0000, 
raw observation next is [23.33333333333334, 36.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5042649460279474, 6.9112, 6.9112, 121.9260426156618, 360050.7694774281, 360050.7694774281, 100997.300993555], 
processed observation next is [0.0, 0.30434782608695654, 0.4197530864197533, 0.3666666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.38033118253493414, 0.0, 0.0, 0.8094621288201359, 0.12858956052765289, 0.12858956052765289, 0.19422557883375963], 
reward next is 0.8058, 
noisyNet noise sample is [array([-0.9611089], dtype=float32), 0.522605]. 
=============================================
[2019-03-23 01:12:01,226] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1064998: loss 0.4708
[2019-03-23 01:12:01,233] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1064999: learning rate 0.0010
[2019-03-23 01:12:01,428] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1065089: loss 28.8367
[2019-03-23 01:12:01,432] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1065090: learning rate 0.0010
[2019-03-23 01:12:01,754] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1065236: loss 0.2269
[2019-03-23 01:12:01,756] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1065237: learning rate 0.0010
[2019-03-23 01:12:02,880] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1065748: loss 0.4707
[2019-03-23 01:12:02,880] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1065748: learning rate 0.0010
[2019-03-23 01:12:02,911] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.7022356e-01 7.9655747e-32 6.6656921e-27 2.2977640e-01 2.9661425e-12], sum to 1.0000
[2019-03-23 01:12:02,919] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1863
[2019-03-23 01:12:02,926] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1414217.760891982 W.
[2019-03-23 01:12:02,932] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.26666666666667, 42.0, 1.0, 2.0, 0.6010691933483745, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9620622837747225, 6.911199999999999, 6.9112, 121.9260426156618, 1414217.760891982, 1414217.760891983, 293399.7342347741], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 127200.0000, 
sim time next is 127800.0000, 
raw observation next is [31.65, 40.0, 1.0, 2.0, 0.617591696919871, 1.0, 1.0, 0.617591696919871, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1447782.85019919, 1447782.85019919, 276005.4301951317], 
processed observation next is [1.0, 0.4782608695652174, 0.7277777777777777, 0.4, 1.0, 1.0, 0.5447520201427036, 1.0, 0.5, 0.5447520201427036, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5170653036425679, 0.5170653036425679, 0.5307796734521764], 
reward next is 0.4692, 
noisyNet noise sample is [array([-0.2725229], dtype=float32), -0.053782873]. 
=============================================
[2019-03-23 01:12:03,350] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1065961: loss 2.1046
[2019-03-23 01:12:03,352] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1065961: learning rate 0.0010
[2019-03-23 01:12:04,139] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1066320: loss 0.1171
[2019-03-23 01:12:04,141] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1066320: learning rate 0.0010
[2019-03-23 01:12:04,423] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1066449: loss 1.2271
[2019-03-23 01:12:04,427] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1066450: learning rate 0.0010
[2019-03-23 01:12:04,526] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1066495: loss 1.1219
[2019-03-23 01:12:04,528] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1066495: loss 0.1277
[2019-03-23 01:12:04,530] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1066495: learning rate 0.0010
[2019-03-23 01:12:04,531] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1066496: learning rate 0.0010
[2019-03-23 01:12:04,576] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1066516: loss 0.9130
[2019-03-23 01:12:04,578] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1066516: learning rate 0.0010
[2019-03-23 01:12:04,986] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1066704: loss 0.1477
[2019-03-23 01:12:04,989] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1066704: learning rate 0.0010
[2019-03-23 01:12:05,052] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1066733: loss 0.2639
[2019-03-23 01:12:05,054] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1066733: learning rate 0.0010
[2019-03-23 01:12:05,063] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1066734: loss 0.1272
[2019-03-23 01:12:05,065] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1066734: learning rate 0.0010
[2019-03-23 01:12:06,596] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1067439: loss 0.0727
[2019-03-23 01:12:06,599] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1067439: learning rate 0.0010
[2019-03-23 01:12:07,689] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:12:07,702] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6389
[2019-03-23 01:12:07,708] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.3, 65.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6399385127152585, 6.911200000000001, 6.9112, 121.9260426156618, 476272.3008159592, 476272.3008159588, 135207.6524504185], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 868800.0000, 
sim time next is 869400.0000, 
raw observation next is [23.15, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6376080674803688, 6.911199999999999, 6.9112, 121.9260426156618, 474414.9371086915, 474414.937108692, 134870.6812537782], 
processed observation next is [0.0, 0.043478260869565216, 0.4129629629629629, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.547010084350461, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16943390611024697, 0.16943390611024714, 0.25936669471880425], 
reward next is 0.7406, 
noisyNet noise sample is [array([1.0649683], dtype=float32), 0.050421033]. 
=============================================
[2019-03-23 01:12:08,127] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1068140: loss 0.0340
[2019-03-23 01:12:08,133] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1068141: learning rate 0.0010
[2019-03-23 01:12:10,663] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1069304: loss 0.0289
[2019-03-23 01:12:10,666] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1069304: learning rate 0.0010
[2019-03-23 01:12:11,925] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:12:11,936] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0999
[2019-03-23 01:12:11,943] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.06666666666667, 51.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4527503627013359, 6.911199999999999, 6.9112, 121.9260426156618, 323261.0333711177, 323261.0333711182, 94680.38708746343], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 273000.0000, 
sim time next is 273600.0000, 
raw observation next is [20.0, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4511531928078509, 6.911199999999999, 6.9112, 121.9260426156618, 322120.4242055321, 322120.4242055326, 94363.3432876786], 
processed observation next is [0.0, 0.17391304347826086, 0.2962962962962963, 0.52, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.31394149100981356, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1150430086448329, 0.11504300864483306, 0.18146796786092037], 
reward next is 0.8185, 
noisyNet noise sample is [array([0.58254194], dtype=float32), -2.2118201]. 
=============================================
[2019-03-23 01:12:17,511] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.5587516e-10 0.0000000e+00 7.0322294e-31 1.1205923e-11 1.0000000e+00], sum to 1.0000
[2019-03-23 01:12:17,520] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2290
[2019-03-23 01:12:17,525] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.96666666666667, 27.66666666666667, 1.0, 2.0, 0.3039824604392677, 1.0, 2.0, 0.3039824604392677, 1.0, 2.0, 0.5092466034531964, 6.9112, 6.9112, 121.94756008, 1138691.900796383, 1138691.900796383, 254883.3367980399], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 387600.0000, 
sim time next is 388200.0000, 
raw observation next is [29.08333333333333, 27.33333333333333, 1.0, 2.0, 0.3066203586357902, 1.0, 2.0, 0.3066203586357902, 1.0, 2.0, 0.513328960863204, 6.911200000000001, 6.9112, 121.94756008, 1148048.055284298, 1148048.055284297, 255937.6893545483], 
processed observation next is [1.0, 0.4782608695652174, 0.6327160493827159, 0.27333333333333326, 1.0, 1.0, 0.1745480459949883, 1.0, 1.0, 0.1745480459949883, 1.0, 1.0, 0.391661201079005, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.41001716260153503, 0.4100171626015347, 0.4921878641433621], 
reward next is 0.5078, 
noisyNet noise sample is [array([-1.2029917], dtype=float32), -2.0584276]. 
=============================================
[2019-03-23 01:12:18,548] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1072904: loss 0.0332
[2019-03-23 01:12:18,550] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1072904: learning rate 0.0010
[2019-03-23 01:12:18,568] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1072911: loss 0.0807
[2019-03-23 01:12:18,570] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1072912: learning rate 0.0010
[2019-03-23 01:12:18,988] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1073103: loss 0.0361
[2019-03-23 01:12:18,990] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1073103: learning rate 0.0010
[2019-03-23 01:12:19,319] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 5.832699e-25], sum to 1.0000
[2019-03-23 01:12:19,329] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1824
[2019-03-23 01:12:19,336] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.28333333333333, 45.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.595723070305358, 6.9112, 6.9112, 121.9260426156618, 441085.5432829831, 441085.5432829831, 129261.3544812115], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 600600.0000, 
sim time next is 601200.0000, 
raw observation next is [26.1, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5914682146641194, 6.911200000000001, 6.9112, 121.9260426156618, 437666.8967051255, 437666.896705125, 128703.69511926], 
processed observation next is [1.0, 1.0, 0.5222222222222223, 0.46, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4893352683301492, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15630960596611626, 0.15630960596611607, 0.24750710599857692], 
reward next is 0.7525, 
noisyNet noise sample is [array([2.2734394], dtype=float32), -1.1006339]. 
=============================================
[2019-03-23 01:12:20,047] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1073586: loss 0.0364
[2019-03-23 01:12:20,048] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1073586: learning rate 0.0010
[2019-03-23 01:12:20,541] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1073808: loss 0.0411
[2019-03-23 01:12:20,543] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1073808: learning rate 0.0010
[2019-03-23 01:12:21,479] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1074242: loss 0.1530
[2019-03-23 01:12:21,482] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1074242: learning rate 0.0010
[2019-03-23 01:12:21,631] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1074308: loss 0.2880
[2019-03-23 01:12:21,637] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1074309: learning rate 0.0010
[2019-03-23 01:12:21,800] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1074383: loss 0.0578
[2019-03-23 01:12:21,803] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1074384: learning rate 0.0010
[2019-03-23 01:12:21,848] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1074405: loss 0.0301
[2019-03-23 01:12:21,850] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1074405: learning rate 0.0010
[2019-03-23 01:12:21,934] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1074444: loss 0.0378
[2019-03-23 01:12:21,937] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1074444: learning rate 0.0010
[2019-03-23 01:12:22,218] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1074572: loss 0.0261
[2019-03-23 01:12:22,221] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1074572: learning rate 0.0010
[2019-03-23 01:12:22,373] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1074644: loss 0.0341
[2019-03-23 01:12:22,378] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1074644: learning rate 0.0010
[2019-03-23 01:12:22,562] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1074727: loss 0.0611
[2019-03-23 01:12:22,566] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1074727: learning rate 0.0010
[2019-03-23 01:12:23,170] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 01:12:23,175] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:12:23,176] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:12:23,176] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:12:23,178] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:12:23,179] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:12:23,180] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:12:23,180] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:12:23,181] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:12:23,177] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:12:23,184] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:12:23,203] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run44
[2019-03-23 01:12:23,227] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run44
[2019-03-23 01:12:23,229] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run44
[2019-03-23 01:12:23,255] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run44
[2019-03-23 01:12:23,307] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run44
[2019-03-23 01:13:17,317] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10719933], dtype=float32), -0.34495604]
[2019-03-23 01:13:17,319] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.86233749666667, 69.13280215666667, 1.0, 2.0, 0.6650254839167669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757921.2156831276, 757921.2156831276, 169627.6629575648]
[2019-03-23 01:13:17,321] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:13:17,324] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.8561856e-28], sampled 0.8048932919404952
[2019-03-23 01:13:17,325] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 757921.2156831276 W.
[2019-03-23 01:13:29,635] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10719933], dtype=float32), -0.34495604]
[2019-03-23 01:13:29,636] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.2, 86.16666666666667, 1.0, 2.0, 0.5281898458990353, 1.0, 2.0, 0.5281898458990353, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156617, 1215194.603213702, 1215194.603213702, 244764.7002013341]
[2019-03-23 01:13:29,637] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:13:29,640] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9999976e-01 8.6715927e-31 1.4273161e-24 3.8769862e-08 1.9033831e-07], sampled 0.7754992233550366
[2019-03-23 01:13:29,642] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1215194.603213702 W.
[2019-03-23 01:13:32,719] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.10719933], dtype=float32), -0.34495604]
[2019-03-23 01:13:32,720] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.10366767666667, 94.17606928666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9283768085363056, 6.9112, 6.9112, 121.9260426156618, 673448.377784598, 673448.377784598, 180782.5539952612]
[2019-03-23 01:13:32,721] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:13:32,725] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 5.120868e-37], sampled 0.353686840693349
[2019-03-23 01:14:14,301] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10719933], dtype=float32), -0.34495604]
[2019-03-23 01:14:14,308] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.170914535, 43.94471377833334, 1.0, 2.0, 0.7039126908009968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 871536.8673822574, 871536.8673822574, 179627.9074747541]
[2019-03-23 01:14:14,310] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:14:14,312] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.3805188e-35 3.7592837e-26 3.3118224e-22 1.3268009e-14], sampled 0.9702941473777322
[2019-03-23 01:14:14,312] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 871536.8673822574 W.
[2019-03-23 01:14:14,684] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8662.1184 2217149920.0623 518.0000
[2019-03-23 01:14:15,102] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8422.7911 2333744264.2058 518.0000
[2019-03-23 01:14:15,124] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8596.8152 2254349922.7303 502.0000
[2019-03-23 01:14:15,447] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7938.9163 2527259786.1869 642.0000
[2019-03-23 01:14:15,452] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8447.4203 2293090276.4100 598.0000
[2019-03-23 01:14:16,467] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1075000, evaluation results [1075000.0, 7938.91625432588, 2527259786.186905, 642.0, 8596.815177089069, 2254349922.7303224, 502.0, 8662.118397392222, 2217149920.062303, 518.0, 8422.79107793896, 2333744264.2057996, 518.0, 8447.420348909118, 2293090276.409989, 598.0]
[2019-03-23 01:14:18,146] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1075772: loss 13.1086
[2019-03-23 01:14:18,148] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1075772: learning rate 0.0010
[2019-03-23 01:14:18,240] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.9352128e-30], sum to 1.0000
[2019-03-23 01:14:18,249] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8718
[2019-03-23 01:14:18,259] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.46666666666667, 47.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5717422269954027, 6.911199999999999, 6.9112, 121.9260426156618, 421654.4595051915, 421654.4595051919, 126099.4728232933], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 510600.0000, 
sim time next is 511200.0000, 
raw observation next is [25.2, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5698504442801479, 6.9112, 6.9112, 121.9260426156618, 419873.7658518215, 419873.7658518215, 125727.5039890159], 
processed observation next is [1.0, 0.9565217391304348, 0.4888888888888889, 0.48, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4623130553501848, 0.0, 0.0, 0.8094621288201359, 0.14995491637565053, 0.14995491637565053, 0.24178366151733827], 
reward next is 0.7582, 
noisyNet noise sample is [array([-1.4886153], dtype=float32), 0.13825047]. 
=============================================
[2019-03-23 01:14:19,382] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1076341: loss 13.9956
[2019-03-23 01:14:19,386] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1076342: learning rate 0.0010
[2019-03-23 01:14:21,838] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1077455: loss 13.7407
[2019-03-23 01:14:21,839] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1077456: learning rate 0.0010
[2019-03-23 01:14:25,272] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:14:25,278] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2145
[2019-03-23 01:14:25,282] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.66666666666667, 22.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6484748907236336, 6.9112, 6.9112, 121.9260426156618, 478964.2272798027, 478964.2272798027, 133584.5979597016], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 673800.0000, 
sim time next is 674400.0000, 
raw observation next is [32.43333333333334, 22.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6467208562058917, 6.9112, 6.9112, 121.9260426156618, 477304.4490015315, 477304.4490015315, 133216.0605064045], 
processed observation next is [1.0, 0.8260869565217391, 0.7567901234567903, 0.2266666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5584010702573646, 0.0, 0.0, 0.8094621288201359, 0.17046587464340412, 0.17046587464340412, 0.2561847317430856], 
reward next is 0.7438, 
noisyNet noise sample is [array([-1.092871], dtype=float32), 0.52051383]. 
=============================================
[2019-03-23 01:14:25,665] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:14:25,677] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3748
[2019-03-23 01:14:25,686] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 80.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6599242786417951, 6.911200000000001, 6.9112, 121.9260426156618, 492677.7867240984, 492677.7867240979, 138954.5656639212], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1289400.0000, 
sim time next is 1290000.0000, 
raw observation next is [21.6, 81.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6576795810007297, 6.911200000000001, 6.9112, 121.9260426156618, 490937.0195801846, 490937.0195801841, 138616.3835236553], 
processed observation next is [1.0, 0.9565217391304348, 0.3555555555555556, 0.8133333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5720994762509121, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17533464985006592, 0.17533464985006575, 0.26656996831472174], 
reward next is 0.7334, 
noisyNet noise sample is [array([1.4279962], dtype=float32), -0.8385428]. 
=============================================
[2019-03-23 01:14:25,705] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[68.483475]
 [68.52826 ]
 [68.54539 ]
 [68.56542 ]
 [68.46915 ]], R is [[68.50740051]
 [68.55510712]
 [68.60173035]
 [68.64730835]
 [68.69187164]].
[2019-03-23 01:14:29,674] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1081024: loss -123.4013
[2019-03-23 01:14:29,677] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1081025: learning rate 0.0010
[2019-03-23 01:14:29,695] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1081035: loss 50.7939
[2019-03-23 01:14:29,698] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1081036: learning rate 0.0010
[2019-03-23 01:14:30,110] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1081219: loss 51.0735
[2019-03-23 01:14:30,112] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1081220: learning rate 0.0010
[2019-03-23 01:14:31,340] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1081777: loss 37.4827
[2019-03-23 01:14:31,343] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1081778: learning rate 0.0010
[2019-03-23 01:14:31,891] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1082017: loss 56.6927
[2019-03-23 01:14:31,892] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1082017: learning rate 0.0010
[2019-03-23 01:14:32,565] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1082326: loss 51.3946
[2019-03-23 01:14:32,571] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1082327: learning rate 0.0010
[2019-03-23 01:14:32,685] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.83238755e-02 1.03037967e-21 1.06545895e-20 5.03257050e-26
 9.61676180e-01], sum to 1.0000
[2019-03-23 01:14:32,694] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8237
[2019-03-23 01:14:32,697] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.11666666666667, 23.0, 1.0, 2.0, 0.9591168644220266, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.501973463247308, 6.9112, 121.9235844889988, 1508882.632578595, 1206359.91588621, 235568.2879838767], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 744600.0000, 
sim time next is 745200.0000, 
raw observation next is [32.1, 23.0, 1.0, 2.0, 0.355297297493868, 1.0, 1.0, 0.355297297493868, 1.0, 1.0, 0.5860621057496868, 6.911199999999999, 6.9112, 121.94756008, 1314446.759102248, 1314446.759102248, 276288.09294713], 
processed observation next is [1.0, 0.6521739130434783, 0.7444444444444445, 0.23, 1.0, 1.0, 0.23249678273079527, 1.0, 0.5, 0.23249678273079527, 1.0, 0.5, 0.4825776321871084, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.46944527110794565, 0.46944527110794565, 0.5313232556675577], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5689138], dtype=float32), 0.8058357]. 
=============================================
[2019-03-23 01:14:32,856] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1082450: loss 50.6634
[2019-03-23 01:14:32,860] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1082451: learning rate 0.0010
[2019-03-23 01:14:32,943] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1082495: loss 36.0617
[2019-03-23 01:14:32,944] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1082496: learning rate 0.0010
[2019-03-23 01:14:32,986] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1082515: loss 49.6576
[2019-03-23 01:14:32,990] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1082516: learning rate 0.0010
[2019-03-23 01:14:33,180] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1082599: loss 45.9078
[2019-03-23 01:14:33,182] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1082599: learning rate 0.0010
[2019-03-23 01:14:33,396] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1082694: loss 55.0432
[2019-03-23 01:14:33,401] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1082696: learning rate 0.0010
[2019-03-23 01:14:33,675] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1082825: loss 49.1662
[2019-03-23 01:14:33,678] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1082826: learning rate 0.0010
[2019-03-23 01:14:33,742] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1082854: loss 51.5175
[2019-03-23 01:14:33,744] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1082854: learning rate 0.0010
[2019-03-23 01:14:35,052] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1083450: loss 0.3343
[2019-03-23 01:14:35,054] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1083450: learning rate 0.0010
[2019-03-23 01:14:35,626] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:14:35,632] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1565
[2019-03-23 01:14:35,638] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.5, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6720331944041132, 6.911200000000001, 6.9112, 121.9260426156618, 501739.6473098276, 501739.6473098272, 140247.8033947854], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 860400.0000, 
sim time next is 861000.0000, 
raw observation next is [25.35, 57.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6710387486945251, 6.9112, 6.9112, 121.9260426156618, 500957.4845463603, 500957.4845463603, 140076.8852831712], 
processed observation next is [0.0, 1.0, 0.4944444444444445, 0.575, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5887984358681563, 0.0, 0.0, 0.8094621288201359, 0.17891338733798584, 0.17891338733798584, 0.26937862554456], 
reward next is 0.7306, 
noisyNet noise sample is [array([-1.4328018], dtype=float32), -1.1949493]. 
=============================================
[2019-03-23 01:14:35,648] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[73.54742 ]
 [73.62604 ]
 [73.692345]
 [73.75678 ]
 [73.82293 ]], R is [[73.44676971]
 [73.44259644]
 [73.43933105]
 [73.43689728]
 [73.43493652]].
[2019-03-23 01:14:36,226] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1083982: loss 0.2208
[2019-03-23 01:14:36,228] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1083982: learning rate 0.0010
[2019-03-23 01:14:37,056] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.1443085e-33], sum to 1.0000
[2019-03-23 01:14:37,066] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0416
[2019-03-23 01:14:37,070] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.33333333333334, 37.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7152182454521364, 6.911200000000001, 6.9112, 121.9260426156618, 534146.760877282, 534146.7608772815, 147743.0529461366], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 822000.0000, 
sim time next is 822600.0000, 
raw observation next is [31.5, 37.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7190496908676002, 6.911200000000001, 6.9112, 121.9260426156618, 536928.9737933252, 536928.9737933248, 148313.7352797832], 
processed observation next is [0.0, 0.5217391304347826, 0.7222222222222222, 0.37, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6488121135845001, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19176034778333045, 0.1917603477833303, 0.2852187216918908], 
reward next is 0.7148, 
noisyNet noise sample is [array([0.06306718], dtype=float32), 0.4607332]. 
=============================================
[2019-03-23 01:14:38,839] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1085178: loss 0.1948
[2019-03-23 01:14:38,846] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1085178: learning rate 0.0010
[2019-03-23 01:14:39,623] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.0886289e-38], sum to 1.0000
[2019-03-23 01:14:39,633] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1821
[2019-03-23 01:14:39,639] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.16666666666667, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4939936800975059, 6.911199999999999, 6.9112, 121.9260426156618, 354409.694170025, 354409.6941700254, 115241.7152390262], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1128000.0000, 
sim time next is 1128600.0000, 
raw observation next is [19.15, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4938253675198766, 6.9112, 6.9112, 121.9260426156618, 354170.1565556718, 354170.1565556718, 115187.7801225105], 
processed observation next is [1.0, 0.043478260869565216, 0.2648148148148148, 0.74, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3672817093998457, 0.0, 0.0, 0.8094621288201359, 0.12648934162702566, 0.12648934162702566, 0.22151496177405866], 
reward next is 0.7785, 
noisyNet noise sample is [array([0.796637], dtype=float32), -0.5476308]. 
=============================================
[2019-03-23 01:14:40,362] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:14:40,374] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6068
[2019-03-23 01:14:40,379] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.4, 65.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5670044032273566, 6.911199999999999, 6.9112, 121.9260426156618, 414404.7320090333, 414404.7320090338, 123885.8967230845], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 879600.0000, 
sim time next is 880200.0000, 
raw observation next is [21.3, 65.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5605648372643577, 6.9112, 6.9112, 121.9260426156618, 408958.342293522, 408958.342293522, 123018.046987038], 
processed observation next is [0.0, 0.17391304347826086, 0.3444444444444445, 0.655, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45070604658044705, 0.0, 0.0, 0.8094621288201359, 0.14605655081911498, 0.14605655081911498, 0.2365731672827654], 
reward next is 0.7634, 
noisyNet noise sample is [array([0.17668465], dtype=float32), -0.24614303]. 
=============================================
[2019-03-23 01:14:47,037] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1088911: loss 0.3319
[2019-03-23 01:14:47,039] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1088911: learning rate 0.0010
[2019-03-23 01:14:47,123] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1088955: loss 0.2558
[2019-03-23 01:14:47,131] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1088956: learning rate 0.0010
[2019-03-23 01:14:47,403] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1089075: loss 0.2175
[2019-03-23 01:14:47,404] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1089075: learning rate 0.0010
[2019-03-23 01:14:48,609] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1089631: loss 0.1873
[2019-03-23 01:14:48,610] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1089631: learning rate 0.0010
[2019-03-23 01:14:49,175] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1089889: loss 0.1163
[2019-03-23 01:14:49,178] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1089891: learning rate 0.0010
[2019-03-23 01:14:49,842] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1090194: loss 0.3253
[2019-03-23 01:14:49,845] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1090195: learning rate 0.0010
[2019-03-23 01:14:50,227] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1090371: loss 0.2475
[2019-03-23 01:14:50,232] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1090371: learning rate 0.0010
[2019-03-23 01:14:50,236] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1090374: loss 0.2542
[2019-03-23 01:14:50,238] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1090375: learning rate 0.0010
[2019-03-23 01:14:50,248] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1090379: loss 0.2891
[2019-03-23 01:14:50,250] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1090379: learning rate 0.0010
[2019-03-23 01:14:50,477] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1090484: loss 0.2457
[2019-03-23 01:14:50,480] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1090486: learning rate 0.0010
[2019-03-23 01:14:50,626] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1090549: loss 0.2446
[2019-03-23 01:14:50,630] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1090550: learning rate 0.0010
[2019-03-23 01:14:50,910] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 5.1950278e-36 4.6687662e-35], sum to 1.0000
[2019-03-23 01:14:50,916] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4655
[2019-03-23 01:14:50,924] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.7, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5758084461689269, 6.9112, 6.9112, 121.9260426156618, 425891.0697441535, 425891.0697441535, 127158.4238283086], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1317600.0000, 
sim time next is 1318200.0000, 
raw observation next is [19.93333333333333, 85.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6118626773132825, 6.911200000000001, 6.9112, 121.9260426156618, 453123.1915112764, 453123.1915112759, 130823.7720392104], 
processed observation next is [1.0, 0.2608695652173913, 0.293827160493827, 0.8516666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.514828346641603, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1618297112540273, 0.1618297112540271, 0.2515841769984815], 
reward next is 0.7484, 
noisyNet noise sample is [array([-0.51611155], dtype=float32), -0.16964613]. 
=============================================
[2019-03-23 01:14:51,108] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1090769: loss 0.3762
[2019-03-23 01:14:51,112] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1090771: learning rate 0.0010
[2019-03-23 01:14:51,143] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1090786: loss 0.4006
[2019-03-23 01:14:51,145] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1090786: learning rate 0.0010
[2019-03-23 01:14:53,350] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1091763: loss -194.4401
[2019-03-23 01:14:53,352] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1091764: learning rate 0.0010
[2019-03-23 01:14:53,757] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:14:53,772] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2001
[2019-03-23 01:14:53,779] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.3, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6017766037209293, 6.911200000000001, 6.9112, 121.9260426156618, 444038.8394040153, 444038.8394040149, 128943.5157934731], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1305000.0000, 
sim time next is 1305600.0000, 
raw observation next is [19.23333333333333, 87.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5840144606092259, 6.9112, 6.9112, 121.9260426156618, 430791.3083508852, 430791.3083508852, 127247.2649149982], 
processed observation next is [1.0, 0.08695652173913043, 0.26790123456790116, 0.8733333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4800180757615323, 0.0, 0.0, 0.8094621288201359, 0.15385403869674472, 0.15385403869674472, 0.24470627868268885], 
reward next is 0.7553, 
noisyNet noise sample is [array([-0.46908468], dtype=float32), -0.84752756]. 
=============================================
[2019-03-23 01:14:54,232] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1092167: loss -62.3075
[2019-03-23 01:14:54,236] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1092168: learning rate 0.0010
[2019-03-23 01:14:56,830] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1093352: loss -36.7654
[2019-03-23 01:14:56,834] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1093353: learning rate 0.0010
[2019-03-23 01:14:58,159] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 6.7611709e-33 4.8220576e-29], sum to 1.0000
[2019-03-23 01:14:58,164] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9850
[2019-03-23 01:14:58,173] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.06666666666667, 82.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5911150158173831, 6.911200000000001, 6.9112, 121.9260426156618, 437124.0545315489, 437124.0545315485, 128503.9120362042], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1194600.0000, 
sim time next is 1195200.0000, 
raw observation next is [20.0, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5890889798343881, 6.911199999999999, 6.9112, 121.9260426156618, 435611.5050395669, 435611.5050395674, 128309.5629997572], 
processed observation next is [1.0, 0.8695652173913043, 0.2962962962962963, 0.83, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4863612247929851, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15557553751413103, 0.15557553751413122, 0.2467491596149177], 
reward next is 0.7533, 
noisyNet noise sample is [array([-0.44420323], dtype=float32), -0.6138258]. 
=============================================
[2019-03-23 01:15:04,823] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1097000: loss -126.5082
[2019-03-23 01:15:04,827] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1097000: learning rate 0.0010
[2019-03-23 01:15:04,902] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1097036: loss 1.9324
[2019-03-23 01:15:04,907] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1097039: learning rate 0.0010
[2019-03-23 01:15:05,118] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1097136: loss 1.3447
[2019-03-23 01:15:05,120] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1097136: learning rate 0.0010
[2019-03-23 01:15:06,542] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1097782: loss 24.2738
[2019-03-23 01:15:06,547] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1097782: learning rate 0.0010
[2019-03-23 01:15:06,998] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1097993: loss -8.7013
[2019-03-23 01:15:07,001] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1097993: learning rate 0.0010
[2019-03-23 01:15:07,674] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1098282: loss -39.4088
[2019-03-23 01:15:07,676] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1098282: learning rate 0.0010
[2019-03-23 01:15:07,971] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1098393: loss -17.6817
[2019-03-23 01:15:07,974] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1098393: learning rate 0.0010
[2019-03-23 01:15:08,086] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1098440: loss -307.3843
[2019-03-23 01:15:08,088] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1098440: learning rate 0.0010
[2019-03-23 01:15:08,099] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1098445: loss -123.8356
[2019-03-23 01:15:08,101] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1098445: learning rate 0.0010
[2019-03-23 01:15:08,308] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1098522: loss -206.3029
[2019-03-23 01:15:08,311] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1098523: learning rate 0.0010
[2019-03-23 01:15:08,573] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1098628: loss -20.6878
[2019-03-23 01:15:08,576] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1098629: learning rate 0.0010
[2019-03-23 01:15:09,152] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1098911: loss -194.2764
[2019-03-23 01:15:09,154] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1098911: learning rate 0.0010
[2019-03-23 01:15:09,194] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1098927: loss 2.7250
[2019-03-23 01:15:09,197] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1098927: learning rate 0.0010
[2019-03-23 01:15:10,676] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1099632: loss 0.1243
[2019-03-23 01:15:10,678] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1099632: learning rate 0.0010
[2019-03-23 01:15:11,469] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 01:15:11,472] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:15:11,473] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:15:11,473] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:15:11,474] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:15:11,475] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:15:11,474] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:15:11,476] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:15:11,476] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:15:11,476] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:15:11,477] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:15:11,503] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run45
[2019-03-23 01:15:11,528] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run45
[2019-03-23 01:15:11,552] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run45
[2019-03-23 01:15:11,583] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run45
[2019-03-23 01:15:11,604] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run45
[2019-03-23 01:15:18,055] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.1193524], dtype=float32), -0.39278013]
[2019-03-23 01:15:18,056] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.94705349, 34.50914291, 1.0, 2.0, 0.7880722742396258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 981438.0559825955, 981438.0559825955, 196793.7253596442]
[2019-03-23 01:15:18,057] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:15:18,059] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.1553162e-01 2.6503075e-32 8.8908797e-24 3.8446832e-01 4.2457424e-17], sampled 0.7343820426581282
[2019-03-23 01:15:22,874] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.1193524], dtype=float32), -0.39278013]
[2019-03-23 01:15:22,878] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.53333333333333, 35.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5652713335445406, 6.911200000000001, 6.9112, 121.9260426156618, 413866.4897098139, 413866.4897098134, 124056.8006176957]
[2019-03-23 01:15:22,879] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:15:22,882] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3789002498058035
[2019-03-23 01:15:42,012] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.1193524], dtype=float32), -0.39278013]
[2019-03-23 01:15:42,013] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.91185028333333, 73.42129448166666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8926780211617809, 6.9112, 6.9112, 121.9260426156618, 649882.8294066482, 649882.8294066482, 175601.0788870761]
[2019-03-23 01:15:42,014] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:15:42,016] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4530732523170198
[2019-03-23 01:15:51,903] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.1193524], dtype=float32), -0.39278013]
[2019-03-23 01:15:51,904] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.48431618, 72.577564695, 1.0, 2.0, 0.7103360701319473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 809588.3949332931, 809588.3949332931, 178108.4882717628]
[2019-03-23 01:15:51,907] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:15:51,910] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 4.3849766e-29 2.1779975e-08 8.8646882e-22], sampled 0.47468557611275997
[2019-03-23 01:15:51,911] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 809588.3949332931 W.
[2019-03-23 01:15:58,768] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.1193524], dtype=float32), -0.39278013]
[2019-03-23 01:15:58,769] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.5, 57.0, 1.0, 2.0, 0.6421166039369518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426075341, 734853.8733361773, 734853.8733361773, 165626.8975199097]
[2019-03-23 01:15:58,770] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:15:58,774] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.00000000e+00 0.00000000e+00 0.00000000e+00 1.00358025e-16
 3.83434541e-36], sampled 0.22486955208091086
[2019-03-23 01:15:58,775] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 734853.8733361773 W.
[2019-03-23 01:17:00,379] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.1193524], dtype=float32), -0.39278013]
[2019-03-23 01:17:00,381] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.66666666666666, 27.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5557086012621217, 6.9112, 6.9112, 121.9260426156618, 396791.6127407072, 396791.6127407072, 117061.556796797]
[2019-03-23 01:17:00,383] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:17:00,386] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9656794244726302
[2019-03-23 01:17:03,447] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8679.4733 2247475362.7868 360.0000
[2019-03-23 01:17:03,558] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8073.4335 2503537756.2435 499.0000
[2019-03-23 01:17:03,876] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8731.7999 2211585968.9420 372.0000
[2019-03-23 01:17:03,943] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8524.4765 2316485571.4832 385.0000
[2019-03-23 01:17:04,016] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8563.1867 2278008370.4538 432.0000
[2019-03-23 01:17:05,034] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1100000, evaluation results [1100000.0, 8073.433474860678, 2503537756.2435274, 499.0, 8679.473349069354, 2247475362.786835, 360.0, 8731.799913180499, 2211585968.941958, 372.0, 8524.476500155484, 2316485571.4832478, 385.0, 8563.186702678258, 2278008370.453811, 432.0]
[2019-03-23 01:17:05,170] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1100072: loss 0.0854
[2019-03-23 01:17:05,176] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1100072: learning rate 0.0010
[2019-03-23 01:17:07,854] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1101289: loss 0.4687
[2019-03-23 01:17:07,856] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1101290: learning rate 0.0010
[2019-03-23 01:17:13,798] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.5927134e-37 9.4955060e-33], sum to 1.0000
[2019-03-23 01:17:13,806] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0033
[2019-03-23 01:17:13,814] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.46666666666667, 90.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5489317030182228, 6.911200000000001, 6.9112, 121.9260426156618, 402703.8325698979, 402703.8325698974, 123021.414559417], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1815600.0000, 
sim time next is 1816200.0000, 
raw observation next is [18.45, 90.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5495339875939582, 6.911200000000001, 6.9112, 121.9260426156618, 403160.4601987688, 403160.4601987683, 123079.9698853423], 
processed observation next is [1.0, 0.0, 0.23888888888888887, 0.905, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4369174844924477, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14398587864241744, 0.14398587864241724, 0.23669224977950443], 
reward next is 0.7633, 
noisyNet noise sample is [array([-0.5408609], dtype=float32), -0.022648834]. 
=============================================
[2019-03-23 01:17:15,618] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.99997258e-01 0.00000000e+00 1.16153145e-30 2.76250535e-06
 4.91165289e-16], sum to 1.0000
[2019-03-23 01:17:15,624] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4363
[2019-03-23 01:17:15,630] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 871478.3485273995 W.
[2019-03-23 01:17:15,638] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.7, 77.0, 1.0, 2.0, 0.7016254894231534, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 871478.3485273995, 871478.3485273995, 179247.7330225273], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1848600.0000, 
sim time next is 1849200.0000, 
raw observation next is [21.73333333333333, 77.0, 1.0, 2.0, 0.3553001569778301, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5872191660624815, 6.911199999999999, 6.9112, 121.9260426156618, 877642.5560647104, 877642.5560647108, 207467.8256808424], 
processed observation next is [1.0, 0.391304347826087, 0.3604938271604937, 0.77, 1.0, 1.0, 0.23250018687836915, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.4840239575781018, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31344377002311086, 0.313443770023111, 0.39897658784777384], 
reward next is 0.6010, 
noisyNet noise sample is [array([0.46711293], dtype=float32), -0.18349814]. 
=============================================
[2019-03-23 01:17:15,722] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1104899: loss 0.4466
[2019-03-23 01:17:15,723] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1104899: learning rate 0.0010
[2019-03-23 01:17:15,977] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1105015: loss 0.1691
[2019-03-23 01:17:15,981] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1105016: learning rate 0.0010
[2019-03-23 01:17:16,343] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1105183: loss 79.3602
[2019-03-23 01:17:16,347] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1105183: learning rate 0.0010
[2019-03-23 01:17:16,894] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.8895366e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 01:17:16,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6343
[2019-03-23 01:17:16,912] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.7, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5505644310826548, 6.911199999999999, 6.9112, 121.9260426156618, 403607.0220586109, 403607.0220586113, 123024.8125655416], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1810800.0000, 
sim time next is 1811400.0000, 
raw observation next is [18.66666666666667, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5500412051978689, 6.9112, 6.9112, 121.9260426156618, 403319.8982350342, 403319.8982350342, 123024.5208943414], 
processed observation next is [1.0, 1.0, 0.24691358024691376, 0.8833333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4375515064973361, 0.0, 0.0, 0.8094621288201359, 0.1440428207982265, 0.1440428207982265, 0.2365856171045027], 
reward next is 0.7634, 
noisyNet noise sample is [array([0.52492607], dtype=float32), -1.5543926]. 
=============================================
[2019-03-23 01:17:17,221] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1105578: loss 0.2664
[2019-03-23 01:17:17,223] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1105579: learning rate 0.0010
[2019-03-23 01:17:17,322] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:17:17,330] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6065
[2019-03-23 01:17:17,339] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.76666666666667, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5679026930189166, 6.911199999999999, 6.9112, 121.9260426156618, 413928.9163509767, 413928.9163509772, 123485.7860607681], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1657200.0000, 
sim time next is 1657800.0000, 
raw observation next is [18.55, 85.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5563359229845112, 6.9112, 6.9112, 121.9260426156618, 405264.0766751649, 405264.0766751649, 122406.464187503], 
processed observation next is [1.0, 0.17391304347826086, 0.2425925925925926, 0.855, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44541990373063894, 0.0, 0.0, 0.8094621288201359, 0.14473717024113034, 0.14473717024113034, 0.23539704651442886], 
reward next is 0.7646, 
noisyNet noise sample is [array([1.544803], dtype=float32), -2.2703378]. 
=============================================
[2019-03-23 01:17:17,881] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1105883: loss 0.0816
[2019-03-23 01:17:17,883] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1105883: learning rate 0.0010
[2019-03-23 01:17:18,615] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1106215: loss 0.2385
[2019-03-23 01:17:18,618] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1106215: learning rate 0.0010
[2019-03-23 01:17:18,710] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1106258: loss 0.2493
[2019-03-23 01:17:18,712] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1106259: learning rate 0.0010
[2019-03-23 01:17:18,791] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1106294: loss 0.2340
[2019-03-23 01:17:18,798] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1106297: learning rate 0.0010
[2019-03-23 01:17:18,809] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1106302: loss 0.2081
[2019-03-23 01:17:18,811] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1106304: learning rate 0.0010
[2019-03-23 01:17:19,130] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1106451: loss 0.2699
[2019-03-23 01:17:19,131] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1106451: learning rate 0.0010
[2019-03-23 01:17:19,312] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1106531: loss 0.1680
[2019-03-23 01:17:19,316] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1106531: learning rate 0.0010
[2019-03-23 01:17:20,067] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1106873: loss 0.1729
[2019-03-23 01:17:20,071] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1106874: learning rate 0.0010
[2019-03-23 01:17:20,103] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1106895: loss 0.1858
[2019-03-23 01:17:20,105] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1106895: learning rate 0.0010
[2019-03-23 01:17:21,899] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1107714: loss -97.3328
[2019-03-23 01:17:21,904] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1107714: learning rate 0.0010
[2019-03-23 01:17:22,981] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1108209: loss -43.1334
[2019-03-23 01:17:22,983] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1108209: learning rate 0.0010
[2019-03-23 01:17:25,307] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.3071687e-03 4.0762990e-38 2.4346235e-33 9.9469286e-01 9.5636955e-20], sum to 1.0000
[2019-03-23 01:17:25,321] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6847
[2019-03-23 01:17:25,325] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:17:25,329] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.58333333333333, 68.33333333333334, 1.0, 2.0, 0.4635284062096365, 1.0, 2.0, 0.4635284062096365, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1109074.034739468, 1109074.034739469, 226577.8287016024], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1767000.0000, 
sim time next is 1767600.0000, 
raw observation next is [24.7, 68.0, 1.0, 2.0, 0.4860133214931208, 1.0, 2.0, 0.4860133214931208, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1162731.207680773, 1162731.207680773, 233443.2386757972], 
processed observation next is [1.0, 0.4782608695652174, 0.4703703703703703, 0.68, 1.0, 1.0, 0.38811109701562, 1.0, 1.0, 0.38811109701562, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.41526114560027605, 0.41526114560027605, 0.44892930514576385], 
reward next is 0.5511, 
noisyNet noise sample is [array([-0.15994556], dtype=float32), -0.36851323]. 
=============================================
[2019-03-23 01:17:25,337] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2950
[2019-03-23 01:17:25,341] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.06666666666667, 87.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6268239092629985, 6.9112, 6.9112, 121.9260426156618, 466161.2484356064, 466161.2484356064, 133619.5779640905], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1743600.0000, 
sim time next is 1744200.0000, 
raw observation next is [20.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6178837878521322, 6.911200000000001, 6.9112, 121.9260426156618, 459425.143276196, 459425.1432761955, 132680.6583655689], 
processed observation next is [1.0, 0.17391304347826086, 0.2962962962962963, 0.88, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5223547348151651, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16408040831292714, 0.16408040831292697, 0.25515511224147863], 
reward next is 0.7448, 
noisyNet noise sample is [array([0.15304779], dtype=float32), 0.92904645]. 
=============================================
[2019-03-23 01:17:25,516] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1109369: loss 37.5106
[2019-03-23 01:17:25,517] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1109369: learning rate 0.0010
[2019-03-23 01:17:28,924] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.5159218e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 01:17:28,934] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5649
[2019-03-23 01:17:28,945] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 691428.2631285499 W.
[2019-03-23 01:17:28,951] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.9, 75.0, 1.0, 2.0, 0.303354319464507, 1.0, 2.0, 0.303354319464507, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 691428.2631285499, 691428.2631285504, 181267.5805703168], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2059200.0000, 
sim time next is 2059800.0000, 
raw observation next is [26.75, 75.33333333333333, 1.0, 2.0, 0.3017633263518829, 1.0, 2.0, 0.3017633263518829, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 687800.3236812069, 687800.3236812069, 180884.3320950442], 
processed observation next is [0.0, 0.8695652173913043, 0.5462962962962963, 0.7533333333333333, 1.0, 1.0, 0.16876586470462251, 1.0, 1.0, 0.16876586470462251, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24564297274328817, 0.24564297274328817, 0.34785448479816194], 
reward next is 0.6521, 
noisyNet noise sample is [array([-0.34812564], dtype=float32), -1.9463699]. 
=============================================
[2019-03-23 01:17:33,443] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1112969: loss -13.0367
[2019-03-23 01:17:33,446] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1112969: learning rate 0.0010
[2019-03-23 01:17:33,597] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1113041: loss 3.9329
[2019-03-23 01:17:33,599] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1113041: learning rate 0.0010
[2019-03-23 01:17:33,916] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1113185: loss 0.5182
[2019-03-23 01:17:33,918] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1113185: learning rate 0.0010
[2019-03-23 01:17:35,016] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1113692: loss -31.0410
[2019-03-23 01:17:35,021] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1113692: learning rate 0.0010
[2019-03-23 01:17:35,467] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1113898: loss 1.9374
[2019-03-23 01:17:35,470] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1113899: learning rate 0.0010
[2019-03-23 01:17:35,878] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0093865e-14 0.0000000e+00 4.1317009e-31 1.0000000e+00 5.3204743e-22], sum to 1.0000
[2019-03-23 01:17:35,885] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2991
[2019-03-23 01:17:35,890] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.13333333333333, 86.66666666666667, 1.0, 2.0, 0.39239374060222, 1.0, 1.0, 0.39239374060222, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 939902.2245810177, 939902.2245810177, 206051.7308901576], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1938000.0000, 
sim time next is 1938600.0000, 
raw observation next is [22.25, 86.5, 1.0, 2.0, 0.3857767505387788, 1.0, 2.0, 0.3857767505387788, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 922777.8427010118, 922777.8427010123, 204182.7396058012], 
processed observation next is [1.0, 0.43478260869565216, 0.37962962962962965, 0.865, 1.0, 1.0, 0.2687818458794986, 1.0, 1.0, 0.2687818458794986, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32956351525036137, 0.32956351525036154, 0.3926591146265408], 
reward next is 0.6073, 
noisyNet noise sample is [array([0.3896746], dtype=float32), -1.1260734]. 
=============================================
[2019-03-23 01:17:35,896] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:17:35,906] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3280
[2019-03-23 01:17:35,913] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.4, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6097179524550761, 6.911200000000001, 6.9112, 121.9260426156618, 452837.8127605354, 452837.8127605349, 131499.0370750023], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1998000.0000, 
sim time next is 1998600.0000, 
raw observation next is [19.38333333333333, 92.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6101728157752069, 6.9112, 6.9112, 121.9260426156618, 453233.5909820479, 453233.5909820479, 131585.1562218275], 
processed observation next is [0.0, 0.13043478260869565, 0.27345679012345664, 0.9216666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5127160197190086, 0.0, 0.0, 0.8094621288201359, 0.16186913963644567, 0.16186913963644567, 0.25304837734966823], 
reward next is 0.7470, 
noisyNet noise sample is [array([-0.43662718], dtype=float32), 2.09999]. 
=============================================
[2019-03-23 01:17:36,270] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1114262: loss -7.6312
[2019-03-23 01:17:36,272] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1114262: learning rate 0.0010
[2019-03-23 01:17:36,352] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1114297: loss -9.1525
[2019-03-23 01:17:36,353] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1114298: learning rate 0.0010
[2019-03-23 01:17:36,436] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1114340: loss 3.7015
[2019-03-23 01:17:36,441] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1114342: learning rate 0.0010
[2019-03-23 01:17:36,472] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1114353: loss -84.8501
[2019-03-23 01:17:36,475] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1114354: learning rate 0.0010
[2019-03-23 01:17:36,823] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1114513: loss 0.4932
[2019-03-23 01:17:36,827] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1114514: learning rate 0.0010
[2019-03-23 01:17:36,925] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1114563: loss 0.2353
[2019-03-23 01:17:36,933] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1114567: learning rate 0.0010
[2019-03-23 01:17:37,794] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1114961: loss -12.9022
[2019-03-23 01:17:37,797] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1114962: learning rate 0.0010
[2019-03-23 01:17:37,921] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1115014: loss 2.5978
[2019-03-23 01:17:37,924] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1115015: learning rate 0.0010
[2019-03-23 01:17:38,253] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:17:38,261] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3690
[2019-03-23 01:17:38,264] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.53333333333333, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6130041373919772, 6.911199999999999, 6.9112, 121.9260426156618, 455247.0674391703, 455247.0674391708, 131789.7728118257], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1986000.0000, 
sim time next is 1986600.0000, 
raw observation next is [19.51666666666667, 90.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6125229048356146, 6.9112, 6.9112, 121.9260426156618, 454900.6736348627, 454900.6736348627, 131751.8257811827], 
processed observation next is [1.0, 1.0, 0.2783950617283952, 0.9083333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5156536310445181, 0.0, 0.0, 0.8094621288201359, 0.16246452629816524, 0.16246452629816524, 0.25336889573304366], 
reward next is 0.7466, 
noisyNet noise sample is [array([-0.15807667], dtype=float32), 0.49143916]. 
=============================================
[2019-03-23 01:17:39,388] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1115687: loss 32.7805
[2019-03-23 01:17:39,391] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1115687: learning rate 0.0010
[2019-03-23 01:17:40,405] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1116157: loss 41.4660
[2019-03-23 01:17:40,407] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1116157: learning rate 0.0010
[2019-03-23 01:17:43,013] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1117349: loss -107.3715
[2019-03-23 01:17:43,016] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1117350: learning rate 0.0010
[2019-03-23 01:17:46,308] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:17:46,318] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9313
[2019-03-23 01:17:46,325] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.46666666666667, 88.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7569626513981861, 6.911200000000001, 6.9112, 121.9260426156618, 563854.2577225622, 563854.2577225617, 154106.9054012732], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2101200.0000, 
sim time next is 2101800.0000, 
raw observation next is [22.58333333333334, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7625323748962953, 6.9112, 6.9112, 121.9260426156618, 567753.6552885142, 567753.6552885142, 154946.3775215261], 
processed observation next is [0.0, 0.30434782608695654, 0.39197530864197555, 0.8833333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7031654686203692, 0.0, 0.0, 0.8094621288201359, 0.2027691626030408, 0.2027691626030408, 0.2979738029260117], 
reward next is 0.7020, 
noisyNet noise sample is [array([-2.0600822], dtype=float32), 0.94551927]. 
=============================================
[2019-03-23 01:17:50,727] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1120834: loss 5.6551
[2019-03-23 01:17:50,728] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1120834: learning rate 0.0010
[2019-03-23 01:17:51,181] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1121000: loss -43.6223
[2019-03-23 01:17:51,187] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1121002: learning rate 0.0010
[2019-03-23 01:17:51,909] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1121331: loss 0.2317
[2019-03-23 01:17:51,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1121331: learning rate 0.0010
[2019-03-23 01:17:51,982] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:17:51,989] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4266
[2019-03-23 01:17:51,993] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.75, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8489544215188005, 6.9112, 6.9112, 121.9260426156618, 627987.161123342, 627987.161123342, 167502.044752534], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2856600.0000, 
sim time next is 2857200.0000, 
raw observation next is [22.66666666666667, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.839282140378797, 6.911200000000001, 6.9112, 121.9260426156618, 621748.3819943079, 621748.3819943074, 165943.7571723617], 
processed observation next is [1.0, 0.043478260869565216, 0.39506172839506193, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7991026754734961, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22205299356939567, 0.2220529935693955, 0.3191226099468494], 
reward next is 0.6809, 
noisyNet noise sample is [array([-0.88045406], dtype=float32), 0.68416667]. 
=============================================
[2019-03-23 01:17:52,605] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1121653: loss -13.3611
[2019-03-23 01:17:52,610] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1121657: learning rate 0.0010
[2019-03-23 01:17:53,012] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1121844: loss -12.6954
[2019-03-23 01:17:53,016] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1121846: learning rate 0.0010
[2019-03-23 01:17:53,861] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1122250: loss -12.1975
[2019-03-23 01:17:53,863] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1122250: loss -15.6918
[2019-03-23 01:17:53,865] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1122253: learning rate 0.0010
[2019-03-23 01:17:53,867] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1122253: learning rate 0.0010
[2019-03-23 01:17:53,917] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1122278: loss 39.3903
[2019-03-23 01:17:53,920] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1122278: learning rate 0.0010
[2019-03-23 01:17:53,990] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1122306: loss 35.1431
[2019-03-23 01:17:53,992] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1122306: learning rate 0.0010
[2019-03-23 01:17:54,415] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1122508: loss -49.4470
[2019-03-23 01:17:54,418] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1122509: learning rate 0.0010
[2019-03-23 01:17:54,437] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1122519: loss 12.5595
[2019-03-23 01:17:54,439] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1122519: learning rate 0.0010
[2019-03-23 01:17:55,328] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1122936: loss -57.2012
[2019-03-23 01:17:55,330] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1122937: learning rate 0.0010
[2019-03-23 01:17:55,421] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1122974: loss 41.4001
[2019-03-23 01:17:55,424] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1122974: learning rate 0.0010
[2019-03-23 01:17:56,920] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1123675: loss -109.5099
[2019-03-23 01:17:56,922] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1123675: learning rate 0.0010
[2019-03-23 01:17:57,686] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:17:57,693] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8840
[2019-03-23 01:17:57,699] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.16666666666667, 76.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7768085378111421, 6.911200000000001, 6.9112, 121.9260426156618, 578402.3970495828, 578402.3970495823, 156654.7324344631], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2319000.0000, 
sim time next is 2319600.0000, 
raw observation next is [24.03333333333333, 77.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7723490708363018, 6.9112, 6.9112, 121.9260426156618, 575195.9662584868, 575195.9662584868, 156036.3823912499], 
processed observation next is [1.0, 0.8695652173913043, 0.4456790123456789, 0.7733333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7154363385453771, 0.0, 0.0, 0.8094621288201359, 0.20542713080660244, 0.20542713080660244, 0.30006996613701903], 
reward next is 0.6999, 
noisyNet noise sample is [array([-1.6836326], dtype=float32), -0.43285286]. 
=============================================
[2019-03-23 01:17:57,856] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1124114: loss -138.8275
[2019-03-23 01:17:57,858] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1124114: learning rate 0.0010
[2019-03-23 01:17:58,493] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:17:58,500] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4689
[2019-03-23 01:17:58,506] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.93333333333333, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7627663111569172, 6.9112, 6.9112, 121.9260426156618, 568371.08323437, 568371.08323437, 154654.2951145762], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2334000.0000, 
sim time next is 2334600.0000, 
raw observation next is [21.95, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7649706026578578, 6.9112, 6.9112, 121.9260426156618, 569893.5320236493, 569893.5320236493, 155009.2177966414], 
processed observation next is [1.0, 0.0, 0.36851851851851847, 0.925, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7062132533223222, 0.0, 0.0, 0.8094621288201359, 0.20353340429416047, 0.20353340429416047, 0.2980946496089258], 
reward next is 0.7019, 
noisyNet noise sample is [array([0.67598903], dtype=float32), 0.6980008]. 
=============================================
[2019-03-23 01:17:59,754] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 01:17:59,756] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:17:59,756] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:17:59,757] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:17:59,757] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:17:59,758] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:17:59,758] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:17:59,759] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:17:59,760] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:17:59,761] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:17:59,762] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:17:59,788] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run46
[2019-03-23 01:17:59,789] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run46
[2019-03-23 01:17:59,832] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run46
[2019-03-23 01:17:59,833] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run46
[2019-03-23 01:17:59,873] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run46
[2019-03-23 01:18:07,259] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00464116], dtype=float32), -0.3938317]
[2019-03-23 01:18:07,261] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.1, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4305151104329004, 6.9112, 6.9112, 121.9260426156618, 307382.0157680365, 307382.0157680365, 101414.5443748098]
[2019-03-23 01:18:07,262] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:18:07,266] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5883670402439576
[2019-03-23 01:18:27,371] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00464116], dtype=float32), -0.3938317]
[2019-03-23 01:18:27,374] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.5, 59.33333333333334, 1.0, 2.0, 0.6403955804787111, 1.0, 1.0, 0.6403955804787111, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1471206.257560717, 1471206.257560718, 282757.7198431731]
[2019-03-23 01:18:27,376] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:18:27,380] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.562728e-19 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00], sampled 0.38059532370075755
[2019-03-23 01:18:47,912] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00464116], dtype=float32), -0.3938317]
[2019-03-23 01:18:47,912] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.0, 94.0, 1.0, 2.0, 0.741419991478717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 845035.0739355179, 845035.0739355179, 184130.0646707937]
[2019-03-23 01:18:47,917] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:18:47,920] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.3785345e-32 0.0000000e+00], sampled 0.1798520401096091
[2019-03-23 01:18:47,921] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 845035.0739355179 W.
[2019-03-23 01:18:55,251] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00464116], dtype=float32), -0.3938317]
[2019-03-23 01:18:55,254] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.33333333333334, 76.5, 1.0, 2.0, 0.7074885664561705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806341.3142356182, 806341.3142356182, 177567.4645521046]
[2019-03-23 01:18:55,255] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:18:55,258] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 2.0284576e-37 6.3845372e-28 0.0000000e+00], sampled 0.39630546175952597
[2019-03-23 01:18:55,259] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 806341.3142356182 W.
[2019-03-23 01:19:30,718] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00464116], dtype=float32), -0.3938317]
[2019-03-23 01:19:30,719] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7510983251260172, 6.911200000000001, 6.9112, 121.9260426156618, 558637.5946759034, 558637.594675903, 153957.0576091632]
[2019-03-23 01:19:30,720] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:19:30,724] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.061452821957963644
[2019-03-23 01:19:33,518] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00464116], dtype=float32), -0.3938317]
[2019-03-23 01:19:33,519] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.06666666666667, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6960068096895936, 6.9112, 6.9112, 121.9260426156618, 520097.2841173572, 520097.2841173572, 144694.0782621013]
[2019-03-23 01:19:33,520] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:19:33,523] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.41837009332723496
[2019-03-23 01:19:51,346] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7951.2063 2510576140.3634 718.0000
[2019-03-23 01:19:51,730] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8619.3901 2251335199.6919 479.0000
[2019-03-23 01:19:52,077] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8662.7399 2213762944.0091 519.0000
[2019-03-23 01:19:52,204] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8459.4087 2322817533.6690 532.0000
[2019-03-23 01:19:52,241] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8477.3190 2282422725.6586 626.0000
[2019-03-23 01:19:53,259] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1125000, evaluation results [1125000.0, 7951.206254013055, 2510576140.363394, 718.0, 8619.390129304538, 2251335199.6918607, 479.0, 8662.739915486678, 2213762944.0090747, 519.0, 8459.408745859724, 2322817533.669021, 532.0, 8477.31901505348, 2282422725.65863, 626.0]
[2019-03-23 01:19:53,667] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1125190: loss -319.8704
[2019-03-23 01:19:53,669] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1125190: learning rate 0.0010
[2019-03-23 01:20:01,692] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1128851: loss -84.5685
[2019-03-23 01:20:01,693] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1128851: learning rate 0.0010
[2019-03-23 01:20:01,875] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1128936: loss -57.3062
[2019-03-23 01:20:01,876] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1128936: learning rate 0.0010
[2019-03-23 01:20:02,305] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9150276e-03 5.1586913e-25 1.0468897e-31 9.9808502e-01 3.5316295e-29], sum to 1.0000
[2019-03-23 01:20:02,316] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7434
[2019-03-23 01:20:02,321] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.43333333333333, 32.66666666666666, 1.0, 2.0, 0.7369291960359787, 1.0, 2.0, 0.7369291960359787, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1728602.946784842, 1728602.946784842, 320729.8144236236], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2562600.0000, 
sim time next is 2563200.0000, 
raw observation next is [33.4, 33.0, 1.0, 2.0, 0.7564446887036704, 1.0, 2.0, 0.7564446887036704, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1771728.139228824, 1771728.139228825, 328389.7192956171], 
processed observation next is [1.0, 0.6956521739130435, 0.7925925925925925, 0.33, 1.0, 1.0, 0.7100532008377028, 1.0, 1.0, 0.7100532008377028, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.63276004972458, 0.6327600497245803, 0.6315186909531098], 
reward next is 0.3685, 
noisyNet noise sample is [array([-0.42871815], dtype=float32), -0.7962858]. 
=============================================
[2019-03-23 01:20:03,552] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1129704: loss -107.8668
[2019-03-23 01:20:03,553] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1129705: learning rate 0.0010
[2019-03-23 01:20:03,879] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1129851: loss -84.7073
[2019-03-23 01:20:03,881] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1129854: learning rate 0.0010
[2019-03-23 01:20:03,988] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1129901: loss -37.5229
[2019-03-23 01:20:03,990] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1129901: learning rate 0.0010
[2019-03-23 01:20:04,661] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1130209: loss -54.0904
[2019-03-23 01:20:04,663] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1130210: learning rate 0.0010
[2019-03-23 01:20:04,706] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1130230: loss -92.0552
[2019-03-23 01:20:04,710] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1130230: learning rate 0.0010
[2019-03-23 01:20:04,756] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1130252: loss -135.8257
[2019-03-23 01:20:04,757] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1130252: learning rate 0.0010
[2019-03-23 01:20:04,937] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1130333: loss -64.5616
[2019-03-23 01:20:04,939] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1130333: learning rate 0.0010
[2019-03-23 01:20:05,315] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1130494: loss -64.4690
[2019-03-23 01:20:05,318] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1130494: learning rate 0.0010
[2019-03-23 01:20:05,353] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1130512: loss -119.3629
[2019-03-23 01:20:05,355] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1130512: learning rate 0.0010
[2019-03-23 01:20:06,119] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1130861: loss -105.7071
[2019-03-23 01:20:06,120] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1130861: learning rate 0.0010
[2019-03-23 01:20:06,159] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1130879: loss -130.8853
[2019-03-23 01:20:06,161] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1130879: learning rate 0.0010
[2019-03-23 01:20:06,674] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:20:06,687] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1820
[2019-03-23 01:20:06,693] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.16666666666666, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8084906901041499, 6.911200000000001, 6.9112, 121.9260426156618, 599558.7857573384, 599558.7857573379, 161829.6369407922], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2578200.0000, 
sim time next is 2578800.0000, 
raw observation next is [28.93333333333333, 53.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8085184947766424, 6.9112, 6.9112, 121.9260426156618, 599650.9908132306, 599650.9908132306, 161802.6799196225], 
processed observation next is [1.0, 0.8695652173913043, 0.6271604938271603, 0.53, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.760648118470803, 0.0, 0.0, 0.8094621288201359, 0.21416106814758237, 0.21416106814758237, 0.3111589998454279], 
reward next is 0.6888, 
noisyNet noise sample is [array([-1.5002791], dtype=float32), -2.707739]. 
=============================================
[2019-03-23 01:20:08,396] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1131898: loss 0.1298
[2019-03-23 01:20:08,397] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1131899: learning rate 0.0010
[2019-03-23 01:20:09,437] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7292609e-04 1.2857388e-14 9.4345053e-25 9.9972707e-01 1.6875375e-17], sum to 1.0000
[2019-03-23 01:20:09,450] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8608
[2019-03-23 01:20:09,458] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 2611479.688191895 W.
[2019-03-23 01:20:09,463] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.7, 56.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 7.465659224726687, 6.9112, 121.9238701347682, 2611479.688191895, 2327552.067247372, 443048.5646060063], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2817000.0000, 
sim time next is 2817600.0000, 
raw observation next is [32.73333333333333, 56.33333333333334, 1.0, 2.0, 0.7373484996614289, 1.0, 2.0, 0.6820389118071493, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2334168.267299714, 2334168.267299713, 439427.0320380522], 
processed observation next is [1.0, 0.6086956521739131, 0.767901234567901, 0.5633333333333335, 1.0, 1.0, 0.6873196424540821, 1.0, 1.0, 0.621474895008511, 1.0, 0.5, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.8336315240356121, 0.8336315240356118, 0.8450519846885619], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.55875653], dtype=float32), -1.2262846]. 
=============================================
[2019-03-23 01:20:09,588] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1132443: loss 0.5304
[2019-03-23 01:20:09,593] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1132444: learning rate 0.0010
[2019-03-23 01:20:11,932] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1133513: loss 0.2718
[2019-03-23 01:20:11,935] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1133514: learning rate 0.0010
[2019-03-23 01:20:16,248] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 3.3597386e-25 1.1201058e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 01:20:16,256] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0863
[2019-03-23 01:20:16,263] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 755375.0179610882 W.
[2019-03-23 01:20:16,266] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.3, 67.0, 1.0, 2.0, 0.3313962324733744, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5275935949194175, 6.9112, 6.9112, 121.9260426156618, 755375.0179610882, 755375.0179610882, 203874.9476314669], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2748600.0000, 
sim time next is 2749200.0000, 
raw observation next is [29.06666666666667, 68.66666666666667, 1.0, 2.0, 0.3348141345092257, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5330350062737911, 6.9112, 6.9112, 121.9260426156618, 763169.5636305645, 763169.5636305645, 204838.0843442176], 
processed observation next is [0.0, 0.8260869565217391, 0.6320987654320989, 0.6866666666666668, 1.0, 1.0, 0.20811206489193537, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4162937578422388, 0.0, 0.0, 0.8094621288201359, 0.27256055843948734, 0.27256055843948734, 0.39391939296964923], 
reward next is 0.6061, 
noisyNet noise sample is [array([0.4236128], dtype=float32), 2.4178662]. 
=============================================
[2019-03-23 01:20:18,498] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8953630e-18 3.7763896e-25 9.6959486e-25 1.0000000e+00 1.7138431e-15], sum to 1.0000
[2019-03-23 01:20:18,506] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5389
[2019-03-23 01:20:18,510] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.26666666666667, 79.66666666666667, 1.0, 2.0, 0.732397615226401, 1.0, 1.0, 0.732397615226401, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1670388.713446813, 1670388.713446813, 316611.6938350422], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2794800.0000, 
sim time next is 2795400.0000, 
raw observation next is [27.45, 79.5, 1.0, 2.0, 0.8202378254712703, 1.0, 2.0, 0.8202378254712703, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1870936.822607437, 1870936.822607437, 352187.9425390991], 
processed observation next is [1.0, 0.34782608695652173, 0.5722222222222222, 0.795, 1.0, 1.0, 0.7859974112753219, 1.0, 1.0, 0.7859974112753219, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6681917223597988, 0.6681917223597988, 0.6772845048828828], 
reward next is 0.3227, 
noisyNet noise sample is [array([-1.4828172], dtype=float32), 0.1451626]. 
=============================================
[2019-03-23 01:20:19,093] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1136777: loss 10.7817
[2019-03-23 01:20:19,096] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1136778: learning rate 0.0010
[2019-03-23 01:20:19,291] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1136866: loss 7.2124
[2019-03-23 01:20:19,293] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1136866: learning rate 0.0010
[2019-03-23 01:20:20,549] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1137436: loss 44.6380
[2019-03-23 01:20:20,553] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1137437: learning rate 0.0010
[2019-03-23 01:20:21,103] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1137693: loss 0.0499
[2019-03-23 01:20:21,105] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1137694: learning rate 0.0010
[2019-03-23 01:20:21,494] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1137870: loss -57.8706
[2019-03-23 01:20:21,496] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1137870: learning rate 0.0010
[2019-03-23 01:20:21,992] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1138091: loss 0.4988
[2019-03-23 01:20:21,994] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1138091: learning rate 0.0010
[2019-03-23 01:20:22,015] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1138103: loss 0.2339
[2019-03-23 01:20:22,017] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1138103: learning rate 0.0010
[2019-03-23 01:20:22,041] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1138113: loss 2.3369
[2019-03-23 01:20:22,043] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1138113: learning rate 0.0010
[2019-03-23 01:20:22,172] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1138177: loss 1.6123
[2019-03-23 01:20:22,174] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1138177: learning rate 0.0010
[2019-03-23 01:20:22,563] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1138356: loss 0.3244
[2019-03-23 01:20:22,566] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1138356: learning rate 0.0010
[2019-03-23 01:20:22,730] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1138430: loss 0.4214
[2019-03-23 01:20:22,733] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1138430: learning rate 0.0010
[2019-03-23 01:20:23,316] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1138701: loss 0.2864
[2019-03-23 01:20:23,320] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1138701: learning rate 0.0010
[2019-03-23 01:20:23,397] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1138731: loss 0.0865
[2019-03-23 01:20:23,402] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1138731: learning rate 0.0010
[2019-03-23 01:20:24,387] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.7884093e-34 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 01:20:24,395] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7197
[2019-03-23 01:20:24,399] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8229312650370426, 6.911199999999999, 6.9112, 121.9260426156618, 611960.9638264467, 611960.9638264471, 162820.6220606406], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2872800.0000, 
sim time next is 2873400.0000, 
raw observation next is [22.0, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9184213044906089, 6.911199999999999, 6.9112, 121.9260426156618, 683119.485250628, 683119.4852506284, 174789.7478284856], 
processed observation next is [1.0, 0.2608695652173913, 0.37037037037037035, 0.9400000000000002, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8980266306132612, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24397124473236714, 0.2439712447323673, 0.3361341304393954], 
reward next is 0.6639, 
noisyNet noise sample is [array([0.89554274], dtype=float32), -0.5698161]. 
=============================================
[2019-03-23 01:20:26,425] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1140095: loss -14.1734
[2019-03-23 01:20:26,427] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1140096: learning rate 0.0010
[2019-03-23 01:20:27,134] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.3936542e-25 2.5664215e-30 7.9682661e-36 3.5762159e-34], sum to 1.0000
[2019-03-23 01:20:27,143] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3058
[2019-03-23 01:20:27,149] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 796725.8716967289 W.
[2019-03-23 01:20:27,154] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.7, 90.0, 1.0, 2.0, 0.3495281518378261, 1.0, 2.0, 0.3495281518378261, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 796725.8716967289, 796725.8716967293, 192770.2812226564], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2955600.0000, 
sim time next is 2956200.0000, 
raw observation next is [24.75, 90.66666666666667, 1.0, 2.0, 0.3755073239961993, 1.0, 2.0, 0.3755073239961993, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 855976.7115131054, 855976.7115131058, 199566.9989613405], 
processed observation next is [1.0, 0.21739130434782608, 0.4722222222222222, 0.9066666666666667, 1.0, 1.0, 0.25655633809071343, 1.0, 1.0, 0.25655633809071343, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30570596839753766, 0.3057059683975378, 0.3837826903102702], 
reward next is 0.6162, 
noisyNet noise sample is [array([-0.39324787], dtype=float32), 1.0554078]. 
=============================================
[2019-03-23 01:20:27,388] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 9.5644522e-29 1.5838393e-27 9.2374941e-22 3.3726626e-29], sum to 1.0000
[2019-03-23 01:20:27,393] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4050
[2019-03-23 01:20:27,400] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 898780.6227630893 W.
[2019-03-23 01:20:27,406] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.58333333333333, 86.5, 1.0, 2.0, 0.3942739127843165, 1.0, 2.0, 0.3942739127843165, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 898780.6227630893, 898780.6227630897, 204622.3868763643], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2967000.0000, 
sim time next is 2967600.0000, 
raw observation next is [25.66666666666667, 87.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.952942471962619, 6.9112, 121.9223071488625, 1696629.608837196, 1163180.697163301, 245581.3036142746], 
processed observation next is [1.0, 0.34782608695652173, 0.506172839506173, 0.87, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.10417424719626193, 0.0, 0.8094373292052003, 0.6059391460132842, 0.4154216775583218, 0.47227173771975883], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.092137], dtype=float32), 0.82551533]. 
=============================================
[2019-03-23 01:20:27,479] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1140571: loss 5.6103
[2019-03-23 01:20:27,483] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1140573: learning rate 0.0010
[2019-03-23 01:20:27,743] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.7547038e-18 4.1713486e-27 1.6643240e-29 1.1999623e-28], sum to 1.0000
[2019-03-23 01:20:27,749] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1435
[2019-03-23 01:20:27,759] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 745453.2145245726 W.
[2019-03-23 01:20:27,763] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.03333333333333, 93.0, 1.0, 2.0, 0.6540909586629166, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745453.2145245726, 745453.2145245726, 167633.7488643501], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2940000.0000, 
sim time next is 2940600.0000, 
raw observation next is [25.01666666666667, 93.5, 1.0, 2.0, 0.2191741827043379, 1.0, 1.0, 0.2191741827043379, 1.0, 1.0, 0.3489324368701066, 6.911199999999999, 6.9112, 121.94756008, 749365.969286858, 749365.9692868585, 226960.4108684221], 
processed observation next is [1.0, 0.0, 0.48209876543209884, 0.935, 1.0, 1.0, 0.07044545560040225, 1.0, 0.5, 0.07044545560040225, 1.0, 0.5, 0.18616554608763325, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.267630703316735, 0.26763070331673516, 0.4364623285931194], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.486118], dtype=float32), 1.5366204]. 
=============================================
[2019-03-23 01:20:29,066] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 6.0505119e-25 1.7336815e-30 1.6651244e-36 1.6448498e-32], sum to 1.0000
[2019-03-23 01:20:29,076] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8774
[2019-03-23 01:20:29,083] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 685741.3057570759 W.
[2019-03-23 01:20:29,089] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.3, 98.66666666666666, 1.0, 2.0, 0.5947212022469481, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 685741.3057570759, 685741.3057570759, 157559.1659131013], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3022800.0000, 
sim time next is 3023400.0000, 
raw observation next is [23.15, 99.33333333333334, 1.0, 2.0, 0.2969013474714142, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4729910250588465, 6.9112, 6.9112, 121.9260426156618, 682702.4555437241, 682702.4555437241, 194305.6499301796], 
processed observation next is [1.0, 1.0, 0.4129629629629629, 0.9933333333333334, 1.0, 1.0, 0.16297779460882647, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.34123878132355806, 0.0, 0.0, 0.8094621288201359, 0.24382230555133005, 0.24382230555133005, 0.37366471140419155], 
reward next is 0.6263, 
noisyNet noise sample is [array([0.6143047], dtype=float32), 0.59668654]. 
=============================================
[2019-03-23 01:20:29,697] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1141579: loss 23.9827
[2019-03-23 01:20:29,698] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1141579: learning rate 0.0010
[2019-03-23 01:20:34,411] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.7920682e-09 1.1950324e-22 4.4654519e-26 1.0000000e+00 1.9912506e-22], sum to 1.0000
[2019-03-23 01:20:34,420] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8583
[2019-03-23 01:20:34,424] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 82.5, 1.0, 2.0, 1.00713762987373, 1.0, 2.0, 1.00713762987373, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2297797.942608205, 2297797.942608205, 436782.6510494564], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3061800.0000, 
sim time next is 3062400.0000, 
raw observation next is [29.33333333333334, 80.33333333333334, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.081516837486802, 6.9112, 121.9253166217624, 2414512.493281345, 2327295.569067644, 443049.49345882], 
processed observation next is [1.0, 0.43478260869565216, 0.6419753086419755, 0.8033333333333335, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.25, 0.017031683748680228, 0.0, 0.8094573089756244, 0.8623258904576232, 0.83117698895273, 0.8520182566515769], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.22232111], dtype=float32), 0.34125906]. 
=============================================
[2019-03-23 01:20:36,939] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1144851: loss -47.3414
[2019-03-23 01:20:36,942] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1144851: learning rate 0.0010
[2019-03-23 01:20:37,253] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1145000: loss -4.8157
[2019-03-23 01:20:37,254] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1145000: learning rate 0.0010
[2019-03-23 01:20:38,554] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1145609: loss -105.5236
[2019-03-23 01:20:38,557] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1145609: learning rate 0.0010
[2019-03-23 01:20:39,007] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1145822: loss 76.8627
[2019-03-23 01:20:39,008] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1145823: learning rate 0.0010
[2019-03-23 01:20:39,009] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1145824: loss -20.8979
[2019-03-23 01:20:39,012] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1145824: learning rate 0.0010
[2019-03-23 01:20:39,765] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1146177: loss -29.1730
[2019-03-23 01:20:39,767] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1146177: learning rate 0.0010
[2019-03-23 01:20:39,808] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1146194: loss 163.2940
[2019-03-23 01:20:39,811] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1146197: learning rate 0.0010
[2019-03-23 01:20:39,917] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1146251: loss 32.9205
[2019-03-23 01:20:39,918] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1146251: learning rate 0.0010
[2019-03-23 01:20:40,088] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1146330: loss 177.8313
[2019-03-23 01:20:40,091] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1146331: learning rate 0.0010
[2019-03-23 01:20:40,296] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1146422: loss -21.5621
[2019-03-23 01:20:40,299] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1146422: learning rate 0.0010
[2019-03-23 01:20:40,495] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1146516: loss 12.3993
[2019-03-23 01:20:40,500] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1146516: learning rate 0.0010
[2019-03-23 01:20:40,539] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.000000e+00 5.184116e-30 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 01:20:40,548] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6449
[2019-03-23 01:20:40,555] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 731487.804621891 W.
[2019-03-23 01:20:40,561] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.2138428563768585, 1.0, 1.0, 0.2138428563768585, 1.0, 1.0, 0.3404521069423844, 6.9112, 6.9112, 121.94756008, 731487.804621891, 731487.804621891, 225171.4526741965], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3391200.0000, 
sim time next is 3391800.0000, 
raw observation next is [23.23333333333333, 98.50000000000001, 1.0, 2.0, 0.3488614864221559, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5555961511911796, 6.911199999999999, 6.9112, 121.9260426156618, 799691.3224292557, 799691.3224292562, 208770.6921415893], 
processed observation next is [1.0, 0.2608695652173913, 0.4160493827160493, 0.9850000000000001, 1.0, 1.0, 0.22483510288351896, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.4444951889889744, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2856040437247342, 0.28560404372473436, 0.4014821002722871], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.0981643], dtype=float32), -0.36217964]. 
=============================================
[2019-03-23 01:20:41,166] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1146831: loss -37.8319
[2019-03-23 01:20:41,167] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1146832: learning rate 0.0010
[2019-03-23 01:20:41,268] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1146876: loss 38.0580
[2019-03-23 01:20:41,269] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1146876: learning rate 0.0010
[2019-03-23 01:20:43,500] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1147938: loss 6.0042
[2019-03-23 01:20:43,502] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1147938: learning rate 0.0010
[2019-03-23 01:20:43,910] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:20:43,916] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5379
[2019-03-23 01:20:43,920] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 78.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7641822454607435, 6.911200000000001, 6.9112, 121.9260426156618, 569970.8173731556, 569970.8173731552, 154351.4555733862], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3216000.0000, 
sim time next is 3216600.0000, 
raw observation next is [23.45, 79.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7641437841608778, 6.911200000000001, 6.9112, 121.9260426156618, 569896.701681528, 569896.7016815275, 154390.7624276137], 
processed observation next is [0.0, 0.21739130434782608, 0.42407407407407405, 0.795, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7051797302010973, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20353453631483143, 0.20353453631483126, 0.29690531236079554], 
reward next is 0.7031, 
noisyNet noise sample is [array([-0.37598664], dtype=float32), -1.8561335]. 
=============================================
[2019-03-23 01:20:44,542] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1148423: loss -166.4525
[2019-03-23 01:20:44,547] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1148425: learning rate 0.0010
[2019-03-23 01:20:46,688] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1149434: loss 31.1388
[2019-03-23 01:20:46,691] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1149434: learning rate 0.0010
[2019-03-23 01:20:47,247] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:20:47,257] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1649
[2019-03-23 01:20:47,263] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.45, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8388103664634012, 6.9112, 6.9112, 121.9260426156618, 621764.1691819219, 621764.1691819219, 165737.2168575991], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3288600.0000, 
sim time next is 3289200.0000, 
raw observation next is [22.26666666666667, 92.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.823362777269095, 6.911199999999999, 6.9112, 121.9260426156618, 611514.9687537698, 611514.9687537702, 163280.2524206055], 
processed observation next is [0.0, 0.043478260869565216, 0.38024691358024704, 0.9266666666666665, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7792034715863688, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21839820312634634, 0.2183982031263465, 0.31400048542424136], 
reward next is 0.6860, 
noisyNet noise sample is [array([1.0445602], dtype=float32), 0.42007133]. 
=============================================
[2019-03-23 01:20:47,909] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 01:20:47,914] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:20:47,915] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:20:47,915] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:20:47,917] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:20:47,917] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:20:47,918] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:20:47,919] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:20:47,920] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:20:47,921] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:20:47,920] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:20:47,950] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run47
[2019-03-23 01:20:47,975] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run47
[2019-03-23 01:20:47,976] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run47
[2019-03-23 01:20:47,977] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run47
[2019-03-23 01:20:48,045] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run47
[2019-03-23 01:20:58,277] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.12913539], dtype=float32), -0.30390984]
[2019-03-23 01:20:58,278] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.66666666666667, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4540686660633149, 6.9112, 6.9112, 121.9260426156618, 324202.4929771682, 324202.4929771682, 104810.7938732344]
[2019-03-23 01:20:58,279] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:20:58,283] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.573990149101809
[2019-03-23 01:21:24,557] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.12913539], dtype=float32), -0.30390984]
[2019-03-23 01:21:24,559] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.05435958, 64.92407085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8980346872003441, 6.9112, 6.9112, 121.9260426156618, 655820.5274334579, 655820.5274334579, 175957.8594099967]
[2019-03-23 01:21:24,562] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:21:24,565] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.41789088890187087
[2019-03-23 01:21:37,680] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.12913539], dtype=float32), -0.30390984]
[2019-03-23 01:21:37,680] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.32223679, 81.40809583833334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7775220503338969, 6.9112, 6.9112, 121.9260426156618, 579118.9827462651, 579118.9827462651, 156612.2142525011]
[2019-03-23 01:21:37,683] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:21:37,686] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 6.3751143e-37 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6431458669854251
[2019-03-23 01:22:11,315] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.12913539], dtype=float32), -0.30390984]
[2019-03-23 01:22:11,317] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.31210609, 95.32555528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6996448202058352, 6.9112, 6.9112, 121.9260426156618, 522631.2163021744, 522631.2163021744, 145755.0724707236]
[2019-03-23 01:22:11,317] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:22:11,319] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.05146208590167256
[2019-03-23 01:22:20,980] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.12913539], dtype=float32), -0.30390984]
[2019-03-23 01:22:20,983] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.33333333333334, 64.66666666666667, 1.0, 2.0, 0.7865100532757119, 1.0, 2.0, 0.7865100532757119, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1793927.572599094, 1793927.572599094, 338211.9360208516]
[2019-03-23 01:22:20,984] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:22:20,988] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.9393178e-13 4.0393869e-27 5.2954715e-28 1.0000000e+00 1.2335615e-34], sampled 0.18399150346477366
[2019-03-23 01:22:22,968] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.12913539], dtype=float32), -0.30390984]
[2019-03-23 01:22:22,969] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.56666666666667, 38.66666666666666, 1.0, 2.0, 0.6479344435350236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 824238.6104015054, 824238.6104015063, 169353.8906228255]
[2019-03-23 01:22:22,972] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:22:22,977] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.00000000e+00 1.11382615e-27 1.90537777e-22 1.11234366e-13
 8.32135858e-27], sampled 0.5479631918978372
[2019-03-23 01:22:22,977] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 824238.6104015054 W.
[2019-03-23 01:22:40,580] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8524.7136 2277910279.7155 424.0000
[2019-03-23 01:22:40,603] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8600.9794 2248005201.0514 343.0000
[2019-03-23 01:22:40,774] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8039.3768 2503232349.5425 463.0000
[2019-03-23 01:22:40,839] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8706.2942 2212109343.3647 345.0000
[2019-03-23 01:22:40,884] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8483.2900 2315698520.8543 354.0000
[2019-03-23 01:22:41,898] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1150000, evaluation results [1150000.0, 8039.376828569194, 2503232349.5424676, 463.0, 8600.979386744464, 2248005201.05142, 343.0, 8706.294153152676, 2212109343.3646817, 345.0, 8483.290027942063, 2315698520.8542705, 354.0, 8524.713572875295, 2277910279.715515, 424.0]
[2019-03-23 01:22:47,914] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1152759: loss -102.8651
[2019-03-23 01:22:47,917] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1152760: learning rate 0.0010
[2019-03-23 01:22:48,242] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1152908: loss -19.3643
[2019-03-23 01:22:48,247] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1152911: learning rate 0.0010
[2019-03-23 01:22:48,410] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9419057e-01 5.7569523e-03 8.9670174e-14 5.2548326e-05 6.2677959e-23], sum to 1.0000
[2019-03-23 01:22:48,423] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4279
[2019-03-23 01:22:48,431] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1242075.305376721 W.
[2019-03-23 01:22:48,438] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 59.0, 1.0, 2.0, 0.5447472493657746, 1.0, 2.0, 0.5447472493657746, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1242075.305376721, 1242075.305376722, 249568.4711505629], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3416400.0000, 
sim time next is 3417000.0000, 
raw observation next is [30.86666666666667, 59.16666666666667, 1.0, 2.0, 0.6828645645465073, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1493243.633462576, 1493243.633462577, 314146.8362858403], 
processed observation next is [1.0, 0.5652173913043478, 0.6987654320987656, 0.5916666666666667, 1.0, 1.0, 0.6224578149363182, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5333012976652057, 0.5333012976652061, 0.6041285313189236], 
reward next is 0.3959, 
noisyNet noise sample is [array([0.9774925], dtype=float32), -0.25712067]. 
=============================================
[2019-03-23 01:22:48,457] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[47.633377]
 [47.21285 ]
 [46.694283]
 [47.713535]
 [47.69277 ]], R is [[45.24583817]
 [45.31344223]
 [44.8603096 ]
 [44.81685257]
 [44.83816528]].
[2019-03-23 01:22:49,635] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1153535: loss -61.4062
[2019-03-23 01:22:49,637] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1153535: learning rate 0.0010
[2019-03-23 01:22:50,150] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1153772: loss -71.1733
[2019-03-23 01:22:50,152] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1153772: learning rate 0.0010
[2019-03-23 01:22:50,785] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1154059: loss 168.9333
[2019-03-23 01:22:50,788] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1154059: learning rate 0.0010
[2019-03-23 01:22:50,864] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1154093: loss 81.2806
[2019-03-23 01:22:50,866] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1154094: learning rate 0.0010
[2019-03-23 01:22:51,005] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1154153: loss 129.3575
[2019-03-23 01:22:51,006] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1154153: learning rate 0.0010
[2019-03-23 01:22:51,255] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1154272: loss 0.3132
[2019-03-23 01:22:51,258] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1154275: learning rate 0.0010
[2019-03-23 01:22:51,276] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1154283: loss 44.3386
[2019-03-23 01:22:51,277] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1154283: learning rate 0.0010
[2019-03-23 01:22:51,499] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1154380: loss 3.9146
[2019-03-23 01:22:51,502] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1154381: learning rate 0.0010
[2019-03-23 01:22:51,524] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1154392: loss 3.0743
[2019-03-23 01:22:51,525] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1154392: learning rate 0.0010
[2019-03-23 01:22:52,407] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1154792: loss -20.5689
[2019-03-23 01:22:52,409] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1154792: learning rate 0.0010
[2019-03-23 01:22:52,438] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1154806: loss 24.9219
[2019-03-23 01:22:52,439] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1154807: learning rate 0.0010
[2019-03-23 01:22:53,121] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 6.3719648e-26 2.3857297e-26 3.7539700e-32 9.3486172e-32], sum to 1.0000
[2019-03-23 01:22:53,129] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8272
[2019-03-23 01:22:53,139] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 883972.4815574462 W.
[2019-03-23 01:22:53,143] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.08333333333333, 98.5, 1.0, 2.0, 0.7755633476106877, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 883972.4815574462, 883972.4815574462, 190937.0912672804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3466200.0000, 
sim time next is 3466800.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.7888799241521446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 899159.3681744118, 899159.3681744118, 193647.9051287553], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 1.0, 1.0, 1.0, 0.7486665763716007, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3211283457765757, 0.3211283457765757, 0.3723998175552986], 
reward next is 0.6276, 
noisyNet noise sample is [array([1.1766522], dtype=float32), -0.54962075]. 
=============================================
[2019-03-23 01:22:54,937] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1155941: loss 0.6111
[2019-03-23 01:22:54,940] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1155942: learning rate 0.0010
[2019-03-23 01:22:56,014] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1156435: loss -87.6607
[2019-03-23 01:22:56,016] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1156435: learning rate 0.0010
[2019-03-23 01:22:56,185] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9960297e-01 4.4767890e-20 4.7436169e-16 3.9703841e-04 1.6633372e-13], sum to 1.0000
[2019-03-23 01:22:56,196] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4689
[2019-03-23 01:22:56,206] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1477602.923394148 W.
[2019-03-23 01:22:56,210] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.6680592206930426, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9962101402558501, 6.9112, 6.9112, 121.9260426156618, 1477602.923394148, 1477602.923394148, 311258.8367023482], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3598200.0000, 
sim time next is 3598800.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.654503682929133, 1.0, 1.0, 0.654503682929133, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1492574.208591317, 1492574.208591317, 287299.2788173074], 
processed observation next is [1.0, 0.6521739130434783, 0.48148148148148145, 0.83, 1.0, 1.0, 0.5886948606299202, 1.0, 0.5, 0.5886948606299202, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5330622173540418, 0.5330622173540418, 0.5524986131102065], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0484003], dtype=float32), 0.51873183]. 
=============================================
[2019-03-23 01:22:58,121] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1157397: loss 1.2667
[2019-03-23 01:22:58,123] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1157397: learning rate 0.0010
[2019-03-23 01:22:58,796] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 6.8389184e-24 4.3490899e-23 1.0656275e-31 3.5801980e-21], sum to 1.0000
[2019-03-23 01:22:58,804] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7648
[2019-03-23 01:22:58,816] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1238816.448698865 W.
[2019-03-23 01:22:58,823] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.23333333333333, 86.66666666666667, 1.0, 2.0, 0.356867121872787, 1.0, 2.0, 0.356867121872787, 1.0, 1.0, 0.5689872067870282, 6.911199999999999, 6.9112, 121.94756008, 1238816.448698865, 1238816.448698866, 278758.3200147667], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3579600.0000, 
sim time next is 3580200.0000, 
raw observation next is [23.35, 85.5, 1.0, 2.0, 0.5348046516530978, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8553817353481388, 6.911199999999999, 6.9112, 121.9260426156422, 1255191.479473295, 1255191.479473295, 268628.0359716191], 
processed observation next is [1.0, 0.43478260869565216, 0.42037037037037045, 0.855, 1.0, 1.0, 0.4461960138727354, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8192271691851735, -8.881784197001253e-17, 0.0, 0.8094621288200058, 0.44828267124046245, 0.44828267124046245, 0.5165923768684982], 
reward next is 0.4834, 
noisyNet noise sample is [array([-0.2150616], dtype=float32), 1.5968996]. 
=============================================
[2019-03-23 01:23:05,510] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1160739: loss 1.5619
[2019-03-23 01:23:05,511] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1160739: learning rate 0.0010
[2019-03-23 01:23:05,890] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1160911: loss 0.6148
[2019-03-23 01:23:05,893] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1160911: learning rate 0.0010
[2019-03-23 01:23:05,934] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.9889119e-23 1.1495259e-25 1.2398627e-29 1.4518205e-22], sum to 1.0000
[2019-03-23 01:23:05,941] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5732
[2019-03-23 01:23:05,951] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 783875.150366953 W.
[2019-03-23 01:23:05,959] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 92.66666666666667, 1.0, 2.0, 0.2292622532913836, 1.0, 2.0, 0.2292622532913836, 1.0, 1.0, 0.3649929737902054, 6.911199999999999, 6.9112, 121.94756008, 783875.150366953, 783875.1503669535, 230392.1793469131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3703200.0000, 
sim time next is 3703800.0000, 
raw observation next is [25.2, 93.33333333333334, 1.0, 2.0, 0.6813531985646479, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 776539.1335530058, 776539.1335530058, 172642.5457537058], 
processed observation next is [1.0, 0.8695652173913043, 0.4888888888888889, 0.9333333333333335, 1.0, 1.0, 0.6206585697198189, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2773354048403592, 0.2773354048403592, 0.33200489568020347], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.332027], dtype=float32), -0.40220246]. 
=============================================
[2019-03-23 01:23:07,105] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1161460: loss 2.5353
[2019-03-23 01:23:07,106] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1161460: learning rate 0.0010
[2019-03-23 01:23:07,656] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1161710: loss 0.4908
[2019-03-23 01:23:07,658] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1161710: learning rate 0.0010
[2019-03-23 01:23:07,867] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1161807: loss 17.3733
[2019-03-23 01:23:07,869] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1161807: learning rate 0.0010
[2019-03-23 01:23:08,368] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1162037: loss 0.2149
[2019-03-23 01:23:08,370] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1162037: learning rate 0.0010
[2019-03-23 01:23:08,417] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1162056: loss 0.2445
[2019-03-23 01:23:08,420] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1162057: learning rate 0.0010
[2019-03-23 01:23:08,426] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1162061: loss 0.1663
[2019-03-23 01:23:08,429] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1162061: learning rate 0.0010
[2019-03-23 01:23:08,842] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1162250: loss -1.2514
[2019-03-23 01:23:08,846] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1162250: learning rate 0.0010
[2019-03-23 01:23:09,032] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1162336: loss -12.7437
[2019-03-23 01:23:09,034] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1162337: learning rate 0.0010
[2019-03-23 01:23:09,088] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1162358: loss -34.4925
[2019-03-23 01:23:09,090] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1162358: learning rate 0.0010
[2019-03-23 01:23:10,069] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1162807: loss -111.3385
[2019-03-23 01:23:10,072] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1162807: learning rate 0.0010
[2019-03-23 01:23:10,159] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1162849: loss -93.6367
[2019-03-23 01:23:10,161] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1162849: learning rate 0.0010
[2019-03-23 01:23:13,506] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1164365: loss 30.5572
[2019-03-23 01:23:13,509] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1164365: learning rate 0.0010
[2019-03-23 01:23:14,485] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1164812: loss 32.1087
[2019-03-23 01:23:14,488] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1164813: learning rate 0.0010
[2019-03-23 01:23:16,352] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1165660: loss -92.2680
[2019-03-23 01:23:16,354] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1165660: learning rate 0.0010
[2019-03-23 01:23:18,397] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.4378565e-26 1.0908722e-25 0.0000000e+00 8.1009139e-36], sum to 1.0000
[2019-03-23 01:23:18,405] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5705
[2019-03-23 01:23:18,413] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 867745.9436200191 W.
[2019-03-23 01:23:18,420] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.33333333333334, 87.33333333333333, 1.0, 2.0, 0.2537783134317985, 1.0, 1.0, 0.2537783134317985, 1.0, 1.0, 0.4040233399660832, 6.911200000000001, 6.9112, 121.94756008, 867745.9436200191, 867745.9436200187, 238969.1879274376], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3966000.0000, 
sim time next is 3966600.0000, 
raw observation next is [27.16666666666666, 88.16666666666667, 1.0, 2.0, 0.3813882988467684, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6071825927137972, 6.911199999999999, 6.9112, 121.9260426156618, 869390.1188066201, 869390.1188066206, 218430.6492881092], 
processed observation next is [0.0, 0.9130434782608695, 0.5617283950617282, 0.8816666666666667, 1.0, 1.0, 0.26355749862710526, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.5089782408922464, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3104964710023643, 0.3104964710023645, 0.4200589409386716], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7800097], dtype=float32), 0.2505475]. 
=============================================
[2019-03-23 01:23:23,316] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1168848: loss -56.5992
[2019-03-23 01:23:23,317] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1168848: learning rate 0.0010
[2019-03-23 01:23:23,608] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1168983: loss 96.4820
[2019-03-23 01:23:23,612] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1168984: learning rate 0.0010
[2019-03-23 01:23:24,672] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1169488: loss -174.4267
[2019-03-23 01:23:24,675] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1169488: learning rate 0.0010
[2019-03-23 01:23:25,015] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1169623: loss 65.3133
[2019-03-23 01:23:25,016] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1169623: learning rate 0.0010
[2019-03-23 01:23:25,465] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1169839: loss -30.0378
[2019-03-23 01:23:25,467] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1169839: learning rate 0.0010
[2019-03-23 01:23:26,010] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1170088: loss 94.5124
[2019-03-23 01:23:26,013] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1170088: learning rate 0.0010
[2019-03-23 01:23:26,227] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1170189: loss -39.8662
[2019-03-23 01:23:26,229] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1170189: learning rate 0.0010
[2019-03-23 01:23:26,288] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1170220: loss -204.6367
[2019-03-23 01:23:26,290] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1170221: learning rate 0.0010
[2019-03-23 01:23:26,742] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1170434: loss 101.1425
[2019-03-23 01:23:26,744] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1170435: learning rate 0.0010
[2019-03-23 01:23:26,828] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1170478: loss 75.2213
[2019-03-23 01:23:26,833] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1170479: learning rate 0.0010
[2019-03-23 01:23:26,863] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1170493: loss -41.5821
[2019-03-23 01:23:26,866] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1170493: learning rate 0.0010
[2019-03-23 01:23:28,012] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1171032: loss 96.2844
[2019-03-23 01:23:28,017] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1171033: learning rate 0.0010
[2019-03-23 01:23:28,120] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.1587928e-19 2.0526873e-24 3.4985144e-15 1.2615691e-24], sum to 1.0000
[2019-03-23 01:23:28,126] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1821
[2019-03-23 01:23:28,134] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1618513.931247208 W.
[2019-03-23 01:23:28,140] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.91666666666666, 36.33333333333334, 1.0, 2.0, 0.6864151631996199, 1.0, 2.0, 0.6864151631996199, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1618513.931247208, 1618513.931247208, 301574.0421333034], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4273800.0000, 
sim time next is 4274400.0000, 
raw observation next is [31.93333333333334, 36.66666666666667, 1.0, 2.0, 0.6499851671054432, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9660431820908139, 6.911199999999999, 6.9112, 121.9260426156618, 1487125.851103733, 1487125.851103733, 301368.8411478158], 
processed observation next is [1.0, 0.4782608695652174, 0.7382716049382719, 0.3666666666666667, 1.0, 1.0, 0.5833156751255276, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9575539776135172, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5311163753941904, 0.5311163753941904, 0.5795554637457996], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9784355], dtype=float32), 0.53100514]. 
=============================================
[2019-03-23 01:23:28,175] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1171108: loss -94.6854
[2019-03-23 01:23:28,178] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1171108: learning rate 0.0010
[2019-03-23 01:23:29,740] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1171862: loss -101.6527
[2019-03-23 01:23:29,742] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1171862: learning rate 0.0010
[2019-03-23 01:23:30,510] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1172323: loss -25.8621
[2019-03-23 01:23:30,514] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1172326: learning rate 0.0010
[2019-03-23 01:23:32,678] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1173368: loss -108.7691
[2019-03-23 01:23:32,681] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1173368: learning rate 0.0010
[2019-03-23 01:23:32,701] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.9251816e-15 3.5685425e-27 7.6646134e-10 6.6205414e-33], sum to 1.0000
[2019-03-23 01:23:32,707] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5973
[2019-03-23 01:23:32,715] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1344263.027080283 W.
[2019-03-23 01:23:32,721] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.33333333333334, 42.66666666666667, 1.0, 2.0, 0.5866106142505596, 1.0, 2.0, 0.5866106142505596, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1344263.027080283, 1344263.027080284, 263795.9086678233], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4191600.0000, 
sim time next is 4192200.0000, 
raw observation next is [32.5, 41.0, 1.0, 2.0, 0.5410347783144216, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8630707809849518, 6.911199999999999, 6.9112, 121.9260426156618, 1255849.839463358, 1255849.839463359, 271242.4210663408], 
processed observation next is [1.0, 0.5217391304347826, 0.7592592592592593, 0.41, 1.0, 1.0, 0.45361283132669233, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.8288384762311898, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.44851779980834217, 0.4485177998083425, 0.5216200405121939], 
reward next is 0.4784, 
noisyNet noise sample is [array([-0.5542679], dtype=float32), -0.036760207]. 
=============================================
[2019-03-23 01:23:35,805] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 01:23:35,809] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:23:35,810] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:23:35,812] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:23:35,814] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:23:35,815] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:23:35,815] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:23:35,815] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:23:35,817] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:23:35,816] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:23:35,825] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:23:35,836] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run48
[2019-03-23 01:23:35,860] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run48
[2019-03-23 01:23:35,882] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run48
[2019-03-23 01:23:35,909] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run48
[2019-03-23 01:23:35,931] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run48
[2019-03-23 01:23:41,632] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.12548393], dtype=float32), -0.276953]
[2019-03-23 01:23:41,633] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.26666666666667, 42.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5305961583310669, 6.911200000000001, 6.9112, 121.9260426156618, 379576.7782969117, 379576.7782969113, 117709.4758735811]
[2019-03-23 01:23:41,634] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:23:41,636] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9621966543394194
[2019-03-23 01:23:54,289] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.12548393], dtype=float32), -0.276953]
[2019-03-23 01:23:54,291] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.97740588, 82.37573352333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6504320429216401, 6.911200000000001, 6.9112, 121.9260426156618, 484666.2682689414, 484666.268268941, 136803.1934189676]
[2019-03-23 01:23:54,292] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:23:54,296] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5179291708495755
[2019-03-23 01:24:08,026] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.12548393], dtype=float32), -0.276953]
[2019-03-23 01:24:08,027] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.59319959833334, 47.01148649, 1.0, 2.0, 0.555098320500097, 1.0, 1.0, 0.555098320500097, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9257890239766, 1294269.040405394, 1294269.040405394, 254291.7127230788]
[2019-03-23 01:24:08,027] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:24:08,029] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.0546825e-11 4.7520046e-31 1.7730076e-23 1.0000000e+00 9.9614271e-32], sampled 0.20105116363419584
[2019-03-23 01:24:18,147] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.12548393], dtype=float32), -0.276953]
[2019-03-23 01:24:18,148] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.91666666666667, 58.0, 1.0, 2.0, 0.5344635488373123, 1.0, 2.0, 0.5344635488373123, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425975344, 1218608.844444944, 1218608.844444944, 246247.5349072722]
[2019-03-23 01:24:18,149] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:24:18,152] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.7403736e-02 3.2664599e-31 1.4468606e-21 9.4259626e-01 6.8397037e-29], sampled 0.4249556101306602
[2019-03-23 01:24:30,945] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.12548393], dtype=float32), -0.276953]
[2019-03-23 01:24:30,946] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.24889740333333, 92.24921412666667, 1.0, 2.0, 0.5610957516062766, 1.0, 1.0, 0.5610957516062766, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260184864389, 1279382.567363903, 1279382.567363903, 254926.7606824395]
[2019-03-23 01:24:30,947] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:24:30,951] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.6167839e-10 0.0000000e+00 2.1154663e-30 1.0000000e+00 1.1537926e-31], sampled 0.7076854685751695
[2019-03-23 01:24:38,152] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.12548393], dtype=float32), -0.276953]
[2019-03-23 01:24:38,153] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.33333333333333, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9002739061657757, 6.911199999999999, 6.9112, 121.9260426156618, 660463.8643817212, 660463.8643817217, 175638.6366253741]
[2019-03-23 01:24:38,156] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:24:38,160] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9270042924262609
[2019-03-23 01:25:26,865] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8638.6561 2246520859.9017 348.0000
[2019-03-23 01:25:26,991] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8527.1179 2276850727.4756 467.0000
[2019-03-23 01:25:27,044] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8050.5112 2502394748.7811 527.0000
[2019-03-23 01:25:27,059] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8710.9809 2210395940.2485 387.0000
[2019-03-23 01:25:27,065] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8501.0971 2314808273.1070 400.0000
[2019-03-23 01:25:28,080] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1175000, evaluation results [1175000.0, 8050.511246612812, 2502394748.781063, 527.0, 8638.656104634856, 2246520859.9017243, 348.0, 8710.98087782004, 2210395940.2485313, 387.0, 8501.097114309894, 2314808273.1070027, 400.0, 8527.11791541736, 2276850727.4756403, 467.0]
[2019-03-23 01:25:31,913] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1176746: loss 3.1932
[2019-03-23 01:25:31,915] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1176746: learning rate 0.0010
[2019-03-23 01:25:32,209] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1176878: loss 4.9902
[2019-03-23 01:25:32,212] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1176878: learning rate 0.0010
[2019-03-23 01:25:33,760] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1177589: loss 0.4204
[2019-03-23 01:25:33,761] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1177589: learning rate 0.0010
[2019-03-23 01:25:34,082] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1177735: loss 0.2001
[2019-03-23 01:25:34,087] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1177737: learning rate 0.0010
[2019-03-23 01:25:34,488] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1177917: loss 0.6655
[2019-03-23 01:25:34,489] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1177917: learning rate 0.0010
[2019-03-23 01:25:34,509] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1177926: loss 0.4253
[2019-03-23 01:25:34,513] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1177926: learning rate 0.0010
[2019-03-23 01:25:34,629] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:25:34,642] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4529
[2019-03-23 01:25:34,647] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.876086033727478, 6.911200000000001, 6.9112, 121.9260426156618, 644049.208679685, 644049.2086796846, 172143.727768486], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4575600.0000, 
sim time next is 4576200.0000, 
raw observation next is [22.58333333333333, 96.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8656321800624956, 6.9112, 6.9112, 121.9260426156618, 637540.6649169078, 637540.6649169078, 170482.9726250153], 
processed observation next is [0.0, 1.0, 0.3919753086419751, 0.9666666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8320402250781195, 0.0, 0.0, 0.8094621288201359, 0.22769309461318135, 0.22769309461318135, 0.32785187043272174], 
reward next is 0.6721, 
noisyNet noise sample is [array([-0.081598], dtype=float32), 2.0564265]. 
=============================================
[2019-03-23 01:25:34,877] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1178093: loss -195.9559
[2019-03-23 01:25:34,879] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1178095: learning rate 0.0010
[2019-03-23 01:25:34,970] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1178133: loss 0.1015
[2019-03-23 01:25:34,971] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1178133: learning rate 0.0010
[2019-03-23 01:25:35,360] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1178312: loss 0.8829
[2019-03-23 01:25:35,362] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1178312: learning rate 0.0010
[2019-03-23 01:25:35,432] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1178345: loss 0.9792
[2019-03-23 01:25:35,433] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1178345: learning rate 0.0010
[2019-03-23 01:25:35,475] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1178361: loss 0.6631
[2019-03-23 01:25:35,480] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1178363: learning rate 0.0010
[2019-03-23 01:25:36,480] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1178825: loss 0.6567
[2019-03-23 01:25:36,483] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1178826: learning rate 0.0010
[2019-03-23 01:25:36,693] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1178920: loss 6.1825
[2019-03-23 01:25:36,697] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1178922: learning rate 0.0010
[2019-03-23 01:25:39,169] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1180055: loss -27.7035
[2019-03-23 01:25:39,173] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1180055: learning rate 0.0010
[2019-03-23 01:25:40,229] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1180544: loss -160.2881
[2019-03-23 01:25:40,232] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1180545: learning rate 0.0010
[2019-03-23 01:25:42,272] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1181469: loss 9.5407
[2019-03-23 01:25:42,275] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1181469: learning rate 0.0010
[2019-03-23 01:25:48,706] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 5.3852306e-27 1.6329024e-25 1.9056801e-25 1.3264694e-29], sum to 1.0000
[2019-03-23 01:25:48,713] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1490
[2019-03-23 01:25:48,722] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 687284.6638056391 W.
[2019-03-23 01:25:48,728] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.13333333333333, 92.66666666666666, 1.0, 2.0, 0.3006868350854187, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4787742868361701, 6.9112, 6.9112, 121.9260426156618, 687284.6638056391, 687284.6638056391, 195399.2689895009], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4758000.0000, 
sim time next is 4758600.0000, 
raw observation next is [24.16666666666667, 92.33333333333333, 1.0, 2.0, 0.2994992088736116, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4769573109208171, 6.9112, 6.9112, 121.9260426156618, 686058.1626092664, 686058.1626092664, 195053.8885967879], 
processed observation next is [1.0, 0.043478260869565216, 0.45061728395061745, 0.9233333333333333, 1.0, 1.0, 0.1660704867542995, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.34619663865102135, 0.0, 0.0, 0.8094621288201359, 0.24502077236045228, 0.24502077236045228, 0.3751036319168998], 
reward next is 0.6249, 
noisyNet noise sample is [array([1.0365144], dtype=float32), -2.3587346]. 
=============================================
[2019-03-23 01:25:49,412] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:25:49,419] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7602
[2019-03-23 01:25:49,428] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1184731: loss 45.4116
[2019-03-23 01:25:49,429] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 769602.0651350217 W.
[2019-03-23 01:25:49,430] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1184732: learning rate 0.0010
[2019-03-23 01:25:49,434] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.08333333333333, 85.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9681992712670706, 7.019230506949532, 6.9112, 121.9255733349853, 769602.0651350217, 714281.0028455601, 183812.6621948106], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4608600.0000, 
sim time next is 4609200.0000, 
raw observation next is [24.46666666666667, 86.33333333333334, 1.0, 1.0, 0.3488957074343464, 1.0, 1.0, 0.3488957074343464, 1.0, 2.0, 0.5554941621998578, 6.9112, 6.9112, 121.94756008, 1195074.696866237, 1195074.696866237, 275431.6956953271], 
processed observation next is [1.0, 0.34782608695652173, 0.46172839506172847, 0.8633333333333334, 1.0, 0.5, 0.2248758421837457, 1.0, 0.5, 0.2248758421837457, 1.0, 1.0, 0.44436770274982224, 0.0, 0.0, 0.8096049824067558, 0.42681239173794183, 0.42681239173794183, 0.529676337875629], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5645436], dtype=float32), -0.39574307]. 
=============================================
[2019-03-23 01:25:49,732] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1184869: loss -101.3751
[2019-03-23 01:25:49,735] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1184869: learning rate 0.0010
[2019-03-23 01:25:50,734] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 6.8033722e-32 2.2040469e-29 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 01:25:50,741] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2143
[2019-03-23 01:25:50,750] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 753419.3371070717 W.
[2019-03-23 01:25:50,759] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3249809323710715, 1.0, 2.0, 0.3249809323710715, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 753419.3371070717, 753419.337107072, 187169.2505385788], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4676400.0000, 
sim time next is 4677000.0000, 
raw observation next is [23.0, 94.00000000000001, 1.0, 2.0, 0.3685805411278025, 1.0, 2.0, 0.3685805411278025, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 855999.033673447, 855999.0336734474, 198474.760337217], 
processed observation next is [1.0, 0.13043478260869565, 0.4074074074074074, 0.9400000000000002, 1.0, 1.0, 0.24831016800928868, 1.0, 1.0, 0.24831016800928868, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30571394059765966, 0.30571394059765983, 0.381682231417725], 
reward next is 0.6183, 
noisyNet noise sample is [array([-0.2829354], dtype=float32), -0.4008054]. 
=============================================
[2019-03-23 01:25:50,790] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[42.022728]
 [42.430893]
 [41.916595]
 [42.719894]
 [41.2817  ]], R is [[42.09202576]
 [41.67110443]
 [41.25439453]
 [40.84185028]
 [40.43343353]].
[2019-03-23 01:25:51,192] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1185525: loss -22.3951
[2019-03-23 01:25:51,197] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1185526: learning rate 0.0010
[2019-03-23 01:25:51,289] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.2231205e-23 1.0050566e-21 9.6393013e-14 7.6631920e-26], sum to 1.0000
[2019-03-23 01:25:51,297] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2394
[2019-03-23 01:25:51,305] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1578827.862249834 W.
[2019-03-23 01:25:51,309] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 82.33333333333334, 1.0, 2.0, 0.7578457358589564, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1578827.862249834, 1578827.862249834, 328008.6697086301], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4614000.0000, 
sim time next is 4614600.0000, 
raw observation next is [26.0, 80.66666666666667, 1.0, 2.0, 0.7406489493315389, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1559198.439652309, 1559198.439652309, 324742.4514512456], 
processed observation next is [1.0, 0.391304347826087, 0.5185185185185185, 0.8066666666666668, 1.0, 1.0, 0.691248749204213, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5568565855901104, 0.5568565855901104, 0.6245047143293184], 
reward next is 0.3755, 
noisyNet noise sample is [array([0.06911973], dtype=float32), -1.9480577]. 
=============================================
[2019-03-23 01:25:51,577] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1185699: loss 0.3071
[2019-03-23 01:25:51,581] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1185700: learning rate 0.0010
[2019-03-23 01:25:51,888] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1185839: loss -88.1939
[2019-03-23 01:25:51,893] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1185841: learning rate 0.0010
[2019-03-23 01:25:51,957] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1185870: loss 63.2827
[2019-03-23 01:25:51,958] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1185871: learning rate 0.0010
[2019-03-23 01:25:52,088] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.00000000e+00 1.14426655e-26 2.38531595e-22 8.86867719e-30
 1.44384225e-26], sum to 1.0000
[2019-03-23 01:25:52,096] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9857
[2019-03-23 01:25:52,104] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 758815.3493345275 W.
[2019-03-23 01:25:52,110] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.93333333333333, 94.33333333333334, 1.0, 2.0, 0.2219365655811787, 1.0, 2.0, 0.2219365655811787, 1.0, 1.0, 0.3533302403745666, 6.9112, 6.9112, 121.94756008, 758815.3493345275, 758815.3493345275, 227894.4617582668], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4670400.0000, 
sim time next is 4671000.0000, 
raw observation next is [24.9, 94.5, 1.0, 2.0, 0.3323884664110318, 1.0, 2.0, 0.3323884664110318, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 757637.8051193348, 757637.8051193352, 188414.9093364565], 
processed observation next is [1.0, 0.043478260869565216, 0.47777777777777775, 0.945, 1.0, 1.0, 0.2052243647750379, 1.0, 1.0, 0.2052243647750379, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27058493039976245, 0.27058493039976256, 0.3623363641085702], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.965676], dtype=float32), 0.98576766]. 
=============================================
[2019-03-23 01:25:52,126] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[38.057545]
 [38.865376]
 [39.0425  ]
 [39.53606 ]
 [39.133858]], R is [[37.44330215]
 [37.63061142]
 [37.25430679]
 [37.55493927]
 [37.74098206]].
[2019-03-23 01:25:52,194] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1185976: loss -150.0097
[2019-03-23 01:25:52,196] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1185976: learning rate 0.0010
[2019-03-23 01:25:52,672] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1186194: loss 47.5890
[2019-03-23 01:25:52,674] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1186195: learning rate 0.0010
[2019-03-23 01:25:52,697] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1186205: loss 23.8615
[2019-03-23 01:25:52,698] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1186205: learning rate 0.0010
[2019-03-23 01:25:52,768] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1186234: loss 11.7440
[2019-03-23 01:25:52,771] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1186235: learning rate 0.0010
[2019-03-23 01:25:53,013] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1186347: loss -97.7214
[2019-03-23 01:25:53,015] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1186348: learning rate 0.0010
[2019-03-23 01:25:53,642] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1186626: loss -75.4269
[2019-03-23 01:25:53,644] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1186626: learning rate 0.0010
[2019-03-23 01:25:53,925] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1186761: loss 31.9801
[2019-03-23 01:25:53,930] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1186761: learning rate 0.0010
[2019-03-23 01:25:55,954] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.8240073e-17 5.7340048e-15 6.0499800e-18 1.0000000e+00 2.0249779e-30], sum to 1.0000
[2019-03-23 01:25:55,964] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7800
[2019-03-23 01:25:55,971] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.38333333333333, 86.33333333333334, 1.0, 2.0, 0.9183343253046813, 1.0, 1.0, 0.9183343253046813, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9255871275051, 2094954.328191153, 2094954.328191153, 395078.9870167245], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4719000.0000, 
sim time next is 4719600.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.9105464558978875, 1.0, 2.0, 0.9105464558978875, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260424767687, 2077167.542975698, 2077167.542975698, 391552.1502017472], 
processed observation next is [1.0, 0.6521739130434783, 0.5555555555555556, 0.89, 1.0, 1.0, 0.8935076855927232, 1.0, 1.0, 0.8935076855927232, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621278980302, 0.7418455510627493, 0.7418455510627493, 0.7529849042341292], 
reward next is 0.2470, 
noisyNet noise sample is [array([1.1916016], dtype=float32), 1.6831144]. 
=============================================
[2019-03-23 01:25:57,099] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1188200: loss -219.6344
[2019-03-23 01:25:57,105] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1188203: learning rate 0.0010
[2019-03-23 01:25:58,421] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1188740: loss -224.2275
[2019-03-23 01:25:58,425] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1188740: learning rate 0.0010
[2019-03-23 01:25:58,861] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9865317e-01 1.3468119e-03 1.1927292e-10 1.6037919e-19 1.3920045e-37], sum to 1.0000
[2019-03-23 01:25:58,867] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2238
[2019-03-23 01:25:58,876] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 944470.4433686096 W.
[2019-03-23 01:25:58,882] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.75, 84.0, 1.0, 2.0, 0.4143046190243825, 1.0, 2.0, 0.4143046190243825, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 944470.4433686096, 944470.4433686101, 210153.5047976114], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4986600.0000, 
sim time next is 4987200.0000, 
raw observation next is [26.8, 84.0, 1.0, 2.0, 0.6411912630064712, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 730744.7049545012, 730744.7049545012, 165311.5555416672], 
processed observation next is [1.0, 0.7391304347826086, 0.5481481481481482, 0.84, 1.0, 1.0, 0.5728467416743704, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2609802517694647, 0.2609802517694647, 0.3179068375801293], 
reward next is 0.6821, 
noisyNet noise sample is [array([-0.6494054], dtype=float32), 0.10035264]. 
=============================================
[2019-03-23 01:26:00,599] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1189764: loss -285.4734
[2019-03-23 01:26:00,603] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1189766: learning rate 0.0010
[2019-03-23 01:26:04,439] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.0104598e-32 2.7502304e-22 7.0290057e-10 7.2467081e-33], sum to 1.0000
[2019-03-23 01:26:04,451] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9424
[2019-03-23 01:26:04,457] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2050280.962369176 W.
[2019-03-23 01:26:04,464] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.08333333333333, 89.83333333333333, 1.0, 2.0, 0.8987739786421935, 1.0, 2.0, 0.8987739786421935, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2050280.962369176, 2050280.962369176, 386260.796217838], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4873800.0000, 
sim time next is 4874400.0000, 
raw observation next is [27.3, 89.0, 1.0, 2.0, 0.6091627459630482, 1.0, 2.0, 0.6091627459630482, 1.0, 1.0, 0.969806930618773, 6.911199999999999, 6.9112, 121.94756008, 2084470.238525755, 2084470.238525755, 400390.529515358], 
processed observation next is [1.0, 0.43478260869565216, 0.5666666666666667, 0.89, 1.0, 1.0, 0.5347175547179145, 1.0, 1.0, 0.5347175547179145, 1.0, 0.5, 0.9622586632734661, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7444536566163411, 0.7444536566163411, 0.7699817875295346], 
reward next is 0.2300, 
noisyNet noise sample is [array([0.16588704], dtype=float32), -1.7852709]. 
=============================================
[2019-03-23 01:26:07,061] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1192790: loss -268.5455
[2019-03-23 01:26:07,063] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1192790: learning rate 0.0010
[2019-03-23 01:26:07,305] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1192902: loss -177.4024
[2019-03-23 01:26:07,307] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1192903: learning rate 0.0010
[2019-03-23 01:26:08,731] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1193573: loss -267.3111
[2019-03-23 01:26:08,735] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1193574: learning rate 0.0010
[2019-03-23 01:26:09,099] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1193741: loss -214.2584
[2019-03-23 01:26:09,103] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1193741: learning rate 0.0010
[2019-03-23 01:26:09,446] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1193901: loss -244.8365
[2019-03-23 01:26:09,450] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1193903: learning rate 0.0010
[2019-03-23 01:26:09,595] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1193974: loss -217.0610
[2019-03-23 01:26:09,596] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1193974: learning rate 0.0010
[2019-03-23 01:26:09,732] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1194041: loss -124.7470
[2019-03-23 01:26:09,734] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1194041: learning rate 0.0010
[2019-03-23 01:26:10,038] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1194181: loss -152.7943
[2019-03-23 01:26:10,040] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1194181: learning rate 0.0010
[2019-03-23 01:26:10,096] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1194209: loss -158.6080
[2019-03-23 01:26:10,098] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1194210: learning rate 0.0010
[2019-03-23 01:26:10,113] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1194214: loss -136.8949
[2019-03-23 01:26:10,116] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1194215: learning rate 0.0010
[2019-03-23 01:26:10,255] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1194283: loss 63.2458
[2019-03-23 01:26:10,257] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1194285: learning rate 0.0010
[2019-03-23 01:26:10,795] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.0111733e-13 7.2833848e-30 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 01:26:10,803] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7341
[2019-03-23 01:26:10,810] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1704174.479546672 W.
[2019-03-23 01:26:10,816] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.4981315407168819, 1.0, 2.0, 0.4981315407168819, 1.0, 2.0, 0.7930416358329697, 6.911199999999999, 6.9112, 121.94756008, 1704174.479546672, 1704174.479546672, 342672.9177736011], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4978800.0000, 
sim time next is 4979400.0000, 
raw observation next is [28.0, 74.83333333333334, 1.0, 2.0, 0.5753609354548812, 1.0, 2.0, 0.5753609354548812, 1.0, 2.0, 0.915993347441657, 6.911199999999999, 6.9112, 121.94756008, 1968677.66858638, 1968677.668586381, 382114.4821117485], 
processed observation next is [1.0, 0.6521739130434783, 0.5925925925925926, 0.7483333333333334, 1.0, 1.0, 0.4944773041129538, 1.0, 1.0, 0.4944773041129538, 1.0, 1.0, 0.8949916843020711, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7030991673522786, 0.703099167352279, 0.7348355425225932], 
reward next is 0.2652, 
noisyNet noise sample is [array([2.7207887], dtype=float32), 0.5155402]. 
=============================================
[2019-03-23 01:26:11,178] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1194712: loss -163.4586
[2019-03-23 01:26:11,184] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1194713: learning rate 0.0010
[2019-03-23 01:26:11,380] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1194805: loss -184.7704
[2019-03-23 01:26:11,382] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1194806: learning rate 0.0010
[2019-03-23 01:26:12,819] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.6751203e-13 2.0478765e-17 1.4912614e-18 1.0000000e+00 7.4232995e-37], sum to 1.0000
[2019-03-23 01:26:12,827] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0395
[2019-03-23 01:26:12,833] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.35, 81.5, 1.0, 2.0, 0.7363291917005105, 1.0, 1.0, 0.7363291917005105, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1679363.938857129, 1679363.93885713, 318147.2073620684], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4984200.0000, 
sim time next is 4984800.0000, 
raw observation next is [27.13333333333333, 82.33333333333334, 1.0, 2.0, 0.7624593519396031, 1.0, 2.0, 0.7624593519396031, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1739017.639688469, 1739017.639688468, 328486.2867865461], 
processed observation next is [1.0, 0.6956521739130435, 0.5604938271604937, 0.8233333333333335, 1.0, 1.0, 0.7172135142138132, 1.0, 1.0, 0.7172135142138132, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6210777284601675, 0.6210777284601672, 0.6317043976664348], 
reward next is 0.3683, 
noisyNet noise sample is [array([-1.2505856], dtype=float32), 0.8826487]. 
=============================================
[2019-03-23 01:26:12,840] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 3.5271580e-26 2.0071847e-27 0.0000000e+00 2.4391077e-37], sum to 1.0000
[2019-03-23 01:26:12,847] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0175
[2019-03-23 01:26:12,856] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 730774.6371485895 W.
[2019-03-23 01:26:12,860] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 98.0, 1.0, 2.0, 0.2137391894581271, 1.0, 2.0, 0.2137391894581271, 1.0, 2.0, 0.3402797506167664, 6.911200000000001, 6.9112, 121.94756008, 730774.6371485895, 730774.637148589, 225135.1257842502], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5001600.0000, 
sim time next is 5002200.0000, 
raw observation next is [24.0, 97.0, 1.0, 2.0, 0.3179283981111764, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5061523639980546, 6.911199999999999, 6.9112, 121.9260426156618, 724662.3140372544, 724662.3140372549, 200124.2100437599], 
processed observation next is [1.0, 0.9130434782608695, 0.4444444444444444, 0.97, 1.0, 1.0, 0.18800999775140048, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.38269045499756826, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25880796929901945, 0.2588079692990196, 0.38485425008415364], 
reward next is 0.6151, 
noisyNet noise sample is [array([1.1753006], dtype=float32), 0.27489993]. 
=============================================
[2019-03-23 01:26:12,877] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 6.846547e-37 0.000000e+00], sum to 1.0000
[2019-03-23 01:26:12,883] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7771
[2019-03-23 01:26:12,891] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 928519.9485248583 W.
[2019-03-23 01:26:12,895] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 76.33333333333334, 1.0, 2.0, 0.8146239138299729, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 928519.9485248583, 928519.9485248579, 198988.4448202822], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5056800.0000, 
sim time next is 5057400.0000, 
raw observation next is [30.0, 75.66666666666666, 1.0, 2.0, 0.2699153295239614, 1.0, 1.0, 0.2699153295239614, 1.0, 1.0, 0.4297139951307304, 6.9112, 6.9112, 121.94756008, 922956.5736728768, 922956.5736728768, 244797.9727274355], 
processed observation next is [0.0, 0.5217391304347826, 0.6666666666666666, 0.7566666666666666, 1.0, 1.0, 0.13085158276662073, 1.0, 0.5, 0.13085158276662073, 1.0, 0.5, 0.28714249391341296, 0.0, 0.0, 0.8096049824067558, 0.32962734774031316, 0.32962734774031316, 0.4707653321681452], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04747974], dtype=float32), -0.46369803]. 
=============================================
[2019-03-23 01:26:14,274] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1196157: loss 5.2047
[2019-03-23 01:26:14,275] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1196158: learning rate 0.0010
[2019-03-23 01:26:15,664] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1196790: loss -28.3338
[2019-03-23 01:26:15,665] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1196790: learning rate 0.0010
[2019-03-23 01:26:16,699] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.3762941e-20 4.8420768e-36 6.1247673e-28 4.3113147e-37], sum to 1.0000
[2019-03-23 01:26:16,705] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7751
[2019-03-23 01:26:16,712] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 944328.3200474189 W.
[2019-03-23 01:26:16,719] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 70.83333333333333, 1.0, 2.0, 0.4142423131133587, 1.0, 2.0, 0.4142423131133587, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 944328.3200474189, 944328.3200474194, 210137.9076247652], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5071800.0000, 
sim time next is 5072400.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.4084675907300974, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6502937073030239, 6.911199999999999, 6.9112, 121.9260426156618, 931155.9647937408, 931155.9647937412, 226734.6432882753], 
processed observation next is [0.0, 0.7391304347826086, 0.7037037037037037, 0.7, 1.0, 1.0, 0.2957947508691636, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.5628671341287799, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3325557017120503, 0.33255570171205046, 0.4360281601697602], 
reward next is 0.5640, 
noisyNet noise sample is [array([-0.77251565], dtype=float32), 0.74717885]. 
=============================================
[2019-03-23 01:26:17,661] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1197726: loss 39.1566
[2019-03-23 01:26:17,662] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1197726: learning rate 0.0010
[2019-03-23 01:26:17,938] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 9.9305834e-24 1.4077485e-22 1.1161571e-08 3.3478796e-32], sum to 1.0000
[2019-03-23 01:26:17,946] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6376
[2019-03-23 01:26:17,954] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 797679.2035729453 W.
[2019-03-23 01:26:17,960] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.51666666666667, 88.33333333333334, 1.0, 2.0, 0.6998923328327609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 797679.2035729453, 797679.2035729453, 176124.6628649394], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5260200.0000, 
sim time next is 5260800.0000, 
raw observation next is [26.43333333333334, 88.66666666666667, 1.0, 2.0, 0.3526203871730032, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5613831404236884, 6.9112, 6.9112, 121.9260426156618, 803778.1095693308, 803778.1095693308, 209932.2448243908], 
processed observation next is [1.0, 0.9130434782608695, 0.5345679012345682, 0.8866666666666667, 1.0, 1.0, 0.22930998472976571, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.45172892552961047, 0.0, 0.0, 0.8094621288201359, 0.2870636105604753, 0.2870636105604753, 0.4037158554315208], 
reward next is 0.5963, 
noisyNet noise sample is [array([-0.16104648], dtype=float32), -0.10860223]. 
=============================================
[2019-03-23 01:26:22,515] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 01:26:22,517] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:26:22,517] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:26:22,518] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:26:22,518] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:26:22,519] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:26:22,521] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:26:22,522] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:26:22,520] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:26:22,521] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:26:22,525] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:26:22,547] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run49
[2019-03-23 01:26:22,547] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run49
[2019-03-23 01:26:22,594] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run49
[2019-03-23 01:26:22,617] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run49
[2019-03-23 01:26:22,617] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run49
[2019-03-23 01:26:29,726] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.1227854], dtype=float32), -0.28153]
[2019-03-23 01:26:29,728] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.56666666666667, 78.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5461983950926865, 6.9112, 6.9112, 121.9260426156618, 389999.3306730018, 389999.3306730018, 110585.2389807574]
[2019-03-23 01:26:29,729] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:26:29,732] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6598694217867721
[2019-03-23 01:26:33,896] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.1227854], dtype=float32), -0.28153]
[2019-03-23 01:26:33,896] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.0, 33.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4821580424525772, 6.9112, 6.9112, 121.9260426156618, 344262.6521716697, 344262.6521716697, 92037.16313696415]
[2019-03-23 01:26:33,899] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:26:33,902] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8365704803153422
[2019-03-23 01:26:37,941] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.1227854], dtype=float32), -0.28153]
[2019-03-23 01:26:37,942] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.33333333333333, 61.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3975835848019993, 6.9112, 6.9112, 121.9260426156618, 283864.9969819394, 283864.9969819394, 93922.92840913258]
[2019-03-23 01:26:37,943] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:26:37,946] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9971955869222242
[2019-03-23 01:26:42,600] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.1227854], dtype=float32), -0.28153]
[2019-03-23 01:26:42,603] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.26666666666667, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5459851468133904, 6.9112, 6.9112, 121.9260426156618, 399236.7643035965, 399236.7643035965, 122178.4296125197]
[2019-03-23 01:26:42,605] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:26:42,609] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6218679324894089
[2019-03-23 01:26:58,332] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.1227854], dtype=float32), -0.28153]
[2019-03-23 01:26:58,333] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.92164191666667, 50.22263780666667, 1.0, 2.0, 0.8548371906401806, 1.0, 2.0, 0.8548371906401806, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 127.6213244969452, 2014903.755607197, 2014903.755607197, 371251.8637238942]
[2019-03-23 01:26:58,334] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:26:58,339] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.4604735e-10 0.0000000e+00 4.1850189e-37 1.0000000e+00 1.8038914e-31], sampled 0.34625019761238074
[2019-03-23 01:27:39,951] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.1227854], dtype=float32), -0.28153]
[2019-03-23 01:27:39,952] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.41666666666666, 87.16666666666667, 1.0, 2.0, 0.7433120040313741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 847192.6912492398, 847192.6912492398, 184509.8407214692]
[2019-03-23 01:27:39,952] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:27:39,955] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 1.0508472e-34 2.9343790e-38 0.0000000e+00], sampled 0.7783015963418597
[2019-03-23 01:27:39,956] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 847192.6912492398 W.
[2019-03-23 01:27:40,156] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.1227854], dtype=float32), -0.28153]
[2019-03-23 01:27:40,156] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.85, 74.5, 1.0, 2.0, 0.540259840718008, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8601112614577077, 6.911200000000001, 6.9112, 121.9258607613757, 1231835.363701634, 1231835.363701633, 271337.8196398977]
[2019-03-23 01:27:40,159] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:27:40,161] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9999893e-01 0.0000000e+00 4.6611331e-25 1.1141364e-06 2.0579837e-33], sampled 0.7324827337565182
[2019-03-23 01:27:40,164] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1231835.363701634 W.
[2019-03-23 01:28:10,261] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.1227854], dtype=float32), -0.28153]
[2019-03-23 01:28:10,262] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.16666666666667, 93.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4999902506747789, 6.911199999999999, 6.9112, 121.9260426156618, 360742.0682562892, 360742.0682562897, 116422.3757515038]
[2019-03-23 01:28:10,263] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:28:10,265] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5421718664567212
[2019-03-23 01:28:14,927] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7951.9074 2510774058.7953 717.0000
[2019-03-23 01:28:15,518] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8608.6237 2251038672.2708 502.0000
[2019-03-23 01:28:15,524] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8468.7259 2283340790.7429 634.0000
[2019-03-23 01:28:15,642] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8659.9197 2214492210.1927 520.0000
[2019-03-23 01:28:15,669] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8444.2121 2322655044.7322 555.0000
[2019-03-23 01:28:16,683] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1200000, evaluation results [1200000.0, 7951.907436329118, 2510774058.7953086, 717.0, 8608.623673697755, 2251038672.2707705, 502.0, 8659.919680914636, 2214492210.192695, 520.0, 8444.212135205427, 2322655044.7322245, 555.0, 8468.725935505714, 2283340790.7429256, 634.0]
[2019-03-23 01:28:18,450] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1200811: loss 39.5020
[2019-03-23 01:28:18,452] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1200811: learning rate 0.0010
[2019-03-23 01:28:18,631] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1200894: loss 9.2146
[2019-03-23 01:28:18,633] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1200895: learning rate 0.0010
[2019-03-23 01:28:19,243] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.8539495e-28 4.3532861e-32 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 01:28:19,252] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7532
[2019-03-23 01:28:19,263] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 871129.2699850696 W.
[2019-03-23 01:28:19,268] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.06666666666667, 90.16666666666667, 1.0, 2.0, 0.7641259950237215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 871129.2699850696, 871129.2699850696, 188644.0157370383], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5386200.0000, 
sim time next is 5386800.0000, 
raw observation next is [25.23333333333333, 89.33333333333334, 1.0, 2.0, 0.3746898226349515, 1.0, 1.0, 0.3746898226349515, 1.0, 1.0, 0.5965184004304446, 6.911200000000001, 6.9112, 121.94756008, 1281525.189722145, 1281525.189722144, 286172.462734153], 
processed observation next is [1.0, 0.34782608695652173, 0.49012345679012337, 0.8933333333333334, 1.0, 1.0, 0.25558312218446605, 1.0, 0.5, 0.25558312218446605, 1.0, 0.5, 0.4956480005380557, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4576875677579089, 0.4576875677579086, 0.5503316591041404], 
reward next is 0.4497, 
noisyNet noise sample is [array([0.06631014], dtype=float32), -1.4647765]. 
=============================================
[2019-03-23 01:28:20,110] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1201566: loss 96.1152
[2019-03-23 01:28:20,112] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1201569: learning rate 0.0010
[2019-03-23 01:28:20,475] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1201731: loss 1.3884
[2019-03-23 01:28:20,478] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1201731: learning rate 0.0010
[2019-03-23 01:28:20,845] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1201905: loss 24.7989
[2019-03-23 01:28:20,847] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1201905: learning rate 0.0010
[2019-03-23 01:28:21,011] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1201979: loss 73.2191
[2019-03-23 01:28:21,015] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1201980: learning rate 0.0010
[2019-03-23 01:28:21,097] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1202011: loss -132.9874
[2019-03-23 01:28:21,101] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1202011: learning rate 0.0010
[2019-03-23 01:28:21,173] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1202049: loss -60.4963
[2019-03-23 01:28:21,176] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1202052: learning rate 0.0010
[2019-03-23 01:28:21,476] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.0217457e-27 1.5997455e-23 7.8326729e-15 1.3074316e-26], sum to 1.0000
[2019-03-23 01:28:21,485] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2594
[2019-03-23 01:28:21,491] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1439400.822079517 W.
[2019-03-23 01:28:21,498] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.1, 84.0, 1.0, 2.0, 0.6213914640775805, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9782860237450614, 6.9112, 6.9112, 121.9254484905762, 1439400.822079517, 1439400.822079517, 299717.1794596689], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5307600.0000, 
sim time next is 5308200.0000, 
raw observation next is [24.25, 83.5, 1.0, 2.0, 0.6306803250019782, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9813196693452887, 6.911200000000001, 6.9112, 121.9260424344924, 1447353.981694507, 1447353.981694507, 301966.4046477867], 
processed observation next is [1.0, 0.43478260869565216, 0.4537037037037037, 0.835, 1.0, 1.0, 0.5603337202404503, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9766495866816107, 8.881784197001253e-17, 0.0, 0.8094621276173596, 0.5169121363194668, 0.5169121363194668, 0.5807046243226667], 
reward next is 0.4193, 
noisyNet noise sample is [array([-0.01894205], dtype=float32), -0.7971582]. 
=============================================
[2019-03-23 01:28:21,583] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1202232: loss -70.4400
[2019-03-23 01:28:21,584] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1202232: learning rate 0.0010
[2019-03-23 01:28:21,632] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1202246: loss -17.3388
[2019-03-23 01:28:21,637] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1202247: learning rate 0.0010
[2019-03-23 01:28:21,750] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1202309: loss 10.0894
[2019-03-23 01:28:21,751] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1202309: learning rate 0.0010
[2019-03-23 01:28:22,585] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 4.1809964e-30 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 01:28:22,595] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0624
[2019-03-23 01:28:22,600] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 88.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9189826809144311, 6.911200000000001, 6.9112, 121.9260425833843, 675646.532760444, 675646.5327604435, 177786.290552057], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5290200.0000, 
sim time next is 5290800.0000, 
raw observation next is [23.5, 88.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9040403848817026, 6.911200000000001, 6.9112, 121.926042615652, 667302.0285639882, 667302.0285639877, 175060.8687995573], 
processed observation next is [1.0, 0.21739130434782608, 0.42592592592592593, 0.8833333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8800504811021281, 8.881784197001253e-17, 0.0, 0.8094621288200708, 0.2383221530585672, 0.23832215305856702, 0.33665551692222556], 
reward next is 0.6633, 
noisyNet noise sample is [array([1.5527186], dtype=float32), -0.50415045]. 
=============================================
[2019-03-23 01:28:22,625] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1202703: loss 112.3114
[2019-03-23 01:28:22,627] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1202703: learning rate 0.0010
[2019-03-23 01:28:23,078] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1202881: loss -55.1399
[2019-03-23 01:28:23,084] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1202882: learning rate 0.0010
[2019-03-23 01:28:26,052] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1204227: loss 30.5603
[2019-03-23 01:28:26,054] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1204227: learning rate 0.0010
[2019-03-23 01:28:26,308] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.7892602e-29 5.7597606e-31 1.8121108e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 01:28:26,316] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1160
[2019-03-23 01:28:26,328] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1027768.655537647 W.
[2019-03-23 01:28:26,333] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.56666666666667, 84.33333333333334, 1.0, 2.0, 0.4508200086461896, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7177201359473989, 6.911199999999999, 6.9112, 121.9260426156618, 1027768.655537647, 1027768.655537648, 240300.0918928134], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5559600.0000, 
sim time next is 5560200.0000, 
raw observation next is [25.65, 84.0, 1.0, 2.0, 0.4949835628525504, 1.0, 1.0, 0.4949835628525504, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1128525.815663395, 1128525.815663395, 233835.1758214166], 
processed observation next is [1.0, 0.34782608695652173, 0.5055555555555555, 0.84, 1.0, 1.0, 0.39878995577684573, 1.0, 0.5, 0.39878995577684573, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4030449341654982, 0.4030449341654982, 0.44968303042580116], 
reward next is 0.5503, 
noisyNet noise sample is [array([0.64320636], dtype=float32), 0.16496886]. 
=============================================
[2019-03-23 01:28:27,354] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1204819: loss 19.6813
[2019-03-23 01:28:27,359] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1204819: learning rate 0.0010
[2019-03-23 01:28:29,008] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.5480778e-33 3.9749575e-12 6.2218104e-36], sum to 1.0000
[2019-03-23 01:28:29,018] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5614
[2019-03-23 01:28:29,029] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 688110.7512925799 W.
[2019-03-23 01:28:29,033] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 91.0, 1.0, 2.0, 0.2994921958276945, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4770776748190481, 6.9112, 6.9112, 121.9260426156618, 688110.7512925799, 688110.7512925799, 195010.5884919325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5376000.0000, 
sim time next is 5376600.0000, 
raw observation next is [24.25, 91.0, 1.0, 2.0, 0.5939191934695501, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686250.1481521316, 686250.1481521316, 157489.0738889625], 
processed observation next is [1.0, 0.21739130434782608, 0.4537037037037037, 0.91, 1.0, 1.0, 0.5165704684161311, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2450893386257613, 0.2450893386257613, 0.3028636036326202], 
reward next is 0.6971, 
noisyNet noise sample is [array([0.1609768], dtype=float32), 0.79130584]. 
=============================================
[2019-03-23 01:28:29,400] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1205755: loss 69.1513
[2019-03-23 01:28:29,405] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1205756: learning rate 0.0010
[2019-03-23 01:28:36,252] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1208871: loss -45.3750
[2019-03-23 01:28:36,254] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1208871: learning rate 0.0010
[2019-03-23 01:28:36,502] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1208984: loss -43.4470
[2019-03-23 01:28:36,505] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1208984: learning rate 0.0010
[2019-03-23 01:28:36,763] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1209099: loss 29.9666
[2019-03-23 01:28:36,767] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1209100: learning rate 0.0010
[2019-03-23 01:28:38,051] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1209697: loss 101.6066
[2019-03-23 01:28:38,053] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1209697: learning rate 0.0010
[2019-03-23 01:28:38,477] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1209888: loss -54.1473
[2019-03-23 01:28:38,480] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1209889: learning rate 0.0010
[2019-03-23 01:28:38,775] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1210025: loss -83.8306
[2019-03-23 01:28:38,780] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1210025: learning rate 0.0010
[2019-03-23 01:28:38,962] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1210113: loss 10.8886
[2019-03-23 01:28:38,964] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1210113: learning rate 0.0010
[2019-03-23 01:28:39,059] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1210152: loss -27.0798
[2019-03-23 01:28:39,063] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1210153: learning rate 0.0010
[2019-03-23 01:28:39,306] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1210267: loss -78.2097
[2019-03-23 01:28:39,309] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1210267: learning rate 0.0010
[2019-03-23 01:28:39,544] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1210375: loss 59.7252
[2019-03-23 01:28:39,550] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1210377: learning rate 0.0010
[2019-03-23 01:28:39,773] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1210476: loss 34.3958
[2019-03-23 01:28:39,775] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1210476: learning rate 0.0010
[2019-03-23 01:28:40,527] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1210795: loss 75.2049
[2019-03-23 01:28:40,530] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1210796: learning rate 0.0010
[2019-03-23 01:28:41,152] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1211045: loss 35.3830
[2019-03-23 01:28:41,154] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1211047: learning rate 0.0010
[2019-03-23 01:28:42,727] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1211776: loss 49.4115
[2019-03-23 01:28:42,730] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1211776: learning rate 0.0010
[2019-03-23 01:28:44,072] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1212406: loss 14.7974
[2019-03-23 01:28:44,076] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1212406: learning rate 0.0010
[2019-03-23 01:28:45,972] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1213290: loss 17.1671
[2019-03-23 01:28:45,975] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1213291: learning rate 0.0010
[2019-03-23 01:28:53,222] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:28:53,234] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3509
[2019-03-23 01:28:53,237] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.2, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7362978097381586, 6.911199999999999, 6.9112, 121.9260426156618, 549766.0211481072, 549766.0211481077, 150356.9461168743], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5796000.0000, 
sim time next is 5796600.0000, 
raw observation next is [22.15, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9564417232752017, 7.917682810059738, 6.9112, 121.9987223994604, 1230211.620169036, 714495.229002947, 174946.5657806816], 
processed observation next is [1.0, 0.08695652173913043, 0.3759259259259259, 0.865, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9455521540940021, 0.10064828100597376, 0.0, 0.8099446470029106, 0.4393612929175129, 0.2551768675010525, 0.33643570342438767], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.33382043], dtype=float32), -0.25178024]. 
=============================================
[2019-03-23 01:28:53,663] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1216911: loss 1.4680
[2019-03-23 01:28:53,664] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1216911: learning rate 0.0010
[2019-03-23 01:28:53,745] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1216948: loss 3.7171
[2019-03-23 01:28:53,746] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1216948: learning rate 0.0010
[2019-03-23 01:28:54,495] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1217298: loss 687.4654
[2019-03-23 01:28:54,498] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1217299: learning rate 0.0010
[2019-03-23 01:28:55,555] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1217792: loss 8.6152
[2019-03-23 01:28:55,559] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1217793: learning rate 0.0010
[2019-03-23 01:28:55,918] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1217963: loss 1.6408
[2019-03-23 01:28:55,919] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1217963: learning rate 0.0010
[2019-03-23 01:28:56,234] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1218107: loss 8.0094
[2019-03-23 01:28:56,238] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1218108: learning rate 0.0010
[2019-03-23 01:28:56,431] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1218204: loss 3.8056
[2019-03-23 01:28:56,435] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1218205: learning rate 0.0010
[2019-03-23 01:28:56,454] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1218213: loss 5.7637
[2019-03-23 01:28:56,457] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1218214: learning rate 0.0010
[2019-03-23 01:28:56,704] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1218331: loss 5.4490
[2019-03-23 01:28:56,707] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1218332: learning rate 0.0010
[2019-03-23 01:28:57,173] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1218552: loss 5.8827
[2019-03-23 01:28:57,174] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1218552: learning rate 0.0010
[2019-03-23 01:28:57,227] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1218574: loss 8.9160
[2019-03-23 01:28:57,229] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1218575: learning rate 0.0010
[2019-03-23 01:28:57,827] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1218858: loss 5.9047
[2019-03-23 01:28:57,829] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1218858: learning rate 0.0010
[2019-03-23 01:28:58,588] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1219222: loss 1.4376
[2019-03-23 01:28:58,591] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1219223: learning rate 0.0010
[2019-03-23 01:28:59,655] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1219724: loss 24.2796
[2019-03-23 01:28:59,657] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1219724: learning rate 0.0010
[2019-03-23 01:29:00,008] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:29:00,016] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8898
[2019-03-23 01:29:00,022] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.93333333333333, 85.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8160526579088763, 6.9112, 6.9112, 121.9260426156618, 604783.5024734009, 604783.5024734009, 152128.9699587497], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5883000.0000, 
sim time next is 5883600.0000, 
raw observation next is [19.86666666666667, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.671933051042869, 6.9112, 6.9112, 121.9260426156618, 497637.2953880061, 497637.2953880061, 136654.3298328603], 
processed observation next is [1.0, 0.08695652173913043, 0.2913580246913582, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5899163138035862, 0.0, 0.0, 0.8094621288201359, 0.17772760549571645, 0.17772760549571645, 0.262796788140116], 
reward next is 0.7372, 
noisyNet noise sample is [array([0.02312649], dtype=float32), -2.2517238]. 
=============================================
[2019-03-23 01:29:00,884] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1220301: loss 20.1824
[2019-03-23 01:29:00,888] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1220302: learning rate 0.0010
[2019-03-23 01:29:02,140] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:29:02,149] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6832
[2019-03-23 01:29:02,153] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.65, 85.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7642173811729479, 6.911199999999999, 6.9112, 121.9260426156618, 569760.3210193092, 569760.3210193097, 154574.2473367066], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5959800.0000, 
sim time next is 5960400.0000, 
raw observation next is [22.63333333333333, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7596686511576096, 6.9112, 6.9112, 121.9260426156618, 566588.464542882, 566588.464542882, 153830.5899527839], 
processed observation next is [1.0, 1.0, 0.393827160493827, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.699585813947012, 0.0, 0.0, 0.8094621288201359, 0.2023530230510293, 0.2023530230510293, 0.2958280576015075], 
reward next is 0.7042, 
noisyNet noise sample is [array([0.78180087], dtype=float32), 0.1362157]. 
=============================================
[2019-03-23 01:29:02,967] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1221281: loss 15.6582
[2019-03-23 01:29:02,968] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1221281: learning rate 0.0010
[2019-03-23 01:29:10,532] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1224852: loss 7.7087
[2019-03-23 01:29:10,535] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1224853: learning rate 0.0010
[2019-03-23 01:29:10,645] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1224907: loss 10.5819
[2019-03-23 01:29:10,648] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1224908: learning rate 0.0010
[2019-03-23 01:29:10,844] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 01:29:10,845] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:29:10,846] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:29:10,847] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:29:10,848] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:29:10,848] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:29:10,850] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:29:10,849] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:29:10,851] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:29:10,852] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:29:10,852] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:29:10,875] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run50
[2019-03-23 01:29:10,900] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run50
[2019-03-23 01:29:10,900] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run50
[2019-03-23 01:29:10,948] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run50
[2019-03-23 01:29:10,949] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run50
[2019-03-23 01:29:14,467] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.11909539], dtype=float32), -0.25765702]
[2019-03-23 01:29:14,470] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.99965579, 16.49908805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5661042754902031, 6.911200000000001, 6.9112, 121.9260426156618, 404216.3735608603, 404216.3735608599, 100920.3300159872]
[2019-03-23 01:29:14,473] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:29:14,475] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.26229711798414046
[2019-03-23 01:29:54,533] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.11909539], dtype=float32), -0.25765702]
[2019-03-23 01:29:54,536] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.18333333333333, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9524193329786486, 6.911199999999999, 6.9112, 121.9259092166505, 711803.5902198089, 711803.5902198093, 174431.5024216902]
[2019-03-23 01:29:54,536] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:29:54,539] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.5445163e-34 0.0000000e+00], sampled 0.4188714821289442
[2019-03-23 01:29:54,541] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 711803.5902198089 W.
[2019-03-23 01:30:08,748] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.11909539], dtype=float32), -0.25765702]
[2019-03-23 01:30:08,751] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.2, 84.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7838710027527225, 6.9112, 6.9112, 121.9260426156618, 582091.909508787, 582091.909508787, 158401.3050666619]
[2019-03-23 01:30:08,753] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:30:08,757] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.846461621679656
[2019-03-23 01:30:09,756] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.11909539], dtype=float32), -0.25765702]
[2019-03-23 01:30:09,759] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.16666666666666, 79.83333333333334, 1.0, 2.0, 0.7145475514986119, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1529405.731963397, 1529405.731963397, 319889.1015108336]
[2019-03-23 01:30:09,760] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:30:09,762] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9931180e-01 8.6936293e-33 9.6273230e-29 6.8818952e-04 1.3059465e-37], sampled 0.03559599470711472
[2019-03-23 01:30:09,763] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1529405.731963397 W.
[2019-03-23 01:30:26,996] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.11909539], dtype=float32), -0.25765702]
[2019-03-23 01:30:26,997] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.33333333333334, 66.0, 1.0, 2.0, 0.5102522699036978, 1.0, 2.0, 0.5102522699036978, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1163363.76586093, 1163363.76586093, 238572.4512838001]
[2019-03-23 01:30:26,998] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:30:27,001] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9999881e-01 3.7734588e-34 1.5509163e-29 1.1684135e-06 0.0000000e+00], sampled 0.7996458724524168
[2019-03-23 01:30:27,003] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1163363.76586093 W.
[2019-03-23 01:30:30,921] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.11909539], dtype=float32), -0.25765702]
[2019-03-23 01:30:30,922] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.65, 71.0, 1.0, 2.0, 0.7159557079344521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 815996.650882165, 815996.650882165, 179189.3506937741]
[2019-03-23 01:30:30,924] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:30:30,927] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9918300e-01 0.0000000e+00 2.3062749e-33 8.1693416e-04 2.1868577e-38], sampled 0.8731259185524998
[2019-03-23 01:30:30,928] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 815996.650882165 W.
[2019-03-23 01:30:39,380] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.11909539], dtype=float32), -0.25765702]
[2019-03-23 01:30:39,381] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.16666666666667, 87.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7372767316348683, 6.911199999999999, 6.9112, 121.9260426156618, 550251.0177624619, 550251.0177624624, 150805.1296352828]
[2019-03-23 01:30:39,382] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:30:39,384] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.1018485236196367
[2019-03-23 01:30:43,723] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.11909539], dtype=float32), -0.25765702]
[2019-03-23 01:30:43,725] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.36666666666667, 82.66666666666667, 1.0, 2.0, 0.660406725485966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 752654.690192324, 752654.690192324, 168781.9056613451]
[2019-03-23 01:30:43,727] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:30:43,729] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.4254678e-01 0.0000000e+00 5.8944835e-31 5.7453189e-02 6.0720110e-34], sampled 0.7225764088872965
[2019-03-23 01:30:43,729] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 752654.690192324 W.
[2019-03-23 01:30:47,339] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.11909539], dtype=float32), -0.25765702]
[2019-03-23 01:30:47,340] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.1, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8515464534034758, 6.911200000000001, 6.9112, 121.9260426156618, 627703.4341071721, 627703.4341071716, 168529.5185562889]
[2019-03-23 01:30:47,341] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:30:47,344] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2152813e-25 0.0000000e+00], sampled 0.9937880786308358
[2019-03-23 01:30:48,460] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.11909539], dtype=float32), -0.25765702]
[2019-03-23 01:30:48,462] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.86666666666667, 52.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8035824835376316, 6.911200000000001, 6.9112, 121.9260426156618, 596785.8336719185, 596785.833671918, 160819.8100004854]
[2019-03-23 01:30:48,464] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:30:48,467] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 1.931418e-34 0.000000e+00], sampled 0.5999635139610984
[2019-03-23 01:30:56,731] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.11909539], dtype=float32), -0.25765702]
[2019-03-23 01:30:56,732] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.73991084, 100.281371995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7440572537810721, 6.911199999999999, 6.9112, 121.9260426156618, 553527.265778832, 553527.2657788324, 145799.0291153339]
[2019-03-23 01:30:56,734] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:30:56,739] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.0462906e-35 0.0000000e+00], sampled 0.9592742937361766
[2019-03-23 01:30:56,775] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.11909539], dtype=float32), -0.25765702]
[2019-03-23 01:30:56,779] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.17520038333333, 112.3749659166667, 1.0, 1.0, 0.6706525769529376, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9259696518883, 793435.1166143862, 793435.1166143859, 172011.0339910716]
[2019-03-23 01:30:56,781] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:30:56,783] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 2.7211759e-38 2.5214308e-17 1.1260560e-37], sampled 0.66522388919247
[2019-03-23 01:30:56,787] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 793435.1166143862 W.
[2019-03-23 01:31:03,520] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8584.7598 2248940342.8954 350.0000
[2019-03-23 01:31:03,526] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8039.9775 2503671288.1372 496.0000
[2019-03-23 01:31:04,168] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8496.2062 2317030452.4727 361.0000
[2019-03-23 01:31:04,200] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8536.2741 2280157293.2085 401.0000
[2019-03-23 01:31:04,286] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8703.5300 2213951854.4603 342.0000
[2019-03-23 01:31:05,299] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1225000, evaluation results [1225000.0, 8039.977530384937, 2503671288.137212, 496.0, 8584.759762725113, 2248940342.895368, 350.0, 8703.529985137846, 2213951854.460258, 342.0, 8496.206167634466, 2317030452.4727426, 361.0, 8536.274108397138, 2280157293.2085195, 401.0]
[2019-03-23 01:31:06,558] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1225577: loss 0.2279
[2019-03-23 01:31:06,560] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1225577: learning rate 0.0010
[2019-03-23 01:31:06,793] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1225685: loss 6.5182
[2019-03-23 01:31:06,795] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1225685: learning rate 0.0010
[2019-03-23 01:31:07,198] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1225869: loss 7.8806
[2019-03-23 01:31:07,203] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1225871: learning rate 0.0010
[2019-03-23 01:31:07,520] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1226016: loss 8.1619
[2019-03-23 01:31:07,523] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1226016: learning rate 0.0010
[2019-03-23 01:31:07,663] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1226082: loss 11.2466
[2019-03-23 01:31:07,666] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1226082: learning rate 0.0010
[2019-03-23 01:31:07,764] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1226125: loss 10.1276
[2019-03-23 01:31:07,766] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1226125: learning rate 0.0010
[2019-03-23 01:31:07,890] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:31:07,903] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9271
[2019-03-23 01:31:07,910] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.25, 62.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8882263089829162, 6.911199999999999, 6.9112, 121.9260426156618, 650476.0634750358, 650476.0634750363, 174298.3373786854], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6204600.0000, 
sim time next is 6205200.0000, 
raw observation next is [28.13333333333333, 63.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8937849823131399, 6.911199999999999, 6.9112, 121.9260426156618, 654196.3681895522, 654196.3681895526, 175104.5833877106], 
processed observation next is [1.0, 0.8260869565217391, 0.5975308641975308, 0.6333333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8672312278914248, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2336415600676972, 0.23364156006769735, 0.336739583437905], 
reward next is 0.6633, 
noisyNet noise sample is [array([0.42706254], dtype=float32), -1.3048733]. 
=============================================
[2019-03-23 01:31:07,976] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1226220: loss 9.3304
[2019-03-23 01:31:07,978] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1226220: learning rate 0.0010
[2019-03-23 01:31:08,413] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1226418: loss 10.0347
[2019-03-23 01:31:08,420] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1226420: learning rate 0.0010
[2019-03-23 01:31:08,621] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1226511: loss 8.6668
[2019-03-23 01:31:08,624] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1226512: learning rate 0.0010
[2019-03-23 01:31:08,935] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1226653: loss 7.6462
[2019-03-23 01:31:08,938] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1226654: learning rate 0.0010
[2019-03-23 01:31:09,904] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1227093: loss 4.8107
[2019-03-23 01:31:09,907] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1227093: learning rate 0.0010
[2019-03-23 01:31:12,053] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1228084: loss -31.3930
[2019-03-23 01:31:12,054] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1228084: learning rate 0.0010
[2019-03-23 01:31:13,611] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1228770: loss -88.1435
[2019-03-23 01:31:13,614] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1228772: learning rate 0.0010
[2019-03-23 01:31:14,339] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:31:14,346] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3157
[2019-03-23 01:31:14,350] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.18333333333333, 82.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8354115024651093, 6.9112, 6.9112, 121.9260426156618, 617793.9123620167, 617793.9123620167, 165863.8036262137], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6249000.0000, 
sim time next is 6249600.0000, 
raw observation next is [24.3, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8392976844879425, 6.9112, 6.9112, 121.9260426156618, 620369.8874552547, 620369.8874552547, 166452.199811738], 
processed observation next is [0.0, 0.34782608695652173, 0.4555555555555556, 0.82, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7991221056099281, 0.0, 0.0, 0.8094621288201359, 0.2215606740911624, 0.2215606740911624, 0.3201003842533423], 
reward next is 0.6799, 
noisyNet noise sample is [array([-2.2575545], dtype=float32), -0.38840523]. 
=============================================
[2019-03-23 01:31:14,500] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.4265043e-30 4.5879214e-28 1.7495907e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 01:31:14,510] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1301
[2019-03-23 01:31:14,517] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 716186.7190315427 W.
[2019-03-23 01:31:14,522] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.06666666666667, 63.33333333333333, 1.0, 2.0, 0.3142116681295922, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5002352088219276, 6.9112, 6.9112, 121.9260426156618, 716186.7190315427, 716186.7190315427, 199102.3064154709], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6288000.0000, 
sim time next is 6288600.0000, 
raw observation next is [28.93333333333333, 63.66666666666666, 1.0, 2.0, 0.3124773384403047, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4974740994734073, 6.911199999999999, 6.9112, 121.9260426156618, 712231.8024938222, 712231.8024938226, 198627.1931935948], 
processed observation next is [0.0, 0.782608695652174, 0.6271604938271603, 0.6366666666666666, 1.0, 1.0, 0.18152064100036272, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.37184262434175913, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2543685008906508, 0.25436850089065094, 0.38197537152614386], 
reward next is 0.6180, 
noisyNet noise sample is [array([-2.318416], dtype=float32), 0.66636676]. 
=============================================
[2019-03-23 01:31:15,618] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1229683: loss 23.8089
[2019-03-23 01:31:15,623] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1229684: learning rate 0.0010
[2019-03-23 01:31:21,811] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.6861664e-01 1.3138334e-01 3.9549280e-30 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 01:31:21,819] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2968
[2019-03-23 01:31:21,829] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1925313.20413099 W.
[2019-03-23 01:31:21,833] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.03333333333333, 62.33333333333334, 1.0, 2.0, 0.8440513195871305, 1.0, 2.0, 0.8440513195871305, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1925313.20413099, 1925313.20413099, 362293.8211967392], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6439200.0000, 
sim time next is 6439800.0000, 
raw observation next is [31.21666666666667, 61.16666666666666, 1.0, 2.0, 0.5491181668016137, 1.0, 2.0, 0.5491181668016137, 1.0, 1.0, 0.8742140050783476, 6.911199999999999, 6.9112, 121.94756008, 1878789.945565319, 1878789.945565319, 368350.3580406802], 
processed observation next is [1.0, 0.5217391304347826, 0.7117283950617285, 0.6116666666666666, 1.0, 1.0, 0.46323591285906396, 1.0, 1.0, 0.46323591285906396, 1.0, 0.5, 0.8427675063479345, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6709964091304711, 0.6709964091304711, 0.7083660731551542], 
reward next is 0.2916, 
noisyNet noise sample is [array([-1.2997389], dtype=float32), 1.0952673]. 
=============================================
[2019-03-23 01:31:22,737] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1232918: loss 43.5551
[2019-03-23 01:31:22,738] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1232918: learning rate 0.0010
[2019-03-23 01:31:22,760] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1232930: loss 2.6816
[2019-03-23 01:31:22,762] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1232930: learning rate 0.0010
[2019-03-23 01:31:22,937] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1233010: loss 189.5852
[2019-03-23 01:31:22,938] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1233010: learning rate 0.0010
[2019-03-23 01:31:23,024] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.8153442e-21 1.8139150e-34 3.5589158e-28 0.0000000e+00], sum to 1.0000
[2019-03-23 01:31:23,030] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1224
[2019-03-23 01:31:23,036] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2086334.52736031 W.
[2019-03-23 01:31:23,041] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.83333333333333, 76.66666666666667, 1.0, 2.0, 0.609706927574535, 1.0, 2.0, 0.609706927574535, 1.0, 2.0, 0.9706732854670178, 6.911200000000001, 6.9112, 121.94756008, 2086334.52736031, 2086334.52736031, 400689.791198113], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6432000.0000, 
sim time next is 6432600.0000, 
raw observation next is [29.06666666666667, 75.83333333333333, 1.0, 2.0, 0.9231894683523036, 1.0, 2.0, 0.9231894683523036, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2106043.197601863, 2106043.197601863, 397288.4897285132], 
processed observation next is [1.0, 0.43478260869565216, 0.6320987654320989, 0.7583333333333333, 1.0, 1.0, 0.9085588908955996, 1.0, 1.0, 0.9085588908955996, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7521582848578083, 0.7521582848578083, 0.7640163264009868], 
reward next is 0.2360, 
noisyNet noise sample is [array([-0.4569875], dtype=float32), -1.0425487]. 
=============================================
[2019-03-23 01:31:24,613] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1233701: loss 357.4243
[2019-03-23 01:31:24,615] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1233702: learning rate 0.0010
[2019-03-23 01:31:25,092] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1233923: loss 277.6293
[2019-03-23 01:31:25,094] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1233924: learning rate 0.0010
[2019-03-23 01:31:25,402] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1234071: loss 211.7768
[2019-03-23 01:31:25,407] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1234071: learning rate 0.0010
[2019-03-23 01:31:25,533] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1234129: loss 266.2588
[2019-03-23 01:31:25,536] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1234129: learning rate 0.0010
[2019-03-23 01:31:25,573] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1234148: loss 290.0055
[2019-03-23 01:31:25,577] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1234149: learning rate 0.0010
[2019-03-23 01:31:25,737] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1234226: loss 272.2842
[2019-03-23 01:31:25,738] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1234226: learning rate 0.0010
[2019-03-23 01:31:25,968] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1234334: loss 376.5380
[2019-03-23 01:31:25,970] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1234335: learning rate 0.0010
[2019-03-23 01:31:26,375] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1234524: loss 248.2278
[2019-03-23 01:31:26,379] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1234525: learning rate 0.0010
[2019-03-23 01:31:26,641] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1234643: loss 96.5092
[2019-03-23 01:31:26,645] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1234645: learning rate 0.0010
[2019-03-23 01:31:27,490] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1235040: loss 151.0575
[2019-03-23 01:31:27,492] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1235040: learning rate 0.0010
[2019-03-23 01:31:29,172] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1235828: loss 0.5075
[2019-03-23 01:31:29,176] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1235830: learning rate 0.0010
[2019-03-23 01:31:30,537] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1236476: loss 0.1363
[2019-03-23 01:31:30,540] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1236477: learning rate 0.0010
[2019-03-23 01:31:32,421] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1237360: loss 0.0642
[2019-03-23 01:31:32,423] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1237360: learning rate 0.0010
[2019-03-23 01:31:32,565] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:31:32,576] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7577
[2019-03-23 01:31:32,584] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 920851.1257386629 W.
[2019-03-23 01:31:32,588] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 51.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9602924705812479, 7.314453561267866, 6.9112, 121.9247499997055, 920851.1257386629, 714351.4492335456, 170012.2334651199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6574200.0000, 
sim time next is 6574800.0000, 
raw observation next is [25.6, 51.33333333333334, 1.0, 1.0, 0.5824211862821203, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9257997833692, 728959.8808078927, 728959.8808078927, 157427.5567001055], 
processed observation next is [1.0, 0.08695652173913043, 0.5037037037037038, 0.5133333333333334, 1.0, 0.5, 0.5028823646215718, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094605166662409, 0.26034281457424735, 0.26034281457424735, 0.3027453013463567], 
reward next is 0.6973, 
noisyNet noise sample is [array([1.1931052], dtype=float32), -2.192409]. 
=============================================
[2019-03-23 01:31:38,496] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:31:38,504] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6260
[2019-03-23 01:31:38,509] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.7, 60.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7133505693014074, 6.911200000000001, 6.9112, 121.9260426156618, 533030.0424065898, 533030.0424065894, 146794.1895876025], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6900000.0000, 
sim time next is 6900600.0000, 
raw observation next is [25.55, 61.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7124820758212475, 6.911199999999999, 6.9112, 121.9260426156618, 532394.6054271165, 532394.605427117, 146627.9892694213], 
processed observation next is [0.0, 0.8695652173913043, 0.5018518518518519, 0.6133333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6406025947765592, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19014093050968447, 0.19014093050968464, 0.2819769024411948], 
reward next is 0.7180, 
noisyNet noise sample is [array([0.9116708], dtype=float32), 1.1734937]. 
=============================================
[2019-03-23 01:31:39,205] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1240493: loss 0.0093
[2019-03-23 01:31:39,206] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1240493: learning rate 0.0010
[2019-03-23 01:31:40,200] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1240957: loss 0.0281
[2019-03-23 01:31:40,202] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1240957: learning rate 0.0010
[2019-03-23 01:31:40,237] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1240975: loss 0.0207
[2019-03-23 01:31:40,240] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:31:40,240] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1240975: learning rate 0.0010
[2019-03-23 01:31:40,248] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1729
[2019-03-23 01:31:40,253] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.95, 44.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5470310471236842, 6.911200000000001, 6.9112, 121.9260426156618, 390594.0164774082, 390594.0164774077, 112015.1726301024], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6669000.0000, 
sim time next is 6669600.0000, 
raw observation next is [22.93333333333333, 44.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5323193141867786, 6.9112, 6.9112, 121.9260426156618, 380086.8635870015, 380086.8635870015, 110390.4025000821], 
processed observation next is [1.0, 0.17391304347826086, 0.40493827160493817, 0.4433333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.41539914273347317, 0.0, 0.0, 0.8094621288201359, 0.13574530842392912, 0.13574530842392912, 0.21228923557708096], 
reward next is 0.7877, 
noisyNet noise sample is [array([-0.3547015], dtype=float32), -0.15784194]. 
=============================================
[2019-03-23 01:31:41,069] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 4.1169856e-26 6.3816266e-32 0.0000000e+00 9.4829718e-35], sum to 1.0000
[2019-03-23 01:31:41,076] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5123
[2019-03-23 01:31:41,082] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 748696.1272411197 W.
[2019-03-23 01:31:41,090] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.4, 93.66666666666667, 1.0, 2.0, 0.3067905990462116, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5011743772524123, 6.9112, 6.9112, 121.9260426156618, 748696.1272411197, 748696.1272411197, 194836.2683520631], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7388400.0000, 
sim time next is 7389000.0000, 
raw observation next is [20.5, 93.5, 1.0, 2.0, 0.273678444525784, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4473376157797748, 6.911199999999999, 6.9112, 121.9260426156618, 668303.7847331164, 668303.7847331169, 186124.7990162837], 
processed observation next is [1.0, 0.5217391304347826, 0.3148148148148148, 0.935, 1.0, 1.0, 0.1353314815783143, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.30917201972471847, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23867992311897013, 0.2386799231189703, 0.3579323058005456], 
reward next is 0.6421, 
noisyNet noise sample is [array([-2.8750763], dtype=float32), -0.45713916]. 
=============================================
[2019-03-23 01:31:41,105] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[43.030357]
 [40.940712]
 [40.146313]
 [40.205025]
 [40.489628]], R is [[44.70134354]
 [44.8796463 ]
 [44.43085098]
 [43.98654175]
 [44.19641113]].
[2019-03-23 01:31:41,872] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1241742: loss 0.0347
[2019-03-23 01:31:41,876] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1241742: learning rate 0.0010
[2019-03-23 01:31:42,408] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1241995: loss 0.0474
[2019-03-23 01:31:42,411] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1241995: learning rate 0.0010
[2019-03-23 01:31:42,686] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1242129: loss 0.0299
[2019-03-23 01:31:42,687] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1242129: learning rate 0.0010
[2019-03-23 01:31:42,920] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1242237: loss 0.0147
[2019-03-23 01:31:42,924] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1242238: learning rate 0.0010
[2019-03-23 01:31:42,933] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1242240: loss 0.0103
[2019-03-23 01:31:42,936] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1242242: learning rate 0.0010
[2019-03-23 01:31:43,328] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1242425: loss 0.1024
[2019-03-23 01:31:43,331] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1242425: learning rate 0.0010
[2019-03-23 01:31:43,604] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1242558: loss 0.0168
[2019-03-23 01:31:43,605] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1242558: learning rate 0.0010
[2019-03-23 01:31:43,998] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1242739: loss 0.0289
[2019-03-23 01:31:44,000] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1242740: learning rate 0.0010
[2019-03-23 01:31:44,306] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1242886: loss 0.0112
[2019-03-23 01:31:44,309] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1242887: learning rate 0.0010
[2019-03-23 01:31:45,170] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1243290: loss 0.0320
[2019-03-23 01:31:45,176] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1243291: learning rate 0.0010
[2019-03-23 01:31:45,604] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1243494: loss -23.1969
[2019-03-23 01:31:45,609] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1243496: learning rate 0.0010
[2019-03-23 01:31:47,180] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1244233: loss 41.5759
[2019-03-23 01:31:47,183] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1244233: learning rate 0.0010
[2019-03-23 01:31:49,340] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1245246: loss -104.9966
[2019-03-23 01:31:49,342] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1245246: learning rate 0.0010
[2019-03-23 01:31:54,651] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:31:54,661] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6547
[2019-03-23 01:31:54,666] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.93333333333333, 62.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8022307649234325, 6.911200000000001, 6.9112, 121.9260426156618, 595493.9396871377, 595493.9396871373, 160787.4317623484], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6949200.0000, 
sim time next is 6949800.0000, 
raw observation next is [27.2, 61.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8049185204823727, 6.911200000000001, 6.9112, 121.9260426156618, 597239.643988092, 597239.6439880915, 161237.0436977538], 
processed observation next is [0.0, 0.43478260869565216, 0.5629629629629629, 0.615, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7561481506029657, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21329987285288998, 0.21329987285288982, 0.3100712378802958], 
reward next is 0.6899, 
noisyNet noise sample is [array([0.8267556], dtype=float32), -1.0793806]. 
=============================================
[2019-03-23 01:31:55,972] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:31:55,980] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0894
[2019-03-23 01:31:55,987] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1052061.293706001 W.
[2019-03-23 01:31:55,990] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.03333333333333, 76.66666666666667, 1.0, 2.0, 0.4435999411045365, 1.0, 1.0, 0.4435999411045365, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1052061.293706001, 1052061.293706001, 220286.6783587952], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7033800.0000, 
sim time next is 7034400.0000, 
raw observation next is [24.2, 76.0, 1.0, 2.0, 0.3500384387477668, 1.0, 2.0, 0.3500384387477668, 1.0, 1.0, 0.5596439907788946, 6.9112, 6.9112, 121.94756008, 1230617.264665501, 1230617.264665501, 275864.8465932219], 
processed observation next is [1.0, 0.43478260869565216, 0.45185185185185184, 0.76, 1.0, 1.0, 0.2262362366044843, 1.0, 1.0, 0.2262362366044843, 1.0, 0.5, 0.4495549884736182, 0.0, 0.0, 0.8096049824067558, 0.4395061659519646, 0.4395061659519646, 0.5305093203715805], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.004447], dtype=float32), -0.24552919]. 
=============================================
[2019-03-23 01:31:56,117] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1248431: loss -85.2213
[2019-03-23 01:31:56,117] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1248431: learning rate 0.0010
[2019-03-23 01:31:57,404] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1249035: loss -194.7491
[2019-03-23 01:31:57,406] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1249036: learning rate 0.0010
[2019-03-23 01:31:57,446] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1249056: loss 45.3395
[2019-03-23 01:31:57,449] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1249057: learning rate 0.0010
[2019-03-23 01:31:58,951] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1249755: loss -20.1817
[2019-03-23 01:31:58,952] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1249756: learning rate 0.0010
[2019-03-23 01:31:59,471] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 01:31:59,472] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:31:59,473] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:31:59,473] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:31:59,474] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:31:59,474] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:31:59,475] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:31:59,475] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:31:59,476] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:31:59,479] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:31:59,479] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:31:59,506] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run51
[2019-03-23 01:31:59,531] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run51
[2019-03-23 01:31:59,555] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run51
[2019-03-23 01:31:59,556] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run51
[2019-03-23 01:31:59,575] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run51
[2019-03-23 01:32:08,134] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.2217306], dtype=float32), -0.25111228]
[2019-03-23 01:32:08,135] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.84402887333333, 79.26466879833333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4905809879315274, 6.9112, 6.9112, 121.9260426156618, 353742.9862690528, 353742.9862690528, 115617.2123725263]
[2019-03-23 01:32:08,136] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:32:08,140] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.47824148234354225
[2019-03-23 01:32:13,782] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2217306], dtype=float32), -0.25111228]
[2019-03-23 01:32:13,783] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.33025880333334, 49.66817087666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.483933105114802, 6.9112, 6.9112, 121.9260426156618, 348558.2555734751, 348558.2555734751, 114965.1495887112]
[2019-03-23 01:32:13,783] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:32:13,788] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7765894577994301
[2019-03-23 01:32:49,305] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.2217306], dtype=float32), -0.25111228]
[2019-03-23 01:32:49,306] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.5, 47.83333333333334, 1.0, 2.0, 0.6683672071984985, 1.0, 2.0, 0.6683672071984985, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1524220.985749849, 1524220.985749849, 292362.8793014268]
[2019-03-23 01:32:49,308] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:32:49,311] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 4.2877015e-35 8.8607794e-19 1.5040717e-31], sampled 0.900849640639511
[2019-03-23 01:32:49,312] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1524220.985749849 W.
[2019-03-23 01:33:07,140] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.2217306], dtype=float32), -0.25111228]
[2019-03-23 01:33:07,141] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.35, 61.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7993673894848758, 6.911200000000001, 6.9112, 121.9260426156618, 592642.6009070501, 592642.6009070497, 160747.1638545685]
[2019-03-23 01:33:07,145] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:33:07,149] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.01910415416273381
[2019-03-23 01:33:20,422] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.2217306], dtype=float32), -0.25111228]
[2019-03-23 01:33:20,423] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.8669947, 90.33158008666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.873397362295578, 6.9112, 6.9112, 121.9260426156618, 640097.2279614821, 640097.2279614821, 172252.4594886069]
[2019-03-23 01:33:20,424] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:33:20,429] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.34283616052798294
[2019-03-23 01:33:29,836] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2217306], dtype=float32), -0.25111228]
[2019-03-23 01:33:29,839] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.33333333333334, 87.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7997697925090674, 6.9112, 6.9112, 121.9260426156618, 592286.8847662254, 592286.8847662254, 161056.3846434384]
[2019-03-23 01:33:29,840] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:33:29,841] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9829626719377145
[2019-03-23 01:33:35,542] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2217306], dtype=float32), -0.25111228]
[2019-03-23 01:33:35,544] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.91666666666667, 49.83333333333334, 1.0, 2.0, 0.8250172782728814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 963667.053957125, 963667.053957125, 202347.5751728557]
[2019-03-23 01:33:35,548] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:33:35,551] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 1.2275932e-37 0.0000000e+00 3.2989091e-38], sampled 0.5206879493251148
[2019-03-23 01:33:35,552] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 963667.053957125 W.
[2019-03-23 01:33:45,726] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.2217306], dtype=float32), -0.25111228]
[2019-03-23 01:33:45,726] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.17520038333333, 112.3749659166667, 1.0, 1.0, 0.6706525769529376, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9259696518883, 793435.1166143862, 793435.1166143859, 172011.0339910716]
[2019-03-23 01:33:45,727] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:33:45,730] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.449599744668466
[2019-03-23 01:33:45,733] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 793435.1166143862 W.
[2019-03-23 01:33:47,843] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2217306], dtype=float32), -0.25111228]
[2019-03-23 01:33:47,844] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.13333333333333, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4997807184851376, 6.9112, 6.9112, 121.9260426156618, 360481.8886706729, 360481.8886706729, 116366.1598007751]
[2019-03-23 01:33:47,844] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:33:47,847] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.07465233571459673
[2019-03-23 01:33:52,834] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8636.8954 2217632499.0985 537.0000
[2019-03-23 01:33:53,236] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8564.5002 2256355070.0555 531.0000
[2019-03-23 01:33:53,302] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8393.0271 2331677378.4245 590.0000
[2019-03-23 01:33:53,326] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7879.2047 2520482079.7072 791.0000
[2019-03-23 01:33:53,353] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8422.7111 2288568631.7163 663.0000
[2019-03-23 01:33:54,371] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1250000, evaluation results [1250000.0, 7879.204731392427, 2520482079.707243, 791.0, 8564.500178621929, 2256355070.055514, 531.0, 8636.895414182503, 2217632499.098464, 537.0, 8393.027139383445, 2331677378.4245014, 590.0, 8422.711134114892, 2288568631.716331, 663.0]
[2019-03-23 01:33:54,434] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1250032: loss -93.7141
[2019-03-23 01:33:54,436] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1250032: learning rate 0.0010
[2019-03-23 01:33:54,513] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1250073: loss 40.7704
[2019-03-23 01:33:54,514] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1250073: learning rate 0.0010
[2019-03-23 01:33:54,906] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1250249: loss 22.8366
[2019-03-23 01:33:54,908] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1250251: learning rate 0.0010
[2019-03-23 01:33:54,916] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1250255: loss -132.5591
[2019-03-23 01:33:54,918] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1250256: learning rate 0.0010
[2019-03-23 01:33:55,257] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1250413: loss 39.4292
[2019-03-23 01:33:55,264] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1250415: learning rate 0.0010
[2019-03-23 01:33:55,514] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1250524: loss 153.3991
[2019-03-23 01:33:55,517] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1250525: learning rate 0.0010
[2019-03-23 01:33:56,027] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1250760: loss 36.6965
[2019-03-23 01:33:56,030] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1250761: learning rate 0.0010
[2019-03-23 01:33:56,267] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1250870: loss 0.4192
[2019-03-23 01:33:56,272] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1250873: learning rate 0.0010
[2019-03-23 01:33:57,175] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1251282: loss 44.2139
[2019-03-23 01:33:57,177] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1251282: learning rate 0.0010
[2019-03-23 01:33:57,984] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1251651: loss 0.4317
[2019-03-23 01:33:57,987] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1251652: learning rate 0.0010
[2019-03-23 01:33:59,185] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:33:59,194] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2492
[2019-03-23 01:33:59,199] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.8, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6387116942877805, 6.9112, 6.9112, 121.9260426156618, 476212.9006011125, 476212.9006011125, 135930.4037984677], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7176000.0000, 
sim time next is 7176600.0000, 
raw observation next is [19.8, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6396074601319687, 6.9112, 6.9112, 121.9260426156618, 476969.7344642891, 476969.7344642891, 136123.4495222817], 
processed observation next is [1.0, 0.043478260869565216, 0.2888888888888889, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5495093251649608, 0.0, 0.0, 0.8094621288201359, 0.17034633373724611, 0.17034633373724611, 0.2617758644659264], 
reward next is 0.7382, 
noisyNet noise sample is [array([-0.20536591], dtype=float32), -1.4395032]. 
=============================================
[2019-03-23 01:33:59,557] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1252373: loss 0.3480
[2019-03-23 01:33:59,558] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1252373: learning rate 0.0010
[2019-03-23 01:34:01,776] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1253376: loss 0.6266
[2019-03-23 01:34:01,777] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1253376: learning rate 0.0010
[2019-03-23 01:34:04,286] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 2.298408e-33], sum to 1.0000
[2019-03-23 01:34:04,293] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3228
[2019-03-23 01:34:04,297] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.41666666666667, 71.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7875999549271682, 6.911200000000001, 6.9112, 121.9260426156618, 588459.4273215273, 588459.4273215268, 153883.3988421138], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7217400.0000, 
sim time next is 7218000.0000, 
raw observation next is [23.5, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8056431330175652, 6.911199999999999, 6.9112, 121.9260426156618, 601970.9034722741, 601970.9034722745, 156090.9391330013], 
processed observation next is [1.0, 0.5652173913043478, 0.42592592592592593, 0.71, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7570539162719564, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21498960838295503, 0.2149896083829552, 0.3001748829480794], 
reward next is 0.6998, 
noisyNet noise sample is [array([-1.0831679], dtype=float32), -0.54068893]. 
=============================================
[2019-03-23 01:34:04,309] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[74.48453]
 [72.49647]
 [68.16246]
 [60.67464]
 [59.88155]], R is [[75.34877777]
 [75.29936218]
 [75.25191498]
 [75.20301819]
 [75.11616516]].
[2019-03-23 01:34:08,991] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 7.3494904e-26 3.8290084e-37], sum to 1.0000
[2019-03-23 01:34:08,997] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9777
[2019-03-23 01:34:09,006] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.31666666666667, 88.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6400239316256596, 6.911199999999999, 6.9112, 121.9260426156618, 477081.2906134366, 477081.2906134371, 135939.4171804952], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7275000.0000, 
sim time next is 7275600.0000, 
raw observation next is [20.3, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6331351304035586, 6.9112, 6.9112, 121.9260426156618, 471953.4272550129, 471953.4272550129, 135259.7003546018], 
processed observation next is [1.0, 0.21739130434782608, 0.3074074074074074, 0.89, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5414189130044482, 0.0, 0.0, 0.8094621288201359, 0.16855479544821889, 0.16855479544821889, 0.26011480837423423], 
reward next is 0.7399, 
noisyNet noise sample is [array([-0.02589968], dtype=float32), -0.47838697]. 
=============================================
[2019-03-23 01:34:09,031] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:34:09,031] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:09,099] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run7
[2019-03-23 01:34:09,394] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.1682137e-21 3.9557637e-26], sum to 1.0000
[2019-03-23 01:34:09,401] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6987
[2019-03-23 01:34:09,407] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.83333333333334, 90.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7082446078322056, 6.911200000000001, 6.9112, 121.9260426156618, 529127.9296021007, 529127.9296021003, 144859.7611370621], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7283400.0000, 
sim time next is 7284000.0000, 
raw observation next is [20.86666666666667, 90.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7575961908812489, 6.9112, 6.9112, 121.9260426156618, 566058.798012144, 566058.798012144, 150516.7302674497], 
processed observation next is [1.0, 0.30434782608695654, 0.3283950617283952, 0.9033333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.696995238601561, 0.0, 0.0, 0.8094621288201359, 0.2021638564329086, 0.2021638564329086, 0.2894552505143263], 
reward next is 0.7105, 
noisyNet noise sample is [array([1.8124263], dtype=float32), 1.0967984]. 
=============================================
[2019-03-23 01:34:09,420] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.23321 ]
 [72.41581 ]
 [72.389015]
 [72.405846]
 [72.405594]], R is [[72.01972961]
 [72.02095032]
 [72.03253174]
 [72.04386139]
 [72.05813599]].
[2019-03-23 01:34:09,496] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1256897: loss 0.2813
[2019-03-23 01:34:09,499] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1256898: learning rate 0.0010
[2019-03-23 01:34:09,579] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1256943: loss 0.6581
[2019-03-23 01:34:09,582] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1256945: learning rate 0.0010
[2019-03-23 01:34:10,551] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9902904e-01 3.6352494e-37 4.9910583e-23 1.9000375e-04 7.8104989e-04], sum to 1.0000
[2019-03-23 01:34:10,558] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2189
[2019-03-23 01:34:10,567] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 870322.4682676005 W.
[2019-03-23 01:34:10,572] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.4, 95.0, 1.0, 2.0, 0.3530163856481477, 1.0, 1.0, 0.3530163856481477, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 870322.4682676005, 870322.4682676005, 196202.162750418], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7378800.0000, 
sim time next is 7379400.0000, 
raw observation next is [19.45, 95.0, 1.0, 2.0, 0.3622904017479483, 1.0, 2.0, 0.3622904017479483, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 890806.4385129891, 890806.4385129896, 198610.5181397655], 
processed observation next is [1.0, 0.391304347826087, 0.2759259259259259, 0.95, 1.0, 1.0, 0.24082190684279559, 1.0, 1.0, 0.24082190684279559, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31814515661178183, 0.318145156611782, 0.38194330411493366], 
reward next is 0.6181, 
noisyNet noise sample is [array([0.55166477], dtype=float32), -0.8468127]. 
=============================================
[2019-03-23 01:34:10,954] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1257693: loss 0.4421
[2019-03-23 01:34:10,955] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1257693: learning rate 0.0010
[2019-03-23 01:34:11,499] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1257944: loss 0.1903
[2019-03-23 01:34:11,503] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1257945: learning rate 0.0010
[2019-03-23 01:34:11,508] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1257945: loss 0.2610
[2019-03-23 01:34:11,510] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1257947: learning rate 0.0010
[2019-03-23 01:34:12,027] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1258189: loss 0.2954
[2019-03-23 01:34:12,029] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1258189: learning rate 0.0010
[2019-03-23 01:34:12,088] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1258217: loss 0.3561
[2019-03-23 01:34:12,091] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1258217: learning rate 0.0010
[2019-03-23 01:34:12,212] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1258284: loss 0.1888
[2019-03-23 01:34:12,215] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1258285: learning rate 0.0010
[2019-03-23 01:34:12,652] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1258498: loss 0.0923
[2019-03-23 01:34:12,658] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1258500: learning rate 0.0010
[2019-03-23 01:34:13,033] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1258675: loss 0.3717
[2019-03-23 01:34:13,036] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1258675: learning rate 0.0010
[2019-03-23 01:34:13,197] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.5942064e-24 5.2543501e-25], sum to 1.0000
[2019-03-23 01:34:13,204] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0086
[2019-03-23 01:34:13,205] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1258755: loss 0.3655
[2019-03-23 01:34:13,209] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1258757: learning rate 0.0010
[2019-03-23 01:34:13,213] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 83.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6943543299886185, 6.9112, 6.9112, 121.9260426156618, 518856.1939715584, 518856.1939715584, 143817.110414711], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7338000.0000, 
sim time next is 7338600.0000, 
raw observation next is [21.65, 84.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6918348055565564, 6.911199999999999, 6.9112, 121.9260426156618, 516955.5983200212, 516955.5983200216, 143440.8833741405], 
processed observation next is [1.0, 0.9565217391304348, 0.35740740740740734, 0.845, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6147935069456955, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18462699940000757, 0.1846269994000077, 0.2758478526425779], 
reward next is 0.7242, 
noisyNet noise sample is [array([0.6845003], dtype=float32), 0.04389513]. 
=============================================
[2019-03-23 01:34:13,809] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2041127e-27 1.0700023e-31], sum to 1.0000
[2019-03-23 01:34:13,816] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3905
[2019-03-23 01:34:13,823] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.73333333333333, 84.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6350247622619557, 6.9112, 6.9112, 121.9260426156618, 473112.7410589079, 473112.7410589079, 135187.1467711739], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7348800.0000, 
sim time next is 7349400.0000, 
raw observation next is [20.7, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6306384746077532, 6.911200000000001, 6.9112, 121.9260426156618, 469594.8360894875, 469594.8360894871, 134510.7461469014], 
processed observation next is [1.0, 0.043478260869565216, 0.3222222222222222, 0.84, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5382980932596915, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16771244146053124, 0.1677124414605311, 0.25867451182096424], 
reward next is 0.7413, 
noisyNet noise sample is [array([0.33974302], dtype=float32), 1.5162872]. 
=============================================
[2019-03-23 01:34:14,196] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1259216: loss 0.4658
[2019-03-23 01:34:14,197] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1259216: learning rate 0.0010
[2019-03-23 01:34:14,530] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1259373: loss -5.8375
[2019-03-23 01:34:14,534] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1259373: learning rate 0.0010
[2019-03-23 01:34:16,430] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1260266: loss -19.3477
[2019-03-23 01:34:16,433] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1260266: learning rate 0.0010
[2019-03-23 01:34:18,536] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1261256: loss -124.1590
[2019-03-23 01:34:18,538] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1261256: learning rate 0.0010
[2019-03-23 01:34:20,526] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:34:20,536] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1802
[2019-03-23 01:34:20,541] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.93333333333333, 77.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8316696749318367, 6.911200000000001, 6.9112, 121.9260426156618, 614468.15821595, 614468.1582159495, 165585.343814843], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7491000.0000, 
sim time next is 7491600.0000, 
raw observation next is [24.9, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8335770943131251, 6.911200000000001, 6.9112, 121.9260426156618, 615932.3355638115, 615932.335563811, 165805.6655240156], 
processed observation next is [0.0, 0.7391304347826086, 0.47777777777777775, 0.78, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7919713678914064, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21997583412993266, 0.2199758341299325, 0.3188570490846454], 
reward next is 0.6811, 
noisyNet noise sample is [array([-1.2551385], dtype=float32), 0.22839172]. 
=============================================
[2019-03-23 01:34:21,118] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:34:21,131] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3256
[2019-03-23 01:34:21,138] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.85, 94.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7692568864060393, 6.9112, 6.9112, 121.9260426156618, 572409.2331203254, 572409.2331203254, 155980.4805533093], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7512600.0000, 
sim time next is 7513200.0000, 
raw observation next is [21.8, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7684585711716694, 6.911200000000001, 6.9112, 121.9260426156618, 571851.8609978136, 571851.8609978132, 155861.4446022288], 
processed observation next is [0.0, 1.0, 0.362962962962963, 0.95, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7105732139645867, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20423280749921915, 0.204232807499219, 0.29973354731197843], 
reward next is 0.7003, 
noisyNet noise sample is [array([-0.24820648], dtype=float32), -1.1164548]. 
=============================================
[2019-03-23 01:34:21,268] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:34:21,277] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5915
[2019-03-23 01:34:21,284] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.4, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6248823388907947, 6.9112, 6.9112, 121.9260426156618, 465030.2284631633, 465030.2284631633, 133693.8974378876], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7768800.0000, 
sim time next is 7769400.0000, 
raw observation next is [22.26666666666667, 71.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6234526668573799, 6.9112, 6.9112, 121.9260426156618, 463768.0554727738, 463768.0554727738, 133385.3455682528], 
processed observation next is [1.0, 0.9565217391304348, 0.38024691358024704, 0.715, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5293158335717248, 0.0, 0.0, 0.8094621288201359, 0.16563144838313348, 0.16563144838313348, 0.25651027993894765], 
reward next is 0.7435, 
noisyNet noise sample is [array([-1.6296191], dtype=float32), -0.77830184]. 
=============================================
[2019-03-23 01:34:21,842] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:34:21,855] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0034
[2019-03-23 01:34:21,861] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7138849383946066, 6.911199999999999, 6.9112, 121.9260426156618, 533168.5250358587, 533168.5250358592, 147559.7199382778], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7530600.0000, 
sim time next is 7531200.0000, 
raw observation next is [20.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7140146937157669, 6.9112, 6.9112, 121.9260426156618, 533265.4717438206, 533265.4717438206, 147574.3220187896], 
processed observation next is [0.0, 0.17391304347826086, 0.32962962962962955, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6425183671447084, 0.0, 0.0, 0.8094621288201359, 0.19045195419422165, 0.19045195419422165, 0.2837967731130569], 
reward next is 0.7162, 
noisyNet noise sample is [array([-1.1007167], dtype=float32), -0.7650334]. 
=============================================
[2019-03-23 01:34:23,949] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.4718309e-26 1.5088138e-37], sum to 1.0000
[2019-03-23 01:34:23,958] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1731
[2019-03-23 01:34:23,967] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.16666666666666, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8448177481290675, 6.911200000000001, 6.9112, 121.9260426156618, 622480.4378144743, 622480.4378144739, 167750.0592543077], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7567800.0000, 
sim time next is 7568400.0000, 
raw observation next is [27.33333333333334, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8524385235040911, 6.911200000000001, 6.9112, 121.9260426156618, 626950.3815509266, 626950.3815509261, 169023.6220428844], 
processed observation next is [0.0, 0.6086956521739131, 0.5679012345679014, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8155481543801137, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22391085055390236, 0.2239108505539022, 0.32504542700554695], 
reward next is 0.6750, 
noisyNet noise sample is [array([0.9668004], dtype=float32), 1.2830824]. 
=============================================
[2019-03-23 01:34:24,088] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.8208297e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 01:34:24,094] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7002
[2019-03-23 01:34:24,098] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.06666666666667, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6672051165844451, 6.9112, 6.9112, 121.9260426156618, 491238.85314851, 491238.85314851, 134579.6510345273], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7784400.0000, 
sim time next is 7785000.0000, 
raw observation next is [21.1, 71.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6226744746749479, 6.911200000000001, 6.9112, 121.9260426156618, 458227.8575588133, 458227.8575588129, 130246.4453063506], 
processed observation next is [1.0, 0.08695652173913043, 0.3370370370370371, 0.715, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5283430933436848, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16365280627100476, 0.1636528062710046, 0.25047393328144346], 
reward next is 0.7495, 
noisyNet noise sample is [array([0.98803586], dtype=float32), -0.7189995]. 
=============================================
[2019-03-23 01:34:24,120] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.72216]
 [72.26287]
 [71.97134]
 [71.92033]
 [71.94092]], R is [[72.75382233]
 [72.76747894]
 [72.7605896 ]
 [72.79236603]
 [72.82326508]].
[2019-03-23 01:34:26,304] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1264895: loss -224.5210
[2019-03-23 01:34:26,307] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1264895: learning rate 0.0010
[2019-03-23 01:34:26,354] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1264921: loss -222.9193
[2019-03-23 01:34:26,354] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1264921: learning rate 0.0010
[2019-03-23 01:34:28,097] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1265737: loss -222.9843
[2019-03-23 01:34:28,103] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1265737: learning rate 0.0010
[2019-03-23 01:34:28,509] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1265930: loss -75.4342
[2019-03-23 01:34:28,510] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1265930: learning rate 0.0010
[2019-03-23 01:34:28,596] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1265970: loss -70.7089
[2019-03-23 01:34:28,599] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1265970: learning rate 0.0010
[2019-03-23 01:34:28,923] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1266123: loss -36.8871
[2019-03-23 01:34:28,927] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1266124: learning rate 0.0010
[2019-03-23 01:34:29,007] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1266160: loss -99.2735
[2019-03-23 01:34:29,009] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1266160: learning rate 0.0010
[2019-03-23 01:34:29,275] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1266281: loss -289.6658
[2019-03-23 01:34:29,279] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1266283: learning rate 0.0010
[2019-03-23 01:34:29,782] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1266520: loss -50.4835
[2019-03-23 01:34:29,786] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1266521: learning rate 0.0010
[2019-03-23 01:34:30,007] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1266625: loss -103.9631
[2019-03-23 01:34:30,010] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1266626: learning rate 0.0010
[2019-03-23 01:34:30,352] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1266786: loss 10.6641
[2019-03-23 01:34:30,354] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1266786: learning rate 0.0010
[2019-03-23 01:34:31,406] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1267276: loss -76.7385
[2019-03-23 01:34:31,409] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1267276: learning rate 0.0010
[2019-03-23 01:34:32,672] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:34:32,673] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:32,740] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run7
[2019-03-23 01:34:33,260] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 6.8788295e-36 9.5600021e-29 2.1664587e-08 1.5162998e-34], sum to 1.0000
[2019-03-23 01:34:33,267] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3293
[2019-03-23 01:34:33,273] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1090592.095952695 W.
[2019-03-23 01:34:33,278] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.85, 54.0, 1.0, 2.0, 0.9073474402466588, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260111850394, 1090592.095952695, 1090592.095952695, 221839.6617164774], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7734600.0000, 
sim time next is 7735200.0000, 
raw observation next is [28.03333333333333, 53.0, 1.0, 2.0, 0.4538425874134034, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7310427448160036, 6.911200000000001, 6.9112, 121.9260426156618, 1084452.257640354, 1084452.257640354, 239912.3511277445], 
processed observation next is [1.0, 0.5217391304347826, 0.5938271604938271, 0.53, 1.0, 1.0, 0.3498126040635755, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.6638034310200044, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3873043777286979, 0.3873043777286979, 0.4613699060148933], 
reward next is 0.5386, 
noisyNet noise sample is [array([-0.6955905], dtype=float32), -0.8039314]. 
=============================================
[2019-03-23 01:34:33,307] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.7560114e-31 3.2298766e-29], sum to 1.0000
[2019-03-23 01:34:33,318] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9276
[2019-03-23 01:34:33,323] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 917892.2925000658 W.
[2019-03-23 01:34:33,328] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.7, 80.0, 1.0, 2.0, 0.374033220273071, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6140179750418017, 6.911199999999999, 6.9112, 121.9260426156607, 917892.2925000658, 917892.2925000662, 213418.1067123396], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7722000.0000, 
sim time next is 7722600.0000, 
raw observation next is [22.06666666666667, 78.5, 1.0, 2.0, 0.2466446779637043, 1.0, 1.0, 0.2466446779637043, 1.0, 2.0, 0.401188541276547, 6.9112, 6.9112, 121.94756008, 898053.8915357658, 898053.8915357658, 235421.0566617323], 
processed observation next is [1.0, 0.391304347826087, 0.3728395061728396, 0.785, 1.0, 1.0, 0.103148426147267, 1.0, 0.5, 0.103148426147267, 1.0, 1.0, 0.2514856765956837, 0.0, 0.0, 0.8096049824067558, 0.32073353269134497, 0.32073353269134497, 0.4527328012725621], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19421828], dtype=float32), 0.33928555]. 
=============================================
[2019-03-23 01:34:33,904] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.7724281e-12 1.3168853e-21], sum to 1.0000
[2019-03-23 01:34:33,910] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8980
[2019-03-23 01:34:33,916] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.96666666666667, 60.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7150801088511497, 6.911199999999999, 6.9112, 121.9260426156618, 534141.4508401909, 534141.4508401913, 147532.4356711508], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7757400.0000, 
sim time next is 7758000.0000, 
raw observation next is [25.7, 61.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7087221740470464, 6.9112, 6.9112, 121.9260426156618, 529514.8913242135, 529514.8913242135, 146492.8245008682], 
processed observation next is [1.0, 0.8260869565217391, 0.5074074074074074, 0.61, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.635902717558808, 0.0, 0.0, 0.8094621288201359, 0.1891124611872191, 0.1891124611872191, 0.28171697019397735], 
reward next is 0.7183, 
noisyNet noise sample is [array([0.3439946], dtype=float32), -1.2499588]. 
=============================================
[2019-03-23 01:34:33,931] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[79.39124 ]
 [79.93946 ]
 [80.147804]
 [80.534   ]
 [81.10328 ]], R is [[78.88166046]
 [78.80912781]
 [78.7352066 ]
 [78.65946198]
 [78.58175659]].
[2019-03-23 01:34:34,353] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:34:34,353] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:34,418] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run7
[2019-03-23 01:34:35,796] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:34:35,798] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:35,874] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run7
[2019-03-23 01:34:41,818] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:34:41,827] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6559
[2019-03-23 01:34:41,832] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.03333333333333, 74.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6832291948663949, 6.911200000000001, 6.9112, 121.9260426156618, 508886.7422677326, 508886.7422677322, 139940.0865819167], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7890000.0000, 
sim time next is 7890600.0000, 
raw observation next is [22.16666666666667, 73.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.65053597074516, 6.911200000000001, 6.9112, 121.9260426156618, 484560.4938643465, 484560.493864346, 136631.2742001959], 
processed observation next is [1.0, 0.30434782608695654, 0.3765432098765434, 0.7383333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.56316996343145, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1730573192372666, 0.17305731923726644, 0.2627524503849921], 
reward next is 0.7372, 
noisyNet noise sample is [array([0.5633055], dtype=float32), 0.8066035]. 
=============================================
[2019-03-23 01:34:42,657] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:34:42,658] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:42,679] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:34:42,680] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:42,723] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run7
[2019-03-23 01:34:42,780] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run7
[2019-03-23 01:34:44,160] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:34:44,161] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:44,231] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run7
[2019-03-23 01:34:44,366] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:34:44,367] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:44,423] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run7
[2019-03-23 01:34:44,445] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:34:44,445] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:44,490] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run7
[2019-03-23 01:34:44,593] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:34:44,593] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:44,660] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run7
[2019-03-23 01:34:44,663] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:34:44,681] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:44,709] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run7
[2019-03-23 01:34:44,798] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:34:44,799] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:44,834] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run7
[2019-03-23 01:34:45,002] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:34:45,002] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:45,017] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run7
[2019-03-23 01:34:45,045] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:34:45,046] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:45,069] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run7
[2019-03-23 01:34:45,369] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:34:45,369] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:45,375] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run7
[2019-03-23 01:34:45,757] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:34:45,757] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:45,766] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run7
[2019-03-23 01:34:46,409] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 01:34:46,411] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:34:46,412] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:46,412] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:34:46,413] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:34:46,414] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:34:46,413] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:34:46,415] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:46,415] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:46,416] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:46,414] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:34:46,430] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run52
[2019-03-23 01:34:46,454] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run52
[2019-03-23 01:34:46,475] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run52
[2019-03-23 01:34:46,475] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run52
[2019-03-23 01:34:46,476] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run52
[2019-03-23 01:34:47,974] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.18370543], dtype=float32), -0.13674285]
[2019-03-23 01:34:47,975] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.26666666666667, 40.33333333333334, 1.0, 2.0, 0.8917686253573257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.056331691195534, 6.9112, 121.9253268945307, 1197990.797752987, 1123670.836407546, 219788.9514315095]
[2019-03-23 01:34:47,977] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:34:47,981] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 5.4514138e-34 7.1465739e-22 2.0209368e-35], sampled 0.496019875700332
[2019-03-23 01:34:47,983] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1197990.797752987 W.
[2019-03-23 01:34:52,177] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.18370543], dtype=float32), -0.13674285]
[2019-03-23 01:34:52,178] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.22925107, 54.55725255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4886627256537351, 6.9112, 6.9112, 121.9260426156618, 355895.0745835142, 355895.0745835142, 116848.1231598912]
[2019-03-23 01:34:52,180] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:34:52,182] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.40780845721983594
[2019-03-23 01:34:59,241] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.18370543], dtype=float32), -0.13674285]
[2019-03-23 01:34:59,243] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.6, 32.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4645613651819666, 6.911200000000001, 6.9112, 121.9260426156618, 331695.8416133015, 331695.8416133011, 91228.95928164852]
[2019-03-23 01:34:59,244] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:34:59,247] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.938567836399052
[2019-03-23 01:35:33,325] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.18370543], dtype=float32), -0.13674285]
[2019-03-23 01:35:33,327] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.25, 75.5, 1.0, 2.0, 0.7351952668707458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 837936.5520631167, 837936.5520631167, 182918.2831576054]
[2019-03-23 01:35:33,328] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:35:33,330] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 6.256914e-37 0.000000e+00], sampled 0.6217922812120902
[2019-03-23 01:35:33,333] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 837936.5520631167 W.
[2019-03-23 01:35:47,243] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.18370543], dtype=float32), -0.13674285]
[2019-03-23 01:35:47,245] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.6, 85.0, 1.0, 2.0, 0.7386708770725092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 841900.0438049373, 841900.0438049373, 183597.6328214991]
[2019-03-23 01:35:47,246] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:35:47,250] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.8447488e-37 0.0000000e+00], sampled 0.3438396993501407
[2019-03-23 01:35:47,250] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 841900.0438049373 W.
[2019-03-23 01:35:55,676] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.18370543], dtype=float32), -0.13674285]
[2019-03-23 01:35:55,677] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.1, 92.0, 1.0, 2.0, 0.7099768805747595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 809178.8012085373, 809178.8012085373, 178042.6388841437]
[2019-03-23 01:35:55,679] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:35:55,681] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 6.837442e-36 0.000000e+00], sampled 0.10157603130627002
[2019-03-23 01:35:55,683] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 809178.8012085373 W.
[2019-03-23 01:36:13,350] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.18370543], dtype=float32), -0.13674285]
[2019-03-23 01:36:13,350] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.24340635, 83.17622436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7378791026766208, 6.9112, 6.9112, 121.9260426156618, 549478.5015423867, 549478.5015423867, 151965.5657088714]
[2019-03-23 01:36:13,351] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:36:13,353] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.07915314224550485
[2019-03-23 01:36:26,198] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.18370543], dtype=float32), -0.13674285]
[2019-03-23 01:36:26,200] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.5, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8703028441710153, 6.9112, 6.9112, 121.9260426156618, 639294.0155717502, 639294.0155717502, 171516.6513472252]
[2019-03-23 01:36:26,202] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:36:26,204] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6689023516637587
[2019-03-23 01:36:40,153] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8461.0729 2284102613.8261 640.0000
[2019-03-23 01:36:40,328] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7938.5578 2512247145.1360 720.0000
[2019-03-23 01:36:40,328] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8601.9312 2252326840.8311 509.0000
[2019-03-23 01:36:40,400] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8661.6044 2214756466.9861 525.0000
[2019-03-23 01:36:40,428] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8432.3618 2324292121.5915 555.0000
[2019-03-23 01:36:41,444] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1275000, evaluation results [1275000.0, 7938.557826039647, 2512247145.136011, 720.0, 8601.931245959971, 2252326840.831133, 509.0, 8661.604407201512, 2214756466.986145, 525.0, 8432.361836628148, 2324292121.5914974, 555.0, 8461.072891507216, 2284102613.826118, 640.0]
[2019-03-23 01:36:42,285] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:36:42,292] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6312
[2019-03-23 01:36:42,297] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 73.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4433730685230631, 6.911199999999999, 6.9112, 121.9260426156618, 316564.3200222696, 316564.3200222701, 100073.1911330404], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 21000.0000, 
sim time next is 21600.0000, 
raw observation next is [18.0, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4408848643622817, 6.9112, 6.9112, 121.9260426156618, 314787.4004062574, 314787.4004062574, 99524.2632598266], 
processed observation next is [1.0, 0.2608695652173913, 0.2222222222222222, 0.73, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3011060804528521, 0.0, 0.0, 0.8094621288201359, 0.11242407157366337, 0.11242407157366337, 0.191392813961205], 
reward next is 0.8086, 
noisyNet noise sample is [array([0.33625072], dtype=float32), -1.2746949]. 
=============================================
[2019-03-23 01:36:42,780] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:36:42,793] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7511
[2019-03-23 01:36:42,798] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 43.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5260298330170846, 6.9112, 6.9112, 121.9260426156618, 375938.5143793615, 375938.5143793615, 117229.2416156591], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 340200.0000, 
sim time next is 340800.0000, 
raw observation next is [23.86666666666667, 44.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5241608711875023, 6.911200000000001, 6.9112, 121.9260426156618, 374405.9697968814, 374405.969796881, 117019.0348953384], 
processed observation next is [0.0, 0.9565217391304348, 0.4395061728395063, 0.44, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.40520108898437784, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1337164177846005, 0.13371641778460036, 0.22503660556795846], 
reward next is 0.7750, 
noisyNet noise sample is [array([0.70637417], dtype=float32), -0.051306546]. 
=============================================
[2019-03-23 01:36:44,380] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:36:44,395] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2363
[2019-03-23 01:36:44,398] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.96666666666667, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6924077427508172, 6.9112, 6.9112, 121.9260426156618, 517427.2314256969, 517427.2314256969, 143893.1180019691], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 78600.0000, 
sim time next is 79200.0000, 
raw observation next is [25.8, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6914395391794388, 6.911199999999999, 6.9112, 121.9260426156618, 516704.5935446547, 516704.5935446552, 143834.0507842301], 
processed observation next is [1.0, 0.9565217391304348, 0.5111111111111112, 0.59, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6142994239742985, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18453735483737668, 0.18453735483737685, 0.2766039438158271], 
reward next is 0.7234, 
noisyNet noise sample is [array([-1.1491816], dtype=float32), 0.48410982]. 
=============================================
[2019-03-23 01:36:45,983] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:36:45,992] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9056
[2019-03-23 01:36:45,996] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.03333333333333, 18.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5547526601178036, 6.911199999999999, 6.9112, 121.9260426156618, 396108.8675256512, 396108.8675256517, 99237.96431657096], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 180600.0000, 
sim time next is 181200.0000, 
raw observation next is [25.66666666666667, 20.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5486117206148479, 6.9112, 6.9112, 121.9260426156618, 391722.9456194183, 391722.9456194183, 98887.81281734718], 
processed observation next is [0.0, 0.08695652173913043, 0.506172839506173, 0.2, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4357646507685598, 0.0, 0.0, 0.8094621288201359, 0.1399010520069351, 0.1399010520069351, 0.19016887080259073], 
reward next is 0.8098, 
noisyNet noise sample is [array([0.5837364], dtype=float32), -2.3422518]. 
=============================================
[2019-03-23 01:36:54,472] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:36:54,479] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3922
[2019-03-23 01:36:54,485] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.7, 37.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5549291715134465, 6.9112, 6.9112, 121.9260426156618, 398965.7200231063, 398965.7200231063, 120308.6566349459], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 333000.0000, 
sim time next is 333600.0000, 
raw observation next is [25.56666666666667, 38.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5523188884656544, 6.9112, 6.9112, 121.9260426156618, 396999.1533287051, 396999.1533287051, 120065.8001078649], 
processed observation next is [0.0, 0.8695652173913043, 0.5024691358024692, 0.38, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4403986105820679, 0.0, 0.0, 0.8094621288201359, 0.14178541190310898, 0.14178541190310898, 0.23089576943820173], 
reward next is 0.7691, 
noisyNet noise sample is [array([-1.2531484], dtype=float32), -0.2559748]. 
=============================================
[2019-03-23 01:37:01,356] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:37:01,363] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8992
[2019-03-23 01:37:01,370] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.7, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.502543295436406, 6.9112, 6.9112, 121.9260426156618, 358821.2042698291, 358821.2042698291, 111663.2569125693], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 345600.0000, 
sim time next is 346200.0000, 
raw observation next is [22.55, 48.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4993592877329123, 6.911200000000001, 6.9112, 121.9260426156618, 356547.2607807575, 356547.2607807571, 110892.7900654733], 
processed observation next is [1.0, 0.0, 0.3907407407407408, 0.485, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3741991096661404, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1273383074216991, 0.12733830742169897, 0.21325536551052557], 
reward next is 0.7867, 
noisyNet noise sample is [array([-0.8867564], dtype=float32), -0.66288584]. 
=============================================
[2019-03-23 01:37:04,062] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.9652333e-38 7.4372922e-32 1.8438097e-33], sum to 1.0000
[2019-03-23 01:37:04,070] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7689
[2019-03-23 01:37:04,073] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.96666666666667, 42.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5287426894443796, 6.9112, 6.9112, 121.9260426156618, 382314.7678561966, 382314.7678561966, 118993.5963932498], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 429600.0000, 
sim time next is 430200.0000, 
raw observation next is [24.7, 43.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5229126116927667, 6.9112, 6.9112, 121.9260426156618, 378030.3166560044, 378030.3166560044, 118500.3352188996], 
processed observation next is [1.0, 1.0, 0.4703703703703703, 0.435, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4036407646159583, 0.0, 0.0, 0.8094621288201359, 0.13501082737714443, 0.13501082737714443, 0.2278852600363454], 
reward next is 0.7721, 
noisyNet noise sample is [array([-1.3662037], dtype=float32), 0.10155812]. 
=============================================
[2019-03-23 01:37:10,451] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:37:10,459] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5353
[2019-03-23 01:37:10,463] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.13333333333333, 38.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.581454308048091, 6.9112, 6.9112, 121.9260426156618, 431397.1691045445, 431397.1691045445, 128518.7117512123], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 504600.0000, 
sim time next is 505200.0000, 
raw observation next is [27.86666666666667, 39.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.58157758360695, 6.911200000000001, 6.9112, 121.9260426156618, 431330.4109728995, 431330.410972899, 128422.1086303506], 
processed observation next is [1.0, 0.8695652173913043, 0.5876543209876545, 0.3966666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.47697197950868747, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1540465753474641, 0.15404657534746394, 0.246965593519905], 
reward next is 0.7530, 
noisyNet noise sample is [array([1.0069965], dtype=float32), 1.8893669]. 
=============================================
[2019-03-23 01:37:12,124] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:37:12,132] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1339
[2019-03-23 01:37:12,137] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.5, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.553005712720344, 6.9112, 6.9112, 121.9260426156618, 402097.0728933017, 402097.0728933017, 121826.5048305124], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 534600.0000, 
sim time next is 535200.0000, 
raw observation next is [19.43333333333333, 77.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.542233360721633, 6.9112, 6.9112, 121.9260426156618, 394106.3943858549, 394106.3943858549, 120867.0937354779], 
processed observation next is [1.0, 0.17391304347826086, 0.2753086419753085, 0.7733333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.42779170090204116, 0.0, 0.0, 0.8094621288201359, 0.1407522837092339, 0.1407522837092339, 0.2324367187220729], 
reward next is 0.7676, 
noisyNet noise sample is [array([0.78598213], dtype=float32), -0.15635704]. 
=============================================
[2019-03-23 01:37:21,072] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:37:21,080] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2378
[2019-03-23 01:37:21,088] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.95, 37.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5608382097411738, 6.911200000000001, 6.9112, 121.9260426156618, 409638.4931463773, 409638.4931463768, 123244.8166578075], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 693000.0000, 
sim time next is 693600.0000, 
raw observation next is [26.8, 37.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5590646756187225, 6.911200000000001, 6.9112, 121.9260426156618, 408010.9690253361, 408010.9690253356, 122952.3181862347], 
processed observation next is [1.0, 0.0, 0.5481481481481482, 0.3733333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4488308445234031, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1457182032233343, 0.14571820322333415, 0.23644676574275902], 
reward next is 0.7636, 
noisyNet noise sample is [array([-0.02202712], dtype=float32), 0.49771592]. 
=============================================
[2019-03-23 01:37:25,027] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:37:25,034] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6846
[2019-03-23 01:37:25,038] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.05, 28.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.60120480233555, 6.9112, 6.9112, 121.9260426156618, 441603.5201271847, 441603.5201271847, 127872.1386735292], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 761400.0000, 
sim time next is 762000.0000, 
raw observation next is [29.93333333333333, 28.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.598517730138238, 6.911200000000001, 6.9112, 121.9260426156618, 439587.1093489056, 439587.1093489051, 127609.2953462375], 
processed observation next is [1.0, 0.8260869565217391, 0.6641975308641974, 0.2833333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4981471626727974, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15699539619603772, 0.15699539619603753, 0.24540249105045672], 
reward next is 0.7546, 
noisyNet noise sample is [array([0.9568967], dtype=float32), -0.62165326]. 
=============================================
[2019-03-23 01:37:25,054] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[74.25284]
 [74.30252]
 [74.57175]
 [74.61293]
 [74.46926]], R is [[74.37149811]
 [74.38187408]
 [74.3915863 ]
 [74.40016937]
 [74.40769196]].
[2019-03-23 01:37:27,854] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:37:27,860] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5880
[2019-03-23 01:37:27,866] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.08333333333334, 58.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6002825138501496, 6.911200000000001, 6.9112, 121.9260426156618, 445187.3791796602, 445187.3791796597, 130152.2768747928], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 807000.0000, 
sim time next is 807600.0000, 
raw observation next is [24.36666666666667, 57.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6047730598495389, 6.911200000000001, 6.9112, 121.9260426156618, 448972.2685989626, 448972.2685989622, 130888.9548537684], 
processed observation next is [0.0, 0.34782608695652173, 0.4580246913580248, 0.5733333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5059663248119236, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16034723878534377, 0.16034723878534365, 0.2517095285649392], 
reward next is 0.7483, 
noisyNet noise sample is [array([0.44796506], dtype=float32), -1.2400686]. 
=============================================
[2019-03-23 01:37:29,701] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:37:29,708] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6046
[2019-03-23 01:37:29,713] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.68333333333334, 66.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5788123886679982, 6.9112, 6.9112, 121.9260426156618, 425028.9059156064, 425028.9059156064, 125808.7407440702], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 877800.0000, 
sim time next is 878400.0000, 
raw observation next is [21.6, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5765128688046164, 6.911200000000001, 6.9112, 121.9260426156618, 422752.8919413677, 422752.8919413672, 125330.9529423414], 
processed observation next is [0.0, 0.17391304347826086, 0.3555555555555556, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4706410860057704, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1509831756933456, 0.15098317569334543, 0.24102106335065654], 
reward next is 0.7590, 
noisyNet noise sample is [array([-0.59543407], dtype=float32), 0.10054904]. 
=============================================
[2019-03-23 01:37:29,873] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:37:29,881] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8366
[2019-03-23 01:37:29,885] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.53333333333333, 55.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.477528187281664, 6.911200000000001, 6.9112, 121.9260426156618, 340956.2311308848, 340956.2311308844, 111119.3461296092], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 956400.0000, 
sim time next is 957000.0000, 
raw observation next is [21.41666666666666, 55.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4741755146888413, 6.9112, 6.9112, 121.9260426156618, 338561.8430529447, 338561.8430529447, 110207.2514218741], 
processed observation next is [1.0, 0.043478260869565216, 0.3487654320987652, 0.5566666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.34271939336105156, 0.0, 0.0, 0.8094621288201359, 0.12091494394748024, 0.12091494394748024, 0.2119370219651425], 
reward next is 0.7881, 
noisyNet noise sample is [array([1.5383847], dtype=float32), -0.5439108]. 
=============================================
[2019-03-23 01:37:29,897] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.725784]
 [69.83292 ]
 [69.949356]
 [70.06552 ]
 [70.24009 ]], R is [[69.61640167]
 [69.70654297]
 [69.79399872]
 [69.87884521]
 [69.96117401]].
[2019-03-23 01:37:33,698] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:37:33,707] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5985
[2019-03-23 01:37:33,711] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.45, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7160886733440897, 6.911200000000001, 6.9112, 121.9260426156618, 535068.6616440361, 535068.6616440356, 147136.4776365505], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 916200.0000, 
sim time next is 916800.0000, 
raw observation next is [28.43333333333333, 46.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7141551367145207, 6.911199999999999, 6.9112, 121.9260426156618, 533660.5469159131, 533660.5469159136, 146720.7940856188], 
processed observation next is [0.0, 0.6086956521739131, 0.6086419753086418, 0.46666666666666656, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6426939208931509, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19059305246996897, 0.19059305246996913, 0.28215537324157464], 
reward next is 0.7178, 
noisyNet noise sample is [array([-0.8885037], dtype=float32), -0.2813512]. 
=============================================
[2019-03-23 01:37:35,034] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 01:37:35,037] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:37:35,038] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:37:35,038] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:37:35,040] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:37:35,039] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:37:35,040] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:37:35,042] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:37:35,044] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:37:35,044] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:37:35,044] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:37:35,073] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run53
[2019-03-23 01:37:35,098] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run53
[2019-03-23 01:37:35,100] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run53
[2019-03-23 01:37:35,120] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run53
[2019-03-23 01:37:35,159] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run53
[2019-03-23 01:37:37,739] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.18738256], dtype=float32), -0.090952404]
[2019-03-23 01:37:37,740] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.73013142, 44.62948841, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7569511423103926, 6.911200000000001, 6.9112, 121.9260426156618, 546291.1078469381, 546291.1078469376, 138951.4600538381]
[2019-03-23 01:37:37,741] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:37:37,746] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.00000e+00 0.00000e+00 0.00000e+00 4.82787e-38 0.00000e+00], sampled 0.7879598526912565
[2019-03-23 01:38:28,741] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.18738256], dtype=float32), -0.090952404]
[2019-03-23 01:38:28,742] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.0, 75.0, 1.0, 2.0, 0.9298503576153945, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1059947.525995646, 1059947.525995645, 224246.9105713485]
[2019-03-23 01:38:28,743] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:38:28,747] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9814641e-01 6.5320436e-36 1.6259785e-29 1.8535993e-03 9.7270596e-24], sampled 0.7203377403712868
[2019-03-23 01:38:28,748] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1059947.525995646 W.
[2019-03-23 01:39:29,314] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8507.7681 2279698485.1512 482.0000
[2019-03-23 01:39:29,411] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8009.9311 2505653692.1778 600.0000
[2019-03-23 01:39:29,412] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8693.3386 2211829063.3248 408.0000
[2019-03-23 01:39:29,427] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8492.9694 2318460095.7388 426.0000
[2019-03-23 01:39:29,445] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8643.0040 2247310519.9641 404.0000
[2019-03-23 01:39:30,462] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1300000, evaluation results [1300000.0, 8009.931114728239, 2505653692.177846, 600.0, 8643.003956724644, 2247310519.9640555, 404.0, 8693.3386453618, 2211829063.324831, 408.0, 8492.969415735699, 2318460095.738842, 426.0, 8507.768138837788, 2279698485.151178, 482.0]
[2019-03-23 01:39:33,764] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.9890176e-37 6.3163607e-38], sum to 1.0000
[2019-03-23 01:39:33,775] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4356
[2019-03-23 01:39:33,783] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 986650.3513342865 W.
[2019-03-23 01:39:33,789] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.33333333333334, 52.83333333333334, 1.0, 2.0, 0.399645700041837, 1.0, 1.0, 0.399645700041837, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 986650.3513342865, 986650.351334287, 208967.5056351623], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 997800.0000, 
sim time next is 998400.0000, 
raw observation next is [25.36666666666667, 52.66666666666667, 1.0, 2.0, 0.4677810492569576, 1.0, 2.0, 0.4677810492569576, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1150801.785953727, 1150801.785953727, 228859.9494841473], 
processed observation next is [1.0, 0.5652173913043478, 0.49506172839506185, 0.5266666666666667, 1.0, 1.0, 0.3664060110201876, 1.0, 1.0, 0.3664060110201876, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4110006378406168, 0.4110006378406168, 0.44011528746951406], 
reward next is 0.5599, 
noisyNet noise sample is [array([-0.3643575], dtype=float32), -0.3383379]. 
=============================================
[2019-03-23 01:39:34,594] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:39:34,602] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6753
[2019-03-23 01:39:34,608] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.06666666666667, 44.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5069700352519486, 6.9112, 6.9112, 121.9260426156618, 364243.4703237468, 364243.4703237468, 116417.8645827075], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1023600.0000, 
sim time next is 1024200.0000, 
raw observation next is [24.0, 45.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5074894619414326, 6.911200000000001, 6.9112, 121.9260426156618, 364624.7804239031, 364624.7804239027, 116460.9129305697], 
processed observation next is [1.0, 0.8695652173913043, 0.4444444444444444, 0.45, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.38436182742679076, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13022313586567968, 0.13022313586567952, 0.2239632940972494], 
reward next is 0.7760, 
noisyNet noise sample is [array([-0.22014089], dtype=float32), 0.5038979]. 
=============================================
[2019-03-23 01:39:35,489] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.2702314e-02 1.4650980e-24 1.1027576e-26 9.5729768e-01 4.5012795e-18], sum to 1.0000
[2019-03-23 01:39:35,496] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8092
[2019-03-23 01:39:35,501] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.7, 68.0, 1.0, 2.0, 0.4860047945756171, 1.0, 2.0, 0.4860047945756171, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1162731.207683, 1162731.207683, 233441.3436111418], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1767600.0000, 
sim time next is 1768200.0000, 
raw observation next is [24.76666666666667, 67.83333333333334, 1.0, 2.0, 0.5259212537322919, 1.0, 2.0, 0.5259212537322919, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1256004.482956213, 1256004.482956213, 245994.018618151], 
processed observation next is [1.0, 0.4782608695652174, 0.4728395061728396, 0.6783333333333335, 1.0, 1.0, 0.43562054015749035, 1.0, 1.0, 0.43562054015749035, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4485730296272189, 0.4485730296272189, 0.47306542041952115], 
reward next is 0.5269, 
noisyNet noise sample is [array([1.5504465], dtype=float32), -0.10971494]. 
=============================================
[2019-03-23 01:39:40,758] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 9.0192821e-28 2.1375039e-17 2.9352688e-27], sum to 1.0000
[2019-03-23 01:39:40,769] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9418
[2019-03-23 01:39:40,781] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.43333333333334, 74.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5195722768449231, 6.911200000000001, 6.9112, 121.9260426156618, 375307.6200615665, 375307.6200615661, 118119.5453265965], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1119000.0000, 
sim time next is 1119600.0000, 
raw observation next is [19.3, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5143122230897516, 6.911199999999999, 6.9112, 121.9260426156618, 371049.9269674123, 371049.9269674128, 117534.2254702337], 
processed observation next is [1.0, 1.0, 0.27037037037037037, 0.75, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3928902788621894, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1325178310597901, 0.1325178310597903, 0.22602735667352633], 
reward next is 0.7740, 
noisyNet noise sample is [array([-0.3059859], dtype=float32), 0.16531894]. 
=============================================
[2019-03-23 01:39:45,084] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5046735e-32 0.0000000e+00 7.0781218e-37 1.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 01:39:45,095] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9236
[2019-03-23 01:39:45,100] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.66666666666667, 94.0, 1.0, 2.0, 0.1731495099200596, 1.0, 2.0, 0.1731495099200596, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 433722.883592173, 433722.883592173, 154453.5089385769], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1208400.0000, 
sim time next is 1209000.0000, 
raw observation next is [18.63333333333333, 94.0, 1.0, 2.0, 0.1724955527775441, 1.0, 2.0, 0.1724955527775441, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 432274.3021098499, 432274.3021098503, 154323.4848352986], 
processed observation next is [1.0, 1.0, 0.24567901234567888, 0.94, 1.0, 1.0, 0.014875658068504887, 1.0, 1.0, 0.014875658068504887, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15438367932494637, 0.15438367932494654, 0.2967759323755742], 
reward next is 0.7032, 
noisyNet noise sample is [array([0.40638795], dtype=float32), -0.42389098]. 
=============================================
[2019-03-23 01:39:45,108] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.89942]
 [70.63071]
 [70.34869]
 [70.10044]
 [69.91171]], R is [[71.10173798]
 [71.09369659]
 [71.0853653 ]
 [71.07685089]
 [71.06830597]].
[2019-03-23 01:39:49,779] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:39:49,786] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1816
[2019-03-23 01:39:49,794] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.93333333333334, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5790464001795391, 6.9112, 6.9112, 121.9260426156618, 426928.5387358972, 426928.5387358972, 126693.7775862059], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1383000.0000, 
sim time next is 1383600.0000, 
raw observation next is [21.86666666666667, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.578083896160086, 6.9112, 6.9112, 121.9260426156618, 425900.5294356198, 425900.5294356198, 126440.7654284123], 
processed observation next is [0.0, 0.0, 0.36543209876543226, 0.67, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4726048702001075, 0.0, 0.0, 0.8094621288201359, 0.1521073319412928, 0.1521073319412928, 0.2431553181315621], 
reward next is 0.7568, 
noisyNet noise sample is [array([1.4166813], dtype=float32), 0.39031008]. 
=============================================
[2019-03-23 01:39:51,494] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:39:51,505] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4180
[2019-03-23 01:39:51,510] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.9, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.576123299525981, 6.911199999999999, 6.9112, 121.9260426156618, 426383.5403855576, 426383.540385558, 127342.8836389008], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1411200.0000, 
sim time next is 1411800.0000, 
raw observation next is [27.25, 41.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5791032809509709, 6.911199999999999, 6.9112, 121.9260426156618, 428873.3851911566, 428873.385191157, 127789.7316306443], 
processed observation next is [0.0, 0.34782608695652173, 0.5648148148148148, 0.41666666666666674, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4738791011887135, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15316906613969877, 0.15316906613969894, 0.2457494839050852], 
reward next is 0.7543, 
noisyNet noise sample is [array([-1.397525], dtype=float32), 0.44216955]. 
=============================================
[2019-03-23 01:39:58,040] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:39:58,049] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9991
[2019-03-23 01:39:58,054] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [34.0, 23.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6622793753291203, 6.9112, 6.9112, 121.9260426156618, 493285.145070452, 493285.145070452, 137796.0782393259], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1436400.0000, 
sim time next is 1437000.0000, 
raw observation next is [34.16666666666667, 22.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6779414658447038, 6.9112, 6.9112, 121.9260426156618, 505017.0099025817, 505017.0099025817, 139461.2250374989], 
processed observation next is [0.0, 0.6521739130434783, 0.8209876543209879, 0.225, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5974268323058798, 0.0, 0.0, 0.8094621288201359, 0.1803632178223506, 0.1803632178223506, 0.26819466353365173], 
reward next is 0.7318, 
noisyNet noise sample is [array([0.6262892], dtype=float32), 0.956511]. 
=============================================
[2019-03-23 01:39:58,067] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[82.5235  ]
 [82.42882 ]
 [82.33524 ]
 [82.244255]
 [82.15828 ]], R is [[82.43103027]
 [82.34172821]
 [82.25395203]
 [82.1677475 ]
 [82.0830307 ]].
[2019-03-23 01:40:09,921] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:40:09,930] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5703
[2019-03-23 01:40:09,937] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.01666666666667, 57.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5579044372756102, 6.9112, 6.9112, 121.9260426156618, 409018.8289373687, 409018.8289373687, 123669.8004869244], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1638600.0000, 
sim time next is 1639200.0000, 
raw observation next is [22.93333333333334, 58.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5550341543835163, 6.911200000000001, 6.9112, 121.9260426156618, 406919.5165485155, 406919.5165485151, 123424.8667499367], 
processed observation next is [1.0, 1.0, 0.40493827160493856, 0.5800000000000001, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4437926929793954, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14532839876732695, 0.14532839876732684, 0.2373555129806475], 
reward next is 0.7626, 
noisyNet noise sample is [array([0.1670641], dtype=float32), -0.8851366]. 
=============================================
[2019-03-23 01:40:12,546] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:40:12,559] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2893
[2019-03-23 01:40:12,563] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.56666666666667, 59.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6370342673993835, 6.911200000000001, 6.9112, 121.9260426156618, 474651.1184127104, 474651.11841271, 135428.5010714584], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2413200.0000, 
sim time next is 2413800.0000, 
raw observation next is [24.35, 60.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6370910589841682, 6.9112, 6.9112, 121.9260426156618, 474672.5271166008, 474672.5271166008, 135412.9918662141], 
processed observation next is [1.0, 0.9565217391304348, 0.4574074074074075, 0.605, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5463638237302102, 0.0, 0.0, 0.8094621288201359, 0.16952590254164313, 0.16952590254164313, 0.26040959974271943], 
reward next is 0.7396, 
noisyNet noise sample is [array([0.9674372], dtype=float32), 1.2450727]. 
=============================================
[2019-03-23 01:40:16,449] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:40:16,457] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9963
[2019-03-23 01:40:16,461] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.03333333333333, 74.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.666894053041703, 6.911200000000001, 6.9112, 121.9260426156618, 498247.1780415904, 498247.17804159, 140498.3646362427], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2020200.0000, 
sim time next is 2020800.0000, 
raw observation next is [23.26666666666667, 73.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6700585823262282, 6.9112, 6.9112, 121.9260426156618, 500677.0201241608, 500677.0201241608, 141099.965908094], 
processed observation next is [0.0, 0.391304347826087, 0.41728395061728407, 0.7333333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5875732279077852, 0.0, 0.0, 0.8094621288201359, 0.17881322147291456, 0.17881322147291456, 0.2713460882847961], 
reward next is 0.7287, 
noisyNet noise sample is [array([-1.6175928], dtype=float32), 0.09742349]. 
=============================================
[2019-03-23 01:40:19,366] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:40:19,378] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2276
[2019-03-23 01:40:19,386] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.95, 89.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6076281903106898, 6.911200000000001, 6.9112, 121.9260426156618, 447712.193460363, 447712.1934603626, 129142.7870668495], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1833000.0000, 
sim time next is 1833600.0000, 
raw observation next is [19.1, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5791145466647503, 6.911199999999999, 6.9112, 121.9260426156618, 426956.3076411831, 426956.3076411836, 126688.0224608762], 
processed observation next is [1.0, 0.21739130434782608, 0.262962962962963, 0.8833333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4738931833309378, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15248439558613683, 0.152484395586137, 0.24363081242476192], 
reward next is 0.7564, 
noisyNet noise sample is [array([-0.77069956], dtype=float32), -2.9949129]. 
=============================================
[2019-03-23 01:40:21,259] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:40:21,265] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2063
[2019-03-23 01:40:21,271] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.35, 81.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8149988193316605, 6.9112, 6.9112, 121.9260426156618, 603073.1176527784, 603073.1176527784, 163161.0308498087], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2106600.0000, 
sim time next is 2107200.0000, 
raw observation next is [24.6, 80.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8256042949158853, 6.911199999999999, 6.9112, 121.9260426156618, 610113.1486992022, 610113.1486992026, 164787.8541910054], 
processed observation next is [0.0, 0.391304347826087, 0.46666666666666673, 0.8033333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7820053686448566, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21789755310685793, 0.21789755310685807, 0.3168997195980873], 
reward next is 0.6831, 
noisyNet noise sample is [array([1.2750849], dtype=float32), 0.29299185]. 
=============================================
[2019-03-23 01:40:23,335] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 01:40:23,336] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:40:23,337] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:40:23,337] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:40:23,338] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:40:23,340] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:40:23,341] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:40:23,339] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:40:23,342] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:40:23,342] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:40:23,343] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:40:23,361] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run54
[2019-03-23 01:40:23,378] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run54
[2019-03-23 01:40:23,379] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run54
[2019-03-23 01:40:23,379] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run54
[2019-03-23 01:40:23,433] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run54
[2019-03-23 01:40:25,172] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02161224], dtype=float32), -0.075333044]
[2019-03-23 01:40:25,173] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.35995212333333, 37.49983241666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8871602874908204, 6.911200000000001, 6.9112, 121.9260426156618, 661585.3529896311, 661585.3529896307, 163427.6361335009]
[2019-03-23 01:40:25,175] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:40:25,179] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.026759184166711303
[2019-03-23 01:40:33,321] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02161224], dtype=float32), -0.075333044]
[2019-03-23 01:40:33,323] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [17.84776121333334, 80.81522204333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4626439992819655, 6.911200000000001, 6.9112, 121.9260426156618, 330326.7197745544, 330326.719774554, 109247.5867890847]
[2019-03-23 01:40:33,324] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:40:33,328] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.056808201759578125
[2019-03-23 01:41:26,600] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02161224], dtype=float32), -0.075333044]
[2019-03-23 01:41:26,602] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.93669087666667, 84.90336119, 1.0, 2.0, 0.75225416765572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 857390.2570864975, 857390.2570864975, 186277.4924251681]
[2019-03-23 01:41:26,602] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:41:26,605] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3999229e-19 1.7104146e-37], sampled 0.7587256353043099
[2019-03-23 01:41:26,606] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 857390.2570864975 W.
[2019-03-23 01:41:28,687] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02161224], dtype=float32), -0.075333044]
[2019-03-23 01:41:28,688] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.0, 81.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8663332458793265, 6.9112, 6.9112, 121.9260426156618, 635228.6769757208, 635228.6769757208, 171267.055703836]
[2019-03-23 01:41:28,690] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:41:28,694] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5492764058515509
[2019-03-23 01:41:29,747] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02161224], dtype=float32), -0.075333044]
[2019-03-23 01:41:29,750] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.4, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9541587700999002, 6.911200000000001, 6.9112, 121.9260426156618, 684262.951892505, 684262.9518925046, 185279.0933673404]
[2019-03-23 01:41:29,753] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:41:29,756] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5331620209378918
[2019-03-23 01:41:51,724] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02161224], dtype=float32), -0.075333044]
[2019-03-23 01:41:51,724] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.45, 81.16666666666666, 1.0, 2.0, 0.6844256779082533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 780042.624075651, 780042.624075651, 173217.4846577563]
[2019-03-23 01:41:51,724] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:41:51,730] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 8.4418061e-33 8.2618469e-12 5.7751115e-33], sampled 0.17805121546442892
[2019-03-23 01:41:51,732] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 780042.624075651 W.
[2019-03-23 01:41:52,197] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02161224], dtype=float32), -0.075333044]
[2019-03-23 01:41:52,198] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.986685965, 69.59487246166668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6805907300440864, 6.911200000000001, 6.9112, 121.9260426156618, 507889.5936482186, 507889.5936482181, 140771.870341858]
[2019-03-23 01:41:52,199] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:41:52,202] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4880196340785301
[2019-03-23 01:41:57,336] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02161224], dtype=float32), -0.075333044]
[2019-03-23 01:41:57,338] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.881175215, 76.6439707, 1.0, 2.0, 0.7249112333130014, 1.0, 2.0, 0.7249112333130014, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1653298.626198596, 1653298.626198596, 313704.3192642361]
[2019-03-23 01:41:57,339] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:41:57,344] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.6492972e-07 0.0000000e+00 5.6565946e-38 9.9999988e-01 1.4711673e-35], sampled 0.17170587234514367
[2019-03-23 01:42:01,026] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02161224], dtype=float32), -0.075333044]
[2019-03-23 01:42:01,028] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.48047967, 42.76473036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7089391203911156, 6.911199999999999, 6.9112, 121.9260426156618, 507386.5508673012, 507386.5508673016, 129095.8196579839]
[2019-03-23 01:42:01,029] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:42:01,033] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3787341511691825
[2019-03-23 01:42:17,166] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8650.8182 2246689610.9423 394.0000
[2019-03-23 01:42:17,282] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8027.5304 2503359921.2702 573.0000
[2019-03-23 01:42:17,510] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8518.8644 2316027512.3493 432.0000
[2019-03-23 01:42:17,532] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8533.0848 2277504001.9663 478.0000
[2019-03-23 01:42:17,678] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8718.2005 2210376328.4862 400.0000
[2019-03-23 01:42:18,692] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1325000, evaluation results [1325000.0, 8027.530438224778, 2503359921.270239, 573.0, 8650.818228495475, 2246689610.942307, 394.0, 8718.200476103277, 2210376328.4862294, 400.0, 8518.864374509016, 2316027512.3492556, 432.0, 8533.084825228434, 2277504001.966291, 478.0]
[2019-03-23 01:42:20,677] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:42:20,684] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2587
[2019-03-23 01:42:20,693] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.1, 89.0, 1.0, 2.0, 0.5870482060617273, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683388.0042693508, 683388.0042693508, 156544.1986357401], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2183400.0000, 
sim time next is 2184000.0000, 
raw observation next is [24.13333333333333, 89.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9234351418543006, 6.9112, 6.9112, 121.9260426156618, 675303.7692857292, 675303.7692857292, 179188.0657351998], 
processed observation next is [1.0, 0.2608695652173913, 0.44938271604938257, 0.89, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.9042939273178757, 0.0, 0.0, 0.8094621288201359, 0.24117991760204613, 0.24117991760204613, 0.3445924341061535], 
reward next is 0.6554, 
noisyNet noise sample is [array([0.59195215], dtype=float32), -0.08314048]. 
=============================================
[2019-03-23 01:42:20,710] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[65.78505]
 [65.27287]
 [65.01562]
 [64.67365]
 [65.04791]], R is [[70.47324371]
 [70.46746063]
 [70.41282654]
 [70.26669312]
 [70.11713409]].
[2019-03-23 01:42:23,860] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:42:23,868] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3641
[2019-03-23 01:42:23,871] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.9, 73.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9300027343765181, 6.911199999999999, 6.9112, 121.9260426156618, 675130.9396147506, 675130.939614751, 180931.1324267512], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1970400.0000, 
sim time next is 1971000.0000, 
raw observation next is [26.75, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9394481087044458, 6.9112, 6.9112, 121.9260426156618, 681212.4800686174, 681212.4800686174, 182340.1147306606], 
processed observation next is [1.0, 0.8260869565217391, 0.5462962962962963, 0.75, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9243101358805572, 0.0, 0.0, 0.8094621288201359, 0.24329017145307763, 0.24329017145307763, 0.35065406678973193], 
reward next is 0.6493, 
noisyNet noise sample is [array([1.3072598], dtype=float32), 0.104820184]. 
=============================================
[2019-03-23 01:42:23,881] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[71.63471 ]
 [71.20974 ]
 [71.112206]
 [71.14549 ]
 [71.20734 ]], R is [[71.36557007]
 [71.30397034]
 [71.24523163]
 [71.18895721]
 [71.13407135]].
[2019-03-23 01:42:27,201] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:42:27,214] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5498
[2019-03-23 01:42:27,220] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.55, 95.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7002347216166822, 6.9112, 6.9112, 121.9260426156618, 523261.7989796214, 523261.7989796214, 145126.6849555077], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2263800.0000, 
sim time next is 2264400.0000, 
raw observation next is [20.4, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6874193035932777, 6.9112, 6.9112, 121.9260426156618, 513691.4985777623, 513691.4985777623, 143235.2654321778], 
processed observation next is [1.0, 0.21739130434782608, 0.31111111111111106, 0.95, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6092741294915971, 0.0, 0.0, 0.8094621288201359, 0.18346124949205794, 0.18346124949205794, 0.27545243352341886], 
reward next is 0.7245, 
noisyNet noise sample is [array([-0.39712077], dtype=float32), 0.40259412]. 
=============================================
[2019-03-23 01:42:31,175] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:42:31,183] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0720
[2019-03-23 01:42:31,191] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.76666666666667, 72.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9020667625475866, 6.911199999999999, 6.9112, 121.9260426156618, 657829.3039090307, 657829.3039090312, 176664.5949826682], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2112600.0000, 
sim time next is 2113200.0000, 
raw observation next is [27.0, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9100061342481355, 6.911199999999999, 6.9112, 121.9260426156618, 662621.1014003617, 662621.1014003622, 177899.2573219364], 
processed observation next is [0.0, 0.4782608695652174, 0.5555555555555556, 0.72, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8875076678101692, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23665039335727206, 0.23665039335727223, 0.34211395638833925], 
reward next is 0.6579, 
noisyNet noise sample is [array([-0.44350395], dtype=float32), -0.31610852]. 
=============================================
[2019-03-23 01:42:31,362] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9127818e-07 2.2081172e-31 7.7105385e-28 9.9999976e-01 1.5400930e-22], sum to 1.0000
[2019-03-23 01:42:31,363] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5393
[2019-03-23 01:42:31,369] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.58333333333334, 40.16666666666667, 1.0, 2.0, 0.8968323547105207, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.983004694033585, 6.9112, 121.9256775832896, 1146835.153234201, 1110064.842144637, 220517.427377286], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2368200.0000, 
sim time next is 2368800.0000, 
raw observation next is [28.7, 40.0, 1.0, 2.0, 0.4552310163702858, 1.0, 1.0, 0.4552310163702858, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9259993761917, 1115627.540859124, 1115627.540859124, 224939.3404525516], 
processed observation next is [1.0, 0.43478260869565216, 0.6185185185185185, 0.4, 1.0, 1.0, 0.3514654956789117, 1.0, 0.5, 0.3514654956789117, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094618417550203, 0.3984384074496871, 0.3984384074496871, 0.4325756547164454], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2092303], dtype=float32), 0.75707483]. 
=============================================
[2019-03-23 01:42:38,365] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:42:38,371] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9530
[2019-03-23 01:42:38,382] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.05, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8863561704989473, 6.911199999999999, 6.9112, 121.9260426156618, 651119.6854323146, 651119.6854323151, 173600.7314987234], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2226600.0000, 
sim time next is 2227200.0000, 
raw observation next is [23.0, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8793845981291716, 6.9112, 6.9112, 121.9260426156618, 646437.2883428335, 646437.2883428335, 172582.0921694249], 
processed observation next is [1.0, 0.782608695652174, 0.4074074074074074, 0.95, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8492307476614643, 0.0, 0.0, 0.8094621288201359, 0.23087046012244053, 0.23087046012244053, 0.3318886387873556], 
reward next is 0.6681, 
noisyNet noise sample is [array([0.822288], dtype=float32), 0.24727696]. 
=============================================
[2019-03-23 01:42:42,187] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:42:42,195] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0137
[2019-03-23 01:42:42,201] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.93333333333333, 49.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7632981025286134, 6.9112, 6.9112, 121.9260426156618, 569856.6919778766, 569856.6919778766, 150107.8440992575], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2530200.0000, 
sim time next is 2530800.0000, 
raw observation next is [27.2, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7381181336125349, 6.9112, 6.9112, 121.9260426156618, 551179.0459050236, 551179.0459050236, 147517.3915860565], 
processed observation next is [1.0, 0.30434782608695654, 0.5629629629629629, 0.49, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6726476670156686, 0.0, 0.0, 0.8094621288201359, 0.19684965925179412, 0.19684965925179412, 0.2836872915116471], 
reward next is 0.7163, 
noisyNet noise sample is [array([-0.14792934], dtype=float32), -1.0292152]. 
=============================================
[2019-03-23 01:42:53,823] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:42:53,832] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8509
[2019-03-23 01:42:53,838] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.1, 94.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7423591923142777, 6.911200000000001, 6.9112, 121.9260426156618, 554373.5919424244, 554373.591942424, 150926.9348299883], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2604000.0000, 
sim time next is 2604600.0000, 
raw observation next is [21.05, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7416090669811656, 6.911200000000001, 6.9112, 121.9260426156618, 553828.8306514915, 553828.8306514911, 150813.5587355674], 
processed observation next is [0.0, 0.13043478260869565, 0.3351851851851852, 0.95, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6770113337264568, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19779601094696125, 0.1977960109469611, 0.29002607449147577], 
reward next is 0.7100, 
noisyNet noise sample is [array([0.5281152], dtype=float32), -0.9004285]. 
=============================================
[2019-03-23 01:42:56,714] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 9.0485258e-31 3.3956080e-26 2.2611860e-26 1.6748003e-22], sum to 1.0000
[2019-03-23 01:42:56,725] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2380
[2019-03-23 01:42:56,732] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 696247.9207463762 W.
[2019-03-23 01:42:56,736] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.83333333333333, 74.66666666666667, 1.0, 1.0, 0.3054679158838075, 1.0, 1.0, 0.3054679158838075, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696247.9207463762, 696247.9207463762, 181777.9677308293], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2657400.0000, 
sim time next is 2658000.0000, 
raw observation next is [26.66666666666667, 75.33333333333334, 1.0, 2.0, 0.3045320034447048, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4848921248466158, 6.911199999999999, 6.9112, 121.9260426156618, 695969.6819950693, 695969.6819950697, 196437.2968168806], 
processed observation next is [0.0, 0.782608695652174, 0.5432098765432101, 0.7533333333333334, 1.0, 1.0, 0.17206190886274383, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.3561151560582697, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24856060071252473, 0.2485606007125249, 0.37776403234015504], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7094915], dtype=float32), 0.6302008]. 
=============================================
[2019-03-23 01:42:56,747] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[53.454582]
 [59.860275]
 [59.493137]
 [59.395947]
 [59.020596]], R is [[50.98986816]
 [51.1303978 ]
 [51.26116943]
 [51.39705658]
 [51.53499985]].
[2019-03-23 01:43:00,854] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.00000000e+00 6.11889666e-31 1.08189454e-35 0.00000000e+00
 1.01213849e-31], sum to 1.0000
[2019-03-23 01:43:00,866] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0805
[2019-03-23 01:43:00,877] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 685840.345584852 W.
[2019-03-23 01:43:00,883] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.75, 85.5, 1.0, 2.0, 0.2991479650534387, 1.0, 2.0, 0.2991479650534387, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 685840.345584852, 685840.3455848525, 180455.7960423274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2849400.0000, 
sim time next is 2850000.0000, 
raw observation next is [23.83333333333334, 90.33333333333333, 1.0, 2.0, 0.578295008835927, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 673367.0358520128, 673367.0358520128, 155060.8592348742], 
processed observation next is [1.0, 1.0, 0.43827160493827183, 0.9033333333333333, 1.0, 1.0, 0.4979702486141988, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24048822709000459, 0.24048822709000459, 0.2981939600670658], 
reward next is 0.7018, 
noisyNet noise sample is [array([-0.39166158], dtype=float32), 2.1922174]. 
=============================================
[2019-03-23 01:43:00,896] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[52.30935 ]
 [52.102646]
 [52.593582]
 [52.3462  ]
 [53.09716 ]], R is [[52.64926147]
 [52.1227684 ]
 [51.60153961]
 [51.08552551]
 [50.57466888]].
[2019-03-23 01:43:04,301] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:43:04,312] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8091
[2019-03-23 01:43:04,318] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 891611.783777189 W.
[2019-03-23 01:43:04,321] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.3900855824853787, 0.0, 2.0, 0.0, 1.0, 1.0, 0.621115380819611, 6.911199999999999, 6.9112, 121.9260426156618, 891611.783777189, 891611.7837771894, 221024.7023486522], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3382200.0000, 
sim time next is 3382800.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.2625667933606483, 1.0, 1.0, 0.2625667933606483, 1.0, 2.0, 0.4180148862336213, 6.9112, 6.9112, 121.94756008, 897814.0524729715, 897814.0524729715, 242125.6121572588], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.12210332542934323, 1.0, 0.5, 0.12210332542934323, 1.0, 1.0, 0.27251860779202663, 0.0, 0.0, 0.8096049824067558, 0.3206478758832041, 0.3206478758832041, 0.46562617722549765], 
reward next is 0.5344, 
noisyNet noise sample is [array([1.5810695], dtype=float32), 0.12877907]. 
=============================================
[2019-03-23 01:43:11,794] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 01:43:11,796] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:43:11,797] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:43:11,798] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:43:11,798] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:43:11,799] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:43:11,800] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:43:11,800] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:43:11,802] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:43:11,801] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:43:11,805] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:43:11,832] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run55
[2019-03-23 01:43:11,832] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run55
[2019-03-23 01:43:11,879] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run55
[2019-03-23 01:43:11,880] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run55
[2019-03-23 01:43:11,880] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run55
[2019-03-23 01:43:18,211] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.20980166], dtype=float32), -0.15568934]
[2019-03-23 01:43:18,212] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.0, 30.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6367311976425082, 6.9112, 6.9112, 121.9260426156618, 466062.7567073516, 466062.7567073516, 130388.5608691772]
[2019-03-23 01:43:18,213] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:43:18,217] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.33858424751118654
[2019-03-23 01:44:07,264] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.20980166], dtype=float32), -0.15568934]
[2019-03-23 01:44:07,264] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.8, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9056021325062202, 6.911200000000001, 6.9112, 121.9260426156618, 661518.8646256499, 661518.8646256494, 176935.2914496922]
[2019-03-23 01:44:07,265] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:44:07,268] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.18431742956844654
[2019-03-23 01:44:35,927] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.20980166], dtype=float32), -0.15568934]
[2019-03-23 01:44:35,930] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.83333333333334, 79.5, 1.0, 2.0, 0.8864830664222373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426055986, 1083396.314651522, 1083396.314651522, 217744.1246719979]
[2019-03-23 01:44:35,930] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:44:35,932] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.2014695e-12 2.4658642e-37 0.0000000e+00 0.0000000e+00], sampled 0.2706545134656523
[2019-03-23 01:44:35,933] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1083396.314651522 W.
[2019-03-23 01:44:47,177] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.20980166], dtype=float32), -0.15568934]
[2019-03-23 01:44:47,180] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.6, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6301162620952794, 6.911199999999999, 6.9112, 121.9260426156618, 469053.9367859669, 469053.9367859674, 134320.183666583]
[2019-03-23 01:44:47,180] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:44:47,183] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.26107431695135563
[2019-03-23 01:45:05,792] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8650.2738 2216419649.2346 528.0000
[2019-03-23 01:45:06,269] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8583.2521 2254691770.0985 524.0000
[2019-03-23 01:45:06,285] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8405.4933 2327485942.0485 586.0000
[2019-03-23 01:45:06,341] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8438.1121 2286302645.9353 654.0000
[2019-03-23 01:45:06,359] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7921.5410 2515910998.7854 764.0000
[2019-03-23 01:45:07,378] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1350000, evaluation results [1350000.0, 7921.541024989694, 2515910998.785413, 764.0, 8583.252054475015, 2254691770.0984716, 524.0, 8650.273846081027, 2216419649.234578, 528.0, 8405.493254566032, 2327485942.0484805, 586.0, 8438.11214288898, 2286302645.9353085, 654.0]
[2019-03-23 01:45:17,708] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.2477722e-24 2.1705220e-29 1.8461027e-27 1.1120673e-29], sum to 1.0000
[2019-03-23 01:45:17,715] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7778
[2019-03-23 01:45:17,721] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 746509.0459289636 W.
[2019-03-23 01:45:17,730] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.6550169371698352, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 746509.0459289636, 746509.0459289631, 167801.0231239493], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3016800.0000, 
sim time next is 3017400.0000, 
raw observation next is [23.98333333333333, 99.33333333333334, 1.0, 2.0, 0.2167809901568422, 1.0, 1.0, 0.2167809901568422, 1.0, 1.0, 0.3451223963936536, 6.911200000000001, 6.9112, 121.94756008, 741179.5857120238, 741179.5857120233, 226154.6460999679], 
processed observation next is [1.0, 0.9565217391304348, 0.4438271604938271, 0.9933333333333334, 1.0, 1.0, 0.06759641685338358, 1.0, 0.5, 0.06759641685338358, 1.0, 0.5, 0.18140299549206698, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2647069948971513, 0.26470699489715116, 0.43491278096147673], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.59986204], dtype=float32), -1.4171114]. 
=============================================
[2019-03-23 01:45:20,610] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2490268e-16 3.5393611e-04 3.9660616e-16 2.2439872e-09 9.9964607e-01], sum to 1.0000
[2019-03-23 01:45:20,621] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2930
[2019-03-23 01:45:20,626] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.2, 86.0, 1.0, 2.0, 0.5134994596333885, 1.0, 2.0, 0.5134994596333885, 1.0, 2.0, 0.8175078632462257, 6.911200000000001, 6.9112, 121.94756008, 1756801.870977689, 1756801.870977688, 350264.1531776962], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3085200.0000, 
sim time next is 3085800.0000, 
raw observation next is [28.5, 84.16666666666667, 1.0, 2.0, 0.2992142637372193, 1.0, 2.0, 0.2992142637372193, 1.0, 2.0, 0.4763588525979081, 6.9112, 6.9112, 121.94756008, 1023209.102699163, 1023209.102699163, 255752.2653157021], 
processed observation next is [1.0, 0.7391304347826086, 0.6111111111111112, 0.8416666666666667, 1.0, 1.0, 0.16573126635383253, 1.0, 1.0, 0.16573126635383253, 1.0, 1.0, 0.3454485657473851, 0.0, 0.0, 0.8096049824067558, 0.3654318223925582, 0.3654318223925582, 0.49183127945327326], 
reward next is 0.5082, 
noisyNet noise sample is [array([0.71931887], dtype=float32), -0.7342022]. 
=============================================
[2019-03-23 01:45:21,482] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.6602648e-01 2.4479863e-09 3.4264834e-14 3.1580023e-02 2.3934969e-03], sum to 1.0000
[2019-03-23 01:45:21,489] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3013
[2019-03-23 01:45:21,498] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1627187.998533519 W.
[2019-03-23 01:45:21,503] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.2, 89.66666666666666, 1.0, 2.0, 0.8002168572382222, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1627187.998533519, 1627187.99853352, 336276.5890511885], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3055200.0000, 
sim time next is 3055800.0000, 
raw observation next is [26.6, 89.33333333333333, 1.0, 2.0, 0.8969709405636201, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1737626.779722391, 1737626.779722391, 356314.8545076476], 
processed observation next is [1.0, 0.34782608695652173, 0.5407407407407407, 0.8933333333333333, 1.0, 1.0, 0.8773463578138335, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.6205809927579967, 0.6205809927579967, 0.6852208740531684], 
reward next is 0.3148, 
noisyNet noise sample is [array([1.0023338], dtype=float32), -0.6621755]. 
=============================================
[2019-03-23 01:45:30,439] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:45:30,448] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8955
[2019-03-23 01:45:30,455] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 785358.8397206649 W.
[2019-03-23 01:45:30,460] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.6890878480145702, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 785358.8397206649, 785358.8397206644, 174087.8019216164], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3447000.0000, 
sim time next is 3447600.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.2301848497729828, 1.0, 1.0, 0.2301848497729828, 1.0, 1.0, 0.3664617774357811, 6.911199999999999, 6.9112, 121.94756008, 787031.2376376296, 787031.23763763, 230708.869326417], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.89, 1.0, 1.0, 0.0835533925868843, 1.0, 0.5, 0.0835533925868843, 1.0, 0.5, 0.20807722179472637, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.281082584870582, 0.28108258487058213, 0.44367090255080194], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.496563], dtype=float32), -2.2813451]. 
=============================================
[2019-03-23 01:45:32,855] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.000000e+00 6.410732e-33 4.734717e-34 0.000000e+00 8.385274e-36], sum to 1.0000
[2019-03-23 01:45:32,860] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5541
[2019-03-23 01:45:32,865] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 830078.9477355141 W.
[2019-03-23 01:45:32,871] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.4, 67.5, 1.0, 2.0, 0.3641524161689186, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5797425061571502, 6.9112, 6.9112, 121.9260426156618, 830078.9477355141, 830078.9477355141, 213299.8453051036], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3951000.0000, 
sim time next is 3951600.0000, 
raw observation next is [30.23333333333333, 68.66666666666666, 1.0, 2.0, 0.3723556684481726, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5928023509469978, 6.911199999999999, 6.9112, 121.9260426156618, 848788.4693564274, 848788.4693564279, 215726.8117314155], 
processed observation next is [0.0, 0.7391304347826086, 0.6753086419753086, 0.6866666666666665, 1.0, 1.0, 0.25280436720020544, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4910029386837473, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30313873905586697, 0.30313873905586713, 0.4148592533296452], 
reward next is 0.5851, 
noisyNet noise sample is [array([-0.712322], dtype=float32), -0.21507932]. 
=============================================
[2019-03-23 01:45:35,804] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:45:35,813] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3463
[2019-03-23 01:45:35,822] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 718957.6211629212 W.
[2019-03-23 01:45:35,826] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.65, 79.66666666666667, 1.0, 2.0, 0.210284532456131, 1.0, 1.0, 0.210284532456131, 1.0, 2.0, 0.3347798241592647, 6.9112, 6.9112, 121.94756008, 718957.6211629212, 718957.6211629212, 223983.5072788296], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3325800.0000, 
sim time next is 3326400.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.3220285543206188, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5126799462162523, 6.911199999999999, 6.9112, 121.9260426156618, 734012.3792084327, 734012.3792084332, 201259.0350893067], 
processed observation next is [0.0, 0.5217391304347826, 0.5555555555555556, 0.79, 1.0, 1.0, 0.19289113609597475, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.3908499327703154, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26214727828872597, 0.26214727828872614, 0.38703660594097444], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5213815], dtype=float32), -0.5344819]. 
=============================================
[2019-03-23 01:45:37,544] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 6.7598975e-36 5.8746078e-19], sum to 1.0000
[2019-03-23 01:45:37,551] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6063
[2019-03-23 01:45:37,556] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 780704.4502064683 W.
[2019-03-23 01:45:37,560] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.3425030411935462, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5452759961254379, 6.911200000000001, 6.9112, 121.9260426156618, 780704.4502064683, 780704.4502064679, 207022.5675148202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3359400.0000, 
sim time next is 3360000.0000, 
raw observation next is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.693042760503217, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 789868.6070463279, 789868.6070463276, 174831.2020543202], 
processed observation next is [0.0, 0.9130434782608695, 0.5432098765432101, 0.8566666666666667, 1.0, 1.0, 0.6345747148847821, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28209593108797426, 0.28209593108797415, 0.3362138501044619], 
reward next is 0.6638, 
noisyNet noise sample is [array([0.03811824], dtype=float32), -1.6177582]. 
=============================================
[2019-03-23 01:45:37,573] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[38.200603]
 [37.46462 ]
 [37.573887]
 [37.20572 ]
 [37.18371 ]], R is [[38.48258591]
 [38.09775925]
 [37.71678162]
 [37.33961487]
 [36.96622086]].
[2019-03-23 01:45:42,475] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:45:42,485] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9064
[2019-03-23 01:45:42,492] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.72904186820686, 6.9112, 6.9112, 121.9260426156618, 544647.517373175, 544647.517373175, 148935.6704378583], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4131000.0000, 
sim time next is 4131600.0000, 
raw observation next is [20.9, 94.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7271033453765213, 6.911199999999999, 6.9112, 121.9260426156618, 543218.0077763866, 543218.007776387, 148663.0233789799], 
processed observation next is [1.0, 0.8260869565217391, 0.32962962962962955, 0.9466666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6588791817206515, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19400643134870948, 0.19400643134870965, 0.28589042957496136], 
reward next is 0.7141, 
noisyNet noise sample is [array([0.8248386], dtype=float32), 0.33986944]. 
=============================================
[2019-03-23 01:45:51,061] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3422198e-11 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 01:45:51,075] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3790
[2019-03-23 01:45:51,080] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.03333333333333, 94.0, 1.0, 2.0, 0.2240728421589587, 1.0, 2.0, 0.2240728421589587, 1.0, 2.0, 0.3567312622600634, 6.9112, 6.9112, 121.94756008, 766123.065456268, 766123.065456268, 228619.7325151584], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3709200.0000, 
sim time next is 3709800.0000, 
raw observation next is [25.05, 94.0, 1.0, 2.0, 0.2201924015782168, 1.0, 2.0, 0.2201924015782168, 1.0, 2.0, 0.3505534744783954, 6.911199999999999, 6.9112, 121.94756008, 752849.0127683505, 752849.012768351, 227304.2068699248], 
processed observation next is [1.0, 0.9565217391304348, 0.48333333333333334, 0.94, 1.0, 1.0, 0.07165762092644856, 1.0, 1.0, 0.07165762092644856, 1.0, 1.0, 0.18819184309799425, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2688746474172681, 0.26887464741726824, 0.43712347474985536], 
reward next is 0.5629, 
noisyNet noise sample is [array([0.51068], dtype=float32), 0.05127826]. 
=============================================
[2019-03-23 01:46:00,137] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 01:46:00,139] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:46:00,140] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:46:00,140] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:46:00,141] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:46:00,143] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:46:00,144] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:46:00,145] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:46:00,147] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:46:00,148] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:46:00,150] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:46:00,167] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run56
[2019-03-23 01:46:00,195] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run56
[2019-03-23 01:46:00,196] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run56
[2019-03-23 01:46:00,196] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run56
[2019-03-23 01:46:00,266] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run56
[2019-03-23 01:46:08,704] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.17890224], dtype=float32), -0.13641942]
[2019-03-23 01:46:08,705] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.805897065, 58.34301727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4360354578135641, 6.9112, 6.9112, 121.9260426156618, 311324.2697187667, 311324.2697187667, 97310.17005217918]
[2019-03-23 01:46:08,707] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:46:08,709] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9688829623237016
[2019-03-23 01:46:33,276] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.17890224], dtype=float32), -0.13641942]
[2019-03-23 01:46:33,278] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.28313876333333, 83.82882919833334, 1.0, 2.0, 0.6376977314953922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 751187.2139907591, 751187.2139907591, 165818.6311110856]
[2019-03-23 01:46:33,279] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:46:33,283] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.000000e+00 0.000000e+00 5.662751e-37 0.000000e+00 1.309192e-28], sampled 0.47093286191914885
[2019-03-23 01:46:33,285] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 751187.2139907591 W.
[2019-03-23 01:46:51,359] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.17890224], dtype=float32), -0.13641942]
[2019-03-23 01:46:51,361] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.81353997333333, 94.48229862000001, 1.0, 2.0, 0.5836479059340361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 674309.5175814921, 674309.5175814921, 155730.5839687896]
[2019-03-23 01:46:51,363] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:46:51,366] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.14741924609786583
[2019-03-23 01:46:53,490] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.17890224], dtype=float32), -0.13641942]
[2019-03-23 01:46:53,491] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.03333333333333, 78.50000000000001, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.291144491820797, 6.9112, 121.9244548371205, 1357498.847911878, 1162935.842770685, 245597.3187653111]
[2019-03-23 01:46:53,494] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:46:53,496] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 1.0481901e-24 5.5534172e-21 2.4769758e-10], sampled 0.2726341563246376
[2019-03-23 01:46:53,499] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1357498.847911878 W.
[2019-03-23 01:46:55,364] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.17890224], dtype=float32), -0.13641942]
[2019-03-23 01:46:55,366] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.0, 64.66666666666667, 1.0, 2.0, 0.7355249996289563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 838312.5694901944, 838312.5694901944, 182981.6025455396]
[2019-03-23 01:46:55,367] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:46:55,370] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 3.4109210e-37 0.0000000e+00 1.9514858e-29], sampled 0.5160067093289142
[2019-03-23 01:46:55,371] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 838312.5694901944 W.
[2019-03-23 01:46:59,561] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.17890224], dtype=float32), -0.13641942]
[2019-03-23 01:46:59,565] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.95, 89.16666666666667, 1.0, 2.0, 0.6158415314061815, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9804397745570975, 6.911199999999999, 6.9112, 121.9260426156618, 1404325.600643813, 1404325.600643813, 300078.7173028438]
[2019-03-23 01:46:59,566] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:46:59,568] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 4.0288437e-28 3.3522989e-26 3.8216822e-11], sampled 0.44875965697355924
[2019-03-23 01:46:59,569] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1404325.600643813 W.
[2019-03-23 01:47:07,115] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.17890224], dtype=float32), -0.13641942]
[2019-03-23 01:47:07,117] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.88900995666667, 82.34240469333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.837099825370155, 6.9112, 6.9112, 121.9260426156618, 614404.758260902, 614404.758260902, 167380.5316675921]
[2019-03-23 01:47:07,118] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:47:07,124] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5627816360563112
[2019-03-23 01:47:08,255] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.17890224], dtype=float32), -0.13641942]
[2019-03-23 01:47:08,259] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.33333333333333, 92.33333333333334, 1.0, 2.0, 0.6277716412333242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 723173.3061653548, 723173.3061653548, 163300.3223782511]
[2019-03-23 01:47:08,261] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:47:08,263] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.17882635310641537
[2019-03-23 01:47:08,265] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 723173.3061653548 W.
[2019-03-23 01:47:09,807] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.17890224], dtype=float32), -0.13641942]
[2019-03-23 01:47:09,807] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.0, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6910170313866495, 6.9112, 6.9112, 121.9260426156618, 515825.8176019556, 515825.8176019556, 142100.6641269657]
[2019-03-23 01:47:09,808] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:47:09,810] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9387439826756565
[2019-03-23 01:47:10,883] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.17890224], dtype=float32), -0.13641942]
[2019-03-23 01:47:10,884] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.03333333333333, 77.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.700876951747057, 6.9112, 6.9112, 121.9260426156618, 523685.6599072826, 523685.6599072826, 145499.0000626032]
[2019-03-23 01:47:10,886] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:47:10,890] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5998029915302512
[2019-03-23 01:47:28,538] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.17890224], dtype=float32), -0.13641942]
[2019-03-23 01:47:28,540] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.33333333333334, 52.66666666666667, 1.0, 2.0, 0.5627922807528962, 1.0, 2.0, 0.5627922807528962, 1.0, 1.0, 0.8959836398235903, 6.9112, 6.9112, 121.94756008, 1925625.908819456, 1925625.908819456, 375475.9279419024]
[2019-03-23 01:47:28,541] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:47:28,544] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.7288430e-11 1.9580674e-32 4.7061605e-18 1.2735993e-17 1.0000000e+00], sampled 0.8219900442602468
[2019-03-23 01:47:36,156] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.17890224], dtype=float32), -0.13641942]
[2019-03-23 01:47:36,157] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.16666666666666, 87.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8405171561535074, 6.9112, 6.9112, 121.9260426156618, 623365.3700770993, 623365.3700770993, 165807.8275517702]
[2019-03-23 01:47:36,162] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:47:36,165] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.1782644275263986
[2019-03-23 01:47:39,626] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.17890224], dtype=float32), -0.13641942]
[2019-03-23 01:47:39,627] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.8, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8959289873376889, 6.9112, 6.9112, 121.9260426156618, 654336.6555681797, 654336.6555681797, 175667.7980884768]
[2019-03-23 01:47:39,628] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:47:39,630] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4660041993224888
[2019-03-23 01:47:53,802] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8562.0716 2258599570.3454 521.0000
[2019-03-23 01:47:53,824] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.9283 2338841974.3718 560.0000
[2019-03-23 01:47:53,831] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8640.5382 2219013366.3383 528.0000
[2019-03-23 01:47:53,850] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7874.8077 2532432634.3392 688.0000
[2019-03-23 01:47:53,946] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8421.0476 2293398644.7475 642.0000
[2019-03-23 01:47:54,962] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1375000, evaluation results [1375000.0, 7874.807725787931, 2532432634.3391743, 688.0, 8562.071620384171, 2258599570.3454256, 521.0, 8640.538214590717, 2219013366.3383102, 528.0, 8364.928328189531, 2338841974.3717685, 560.0, 8421.04761581684, 2293398644.7475214, 642.0]
[2019-03-23 01:47:55,031] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.5252288e-36], sum to 1.0000
[2019-03-23 01:47:55,038] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1297
[2019-03-23 01:47:55,046] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 782240.8348507934 W.
[2019-03-23 01:47:55,059] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.93333333333333, 47.33333333333333, 1.0, 2.0, 0.3431767251179146, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5463485228733861, 6.911199999999999, 6.9112, 121.9260426156618, 782240.8348507934, 782240.8348507938, 207214.5952548875], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3861600.0000, 
sim time next is 3862200.0000, 
raw observation next is [33.91666666666666, 46.66666666666667, 1.0, 2.0, 0.3414041733637268, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5435265627527387, 6.911199999999999, 6.9112, 121.9260426156618, 778198.4096926468, 778198.4096926473, 206708.2119871833], 
processed observation next is [0.0, 0.6956521739130435, 0.811728395061728, 0.46666666666666673, 1.0, 1.0, 0.2159573492425319, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.42940820344092334, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2779280034616596, 0.27792800346165975, 0.39751579228304484], 
reward next is 0.6025, 
noisyNet noise sample is [array([0.1954738], dtype=float32), 0.7220083]. 
=============================================
[2019-03-23 01:47:55,545] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.4692611e-08 1.3953317e-18 0.0000000e+00 1.3939947e-09], sum to 1.0000
[2019-03-23 01:47:55,550] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0472
[2019-03-23 01:47:55,558] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2223440.429634645 W.
[2019-03-23 01:47:55,562] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.0, 42.0, 1.0, 2.0, 0.6727200971451551, 1.0, 2.0, 0.6497247105490122, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2223440.429634645, 2223440.429634645, 421989.9449392776], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3772800.0000, 
sim time next is 3773400.0000, 
raw observation next is [34.56666666666667, 46.83333333333333, 1.0, 2.0, 0.9232099713584067, 1.0, 2.0, 0.9232099713584067, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2106090.025627504, 2106090.025627504, 397297.371864324], 
processed observation next is [1.0, 0.6956521739130435, 0.8358024691358026, 0.46833333333333327, 1.0, 1.0, 0.9085832992361984, 1.0, 1.0, 0.9085832992361984, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.75217500915268, 0.75217500915268, 0.7640334074313924], 
reward next is 0.2360, 
noisyNet noise sample is [array([-1.0588825], dtype=float32), 0.19423074]. 
=============================================
[2019-03-23 01:47:58,051] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:47:58,060] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4205
[2019-03-23 01:47:58,064] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.896795983810307, 6.911200000000001, 6.9112, 121.9260426156618, 657144.5766457634, 657144.5766457629, 175347.5111143859], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3813600.0000, 
sim time next is 3814200.0000, 
raw observation next is [26.0, 76.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9043854417873729, 6.9112, 6.9112, 121.9260426156618, 661481.1542786269, 661481.1542786269, 176608.1394257286], 
processed observation next is [0.0, 0.13043478260869565, 0.5185185185185185, 0.765, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8804818022342161, 0.0, 0.0, 0.8094621288201359, 0.2362432693852239, 0.2362432693852239, 0.3396310373571704], 
reward next is 0.6604, 
noisyNet noise sample is [array([-2.6144497], dtype=float32), -1.642578]. 
=============================================
[2019-03-23 01:48:01,970] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:48:01,977] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6865
[2019-03-23 01:48:01,983] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 854243.902472947 W.
[2019-03-23 01:48:01,988] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.1, 88.33333333333333, 1.0, 2.0, 0.7494951672432678, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 854243.902472947, 854243.902472947, 185729.0653094696], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3919200.0000, 
sim time next is 3919800.0000, 
raw observation next is [27.05, 88.66666666666667, 1.0, 2.0, 0.3767944289283616, 1.0, 1.0, 0.3767944289283616, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 858912.3378525564, 858912.3378525568, 199911.6615820925], 
processed observation next is [0.0, 0.34782608695652173, 0.5574074074074075, 0.8866666666666667, 1.0, 1.0, 0.2580886058670972, 1.0, 0.5, 0.2580886058670972, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.306754406375913, 0.30675440637591317, 0.38444550304248554], 
reward next is 0.6156, 
noisyNet noise sample is [array([0.97440547], dtype=float32), -0.54295385]. 
=============================================
[2019-03-23 01:48:04,937] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.9436149e-36 3.7666216e-32 0.0000000e+00 4.7900705e-27], sum to 1.0000
[2019-03-23 01:48:04,945] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9922
[2019-03-23 01:48:04,954] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 754250.3507502541 W.
[2019-03-23 01:48:04,959] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.08333333333333, 98.00000000000001, 1.0, 2.0, 0.3309030639325832, 1.0, 2.0, 0.3309030639325832, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 754250.3507502541, 754250.3507502541, 188041.8920393455], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4054200.0000, 
sim time next is 4054800.0000, 
raw observation next is [24.16666666666666, 96.0, 1.0, 2.0, 0.2148847900938667, 1.0, 2.0, 0.2148847900938667, 1.0, 1.0, 0.3421035841384718, 6.9112, 6.9112, 121.94756008, 734693.324284091, 734693.324284091, 225518.4890457798], 
processed observation next is [1.0, 0.9565217391304348, 0.45061728395061706, 0.96, 1.0, 1.0, 0.0653390358260318, 1.0, 1.0, 0.0653390358260318, 1.0, 0.5, 0.17762948017308974, 0.0, 0.0, 0.8096049824067558, 0.26239047295860396, 0.26239047295860396, 0.433689402011115], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3712603], dtype=float32), 2.4316597]. 
=============================================
[2019-03-23 01:48:08,116] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:48:08,121] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4119
[2019-03-23 01:48:08,126] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.88333333333333, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9092642865557872, 6.9112, 6.9112, 121.9260426156618, 663273.1187100431, 663273.1187100431, 177594.3162436209], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4302600.0000, 
sim time next is 4303200.0000, 
raw observation next is [29.76666666666667, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9142452531603961, 6.911200000000001, 6.9112, 121.9260426156618, 666038.0336274105, 666038.0336274102, 178415.1233911653], 
processed observation next is [1.0, 0.8260869565217391, 0.6580246913580248, 0.57, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8928065664504949, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23787072629550376, 0.23787072629550363, 0.3431060065214718], 
reward next is 0.6569, 
noisyNet noise sample is [array([-0.35114622], dtype=float32), 2.1745315]. 
=============================================
[2019-03-23 01:48:13,250] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:48:13,260] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6584
[2019-03-23 01:48:13,266] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.6, 77.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8512838293012994, 6.9112, 6.9112, 121.9260426156618, 620558.917189816, 620558.917189816, 170036.0535172093], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4123800.0000, 
sim time next is 4124400.0000, 
raw observation next is [24.4, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8176619541321778, 6.911200000000001, 6.9112, 121.9260426156618, 603134.7000894656, 603134.7000894651, 164114.4059654844], 
processed observation next is [1.0, 0.7391304347826086, 0.4592592592592592, 0.8066666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7720774426652222, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.215405250031952, 0.21540525003195182, 0.31560462685670077], 
reward next is 0.6844, 
noisyNet noise sample is [array([-0.22318637], dtype=float32), -0.4990698]. 
=============================================
[2019-03-23 01:48:18,934] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:48:18,943] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8025
[2019-03-23 01:48:18,951] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.16666666666667, 71.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7749739947022038, 6.911200000000001, 6.9112, 121.9260426156618, 576829.590448756, 576829.5904487555, 156568.702437665], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4233000.0000, 
sim time next is 4233600.0000, 
raw observation next is [25.0, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7910547978420029, 6.911199999999999, 6.9112, 121.9260426156618, 587777.388542051, 587777.3885420514, 159114.2347651142], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.74, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7388184973025036, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20992049590787534, 0.2099204959078755, 0.305988913009835], 
reward next is 0.6940, 
noisyNet noise sample is [array([-2.2080972], dtype=float32), 0.5410253]. 
=============================================
[2019-03-23 01:48:21,918] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:48:21,923] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1025
[2019-03-23 01:48:21,929] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.66666666666666, 63.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7482224079289143, 6.9112, 6.9112, 121.9260426156618, 558505.5430934534, 558505.5430934534, 151972.3748782161], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4236000.0000, 
sim time next is 4236600.0000, 
raw observation next is [25.83333333333334, 60.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7311725246256122, 6.911199999999999, 6.9112, 121.9260426156618, 546189.3536171973, 546189.3536171977, 149302.6903108625], 
processed observation next is [1.0, 0.0, 0.5123456790123458, 0.6066666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6639656557820153, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19506762629185617, 0.19506762629185634, 0.2871205582901202], 
reward next is 0.7129, 
noisyNet noise sample is [array([2.3988817], dtype=float32), -0.19167043]. 
=============================================
[2019-03-23 01:48:29,635] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.3902360e-01 9.4188589e-32 2.2449324e-29 3.4119856e-18 3.6097640e-01], sum to 1.0000
[2019-03-23 01:48:29,640] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3171
[2019-03-23 01:48:29,651] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 801549.1594361307 W.
[2019-03-23 01:48:29,657] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.6, 94.33333333333334, 1.0, 2.0, 0.2344287213857358, 1.0, 2.0, 0.2344287213857358, 1.0, 2.0, 0.3732181592565331, 6.911200000000001, 6.9112, 121.94756008, 801549.1594361307, 801549.1594361303, 232171.7474971882], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4675200.0000, 
sim time next is 4675800.0000, 
raw observation next is [23.3, 94.16666666666667, 1.0, 2.0, 0.3320783821764575, 1.0, 2.0, 0.3320783821764575, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 764490.2063700467, 764490.2063700472, 188703.0990503377], 
processed observation next is [1.0, 0.08695652173913043, 0.41851851851851857, 0.9416666666666668, 1.0, 1.0, 0.20485521687673514, 1.0, 1.0, 0.20485521687673514, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27303221656073096, 0.2730322165607311, 0.3628905750968033], 
reward next is 0.6371, 
noisyNet noise sample is [array([-1.3705773], dtype=float32), -0.28183818]. 
=============================================
[2019-03-23 01:48:44,060] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.3016568e-36 0.0000000e+00 0.0000000e+00 7.0850915e-37], sum to 1.0000
[2019-03-23 01:48:44,070] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3231
[2019-03-23 01:48:44,075] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 870778.370430229 W.
[2019-03-23 01:48:44,081] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.35, 87.0, 1.0, 2.0, 0.7639939161374625, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 870778.370430229, 870778.370430229, 188616.2904284667], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4923000.0000, 
sim time next is 4923600.0000, 
raw observation next is [27.23333333333333, 86.0, 1.0, 2.0, 0.3726713308933288, 1.0, 1.0, 0.3726713308933288, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 849508.4238330863, 849508.4238330867, 198815.364208125], 
processed observation next is [1.0, 1.0, 0.5641975308641974, 0.86, 1.0, 1.0, 0.25318015582539144, 1.0, 0.5, 0.25318015582539144, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3033958656546737, 0.30339586565467386, 0.38233723886177884], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.54968536], dtype=float32), -0.556666]. 
=============================================
[2019-03-23 01:48:46,032] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 4.3785867e-31 3.3869774e-27 0.0000000e+00 2.8715241e-17], sum to 1.0000
[2019-03-23 01:48:46,043] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9221
[2019-03-23 01:48:46,051] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1177598.398801912 W.
[2019-03-23 01:48:46,059] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.3443272443407696, 1.0, 1.0, 0.3443272443407696, 1.0, 2.0, 0.5481801869459664, 6.9112, 6.9112, 121.94756008, 1177598.398801912, 1177598.398801912, 273554.1060880609], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4712400.0000, 
sim time next is 4713000.0000, 
raw observation next is [27.38333333333333, 86.33333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.484254087861131, 6.9112, 121.9239946886891, 1456460.898668406, 1163010.915696615, 245589.492127828], 
processed observation next is [1.0, 0.5652173913043478, 0.569753086419753, 0.8633333333333334, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.05730540878611308, 0.0, 0.8094485327147312, 0.5201646066672879, 0.4153610413202196, 0.4722874848612077], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.11598315], dtype=float32), 1.9231039]. 
=============================================
[2019-03-23 01:48:46,074] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[25.189962]
 [24.057892]
 [24.94784 ]
 [25.194473]
 [24.316483]], R is [[23.67923355]
 [23.44244194]
 [23.59959221]
 [23.83090019]
 [24.10725021]].
[2019-03-23 01:48:47,111] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 01:48:47,112] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:48:47,113] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:47,114] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:48:47,114] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:47,115] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:48:47,117] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:47,117] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:48:47,118] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:47,120] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:48:47,121] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:48:47,151] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run57
[2019-03-23 01:48:47,177] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run57
[2019-03-23 01:48:47,204] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run57
[2019-03-23 01:48:47,205] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run57
[2019-03-23 01:48:47,243] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run57
[2019-03-23 01:48:51,652] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21556363], dtype=float32), -0.12538315]
[2019-03-23 01:48:51,653] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.03844218, 16.737273373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.650402732528869, 6.911200000000001, 6.9112, 121.9260426156618, 470744.3556453687, 470744.3556453683, 129523.9962408768]
[2019-03-23 01:48:51,655] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:48:51,658] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5580843738773972
[2019-03-23 01:49:19,167] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21556363], dtype=float32), -0.12538315]
[2019-03-23 01:49:19,168] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.19087862333334, 84.15955902500001, 1.0, 2.0, 0.6451380841744241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 735244.9251085663, 735244.9251085663, 166016.9705687058]
[2019-03-23 01:49:19,171] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:49:19,175] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.00000e+00 0.00000e+00 7.94113e-38 0.00000e+00 1.72745e-37], sampled 0.8327845467252764
[2019-03-23 01:49:19,176] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 735244.9251085663 W.
[2019-03-23 01:49:24,211] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.21556363], dtype=float32), -0.12538315]
[2019-03-23 01:49:24,212] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.64057002833334, 51.81130974166667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5831749610084912, 6.9112, 6.9112, 121.9260426156618, 435023.5738627877, 435023.5738627877, 130770.1066346185]
[2019-03-23 01:49:24,214] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:49:24,217] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9462875420804123
[2019-03-23 01:49:52,439] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21556363], dtype=float32), -0.12538315]
[2019-03-23 01:49:52,440] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8694299373129907, 6.9112, 6.9112, 121.9260426156618, 637255.9006640315, 637255.9006640315, 171721.9162657092]
[2019-03-23 01:49:52,442] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:49:52,447] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5292502681907892
[2019-03-23 01:49:57,523] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21556363], dtype=float32), -0.12538315]
[2019-03-23 01:49:57,526] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.5, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6434297828236937, 6.911199999999999, 6.9112, 121.9260426156618, 479461.7145841824, 479461.7145841828, 136113.2392587657]
[2019-03-23 01:49:57,528] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:49:57,533] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5634148913633091
[2019-03-23 01:50:01,533] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21556363], dtype=float32), -0.12538315]
[2019-03-23 01:50:01,534] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.33333333333333, 93.16666666666667, 1.0, 2.0, 0.784767601005829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 894469.4380812166, 894469.4380812166, 192820.997223883]
[2019-03-23 01:50:01,535] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:50:01,538] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.9621282e-28], sampled 0.0018300133188475787
[2019-03-23 01:50:01,540] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 894469.4380812166 W.
[2019-03-23 01:50:39,174] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21556363], dtype=float32), -0.12538315]
[2019-03-23 01:50:39,178] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.7, 43.0, 1.0, 2.0, 0.8887618542988387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.972649842010482, 6.9112, 121.9257811772168, 1139611.043544204, 1108143.299584757, 218875.6204430326]
[2019-03-23 01:50:39,179] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:50:39,180] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 2.2896144e-32 0.0000000e+00 2.5431598e-29], sampled 0.949845831801349
[2019-03-23 01:50:39,181] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1139611.043544204 W.
[2019-03-23 01:50:41,027] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7876.5266 2526116865.3439 706.0000
[2019-03-23 01:50:41,113] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8377.1670 2333239319.1178 558.0000
[2019-03-23 01:50:41,149] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8646.7107 2217656257.8659 525.0000
[2019-03-23 01:50:41,316] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8578.5148 2256916934.0198 512.0000
[2019-03-23 01:50:41,320] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8426.6630 2290094574.5810 638.0000
[2019-03-23 01:50:42,338] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1400000, evaluation results [1400000.0, 7876.526600266436, 2526116865.3439074, 706.0, 8578.514834768286, 2256916934.0197816, 512.0, 8646.710707904227, 2217656257.8658795, 525.0, 8377.166961965295, 2333239319.1177998, 558.0, 8426.662984337825, 2290094574.581001, 638.0]
[2019-03-23 01:50:44,401] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.2335844e-38], sum to 1.0000
[2019-03-23 01:50:44,410] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8422
[2019-03-23 01:50:44,417] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 769188.0557066656 W.
[2019-03-23 01:50:44,423] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 91.5, 1.0, 2.0, 0.3374532146873329, 1.0, 2.0, 0.3374532146873329, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769188.0557066656, 769188.0557066656, 189691.6744871228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4743000.0000, 
sim time next is 4743600.0000, 
raw observation next is [25.33333333333333, 92.33333333333334, 1.0, 2.0, 0.6754530220922546, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769811.3179742, 769811.3179742, 171547.8416599843], 
processed observation next is [1.0, 0.9130434782608695, 0.49382716049382697, 0.9233333333333335, 1.0, 1.0, 0.6136345501098268, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27493261356221427, 0.27493261356221427, 0.3298996954999698], 
reward next is 0.6701, 
noisyNet noise sample is [array([-0.2613469], dtype=float32), -0.72941065]. 
=============================================
[2019-03-23 01:50:45,867] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.2902636e-37 0.0000000e+00 2.6908153e-32], sum to 1.0000
[2019-03-23 01:50:45,876] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4531
[2019-03-23 01:50:45,887] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 762130.1607300069 W.
[2019-03-23 01:50:45,892] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.6, 89.66666666666667, 1.0, 2.0, 0.2229055923286105, 1.0, 2.0, 0.2229055923286105, 1.0, 1.0, 0.3548729625154761, 6.9112, 6.9112, 121.94756008, 762130.1607300069, 762130.1607300069, 228223.1322367488], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4994400.0000, 
sim time next is 4995000.0000, 
raw observation next is [25.4, 90.0, 1.0, 2.0, 0.3300919356996783, 1.0, 2.0, 0.3300919356996783, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 752400.5824014569, 752400.5824014574, 187838.9129108287], 
processed observation next is [1.0, 0.8260869565217391, 0.49629629629629624, 0.9, 1.0, 1.0, 0.2024903996424742, 1.0, 1.0, 0.2024903996424742, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26871449371480605, 0.2687144937148062, 0.36122867867467057], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9780187], dtype=float32), 1.3037367]. 
=============================================
[2019-03-23 01:50:45,904] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[37.222275]
 [37.506203]
 [37.483532]
 [37.237183]
 [37.324814]], R is [[36.8249054 ]
 [37.01776505]
 [37.28245544]
 [37.5430603 ]
 [37.80054855]].
[2019-03-23 01:50:45,945] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 4.3421121e-30 2.8017655e-24 0.0000000e+00 7.4347527e-21], sum to 1.0000
[2019-03-23 01:50:45,955] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1820
[2019-03-23 01:50:45,960] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 752400.5824014569 W.
[2019-03-23 01:50:45,967] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 90.0, 1.0, 2.0, 0.3300919356996783, 1.0, 2.0, 0.3300919356996783, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 752400.5824014569, 752400.5824014574, 187838.9129108287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4995000.0000, 
sim time next is 4995600.0000, 
raw observation next is [25.2, 90.33333333333334, 1.0, 2.0, 0.6511921809855625, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742147.9414791141, 742147.9414791141, 167107.9200216467], 
processed observation next is [1.0, 0.8260869565217391, 0.4888888888888889, 0.9033333333333334, 1.0, 1.0, 0.584752596411384, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2650528362425408, 0.2650528362425408, 0.3213613846570129], 
reward next is 0.6786, 
noisyNet noise sample is [array([0.66106254], dtype=float32), -2.2920995]. 
=============================================
[2019-03-23 01:50:46,257] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.5514108e-31 5.6079907e-17 9.2516758e-36 2.1993309e-14], sum to 1.0000
[2019-03-23 01:50:46,263] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2173
[2019-03-23 01:50:46,272] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1751880.135222731 W.
[2019-03-23 01:50:46,278] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.5, 87.66666666666667, 1.0, 2.0, 0.5120622837701333, 1.0, 2.0, 0.5120622837701333, 1.0, 2.0, 0.8152198324663732, 6.911199999999999, 6.9112, 121.94756008, 1751880.135222731, 1751880.135222732, 349548.8104126156], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4800000.0000, 
sim time next is 4800600.0000, 
raw observation next is [26.75, 87.0, 1.0, 2.0, 0.5458095229529798, 1.0, 2.0, 0.5458095229529798, 1.0, 2.0, 0.868946536316315, 6.9112, 6.9112, 121.94756008, 1867457.695664223, 1867457.695664223, 366641.4056063699], 
processed observation next is [1.0, 0.5652173913043478, 0.5462962962962963, 0.87, 1.0, 1.0, 0.45929705113449976, 1.0, 1.0, 0.45929705113449976, 1.0, 1.0, 0.8361831703953937, 0.0, 0.0, 0.8096049824067558, 0.6669491770229368, 0.6669491770229368, 0.705079626166096], 
reward next is 0.2949, 
noisyNet noise sample is [array([-0.6358884], dtype=float32), -0.16683315]. 
=============================================
[2019-03-23 01:50:54,921] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:50:54,925] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5619
[2019-03-23 01:50:54,935] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 687025.6677885713 W.
[2019-03-23 01:50:54,944] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 91.0, 1.0, 2.0, 0.3014236085184328, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4798762014429363, 6.911199999999999, 6.9112, 121.9260426156618, 687025.6677885713, 687025.6677885718, 195630.2061034984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5592000.0000, 
sim time next is 5592600.0000, 
raw observation next is [25.15, 91.0, 1.0, 2.0, 0.6021179822553758, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686194.2345030545, 686194.2345030545, 158442.8924369295], 
processed observation next is [1.0, 0.7391304347826086, 0.487037037037037, 0.91, 1.0, 1.0, 0.5263309312563997, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2450693694653766, 0.2450693694653766, 0.3046978700710183], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.98291326], dtype=float32), 0.4814121]. 
=============================================
[2019-03-23 01:51:02,661] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:51:02,663] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4202
[2019-03-23 01:51:02,670] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 761639.2330084594 W.
[2019-03-23 01:51:02,674] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.6682861769971913, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 761639.2330084594, 761639.2330084594, 170227.2367009749], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5043600.0000, 
sim time next is 5044200.0000, 
raw observation next is [26.33333333333334, 87.33333333333334, 1.0, 2.0, 0.3383649172684933, 1.0, 1.0, 0.3383649172684933, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 771267.2285145546, 771267.228514555, 189922.6877738646], 
processed observation next is [0.0, 0.391304347826087, 0.5308641975308644, 0.8733333333333334, 1.0, 1.0, 0.21233918722439682, 1.0, 0.5, 0.21233918722439682, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27545258161234093, 0.2754525816123411, 0.3652359380266627], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.0527146], dtype=float32), -0.564422]. 
=============================================
[2019-03-23 01:51:05,320] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:51:05,327] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5038
[2019-03-23 01:51:05,335] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 829306.5451103173 W.
[2019-03-23 01:51:05,340] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.85, 96.5, 1.0, 2.0, 0.727627498704909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 829306.5451103173, 829306.545110317, 181443.093493606], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5124600.0000, 
sim time next is 5125200.0000, 
raw observation next is [26.13333333333333, 95.33333333333334, 1.0, 2.0, 0.7367783672485311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 839741.87431603, 839741.87431603, 183226.9879036629], 
processed observation next is [0.0, 0.30434782608695654, 0.5234567901234567, 0.9533333333333335, 1.0, 1.0, 0.6866409133911084, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.299907812255725, 0.299907812255725, 0.3523595921224287], 
reward next is 0.6476, 
noisyNet noise sample is [array([-1.8516719], dtype=float32), -0.13510592]. 
=============================================
[2019-03-23 01:51:06,108] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:51:06,115] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8398
[2019-03-23 01:51:06,119] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.76666666666667, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7845723946742486, 6.9112, 6.9112, 121.9260426156618, 585735.2900268685, 585735.2900268685, 156154.8769956373], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5800800.0000, 
sim time next is 5801400.0000, 
raw observation next is [21.7, 90.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7669539703929102, 6.9112, 6.9112, 121.9260426156618, 572586.5997612883, 572586.5997612883, 154044.417050378], 
processed observation next is [1.0, 0.13043478260869565, 0.3592592592592592, 0.905, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7086924629911379, 0.0, 0.0, 0.8094621288201359, 0.2044952142004601, 0.2044952142004601, 0.29623926355841923], 
reward next is 0.7038, 
noisyNet noise sample is [array([1.0679212], dtype=float32), -0.12896976]. 
=============================================
[2019-03-23 01:51:06,221] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:51:06,230] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4380
[2019-03-23 01:51:06,235] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.56666666666667, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7486853013765797, 6.911200000000001, 6.9112, 121.9260426156618, 558960.1968251583, 558960.1968251579, 151876.8222797629], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5802600.0000, 
sim time next is 5803200.0000, 
raw observation next is [21.5, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7502922782445649, 6.9112, 6.9112, 121.9260426156618, 560169.4985570945, 560169.4985570945, 152050.7340453684], 
processed observation next is [1.0, 0.17391304347826086, 0.35185185185185186, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6878653478057062, 0.0, 0.0, 0.8094621288201359, 0.2000605351989623, 0.2000605351989623, 0.29240525777955456], 
reward next is 0.7076, 
noisyNet noise sample is [array([-1.3003566], dtype=float32), 0.9934751]. 
=============================================
[2019-03-23 01:51:06,394] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 8.637807e-34 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 01:51:06,404] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4617
[2019-03-23 01:51:06,413] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 905166.363229948 W.
[2019-03-23 01:51:06,418] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 94.0, 1.0, 2.0, 0.3970735335706838, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6321539972267023, 6.911199999999999, 6.9112, 121.9260426156618, 905166.363229948, 905166.3632299484, 223205.1955198046], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5130000.0000, 
sim time next is 5130600.0000, 
raw observation next is [27.33333333333333, 93.16666666666667, 1.0, 2.0, 0.3923838005029141, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6246877894488698, 6.9112, 6.9112, 121.9260426156618, 894469.4380812157, 894469.4380812157, 221768.5832616005], 
processed observation next is [0.0, 0.391304347826087, 0.5679012345679011, 0.9316666666666668, 1.0, 1.0, 0.2766473815510882, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5308597368110872, 0.0, 0.0, 0.8094621288201359, 0.31945337074329133, 0.31945337074329133, 0.4264780447338471], 
reward next is 0.5735, 
noisyNet noise sample is [array([1.3835437], dtype=float32), 1.2640872]. 
=============================================
[2019-03-23 01:51:06,890] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 7.1572709e-29 1.4683847e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 01:51:06,898] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9150
[2019-03-23 01:51:06,908] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 791980.1901135074 W.
[2019-03-23 01:51:06,914] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.83333333333334, 98.33333333333334, 1.0, 2.0, 0.2316315341052833, 1.0, 1.0, 0.2316315341052833, 1.0, 1.0, 0.3687649460080228, 6.9112, 6.9112, 121.94756008, 791980.1901135074, 791980.1901135074, 231206.4156030026], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5116200.0000, 
sim time next is 5116800.0000, 
raw observation next is [24.86666666666667, 98.66666666666667, 1.0, 2.0, 0.3486320411987419, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5550335637413042, 6.9112, 6.9112, 121.9260426156618, 794682.1889868211, 794682.1889868211, 208779.7120355274], 
processed observation next is [0.0, 0.21739130434782608, 0.47654320987654336, 0.9866666666666667, 1.0, 1.0, 0.2245619538080261, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.4437919546766302, 0.0, 0.0, 0.8094621288201359, 0.2838150674952932, 0.2838150674952932, 0.40149944622216804], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6797959], dtype=float32), 0.17424202]. 
=============================================
[2019-03-23 01:51:07,752] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 3.6200160e-33 1.0170239e-29 1.8697375e-36], sum to 1.0000
[2019-03-23 01:51:07,761] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1548
[2019-03-23 01:51:07,769] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 738676.7445990895 W.
[2019-03-23 01:51:07,772] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.33333333333334, 87.33333333333334, 1.0, 2.0, 0.2160493090182401, 1.0, 2.0, 0.2160493090182401, 1.0, 2.0, 0.3439575361918079, 6.9112, 6.9112, 121.94756008, 738676.7445990895, 738676.7445990895, 225908.9356964308], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5178000.0000, 
sim time next is 5178600.0000, 
raw observation next is [25.2, 87.5, 1.0, 2.0, 0.2147504352582471, 1.0, 2.0, 0.2147504352582471, 1.0, 2.0, 0.3418896868645339, 6.911200000000001, 6.9112, 121.94756008, 734233.7437485808, 734233.7437485803, 225473.490596911], 
processed observation next is [0.0, 0.9565217391304348, 0.4888888888888889, 0.875, 1.0, 1.0, 0.06517908959315132, 1.0, 1.0, 0.06517908959315132, 1.0, 1.0, 0.17736210858066737, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2622263370530646, 0.2622263370530644, 0.43360286653252117], 
reward next is 0.5664, 
noisyNet noise sample is [array([-1.838577], dtype=float32), -1.1318473]. 
=============================================
[2019-03-23 01:51:08,255] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.9835622e-38], sum to 1.0000
[2019-03-23 01:51:08,263] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5551
[2019-03-23 01:51:08,270] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 830576.2837772614 W.
[2019-03-23 01:51:08,276] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 81.0, 1.0, 2.0, 0.3643704774092111, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5800896667534546, 6.911199999999999, 6.9112, 121.9260426156618, 830576.2837772614, 830576.2837772619, 213364.0556254929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5167200.0000, 
sim time next is 5167800.0000, 
raw observation next is [27.9, 82.0, 1.0, 2.0, 0.7406873351681603, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 844199.5673995045, 844199.5673995045, 183992.3019986841], 
processed observation next is [0.0, 0.8260869565217391, 0.5888888888888888, 0.82, 1.0, 1.0, 0.6912944466287623, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.301499845499823, 0.301499845499823, 0.3538313499974694], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.20043397], dtype=float32), -1.3770982]. 
=============================================
[2019-03-23 01:51:08,924] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.0858544e-37 0.0000000e+00 2.0802827e-34], sum to 1.0000
[2019-03-23 01:51:08,928] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1311
[2019-03-23 01:51:08,936] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 769341.8530389293 W.
[2019-03-23 01:51:08,944] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3375206538152269, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5373438731541249, 6.911199999999999, 6.9112, 121.9260426156618, 769341.8530389293, 769341.8530389298, 205603.5094520619], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5186400.0000, 
sim time next is 5187000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3374247315256905, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5371911617452121, 6.911199999999999, 6.9112, 121.9260426156618, 769123.0988516951, 769123.0988516955, 205576.2487138937], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.21121991848296492, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.42148895218151505, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27468682101846253, 0.2746868210184627, 0.395338939834411], 
reward next is 0.6047, 
noisyNet noise sample is [array([-0.11984956], dtype=float32), 0.97446513]. 
=============================================
[2019-03-23 01:51:08,955] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[26.65191 ]
 [26.926027]
 [27.018282]
 [27.23776 ]
 [27.868395]], R is [[27.17880821]
 [26.90702057]
 [27.30825424]
 [27.64010429]
 [27.36370277]].
[2019-03-23 01:51:10,303] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9999940e-01 4.6574545e-33 1.0048638e-22 1.1255251e-18 6.5454520e-07], sum to 1.0000
[2019-03-23 01:51:10,310] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3485
[2019-03-23 01:51:10,315] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1050948.680750285 W.
[2019-03-23 01:51:10,319] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.3073205152045962, 1.0, 1.0, 0.3073205152045962, 1.0, 1.0, 0.4892642689361515, 6.911199999999999, 6.9112, 121.94756008, 1050948.680750285, 1050948.680750286, 258867.5389762969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5197200.0000, 
sim time next is 5197800.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.902454835918967, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1033229.497713951, 1033229.497713951, 218260.8791360474], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.8838748046654369, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.36901053489783964, 0.36901053489783964, 0.41973245987701424], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1465691], dtype=float32), -0.68598855]. 
=============================================
[2019-03-23 01:51:10,327] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:51:10,333] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2658
[2019-03-23 01:51:10,338] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.86666666666667, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.671933051042869, 6.9112, 6.9112, 121.9260426156618, 497637.2953880061, 497637.2953880061, 136654.3298328603], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5883600.0000, 
sim time next is 5884200.0000, 
raw observation next is [19.8, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6073533600549523, 6.9112, 6.9112, 121.9260426156618, 449493.3936937976, 449493.3936937976, 130221.6177659613], 
processed observation next is [1.0, 0.08695652173913043, 0.2888888888888889, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5091917000686904, 0.0, 0.0, 0.8094621288201359, 0.160533354890642, 0.160533354890642, 0.25042618801146405], 
reward next is 0.7496, 
noisyNet noise sample is [array([1.2222736], dtype=float32), 1.3975272]. 
=============================================
[2019-03-23 01:51:15,491] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.1244103e-27], sum to 1.0000
[2019-03-23 01:51:15,501] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5891
[2019-03-23 01:51:15,511] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 848400.0260319511 W.
[2019-03-23 01:51:15,515] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.85, 84.5, 1.0, 2.0, 0.7310138901438108, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 848400.0260319511, 848400.0260319506, 182855.3889961193], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5283000.0000, 
sim time next is 5283600.0000, 
raw observation next is [24.76666666666667, 84.66666666666667, 1.0, 2.0, 0.2371748267796562, 1.0, 1.0, 0.2371748267796562, 1.0, 1.0, 0.3776185102803977, 6.911199999999999, 6.9112, 121.94756008, 812221.9335843371, 812221.9335843376, 233129.6817784925], 
processed observation next is [1.0, 0.13043478260869565, 0.4728395061728396, 0.8466666666666667, 1.0, 1.0, 0.09187479378530501, 1.0, 0.5, 0.09187479378530501, 1.0, 0.5, 0.22202313785049713, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2900792619944061, 0.29007926199440626, 0.44832631111248555], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5644489], dtype=float32), -0.63287216]. 
=============================================
[2019-03-23 01:51:19,415] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:51:19,421] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4600
[2019-03-23 01:51:19,429] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.5, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9332701388575831, 6.9112, 6.9112, 121.9260426156618, 678271.6411749079, 678271.6411749079, 181261.7709783288], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5631600.0000, 
sim time next is 5632200.0000, 
raw observation next is [23.5, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9317742918926277, 6.9112, 6.9112, 121.9260426156618, 677184.0883335762, 677184.0883335762, 181057.1023545301], 
processed observation next is [0.0, 0.17391304347826086, 0.42592592592592593, 0.97, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9147178648657847, 0.0, 0.0, 0.8094621288201359, 0.24185146011913436, 0.24185146011913436, 0.34818673529717326], 
reward next is 0.6518, 
noisyNet noise sample is [array([-0.250801], dtype=float32), -0.04475807]. 
=============================================
[2019-03-23 01:51:19,444] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 8.1596807e-30 3.2248854e-17 1.7442027e-37 1.8166502e-19], sum to 1.0000
[2019-03-23 01:51:19,455] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3612
[2019-03-23 01:51:19,465] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1169629.738503027 W.
[2019-03-23 01:51:19,470] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.65, 84.0, 1.0, 2.0, 0.9790646989863638, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.015678948510286, 6.9112, 121.9255959868859, 1169629.738503027, 1116127.374629188, 235706.2787691594], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5560200.0000, 
sim time next is 5560800.0000, 
raw observation next is [25.73333333333333, 83.66666666666666, 1.0, 2.0, 0.6155507456256712, 1.0, 1.0, 0.6155507456256712, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9259797003447, 1403661.904390015, 1403661.904390015, 273430.7413499086], 
processed observation next is [1.0, 0.34782608695652173, 0.5086419753086419, 0.8366666666666666, 1.0, 1.0, 0.5423223162210372, 1.0, 0.5, 0.5423223162210372, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094617111278577, 0.501307822996434, 0.501307822996434, 0.5258283487498242], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16733691], dtype=float32), 0.0082399575]. 
=============================================
[2019-03-23 01:51:21,167] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.8769642e-31 4.6949928e-24 3.4999833e-11 1.7030419e-10], sum to 1.0000
[2019-03-23 01:51:21,172] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9240
[2019-03-23 01:51:21,179] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1758477.843682373 W.
[2019-03-23 01:51:21,186] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333334, 79.33333333333334, 1.0, 2.0, 0.5139888517391284, 1.0, 2.0, 0.5139888517391284, 1.0, 2.0, 0.8182869914169519, 6.911199999999999, 6.9112, 121.94756008, 1758477.843682373, 1758477.843682373, 350507.9996128613], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5394000.0000, 
sim time next is 5394600.0000, 
raw observation next is [27.5, 78.5, 1.0, 2.0, 0.7585121053901102, 1.0, 2.0, 0.7585121053901102, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1730006.04017544, 1730006.040175441, 326909.0813552795], 
processed observation next is [1.0, 0.43478260869565216, 0.5740740740740741, 0.785, 1.0, 1.0, 0.7125144111787025, 1.0, 1.0, 0.7125144111787025, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6178593000626571, 0.6178593000626574, 0.6286713102986144], 
reward next is 0.3713, 
noisyNet noise sample is [array([0.14253034], dtype=float32), 0.2639563]. 
=============================================
[2019-03-23 01:51:25,177] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:51:25,186] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4069
[2019-03-23 01:51:25,195] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1152760.264514826 W.
[2019-03-23 01:51:25,200] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.2, 94.00000000000001, 1.0, 2.0, 0.5056050620685576, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8049397252204356, 6.911199999999999, 6.9112, 121.9260426156618, 1152760.264514826, 1152760.264514826, 258934.2889695283], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5454600.0000, 
sim time next is 5455200.0000, 
raw observation next is [26.2, 94.0, 1.0, 2.0, 0.4280662200794914, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6814953635100564, 6.911199999999999, 6.9112, 121.9260426156618, 975862.0827153341, 975862.0827153346, 232923.4560656112], 
processed observation next is [1.0, 0.13043478260869565, 0.5259259259259259, 0.94, 1.0, 1.0, 0.3191264524755851, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6018692043875704, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3485221723983336, 0.3485221723983338, 0.44792972320309843], 
reward next is 0.5521, 
noisyNet noise sample is [array([-1.9823301], dtype=float32), 2.173054]. 
=============================================
[2019-03-23 01:51:25,849] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.1863426e-38 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 01:51:25,858] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6314
[2019-03-23 01:51:25,867] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 853624.7008561962 W.
[2019-03-23 01:51:25,871] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.95, 90.33333333333333, 1.0, 2.0, 0.3744760977399391, 1.0, 2.0, 0.3744760977399391, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 853624.7008561962, 853624.7008561967, 199294.6983047535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5443800.0000, 
sim time next is 5444400.0000, 
raw observation next is [26.9, 90.66666666666667, 1.0, 2.0, 0.748240396223749, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 852812.9701761263, 852812.9701761263, 185481.6825828658], 
processed observation next is [1.0, 0.0, 0.5518518518518518, 0.9066666666666667, 1.0, 1.0, 0.7002861859806536, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30457606077718796, 0.30457606077718796, 0.35669554342858806], 
reward next is 0.6433, 
noisyNet noise sample is [array([-0.6888881], dtype=float32), 1.1756955]. 
=============================================
[2019-03-23 01:51:28,525] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:51:28,533] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0829
[2019-03-23 01:51:28,544] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 727871.5878061143 W.
[2019-03-23 01:51:28,549] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.91666666666667, 81.0, 1.0, 2.0, 0.2128904996155617, 1.0, 1.0, 0.2128904996155617, 1.0, 2.0, 0.3389286087475037, 6.911199999999999, 6.9112, 121.94756008, 727871.5878061143, 727871.5878061148, 224851.5941243818], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5507400.0000, 
sim time next is 5508000.0000, 
raw observation next is [26.9, 81.0, 1.0, 2.0, 0.3218541292118418, 1.0, 2.0, 0.3218541292118418, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 733614.6149344357, 733614.6149344362, 185788.228818108], 
processed observation next is [1.0, 0.782608695652174, 0.5518518518518518, 0.81, 1.0, 1.0, 0.19268348715695455, 1.0, 1.0, 0.19268348715695455, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26200521961944134, 0.2620052196194415, 0.3572850554194385], 
reward next is 0.6427, 
noisyNet noise sample is [array([-0.99062043], dtype=float32), -0.5462325]. 
=============================================
[2019-03-23 01:51:28,563] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[40.127712]
 [40.138985]
 [39.468098]
 [38.885887]
 [37.914978]], R is [[40.32381058]
 [39.92057419]
 [40.13790512]
 [40.30718994]
 [40.47306824]].
[2019-03-23 01:51:30,419] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:51:30,427] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4536
[2019-03-23 01:51:30,437] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1384939.743048194 W.
[2019-03-23 01:51:30,441] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.71666666666667, 79.33333333333334, 1.0, 2.0, 0.6073478945005766, 1.0, 2.0, 0.6073478945005766, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1384939.743048194, 1384939.743048195, 270577.3873391736], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5568600.0000, 
sim time next is 5569200.0000, 
raw observation next is [26.8, 79.0, 1.0, 2.0, 0.6726669931245092, 1.0, 2.0, 0.6726669931245092, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1534036.531085233, 1534036.531085234, 293946.9312364421], 
processed observation next is [1.0, 0.4782608695652174, 0.5481481481481482, 0.79, 1.0, 1.0, 0.610317848957749, 1.0, 1.0, 0.610317848957749, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5478701896732975, 0.5478701896732978, 0.565282560070081], 
reward next is 0.4347, 
noisyNet noise sample is [array([-0.9810441], dtype=float32), -0.19527805]. 
=============================================
[2019-03-23 01:51:36,023] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:51:36,034] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9898
[2019-03-23 01:51:36,043] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 745952.7164325976 W.
[2019-03-23 01:51:36,051] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.51666666666667, 95.66666666666666, 1.0, 2.0, 0.3272645143956351, 1.0, 2.0, 0.3272645143956351, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745952.7164325976, 745952.7164325976, 187132.2477809986], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5608200.0000, 
sim time next is 5608800.0000, 
raw observation next is [24.4, 96.0, 1.0, 2.0, 0.3251402906803709, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5176339318431559, 6.911199999999999, 6.9112, 121.9260426156618, 741108.5112555813, 741108.5112555816, 202123.3201714072], 
processed observation next is [1.0, 0.9565217391304348, 0.4592592592592592, 0.96, 1.0, 1.0, 0.19659558414329872, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.3970424148039448, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2646816111627076, 0.2646816111627077, 0.38869869263732154], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.02238303], dtype=float32), 0.7505691]. 
=============================================
[2019-03-23 01:51:36,112] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 01:51:36,115] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:51:36,116] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:51:36,116] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:51:36,117] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:51:36,117] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:51:36,120] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:51:36,118] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:51:36,119] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:51:36,121] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:51:36,123] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:51:36,157] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run58
[2019-03-23 01:51:36,183] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run58
[2019-03-23 01:51:36,206] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run58
[2019-03-23 01:51:36,207] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run58
[2019-03-23 01:51:36,208] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run58
[2019-03-23 01:52:04,540] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.2015906], dtype=float32), -0.0926202]
[2019-03-23 01:52:04,540] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.48333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6700497137596068, 6.911200000000001, 6.9112, 121.9260426156618, 500514.6344258654, 500514.634425865, 140566.5897577401]
[2019-03-23 01:52:04,541] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:52:04,545] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5574613919103151
[2019-03-23 01:52:47,815] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.2015906], dtype=float32), -0.0926202]
[2019-03-23 01:52:47,817] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.75216881, 74.23014898, 1.0, 2.0, 0.57476027749844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 675284.9455901738, 675284.9455901738, 154723.912465672]
[2019-03-23 01:52:47,818] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:52:47,820] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.40983521398844436
[2019-03-23 01:53:02,287] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.2015906], dtype=float32), -0.0926202]
[2019-03-23 01:53:02,288] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.46666666666667, 88.0, 1.0, 2.0, 0.5875926383373867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 680445.7219716633, 680445.7219716633, 156475.150120633]
[2019-03-23 01:53:02,290] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:53:02,294] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8695716482872631
[2019-03-23 01:53:05,843] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.2015906], dtype=float32), -0.0926202]
[2019-03-23 01:53:05,845] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.89672991833334, 68.15985296666668, 1.0, 2.0, 0.8402471022344682, 1.0, 2.0, 0.8402471022344682, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260424316144, 1916626.328347605, 1916626.328347605, 360667.1344301988]
[2019-03-23 01:53:05,846] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:53:05,850] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8670880123640883
[2019-03-23 01:53:05,853] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1916626.328347605 W.
[2019-03-23 01:53:05,908] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.2015906], dtype=float32), -0.0926202]
[2019-03-23 01:53:05,910] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.0, 70.0, 1.0, 2.0, 0.6341864779683021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 724157.1003954499, 724157.1003954499, 164127.4362962184]
[2019-03-23 01:53:05,911] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:53:05,914] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6596448439209023
[2019-03-23 01:53:05,916] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 724157.1003954499 W.
[2019-03-23 01:53:14,119] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.2015906], dtype=float32), -0.0926202]
[2019-03-23 01:53:14,121] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.94947602, 70.93195215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7229584976050676, 6.9112, 6.9112, 121.9260426156618, 540200.5777550047, 540200.5777550047, 147920.4800561844]
[2019-03-23 01:53:14,122] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:53:14,125] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7048645093730868
[2019-03-23 01:53:26,222] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.7427 2219188629.1108 543.0000
[2019-03-23 01:53:26,557] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8362.6190 2339479169.9832 616.0000
[2019-03-23 01:53:26,676] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.2402 2292979445.9673 697.0000
[2019-03-23 01:53:26,686] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8558.6925 2258281932.5947 536.0000
[2019-03-23 01:53:26,754] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.4519 2529808370.8593 831.0000
[2019-03-23 01:53:27,771] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1425000, evaluation results [1425000.0, 7841.4518751717205, 2529808370.8593388, 831.0, 8558.692516993873, 2258281932.5946884, 536.0, 8633.742656024266, 2219188629.1107655, 543.0, 8362.61897530337, 2339479169.983213, 616.0, 8404.240247944708, 2292979445.967258, 697.0]
[2019-03-23 01:53:36,360] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:53:36,372] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4171
[2019-03-23 01:53:36,377] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.66666666666667, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.588116895777915, 6.911200000000001, 6.9112, 121.9260426156618, 434646.0116415973, 434646.0116415969, 128077.5562056399], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5885400.0000, 
sim time next is 5886000.0000, 
raw observation next is [19.6, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5846582013413517, 6.911200000000001, 6.9112, 121.9260426156618, 431777.2474732111, 431777.2474732107, 127585.0974123476], 
processed observation next is [1.0, 0.13043478260869565, 0.28148148148148155, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4808227516766896, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15420615981186112, 0.15420615981186095, 0.24535595656220693], 
reward next is 0.7546, 
noisyNet noise sample is [array([0.32750624], dtype=float32), -0.2018194]. 
=============================================
[2019-03-23 01:53:36,396] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[71.371704]
 [71.44836 ]
 [71.52719 ]
 [71.347855]
 [70.80354 ]], R is [[71.40679169]
 [71.44642639]
 [71.48413849]
 [71.51886749]
 [71.54088593]].
[2019-03-23 01:53:37,827] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:53:37,833] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8472
[2019-03-23 01:53:37,839] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.2, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7275738122084495, 6.911200000000001, 6.9112, 121.9260426156618, 543100.8865050849, 543100.8865050845, 149568.3408613119], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5806800.0000, 
sim time next is 5807400.0000, 
raw observation next is [21.33333333333334, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8941397915910094, 6.9112, 6.9112, 121.9260426156618, 667457.4028083998, 667457.4028083998, 169661.9231578297], 
processed observation next is [1.0, 0.21739130434782608, 0.3456790123456792, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8676747394887618, 0.0, 0.0, 0.8094621288201359, 0.23837764386014276, 0.23837764386014276, 0.3262729291496725], 
reward next is 0.6737, 
noisyNet noise sample is [array([0.9628224], dtype=float32), -0.0008778165]. 
=============================================
[2019-03-23 01:53:44,607] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:53:44,613] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2564
[2019-03-23 01:53:44,617] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.7, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7789055737811301, 6.911200000000001, 6.9112, 121.9260426156618, 580029.876305445, 580029.8763054445, 156864.0538228249], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5958000.0000, 
sim time next is 5958600.0000, 
raw observation next is [22.68333333333333, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7752494700025312, 6.911200000000001, 6.9112, 121.9260426156618, 577486.6641014894, 577486.6641014889, 156293.5247110492], 
processed observation next is [1.0, 1.0, 0.39567901234567887, 0.865, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.719061837503164, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20624523717910334, 0.20624523717910317, 0.30056447059817154], 
reward next is 0.6994, 
noisyNet noise sample is [array([-0.39952788], dtype=float32), 0.54613906]. 
=============================================
[2019-03-23 01:53:46,423] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:53:46,432] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9318
[2019-03-23 01:53:46,439] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.1, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7783348354530428, 6.9112, 6.9112, 121.9260426156618, 579615.5525728362, 579615.5525728362, 156787.3850999702], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5956800.0000, 
sim time next is 5957400.0000, 
raw observation next is [22.9, 85.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7779921128531397, 6.9112, 6.9112, 121.9260426156618, 579348.8693811824, 579348.8693811824, 156753.7313164827], 
processed observation next is [1.0, 0.9565217391304348, 0.4037037037037037, 0.855, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7224901410664247, 0.0, 0.0, 0.8094621288201359, 0.2069103104932794, 0.2069103104932794, 0.3014494833009283], 
reward next is 0.6986, 
noisyNet noise sample is [array([0.09957708], dtype=float32), 0.95097154]. 
=============================================
[2019-03-23 01:53:49,961] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.5428323e-31], sum to 1.0000
[2019-03-23 01:53:49,966] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4827
[2019-03-23 01:53:49,972] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.31666666666666, 86.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8102115818987297, 6.9112, 6.9112, 121.9260426156618, 601111.1817791744, 601111.1817791744, 161927.2935096325], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6051000.0000, 
sim time next is 6051600.0000, 
raw observation next is [23.2, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8094703724735696, 6.911199999999999, 6.9112, 121.9260426156618, 600587.236346951, 600587.2363469515, 161822.4290058094], 
processed observation next is [1.0, 0.043478260869565216, 0.4148148148148148, 0.87, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7618379655919618, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21449544155248249, 0.21449544155248265, 0.3111969788573257], 
reward next is 0.6888, 
noisyNet noise sample is [array([-0.1404858], dtype=float32), -0.78655696]. 
=============================================
[2019-03-23 01:53:53,519] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.1476868e-33 8.4099485e-34 5.0621515e-38], sum to 1.0000
[2019-03-23 01:53:53,528] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2697
[2019-03-23 01:53:53,534] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.15, 71.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8621546742579433, 6.9112, 6.9112, 121.9260426156618, 635369.0226849256, 635369.0226849256, 169927.8462655151], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6129000.0000, 
sim time next is 6129600.0000, 
raw observation next is [26.06666666666667, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8615550292078443, 6.911200000000001, 6.9112, 121.9260426156618, 634940.2816062727, 634940.2816062722, 169847.2564729814], 
processed observation next is [1.0, 0.9565217391304348, 0.5209876543209878, 0.72, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8269437865098053, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22676438628795453, 0.22676438628795437, 0.32662933937111804], 
reward next is 0.6734, 
noisyNet noise sample is [array([-1.6033194], dtype=float32), 1.3027942]. 
=============================================
[2019-03-23 01:53:58,266] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.8345781e-24 8.6208765e-29 2.9296554e-18], sum to 1.0000
[2019-03-23 01:53:58,276] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1348
[2019-03-23 01:53:58,284] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1552072.443796224 W.
[2019-03-23 01:53:58,291] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.85, 69.5, 1.0, 2.0, 0.4537118407629625, 1.0, 2.0, 0.4537118407629625, 1.0, 2.0, 0.7223240268576984, 6.9112, 6.9112, 121.94756008, 1552072.443796224, 1552072.443796224, 321409.4933047235], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6172200.0000, 
sim time next is 6172800.0000, 
raw observation next is [27.03333333333333, 68.66666666666667, 1.0, 2.0, 0.4341723852278389, 1.0, 2.0, 0.4341723852278389, 1.0, 2.0, 0.6912165772901411, 6.9112, 6.9112, 121.94756008, 1485166.422537205, 1485166.422537205, 312374.9049449181], 
processed observation next is [1.0, 0.43478260869565216, 0.55679012345679, 0.6866666666666668, 1.0, 1.0, 0.3263956966998083, 1.0, 1.0, 0.3263956966998083, 1.0, 1.0, 0.6140207216126763, 0.0, 0.0, 0.8096049824067558, 0.5304165794775733, 0.5304165794775733, 0.6007209710479194], 
reward next is 0.3993, 
noisyNet noise sample is [array([0.14210054], dtype=float32), 0.7184422]. 
=============================================
[2019-03-23 01:53:59,774] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:53:59,785] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4666
[2019-03-23 01:53:59,789] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.75, 65.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8944427867286469, 6.911200000000001, 6.9112, 121.9260426156618, 654409.3496968211, 654409.3496968206, 175246.0580369054], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6207000.0000, 
sim time next is 6207600.0000, 
raw observation next is [27.6, 65.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8888186783994969, 6.9112, 6.9112, 121.9260426156618, 651059.150198973, 651059.150198973, 174345.011793545], 
processed observation next is [1.0, 0.8695652173913043, 0.5777777777777778, 0.6566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8610233479993712, 0.0, 0.0, 0.8094621288201359, 0.2325211250710618, 0.2325211250710618, 0.3352788688337404], 
reward next is 0.6647, 
noisyNet noise sample is [array([-1.3964579], dtype=float32), -0.83372545]. 
=============================================
[2019-03-23 01:54:04,749] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9999964e-01 3.1340974e-30 3.2694185e-22 3.2729034e-07 9.1145477e-17], sum to 1.0000
[2019-03-23 01:54:04,756] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6936
[2019-03-23 01:54:04,769] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2226142.202879309 W.
[2019-03-23 01:54:04,774] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.3, 80.5, 1.0, 2.0, 0.9757696239177076, 1.0, 1.0, 0.9757696239177076, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9255446578474, 2226142.202879309, 2226142.202879309, 421738.9007893077], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6517800.0000, 
sim time next is 6518400.0000, 
raw observation next is [28.43333333333333, 80.0, 1.0, 2.0, 0.6391836881060236, 1.0, 2.0, 0.6329565060294465, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2165987.912932219, 2165987.912932219, 413297.5043817362], 
processed observation next is [1.0, 0.43478260869565216, 0.6086419753086418, 0.8, 1.0, 1.0, 0.5704567715547899, 1.0, 1.0, 0.5630434595588649, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.7735671117615068, 0.7735671117615068, 0.7948028930418004], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13268146], dtype=float32), -0.8269762]. 
=============================================
[2019-03-23 01:54:09,307] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:54:09,315] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7740
[2019-03-23 01:54:09,322] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 690047.9207745775 W.
[2019-03-23 01:54:09,326] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.26666666666667, 56.0, 1.0, 2.0, 0.201832673574499, 1.0, 2.0, 0.201832673574499, 1.0, 1.0, 0.3213241895618797, 6.911199999999999, 6.9112, 121.94756008, 690047.9207745775, 690047.9207745779, 221194.2193349007], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6456000.0000, 
sim time next is 6456600.0000, 
raw observation next is [31.2, 56.5, 1.0, 2.0, 0.1996776534507798, 1.0, 2.0, 0.1996776534507798, 1.0, 2.0, 0.317893327340813, 6.911200000000001, 6.9112, 121.94756008, 682676.8189885836, 682676.8189885832, 220489.4160244323], 
processed observation next is [1.0, 0.7391304347826086, 0.7111111111111111, 0.565, 1.0, 1.0, 0.047235301727118824, 1.0, 1.0, 0.047235301727118824, 1.0, 1.0, 0.1473666591760162, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.24381314963877987, 0.2438131496387797, 0.42401810773929294], 
reward next is 0.5760, 
noisyNet noise sample is [array([-1.125472], dtype=float32), -0.013474079]. 
=============================================
[2019-03-23 01:54:15,463] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9887842e-01 0.0000000e+00 2.8959694e-29 0.0000000e+00 1.1216118e-03], sum to 1.0000
[2019-03-23 01:54:15,471] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0309
[2019-03-23 01:54:15,480] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1118315.035092918 W.
[2019-03-23 01:54:15,488] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.46666666666667, 84.33333333333333, 1.0, 2.0, 0.4905082708207099, 1.0, 2.0, 0.4905082708207099, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1118315.035092918, 1118315.035092919, 232463.096584404], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6495000.0000, 
sim time next is 6495600.0000, 
raw observation next is [26.43333333333333, 84.66666666666667, 1.0, 2.0, 0.4994991187319561, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7952188645718744, 6.9112, 6.9112, 121.9260426156618, 1138828.599743898, 1138828.599743898, 256795.1008220427], 
processed observation next is [1.0, 0.17391304347826086, 0.5345679012345678, 0.8466666666666667, 1.0, 1.0, 0.40416561753804303, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.7440235807148429, 0.0, 0.0, 0.8094621288201359, 0.406724499908535, 0.406724499908535, 0.49383673235008213], 
reward next is 0.5062, 
noisyNet noise sample is [array([1.5772423], dtype=float32), 0.46141544]. 
=============================================
[2019-03-23 01:54:16,758] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.6102158e-04 0.0000000e+00 7.3675014e-21 1.7841467e-32 9.9903905e-01], sum to 1.0000
[2019-03-23 01:54:16,767] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1792
[2019-03-23 01:54:16,772] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.43333333333333, 80.0, 1.0, 2.0, 0.6353942702590416, 1.0, 2.0, 0.6310617971059556, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2159496.347381277, 2159496.347381277, 412330.5988920451], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6518400.0000, 
sim time next is 6519000.0000, 
raw observation next is [28.56666666666667, 79.5, 1.0, 2.0, 0.6506258474225576, 1.0, 2.0, 0.6386775856877135, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2185589.502257521, 2185589.502257522, 416235.917749665], 
processed observation next is [1.0, 0.43478260869565216, 0.6135802469135804, 0.795, 1.0, 1.0, 0.584078389788759, 1.0, 1.0, 0.5698542686758494, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.780567679377686, 0.7805676793776865, 0.800453687980125], 
reward next is 0.1995, 
noisyNet noise sample is [array([-2.041965], dtype=float32), -2.717439]. 
=============================================
[2019-03-23 01:54:16,795] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[34.346764]
 [33.52001 ]
 [34.177982]
 [33.39564 ]
 [32.296593]], R is [[34.9810791 ]
 [34.63126755]
 [34.50837708]
 [34.41710663]
 [34.33629608]].
[2019-03-23 01:54:19,391] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.4833190e-29 0.0000000e+00 5.2082875e-08], sum to 1.0000
[2019-03-23 01:54:19,398] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5601
[2019-03-23 01:54:19,407] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 730887.2020936813 W.
[2019-03-23 01:54:19,412] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.26666666666667, 81.66666666666667, 1.0, 2.0, 0.2137720971101778, 1.0, 1.0, 0.2137720971101778, 1.0, 2.0, 0.3403321406705585, 6.911200000000001, 6.9112, 121.94756008, 730887.2020936813, 730887.2020936809, 225146.1277417755], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6561600.0000, 
sim time next is 6562200.0000, 
raw observation next is [26.23333333333333, 81.33333333333333, 1.0, 2.0, 0.317874431469329, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5060664473466628, 6.911199999999999, 6.9112, 121.9260426156618, 724539.2483600755, 724539.248360076, 200109.5748195135], 
processed observation next is [1.0, 0.9565217391304348, 0.5271604938271603, 0.8133333333333332, 1.0, 1.0, 0.18794575174920117, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.3825830591833285, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25876401727145554, 0.2587640172714557, 0.38482610542214135], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.37954143], dtype=float32), 0.33565137]. 
=============================================
[2019-03-23 01:54:21,443] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 01:54:21,444] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:54:21,445] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:54:21,446] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:54:21,446] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:54:21,448] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:54:21,449] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:54:21,449] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:54:21,449] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:54:21,452] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:54:21,452] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:54:21,481] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run59
[2019-03-23 01:54:21,508] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run59
[2019-03-23 01:54:21,509] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run59
[2019-03-23 01:54:21,557] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run59
[2019-03-23 01:54:21,558] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run59
[2019-03-23 01:54:30,087] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.12368826], dtype=float32), -0.022007963]
[2019-03-23 01:54:30,088] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.01666666666667, 34.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.567650579433901, 6.9112, 6.9112, 121.9260426156618, 420117.4334875763, 420117.4334875763, 126578.2687741242]
[2019-03-23 01:54:30,090] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:54:30,092] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.29700464175070296
[2019-03-23 01:54:39,466] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.12368826], dtype=float32), -0.022007963]
[2019-03-23 01:54:39,467] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.20351142, 70.67440330333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4013638353406576, 6.9112, 6.9112, 121.9260426156618, 286564.5091858267, 286564.5091858267, 95094.16490441693]
[2019-03-23 01:54:39,468] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:54:39,473] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7665102017960195
[2019-03-23 01:54:56,583] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.12368826], dtype=float32), -0.022007963]
[2019-03-23 01:54:56,584] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.7, 41.5, 1.0, 1.0, 0.8120313595416213, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.925726445972, 1017717.465684638, 1017717.465684638, 202011.2057629502]
[2019-03-23 01:54:56,584] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:54:56,587] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.4689087e-36], sampled 0.07281110892940545
[2019-03-23 01:54:56,590] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1017717.465684638 W.
[2019-03-23 01:55:08,238] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.12368826], dtype=float32), -0.022007963]
[2019-03-23 01:55:08,240] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.85, 71.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7488715285240836, 6.9112, 6.9112, 121.9260426156618, 558298.4220642709, 558298.4220642709, 152773.0104855608]
[2019-03-23 01:55:08,241] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:55:08,244] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3122884550877396
[2019-03-23 01:55:39,713] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.12368826], dtype=float32), -0.022007963]
[2019-03-23 01:55:39,714] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.0, 84.0, 1.0, 2.0, 0.3854790435843486, 1.0, 2.0, 0.3854790435843486, 1.0, 2.0, 0.6136951915622798, 6.9112, 6.9112, 121.94756008, 1318458.554892186, 1318458.554892186, 290779.5920594666]
[2019-03-23 01:55:39,715] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:55:39,719] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.8285264e-01 0.0000000e+00 1.3215466e-26 6.2708174e-30 1.7147303e-02], sampled 0.12129023594244182
[2019-03-23 01:55:39,720] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1318458.554892186 W.
[2019-03-23 01:55:58,051] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.12368826], dtype=float32), -0.022007963]
[2019-03-23 01:55:58,054] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.83333333333334, 59.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8698859786312513, 6.911199999999999, 6.9112, 121.9260426156618, 637471.487934525, 637471.4879345254, 171806.8003167289]
[2019-03-23 01:55:58,055] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:55:58,060] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7602797836492959
[2019-03-23 01:56:01,464] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.12368826], dtype=float32), -0.022007963]
[2019-03-23 01:56:01,466] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.65395116666667, 82.4596642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8283446215808639, 6.911200000000001, 6.9112, 121.9260426156618, 614101.8468754507, 614101.8468754502, 164398.1288493414]
[2019-03-23 01:56:01,467] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:56:01,469] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.050538086070617494
[2019-03-23 01:56:05,589] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.12368826], dtype=float32), -0.022007963]
[2019-03-23 01:56:05,590] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.1, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7004279678047477, 6.9112, 6.9112, 121.9260426156618, 523420.2866390918, 523420.2866390918, 144714.3886772353]
[2019-03-23 01:56:05,591] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:56:05,594] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.508754225912511
[2019-03-23 01:56:13,884] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8590.5979 2295206960.5452 313.0000
[2019-03-23 01:56:13,997] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7981.4233 2570381151.7050 396.0000
[2019-03-23 01:56:14,175] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8499.8539 2326046782.0003 406.0000
[2019-03-23 01:56:14,199] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8691.2389 2249294678.0219 332.0000
[2019-03-23 01:56:14,318] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8449.7130 2368358360.9009 323.0000
[2019-03-23 01:56:15,334] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1450000, evaluation results [1450000.0, 7981.423348832309, 2570381151.7050085, 396.0, 8590.597871893979, 2295206960.54522, 313.0, 8691.23888919767, 2249294678.0218935, 332.0, 8449.712975724722, 2368358360.9008594, 323.0, 8499.853935958748, 2326046782.000301, 406.0]
[2019-03-23 01:56:18,118] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:56:18,126] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1694
[2019-03-23 01:56:18,131] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.46666666666667, 51.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7189381091340221, 6.911200000000001, 6.9112, 121.9260426156618, 528971.8065439806, 528971.8065439801, 139513.8429373974], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6595800.0000, 
sim time next is 6596400.0000, 
raw observation next is [24.63333333333334, 50.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9705243417912096, 7.135660871915008, 6.9112, 121.9253231032527, 829252.1338949471, 714308.7836993913, 167021.2948849102], 
processed observation next is [1.0, 0.34782608695652173, 0.4679012345679015, 0.5033333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9631554272390119, 0.02244608719150083, 0.0, 0.8094573520059797, 0.29616147639105256, 0.25511027989263974, 0.3211947978555965], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5105965], dtype=float32), -0.07671188]. 
=============================================
[2019-03-23 01:56:20,524] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:56:20,532] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5150
[2019-03-23 01:56:20,537] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.08333333333333, 84.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5814063895314128, 6.9112, 6.9112, 121.9260426156618, 419347.5798206844, 419347.5798206844, 122957.6972188956], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6756600.0000, 
sim time next is 6757200.0000, 
raw observation next is [18.0, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5743443904667657, 6.911200000000001, 6.9112, 121.9260426156618, 413895.4883950916, 413895.4883950911, 122239.2000208982], 
processed observation next is [1.0, 0.21739130434782608, 0.2222222222222222, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.46793048808345705, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1478198172839613, 0.1478198172839611, 0.23507538465557348], 
reward next is 0.7649, 
noisyNet noise sample is [array([0.1468949], dtype=float32), -0.86890465]. 
=============================================
[2019-03-23 01:56:21,141] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:56:21,150] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6888
[2019-03-23 01:56:21,155] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.08333333333334, 46.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8808745162367054, 6.911200000000001, 6.9112, 121.9260426156618, 629064.4867052947, 629064.4867052942, 147980.12636816], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6660600.0000, 
sim time next is 6661200.0000, 
raw observation next is [23.06666666666667, 46.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6937722150804417, 6.911200000000001, 6.9112, 121.9260426156618, 495404.7702557205, 495404.7702557201, 129492.6328944815], 
processed observation next is [1.0, 0.08695652173913043, 0.40987654320987665, 0.46666666666666673, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6172152688505521, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17693027509132875, 0.1769302750913286, 0.24902429402784904], 
reward next is 0.7510, 
noisyNet noise sample is [array([0.10731053], dtype=float32), -0.72783726]. 
=============================================
[2019-03-23 01:56:30,649] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:56:30,656] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7508
[2019-03-23 01:56:30,662] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.33333333333333, 48.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8369667846551699, 6.911200000000001, 6.9112, 121.9260426156618, 618008.3107817458, 618008.3107817454, 166368.315369701], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6879000.0000, 
sim time next is 6879600.0000, 
raw observation next is [30.2, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8315420349400252, 6.9112, 6.9112, 121.9260426156618, 614544.7856228406, 614544.7856228406, 165512.8615310591], 
processed observation next is [0.0, 0.6521739130434783, 0.674074074074074, 0.49, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7894275436750314, 0.0, 0.0, 0.8094621288201359, 0.21948028057958593, 0.21948028057958593, 0.318293964482806], 
reward next is 0.6817, 
noisyNet noise sample is [array([-0.6556212], dtype=float32), -0.8756326]. 
=============================================
[2019-03-23 01:56:31,166] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:56:31,176] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5037
[2019-03-23 01:56:31,181] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.23333333333333, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6123210572648364, 6.9112, 6.9112, 121.9260426156618, 454933.6551377579, 454933.6551377579, 131868.3329472635], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7155600.0000, 
sim time next is 7156200.0000, 
raw observation next is [20.06666666666666, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6133503280744236, 6.9112, 6.9112, 121.9260426156618, 455698.0188666207, 455698.0188666207, 131966.6475588233], 
processed observation next is [1.0, 0.8260869565217391, 0.29876543209876516, 0.8666666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5166879100930294, 0.0, 0.0, 0.8094621288201359, 0.16274929245236455, 0.16274929245236455, 0.25378201453619864], 
reward next is 0.7462, 
noisyNet noise sample is [array([-1.0471784], dtype=float32), -0.34474057]. 
=============================================
[2019-03-23 01:56:36,532] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:56:36,541] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2430
[2019-03-23 01:56:36,546] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.63333333333333, 53.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7552494310202316, 6.9112, 6.9112, 121.9260426156618, 563544.0623737776, 563544.0623737776, 153045.5671113986], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6981000.0000, 
sim time next is 6981600.0000, 
raw observation next is [27.36666666666667, 54.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.749525050343079, 6.9112, 6.9112, 121.9260426156618, 559447.7986281158, 559447.7986281158, 152163.5538113487], 
processed observation next is [0.0, 0.8260869565217391, 0.569135802469136, 0.5466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6869063129288489, 0.0, 0.0, 0.8094621288201359, 0.19980278522432707, 0.19980278522432707, 0.2926222188679783], 
reward next is 0.7074, 
noisyNet noise sample is [array([-0.15704972], dtype=float32), 0.60025114]. 
=============================================
[2019-03-23 01:56:52,333] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:56:52,333] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:56:52,419] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run8
[2019-03-23 01:56:54,510] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:56:54,520] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6822
[2019-03-23 01:56:54,534] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 936286.0729021949 W.
[2019-03-23 01:56:54,540] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.08333333333333, 77.83333333333334, 1.0, 2.0, 0.7717946684468769, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 936286.0729021949, 936286.0729021935, 192685.058264574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7296600.0000, 
sim time next is 7297200.0000, 
raw observation next is [23.2, 77.0, 1.0, 2.0, 0.7242267373439768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 883705.087864437, 883705.087864437, 183257.0951506379], 
processed observation next is [1.0, 0.4782608695652174, 0.4148148148148148, 0.77, 1.0, 1.0, 0.6716984968380676, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31560895995158467, 0.31560895995158467, 0.35241749067430367], 
reward next is 0.6476, 
noisyNet noise sample is [array([0.02453976], dtype=float32), -2.023163]. 
=============================================
[2019-03-23 01:57:00,617] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:57:00,624] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2478
[2019-03-23 01:57:00,628] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.2, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6301438244939338, 6.9112, 6.9112, 121.9260426156618, 468979.2119544517, 468979.2119544517, 134238.4447895345], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7369200.0000, 
sim time next is 7369800.0000, 
raw observation next is [19.16666666666667, 95.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7425278383758144, 6.9112, 6.9112, 121.9260426156618, 552510.2683927509, 552510.2683927509, 145735.8353498216], 
processed observation next is [1.0, 0.30434782608695654, 0.2654320987654323, 0.9583333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6781597979697679, 0.0, 0.0, 0.8094621288201359, 0.19732509585455388, 0.19732509585455388, 0.28026122182658003], 
reward next is 0.7197, 
noisyNet noise sample is [array([-1.0592036], dtype=float32), 0.030122451]. 
=============================================
[2019-03-23 01:57:08,540] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 01:57:08,542] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:57:08,543] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:57:08,544] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:57:08,546] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:57:08,546] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:57:08,547] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:57:08,548] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:57:08,550] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:57:08,551] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:57:08,552] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:57:08,580] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run60
[2019-03-23 01:57:08,581] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run60
[2019-03-23 01:57:08,624] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run60
[2019-03-23 01:57:08,655] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run60
[2019-03-23 01:57:08,677] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run60
[2019-03-23 01:57:21,815] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07095724], dtype=float32), -0.019785473]
[2019-03-23 01:57:21,816] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.61490951, 41.49866208666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.596921805440254, 6.911199999999999, 6.9112, 121.9260426156618, 442546.2629652905, 442546.2629652909, 129738.4188260716]
[2019-03-23 01:57:21,817] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:57:21,819] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.1057149110281963
[2019-03-23 01:57:28,944] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.07095724], dtype=float32), -0.019785473]
[2019-03-23 01:57:28,946] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.16666666666666, 30.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6036885607174012, 6.9112, 6.9112, 121.9260426156618, 446610.1522971973, 446610.1522971973, 129776.7028278849]
[2019-03-23 01:57:28,947] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:57:28,950] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7708015907130382
[2019-03-23 01:57:35,602] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.07095724], dtype=float32), -0.019785473]
[2019-03-23 01:57:35,602] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.5, 85.0, 1.0, 2.0, 0.6100478499330592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 750869.859720557, 750869.859720557, 162007.0377479051]
[2019-03-23 01:57:35,605] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:57:35,608] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7871954520290997
[2019-03-23 01:57:35,609] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 750869.859720557 W.
[2019-03-23 01:57:36,720] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07095724], dtype=float32), -0.019785473]
[2019-03-23 01:57:36,721] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6779535511545752, 6.9112, 6.9112, 121.9260426156618, 505296.0638677269, 505296.0638677269, 139737.3450138315]
[2019-03-23 01:57:36,723] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:57:36,725] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.37549291998780576
[2019-03-23 01:57:44,254] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07095724], dtype=float32), -0.019785473]
[2019-03-23 01:57:44,256] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [18.1, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5460815189181336, 6.9112, 6.9112, 121.9260426156618, 390277.3472577312, 390277.3472577312, 118806.5275654492]
[2019-03-23 01:57:44,257] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 01:57:44,263] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9029680381284048
[2019-03-23 01:58:05,809] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.07095724], dtype=float32), -0.019785473]
[2019-03-23 01:58:05,812] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.1, 82.66666666666667, 1.0, 2.0, 0.6102259991700255, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9714996643520202, 6.911199999999999, 6.9112, 121.9260426156618, 1391508.66764853, 1391508.667648531, 297862.1519995787]
[2019-03-23 01:58:05,813] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 01:58:05,815] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 1.0421605e-34 3.1149827e-21 3.6828907e-33], sampled 0.9462558438651625
[2019-03-23 01:58:05,816] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1391508.66764853 W.
[2019-03-23 01:58:37,773] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07095724], dtype=float32), -0.019785473]
[2019-03-23 01:58:37,776] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.73932470166667, 64.37810936333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.769123017261589, 6.911200000000001, 6.9112, 121.9260426156618, 573602.0708867072, 573602.0708867067, 154992.6442911919]
[2019-03-23 01:58:37,777] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 01:58:37,779] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7559458249701184
[2019-03-23 01:58:48,234] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.07095724], dtype=float32), -0.019785473]
[2019-03-23 01:58:48,235] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.2, 91.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.88675813021144, 6.911200000000001, 6.9112, 121.9260426156618, 644472.7525419113, 644472.7525419109, 174990.6251359415]
[2019-03-23 01:58:48,236] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 01:58:48,241] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.2736920627211683
[2019-03-23 01:58:48,790] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07095724], dtype=float32), -0.019785473]
[2019-03-23 01:58:48,792] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.19045026166667, 46.99575181166666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8053452499434912, 6.9112, 6.9112, 121.9260426156618, 598763.5336375543, 598763.5336375543, 160695.1132644697]
[2019-03-23 01:58:48,793] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 01:58:48,797] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.892856957790635
[2019-03-23 01:59:00,905] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8367.8150 2335472324.9890 601.0000
[2019-03-23 01:59:01,069] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.2293 2257660707.4436 533.0000
[2019-03-23 01:59:01,207] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7845.7280 2524618799.5837 799.0000
[2019-03-23 01:59:01,320] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8632.9539 2218263654.9062 538.0000
[2019-03-23 01:59:01,478] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8408.0666 2290614484.9954 679.0000
[2019-03-23 01:59:02,497] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1475000, evaluation results [1475000.0, 7845.7279874961005, 2524618799.583704, 799.0, 8560.229327841267, 2257660707.443614, 533.0, 8632.953938757097, 2218263654.90625, 538.0, 8367.814980838397, 2335472324.98905, 601.0, 8408.066592307367, 2290614484.9953723, 679.0]
[2019-03-23 01:59:11,393] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:59:11,394] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:11,468] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run8
[2019-03-23 01:59:13,682] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9996972e-01 0.0000000e+00 3.2976578e-27 3.0324150e-05 5.2973828e-24], sum to 1.0000
[2019-03-23 01:59:13,687] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0527
[2019-03-23 01:59:13,694] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 853579.8010113713 W.
[2019-03-23 01:59:13,699] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.33333333333333, 81.66666666666667, 1.0, 2.0, 0.347803469040762, 1.0, 1.0, 0.347803469040762, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426120255, 853579.8010113713, 853579.8010113718, 194723.40766167], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7721400.0000, 
sim time next is 7722000.0000, 
raw observation next is [21.7, 80.0, 1.0, 2.0, 0.3752283253274982, 1.0, 2.0, 0.3752283253274982, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156607, 917892.2925000658, 917892.2925000662, 201975.4665613377], 
processed observation next is [1.0, 0.391304347826087, 0.3592592592592592, 0.8, 1.0, 1.0, 0.25622419681845027, 1.0, 1.0, 0.25622419681845027, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201287, 0.3278186758928806, 0.3278186758928808, 0.38841435877180325], 
reward next is 0.6116, 
noisyNet noise sample is [array([-2.0554345], dtype=float32), -0.018720878]. 
=============================================
[2019-03-23 01:59:13,710] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[52.5225  ]
 [57.47479 ]
 [65.492355]
 [66.065895]
 [66.638336]], R is [[50.1754303 ]
 [50.29920578]
 [50.41038513]
 [50.47854233]
 [50.66973495]].
[2019-03-23 01:59:14,342] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 8.4461393e-29 1.9224767e-22 1.7538691e-31 2.8289312e-13], sum to 1.0000
[2019-03-23 01:59:14,348] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0105
[2019-03-23 01:59:14,356] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1272939.502764012 W.
[2019-03-23 01:59:14,362] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 35.0, 1.0, 2.0, 0.5214130195547468, 1.0, 2.0, 0.5214130195547468, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1272939.502764012, 1272939.502764011, 245470.183339487], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 475200.0000, 
sim time next is 475800.0000, 
raw observation next is [30.16666666666666, 34.33333333333334, 1.0, 2.0, 0.3965921876147466, 1.0, 2.0, 0.3965921876147466, 1.0, 1.0, 0.6425493549947205, 6.9112, 6.9112, 121.94756008, 1436330.225846576, 1436330.225846576, 294939.3656211057], 
processed observation next is [1.0, 0.5217391304347826, 0.6728395061728393, 0.34333333333333343, 1.0, 1.0, 0.2816573662080317, 1.0, 1.0, 0.2816573662080317, 1.0, 0.5, 0.5531866937434007, 0.0, 0.0, 0.8096049824067558, 0.5129750806594915, 0.5129750806594915, 0.5671910877328956], 
reward next is 0.4328, 
noisyNet noise sample is [array([-0.5890674], dtype=float32), 0.781039]. 
=============================================
[2019-03-23 01:59:14,611] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:59:14,612] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:14,692] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run8
[2019-03-23 01:59:15,144] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.00000000e+00 0.00000000e+00 1.14659196e-32 1.74335786e-22
 7.44859283e-32], sum to 1.0000
[2019-03-23 01:59:15,150] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2184
[2019-03-23 01:59:15,157] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1272870.507860336 W.
[2019-03-23 01:59:15,163] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.46666666666667, 37.33333333333334, 1.0, 2.0, 0.5204797611979632, 1.0, 1.0, 0.5204797611979632, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1272870.507860336, 1272870.507860336, 245233.1969788505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 48000.0000, 
sim time next is 48600.0000, 
raw observation next is [29.65, 37.0, 1.0, 2.0, 1.00535341299759, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.694956625419608, 6.9112, 121.9228188917875, 1643511.187690331, 1242168.355885983, 246357.7122110239], 
processed observation next is [1.0, 0.5652173913043478, 0.6537037037037037, 0.37, 1.0, 1.0, 1.0063731107114167, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0783756625419608, 0.0, 0.8094407266460472, 0.5869682813179753, 0.4436315556735653, 0.473764831175046], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6682945], dtype=float32), -0.8015555]. 
=============================================
[2019-03-23 01:59:15,498] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:59:15,498] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:15,559] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run8
[2019-03-23 01:59:21,154] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:59:21,156] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:21,228] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run8
[2019-03-23 01:59:21,376] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:59:21,377] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:21,449] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run8
[2019-03-23 01:59:22,413] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:59:22,419] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6632
[2019-03-23 01:59:22,422] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.05, 67.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.747215945252467, 6.911200000000001, 6.9112, 121.9260426156618, 557702.8146296793, 557702.8146296788, 151920.6064078364], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7941000.0000, 
sim time next is 7941600.0000, 
raw observation next is [24.9, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7433068586716526, 6.911199999999999, 6.9112, 121.9260426156618, 554902.9374261406, 554902.9374261411, 151309.3497943805], 
processed observation next is [1.0, 0.9565217391304348, 0.47777777777777775, 0.68, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6791335733395656, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19817962050933594, 0.1981796205093361, 0.2909795188353471], 
reward next is 0.7090, 
noisyNet noise sample is [array([1.5257547], dtype=float32), -0.3486855]. 
=============================================
[2019-03-23 01:59:23,745] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:59:23,747] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:23,816] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run8
[2019-03-23 01:59:24,055] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:59:24,056] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:24,078] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:59:24,079] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:24,114] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run8
[2019-03-23 01:59:24,161] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run8
[2019-03-23 01:59:24,400] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:59:24,402] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:24,422] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run8
[2019-03-23 01:59:24,844] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:59:24,844] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:24,884] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run8
[2019-03-23 01:59:25,217] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:59:25,217] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:25,252] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run8
[2019-03-23 01:59:25,276] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:59:25,277] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:25,329] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run8
[2019-03-23 01:59:25,492] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:59:25,495] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3759
[2019-03-23 01:59:25,498] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.9, 19.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6478635490192041, 6.911200000000001, 6.9112, 121.9260426156618, 469025.944922374, 469025.9449223736, 129339.5435322668], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 219000.0000, 
sim time next is 219600.0000, 
raw observation next is [32.1, 18.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6529502066324472, 6.9112, 6.9112, 121.9260426156618, 471492.8600966573, 471492.8600966573, 129355.7012240609], 
processed observation next is [0.0, 0.5652173913043478, 0.7444444444444445, 0.18, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5661877582905589, 0.0, 0.0, 0.8094621288201359, 0.1683903071773776, 0.1683903071773776, 0.2487609638924248], 
reward next is 0.7512, 
noisyNet noise sample is [array([-0.7310065], dtype=float32), -0.6961395]. 
=============================================
[2019-03-23 01:59:25,529] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:59:25,529] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:25,570] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run8
[2019-03-23 01:59:25,799] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:59:25,799] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:25,847] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run8
[2019-03-23 01:59:25,980] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 01:59:25,981] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:26,005] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run8
[2019-03-23 01:59:29,602] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:59:29,612] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9918
[2019-03-23 01:59:29,618] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.9, 39.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.482116189512495, 6.9112, 6.9112, 121.9260426156618, 344232.7623089361, 344232.7623089361, 95318.12431931996], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 187200.0000, 
sim time next is 187800.0000, 
raw observation next is [21.53333333333333, 41.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4754963667477725, 6.911200000000001, 6.9112, 121.9260426156618, 339505.1379254797, 339505.1379254793, 95168.58438579523], 
processed observation next is [0.0, 0.17391304347826086, 0.35308641975308636, 0.415, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3443704584347156, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1212518349733856, 0.12125183497338547, 0.1830165084342216], 
reward next is 0.8170, 
noisyNet noise sample is [array([-1.3992188], dtype=float32), 0.048631202]. 
=============================================
[2019-03-23 01:59:29,692] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:59:29,703] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4396
[2019-03-23 01:59:29,708] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.7, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6508276223184362, 6.9112, 6.9112, 121.9260426156618, 484782.9932560062, 484782.9932560062, 136665.6863250201], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 100800.0000, 
sim time next is 101400.0000, 
raw observation next is [21.6, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7419280462432282, 6.9112, 6.9112, 121.9260426156618, 552397.185817879, 552397.185817879, 145964.5928269259], 
processed observation next is [1.0, 0.17391304347826086, 0.3555555555555556, 0.77, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6774100578040351, 0.0, 0.0, 0.8094621288201359, 0.1972847092206711, 0.1972847092206711, 0.28070114005178054], 
reward next is 0.7193, 
noisyNet noise sample is [array([-0.04964795], dtype=float32), 0.060697615]. 
=============================================
[2019-03-23 01:59:30,003] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:59:30,010] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1906
[2019-03-23 01:59:30,019] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.5, 40.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6323193274949935, 6.911200000000001, 6.9112, 121.9260426156618, 472510.084088664, 472510.0840886636, 137525.4896184894], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 62400.0000, 
sim time next is 63000.0000, 
raw observation next is [29.4, 40.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6289889581645158, 6.911200000000001, 6.9112, 121.9260426156618, 469884.1350781154, 469884.135078115, 136457.3100235303], 
processed observation next is [1.0, 0.7391304347826086, 0.6444444444444444, 0.405, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5362361977056448, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16781576252789834, 0.1678157625278982, 0.2624179038914044], 
reward next is 0.7376, 
noisyNet noise sample is [array([1.0917116], dtype=float32), -0.95718294]. 
=============================================
[2019-03-23 01:59:30,035] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.750145]
 [67.438286]
 [66.51564 ]
 [66.49834 ]
 [65.88947 ]], R is [[77.03295135]
 [76.99814606]
 [76.89459991]
 [76.64793396]
 [76.40229034]].
[2019-03-23 01:59:32,417] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:59:32,426] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4204
[2019-03-23 01:59:32,430] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [35.88333333333333, 7.666666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7137644671542261, 6.911200000000001, 6.9112, 121.9260426156618, 509686.5817274611, 509686.5817274607, 128791.9139995954], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 150600.0000, 
sim time next is 151200.0000, 
raw observation next is [35.6, 8.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7089454370542396, 6.9112, 6.9112, 121.9260426156618, 506243.2382071864, 506243.2382071864, 128070.7860434141], 
processed observation next is [1.0, 0.782608695652174, 0.8740740740740741, 0.08, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6361817963177996, 0.0, 0.0, 0.8094621288201359, 0.18080115650256656, 0.18080115650256656, 0.24628997316041173], 
reward next is 0.7537, 
noisyNet noise sample is [array([-0.7333538], dtype=float32), -0.9561589]. 
=============================================
[2019-03-23 01:59:32,969] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:59:32,983] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3741
[2019-03-23 01:59:32,986] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.36666666666667, 32.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5892145276560806, 6.911200000000001, 6.9112, 121.9260426156618, 425287.423350328, 425287.4233503275, 123725.84588138], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 249000.0000, 
sim time next is 249600.0000, 
raw observation next is [27.03333333333333, 33.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5802948619018886, 6.911200000000001, 6.9112, 121.9260426156618, 418480.617766693, 418480.6177666925, 122841.1462915584], 
processed observation next is [0.0, 0.9130434782608695, 0.55679012345679, 0.33, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4753685773773607, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14945736348810465, 0.14945736348810446, 0.2362329736376123], 
reward next is 0.7638, 
noisyNet noise sample is [array([-0.05759424], dtype=float32), -0.46657088]. 
=============================================
[2019-03-23 01:59:34,324] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:59:34,335] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9012
[2019-03-23 01:59:34,340] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.2, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4557899002865432, 6.911199999999999, 6.9112, 121.9260426156618, 325431.7053372575, 325431.7053372579, 95308.6136579814], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 271800.0000, 
sim time next is 272400.0000, 
raw observation next is [20.13333333333333, 51.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4542785208491728, 6.9112, 6.9112, 121.9260426156618, 324352.3598062184, 324352.3598062184, 94993.1988653317], 
processed observation next is [0.0, 0.13043478260869565, 0.30123456790123443, 0.5166666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.31784815106146597, 0.0, 0.0, 0.8094621288201359, 0.11584012850222086, 0.11584012850222086, 0.18267922858717633], 
reward next is 0.8173, 
noisyNet noise sample is [array([0.31249595], dtype=float32), -0.3779949]. 
=============================================
[2019-03-23 01:59:37,206] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:59:37,218] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2151
[2019-03-23 01:59:37,225] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.36666666666667, 77.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5366232406861386, 6.9112, 6.9112, 121.9260426156618, 389873.3271422607, 389873.3271422607, 120342.7004674529], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 535800.0000, 
sim time next is 536400.0000, 
raw observation next is [19.3, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5338524601938635, 6.9112, 6.9112, 121.9260426156618, 387705.05735794, 387705.05735794, 120054.0815768482], 
processed observation next is [1.0, 0.21739130434782608, 0.27037037037037037, 0.78, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.41731557524232926, 0.0, 0.0, 0.8094621288201359, 0.13846609191355, 0.13846609191355, 0.23087323380163116], 
reward next is 0.7691, 
noisyNet noise sample is [array([0.16653436], dtype=float32), -0.18121767]. 
=============================================
[2019-03-23 01:59:38,784] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:59:38,792] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4635
[2019-03-23 01:59:38,795] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.35, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4817633720947599, 6.9112, 6.9112, 121.9260426156618, 343980.7928600139, 343980.7928600139, 101340.9864861524], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 264600.0000, 
sim time next is 265200.0000, 
raw observation next is [21.2, 49.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4778714047982316, 6.9112, 6.9112, 121.9260426156618, 341201.2959658253, 341201.2959658253, 100475.4686520121], 
processed observation next is [0.0, 0.043478260869565216, 0.34074074074074073, 0.4933333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3473392559977895, 0.0, 0.0, 0.8094621288201359, 0.12185760570208047, 0.12185760570208047, 0.19322205510002327], 
reward next is 0.8068, 
noisyNet noise sample is [array([1.1893897], dtype=float32), -1.7418026]. 
=============================================
[2019-03-23 01:59:40,545] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:59:40,556] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8780
[2019-03-23 01:59:40,561] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.5, 37.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6341741107608978, 6.9112, 6.9112, 121.9260426156618, 472760.0555131723, 472760.0555131723, 135398.5156114662], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 590400.0000, 
sim time next is 591000.0000, 
raw observation next is [29.31666666666667, 37.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6320467512786772, 6.911200000000001, 6.9112, 121.9260426156618, 471075.2231353492, 471075.2231353488, 135079.1619169091], 
processed observation next is [1.0, 0.8695652173913043, 0.6413580246913582, 0.375, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5400584390983464, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1682411511197676, 0.16824115111976742, 0.25976761907097906], 
reward next is 0.7402, 
noisyNet noise sample is [array([-0.81490964], dtype=float32), -0.7317947]. 
=============================================
[2019-03-23 01:59:40,573] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[74.05669]
 [73.88602]
 [73.94547]
 [73.95737]
 [73.95532]], R is [[74.18977356]
 [74.18749237]
 [74.18473816]
 [74.18148804]
 [74.17765808]].
[2019-03-23 01:59:42,119] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:59:42,129] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0545
[2019-03-23 01:59:42,135] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.75, 52.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4458528980725653, 6.9112, 6.9112, 121.9260426156618, 318335.2631113368, 318335.2631113368, 93167.18632237743], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 275400.0000, 
sim time next is 276000.0000, 
raw observation next is [19.66666666666667, 52.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4443480202505292, 6.911200000000001, 6.9112, 121.9260426156618, 317260.5706232856, 317260.5706232851, 92799.4238829953], 
processed observation next is [0.0, 0.17391304347826086, 0.28395061728395077, 0.5266666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.30543502531316147, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11330734665117342, 0.11330734665117324, 0.17846043054422173], 
reward next is 0.8215, 
noisyNet noise sample is [array([-0.07500574], dtype=float32), -1.6522461]. 
=============================================
[2019-03-23 01:59:42,149] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[70.97197]
 [70.99119]
 [71.02415]
 [71.08353]
 [71.07898]], R is [[71.07008362]
 [71.18021393]
 [71.28851318]
 [71.39494324]
 [71.49952698]].
[2019-03-23 01:59:43,755] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.8445824e-01 3.0649757e-32 3.5478084e-16 1.1554178e-01 9.7386868e-14], sum to 1.0000
[2019-03-23 01:59:43,765] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8256
[2019-03-23 01:59:43,773] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1577028.833920203 W.
[2019-03-23 01:59:43,777] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.91666666666667, 35.0, 1.0, 2.0, 0.4475507883758442, 1.0, 1.0, 0.4475507883758442, 1.0, 2.0, 0.7159716347393549, 6.911199999999999, 6.9112, 121.94756008, 1577028.833920203, 1577028.833920204, 318587.1702134839], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 645000.0000, 
sim time next is 645600.0000, 
raw observation next is [32.13333333333334, 34.0, 1.0, 2.0, 0.4014934111000108, 1.0, 2.0, 0.4014934111000108, 1.0, 2.0, 0.64213575715977, 6.911199999999999, 6.9112, 121.94756008, 1413425.9465798, 1413425.9465798, 297746.5776149549], 
processed observation next is [1.0, 0.4782608695652174, 0.7456790123456792, 0.34, 1.0, 1.0, 0.28749215607144146, 1.0, 1.0, 0.28749215607144146, 1.0, 1.0, 0.5526696964497124, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5047949809213571, 0.5047949809213571, 0.5725895723364517], 
reward next is 0.4274, 
noisyNet noise sample is [array([-0.6496211], dtype=float32), -0.463752]. 
=============================================
[2019-03-23 01:59:44,316] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:59:44,328] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7286
[2019-03-23 01:59:44,335] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.8, 31.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5861927257973137, 6.911200000000001, 6.9112, 121.9260426156618, 424091.9421314274, 424091.9421314269, 123829.7210082921], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 313200.0000, 
sim time next is 313800.0000, 
raw observation next is [27.83333333333334, 31.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5880262866468067, 6.911200000000001, 6.9112, 121.9260426156618, 425478.4019685152, 425478.4019685148, 124007.9457184774], 
processed observation next is [0.0, 0.6521739130434783, 0.58641975308642, 0.31, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4850328583085083, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15195657213161257, 0.15195657213161243, 0.2384768186893796], 
reward next is 0.7615, 
noisyNet noise sample is [array([-0.81301904], dtype=float32), 1.8636627]. 
=============================================
[2019-03-23 01:59:48,383] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:59:48,392] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6399
[2019-03-23 01:59:48,399] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.43333333333334, 43.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7075586210268199, 6.9112, 6.9112, 121.9260426156618, 505252.5290949339, 505252.5290949339, 128638.4930384982], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 372000.0000, 
sim time next is 372600.0000, 
raw observation next is [23.85, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.709537216415466, 6.911199999999999, 6.9112, 121.9260426156618, 506665.868683465, 506665.8686834655, 129720.9442414397], 
processed observation next is [1.0, 0.30434782608695654, 0.43888888888888894, 0.42, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6369215205193324, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18095209595838035, 0.18095209595838055, 0.24946335431046096], 
reward next is 0.7505, 
noisyNet noise sample is [array([0.09228997], dtype=float32), -0.29176334]. 
=============================================
[2019-03-23 01:59:53,908] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 01:59:53,909] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 01:59:53,913] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 01:59:53,914] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1950
[2019-03-23 01:59:53,915] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:53,916] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 01:59:53,917] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 01:59:53,920] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.66666666666667, 49.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5622370507632459, 6.911199999999999, 6.9112, 121.9260426156618, 413411.8579856246, 413411.8579856251, 124622.5500496411], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 512400.0000, 
sim time next is 513000.0000, 
raw observation next is [24.4, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5579741801037426, 6.911200000000001, 6.9112, 121.9260426156618, 409807.9541437743, 409807.9541437739, 124022.2274116831], 
processed observation next is [1.0, 0.9565217391304348, 0.4592592592592592, 0.505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44746772512967814, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14635998362277652, 0.14635998362277639, 0.23850428348400596], 
reward next is 0.7615, 
noisyNet noise sample is [array([-0.8197974], dtype=float32), -0.3746988]. 
=============================================
[2019-03-23 01:59:53,921] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:53,934] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 01:59:53,921] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 01:59:53,979] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:53,979] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:54,000] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 01:59:54,862] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run61
[2019-03-23 01:59:54,984] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run61
[2019-03-23 01:59:55,095] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run61
[2019-03-23 01:59:55,101] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run61
[2019-03-23 01:59:55,167] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run61
[2019-03-23 02:00:10,661] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0028826], dtype=float32), -0.13025285]
[2019-03-23 02:00:10,662] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.3, 30.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4794511681124482, 6.9112, 6.9112, 121.9260426156618, 342329.5023878746, 342329.5023878746, 93555.60178189336]
[2019-03-23 02:00:10,663] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:00:10,667] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.020117184928207354
[2019-03-23 02:00:56,843] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0028826], dtype=float32), -0.13025285]
[2019-03-23 02:00:56,843] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.4, 87.66666666666666, 1.0, 2.0, 0.6936973105979352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790614.989870164, 790614.989870164, 174954.4587630051]
[2019-03-23 02:00:56,845] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:00:56,847] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 7.024914e-30], sampled 0.9998513923735374
[2019-03-23 02:00:56,849] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 790614.989870164 W.
[2019-03-23 02:01:10,678] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0028826], dtype=float32), -0.13025285]
[2019-03-23 02:01:10,679] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.0, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8481013502061904, 6.911200000000001, 6.9112, 121.9260426156618, 624062.4249511969, 624062.4249511964, 168392.6162676172]
[2019-03-23 02:01:10,681] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:01:10,684] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9023901615266061
[2019-03-23 02:01:47,770] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0028826], dtype=float32), -0.13025285]
[2019-03-23 02:01:47,771] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.80732287, 55.79615013, 1.0, 2.0, 0.844648639476644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 962764.0561542663, 962764.0561542659, 205339.718725022]
[2019-03-23 02:01:47,773] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:01:47,778] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 7.7067608e-32 1.4555210e-27 3.5020867e-26], sampled 0.7400040608022177
[2019-03-23 02:01:47,779] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 962764.0561542663 W.
[2019-03-23 02:01:49,043] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8385.1508 2331766137.2924 592.0000
[2019-03-23 02:01:49,077] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8568.6641 2256542006.0368 527.0000
[2019-03-23 02:01:49,182] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8417.4857 2288590797.8813 668.0000
[2019-03-23 02:01:49,198] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7870.4792 2520339066.5214 780.0000
[2019-03-23 02:01:49,242] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8643.3112 2217563455.6656 533.0000
[2019-03-23 02:01:50,256] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1500000, evaluation results [1500000.0, 7870.479162498193, 2520339066.521447, 780.0, 8568.664068901273, 2256542006.0367885, 527.0, 8643.311171261568, 2217563455.665641, 533.0, 8385.150814267892, 2331766137.292364, 592.0, 8417.485746383169, 2288590797.881337, 668.0]
[2019-03-23 02:01:50,283] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[69.68221 ]
 [69.76582 ]
 [69.89247 ]
 [69.98963 ]
 [70.075584]], R is [[69.6778183 ]
 [69.74137878]
 [69.80313873]
 [69.86332703]
 [69.92219543]].
[2019-03-23 02:01:50,993] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:01:51,002] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3131
[2019-03-23 02:01:51,005] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.58333333333333, 64.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6417552480969331, 6.911199999999999, 6.9112, 121.9260426156618, 468535.1334868274, 468535.1334868279, 130335.8707600979], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 618600.0000, 
sim time next is 619200.0000, 
raw observation next is [21.4, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6209980107975837, 6.911199999999999, 6.9112, 121.9260426156618, 453017.5670554137, 453017.5670554141, 128295.4467249858], 
processed observation next is [1.0, 0.17391304347826086, 0.3481481481481481, 0.65, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5262475134969795, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1617919882340763, 0.16179198823407645, 0.246722012932665], 
reward next is 0.7533, 
noisyNet noise sample is [array([-0.8909709], dtype=float32), -0.13157229]. 
=============================================
[2019-03-23 02:01:54,468] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:01:54,476] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1418
[2019-03-23 02:01:54,480] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5866550237094917, 6.9112, 6.9112, 121.9260426156618, 433915.163177006, 433915.163177006, 128147.6001151989], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 804600.0000, 
sim time next is 805200.0000, 
raw observation next is [23.66666666666667, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5893866132718653, 6.9112, 6.9112, 121.9260426156618, 436201.8302523507, 436201.8302523507, 128557.5725910702], 
processed observation next is [0.0, 0.30434782608695654, 0.43209876543209896, 0.59, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4867332665898315, 0.0, 0.0, 0.8094621288201359, 0.1557863679472681, 0.1557863679472681, 0.24722610113667345], 
reward next is 0.7528, 
noisyNet noise sample is [array([0.88099605], dtype=float32), 1.5816675]. 
=============================================
[2019-03-23 02:01:54,988] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.7997383e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 02:01:54,995] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7195
[2019-03-23 02:01:55,001] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 920393.8461937722 W.
[2019-03-23 02:01:55,008] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.95, 38.0, 1.0, 2.0, 0.7408941557618763, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 920393.8461937722, 920393.8461937722, 187028.916747495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1341000.0000, 
sim time next is 1341600.0000, 
raw observation next is [29.13333333333333, 37.33333333333334, 1.0, 2.0, 0.7283097043979974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 908094.5283855873, 908094.5283855873, 184581.2302759129], 
processed observation next is [1.0, 0.5217391304347826, 0.6345679012345677, 0.3733333333333334, 1.0, 1.0, 0.6765591719023778, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.324319474423424, 0.324319474423424, 0.35496390437675557], 
reward next is 0.6450, 
noisyNet noise sample is [array([0.20026012], dtype=float32), 0.6338573]. 
=============================================
[2019-03-23 02:01:59,204] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:01:59,214] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7202
[2019-03-23 02:01:59,224] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.85, 29.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6113936364162964, 6.9112, 6.9112, 121.9260426156618, 449559.9777917759, 449559.9777917759, 129024.7266967485], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 682200.0000, 
sim time next is 682800.0000, 
raw observation next is [29.66666666666666, 29.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6108173213283694, 6.9112, 6.9112, 121.9260426156618, 449242.5108572009, 449242.5108572009, 129024.0069001787], 
processed observation next is [1.0, 0.9130434782608695, 0.6543209876543208, 0.29666666666666663, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5135216516604617, 0.0, 0.0, 0.8094621288201359, 0.16044375387757176, 0.16044375387757176, 0.24812309019265136], 
reward next is 0.7519, 
noisyNet noise sample is [array([0.73559254], dtype=float32), -0.2161689]. 
=============================================
[2019-03-23 02:01:59,721] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:01:59,729] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4781
[2019-03-23 02:01:59,738] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.55, 42.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5283271165696605, 6.911200000000001, 6.9112, 121.9260426156618, 385427.4370846045, 385427.4370846041, 120310.9156500893], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 778200.0000, 
sim time next is 778800.0000, 
raw observation next is [25.4, 43.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5255214448573011, 6.9112, 6.9112, 121.9260426156618, 383361.9925824351, 383361.9925824351, 120071.8173321227], 
processed observation next is [0.0, 0.0, 0.49629629629629624, 0.4333333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.40690180607162635, 0.0, 0.0, 0.8094621288201359, 0.13691499735086968, 0.13691499735086968, 0.23090734102331287], 
reward next is 0.7691, 
noisyNet noise sample is [array([-1.0129808], dtype=float32), -0.31231755]. 
=============================================
[2019-03-23 02:02:05,448] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:02:05,455] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8904
[2019-03-23 02:02:05,460] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.55, 46.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5038866054088362, 6.9112, 6.9112, 121.9260426156618, 361578.0940070787, 361578.0940070787, 116022.9158151637], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1029000.0000, 
sim time next is 1029600.0000, 
raw observation next is [23.5, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.500145840372954, 6.911200000000001, 6.9112, 121.9260426156618, 358784.5467471837, 358784.5467471833, 115697.9607867655], 
processed observation next is [1.0, 0.9565217391304348, 0.42592592592592593, 0.47, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3751823004661924, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1281373381239942, 0.12813733812399403, 0.22249607843608749], 
reward next is 0.7775, 
noisyNet noise sample is [array([0.8174309], dtype=float32), 0.7338685]. 
=============================================
[2019-03-23 02:02:06,642] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:02:06,653] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0416
[2019-03-23 02:02:06,659] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.03333333333333, 34.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5748608632593448, 6.9112, 6.9112, 121.9260426156618, 421216.9992084493, 421216.9992084493, 125037.7695807672], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 769200.0000, 
sim time next is 769800.0000, 
raw observation next is [27.86666666666666, 34.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5717372823760075, 6.911200000000001, 6.9112, 121.9260426156618, 418785.4100805492, 418785.4100805488, 124700.413431227], 
processed observation next is [1.0, 0.9130434782608695, 0.587654320987654, 0.345, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.46467160297000937, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14956621788591043, 0.1495662178859103, 0.23980848736774424], 
reward next is 0.7602, 
noisyNet noise sample is [array([0.6804772], dtype=float32), 1.8893253]. 
=============================================
[2019-03-23 02:02:08,076] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:02:08,086] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8736
[2019-03-23 02:02:08,092] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.96666666666667, 46.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.64089554793572, 6.911200000000001, 6.9112, 121.9260426156618, 477215.2071600215, 477215.207160021, 135510.3202125432], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 930000.0000, 
sim time next is 930600.0000, 
raw observation next is [26.8, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6387827420454686, 6.9112, 6.9112, 121.9260426156618, 475594.6298961016, 475594.6298961016, 135256.7253872942], 
processed observation next is [0.0, 0.782608695652174, 0.5481481481481482, 0.47, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5484784275568357, 0.0, 0.0, 0.8094621288201359, 0.16985522496289343, 0.16985522496289343, 0.26010908728325804], 
reward next is 0.7399, 
noisyNet noise sample is [array([-1.8106353], dtype=float32), -0.5071707]. 
=============================================
[2019-03-23 02:02:21,859] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9999988e-01 3.3668124e-22 2.3295973e-15 5.8383778e-09 1.1221002e-07], sum to 1.0000
[2019-03-23 02:02:21,867] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5575
[2019-03-23 02:02:21,878] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 981535.9454867796 W.
[2019-03-23 02:02:21,883] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 51.0, 1.0, 2.0, 0.263014500877458, 1.0, 2.0, 0.263014500877458, 1.0, 1.0, 0.4384259556143258, 6.9112, 6.9112, 121.94756008, 981535.9454867796, 981535.9454867796, 239880.7098526146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1076400.0000, 
sim time next is 1077000.0000, 
raw observation next is [24.45, 50.33333333333334, 1.0, 2.0, 0.6830729704771555, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 861580.5493294754, 861580.5493294757, 175909.4152946073], 
processed observation next is [1.0, 0.4782608695652174, 0.4611111111111111, 0.5033333333333334, 1.0, 1.0, 0.6227059172347089, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3077073390462412, 0.3077073390462413, 0.338287337105014], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5456975], dtype=float32), 0.35565627]. 
=============================================
[2019-03-23 02:02:21,898] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[55.749866]
 [56.273914]
 [56.0613  ]
 [55.19641 ]
 [56.29525 ]], R is [[54.87280273]
 [54.32407379]
 [54.39341736]
 [54.39352798]
 [53.84959412]].
[2019-03-23 02:02:30,000] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.7163210e-27 4.8639007e-37 0.0000000e+00 1.0000000e+00 5.1476086e-27], sum to 1.0000
[2019-03-23 02:02:30,008] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8424
[2019-03-23 02:02:30,014] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.95, 67.5, 1.0, 2.0, 0.3661038854299972, 1.0, 2.0, 0.3661038854299972, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 912072.3880998166, 912072.3880998166, 199916.2369614747], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1176600.0000, 
sim time next is 1177200.0000, 
raw observation next is [21.9, 68.0, 1.0, 2.0, 0.3713381328674928, 1.0, 2.0, 0.3713381328674928, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 924842.8634783081, 924842.8634783081, 201328.5594733226], 
processed observation next is [1.0, 0.6521739130434783, 0.36666666666666664, 0.68, 1.0, 1.0, 0.2515930153184438, 1.0, 1.0, 0.2515930153184438, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33030102267082434, 0.33030102267082434, 0.3871703066794665], 
reward next is 0.6128, 
noisyNet noise sample is [array([-1.8207835], dtype=float32), -1.0171901]. 
=============================================
[2019-03-23 02:02:30,887] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 8.730486e-29 0.000000e+00], sum to 1.0000
[2019-03-23 02:02:30,898] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7977
[2019-03-23 02:02:30,905] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8793815388996797, 6.9112, 6.9112, 121.9260426156618, 642301.6875181022, 642301.6875181022, 173472.103107573], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1965600.0000, 
sim time next is 1966200.0000, 
raw observation next is [27.86666666666667, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8950153437320179, 6.911199999999999, 6.9112, 121.9260426156618, 653210.5768685131, 653210.5768685136, 175630.9050819749], 
processed observation next is [1.0, 0.782608695652174, 0.5876543209876545, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8687691796650223, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23328949173875468, 0.23328949173875485, 0.3377517405422594], 
reward next is 0.6622, 
noisyNet noise sample is [array([-0.51838225], dtype=float32), -0.114075415]. 
=============================================
[2019-03-23 02:02:37,329] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.9837599e-25 1.2866564e-33], sum to 1.0000
[2019-03-23 02:02:37,337] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7541
[2019-03-23 02:02:37,345] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 999948.2303046787 W.
[2019-03-23 02:02:37,350] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.76666666666667, 38.66666666666667, 1.0, 2.0, 0.2740052672909197, 1.0, 2.0, 0.2740052672909197, 1.0, 2.0, 0.4464421349795213, 6.911199999999998, 6.9112, 121.94756008, 999948.2303046787, 999948.2303046796, 245199.8674267837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1340400.0000, 
sim time next is 1341000.0000, 
raw observation next is [28.95, 38.0, 1.0, 2.0, 0.742357915987044, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156418, 920374.4613942167, 920374.4613942167, 187279.886107738], 
processed observation next is [1.0, 0.5217391304347826, 0.6277777777777778, 0.38, 1.0, 1.0, 0.6932832333179095, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288200032, 0.32870516478364886, 0.32870516478364886, 0.3601536271302654], 
reward next is 0.6398, 
noisyNet noise sample is [array([0.017082], dtype=float32), 1.7960979]. 
=============================================
[2019-03-23 02:02:37,366] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[70.243324]
 [70.45972 ]
 [70.78434 ]
 [71.25341 ]
 [70.57607 ]], R is [[70.13461304]
 [69.96173096]
 [69.26211548]
 [68.56949615]
 [68.43217468]].
[2019-03-23 02:02:44,127] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 02:02:44,128] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:02:44,129] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:02:44,129] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:02:44,130] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:02:44,132] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:02:44,132] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:02:44,134] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:02:44,136] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:02:44,138] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:02:44,137] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:02:44,160] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run62
[2019-03-23 02:02:44,188] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run62
[2019-03-23 02:02:44,218] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run62
[2019-03-23 02:02:44,242] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run62
[2019-03-23 02:02:44,268] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run62
[2019-03-23 02:02:46,755] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.09439], dtype=float32), -0.14484732]
[2019-03-23 02:02:46,757] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.303919805, 39.40038219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6430051219202922, 6.9112, 6.9112, 121.9260426156618, 472824.1868312004, 472824.1868312004, 131970.0278764974]
[2019-03-23 02:02:46,762] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:02:46,767] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9221207662942018
[2019-03-23 02:02:51,945] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09439], dtype=float32), -0.14484732]
[2019-03-23 02:02:51,946] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.5, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4465370478994527, 6.911200000000001, 6.9112, 121.9260426156618, 318823.8419303017, 318823.8419303013, 103199.7690353994]
[2019-03-23 02:02:51,947] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:02:51,950] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3525989525743466
[2019-03-23 02:03:28,337] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.09439], dtype=float32), -0.14484732]
[2019-03-23 02:03:28,338] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.1, 65.0, 1.0, 2.0, 0.4638832987563663, 1.0, 2.0, 0.4638832987563663, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1057570.583723896, 1057570.583723895, 224440.7238970549]
[2019-03-23 02:03:28,340] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:03:28,346] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9994779e-01 2.2296099e-32 1.1720887e-31 5.2218445e-05 3.0905200e-22], sampled 0.2436506683182843
[2019-03-23 02:03:28,349] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1057570.583723896 W.
[2019-03-23 02:04:22,528] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.09439], dtype=float32), -0.14484732]
[2019-03-23 02:04:22,530] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.9, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.865265913193255, 6.911199999999999, 6.9112, 121.9260426156618, 635257.664494153, 635257.6644941535, 170944.6202608313]
[2019-03-23 02:04:22,530] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:04:22,532] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1024488e-23 0.0000000e+00], sampled 0.9252201372954112
[2019-03-23 02:04:28,718] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.09439], dtype=float32), -0.14484732]
[2019-03-23 02:04:28,720] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.5, 95.0, 1.0, 2.0, 0.719459158882967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 895639.2799904635, 895639.2799904635, 182792.3483577713]
[2019-03-23 02:04:28,722] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:04:28,725] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.8428032e-03 4.6855037e-32 3.1911251e-28 9.9615723e-01 1.3564741e-22], sampled 0.11240448174826134
[2019-03-23 02:04:36,229] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8635.4062 2224739801.5461 325.0000
[2019-03-23 02:04:36,452] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7944.1864 2514505538.8846 471.0000
[2019-03-23 02:04:36,614] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8386.4455 2326977745.7359 367.0000
[2019-03-23 02:04:36,685] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8492.2950 2289757849.0494 355.0000
[2019-03-23 02:04:36,751] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8488.7290 2259228815.9438 319.0000
[2019-03-23 02:04:37,770] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1525000, evaluation results [1525000.0, 7944.186369961854, 2514505538.8845787, 471.0, 8488.728999034496, 2259228815.9437847, 319.0, 8635.406215233255, 2224739801.5460906, 325.0, 8386.445515243777, 2326977745.7359104, 367.0, 8492.29496613534, 2289757849.0494213, 355.0]
[2019-03-23 02:04:53,120] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:04:53,131] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5810
[2019-03-23 02:04:53,135] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.33333333333333, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6332158797375899, 6.9112, 6.9112, 121.9260426156618, 471938.9603949608, 471938.9603949608, 135187.200112147], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1730400.0000, 
sim time next is 1731000.0000, 
raw observation next is [21.31666666666667, 80.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.632644623602453, 6.9112, 6.9112, 121.9260426156618, 471526.4231619025, 471526.4231619025, 135144.5333236707], 
processed observation next is [1.0, 0.0, 0.34506172839506183, 0.8083333333333332, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5408057795030662, 0.0, 0.0, 0.8094621288201359, 0.16840229398639375, 0.16840229398639375, 0.25989333331475134], 
reward next is 0.7401, 
noisyNet noise sample is [array([-0.96027625], dtype=float32), -1.456644]. 
=============================================
[2019-03-23 02:04:53,147] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[69.04437 ]
 [69.1761  ]
 [69.285706]
 [69.461555]
 [69.65834 ]], R is [[69.01530457]
 [69.06517792]
 [69.11441803]
 [69.16312408]
 [69.21147919]].
[2019-03-23 02:05:00,125] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:05:00,131] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9250
[2019-03-23 02:05:00,139] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.51666666666667, 80.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7608873107576333, 6.911200000000001, 6.9112, 121.9260426156618, 566885.8206706478, 566885.8206706473, 154495.0604806403], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2074200.0000, 
sim time next is 2074800.0000, 
raw observation next is [23.43333333333334, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7578344721248951, 6.9112, 6.9112, 121.9260426156618, 564721.6582020267, 564721.6582020267, 154046.2701460315], 
processed observation next is [0.0, 0.0, 0.42345679012345705, 0.8066666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6972930901561188, 0.0, 0.0, 0.8094621288201359, 0.20168630650072383, 0.20168630650072383, 0.2962428272039067], 
reward next is 0.7038, 
noisyNet noise sample is [array([1.3914928], dtype=float32), 0.7580845]. 
=============================================
[2019-03-23 02:05:12,719] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:05:12,726] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3633
[2019-03-23 02:05:12,732] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.8, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.622964264554887, 6.9112, 6.9112, 121.9260426156618, 464033.160248418, 464033.160248418, 133902.6624090894], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2012400.0000, 
sim time next is 2013000.0000, 
raw observation next is [20.91666666666667, 83.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6242711628375406, 6.911200000000001, 6.9112, 121.9260426156618, 465047.9171999443, 465047.9171999439, 134071.4773130563], 
processed observation next is [0.0, 0.30434782608695654, 0.3302469135802471, 0.8316666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5303389535469257, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16608854185712296, 0.16608854185712282, 0.2578297640635698], 
reward next is 0.7422, 
noisyNet noise sample is [array([-0.5305112], dtype=float32), 1.2705016]. 
=============================================
[2019-03-23 02:05:12,756] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[69.514046]
 [69.52791 ]
 [69.55801 ]
 [69.58811 ]
 [69.61487 ]], R is [[69.51342773]
 [69.56078339]
 [69.60794067]
 [69.6550293 ]
 [69.70219421]].
[2019-03-23 02:05:25,266] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9999988e-01 5.0548092e-19 1.1676258e-29 9.2119052e-08 0.0000000e+00], sum to 1.0000
[2019-03-23 02:05:25,274] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2519
[2019-03-23 02:05:25,283] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1683162.846782544 W.
[2019-03-23 02:05:25,286] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.6, 81.0, 1.0, 2.0, 0.4919956033874386, 1.0, 2.0, 0.4919956033874386, 1.0, 1.0, 0.7832730237709682, 6.911200000000001, 6.9112, 121.94756008, 1683162.846782544, 1683162.846782544, 339677.7493195151], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2989800.0000, 
sim time next is 2990400.0000, 
raw observation next is [26.73333333333333, 85.33333333333333, 1.0, 2.0, 0.8222000149754288, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1652279.210160893, 1652279.210160893, 340686.7792479093], 
processed observation next is [1.0, 0.6086956521739131, 0.545679012345679, 0.8533333333333333, 1.0, 1.0, 0.7883333511612248, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.5900997179146046, 0.5900997179146046, 0.6551668831690564], 
reward next is 0.3448, 
noisyNet noise sample is [array([0.42931983], dtype=float32), 1.034476]. 
=============================================
[2019-03-23 02:05:30,101] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:05:30,107] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7955
[2019-03-23 02:05:30,110] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.2, 58.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6003127005395112, 6.9112, 6.9112, 121.9260426156618, 441477.4308393403, 441477.4308393403, 128047.323292474], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2442600.0000, 
sim time next is 2443200.0000, 
raw observation next is [23.76666666666667, 56.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5981736303992404, 6.911200000000001, 6.9112, 121.9260426156618, 440835.028431823, 440835.0284318225, 128323.5765179178], 
processed observation next is [1.0, 0.2608695652173913, 0.43580246913580256, 0.5633333333333332, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4977170379990505, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15744108158279393, 0.15744108158279374, 0.24677610868830346], 
reward next is 0.7532, 
noisyNet noise sample is [array([-1.1432676], dtype=float32), 0.40150058]. 
=============================================
[2019-03-23 02:05:30,448] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:05:30,457] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4428
[2019-03-23 02:05:30,463] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.78333333333333, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7710884590378766, 6.9112, 6.9112, 121.9260426156618, 574744.1121849389, 574744.1121849389, 155514.46150746], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2595000.0000, 
sim time next is 2595600.0000, 
raw observation next is [22.6, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7685365422880568, 6.911199999999999, 6.9112, 121.9260426156618, 572984.2352414648, 572984.2352414653, 155087.1769102272], 
processed observation next is [0.0, 0.043478260869565216, 0.39259259259259266, 0.86, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.710670677860071, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2046372268719517, 0.20463722687195188, 0.29824457098120616], 
reward next is 0.7018, 
noisyNet noise sample is [array([-0.4388179], dtype=float32), -1.3746903]. 
=============================================
[2019-03-23 02:05:31,458] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1818196e-11 5.3970172e-26 3.9521508e-30 1.0000000e+00 3.1799727e-36], sum to 1.0000
[2019-03-23 02:05:31,467] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1427
[2019-03-23 02:05:31,472] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.45, 23.5, 1.0, 2.0, 0.4125888387734631, 1.0, 1.0, 0.4125888387734631, 1.0, 2.0, 0.6655142535562454, 6.911199999999999, 6.9112, 121.94756008, 1483158.511061178, 1483158.511061179, 302257.8027859816], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2475000.0000, 
sim time next is 2475600.0000, 
raw observation next is [34.4, 23.66666666666667, 1.0, 2.0, 0.6354262058872194, 1.0, 2.0, 0.6354262058872194, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1532423.680241049, 1532423.68024105, 284064.8925572296], 
processed observation next is [1.0, 0.6521739130434783, 0.8296296296296296, 0.23666666666666672, 1.0, 1.0, 0.565983578437166, 1.0, 1.0, 0.565983578437166, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5472941715146604, 0.5472941715146608, 0.5462786395331338], 
reward next is 0.4537, 
noisyNet noise sample is [array([-0.18416715], dtype=float32), -1.0088503]. 
=============================================
[2019-03-23 02:05:31,894] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 02:05:31,895] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:05:31,896] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:05:31,896] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:05:31,897] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:05:31,898] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:05:31,899] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:05:31,901] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:05:31,900] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:05:31,904] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:05:31,908] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:05:31,931] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run63
[2019-03-23 02:05:31,964] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run63
[2019-03-23 02:05:31,991] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run63
[2019-03-23 02:05:32,018] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run63
[2019-03-23 02:05:32,018] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run63
[2019-03-23 02:06:19,878] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01410695], dtype=float32), -0.197053]
[2019-03-23 02:06:19,882] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.80137836, 90.65265356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6980760934386184, 6.911200000000001, 6.9112, 121.9260426156618, 521555.732729984, 521555.7327299835, 143844.2853582479]
[2019-03-23 02:06:19,886] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:06:19,891] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8543217244507179
[2019-03-23 02:06:38,921] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01410695], dtype=float32), -0.197053]
[2019-03-23 02:06:38,924] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.50584809, 73.74529512666668, 1.0, 2.0, 1.00974354616325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.328558893072194, 6.9112, 121.9242776414178, 1387904.553591264, 1174182.591060058, 244360.9386597299]
[2019-03-23 02:06:38,928] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:06:38,931] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.32404608e-01 3.29897604e-33 1.22579224e-26 5.67595363e-01
 6.87792450e-22], sampled 0.8089695826293517
[2019-03-23 02:06:44,314] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01410695], dtype=float32), -0.197053]
[2019-03-23 02:06:44,314] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.62740352666667, 89.33273792666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8302580159261017, 6.9112, 6.9112, 121.9260426156618, 612390.4694835227, 612390.4694835227, 165731.4663249676]
[2019-03-23 02:06:44,318] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:06:44,321] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7946361066041686
[2019-03-23 02:06:49,353] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01410695], dtype=float32), -0.197053]
[2019-03-23 02:06:49,355] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.25546763, 77.23880243666667, 1.0, 2.0, 0.6794403702255292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 787921.1978173066, 787921.1978173066, 172953.0280601283]
[2019-03-23 02:06:49,356] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:06:49,359] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 1.6190845e-38 6.8556820e-18 4.3309062e-33], sampled 0.32733834958473407
[2019-03-23 02:06:49,360] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 787921.1978173066 W.
[2019-03-23 02:06:50,608] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01410695], dtype=float32), -0.197053]
[2019-03-23 02:06:50,609] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.65, 96.0, 1.0, 2.0, 0.7679308803539852, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1590338.597442181, 1590338.597442181, 329951.9015514805]
[2019-03-23 02:06:50,609] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:06:50,614] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.7403685e-04 0.0000000e+00 0.0000000e+00 9.9952602e-01 0.0000000e+00], sampled 0.26677890716816277
[2019-03-23 02:06:53,817] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01410695], dtype=float32), -0.197053]
[2019-03-23 02:06:53,820] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.93667541333334, 90.42427079333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9098311222420504, 6.9112, 6.9112, 121.9260426156618, 664836.3821076797, 664836.3821076797, 177458.2733887272]
[2019-03-23 02:06:53,822] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:06:53,826] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.10792315154074561
[2019-03-23 02:07:07,930] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01410695], dtype=float32), -0.197053]
[2019-03-23 02:07:07,931] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.85, 28.5, 1.0, 2.0, 0.4011738543253532, 1.0, 2.0, 0.4011738543253532, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1002156.222509685, 1002156.222509685, 209655.7801965676]
[2019-03-23 02:07:07,933] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:07:07,936] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.4143514e-05 7.2056051e-38 2.5293660e-31 9.9992585e-01 8.0371373e-25], sampled 0.37829402391333
[2019-03-23 02:07:12,950] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01410695], dtype=float32), -0.197053]
[2019-03-23 02:07:12,953] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.66666666666667, 86.66666666666667, 1.0, 2.0, 0.5191829500941609, 1.0, 1.0, 0.5191829500941609, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 122.5297800111916, 1183736.741761622, 1183736.741761622, 241467.6240433085]
[2019-03-23 02:07:12,955] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:07:12,960] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3930244e-13 0.0000000e+00 0.0000000e+00 1.0000000e+00 1.1486057e-32], sampled 0.14886769207623896
[2019-03-23 02:07:14,425] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01410695], dtype=float32), -0.197053]
[2019-03-23 02:07:14,426] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.22199239, 73.96904444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9404548851935008, 6.9112, 6.9112, 121.9260426156618, 685024.8142746498, 685024.8142746498, 182000.2541109691]
[2019-03-23 02:07:14,426] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:07:14,430] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3033321241677174
[2019-03-23 02:07:23,341] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8638.6882 2246962150.7606 345.0000
[2019-03-23 02:07:23,918] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8704.5773 2211055528.9986 371.0000
[2019-03-23 02:07:24,108] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8540.4639 2277007931.9867 454.0000
[2019-03-23 02:07:24,135] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8508.8929 2314968587.4176 393.0000
[2019-03-23 02:07:24,181] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8060.2372 2502148467.4207 522.0000
[2019-03-23 02:07:25,198] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1550000, evaluation results [1550000.0, 8060.237235032415, 2502148467.420744, 522.0, 8638.688228329516, 2246962150.760642, 345.0, 8704.577335671886, 2211055528.998564, 371.0, 8508.892928080075, 2314968587.4176087, 393.0, 8540.463901557607, 2277007931.9867063, 454.0]
[2019-03-23 02:07:28,889] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9999976e-01 6.6798447e-20 3.2096718e-21 2.6128004e-07 3.0867459e-14], sum to 1.0000
[2019-03-23 02:07:28,895] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4483
[2019-03-23 02:07:28,905] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1365076.079200646 W.
[2019-03-23 02:07:28,910] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.53333333333333, 40.66666666666667, 1.0, 2.0, 0.3813745104111486, 1.0, 1.0, 0.3813745104111486, 1.0, 2.0, 0.6138467256349587, 6.9112, 6.9112, 121.94756008, 1365076.079200646, 1365076.079200646, 288711.7419537174], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2536800.0000, 
sim time next is 2537400.0000, 
raw observation next is [29.71666666666667, 39.83333333333333, 1.0, 2.0, 0.5699146093001092, 1.0, 2.0, 0.5699146093001092, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1369229.090167162, 1369229.090167162, 260860.9532699205], 
processed observation next is [1.0, 0.34782608695652173, 0.6561728395061729, 0.39833333333333326, 1.0, 1.0, 0.48799358250013, 1.0, 1.0, 0.48799358250013, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.489010389345415, 0.489010389345415, 0.5016556793652317], 
reward next is 0.4983, 
noisyNet noise sample is [array([0.6371563], dtype=float32), 0.5858862]. 
=============================================
[2019-03-23 02:07:35,487] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8023507e-31 0.0000000e+00 0.0000000e+00 1.0000000e+00 1.2570116e-37], sum to 1.0000
[2019-03-23 02:07:35,495] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2857
[2019-03-23 02:07:35,498] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.40000000000001, 30.0, 1.0, 2.0, 0.6412368339207286, 1.0, 2.0, 0.6412368339207286, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1543250.768526138, 1543250.768526139, 286066.5255548644], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2547600.0000, 
sim time next is 2548200.0000, 
raw observation next is [32.5, 30.0, 1.0, 2.0, 0.6483148877225693, 1.0, 2.0, 0.6483148877225693, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1558333.299169872, 1558333.299169872, 288586.6434166981], 
processed observation next is [1.0, 0.4782608695652174, 0.7592592592592593, 0.3, 1.0, 1.0, 0.5813272472887729, 1.0, 1.0, 0.5813272472887729, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5565476068463828, 0.5565476068463828, 0.5549743142628809], 
reward next is 0.4450, 
noisyNet noise sample is [array([-0.43623504], dtype=float32), 0.073677115]. 
=============================================
[2019-03-23 02:07:36,952] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.3314887e-21 2.7825471e-34 2.1942534e-17 2.3519212e-37], sum to 1.0000
[2019-03-23 02:07:36,959] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0601
[2019-03-23 02:07:36,970] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2283977.986879861 W.
[2019-03-23 02:07:36,976] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.35, 63.0, 1.0, 2.0, 1.001088005030623, 1.0, 2.0, 1.001088005030623, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2283977.986879861, 2283977.986879862, 433854.0528627922], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2806200.0000, 
sim time next is 2806800.0000, 
raw observation next is [31.56666666666667, 63.0, 1.0, 2.0, 0.7491673676490243, 1.0, 2.0, 0.6879483458009469, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2354419.018295262, 2354419.018295261, 442713.4921089678], 
processed observation next is [1.0, 0.4782608695652174, 0.7246913580246915, 0.63, 1.0, 1.0, 0.7013897233916955, 1.0, 1.0, 0.6285099354773177, 1.0, 0.5, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.8408639351054508, 0.8408639351054504, 0.8513721002095535], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.05609566], dtype=float32), -2.9639761]. 
=============================================
[2019-03-23 02:07:39,027] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:07:39,037] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2299
[2019-03-23 02:07:39,042] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.28333333333333, 93.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7432691477099088, 6.911200000000001, 6.9112, 121.9260426156618, 554976.0192901063, 554976.0192901058, 151157.0499057712], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2602200.0000, 
sim time next is 2602800.0000, 
raw observation next is [21.2, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7415302778340288, 6.911199999999999, 6.9112, 121.9260426156618, 553714.780050567, 553714.7800505675, 150896.7007057587], 
processed observation next is [0.0, 0.13043478260869565, 0.34074074074074073, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6769128472925359, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19775527858948821, 0.19775527858948838, 0.2901859628956898], 
reward next is 0.7098, 
noisyNet noise sample is [array([2.552046], dtype=float32), -1.681785]. 
=============================================
[2019-03-23 02:07:46,897] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:07:46,904] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7215
[2019-03-23 02:07:46,914] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.95, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9327908148240435, 6.911199999999999, 6.9112, 121.9260426156618, 676356.3763318693, 676356.3763318697, 181429.0719507564], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2725800.0000, 
sim time next is 2726400.0000, 
raw observation next is [30.9, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9455159541854473, 6.9112, 6.9112, 121.9260426156618, 683665.0395828513, 683665.0395828513, 183442.317879582], 
processed observation next is [0.0, 0.5652173913043478, 0.7, 0.54, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9318949427318091, 0.0, 0.0, 0.8094621288201359, 0.24416608556530406, 0.24416608556530406, 0.35277368822996535], 
reward next is 0.6472, 
noisyNet noise sample is [array([-0.8744235], dtype=float32), -0.4229301]. 
=============================================
[2019-03-23 02:07:54,403] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.3497440e-25 6.1510864e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 02:07:54,410] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4890
[2019-03-23 02:07:54,416] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 992859.2566502491 W.
[2019-03-23 02:07:54,420] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 86.0, 1.0, 2.0, 0.2878972648483882, 1.0, 2.0, 0.2878972648483882, 1.0, 1.0, 0.4586297034320801, 6.9112, 6.9112, 121.94756008, 992859.2566502491, 992859.2566502491, 251493.1719098107], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3587400.0000, 
sim time next is 3588000.0000, 
raw observation next is [24.0, 87.0, 1.0, 2.0, 0.2952376765686073, 1.0, 2.0, 0.2952376765686073, 1.0, 2.0, 0.4701415240774079, 6.911199999999999, 6.9112, 121.94756008, 1013839.170508198, 1013839.170508198, 254257.9473956356], 
processed observation next is [1.0, 0.5217391304347826, 0.4444444444444444, 0.87, 1.0, 1.0, 0.16099723401024676, 1.0, 1.0, 0.16099723401024676, 1.0, 1.0, 0.33767690509675985, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.36208541803864214, 0.36208541803864214, 0.48895759114545306], 
reward next is 0.5110, 
noisyNet noise sample is [array([-0.21075931], dtype=float32), 1.7028178]. 
=============================================
[2019-03-23 02:07:54,441] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[22.614653]
 [22.484058]
 [21.96104 ]
 [21.575853]
 [21.65354 ]], R is [[23.54773331]
 [23.82861519]
 [24.16645813]
 [24.439188  ]
 [24.19479561]].
[2019-03-23 02:07:56,898] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:07:56,909] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6684
[2019-03-23 02:07:56,917] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1438137.218814159 W.
[2019-03-23 02:07:56,921] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 43.0, 1.0, 2.0, 0.4159900648688818, 1.0, 2.0, 0.4159900648688818, 1.0, 2.0, 0.662852295231918, 6.9112, 6.9112, 121.94756008, 1438137.218814159, 1438137.218814159, 304235.5522275103], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3146400.0000, 
sim time next is 3147000.0000, 
raw observation next is [31.31666666666667, 41.16666666666667, 1.0, 2.0, 0.7673084868688902, 1.0, 2.0, 0.7673084868688902, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1787955.52139396, 1787955.521393959, 332343.5599470534], 
processed observation next is [1.0, 0.43478260869565216, 0.7154320987654322, 0.41166666666666674, 1.0, 1.0, 0.7229862938915359, 1.0, 1.0, 0.7229862938915359, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6385555433549858, 0.6385555433549853, 0.6391222306674104], 
reward next is 0.3609, 
noisyNet noise sample is [array([1.3628315], dtype=float32), -2.8769686]. 
=============================================
[2019-03-23 02:07:56,933] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[40.60893 ]
 [40.415325]
 [40.498924]
 [39.15246 ]
 [38.90682 ]], R is [[39.18359756]
 [39.20669556]
 [39.23622894]
 [39.27401352]
 [39.30717468]].
[2019-03-23 02:07:57,784] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:07:57,793] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1209
[2019-03-23 02:07:57,802] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 771690.6894540576 W.
[2019-03-23 02:07:57,807] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3385506015944161, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5389835835616517, 6.911199999999999, 6.9112, 121.9260426156618, 771690.6894540576, 771690.6894540581, 205895.6451673593], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2959200.0000, 
sim time next is 2959800.0000, 
raw observation next is [25.0, 94.00000000000001, 1.0, 2.0, 0.3914614391139913, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6232193600784914, 6.911199999999999, 6.9112, 121.9260426156618, 892365.6193357643, 892365.6193357648, 221480.1514768349], 
processed observation next is [1.0, 0.2608695652173913, 0.48148148148148145, 0.9400000000000002, 1.0, 1.0, 0.27554933227856104, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5290242000981142, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3187020069056301, 0.3187020069056303, 0.4259233682246825], 
reward next is 0.5741, 
noisyNet noise sample is [array([-0.75641936], dtype=float32), -1.4422885]. 
=============================================
[2019-03-23 02:07:59,081] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:07:59,089] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9109
[2019-03-23 02:07:59,099] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 764277.5174201874 W.
[2019-03-23 02:07:59,101] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.83333333333334, 65.33333333333334, 1.0, 2.0, 0.3352999685376626, 1.0, 1.0, 0.3352999685376626, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 764277.5174201874, 764277.5174201874, 189148.0244542826], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3183000.0000, 
sim time next is 3183600.0000, 
raw observation next is [29.86666666666667, 62.66666666666667, 1.0, 2.0, 0.3304029768553726, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5260122996274816, 6.911199999999999, 6.9112, 121.9260426156618, 753109.9075532989, 753109.9075532993, 203595.4228846611], 
processed observation next is [1.0, 0.8695652173913043, 0.6617283950617285, 0.6266666666666667, 1.0, 1.0, 0.20286068673258645, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.407515374534352, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26896782412617815, 0.2689678241261783, 0.39152965939357903], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.44046524], dtype=float32), 0.9313478]. 
=============================================
[2019-03-23 02:08:04,130] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:08:04,140] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6036
[2019-03-23 02:08:04,147] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 893865.1696690981 W.
[2019-03-23 02:08:04,150] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 55.5, 1.0, 2.0, 0.377738277818597, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6058859495661395, 6.911200000000001, 6.9112, 121.9260425733795, 893865.1696690981, 893865.1696690976, 216453.2207260136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3137400.0000, 
sim time next is 3138000.0000, 
raw observation next is [28.86666666666667, 54.66666666666666, 1.0, 2.0, 0.7332679355955753, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156489, 869285.7292148967, 869285.7292148962, 184116.5074318761], 
processed observation next is [1.0, 0.30434782608695654, 0.6246913580246916, 0.5466666666666665, 1.0, 1.0, 0.6824618280899707, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288200503, 0.31045918900532027, 0.3104591890053201, 0.3540702065997617], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6669397], dtype=float32), 0.6961301]. 
=============================================
[2019-03-23 02:08:04,164] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[40.65039 ]
 [43.76476 ]
 [50.543808]
 [49.412094]
 [46.275024]], R is [[38.56750107]
 [38.18182755]
 [38.44971466]
 [38.06521606]
 [38.35503387]].
[2019-03-23 02:08:06,249] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:08:06,257] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8522
[2019-03-23 02:08:06,269] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 690162.6960387002 W.
[2019-03-23 02:08:06,274] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9453157664262303, 6.9112, 6.9112, 121.9260426156618, 690162.6960387002, 690162.6960387002, 182386.1243527342], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3049200.0000, 
sim time next is 3049800.0000, 
raw observation next is [23.26666666666667, 98.50000000000001, 1.0, 1.0, 0.3922288565963776, 0.0, 2.0, 0.0, 1.0, 2.0, 0.624766377449541, 6.9112, 6.9112, 121.9260426156618, 900784.506433656, 900784.506433656, 221608.0051276692], 
processed observation next is [1.0, 0.30434782608695654, 0.41728395061728407, 0.9850000000000001, 1.0, 0.5, 0.2764629245194971, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5309579718119262, 0.0, 0.0, 0.8094621288201359, 0.32170875229773427, 0.32170875229773427, 0.42616924063013306], 
reward next is 0.5738, 
noisyNet noise sample is [array([-1.2994002], dtype=float32), -0.3663221]. 
=============================================
[2019-03-23 02:08:06,282] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:08:06,288] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4344
[2019-03-23 02:08:06,294] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 690162.6960387002 W.
[2019-03-23 02:08:06,302] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9453157664725405, 6.9112, 6.9112, 121.9260426156618, 690162.6960387002, 690162.6960387002, 182386.1243653534], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3049200.0000, 
sim time next is 3049800.0000, 
raw observation next is [23.26666666666667, 98.50000000000001, 1.0, 1.0, 0.776857521725268, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 900784.506433656, 900784.506433656, 191983.0466322753], 
processed observation next is [1.0, 0.30434782608695654, 0.41728395061728407, 0.9850000000000001, 1.0, 0.5, 0.7343541925300809, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32170875229773427, 0.32170875229773427, 0.36919816660052945], 
reward next is 0.6308, 
noisyNet noise sample is [array([0.5341642], dtype=float32), 0.8792657]. 
=============================================
[2019-03-23 02:08:08,155] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 9.8537059e-26 2.5627461e-35 6.3308436e-20], sum to 1.0000
[2019-03-23 02:08:08,166] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1897
[2019-03-23 02:08:08,172] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 793395.4481353826 W.
[2019-03-23 02:08:08,175] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.86666666666667, 72.66666666666666, 1.0, 2.0, 0.3480678319571622, 1.0, 1.0, 0.3480678319571622, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 793395.4481353826, 793395.4481353826, 192396.4786146027], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3343200.0000, 
sim time next is 3343800.0000, 
raw observation next is [28.83333333333333, 73.33333333333334, 1.0, 2.0, 0.3513826486711554, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5594126204184181, 6.9112, 6.9112, 121.9260426156618, 800955.2809435166, 800955.2809435166, 209574.1197273224], 
processed observation next is [0.0, 0.6956521739130435, 0.6234567901234566, 0.7333333333333334, 1.0, 1.0, 0.2278364865132802, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4492657755230226, 0.0, 0.0, 0.8094621288201359, 0.28605545747982736, 0.28605545747982736, 0.40302715332177386], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7321707], dtype=float32), 0.14329478]. 
=============================================
[2019-03-23 02:08:08,447] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.6403055e-04 1.5520635e-21 1.3028024e-13 4.2672427e-03 9.9516875e-01], sum to 1.0000
[2019-03-23 02:08:08,455] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9942
[2019-03-23 02:08:08,461] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.83333333333333, 85.66666666666667, 1.0, 2.0, 0.5060281644629017, 1.0, 2.0, 0.5060281644629017, 1.0, 2.0, 0.8056133180117143, 6.911199999999998, 6.9112, 121.94756008, 1731216.056272424, 1731216.056272425, 346557.5921381009], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3084600.0000, 
sim time next is 3085200.0000, 
raw observation next is [28.2, 86.0, 1.0, 2.0, 0.5134994563009349, 1.0, 2.0, 0.5134994563009349, 1.0, 2.0, 0.817507857940851, 6.911199999999999, 6.9112, 121.94756008, 1756801.859565376, 1756801.859565376, 350264.1515176966], 
processed observation next is [1.0, 0.7391304347826086, 0.6, 0.86, 1.0, 1.0, 0.4208326860725415, 1.0, 1.0, 0.4208326860725415, 1.0, 1.0, 0.7718848224260638, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6274292355590629, 0.6274292355590629, 0.6735849067648012], 
reward next is 0.3264, 
noisyNet noise sample is [array([-0.9847529], dtype=float32), -0.008137177]. 
=============================================
[2019-03-23 02:08:17,949] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 4.626316e-23], sum to 1.0000
[2019-03-23 02:08:17,959] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3486
[2019-03-23 02:08:17,968] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 695763.7260453556 W.
[2019-03-23 02:08:17,973] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 84.0, 1.0, 2.0, 0.303946906471278, 0.0, 2.0, 0.0, 1.0, 2.0, 0.484014213104775, 6.911199999999999, 6.9112, 121.9260426156618, 695763.7260453556, 695763.726045356, 196259.541134798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3273600.0000, 
sim time next is 3274200.0000, 
raw observation next is [25.0, 86.5, 1.0, 2.0, 0.6048049231293663, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696634.2781127237, 696634.2781127237, 159265.7226513489], 
processed observation next is [0.0, 0.9130434782608695, 0.48148148148148145, 0.865, 1.0, 1.0, 0.5295296703921027, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2487979564688299, 0.2487979564688299, 0.30628023586797865], 
reward next is 0.6937, 
noisyNet noise sample is [array([0.00821804], dtype=float32), -0.45354682]. 
=============================================
[2019-03-23 02:08:20,053] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 02:08:20,055] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:08:20,055] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:08:20,057] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:08:20,057] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:08:20,059] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:08:20,058] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:08:20,060] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:08:20,061] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:08:20,062] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:08:20,062] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:08:20,079] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run64
[2019-03-23 02:08:20,107] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run64
[2019-03-23 02:08:20,138] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run64
[2019-03-23 02:08:20,138] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run64
[2019-03-23 02:08:20,138] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run64
[2019-03-23 02:09:17,768] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0465072], dtype=float32), -0.1660379]
[2019-03-23 02:09:17,769] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.07753618833333, 99.59636420833334, 1.0, 2.0, 0.451661231007772, 1.0, 1.0, 0.451661231007772, 1.0, 1.0, 0.7190593893437377, 6.911200000000001, 6.9112, 121.94756008, 1545050.574456597, 1545050.574456597, 320451.4284589029]
[2019-03-23 02:09:17,770] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:09:17,771] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.1574606e-14 0.0000000e+00 2.7092382e-27 1.2559651e-17 1.0000000e+00], sampled 0.5951152904251965
[2019-03-23 02:09:26,798] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0465072], dtype=float32), -0.1660379]
[2019-03-23 02:09:26,799] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.36853972, 90.93631613, 1.0, 2.0, 0.7800293528615193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 921624.3010335641, 921624.3010335641, 193425.16211054]
[2019-03-23 02:09:26,802] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:09:26,806] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3274416e-36], sampled 0.9363377954658625
[2019-03-23 02:09:26,807] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 921624.3010335641 W.
[2019-03-23 02:09:41,437] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0465072], dtype=float32), -0.1660379]
[2019-03-23 02:09:41,438] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [34.58333333333334, 35.66666666666666, 1.0, 2.0, 0.7243107745182298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 848353.3711545281, 848353.3711545276, 181905.1600008894]
[2019-03-23 02:09:41,439] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:09:41,442] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 5.9049363e-35 0.0000000e+00 1.6240215e-22], sampled 0.811930984290389
[2019-03-23 02:09:41,443] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 848353.3711545281 W.
[2019-03-23 02:09:46,190] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0465072], dtype=float32), -0.1660379]
[2019-03-23 02:09:46,191] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.1, 82.83333333333333, 1.0, 2.0, 0.4543072392062569, 1.0, 2.0, 0.4543072392062569, 1.0, 2.0, 0.7232719205701966, 6.9112, 6.9112, 121.94756008, 1554111.268977006, 1554111.268977006, 321688.1044548217]
[2019-03-23 02:09:46,192] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:09:46,194] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.4113847e-01 0.0000000e+00 6.5051881e-28 3.7225147e-20 4.5886162e-01], sampled 0.23260520287272135
[2019-03-23 02:09:46,195] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1554111.268977006 W.
[2019-03-23 02:10:08,655] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8615.1495 2271356792.3249 389.0000
[2019-03-23 02:10:08,736] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8414.6821 2350591843.3653 451.0000
[2019-03-23 02:10:08,742] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8464.6718 2309306537.1854 523.0000
[2019-03-23 02:10:08,982] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7946.2607 2546126969.0533 556.0000
[2019-03-23 02:10:09,031] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8680.6427 2232356900.9776 426.0000
[2019-03-23 02:10:10,046] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1575000, evaluation results [1575000.0, 7946.260696188486, 2546126969.053281, 556.0, 8615.14953068558, 2271356792.32489, 389.0, 8680.642671035941, 2232356900.977598, 426.0, 8414.682095445158, 2350591843.365341, 451.0, 8464.671813186067, 2309306537.1853523, 523.0]
[2019-03-23 02:10:12,467] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0865284e-20 0.0000000e+00 1.0406950e-33 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 02:10:12,473] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0662
[2019-03-23 02:10:12,478] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.41666666666667, 77.33333333333333, 1.0, 2.0, 0.2210312968430891, 1.0, 2.0, 0.2210312968430891, 1.0, 2.0, 0.3518890230609835, 6.9112, 6.9112, 121.94756008, 755718.6519634742, 755718.6519634742, 227587.890966316], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3334200.0000, 
sim time next is 3334800.0000, 
raw observation next is [27.73333333333333, 76.66666666666667, 1.0, 2.0, 0.2241685578160013, 1.0, 2.0, 0.2241685578160013, 1.0, 2.0, 0.3568836447033165, 6.911199999999999, 6.9112, 121.94756008, 766450.4885719663, 766450.4885719668, 228652.287939792], 
processed observation next is [0.0, 0.6086956521739131, 0.5827160493827159, 0.7666666666666667, 1.0, 1.0, 0.07639114025714441, 1.0, 1.0, 0.07639114025714441, 1.0, 1.0, 0.19610455587914563, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2737323173471308, 0.273732317347131, 0.43971593834575384], 
reward next is 0.5603, 
noisyNet noise sample is [array([-0.9503982], dtype=float32), -1.5208325]. 
=============================================
[2019-03-23 02:10:12,665] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 5.2632654e-37 3.6024023e-30 0.0000000e+00 8.3454463e-14], sum to 1.0000
[2019-03-23 02:10:12,675] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5952
[2019-03-23 02:10:12,686] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 760208.5766407849 W.
[2019-03-23 02:10:12,694] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 95.0, 1.0, 2.0, 0.333515748178464, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5309679329497277, 6.911200000000001, 6.9112, 121.9260426156618, 760208.5766407849, 760208.5766407844, 204471.1241771349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4050600.0000, 
sim time next is 4051200.0000, 
raw observation next is [24.66666666666667, 96.0, 1.0, 2.0, 0.667338971105306, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 760559.1761341041, 760559.1761341041, 170051.2911945941], 
processed observation next is [1.0, 0.9130434782608695, 0.469135802469136, 0.96, 1.0, 1.0, 0.6039749656015548, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2716282771907515, 0.2716282771907515, 0.32702171383575784], 
reward next is 0.6730, 
noisyNet noise sample is [array([-1.0726813], dtype=float32), 0.06442319]. 
=============================================
[2019-03-23 02:10:13,527] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 3.4771235e-28 0.0000000e+00 1.5473219e-33], sum to 1.0000
[2019-03-23 02:10:13,533] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7660
[2019-03-23 02:10:13,543] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 899159.3681744118 W.
[2019-03-23 02:10:13,549] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.3944399620760723, 1.0, 1.0, 0.3944399620760723, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 899159.3681744118, 899159.3681744123, 204667.8470406949], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3466800.0000, 
sim time next is 3467400.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.440089223683476, 1.0, 2.0, 0.440089223683476, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1003288.853514357, 1003288.853514358, 217476.5017863077], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 1.0, 1.0, 1.0, 0.3334395520041381, 1.0, 1.0, 0.3334395520041381, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.35831744768369894, 0.35831744768369933, 0.41822404189674556], 
reward next is 0.5818, 
noisyNet noise sample is [array([-0.40011567], dtype=float32), 0.36918613]. 
=============================================
[2019-03-23 02:10:15,095] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9789435e-01 1.5540874e-03 5.5131793e-04 2.2492535e-37 2.0148069e-07], sum to 1.0000
[2019-03-23 02:10:15,108] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8474
[2019-03-23 02:10:15,115] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2192961.806154743 W.
[2019-03-23 02:10:15,121] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.7, 59.16666666666667, 1.0, 2.0, 0.6549292638610595, 1.0, 2.0, 0.6408292939069644, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2192961.806154743, 2192961.806154743, 417348.3847740646], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3423000.0000, 
sim time next is 3423600.0000, 
raw observation next is [32.0, 59.0, 1.0, 2.0, 0.989498201301118, 1.0, 2.0, 0.989498201301118, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2257502.467510733, 2257502.467510733, 428280.4945331714], 
processed observation next is [1.0, 0.6521739130434783, 0.7407407407407407, 0.59, 1.0, 1.0, 0.9874978586918072, 1.0, 1.0, 0.9874978586918072, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.8062508812538332, 0.8062508812538332, 0.8236163356407142], 
reward next is 0.1764, 
noisyNet noise sample is [array([-0.4199511], dtype=float32), -1.2179383]. 
=============================================
[2019-03-23 02:10:18,090] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.9527363e-24 0.0000000e+00 2.0552353e-30 1.1077619e-28 1.0000000e+00], sum to 1.0000
[2019-03-23 02:10:18,099] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0766
[2019-03-23 02:10:18,104] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.26666666666667, 68.66666666666667, 1.0, 2.0, 0.6958518600857034, 1.0, 1.0, 0.6612905920192865, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2263070.49974317, 2263070.49974317, 428127.2577867082], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3763200.0000, 
sim time next is 3763800.0000, 
raw observation next is [32.4, 67.5, 1.0, 2.0, 0.7536476228266741, 1.0, 2.0, 0.6901884733897716, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2362095.722280813, 2362095.722280813, 443967.205504767], 
processed observation next is [1.0, 0.5652173913043478, 0.7555555555555555, 0.675, 1.0, 1.0, 0.7067233605079454, 1.0, 1.0, 0.6311767540354424, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.8436056151002903, 0.8436056151002903, 0.8537830875091673], 
reward next is 0.1462, 
noisyNet noise sample is [array([-0.17438315], dtype=float32), 0.37992486]. 
=============================================
[2019-03-23 02:10:20,604] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.9815883e-20 0.0000000e+00 6.3076425e-31 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 02:10:20,608] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5137
[2019-03-23 02:10:20,616] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.5, 88.0, 1.0, 2.0, 0.4744943076771493, 1.0, 2.0, 0.4744943076771493, 1.0, 2.0, 0.7554103910227786, 6.911200000000001, 6.9112, 121.94756008, 1623234.897167994, 1623234.897167993, 331247.0263703177], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3487200.0000, 
sim time next is 3487800.0000, 
raw observation next is [26.75, 88.5, 1.0, 2.0, 0.4970125553114929, 1.0, 2.0, 0.4970125553114929, 1.0, 2.0, 0.7912601746247799, 6.9112, 6.9112, 121.94756008, 1700342.638511725, 1700342.638511725, 342125.178478163], 
processed observation next is [1.0, 0.34782608695652173, 0.5462962962962963, 0.885, 1.0, 1.0, 0.4012054229898725, 1.0, 1.0, 0.4012054229898725, 1.0, 1.0, 0.7390752182809748, 0.0, 0.0, 0.8096049824067558, 0.6072652280399018, 0.6072652280399018, 0.6579330355349289], 
reward next is 0.3421, 
noisyNet noise sample is [array([0.8422488], dtype=float32), -1.0256207]. 
=============================================
[2019-03-23 02:10:21,643] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.4579837e-36], sum to 1.0000
[2019-03-23 02:10:21,649] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2864
[2019-03-23 02:10:21,652] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.33333333333333, 96.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9131790264720923, 6.911200000000001, 6.9112, 121.9260426156618, 666760.5378339073, 666760.5378339068, 178005.8491617356], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3620400.0000, 
sim time next is 3621000.0000, 
raw observation next is [23.16666666666667, 98.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9202438241519169, 6.911199999999999, 6.9112, 121.9260426156618, 671256.3374725258, 671256.3374725262, 179078.5231940151], 
processed observation next is [1.0, 0.9130434782608695, 0.4135802469135804, 0.9816666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9003047801898961, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23973440624018777, 0.23973440624018794, 0.344381775373106], 
reward next is 0.6556, 
noisyNet noise sample is [array([-1.1067193], dtype=float32), 0.39846858]. 
=============================================
[2019-03-23 02:10:21,671] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[69.36694 ]
 [69.21767 ]
 [69.090126]
 [68.90216 ]
 [68.84089 ]], R is [[69.52534485]
 [69.48777771]
 [69.45362854]
 [69.42279816]
 [69.39478302]].
[2019-03-23 02:10:21,688] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9584514e-01 2.7312095e-36 7.1513616e-22 4.7685710e-33 4.1548447e-03], sum to 1.0000
[2019-03-23 02:10:21,694] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8446
[2019-03-23 02:10:21,703] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2068984.366896157 W.
[2019-03-23 02:10:21,710] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.25, 79.0, 1.0, 2.0, 0.6046424118394029, 1.0, 2.0, 0.6046424118394029, 1.0, 2.0, 0.9626104114769249, 6.9112, 6.9112, 121.94756008, 2068984.366896157, 2068984.366896157, 397910.8224365154], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3504600.0000, 
sim time next is 3505200.0000, 
raw observation next is [28.33333333333334, 79.0, 1.0, 2.0, 0.8111086152338939, 1.0, 2.0, 0.8111086152338939, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1850091.812933765, 1850091.812933766, 348366.7538059021], 
processed observation next is [1.0, 0.5652173913043478, 0.6049382716049385, 0.79, 1.0, 1.0, 0.7751293038498737, 1.0, 1.0, 0.7751293038498737, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6607470760477732, 0.6607470760477736, 0.6699360650113502], 
reward next is 0.3301, 
noisyNet noise sample is [array([-0.07518813], dtype=float32), -0.20575936]. 
=============================================
[2019-03-23 02:10:29,004] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:10:29,015] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8203
[2019-03-23 02:10:29,022] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.16666666666666, 95.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8922125006494834, 6.911199999999999, 6.9112, 121.9260426156618, 653252.4559505237, 653252.4559505242, 174853.9624991521], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3635400.0000, 
sim time next is 3636000.0000, 
raw observation next is [23.2, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8858862541019882, 6.911199999999999, 6.9112, 121.9260426156618, 649299.0850802719, 649299.0850802724, 173876.011890106], 
processed observation next is [1.0, 0.08695652173913043, 0.4148148148148148, 0.95, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8573578176274851, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2318925303858114, 0.23189253038581156, 0.3343769459425115], 
reward next is 0.6656, 
noisyNet noise sample is [array([0.7695505], dtype=float32), -2.1644878]. 
=============================================
[2019-03-23 02:10:29,039] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[53.383442]
 [53.61476 ]
 [53.811302]
 [54.044292]
 [54.278435]], R is [[53.40794373]
 [53.53760529]
 [53.6641655 ]
 [53.78778839]
 [53.90857697]].
[2019-03-23 02:10:29,888] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.62395e-20 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00], sum to 1.0000
[2019-03-23 02:10:29,894] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3542
[2019-03-23 02:10:29,899] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.4, 94.0, 1.0, 2.0, 0.2643078533636837, 1.0, 2.0, 0.2643078533636837, 1.0, 2.0, 0.4207867104608194, 6.911200000000001, 6.9112, 121.94756008, 903770.8973776861, 903770.8973776856, 242756.0395595197], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3744000.0000, 
sim time next is 3744600.0000, 
raw observation next is [25.5, 94.00000000000001, 1.0, 2.0, 0.3625986105973163, 1.0, 2.0, 0.3625986105973163, 1.0, 2.0, 0.5772687970832446, 6.9112, 6.9112, 122.5299911778874, 1240132.229295962, 1240132.229295962, 281207.6547726683], 
processed observation next is [1.0, 0.34782608695652173, 0.5, 0.9400000000000002, 1.0, 1.0, 0.24118882213966225, 1.0, 1.0, 0.24118882213966225, 1.0, 1.0, 0.47158599635405574, 0.0, 0.0, 0.8134717192110751, 0.44290436760570073, 0.44290436760570073, 0.5407839514859006], 
reward next is 0.4592, 
noisyNet noise sample is [array([2.8116918], dtype=float32), 1.2754867]. 
=============================================
[2019-03-23 02:10:32,878] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 5.0743088e-32 5.5940884e-37 0.0000000e+00 5.7362699e-26], sum to 1.0000
[2019-03-23 02:10:32,884] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6727
[2019-03-23 02:10:32,894] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1580417.974371243 W.
[2019-03-23 02:10:32,898] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 86.0, 1.0, 2.0, 0.6929840465680214, 1.0, 2.0, 0.6929840465680214, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1580417.974371243, 1580417.974371243, 301517.5298989], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3679200.0000, 
sim time next is 3679800.0000, 
raw observation next is [26.16666666666667, 86.5, 1.0, 2.0, 0.7223236365931521, 1.0, 2.0, 0.7223236365931521, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1647391.67608052, 1647391.67608052, 312702.4510414298], 
processed observation next is [1.0, 0.6086956521739131, 0.5246913580246916, 0.865, 1.0, 1.0, 0.6694329007061335, 1.0, 1.0, 0.6694329007061335, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5883541700287571, 0.5883541700287571, 0.6013508673873651], 
reward next is 0.3986, 
noisyNet noise sample is [array([0.4091781], dtype=float32), 0.8910608]. 
=============================================
[2019-03-23 02:10:34,394] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.1316981e-28 5.1125736e-29 0.0000000e+00 1.8470437e-30], sum to 1.0000
[2019-03-23 02:10:34,401] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0126
[2019-03-23 02:10:34,407] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2093415.512622551 W.
[2019-03-23 02:10:34,413] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.15, 85.5, 1.0, 2.0, 0.6117738404916666, 1.0, 2.0, 0.6117738404916666, 1.0, 1.0, 0.9739638781457454, 6.911199999999999, 6.9112, 121.94756008, 2093415.512622551, 2093415.512622552, 401827.8999569556], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3753000.0000, 
sim time next is 3753600.0000, 
raw observation next is [28.53333333333333, 82.66666666666666, 1.0, 2.0, 0.5989910083423384, 1.0, 2.0, 0.5989910083423384, 1.0, 2.0, 0.9536131930562358, 6.911199999999999, 6.9112, 121.94756008, 2049624.027724799, 2049624.027724799, 394826.1178473246], 
processed observation next is [1.0, 0.43478260869565216, 0.6123456790123456, 0.8266666666666665, 1.0, 1.0, 0.5226083432646886, 1.0, 1.0, 0.5226083432646886, 1.0, 1.0, 0.9420164913202946, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7320085813302853, 0.7320085813302853, 0.7592809958602396], 
reward next is 0.2407, 
noisyNet noise sample is [array([-0.03736276], dtype=float32), -1.0995111]. 
=============================================
[2019-03-23 02:10:36,703] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.312623e-01 3.765482e-09 6.867788e-02 0.000000e+00 5.983479e-05], sum to 1.0000
[2019-03-23 02:10:36,709] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0878
[2019-03-23 02:10:36,713] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.26666666666667, 68.66666666666667, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 9.662776403130621, 6.9112, 121.9147184718023, 3288481.524021582, 1879559.34134802, 375459.3487038051], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3763200.0000, 
sim time next is 3763800.0000, 
raw observation next is [32.4, 67.5, 1.0, 2.0, 0.999533536427589, 1.0, 1.0, 0.8131314301902293, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2783510.796875895, 2783510.796875896, 519428.1788907829], 
processed observation next is [1.0, 0.5652173913043478, 0.7555555555555555, 0.675, 1.0, 1.0, 0.9994446862233203, 1.0, 0.5, 0.77753741689313, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.9941109988842483, 0.9941109988842486, 0.9989003440207362], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1947888], dtype=float32), 0.80703723]. 
=============================================
[2019-03-23 02:10:39,620] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 3.1270195e-36 0.0000000e+00 4.9210947e-33], sum to 1.0000
[2019-03-23 02:10:39,628] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9700
[2019-03-23 02:10:39,635] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 821176.5794920978 W.
[2019-03-23 02:10:39,643] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.25, 71.5, 1.0, 2.0, 0.7204981455042532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 821176.5794920978, 821176.5794920974, 180061.8103743869], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3927000.0000, 
sim time next is 3927600.0000, 
raw observation next is [29.5, 70.0, 1.0, 2.0, 0.3604551306872861, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5738563072582095, 6.911199999999999, 6.9112, 121.9260426156618, 821646.5339212943, 821646.5339212946, 212213.5971080771], 
processed observation next is [0.0, 0.4782608695652174, 0.6481481481481481, 0.7, 1.0, 1.0, 0.23863706034200724, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.4673203840727618, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2934451906861765, 0.29344519068617664, 0.4081030713616868], 
reward next is 0.5919, 
noisyNet noise sample is [array([-1.1435418], dtype=float32), -0.2867596]. 
=============================================
[2019-03-23 02:10:40,024] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:10:40,039] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5511
[2019-03-23 02:10:40,044] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.3, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9013496135720382, 6.911200000000001, 6.9112, 121.9260426156618, 660367.1617360744, 660367.1617360739, 175975.8671899716], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3817800.0000, 
sim time next is 3818400.0000, 
raw observation next is [26.4, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8875743831333509, 6.9112, 6.9112, 121.9260426156618, 652211.1241831966, 652211.1241831966, 173712.7769447136], 
processed observation next is [0.0, 0.17391304347826086, 0.5333333333333333, 0.71, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8594679789166887, 0.0, 0.0, 0.8094621288201359, 0.23293254435114163, 0.23293254435114163, 0.3340630325859877], 
reward next is 0.6659, 
noisyNet noise sample is [array([0.4307171], dtype=float32), 0.9244422]. 
=============================================
[2019-03-23 02:11:01,164] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:11:01,172] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7667
[2019-03-23 02:11:01,177] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.53333333333333, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9260901329852205, 6.911200000000001, 6.9112, 121.9260426156618, 672832.2769742921, 672832.2769742917, 180314.9925060815], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4304400.0000, 
sim time next is 4305000.0000, 
raw observation next is [29.41666666666667, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9351439384359131, 6.911199999999999, 6.9112, 121.9260426156618, 678489.2466698041, 678489.2466698046, 181690.5936804235], 
processed observation next is [1.0, 0.8260869565217391, 0.6450617283950619, 0.6, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9189299230448913, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24231758809635862, 0.24231758809635878, 0.3494049878469683], 
reward next is 0.6506, 
noisyNet noise sample is [array([-0.28112337], dtype=float32), 0.47273287]. 
=============================================
[2019-03-23 02:11:01,198] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[72.56427 ]
 [72.68642 ]
 [73.06344 ]
 [73.27526 ]
 [73.674515]], R is [[72.31510925]
 [72.24520111]
 [72.17793274]
 [72.11304474]
 [72.05038452]].
[2019-03-23 02:11:04,391] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1529494e-36], sum to 1.0000
[2019-03-23 02:11:04,401] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3732
[2019-03-23 02:11:04,406] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.46666666666667, 61.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7022619605257998, 6.9112, 6.9112, 121.9260426156618, 524795.0768329051, 524795.0768329051, 145067.4784956645], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4238400.0000, 
sim time next is 4239000.0000, 
raw observation next is [25.2, 62.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6998455430404165, 6.9112, 6.9112, 121.9260426156618, 522988.6780812491, 522988.6780812491, 144804.5073393174], 
processed observation next is [1.0, 0.043478260869565216, 0.4888888888888889, 0.625, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6248069288005206, 0.0, 0.0, 0.8094621288201359, 0.18678167074330326, 0.18678167074330326, 0.27847020642176423], 
reward next is 0.7215, 
noisyNet noise sample is [array([-0.4507161], dtype=float32), 0.10751658]. 
=============================================
[2019-03-23 02:11:04,426] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[58.327446]
 [58.322716]
 [58.440758]
 [58.549225]
 [58.768425]], R is [[58.51278305]
 [58.64867783]
 [58.78240585]
 [58.9127388 ]
 [59.03649139]].
[2019-03-23 02:11:04,642] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 02:11:04,643] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:11:04,643] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:11:04,643] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:11:04,644] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:11:04,645] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:11:04,645] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:11:04,646] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:11:04,647] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:11:04,648] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:11:04,649] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:11:04,676] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run65
[2019-03-23 02:11:04,704] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run65
[2019-03-23 02:11:04,736] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run65
[2019-03-23 02:11:04,737] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run65
[2019-03-23 02:11:04,737] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run65
[2019-03-23 02:11:42,950] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08234464], dtype=float32), -0.17686966]
[2019-03-23 02:11:42,952] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.73333333333334, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8764275240631775, 6.9112, 6.9112, 121.9260426156618, 643580.1953833711, 643580.1953833711, 172362.736605171]
[2019-03-23 02:11:42,953] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:11:42,955] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.590111018654093
[2019-03-23 02:11:45,318] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08234464], dtype=float32), -0.17686966]
[2019-03-23 02:11:45,320] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.43743058333333, 80.89860691, 1.0, 2.0, 0.2852831471454141, 1.0, 2.0, 0.2852831471454141, 1.0, 2.0, 0.4541800612789617, 6.911200000000001, 6.9112, 121.94756008, 975539.191886393, 975539.1918863925, 250484.0066559408]
[2019-03-23 02:11:45,321] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:11:45,325] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9467826e-01 0.0000000e+00 1.0885393e-21 0.0000000e+00 5.3217174e-03], sampled 0.3868813873765631
[2019-03-23 02:11:45,327] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 975539.191886393 W.
[2019-03-23 02:11:47,479] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08234464], dtype=float32), -0.17686966]
[2019-03-23 02:11:47,480] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.5, 74.0, 1.0, 2.0, 0.6242100204878405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 711382.7584300644, 711382.7584300644, 162291.3242194777]
[2019-03-23 02:11:47,480] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:11:47,484] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9871993e-01 0.0000000e+00 1.1131836e-23 0.0000000e+00 1.2801120e-03], sampled 0.5978987428038017
[2019-03-23 02:11:47,484] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 711382.7584300644 W.
[2019-03-23 02:11:57,753] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08234464], dtype=float32), -0.17686966]
[2019-03-23 02:11:57,757] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.12435057, 101.730893515, 1.0, 2.0, 0.2468782540751305, 1.0, 2.0, 0.2468782540751305, 1.0, 2.0, 0.3930382207510229, 6.9112, 6.9112, 121.94756008, 844139.5322828338, 844139.5322828338, 236521.2254784126]
[2019-03-23 02:11:57,758] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:11:57,759] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.333669e-08 0.000000e+00 1.391750e-16 0.000000e+00 9.999999e-01], sampled 0.8561627517237704
[2019-03-23 02:12:41,706] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08234464], dtype=float32), -0.17686966]
[2019-03-23 02:12:41,709] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.05, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6452941073295463, 6.911200000000001, 6.9112, 121.9260426156618, 481180.6212695008, 481180.6212695003, 136660.7144138094]
[2019-03-23 02:12:41,710] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:12:41,713] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7932827496678391
[2019-03-23 02:12:56,805] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8657.9814 2266745443.8756 315.0000
[2019-03-23 02:12:56,981] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8410.1480 2389477007.8363 317.0000
[2019-03-23 02:12:57,159] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7940.8460 2588883834.6162 399.0000
[2019-03-23 02:12:57,221] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8538.6206 2320740033.5556 309.0000
[2019-03-23 02:12:57,279] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8481.6414 2339136566.5504 388.0000
[2019-03-23 02:12:58,300] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1600000, evaluation results [1600000.0, 7940.846010836548, 2588883834.616159, 399.0, 8538.620648445853, 2320740033.555647, 309.0, 8657.98140029464, 2266745443.8755536, 315.0, 8410.148023605758, 2389477007.8363047, 317.0, 8481.64141637673, 2339136566.550359, 388.0]
[2019-03-23 02:12:59,311] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 6.7584893e-33 0.0000000e+00 5.0594692e-15], sum to 1.0000
[2019-03-23 02:12:59,317] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7593
[2019-03-23 02:12:59,329] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 697684.0322045928 W.
[2019-03-23 02:12:59,335] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.96666666666667, 92.66666666666667, 1.0, 2.0, 0.2040651502421023, 1.0, 2.0, 0.2040651502421023, 1.0, 2.0, 0.3248783651233932, 6.911200000000001, 6.9112, 121.94756008, 697684.0322045928, 697684.0322045924, 221927.0967702295], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4497600.0000, 
sim time next is 4498200.0000, 
raw observation next is [23.95, 92.0, 1.0, 2.0, 0.3015098629703847, 1.0, 2.0, 0.3015098629703847, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 690620.168329109, 690620.1683291094, 180992.7492370127], 
processed observation next is [0.0, 0.043478260869565216, 0.4425925925925926, 0.92, 1.0, 1.0, 0.1684641225837913, 1.0, 1.0, 0.1684641225837913, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24665006011753893, 0.2466500601175391, 0.3480629793019475], 
reward next is 0.6519, 
noisyNet noise sample is [array([-0.10670581], dtype=float32), 0.121622145]. 
=============================================
[2019-03-23 02:13:13,943] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:13:13,950] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1280
[2019-03-23 02:13:13,956] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9287644262221295, 6.9112, 6.9112, 121.9260426156618, 677172.8066893412, 677172.8066893412, 180287.1536491583], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4514400.0000, 
sim time next is 4515000.0000, 
raw observation next is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9338605327586817, 6.9112, 6.9112, 121.9260426156618, 680341.9778733738, 680341.9778733738, 181076.2054195215], 
processed observation next is [0.0, 0.2608695652173913, 0.4074074074074074, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9173256659483522, 0.0, 0.0, 0.8094621288201359, 0.24297927781191922, 0.24297927781191922, 0.34822347196061826], 
reward next is 0.6518, 
noisyNet noise sample is [array([0.26953974], dtype=float32), -3.2731729]. 
=============================================
[2019-03-23 02:13:13,966] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[53.133553]
 [52.939716]
 [52.870026]
 [52.877945]
 [53.007393]], R is [[53.5378685 ]
 [53.65578461]
 [53.77650452]
 [53.89967346]
 [54.02458954]].
[2019-03-23 02:13:14,527] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:13:14,537] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0994
[2019-03-23 02:13:14,548] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9338605327586715, 6.9112, 6.9112, 121.9260426156618, 680341.9778733738, 680341.9778733738, 181076.2054195188], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4515000.0000, 
sim time next is 4515600.0000, 
raw observation next is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9351684933201962, 6.911200000000001, 6.9112, 121.9260426156618, 681251.422701855, 681251.4227018545, 181262.4208888223], 
processed observation next is [0.0, 0.2608695652173913, 0.4074074074074074, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9189606166502453, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24330407953637678, 0.24330407953637662, 0.34858157863235056], 
reward next is 0.6514, 
noisyNet noise sample is [array([-1.19796], dtype=float32), 1.0132469]. 
=============================================
[2019-03-23 02:13:21,185] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.9558005e-10 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 02:13:21,191] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8600
[2019-03-23 02:13:21,198] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.3, 91.5, 1.0, 2.0, 0.2215090621850606, 1.0, 2.0, 0.2215090621850606, 1.0, 2.0, 0.352649641045133, 6.911200000000001, 6.9112, 121.94756008, 757352.9658474746, 757352.9658474742, 227749.6298882732], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4663800.0000, 
sim time next is 4664400.0000, 
raw observation next is [25.2, 92.33333333333334, 1.0, 2.0, 0.2212720290296728, 1.0, 2.0, 0.2212720290296728, 1.0, 2.0, 0.3522722765421247, 6.9112, 6.9112, 121.94756008, 756542.1351930988, 756542.1351930988, 227669.370589478], 
processed observation next is [1.0, 1.0, 0.4888888888888889, 0.9233333333333335, 1.0, 1.0, 0.07294289170199143, 1.0, 1.0, 0.07294289170199143, 1.0, 1.0, 0.19034034567765581, 0.0, 0.0, 0.8096049824067558, 0.270193619711821, 0.270193619711821, 0.4378257126720731], 
reward next is 0.5622, 
noisyNet noise sample is [array([-0.4972545], dtype=float32), -0.07198386]. 
=============================================
[2019-03-23 02:13:25,119] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1256832e-13 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 02:13:25,127] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5858
[2019-03-23 02:13:25,134] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.4, 82.0, 1.0, 2.0, 0.2702791636364628, 1.0, 1.0, 0.2702791636364628, 1.0, 2.0, 0.4302932308870823, 6.911200000000001, 6.9112, 121.94756008, 924201.4289942601, 924201.4289942598, 244931.0672442709], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4935600.0000, 
sim time next is 4936200.0000, 
raw observation next is [25.16666666666667, 83.16666666666667, 1.0, 2.0, 0.3303176352979872, 1.0, 2.0, 0.3303176352979872, 1.0, 2.0, 0.5258764330887437, 6.9112, 6.9112, 121.94756008, 1129650.250037932, 1129650.250037932, 267904.594734182], 
processed observation next is [1.0, 0.13043478260869565, 0.4876543209876545, 0.8316666666666667, 1.0, 1.0, 0.20275908964046094, 1.0, 1.0, 0.20275908964046094, 1.0, 1.0, 0.40734554136092954, 0.0, 0.0, 0.8096049824067558, 0.40344651787069, 0.40344651787069, 0.5152011437195808], 
reward next is 0.4848, 
noisyNet noise sample is [array([-1.233762], dtype=float32), 0.76350707]. 
=============================================
[2019-03-23 02:13:25,964] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:13:25,973] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0140
[2019-03-23 02:13:25,981] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 699337.1341571 W.
[2019-03-23 02:13:25,988] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 99.0, 1.0, 2.0, 0.2039367839346088, 1.0, 1.0, 0.2039367839346088, 1.0, 2.0, 0.3247257305644957, 6.911199999999999, 6.9112, 121.94756008, 699337.1341571, 699337.1341571005, 221892.2780705644], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4690200.0000, 
sim time next is 4690800.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.2051441767478681, 1.0, 2.0, 0.2051441767478681, 1.0, 2.0, 0.3265962104620122, 6.9112, 6.9112, 121.94756008, 701374.8333745925, 701374.8333745925, 222282.3197178192], 
processed observation next is [1.0, 0.30434782608695654, 0.4074074074074074, 1.0, 1.0, 1.0, 0.053743067556985845, 1.0, 1.0, 0.053743067556985845, 1.0, 1.0, 0.15824526307751524, 0.0, 0.0, 0.8096049824067558, 0.2504910119194973, 0.2504910119194973, 0.4274659994573446], 
reward next is 0.5725, 
noisyNet noise sample is [array([-0.20020717], dtype=float32), 1.3591672]. 
=============================================
[2019-03-23 02:13:26,983] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:13:26,989] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9929
[2019-03-23 02:13:26,998] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1734744.540253418 W.
[2019-03-23 02:13:27,005] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.7, 83.66666666666667, 1.0, 2.0, 0.5070585272263205, 1.0, 2.0, 0.5070585272263205, 1.0, 1.0, 0.8072536890876496, 6.9112, 6.9112, 121.94756008, 1734744.540253418, 1734744.540253418, 347066.9636706178], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4966800.0000, 
sim time next is 4967400.0000, 
raw observation next is [25.85, 83.83333333333333, 1.0, 2.0, 0.7685551240456844, 1.0, 2.0, 0.7685551240456844, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1752934.521051661, 1752934.521051661, 330931.3730867897], 
processed observation next is [1.0, 0.4782608695652174, 0.5129629629629631, 0.8383333333333333, 1.0, 1.0, 0.7244703857686718, 1.0, 1.0, 0.7244703857686718, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6260480432327361, 0.6260480432327361, 0.6364064867053648], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.0286167], dtype=float32), 0.34404576]. 
=============================================
[2019-03-23 02:13:31,430] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:13:31,438] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4883
[2019-03-23 02:13:31,445] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 799946.7235793261 W.
[2019-03-23 02:13:31,454] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.28333333333333, 98.83333333333334, 1.0, 2.0, 0.3509404208328875, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5587085792975403, 6.911199999999999, 6.9112, 121.9260426156618, 799946.7235793261, 799946.7235793265, 209446.9110077647], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5123400.0000, 
sim time next is 5124000.0000, 
raw observation next is [25.56666666666667, 97.66666666666667, 1.0, 2.0, 0.2391046157575033, 1.0, 1.0, 0.2391046157575033, 1.0, 2.0, 0.3806623353796352, 6.9112, 6.9112, 121.94756008, 817545.312491792, 817545.312491792, 233795.2025196693], 
processed observation next is [0.0, 0.30434782608695654, 0.5024691358024692, 0.9766666666666667, 1.0, 1.0, 0.09417216161607536, 1.0, 0.5, 0.09417216161607536, 1.0, 1.0, 0.22582791922454395, 0.0, 0.0, 0.8096049824067558, 0.29198046874706857, 0.29198046874706857, 0.44960615869167175], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5499177], dtype=float32), 0.525994]. 
=============================================
[2019-03-23 02:13:31,463] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[44.673347]
 [44.201607]
 [44.119446]
 [44.26523 ]
 [44.570297]], R is [[43.79826355]
 [43.3602829 ]
 [42.92668152]
 [42.49741364]
 [42.0724411 ]].
[2019-03-23 02:13:34,072] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:13:34,081] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5128
[2019-03-23 02:13:34,090] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 812022.2547993138 W.
[2019-03-23 02:13:34,094] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.05, 92.5, 1.0, 2.0, 0.2374901614645532, 1.0, 1.0, 0.2374901614645532, 1.0, 1.0, 0.378092071566153, 6.9112, 6.9112, 121.94756008, 812022.2547993138, 812022.2547993138, 233233.2880985182], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4833000.0000, 
sim time next is 4833600.0000, 
raw observation next is [26.06666666666667, 92.33333333333333, 1.0, 2.0, 0.2367614880591684, 1.0, 2.0, 0.2367614880591684, 1.0, 2.0, 0.3769319997735444, 6.911200000000001, 6.9112, 121.94756008, 809529.4717990384, 809529.4717990379, 232980.1488171264], 
processed observation next is [1.0, 0.9565217391304348, 0.5209876543209878, 0.9233333333333333, 1.0, 1.0, 0.0913827238799624, 1.0, 1.0, 0.0913827238799624, 1.0, 1.0, 0.2211649997169305, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.28911766849965653, 0.28911766849965637, 0.4480387477252431], 
reward next is 0.5520, 
noisyNet noise sample is [array([0.7740399], dtype=float32), -0.76937497]. 
=============================================
[2019-03-23 02:13:34,362] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:13:34,369] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8079
[2019-03-23 02:13:34,375] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 915583.4923511527 W.
[2019-03-23 02:13:34,380] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.8032810717761752, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 915583.4923511527, 915583.4923511527, 196632.9631552653], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4903200.0000, 
sim time next is 4903800.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 0.4097018370656861, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6522586676658783, 6.911199999999999, 6.9112, 121.9260426156618, 933971.307292068, 933971.3072920685, 227123.4674421587], 
processed observation next is [1.0, 0.782608695652174, 0.6296296296296297, 0.89, 1.0, 1.0, 0.2972640917448644, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.5653233345823477, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3335611811757386, 0.33356118117573874, 0.4367758989272283], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.20575349], dtype=float32), -1.8141468]. 
=============================================
[2019-03-23 02:13:34,653] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 8.526649e-37 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 02:13:34,659] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6199
[2019-03-23 02:13:34,665] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1479518.572893833 W.
[2019-03-23 02:13:34,671] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.9, 83.0, 1.0, 2.0, 0.6487842251670757, 1.0, 2.0, 0.6487842251670757, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1479518.572893833, 1479518.572893834, 285230.5978091584], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5562000.0000, 
sim time next is 5562600.0000, 
raw observation next is [25.96666666666667, 82.66666666666667, 1.0, 2.0, 0.6996532334861107, 1.0, 2.0, 0.6996532334861107, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1595641.487128913, 1595641.487128914, 304033.3081492327], 
processed observation next is [1.0, 0.391304347826087, 0.517283950617284, 0.8266666666666667, 1.0, 1.0, 0.6424443255787032, 1.0, 1.0, 0.6424443255787032, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5698719596888975, 0.5698719596888979, 0.5846794387485245], 
reward next is 0.4153, 
noisyNet noise sample is [array([-0.21451771], dtype=float32), 1.2441585]. 
=============================================
[2019-03-23 02:13:38,839] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:13:38,844] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9979
[2019-03-23 02:13:38,852] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 937919.8496053688 W.
[2019-03-23 02:13:38,856] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.7, 85.5, 1.0, 2.0, 0.8060403611144165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 937919.8496053688, 937919.8496053688, 198168.2032382794], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4937400.0000, 
sim time next is 4938000.0000, 
raw observation next is [24.46666666666667, 86.66666666666666, 1.0, 2.0, 0.3703817973973152, 1.0, 1.0, 0.3703817973973152, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 849903.7723222099, 849903.7723222104, 198478.9876237936], 
processed observation next is [1.0, 0.13043478260869565, 0.46172839506172847, 0.8666666666666666, 1.0, 1.0, 0.25045452071108953, 1.0, 0.5, 0.25045452071108953, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3035370615436464, 0.30353706154364657, 0.3816903608149877], 
reward next is 0.6183, 
noisyNet noise sample is [array([0.97082746], dtype=float32), -0.48047814]. 
=============================================
[2019-03-23 02:13:38,868] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[35.806484]
 [35.925613]
 [35.45652 ]
 [35.94981 ]
 [35.836082]], R is [[35.67196655]
 [35.93415451]
 [36.17462921]
 [36.2976799 ]
 [36.4636879 ]].
[2019-03-23 02:13:45,393] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 5.2948523e-33 0.0000000e+00 8.7665373e-27], sum to 1.0000
[2019-03-23 02:13:45,408] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9390
[2019-03-23 02:13:45,415] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 807913.447662462 W.
[2019-03-23 02:13:45,419] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.1, 73.0, 1.0, 2.0, 0.2362891015873604, 1.0, 1.0, 0.2362891015873604, 1.0, 2.0, 0.3761799451258727, 6.9112, 6.9112, 121.94756008, 807913.447662462, 807913.447662462, 232816.2015189472], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5050800.0000, 
sim time next is 5051400.0000, 
raw observation next is [29.25, 74.0, 1.0, 2.0, 0.7043746496813975, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 802790.4516674126, 802790.4516674122, 176977.5018383726], 
processed observation next is [0.0, 0.4782608695652174, 0.6388888888888888, 0.74, 1.0, 1.0, 0.6480650591445208, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2867108755955045, 0.28671087559550434, 0.3403413496891781], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7042127], dtype=float32), 1.249733]. 
=============================================
[2019-03-23 02:13:53,685] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 02:13:53,686] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:13:53,687] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:13:53,687] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:13:53,689] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:13:53,688] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:13:53,689] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:13:53,690] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:13:53,693] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:13:53,695] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:13:53,693] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:13:53,725] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run66
[2019-03-23 02:13:53,726] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run66
[2019-03-23 02:13:53,782] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run66
[2019-03-23 02:13:53,807] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run66
[2019-03-23 02:13:53,836] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run66
[2019-03-23 02:15:10,551] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01303406], dtype=float32), -0.17521244]
[2019-03-23 02:15:10,553] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.75, 91.0, 1.0, 2.0, 0.7092012842446052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 812274.0718545417, 812274.0718545417, 178092.6799761681]
[2019-03-23 02:15:10,554] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:15:10,558] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 1.6760035e-35 0.0000000e+00 8.7323088e-16], sampled 0.1396001753796583
[2019-03-23 02:15:10,559] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 812274.0718545417 W.
[2019-03-23 02:15:44,965] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01303406], dtype=float32), -0.17521244]
[2019-03-23 02:15:44,965] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.16666666666666, 56.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8831969665654257, 6.911200000000001, 6.9112, 121.9260426156618, 660040.5195031044, 660040.5195031039, 165755.4776051568]
[2019-03-23 02:15:44,966] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:15:44,969] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.48444855183991276
[2019-03-23 02:15:45,783] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8389.2919 2357801655.1287 472.0000
[2019-03-23 02:15:45,961] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7898.3836 2552868733.8876 605.0000
[2019-03-23 02:15:46,129] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8450.5240 2311033249.7482 531.0000
[2019-03-23 02:15:46,226] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8670.9206 2236445957.9066 420.0000
[2019-03-23 02:15:46,248] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8582.6975 2281813791.0055 400.0000
[2019-03-23 02:15:47,267] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1625000, evaluation results [1625000.0, 7898.383554810124, 2552868733.8876014, 605.0, 8582.697482691345, 2281813791.005548, 400.0, 8670.92064084532, 2236445957.9066496, 420.0, 8389.29193996231, 2357801655.1287336, 472.0, 8450.523990141633, 2311033249.7482243, 531.0]
[2019-03-23 02:15:48,845] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3833518e-21], sum to 1.0000
[2019-03-23 02:15:48,853] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3657
[2019-03-23 02:15:48,859] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 831476.5188319959 W.
[2019-03-23 02:15:48,865] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.31666666666667, 85.66666666666667, 1.0, 2.0, 0.3647651928071225, 1.0, 2.0, 0.3647651928071225, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 831476.5188319959, 831476.5188319964, 196729.9595308517], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5255400.0000, 
sim time next is 5256000.0000, 
raw observation next is [27.2, 86.0, 1.0, 2.0, 0.2438208726116374, 1.0, 2.0, 0.2438208726116374, 1.0, 1.0, 0.3881707698891791, 6.911199999999999, 6.9112, 121.94756008, 833679.8830196427, 833679.8830196431, 235445.0488876856], 
processed observation next is [1.0, 0.8695652173913043, 0.5629629629629629, 0.86, 1.0, 1.0, 0.09978675310909214, 1.0, 1.0, 0.09978675310909214, 1.0, 0.5, 0.23521346236147384, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2977428153641581, 0.29774281536415825, 0.4527789401686262], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6461132], dtype=float32), -1.8361504]. 
=============================================
[2019-03-23 02:15:48,877] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[28.862646]
 [28.88627 ]
 [28.662514]
 [28.456587]
 [28.291231]], R is [[28.44671249]
 [28.78391838]
 [28.4960804 ]
 [28.21112061]
 [27.92901039]].
[2019-03-23 02:15:49,563] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:15:49,570] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7508
[2019-03-23 02:15:49,575] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.66666666666666, 61.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7778228085217646, 6.911200000000001, 6.9112, 121.9260426156618, 579001.4724363487, 579001.4724363482, 156881.3201349225], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5946000.0000, 
sim time next is 5946600.0000, 
raw observation next is [26.53333333333333, 62.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7803720484927852, 6.911200000000001, 6.9112, 121.9260426156618, 580937.862329826, 580937.8623298255, 157166.0524553224], 
processed observation next is [1.0, 0.8260869565217391, 0.5382716049382715, 0.6233333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7254650606159815, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20747780797493787, 0.2074778079749377, 0.3022424085679277], 
reward next is 0.6978, 
noisyNet noise sample is [array([-1.5419723], dtype=float32), 1.9139214]. 
=============================================
[2019-03-23 02:15:52,796] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 6.1059502e-14 1.1753785e-12 4.0446676e-16 1.4771989e-16], sum to 1.0000
[2019-03-23 02:15:52,807] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9130
[2019-03-23 02:15:52,818] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1836522.75304819 W.
[2019-03-23 02:15:52,823] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.66666666666666, 77.66666666666667, 1.0, 2.0, 0.9836023579993041, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1836522.75304819, 1836522.75304819, 375628.7329214336], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5395200.0000, 
sim time next is 5395800.0000, 
raw observation next is [27.83333333333334, 76.83333333333333, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.983119995402511, 6.9112, 121.9256491153747, 1914944.613333791, 1878115.266413722, 383874.5304048319], 
processed observation next is [1.0, 0.43478260869565216, 0.58641975308642, 0.7683333333333333, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.007191999540251093, 0.0, 0.8094595163874411, 0.6839087904763539, 0.670755452290615, 0.7382202507785229], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.03644091], dtype=float32), -1.1710116]. 
=============================================
[2019-03-23 02:15:58,939] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.5159141e-12 0.0000000e+00 2.9587048e-29 3.6884002e-19 1.0000000e+00], sum to 1.0000
[2019-03-23 02:15:58,946] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4933
[2019-03-23 02:15:58,951] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.5, 91.0, 1.0, 2.0, 0.2434184660836153, 1.0, 2.0, 0.2434184660836153, 1.0, 2.0, 0.3875301255911023, 6.911199999999999, 6.9112, 121.94756008, 832303.2152076472, 832303.2152076476, 235303.7935749436], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5380200.0000, 
sim time next is 5380800.0000, 
raw observation next is [24.53333333333333, 91.0, 1.0, 2.0, 0.2501743911844365, 1.0, 2.0, 0.2501743911844365, 1.0, 2.0, 0.3982857783767295, 6.9112, 6.9112, 121.94756008, 855416.1516041487, 855416.1516041487, 237687.2920206585], 
processed observation next is [1.0, 0.2608695652173913, 0.46419753086419746, 0.91, 1.0, 1.0, 0.10735046569575776, 1.0, 1.0, 0.10735046569575776, 1.0, 1.0, 0.24785722297091187, 0.0, 0.0, 0.8096049824067558, 0.3055057684300531, 0.3055057684300531, 0.45709094619357404], 
reward next is 0.5429, 
noisyNet noise sample is [array([1.0815983], dtype=float32), 2.4881048]. 
=============================================
[2019-03-23 02:16:07,713] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:16:07,723] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7565
[2019-03-23 02:16:07,732] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1027752.465362687 W.
[2019-03-23 02:16:07,735] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.56666666666667, 84.33333333333334, 1.0, 2.0, 0.9004232797358862, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1027752.465362687, 1027752.465362687, 217631.0138043363], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5559600.0000, 
sim time next is 5560200.0000, 
raw observation next is [25.65, 84.0, 1.0, 2.0, 0.4949835605695884, 1.0, 1.0, 0.4949835605695884, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1128525.810454577, 1128525.810454577, 233835.2170949384], 
processed observation next is [1.0, 0.34782608695652173, 0.5055555555555555, 0.84, 1.0, 1.0, 0.39878995305903386, 1.0, 0.5, 0.39878995305903386, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.40304493230520605, 0.40304493230520605, 0.44968310979795845], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6050173], dtype=float32), 0.37751266]. 
=============================================
[2019-03-23 02:16:09,740] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.998269e-27], sum to 1.0000
[2019-03-23 02:16:09,750] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5420
[2019-03-23 02:16:09,761] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 687025.6572967874 W.
[2019-03-23 02:16:09,767] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.1, 91.0, 1.0, 2.0, 0.3014236039173603, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4798761941178791, 6.9112, 6.9112, 121.9260426156618, 687025.6572967874, 687025.6572967874, 195630.2239308282], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5592000.0000, 
sim time next is 5592600.0000, 
raw observation next is [25.15, 91.0, 1.0, 2.0, 0.2007111747673492, 1.0, 1.0, 0.2007111747673492, 1.0, 2.0, 0.3195387269362309, 6.9112, 6.9112, 121.94756008, 686211.9004856532, 686211.9004856532, 220827.1066084725], 
processed observation next is [1.0, 0.7391304347826086, 0.487037037037037, 0.91, 1.0, 1.0, 0.04846568424684429, 1.0, 0.5, 0.04846568424684429, 1.0, 1.0, 0.14942340867028864, 0.0, 0.0, 0.8096049824067558, 0.24507567874487615, 0.24507567874487615, 0.424667512708601], 
reward next is 0.5753, 
noisyNet noise sample is [array([-0.33510143], dtype=float32), 1.3981766]. 
=============================================
[2019-03-23 02:16:14,919] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:16:14,929] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0295
[2019-03-23 02:16:14,939] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.03333333333333, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5940391595836111, 6.911200000000001, 6.9112, 121.9260426156618, 435633.8569697447, 435633.8569697442, 126896.1855464767], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5892000.0000, 
sim time next is 5892600.0000, 
raw observation next is [18.96666666666667, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5826622459303036, 6.911200000000001, 6.9112, 121.9260426156618, 426882.9153257494, 426882.915325749, 125699.8604672475], 
processed observation next is [1.0, 0.17391304347826086, 0.25802469135802475, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.47832780741287945, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1524581840449105, 0.15245818404491038, 0.24173050089855289], 
reward next is 0.7583, 
noisyNet noise sample is [array([-0.47554016], dtype=float32), -0.7195232]. 
=============================================
[2019-03-23 02:16:40,471] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.596659e-25], sum to 1.0000
[2019-03-23 02:16:40,483] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6504
[2019-03-23 02:16:40,493] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 740238.7394508221 W.
[2019-03-23 02:16:40,500] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.2, 87.33333333333334, 1.0, 1.0, 0.3129343992734842, 0.0, 2.0, 0.0, 1.0, 2.0, 0.501889119209734, 6.911199999999999, 6.9112, 121.9258348548666, 740238.7394508221, 740238.7394508226, 197955.9675138238], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6063600.0000, 
sim time next is 6064200.0000, 
raw observation next is [23.25, 87.0, 1.0, 2.0, 0.2963059644704533, 1.0, 1.0, 0.2963059644704533, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425523097, 698253.3441111607, 698253.3441111607, 180640.6256329644], 
processed observation next is [1.0, 0.17391304347826086, 0.4166666666666667, 0.87, 1.0, 1.0, 0.16226900532196825, 1.0, 0.5, 0.16226900532196825, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621283995439, 0.24937619432541455, 0.24937619432541455, 0.34738581852493156], 
reward next is 0.6526, 
noisyNet noise sample is [array([1.7939237], dtype=float32), -0.3634149]. 
=============================================
[2019-03-23 02:16:41,364] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 2.531496e-37], sum to 1.0000
[2019-03-23 02:16:41,378] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2987
[2019-03-23 02:16:41,382] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.76666666666667, 73.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.857412782984946, 6.911200000000001, 6.9112, 121.9260426156618, 631937.0368069203, 631937.0368069198, 169303.1619042859], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6131400.0000, 
sim time next is 6132000.0000, 
raw observation next is [25.63333333333334, 74.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8570181505202789, 6.9112, 6.9112, 121.9260426156618, 631659.3949750976, 631659.3949750976, 169248.9927464655], 
processed observation next is [1.0, 1.0, 0.5049382716049385, 0.7466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8212726881503485, 0.0, 0.0, 0.8094621288201359, 0.22559264106253488, 0.22559264106253488, 0.32547883220474133], 
reward next is 0.6745, 
noisyNet noise sample is [array([-0.84430504], dtype=float32), -0.048408944]. 
=============================================
[2019-03-23 02:16:41,395] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[65.6294  ]
 [65.636215]
 [65.58427 ]
 [65.58578 ]
 [65.58877 ]], R is [[65.65811157]
 [65.6759491 ]
 [65.69337463]
 [65.71018219]
 [65.72644806]].
[2019-03-23 02:16:42,382] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 02:16:42,384] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:16:42,386] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:16:42,387] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:16:42,389] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:16:42,390] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:16:42,393] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:16:42,394] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:16:42,388] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:16:42,395] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:16:42,398] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:16:42,421] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run67
[2019-03-23 02:16:42,452] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run67
[2019-03-23 02:16:42,453] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run67
[2019-03-23 02:16:42,481] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run67
[2019-03-23 02:16:42,530] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run67
[2019-03-23 02:16:43,614] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05643633], dtype=float32), -0.18734844]
[2019-03-23 02:16:43,615] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.32709260333333, 77.25667152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4936294027620174, 6.9112, 6.9112, 121.9260426156618, 354846.6161201343, 354846.6161201343, 113557.4975225419]
[2019-03-23 02:16:43,615] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:16:43,616] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.15631436630033946
[2019-03-23 02:16:52,887] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05643633], dtype=float32), -0.18734844]
[2019-03-23 02:16:52,889] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [33.14013966, 20.21661555666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6529147803588902, 6.9112, 6.9112, 121.9260426156618, 479314.1271555289, 479314.1271555289, 132527.5906791623]
[2019-03-23 02:16:52,891] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:16:52,894] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.02274704677443673
[2019-03-23 02:17:09,262] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05643633], dtype=float32), -0.18734844]
[2019-03-23 02:17:09,264] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.24042147, 70.95691958166667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6305858619872052, 6.9112, 6.9112, 121.9260426156618, 466601.8014848345, 466601.8014848345, 132366.6546284238]
[2019-03-23 02:17:09,265] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:17:09,271] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.6996295e-32], sampled 0.2680415940556812
[2019-03-23 02:17:25,606] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05643633], dtype=float32), -0.18734844]
[2019-03-23 02:17:25,608] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.26277903333333, 87.25360694499999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8255852463058949, 6.9112, 6.9112, 121.9260426156618, 611757.2784671031, 611757.2784671031, 164180.1495381393]
[2019-03-23 02:17:25,610] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:17:25,612] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8160548811213973
[2019-03-23 02:17:28,571] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.05643633], dtype=float32), -0.18734844]
[2019-03-23 02:17:28,572] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [36.82796194, 38.12836124833333, 1.0, 2.0, 0.4060376395001388, 1.0, 2.0, 0.4060376395001388, 1.0, 2.0, 0.6464251458069433, 6.911199999999999, 6.9112, 121.94756008, 1388839.105739386, 1388839.105739387, 299737.0552386053]
[2019-03-23 02:17:28,574] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:17:28,577] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.99931574e-01 1.83645370e-33 1.01539155e-30 6.11336269e-18
 6.83654071e-05], sampled 0.22832274574110356
[2019-03-23 02:17:28,578] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1388839.105739386 W.
[2019-03-23 02:17:30,051] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05643633], dtype=float32), -0.18734844]
[2019-03-23 02:17:30,053] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.948135975, 109.190216, 1.0, 2.0, 0.6187015735714818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 720669.0035087025, 720669.0035087025, 162066.6022302597]
[2019-03-23 02:17:30,053] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:17:30,057] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 3.8909386e-37 0.0000000e+00 8.3586897e-24], sampled 0.04071403990677691
[2019-03-23 02:17:30,058] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 720669.0035087025 W.
[2019-03-23 02:17:35,263] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05643633], dtype=float32), -0.18734844]
[2019-03-23 02:17:35,263] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.0, 79.0, 1.0, 2.0, 0.3478328201555131, 1.0, 2.0, 0.3478328201555131, 1.0, 2.0, 0.5537611778116719, 6.911199999999999, 6.9112, 121.94756008, 1189596.766872304, 1189596.766872304, 274984.8328744756]
[2019-03-23 02:17:35,266] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:17:35,269] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8631428e-06 0.0000000e+00 4.5064460e-33 6.9115031e-12 9.9999809e-01], sampled 0.19657701626701762
[2019-03-23 02:17:40,000] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.05643633], dtype=float32), -0.18734844]
[2019-03-23 02:17:40,001] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.83333333333333, 85.66666666666666, 1.0, 2.0, 0.2799702299790944, 1.0, 2.0, 0.2799702299790944, 1.0, 2.0, 0.4457217241205484, 6.911200000000001, 6.9112, 121.94756008, 957360.0742130023, 957360.0742130019, 248503.3487981473]
[2019-03-23 02:17:40,002] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:17:40,004] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.2291648e-01 0.0000000e+00 4.1875715e-33 3.6904503e-24 7.7708352e-01], sampled 0.7835985864776853
[2019-03-23 02:17:46,615] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05643633], dtype=float32), -0.18734844]
[2019-03-23 02:17:46,616] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9338605327586632, 6.9112, 6.9112, 121.9260426156618, 680341.9778733738, 680341.9778733738, 181076.2054195166]
[2019-03-23 02:17:46,619] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:17:46,621] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6275968561248457
[2019-03-23 02:18:12,503] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05643633], dtype=float32), -0.18734844]
[2019-03-23 02:18:12,504] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.98356057, 83.70978184, 1.0, 2.0, 0.6952039483989284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 811580.3103064372, 811580.3103064372, 176171.0376830513]
[2019-03-23 02:18:12,505] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:18:12,509] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3744243e-35 4.3117788e-13], sampled 0.10241878781480973
[2019-03-23 02:18:12,509] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 811580.3103064372 W.
[2019-03-23 02:18:13,569] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05643633], dtype=float32), -0.18734844]
[2019-03-23 02:18:13,573] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.269735645, 69.54709376166666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9620923794186225, 6.9112, 6.9112, 121.9260426156618, 692247.4781638634, 692247.4781638634, 186157.6334960624]
[2019-03-23 02:18:13,575] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:18:13,578] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.9049973e-31], sampled 0.3578858925199677
[2019-03-23 02:18:13,578] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 692247.4781638634 W.
[2019-03-23 02:18:16,276] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.05643633], dtype=float32), -0.18734844]
[2019-03-23 02:18:16,278] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.0, 45.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6581961526896746, 6.9112, 6.9112, 121.9260426156618, 469993.0400836995, 469993.0400836995, 124085.2016217764]
[2019-03-23 02:18:16,279] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:18:16,282] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4393955526542368
[2019-03-23 02:18:19,982] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.05643633], dtype=float32), -0.18734844]
[2019-03-23 02:18:19,984] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.7232879, 79.97127645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6084430909290375, 6.911200000000001, 6.9112, 121.9260426156618, 451653.125507194, 451653.1255071936, 131205.9489976046]
[2019-03-23 02:18:19,985] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:18:19,989] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.021012902916125453
[2019-03-23 02:18:34,428] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8437.1625 2378290668.9610 317.0000
[2019-03-23 02:18:34,654] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7915.7495 2629058808.5550 353.0000
[2019-03-23 02:18:34,885] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8370.0343 2430347879.7369 260.0000
[2019-03-23 02:18:34,946] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8472.9829 2370262187.5379 252.0000
[2019-03-23 02:18:34,948] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8568.6386 2313248989.0923 277.0000
[2019-03-23 02:18:35,968] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1650000, evaluation results [1650000.0, 7915.749547011968, 2629058808.554974, 353.0, 8472.98286265196, 2370262187.5378733, 252.0, 8568.638618055207, 2313248989.0922847, 277.0, 8370.034338142763, 2430347879.736901, 260.0, 8437.16245829744, 2378290668.9610314, 317.0]
[2019-03-23 02:18:36,095] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999940e-01 3.2703126e-24 2.2588081e-31 4.5072382e-35 6.1299016e-07], sum to 1.0000
[2019-03-23 02:18:36,103] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4352
[2019-03-23 02:18:36,112] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1495233.921347418 W.
[2019-03-23 02:18:36,116] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.8, 75.0, 1.0, 2.0, 0.6541927322830428, 1.0, 2.0, 0.6541927322830428, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1495233.921347418, 1495233.921347419, 287357.7790826919], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6168600.0000, 
sim time next is 6169200.0000, 
raw observation next is [25.96666666666667, 74.0, 1.0, 2.0, 0.6331067479227248, 1.0, 2.0, 0.6331067479227248, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1450562.343156829, 1450562.34315683, 279958.9669620527], 
processed observation next is [1.0, 0.391304347826087, 0.517283950617284, 0.74, 1.0, 1.0, 0.5632223189556248, 1.0, 1.0, 0.5632223189556248, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5180579796988675, 0.5180579796988678, 0.5383826287731782], 
reward next is 0.4616, 
noisyNet noise sample is [array([-1.0249887], dtype=float32), 0.6175654]. 
=============================================
[2019-03-23 02:18:46,915] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 5.541323e-25], sum to 1.0000
[2019-03-23 02:18:46,920] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5699
[2019-03-23 02:18:46,929] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 760923.61119804 W.
[2019-03-23 02:18:46,933] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.85, 75.0, 1.0, 2.0, 0.2225528793016858, 1.0, 2.0, 0.2225528793016858, 1.0, 2.0, 0.3543114318895505, 6.911200000000001, 6.9112, 121.94756008, 760923.61119804, 760923.6111980395, 228103.4397018565], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6342600.0000, 
sim time next is 6343200.0000, 
raw observation next is [28.1, 74.0, 1.0, 2.0, 0.3359932222427228, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5349121523457249, 6.911199999999999, 6.9112, 121.9260426156618, 765858.4985206673, 765858.4985206678, 205171.2705171121], 
processed observation next is [0.0, 0.43478260869565216, 0.5962962962962963, 0.74, 1.0, 1.0, 0.20951574076514623, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.41864019043215606, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2735208923288098, 0.27352089232880994, 0.394560135609831], 
reward next is 0.6054, 
noisyNet noise sample is [array([1.1392037], dtype=float32), 0.2048251]. 
=============================================
[2019-03-23 02:18:47,003] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1833016e-22], sum to 1.0000
[2019-03-23 02:18:47,012] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2967
[2019-03-23 02:18:47,022] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 733733.5535747382 W.
[2019-03-23 02:18:47,027] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.83333333333334, 61.33333333333333, 1.0, 2.0, 0.214604208415601, 1.0, 1.0, 0.214604208415601, 1.0, 2.0, 0.3416568889687654, 6.911200000000001, 6.9112, 121.94756008, 733733.5535747382, 733733.5535747377, 225424.5274244161], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6284400.0000, 
sim time next is 6285000.0000, 
raw observation next is [29.71666666666667, 61.66666666666667, 1.0, 2.0, 0.3208968957607688, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5108783089334248, 6.911199999999999, 6.9112, 121.9260426156618, 731431.7146028429, 731431.7146028434, 200944.7964568382], 
processed observation next is [0.0, 0.7391304347826086, 0.6561728395061729, 0.6166666666666667, 1.0, 1.0, 0.19154392352472477, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.3885978861667809, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26122561235815817, 0.26122561235815833, 0.38643230087853503], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6321315], dtype=float32), 0.4044367]. 
=============================================
[2019-03-23 02:18:47,040] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[48.68205]
 [48.68534]
 [48.53773]
 [48.421  ]
 [48.29368]], R is [[48.57782364]
 [48.658535  ]
 [48.78482056]
 [48.97903061]
 [49.16756058]].
[2019-03-23 02:18:58,353] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.5562982e-38 0.0000000e+00 5.0769042e-09], sum to 1.0000
[2019-03-23 02:18:58,362] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8239
[2019-03-23 02:18:58,370] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 754347.4664094258 W.
[2019-03-23 02:18:58,373] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.43333333333333, 71.0, 1.0, 2.0, 0.3309456493476841, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5268762519088507, 6.911199999999999, 6.9112, 121.9260426156618, 754347.4664094258, 754347.4664094263, 203748.0056716652], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6475200.0000, 
sim time next is 6475800.0000, 
raw observation next is [28.31666666666667, 71.5, 1.0, 2.0, 0.2202989635513012, 1.0, 1.0, 0.2202989635513012, 1.0, 2.0, 0.350723124610027, 6.9112, 6.9112, 121.94756008, 753213.5325455804, 753213.5325455804, 227340.2204568123], 
processed observation next is [1.0, 0.9565217391304348, 0.6043209876543211, 0.715, 1.0, 1.0, 0.07178448041821572, 1.0, 0.5, 0.07178448041821572, 1.0, 1.0, 0.18840390576253377, 0.0, 0.0, 0.8096049824067558, 0.269004833051993, 0.269004833051993, 0.43719273164771594], 
reward next is 0.5628, 
noisyNet noise sample is [array([-0.01452453], dtype=float32), -0.059259098]. 
=============================================
[2019-03-23 02:19:05,985] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 5.6107399e-36 3.5188722e-30 0.0000000e+00 2.8345937e-34], sum to 1.0000
[2019-03-23 02:19:05,990] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1651
[2019-03-23 02:19:05,993] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1176126.55913467 W.
[2019-03-23 02:19:06,001] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.86666666666667, 46.33333333333333, 1.0, 2.0, 0.3196786994947072, 1.0, 2.0, 0.3196786994947072, 1.0, 2.0, 0.5244398146782526, 6.911199999999999, 6.9112, 121.94756008, 1176126.55913467, 1176126.55913467, 262219.1775860984], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6615600.0000, 
sim time next is 6616200.0000, 
raw observation next is [25.08333333333333, 49.16666666666667, 1.0, 2.0, 0.4540582414436518, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7567764742886115, 6.911199999999999, 6.9112, 121.9260426156618, 1129646.112793574, 1129646.112793574, 237116.4136651216], 
processed observation next is [1.0, 0.5652173913043478, 0.4845679012345677, 0.4916666666666667, 1.0, 1.0, 0.3500693350519664, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.6959705928607642, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4034450402834193, 0.4034450402834193, 0.4559931032021569], 
reward next is 0.5440, 
noisyNet noise sample is [array([-0.27088565], dtype=float32), 0.017110426]. 
=============================================
[2019-03-23 02:19:10,132] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:19:10,148] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3449
[2019-03-23 02:19:10,155] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.5, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5758646827639083, 6.911199999999999, 6.9112, 121.9260426156618, 423978.2947817222, 423978.2947817226, 126095.1632008764], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6739200.0000, 
sim time next is 6739800.0000, 
raw observation next is [20.41666666666667, 76.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5764501577368422, 6.9112, 6.9112, 121.9260426156618, 424096.9879644146, 424096.9879644146, 125990.2416056581], 
processed observation next is [1.0, 0.0, 0.31172839506172856, 0.7616666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.47056269717105265, 0.0, 0.0, 0.8094621288201359, 0.15146320998729093, 0.15146320998729093, 0.2422889261647271], 
reward next is 0.7577, 
noisyNet noise sample is [array([0.7205804], dtype=float32), -0.5860994]. 
=============================================
[2019-03-23 02:19:11,532] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.880695e-15 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00], sum to 1.0000
[2019-03-23 02:19:11,540] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0059
[2019-03-23 02:19:11,546] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.58333333333333, 51.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 420319.8647525911, 420319.8647525911, 181223.8189737786], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6727800.0000, 
sim time next is 6728400.0000, 
raw observation next is [24.3, 53.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 421798.9489843328, 421798.9489843328, 181485.9805514008], 
processed observation next is [1.0, 0.9130434782608695, 0.4555555555555556, 0.53, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8096049824067558, 0.15064248178011885, 0.15064248178011885, 0.34901150106038614], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.57678455], dtype=float32), -0.5265429]. 
=============================================
[2019-03-23 02:19:14,307] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:19:14,317] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2167
[2019-03-23 02:19:14,321] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.73333333333333, 92.33333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2455967539036404, 6.911199999999999, 6.9112, 121.94756008, 545894.7034101526, 545894.703410153, 203957.4103871697], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7548000.0000, 
sim time next is 7548600.0000, 
raw observation next is [21.91666666666667, 91.66666666666667, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7381611707101647, 6.9112, 6.9112, 121.9260426156618, 549299.255851145, 549299.255851145, 152252.9415759316], 
processed observation next is [0.0, 0.34782608695652173, 0.36728395061728414, 0.9166666666666667, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.672701463387706, 0.0, 0.0, 0.8094621288201359, 0.1961783056611232, 0.1961783056611232, 0.29279411841525305], 
reward next is 0.7072, 
noisyNet noise sample is [array([0.14686191], dtype=float32), -0.54834026]. 
=============================================
[2019-03-23 02:19:24,260] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:19:24,271] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8501
[2019-03-23 02:19:24,274] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.61666666666667, 92.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6280397098425097, 6.911199999999999, 6.9112, 121.9260426156618, 467367.4500184584, 467367.4500184589, 133992.0192111846], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7188600.0000, 
sim time next is 7189200.0000, 
raw observation next is [19.6, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6230710655449734, 6.9112, 6.9112, 121.9260426156618, 463555.2291145728, 463555.2291145728, 133407.9179949199], 
processed observation next is [1.0, 0.21739130434782608, 0.28148148148148155, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5288388319312167, 0.0, 0.0, 0.8094621288201359, 0.1655554389694903, 0.1655554389694903, 0.25655368845176907], 
reward next is 0.7434, 
noisyNet noise sample is [array([0.22480063], dtype=float32), 1.2277141]. 
=============================================
[2019-03-23 02:19:30,912] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 02:19:30,915] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:19:30,916] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:19:30,916] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:19:30,917] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:19:30,918] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:19:30,918] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:19:30,918] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:19:30,922] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:19:30,919] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:19:30,926] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:19:30,944] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run68
[2019-03-23 02:19:30,971] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run68
[2019-03-23 02:19:30,996] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run68
[2019-03-23 02:19:31,028] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run68
[2019-03-23 02:19:31,061] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run68
[2019-03-23 02:19:36,578] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.16292402], dtype=float32), -0.18343808]
[2019-03-23 02:19:36,579] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.85, 43.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4769450345463549, 6.9112, 6.9112, 121.9260426156618, 340539.7186026516, 340539.7186026516, 103704.3341836381]
[2019-03-23 02:19:36,581] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:19:36,586] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3610278403330557
[2019-03-23 02:19:43,618] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.16292402], dtype=float32), -0.18343808]
[2019-03-23 02:19:43,619] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.50787135, 58.02388509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6304485874639618, 6.9112, 6.9112, 121.9260426156618, 469435.9120523226, 469435.9120523226, 134475.687815396]
[2019-03-23 02:19:43,622] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:19:43,625] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.46910396684467726
[2019-03-23 02:19:49,118] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.16292402], dtype=float32), -0.18343808]
[2019-03-23 02:19:49,120] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.54284215, 87.268249965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5354614838595939, 6.9112, 6.9112, 121.9260426156618, 390904.5347393163, 390904.5347393163, 121017.2625713471]
[2019-03-23 02:19:49,122] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:19:49,125] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5601701745674155
[2019-03-23 02:20:18,919] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.16292402], dtype=float32), -0.18343808]
[2019-03-23 02:20:18,921] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.1, 60.0, 1.0, 2.0, 0.2400804427631918, 1.0, 2.0, 0.2400804427631918, 1.0, 2.0, 0.3822158837531581, 6.911200000000001, 6.9112, 121.94756008, 820883.6417488244, 820883.6417488239, 234135.5476041218]
[2019-03-23 02:20:18,922] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:20:18,926] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.6484687e-01 0.0000000e+00 7.0196034e-33 1.1678905e-20 4.3515316e-01], sampled 0.20124052539395876
[2019-03-23 02:20:18,930] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 820883.6417488244 W.
[2019-03-23 02:20:22,220] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.16292402], dtype=float32), -0.18343808]
[2019-03-23 02:20:22,220] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.66666666666667, 58.0, 1.0, 2.0, 0.9634284050983085, 1.0, 2.0, 0.7950788645255888, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 125.7153414824997, 2721494.675874194, 2721494.675874195, 508731.7711350346]
[2019-03-23 02:20:22,221] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:20:22,224] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.0809356e-17 0.0000000e+00 0.0000000e+00 9.9999905e-01 9.7791894e-07], sampled 0.09937332695679801
[2019-03-23 02:20:22,224] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 0, 0, 1, 0] has been changed to [0, 0, 0, 0, 1] for the demand 2721494.675874194 W.
[2019-03-23 02:20:55,554] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.16292402], dtype=float32), -0.18343808]
[2019-03-23 02:20:55,555] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.05, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7682567586026041, 6.911200000000001, 6.9112, 121.9260426156618, 573712.4523563966, 573712.4523563961, 150940.699520314]
[2019-03-23 02:20:55,557] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:20:55,559] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6019204859004202
[2019-03-23 02:21:22,813] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8426.8048 2348814211.9525 441.0000
[2019-03-23 02:21:23,066] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8466.6080 2310357767.5205 497.0000
[2019-03-23 02:21:23,358] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8588.7557 2279105861.3326 393.0000
[2019-03-23 02:21:23,388] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7938.9883 2542407637.1940 593.0000
[2019-03-23 02:21:23,501] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8667.8381 2238614740.0089 400.0000
[2019-03-23 02:21:24,519] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1675000, evaluation results [1675000.0, 7938.988332535132, 2542407637.1940327, 593.0, 8588.755693049688, 2279105861.3326406, 393.0, 8667.838072026329, 2238614740.0088983, 400.0, 8426.804834924607, 2348814211.95248, 441.0, 8466.608043254753, 2310357767.5205417, 497.0]
[2019-03-23 02:21:27,353] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4724397e-38], sum to 1.0000
[2019-03-23 02:21:27,362] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2938
[2019-03-23 02:21:27,371] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.36666666666667, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7248379737230418, 6.9112, 6.9112, 121.9260426156618, 541485.1908754018, 541485.1908754018, 148512.1746138406], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7089600.0000, 
sim time next is 7090200.0000, 
raw observation next is [23.35, 75.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7185569224267183, 6.9112, 6.9112, 121.9260426156618, 536868.2627914804, 536868.2627914804, 147583.7288295291], 
processed observation next is [1.0, 0.043478260869565216, 0.42037037037037045, 0.755, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.648196153033398, 0.0, 0.0, 0.8094621288201359, 0.19173866528267158, 0.19173866528267158, 0.28381486313370985], 
reward next is 0.7162, 
noisyNet noise sample is [array([-0.89961123], dtype=float32), 0.55325854]. 
=============================================
[2019-03-23 02:21:32,511] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:21:32,512] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:21:32,586] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run9
[2019-03-23 02:21:33,279] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:21:33,284] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9930
[2019-03-23 02:21:33,289] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.9, 77.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6420496926224725, 6.911200000000001, 6.9112, 121.9260426156618, 478828.5192231737, 478828.5192231733, 136413.7023835571], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7247400.0000, 
sim time next is 7248000.0000, 
raw observation next is [21.8, 77.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6395451459947289, 6.911200000000001, 6.9112, 121.9260426156618, 476846.2590035753, 476846.2590035748, 136027.5455985513], 
processed observation next is [1.0, 0.9130434782608695, 0.362962962962963, 0.7766666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5494314324934111, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17030223535841976, 0.17030223535841957, 0.2615914338433679], 
reward next is 0.7384, 
noisyNet noise sample is [array([0.37497032], dtype=float32), -1.2300657]. 
=============================================
[2019-03-23 02:21:33,298] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[73.429115]
 [73.148155]
 [73.04438 ]
 [72.909775]
 [72.90221 ]], R is [[73.82450867]
 [73.82392883]
 [73.82272339]
 [73.82103729]
 [73.81877136]].
[2019-03-23 02:21:34,207] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.2750493e-37], sum to 1.0000
[2019-03-23 02:21:34,219] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8036
[2019-03-23 02:21:34,223] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.46666666666667, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6442197649567291, 6.9112, 6.9112, 121.9260426156618, 481037.2848531926, 481037.2848531926, 137494.8328883965], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7459800.0000, 
sim time next is 7460400.0000, 
raw observation next is [20.63333333333333, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6494472452926935, 6.911200000000001, 6.9112, 121.9260426156618, 485072.165829177, 485072.1658291765, 138300.1057142224], 
processed observation next is [0.0, 0.34782608695652173, 0.3197530864197529, 0.91, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5618090566158668, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1732400592247061, 0.1732400592247059, 0.26596174175812], 
reward next is 0.7340, 
noisyNet noise sample is [array([-1.0122842], dtype=float32), 0.6986534]. 
=============================================
[2019-03-23 02:21:42,538] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:21:42,550] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3291
[2019-03-23 02:21:42,563] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.2, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6460511112741788, 6.911199999999999, 6.9112, 121.9260426156618, 480945.9890144159, 480945.9890144164, 135925.4492098754], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7354800.0000, 
sim time next is 7355400.0000, 
raw observation next is [20.15, 88.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7059994608143687, 6.911200000000001, 6.9112, 121.9260426156618, 525698.4176843334, 525698.4176843329, 142177.5742862917], 
processed observation next is [1.0, 0.13043478260869565, 0.3018518518518518, 0.8866666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6324993260179609, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18774943488726192, 0.18774943488726176, 0.2734184120890225], 
reward next is 0.7266, 
noisyNet noise sample is [array([0.02391595], dtype=float32), 0.59459066]. 
=============================================
[2019-03-23 02:21:47,000] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0429866e-21], sum to 1.0000
[2019-03-23 02:21:47,011] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4693
[2019-03-23 02:21:47,017] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.1, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8317500887718693, 6.911200000000001, 6.9112, 121.9260426156618, 614367.4149149226, 614367.4149149221, 165647.465727494], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7488000.0000, 
sim time next is 7488600.0000, 
raw observation next is [25.06666666666667, 77.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8322854402339905, 6.9112, 6.9112, 121.9260426156618, 614716.0932593086, 614716.0932593086, 165729.4123961597], 
processed observation next is [0.0, 0.6956521739130435, 0.4839506172839507, 0.7716666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7903568002924882, 0.0, 0.0, 0.8094621288201359, 0.2195414618783245, 0.2195414618783245, 0.31871040845415327], 
reward next is 0.6813, 
noisyNet noise sample is [array([-0.3381384], dtype=float32), 0.31259173]. 
=============================================
[2019-03-23 02:21:48,126] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:21:48,139] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1967
[2019-03-23 02:21:48,143] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.03333333333333, 91.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6348539977891459, 6.9112, 6.9112, 121.9260426156618, 473363.0157594518, 473363.0157594518, 135574.878944519], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7432800.0000, 
sim time next is 7433400.0000, 
raw observation next is [20.01666666666667, 91.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6339905980284996, 6.911199999999999, 6.9112, 121.9260426156618, 472726.0505190501, 472726.0505190506, 135496.5534302529], 
processed observation next is [0.0, 0.0, 0.29691358024691367, 0.9183333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5424882475356244, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16883073232823217, 0.16883073232823237, 0.2605702950581787], 
reward next is 0.7394, 
noisyNet noise sample is [array([0.9597412], dtype=float32), 0.679866]. 
=============================================
[2019-03-23 02:21:49,202] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:21:49,209] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6132
[2019-03-23 02:21:49,217] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.6, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6842516946967816, 6.911200000000001, 6.9112, 121.9260426156618, 511295.9417608266, 511295.9417608262, 143503.4996486567], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7464000.0000, 
sim time next is 7464600.0000, 
raw observation next is [21.75, 87.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6896325894523261, 6.911200000000001, 6.9112, 121.9260426156618, 515270.3129725526, 515270.3129725521, 144304.0899764126], 
processed observation next is [0.0, 0.391304347826087, 0.3611111111111111, 0.875, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6120407368154076, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18402511177591166, 0.18402511177591147, 0.277507865339255], 
reward next is 0.7225, 
noisyNet noise sample is [array([0.23304246], dtype=float32), -0.38600034]. 
=============================================
[2019-03-23 02:21:49,978] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:21:49,988] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1652
[2019-03-23 02:21:49,993] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.93333333333333, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8012390761931972, 6.911199999999999, 6.9112, 121.9260426156618, 593700.0873311298, 593700.0873311303, 161115.1900289324], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7478400.0000, 
sim time next is 7479000.0000, 
raw observation next is [25.05, 75.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8046731414826442, 6.911199999999999, 6.9112, 121.9260426156618, 596024.7641865816, 596024.7641865821, 161632.5975525427], 
processed observation next is [0.0, 0.5652173913043478, 0.48333333333333334, 0.755, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7558414268533054, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21286598720949343, 0.2128659872094936, 0.3108319183702744], 
reward next is 0.6892, 
noisyNet noise sample is [array([-0.26320422], dtype=float32), 1.0680741]. 
=============================================
[2019-03-23 02:21:50,012] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[70.458305]
 [70.47221 ]
 [70.512276]
 [70.49975 ]
 [70.507904]], R is [[70.4367218 ]
 [70.42251587]
 [70.40951538]
 [70.39778137]
 [70.38759613]].
[2019-03-23 02:21:54,175] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:21:54,176] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4687
[2019-03-23 02:21:54,182] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.78333333333333, 85.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7063497949993731, 6.911199999999999, 6.9112, 121.9260426156618, 527817.5965687006, 527817.5965687011, 145907.6866592034], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7607400.0000, 
sim time next is 7608000.0000, 
raw observation next is [21.66666666666667, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6966824456674751, 6.911200000000001, 6.9112, 121.9260426156618, 520623.6395780682, 520623.6395780678, 144493.7461378619], 
processed observation next is [1.0, 0.043478260869565216, 0.3580246913580249, 0.8566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6208530570843438, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18593701413502436, 0.18593701413502423, 0.2778725887266575], 
reward next is 0.7221, 
noisyNet noise sample is [array([-1.7804496], dtype=float32), 0.91844755]. 
=============================================
[2019-03-23 02:21:54,214] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[65.752075]
 [65.60033 ]
 [65.426605]
 [65.21261 ]
 [65.03228 ]], R is [[65.97288513]
 [66.03256226]
 [66.08891296]
 [66.14221954]
 [66.19268799]].
[2019-03-23 02:21:58,084] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:21:58,085] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:21:58,180] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run9
[2019-03-23 02:22:02,549] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:22:02,551] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:22:02,618] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run9
[2019-03-23 02:22:03,344] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:22:03,345] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:22:03,417] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run9
[2019-03-23 02:22:09,124] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:22:09,126] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:22:09,191] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run9
[2019-03-23 02:22:10,514] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:22:10,519] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:22:10,575] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run9
[2019-03-23 02:22:11,880] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7218354e-01 3.7580250e-19 9.4304863e-29 6.9912291e-32 8.2781649e-01], sum to 1.0000
[2019-03-23 02:22:11,882] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8636
[2019-03-23 02:22:11,886] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 67.0, 1.0, 2.0, 0.3201319068969283, 1.0, 1.0, 0.3201319068969283, 1.0, 2.0, 0.5175728623933181, 6.9112, 6.9112, 121.94756008, 1155255.818992721, 1155255.818992721, 263246.7131866794], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7894800.0000, 
sim time next is 7895400.0000, 
raw observation next is [24.26666666666667, 66.0, 1.0, 2.0, 0.3040507664079873, 1.0, 2.0, 0.3040507664079873, 1.0, 2.0, 0.4905701368236376, 6.9112, 6.9112, 121.94756008, 1093248.202531639, 1093248.202531639, 257086.8645156444], 
processed observation next is [1.0, 0.391304347826087, 0.4543209876543211, 0.66, 1.0, 1.0, 0.1714890076285563, 1.0, 1.0, 0.1714890076285563, 1.0, 1.0, 0.36321267102954696, 0.0, 0.0, 0.8096049824067558, 0.3904457866184425, 0.3904457866184425, 0.49439781637623925], 
reward next is 0.5056, 
noisyNet noise sample is [array([-0.4742373], dtype=float32), -0.66278297]. 
=============================================
[2019-03-23 02:22:12,752] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:22:12,753] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:22:12,816] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run9
[2019-03-23 02:22:13,057] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:22:13,057] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:22:13,122] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run9
[2019-03-23 02:22:13,151] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:22:13,154] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:22:13,220] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run9
[2019-03-23 02:22:13,476] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:22:13,477] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:22:13,524] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run9
[2019-03-23 02:22:14,361] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:22:14,362] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:22:14,404] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run9
[2019-03-23 02:22:14,620] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:22:14,623] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4500
[2019-03-23 02:22:14,628] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.13333333333333, 24.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6258479521855763, 6.9112, 6.9112, 121.9260426156618, 454595.9906852821, 454595.9906852821, 127948.1073365761], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 243600.0000, 
sim time next is 244200.0000, 
raw observation next is [29.91666666666666, 25.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6226073525000188, 6.9112, 6.9112, 121.9260426156618, 452309.9849383434, 452309.9849383434, 127685.9347243085], 
processed observation next is [0.0, 0.8260869565217391, 0.66358024691358, 0.2533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5282591906250234, 0.0, 0.0, 0.8094621288201359, 0.16153928033512263, 0.16153928033512263, 0.24554987446982404], 
reward next is 0.7545, 
noisyNet noise sample is [array([0.2911213], dtype=float32), 2.191523]. 
=============================================
[2019-03-23 02:22:14,948] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:22:14,949] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:22:15,010] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run9
[2019-03-23 02:22:15,035] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:22:15,036] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:22:15,091] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run9
[2019-03-23 02:22:15,115] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:22:15,116] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:22:15,171] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run9
[2019-03-23 02:22:15,278] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:22:15,279] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:22:15,305] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run9
[2019-03-23 02:22:15,335] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:22:15,337] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:22:15,382] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run9
[2019-03-23 02:22:16,682] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 02:22:16,683] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:22:16,685] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:22:16,685] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:22:16,686] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:22:16,687] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:22:16,687] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:22:16,686] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:22:16,689] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:22:16,689] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:22:16,690] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:22:16,711] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run69
[2019-03-23 02:22:16,738] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run69
[2019-03-23 02:22:16,739] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run69
[2019-03-23 02:22:16,787] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run69
[2019-03-23 02:22:16,810] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run69
[2019-03-23 02:22:32,087] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10779233], dtype=float32), -0.15823339]
[2019-03-23 02:22:32,089] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.66666666666666, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5096711245338452, 6.9112, 6.9112, 121.9260426156618, 363911.9638834934, 363911.9638834934, 110290.6313981796]
[2019-03-23 02:22:32,093] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:22:32,095] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.005779342735873216
[2019-03-23 02:23:18,309] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.10779233], dtype=float32), -0.15823339]
[2019-03-23 02:23:18,310] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.75, 92.5, 1.0, 2.0, 0.233786302405804, 1.0, 1.0, 0.233786302405804, 1.0, 1.0, 0.3721954073183561, 6.9112, 6.9112, 121.94756008, 799351.4813941632, 799351.4813941632, 231949.6566106587]
[2019-03-23 02:23:18,311] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:23:18,314] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.7990935e-10 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00], sampled 0.041252685621549046
[2019-03-23 02:23:22,877] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.10779233], dtype=float32), -0.15823339]
[2019-03-23 02:23:22,878] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.28672862166666, 95.709202905, 1.0, 1.0, 0.7003540190136243, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9259527950484, 798205.6694624844, 798205.6694624844, 176216.5159234771]
[2019-03-23 02:23:22,878] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:23:22,882] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 8.413998e-25], sampled 0.6106218029127474
[2019-03-23 02:23:22,884] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 798205.6694624844 W.
[2019-03-23 02:24:02,386] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.10779233], dtype=float32), -0.15823339]
[2019-03-23 02:24:02,388] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.33333333333333, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4282440064399006, 6.9112, 6.9112, 121.9260426156618, 305760.1547518515, 305760.1547518515, 99045.2334900719]
[2019-03-23 02:24:02,390] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:24:02,392] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.32681593304460876
[2019-03-23 02:24:08,801] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8378.2674 2401710487.3910 289.0000
[2019-03-23 02:24:08,869] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8508.1935 2340757903.5130 261.0000
[2019-03-23 02:24:09,095] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8417.6228 2395717924.5449 243.0000
[2019-03-23 02:24:09,176] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8314.3130 2452140354.8932 240.0000
[2019-03-23 02:24:09,204] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7878.6747 2651409333.6480 281.0000
[2019-03-23 02:24:10,221] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1700000, evaluation results [1700000.0, 7878.674685078269, 2651409333.648021, 281.0, 8417.622778043333, 2395717924.544895, 243.0, 8508.193490595091, 2340757903.512971, 261.0, 8314.312986364685, 2452140354.8931994, 240.0, 8378.26744177138, 2401710487.3909836, 289.0]
[2019-03-23 02:24:11,934] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3801927e-16], sum to 1.0000
[2019-03-23 02:24:11,944] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9470
[2019-03-23 02:24:11,950] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.2, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.676835566190957, 6.9112, 6.9112, 121.9260426156618, 505708.1031354629, 505708.1031354629, 141664.9340395349], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 69600.0000, 
sim time next is 70200.0000, 
raw observation next is [28.1, 46.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6793278293161079, 6.911200000000001, 6.9112, 121.9260426156618, 507578.6785040268, 507578.6785040264, 141962.6743814292], 
processed observation next is [1.0, 0.8260869565217391, 0.5962962962962963, 0.465, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5991597866451348, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18127809946572385, 0.1812780994657237, 0.27300514304121004], 
reward next is 0.7270, 
noisyNet noise sample is [array([-2.3003], dtype=float32), 0.9364204]. 
=============================================
[2019-03-23 02:24:18,959] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.7035534e-27 3.8269376e-28 6.5178148e-36 7.0712349e-16], sum to 1.0000
[2019-03-23 02:24:18,968] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3251
[2019-03-23 02:24:18,977] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1161890.021992159 W.
[2019-03-23 02:24:18,981] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.6, 56.5, 1.0, 2.0, 0.4722625669828958, 1.0, 1.0, 0.4722625669828958, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1161890.021992159, 1161890.021992159, 230233.60285108], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 988200.0000, 
sim time next is 988800.0000, 
raw observation next is [24.73333333333333, 56.33333333333333, 1.0, 2.0, 0.3148379089494231, 1.0, 2.0, 0.3148379089494231, 1.0, 1.0, 0.5139182064300554, 6.911199999999999, 6.9112, 121.94756008, 1151721.601472911, 1151721.601472911, 260611.8931292463], 
processed observation next is [1.0, 0.43478260869565216, 0.4716049382716048, 0.5633333333333332, 1.0, 1.0, 0.18433084398740845, 1.0, 1.0, 0.18433084398740845, 1.0, 0.5, 0.39239775803756916, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4113291433831825, 0.4113291433831825, 0.5011767175562429], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5740948], dtype=float32), 0.14082709]. 
=============================================
[2019-03-23 02:24:20,894] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:24:20,902] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7685
[2019-03-23 02:24:20,910] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.73333333333333, 50.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4689287884277524, 6.911199999999999, 6.9112, 121.9260426156618, 334814.8533255542, 334814.8533255546, 98121.66091002326], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 267600.0000, 
sim time next is 268200.0000, 
raw observation next is [20.65, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4670227748867925, 6.911199999999999, 6.9112, 121.9260426156618, 333453.6650375908, 333453.6650375913, 97665.16711919053], 
processed observation next is [0.0, 0.08695652173913043, 0.3203703703703703, 0.505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3337784686084906, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11909059465628243, 0.1190905946562826, 0.18781762907536642], 
reward next is 0.8122, 
noisyNet noise sample is [array([-0.02437898], dtype=float32), -1.6689017]. 
=============================================
[2019-03-23 02:24:22,020] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:24:22,028] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2436
[2019-03-23 02:24:22,039] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.73333333333333, 62.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6270782315064888, 6.9112, 6.9112, 121.9260426156618, 466690.7862741298, 466690.7862741298, 133931.7321405172], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 202800.0000, 
sim time next is 203400.0000, 
raw observation next is [24.1, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6275272284129344, 6.9112, 6.9112, 121.9260426156618, 466794.668473474, 466794.668473474, 133779.0826168979], 
processed observation next is [0.0, 0.34782608695652173, 0.4481481481481482, 0.6, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5344090355161679, 0.0, 0.0, 0.8094621288201359, 0.16671238159766927, 0.16671238159766927, 0.2572674665709575], 
reward next is 0.7427, 
noisyNet noise sample is [array([-0.98287725], dtype=float32), 0.78846914]. 
=============================================
[2019-03-23 02:24:22,096] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 9.454672e-31], sum to 1.0000
[2019-03-23 02:24:22,105] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4229
[2019-03-23 02:24:22,114] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1066175.757678414 W.
[2019-03-23 02:24:22,124] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.61666666666667, 28.66666666666667, 1.0, 2.0, 0.4223018068909022, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7202218841360363, 6.9112, 6.9112, 121.9260426156618, 1066175.757678414, 1066175.757678414, 225363.1742635489], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 385800.0000, 
sim time next is 386400.0000, 
raw observation next is [28.73333333333333, 28.33333333333334, 1.0, 2.0, 0.4357242519424929, 1.0, 1.0, 0.4357242519424929, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1098037.471383521, 1098037.471383521, 219788.8711130392], 
processed observation next is [1.0, 0.4782608695652174, 0.619753086419753, 0.2833333333333334, 1.0, 1.0, 0.3282431570743964, 1.0, 0.5, 0.3282431570743964, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.39215623977982894, 0.39215623977982894, 0.42267090598661383], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4960583], dtype=float32), 1.6268623]. 
=============================================
[2019-03-23 02:24:28,876] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:24:28,886] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0105
[2019-03-23 02:24:28,890] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.36666666666667, 49.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5405747472542097, 6.9112, 6.9112, 121.9260426156618, 390191.9027488406, 390191.9027488406, 119701.4320588486], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 706800.0000, 
sim time next is 707400.0000, 
raw observation next is [23.2, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5265463445099204, 6.911200000000001, 6.9112, 121.9260426156618, 379998.5811926209, 379998.5811926204, 118548.7738898413], 
processed observation next is [1.0, 0.17391304347826086, 0.4148148148148148, 0.505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4081829306374005, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13571377899736461, 0.13571377899736442, 0.22797841132661786], 
reward next is 0.7720, 
noisyNet noise sample is [array([-0.29427716], dtype=float32), -0.6504013]. 
=============================================
[2019-03-23 02:24:33,485] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 6.3150177e-36 4.2934013e-33 0.0000000e+00 1.6790078e-24], sum to 1.0000
[2019-03-23 02:24:33,495] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3461
[2019-03-23 02:24:33,501] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1164331.222092167 W.
[2019-03-23 02:24:33,507] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.73333333333333, 41.33333333333334, 1.0, 2.0, 0.3185474323160287, 1.0, 2.0, 0.3185474323160287, 1.0, 2.0, 0.5196204938079472, 6.911199999999998, 6.9112, 121.94756008, 1164331.222092167, 1164331.222092167, 262107.9319743618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 469200.0000, 
sim time next is 469800.0000, 
raw observation next is [28.05, 40.5, 1.0, 2.0, 0.9277704583898377, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.210117276176815, 6.9112, 121.9247838410559, 1305276.323351684, 1152205.541357979, 227790.4253779741], 
processed observation next is [1.0, 0.43478260869565216, 0.5944444444444444, 0.405, 1.0, 1.0, 0.9140124504640925, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.029891727617681507, 0.0, 0.809453771865786, 0.4661701154827443, 0.41150197905642105, 0.4380585103422579], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7027666], dtype=float32), -1.7683948]. 
=============================================
[2019-03-23 02:24:34,045] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 8.62176e-30], sum to 1.0000
[2019-03-23 02:24:34,052] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9722
[2019-03-23 02:24:34,059] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.46666666666667, 22.66666666666667, 1.0, 2.0, 0.252816630193296, 1.0, 1.0, 0.252816630193296, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 629699.0923459247, 629699.0923459252, 171613.9704788653], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 493800.0000, 
sim time next is 494400.0000, 
raw observation next is [32.23333333333333, 23.33333333333334, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6343140292875075, 6.911200000000001, 6.9112, 121.9260426156618, 470233.0950987072, 470233.0950987068, 133267.8280637263], 
processed observation next is [1.0, 0.7391304347826086, 0.7493827160493824, 0.2333333333333334, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.5428925366093843, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16794039110668113, 0.167940391106681, 0.2562842847379352], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2565216], dtype=float32), -2.7142138]. 
=============================================
[2019-03-23 02:24:42,228] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:24:42,242] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4947
[2019-03-23 02:24:42,245] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 50.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5492255257963, 6.9112, 6.9112, 121.9260426156618, 401685.9050461988, 401685.9050461988, 122487.7795426499], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 943800.0000, 
sim time next is 944400.0000, 
raw observation next is [23.9, 50.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5424453741303391, 6.9112, 6.9112, 121.9260426156618, 395872.7629029266, 395872.7629029266, 121545.4409969326], 
processed observation next is [0.0, 0.9565217391304348, 0.4407407407407407, 0.5033333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.42805671766292386, 0.0, 0.0, 0.8094621288201359, 0.14138312960818808, 0.14138312960818808, 0.23374123268640884], 
reward next is 0.7663, 
noisyNet noise sample is [array([-1.1303855], dtype=float32), -0.9804812]. 
=============================================
[2019-03-23 02:24:43,527] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:24:43,534] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7004
[2019-03-23 02:24:43,539] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.01666666666667, 66.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6001755620028982, 6.9112, 6.9112, 121.9260426156618, 442942.2229061592, 442942.2229061592, 128842.3733419716], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 875400.0000, 
sim time next is 876000.0000, 
raw observation next is [21.93333333333334, 66.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5961274164887905, 6.9112, 6.9112, 121.9260426156618, 439434.6684181796, 439434.6684181796, 128193.3073959972], 
processed observation next is [0.0, 0.13043478260869565, 0.3679012345679015, 0.6666666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.49515927061098813, 0.0, 0.0, 0.8094621288201359, 0.15694095300649272, 0.15694095300649272, 0.24652559114614844], 
reward next is 0.7535, 
noisyNet noise sample is [array([-0.8036056], dtype=float32), 0.73222685]. 
=============================================
[2019-03-23 02:24:43,553] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.106026]
 [69.14273 ]
 [69.2609  ]
 [69.33993 ]
 [69.43997 ]], R is [[69.03588867]
 [69.09775543]
 [69.15775299]
 [69.21578979]
 [69.27171326]].
[2019-03-23 02:24:52,379] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:24:52,388] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4433
[2019-03-23 02:24:52,396] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.6, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.531397179445031, 6.9112, 6.9112, 121.9260426156618, 387782.5609744494, 387782.5609744494, 120613.5071339999], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 795600.0000, 
sim time next is 796200.0000, 
raw observation next is [22.66666666666667, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5330886213560451, 6.9112, 6.9112, 121.9260426156618, 389285.3410063101, 389285.3410063101, 120868.2957758839], 
processed observation next is [0.0, 0.21739130434782608, 0.39506172839506193, 0.58, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4163607766950563, 0.0, 0.0, 0.8094621288201359, 0.139030478930825, 0.139030478930825, 0.2324390303382383], 
reward next is 0.7676, 
noisyNet noise sample is [array([-2.2288017], dtype=float32), 0.06324216]. 
=============================================
[2019-03-23 02:24:55,345] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:24:55,352] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8888
[2019-03-23 02:24:55,359] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.91666666666666, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5019448079236557, 6.911200000000001, 6.9112, 121.9260426156618, 361761.0121232748, 361761.0121232743, 116431.8546249511], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 949800.0000, 
sim time next is 950400.0000, 
raw observation next is [22.8, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4999962773617797, 6.911199999999999, 6.9112, 121.9260426156618, 360203.8783045569, 360203.8783045574, 116225.4293405314], 
processed observation next is [1.0, 0.0, 0.4, 0.52, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3749953467022246, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12864424225162746, 0.12864424225162766, 0.22351044103948345], 
reward next is 0.7765, 
noisyNet noise sample is [array([-0.8885178], dtype=float32), -1.420708]. 
=============================================
[2019-03-23 02:24:55,714] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:24:55,726] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3920
[2019-03-23 02:24:55,735] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.86666666666667, 38.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5516608096584341, 6.9112, 6.9112, 121.9260426156618, 403949.205804873, 403949.205804873, 122908.8911551506], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 773400.0000, 
sim time next is 774000.0000, 
raw observation next is [26.7, 39.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5483218444855475, 6.911200000000001, 6.9112, 121.9260426156618, 401489.0730841113, 401489.0730841109, 122617.3709213855], 
processed observation next is [1.0, 1.0, 0.5444444444444444, 0.39, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4354023056069344, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1433889546728969, 0.14338895467289675, 0.2358026363872798], 
reward next is 0.7642, 
noisyNet noise sample is [array([0.4810427], dtype=float32), 0.13385832]. 
=============================================
[2019-03-23 02:24:55,762] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[74.93214 ]
 [74.955574]
 [74.98597 ]
 [75.02603 ]
 [75.080765]], R is [[74.9329834 ]
 [74.94728851]
 [74.96082306]
 [74.97357178]
 [74.98564148]].
[2019-03-23 02:24:56,252] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:24:56,261] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6974
[2019-03-23 02:24:56,266] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.63333333333333, 46.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5221368298997539, 6.911200000000001, 6.9112, 121.9260426156618, 380646.3701127509, 380646.3701127504, 119689.9825613083], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 781800.0000, 
sim time next is 782400.0000, 
raw observation next is [24.46666666666667, 47.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5249928578585215, 6.9112, 6.9112, 121.9260426156618, 382578.1213842431, 382578.1213842431, 119861.4001455968], 
processed observation next is [0.0, 0.043478260869565216, 0.46172839506172847, 0.47333333333333344, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.40624107232315176, 0.0, 0.0, 0.8094621288201359, 0.13663504335151538, 0.13663504335151538, 0.23050269258768616], 
reward next is 0.7695, 
noisyNet noise sample is [array([-0.40689898], dtype=float32), -1.0402805]. 
=============================================
[2019-03-23 02:24:57,611] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1518822e-19], sum to 1.0000
[2019-03-23 02:24:57,621] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5822
[2019-03-23 02:24:57,630] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.68333333333333, 59.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5538847822515093, 6.911200000000001, 6.9112, 121.9260426156618, 406104.3324141823, 406104.3324141818, 123338.7138797377], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1641000.0000, 
sim time next is 1641600.0000, 
raw observation next is [22.6, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5548228511813948, 6.9112, 6.9112, 121.9260426156618, 406795.876076451, 406795.876076451, 123421.1086517074], 
processed observation next is [1.0, 0.0, 0.39259259259259266, 0.6, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4435285639767435, 0.0, 0.0, 0.8094621288201359, 0.14528424145587535, 0.14528424145587535, 0.23734828586866807], 
reward next is 0.7627, 
noisyNet noise sample is [array([0.19445948], dtype=float32), -1.0909996]. 
=============================================
[2019-03-23 02:24:58,629] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:24:58,637] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3250
[2019-03-23 02:24:58,641] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.11666666666667, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5672524110698067, 6.9112, 6.9112, 121.9260426156618, 412680.0997343975, 412680.0997343975, 123115.5510352997], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1659000.0000, 
sim time next is 1659600.0000, 
raw observation next is [17.9, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5460933400450861, 6.9112, 6.9112, 121.9260426156618, 396984.9496668494, 396984.9496668494, 121215.906961715], 
processed observation next is [1.0, 0.21739130434782608, 0.21851851851851847, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43261667505635765, 0.0, 0.0, 0.8094621288201359, 0.14178033916673194, 0.14178033916673194, 0.23310751338791344], 
reward next is 0.7669, 
noisyNet noise sample is [array([1.4014449], dtype=float32), 1.3204575]. 
=============================================
[2019-03-23 02:25:01,922] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:25:01,932] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4376
[2019-03-23 02:25:01,935] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.3, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7001147658691224, 6.911200000000001, 6.9112, 121.9260426156618, 523172.8795674267, 523172.8795674262, 145107.2989396534], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1710000.0000, 
sim time next is 1710600.0000, 
raw observation next is [23.25, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7031609436387752, 6.911200000000001, 6.9112, 121.9260426156618, 525436.5758148564, 525436.575814856, 145538.8146758016], 
processed observation next is [1.0, 0.8260869565217391, 0.4166666666666667, 0.7566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6289511795484689, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1876559199338773, 0.18765591993387715, 0.2798823359150031], 
reward next is 0.7201, 
noisyNet noise sample is [array([0.11248954], dtype=float32), -0.4564593]. 
=============================================
[2019-03-23 02:25:05,042] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 02:25:05,044] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:25:05,045] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:25:05,045] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:25:05,047] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:25:05,047] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:25:05,048] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:25:05,050] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:25:05,052] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:25:05,049] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:25:05,054] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:25:05,077] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run70
[2019-03-23 02:25:05,110] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run70
[2019-03-23 02:25:05,111] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run70
[2019-03-23 02:25:05,157] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run70
[2019-03-23 02:25:05,157] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run70
[2019-03-23 02:25:40,225] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.21351455], dtype=float32), -0.13344757]
[2019-03-23 02:25:40,226] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.73333333333333, 72.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7553841634029741, 6.9112, 6.9112, 121.9260426156618, 562908.2399900845, 562908.2399900845, 153745.2441026393]
[2019-03-23 02:25:40,228] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:25:40,231] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8631270461278934
[2019-03-23 02:26:04,228] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.21351455], dtype=float32), -0.13344757]
[2019-03-23 02:26:04,229] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 89.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.732883750322046, 6.9112, 121.9227953514803, 1583871.670445109, 1163107.355561672, 245589.4987700049]
[2019-03-23 02:26:04,232] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:26:04,234] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.2287471e-07 0.0000000e+00 1.5085485e-35 9.9999094e-01 8.6354885e-06], sampled 0.2197251345148552
[2019-03-23 02:26:06,943] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.21351455], dtype=float32), -0.13344757]
[2019-03-23 02:26:06,944] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.28223992, 83.17054606, 1.0, 2.0, 0.5791308233611018, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9239843278202943, 6.911200000000001, 6.9112, 121.9260426156618, 1345442.481310854, 1345442.481310854, 285409.4239628037]
[2019-03-23 02:26:06,945] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:26:06,947] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.9732756e-38 5.2708708e-33], sampled 0.643534028644133
[2019-03-23 02:26:06,948] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1345442.481310854 W.
[2019-03-23 02:26:52,155] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.21351455], dtype=float32), -0.13344757]
[2019-03-23 02:26:52,157] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.33333333333333, 68.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8856115690876952, 6.911199999999999, 6.9112, 121.9260426156618, 647134.6803561307, 647134.6803561312, 174238.8673054833]
[2019-03-23 02:26:52,158] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:26:52,161] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8219933524999016
[2019-03-23 02:26:57,142] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8404.6799 2347636668.3659 484.0000
[2019-03-23 02:26:57,159] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8444.2426 2311336888.4279 513.0000
[2019-03-23 02:26:57,411] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8577.4846 2269303084.1612 441.0000
[2019-03-23 02:26:57,425] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7905.3949 2540882037.6645 639.0000
[2019-03-23 02:26:57,545] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8652.9366 2236461056.2435 432.0000
[2019-03-23 02:26:58,564] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1725000, evaluation results [1725000.0, 7905.394938037306, 2540882037.6644974, 639.0, 8577.484613242052, 2269303084.161153, 441.0, 8652.936585483423, 2236461056.243451, 432.0, 8404.67987606775, 2347636668.365892, 484.0, 8444.242633888873, 2311336888.4278727, 513.0]
[2019-03-23 02:26:58,707] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:26:58,718] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0957
[2019-03-23 02:26:58,722] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.43333333333334, 47.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4960284507286254, 6.911199999999999, 6.9112, 121.9260426156618, 355784.6646768142, 355784.6646768147, 115367.3872006179], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1030200.0000, 
sim time next is 1030800.0000, 
raw observation next is [23.36666666666667, 47.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4925263267212016, 6.9112, 6.9112, 121.9260426156618, 353258.3547297292, 353258.3547297292, 115095.9434839257], 
processed observation next is [1.0, 0.9565217391304348, 0.4209876543209878, 0.47666666666666674, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.365657908401502, 0.0, 0.0, 0.8094621288201359, 0.12616369811776043, 0.12616369811776043, 0.22133835285370326], 
reward next is 0.7787, 
noisyNet noise sample is [array([0.7271286], dtype=float32), 1.1877339]. 
=============================================
[2019-03-23 02:27:09,846] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1992463e-09 0.0000000e+00 7.5099761e-36 6.7870348e-34 1.0000000e+00], sum to 1.0000
[2019-03-23 02:27:09,855] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4133
[2019-03-23 02:27:09,864] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.75, 65.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2269036809396797, 6.911199999999999, 6.9112, 121.94756008, 505325.3849991619, 505325.3849991624, 192553.3204996058], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1169400.0000, 
sim time next is 1170000.0000, 
raw observation next is [21.8, 65.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2253323057554822, 6.9112, 6.9112, 121.94756008, 501941.7646238672, 501941.7646238672, 192181.3922806309], 
processed observation next is [1.0, 0.5652173913043478, 0.362962962962963, 0.65, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.03166538219435272, 0.0, 0.0, 0.8096049824067558, 0.17926491593709543, 0.17926491593709543, 0.3695796005396748], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0498817], dtype=float32), 1.8293415]. 
=============================================
[2019-03-23 02:27:09,878] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[62.642227]
 [62.047417]
 [61.512543]
 [62.495224]
 [63.264046]], R is [[62.83059311]
 [62.20228958]
 [61.58026886]
 [60.96446609]
 [60.35482025]].
[2019-03-23 02:27:15,875] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:27:15,885] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5006
[2019-03-23 02:27:15,893] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.45, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6246559126329172, 6.9112, 6.9112, 121.9260426156618, 457823.5562529006, 457823.5562529006, 129548.5431648708], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1233000.0000, 
sim time next is 1233600.0000, 
raw observation next is [18.53333333333333, 89.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5756490871831841, 6.911200000000001, 6.9112, 121.9260426156618, 422164.3434182303, 422164.3434182298, 125275.80923431], 
processed observation next is [1.0, 0.2608695652173913, 0.24197530864197525, 0.8966666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.46956135897898005, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15077297979222512, 0.15077297979222493, 0.24091501775828847], 
reward next is 0.7591, 
noisyNet noise sample is [array([1.0490533], dtype=float32), -0.07489828]. 
=============================================
[2019-03-23 02:27:42,224] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.1038136e-28 0.0000000e+00 4.0609050e-14], sum to 1.0000
[2019-03-23 02:27:42,229] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8898
[2019-03-23 02:27:42,240] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1067133.284870245 W.
[2019-03-23 02:27:42,245] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.75, 68.5, 1.0, 2.0, 0.4387975047136626, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7146961196912613, 6.9112, 6.9112, 121.9260426156618, 1067133.284870245, 1067133.284870245, 234017.2385723522], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1701000.0000, 
sim time next is 1701600.0000, 
raw observation next is [23.8, 68.33333333333333, 1.0, 2.0, 0.4805998574004668, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7833526873563269, 6.911200000000001, 6.9112, 121.9260426156618, 1169964.049578968, 1169964.049578968, 247746.342089569], 
processed observation next is [1.0, 0.6956521739130435, 0.43703703703703706, 0.6833333333333332, 1.0, 1.0, 0.3816664969053177, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7291908591954085, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.41784430342106, 0.41784430342106, 0.4764352732491711], 
reward next is 0.5236, 
noisyNet noise sample is [array([-0.6670384], dtype=float32), -0.10241697]. 
=============================================
[2019-03-23 02:27:50,081] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:27:50,087] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1932
[2019-03-23 02:27:50,093] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.33333333333334, 90.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8458885369268598, 6.911200000000001, 6.9112, 121.9260426156618, 624329.4816665691, 624329.4816665687, 167574.8088787159], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2626800.0000, 
sim time next is 2627400.0000, 
raw observation next is [23.66666666666666, 89.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8625084422007968, 6.911200000000001, 6.9112, 121.9260426156618, 634859.4340804514, 634859.434080451, 170184.05034402], 
processed observation next is [0.0, 0.391304347826087, 0.4320987654320985, 0.8983333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8281355527509959, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22673551217158977, 0.22673551217158966, 0.3272770198923462], 
reward next is 0.6727, 
noisyNet noise sample is [array([-2.0121188], dtype=float32), -0.09748695]. 
=============================================
[2019-03-23 02:27:53,356] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 02:27:53,358] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:27:53,359] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:27:53,360] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:27:53,360] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:27:53,361] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:27:53,363] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:27:53,363] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:27:53,365] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:27:53,366] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:27:53,366] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:27:53,392] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run71
[2019-03-23 02:27:53,424] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run71
[2019-03-23 02:27:53,426] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run71
[2019-03-23 02:27:53,477] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run71
[2019-03-23 02:27:53,513] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run71
[2019-03-23 02:27:57,598] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.19977231], dtype=float32), -0.100344]
[2019-03-23 02:27:57,600] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.0, 43.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4334760499533581, 6.9112, 6.9112, 121.9260426156618, 309496.5134271246, 309496.5134271246, 94832.64666797694]
[2019-03-23 02:27:57,602] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:27:57,606] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.038624668118994454
[2019-03-23 02:28:06,693] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.19977231], dtype=float32), -0.100344]
[2019-03-23 02:28:06,694] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.2, 67.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6082573260598004, 6.9112, 6.9112, 121.9260426156618, 449989.0765696348, 449989.0765696348, 130202.2797447843]
[2019-03-23 02:28:06,696] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:28:06,699] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5405967903498596
[2019-03-23 02:28:18,006] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.19977231], dtype=float32), -0.100344]
[2019-03-23 02:28:18,006] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.75, 33.83333333333334, 1.0, 2.0, 0.6252992272036346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757309.1827012452, 757309.1827012452, 164373.2362864614]
[2019-03-23 02:28:18,008] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:28:18,010] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9999797e-01 4.9271334e-33 9.6329460e-28 1.6986580e-26 1.9888732e-06], sampled 0.9636567538749822
[2019-03-23 02:28:18,011] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 757309.1827012452 W.
[2019-03-23 02:28:30,392] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.19977231], dtype=float32), -0.100344]
[2019-03-23 02:28:30,394] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.36666666666667, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7450774947547472, 6.9112, 6.9112, 121.9260426156618, 556288.0730518443, 556288.0730518443, 151424.8584388788]
[2019-03-23 02:28:30,394] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:28:30,397] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5234029909191783
[2019-03-23 02:28:55,715] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.19977231], dtype=float32), -0.100344]
[2019-03-23 02:28:55,717] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.5, 78.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6664140939151072, 6.911199999999999, 6.9112, 121.9260426156618, 497938.944488889, 497938.9444888894, 140645.2511598429]
[2019-03-23 02:28:55,719] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:28:55,723] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.550556007710472
[2019-03-23 02:28:56,201] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.19977231], dtype=float32), -0.100344]
[2019-03-23 02:28:56,202] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 73.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9180231216789317, 6.9112, 6.9112, 121.9260426156618, 665195.6568276339, 665195.6568276339, 179476.9893293683]
[2019-03-23 02:28:56,204] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:28:56,206] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6274070856007056
[2019-03-23 02:29:00,318] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.19977231], dtype=float32), -0.100344]
[2019-03-23 02:29:00,319] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.944700075, 98.33408725333332, 1.0, 2.0, 0.2700988993079827, 1.0, 2.0, 0.2700988993079827, 1.0, 2.0, 0.4300062442053428, 6.911199999999999, 6.9112, 121.94756008, 923584.6558748788, 923584.6558748792, 244865.1153391125]
[2019-03-23 02:29:00,320] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:29:00,321] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.4077874e-06 2.4522379e-33 1.6124235e-27 9.9043716e-29 9.9999559e-01], sampled 0.8774535227276816
[2019-03-23 02:29:08,088] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.19977231], dtype=float32), -0.100344]
[2019-03-23 02:29:08,089] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.08400091166667, 65.04274614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7746615031304229, 6.911200000000001, 6.9112, 121.9260426156618, 577514.4841962322, 577514.4841962317, 155853.9345685283]
[2019-03-23 02:29:08,091] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:29:08,093] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8313992772866429
[2019-03-23 02:29:09,872] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.19977231], dtype=float32), -0.100344]
[2019-03-23 02:29:09,873] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 89.0, 1.0, 2.0, 0.7444359265026694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 848474.3952321036, 848474.3952321036, 184730.2626725627]
[2019-03-23 02:29:09,874] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:29:09,879] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.6251400e-02 0.0000000e+00 1.0206178e-34 2.5151664e-36 9.7374862e-01], sampled 0.6409593810858376
[2019-03-23 02:29:12,224] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.19977231], dtype=float32), -0.100344]
[2019-03-23 02:29:12,225] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.88214359, 73.47477759333334, 1.0, 2.0, 0.5938427102511745, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9454169348267396, 6.9112, 6.9112, 121.9260426156618, 1354116.551507056, 1354116.551507056, 291472.9819601224]
[2019-03-23 02:29:12,225] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:29:12,227] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 5.612677e-25], sampled 0.8339214063919519
[2019-03-23 02:29:12,229] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1354116.551507056 W.
[2019-03-23 02:29:22,751] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.19977231], dtype=float32), -0.100344]
[2019-03-23 02:29:22,753] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.05837535, 60.37870936, 1.0, 2.0, 0.6907765892168427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426049232, 787284.4997901951, 787284.4997901951, 174410.5922730523]
[2019-03-23 02:29:22,755] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:29:22,758] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.9808753e-18], sampled 0.0020101332243505077
[2019-03-23 02:29:22,760] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 787284.4997901951 W.
[2019-03-23 02:29:25,070] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.19977231], dtype=float32), -0.100344]
[2019-03-23 02:29:25,072] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.52230564, 76.97661477, 1.0, 2.0, 0.3439171251680185, 1.0, 2.0, 0.3439171251680185, 1.0, 2.0, 0.5475272638662977, 6.9112, 6.9112, 121.94756008, 1176194.715637266, 1176194.715637266, 273387.1709292496]
[2019-03-23 02:29:25,073] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:29:25,077] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.8196518e-07 0.0000000e+00 7.9313304e-34 1.4100942e-32 9.9999917e-01], sampled 0.3865588815780243
[2019-03-23 02:29:39,625] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.19977231], dtype=float32), -0.100344]
[2019-03-23 02:29:39,626] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.33333333333334, 41.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5105993761061856, 6.911200000000001, 6.9112, 121.9260426156618, 369129.5978939062, 369129.5978939057, 117522.3687380079]
[2019-03-23 02:29:39,630] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:29:39,634] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.22432696309529387
[2019-03-23 02:29:39,898] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.19977231], dtype=float32), -0.100344]
[2019-03-23 02:29:39,899] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.29493312833333, 84.24871525833333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7852271201933794, 6.911200000000001, 6.9112, 121.9260426156618, 583244.4964041763, 583244.4964041759, 158497.5115977863]
[2019-03-23 02:29:39,901] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:29:39,906] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.9550455e-31], sampled 0.0889837509097462
[2019-03-23 02:29:43,878] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.19977231], dtype=float32), -0.100344]
[2019-03-23 02:29:43,878] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.4, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7102531558758418, 6.9112, 6.9112, 121.9260426156618, 530562.0642133465, 530562.0642133465, 146928.4777722537]
[2019-03-23 02:29:43,879] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:29:43,881] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.989032958092164
[2019-03-23 02:29:45,368] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7889.2186 2563942004.2034 607.0000
[2019-03-23 02:29:45,598] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8619.9829 2259857701.6383 402.0000
[2019-03-23 02:29:45,876] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8411.3789 2333971479.1055 479.0000
[2019-03-23 02:29:45,890] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8569.7370 2286893880.9065 420.0000
[2019-03-23 02:29:45,958] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8390.7345 2366101909.4287 443.0000
[2019-03-23 02:29:46,977] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1750000, evaluation results [1750000.0, 7889.218577545116, 2563942004.2034016, 607.0, 8569.73702682117, 2286893880.9065204, 420.0, 8619.982943922078, 2259857701.6383014, 402.0, 8390.734547102385, 2366101909.4286966, 443.0, 8411.37890719032, 2333971479.105468, 479.0]
[2019-03-23 02:29:53,136] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:29:53,141] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3891
[2019-03-23 02:29:53,147] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.5, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6102993808339285, 6.9112, 6.9112, 121.9260426156618, 453264.1210875884, 453264.1210875884, 131550.4224020631], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1990800.0000, 
sim time next is 1991400.0000, 
raw observation next is [19.48333333333333, 90.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6103739038253655, 6.9112, 6.9112, 121.9260426156618, 453234.6618031468, 453234.6618031468, 131495.7055898573], 
processed observation next is [0.0, 0.043478260869565216, 0.2771604938271604, 0.9083333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5129673797817068, 0.0, 0.0, 0.8094621288201359, 0.16186952207255242, 0.16186952207255242, 0.25287635690357174], 
reward next is 0.7471, 
noisyNet noise sample is [array([-2.912378], dtype=float32), 0.7255781]. 
=============================================
[2019-03-23 02:29:54,399] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:29:54,412] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3514
[2019-03-23 02:29:54,417] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.58333333333334, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7625323748962953, 6.9112, 6.9112, 121.9260426156618, 567753.6552885142, 567753.6552885142, 154946.3775215261], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2101800.0000, 
sim time next is 2102400.0000, 
raw observation next is [22.7, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.768455451666344, 6.911200000000001, 6.9112, 121.9260426156618, 571897.4936674056, 571897.4936674051, 155831.1881776699], 
processed observation next is [0.0, 0.34782608695652173, 0.39629629629629626, 0.88, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.71056931458293, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20424910488121628, 0.20424910488121611, 0.2996753618801344], 
reward next is 0.7003, 
noisyNet noise sample is [array([0.62460303], dtype=float32), -1.3084168]. 
=============================================
[2019-03-23 02:30:00,117] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:30:00,124] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6579
[2019-03-23 02:30:00,129] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.86666666666667, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7993102084094876, 6.9112, 6.9112, 121.9260426156618, 592639.7584507526, 592639.7584507526, 160723.5787578255], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2105400.0000, 
sim time next is 2106000.0000, 
raw observation next is [24.1, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8056037201637809, 6.9112, 6.9112, 121.9260426156618, 596795.9251734093, 596795.9251734093, 161718.2825605655], 
processed observation next is [0.0, 0.391304347826087, 0.4481481481481482, 0.82, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7570046502047262, 0.0, 0.0, 0.8094621288201359, 0.21314140184764618, 0.21314140184764618, 0.31099669723185674], 
reward next is 0.6890, 
noisyNet noise sample is [array([0.2636971], dtype=float32), 0.07811967]. 
=============================================
[2019-03-23 02:30:00,149] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[62.7575  ]
 [62.8299  ]
 [62.897816]
 [62.96235 ]
 [63.03032 ]], R is [[62.75912094]
 [62.82244873]
 [62.88703156]
 [62.95282745]
 [63.01982117]].
[2019-03-23 02:30:01,256] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:30:01,262] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6680
[2019-03-23 02:30:01,272] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 707931.8878776514 W.
[2019-03-23 02:30:01,281] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.61666666666667, 62.5, 1.0, 2.0, 0.6211834166467393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 707931.8878776514, 707931.8878776518, 161759.2037066336], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2142600.0000, 
sim time next is 2143200.0000, 
raw observation next is [29.43333333333334, 64.0, 1.0, 2.0, 0.3129158698687899, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4981722557895274, 6.911199999999999, 6.9112, 121.9260426156618, 713231.8152750172, 713231.8152750176, 198748.5150851409], 
processed observation next is [0.0, 0.8260869565217391, 0.6456790123456793, 0.64, 1.0, 1.0, 0.18204270222474986, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.3727153197369092, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25472564831250616, 0.2547256483125063, 0.3822086828560402], 
reward next is 0.6178, 
noisyNet noise sample is [array([0.08906301], dtype=float32), -0.6053664]. 
=============================================
[2019-03-23 02:30:04,257] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:30:04,265] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0740
[2019-03-23 02:30:04,270] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 822009.4356445173 W.
[2019-03-23 02:30:04,276] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.8, 91.33333333333334, 1.0, 2.0, 0.360614249815608, 1.0, 2.0, 0.360614249815608, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 822009.4356445173, 822009.4356445178, 195642.2128805121], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2956800.0000, 
sim time next is 2957400.0000, 
raw observation next is [24.85, 92.0, 1.0, 2.0, 0.2545111413601928, 1.0, 2.0, 0.2545111413601928, 1.0, 1.0, 0.4051900258946264, 6.911199999999999, 6.9112, 121.94756008, 870253.1296150039, 870253.1296150044, 239230.7383801116], 
processed observation next is [1.0, 0.21739130434782608, 0.475925925925926, 0.92, 1.0, 1.0, 0.11251326352403906, 1.0, 1.0, 0.11251326352403906, 1.0, 0.5, 0.2564875323682829, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3108046891482157, 0.31080468914821585, 0.4600591122694454], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.91236025], dtype=float32), 0.7013129]. 
=============================================
[2019-03-23 02:30:12,887] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.3094625e-08 1.6304857e-19 8.6089115e-22 9.9999988e-01 4.0374774e-19], sum to 1.0000
[2019-03-23 02:30:12,894] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2830
[2019-03-23 02:30:12,899] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.95, 23.5, 1.0, 2.0, 0.6139073919769555, 1.0, 2.0, 0.6139073919769555, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156254, 1490574.374419176, 1490574.374419176, 276675.2312954646], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2464200.0000, 
sim time next is 2464800.0000, 
raw observation next is [34.06666666666666, 23.33333333333333, 1.0, 2.0, 0.5182064768693205, 1.0, 2.0, 0.5182064768693205, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1260625.83311615, 1260625.83311615, 244297.5622848437], 
processed observation next is [1.0, 0.5217391304347826, 0.8172839506172838, 0.23333333333333328, 1.0, 1.0, 0.42643628198728634, 1.0, 1.0, 0.42643628198728634, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.45022351182719644, 0.45022351182719644, 0.4698030043939302], 
reward next is 0.5302, 
noisyNet noise sample is [array([-0.02925306], dtype=float32), 0.7680232]. 
=============================================
[2019-03-23 02:30:18,829] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:30:18,841] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0920
[2019-03-23 02:30:18,845] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.1, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5246409988203619, 6.911200000000001, 6.9112, 121.9260426156618, 377019.6211152648, 377019.6211152644, 117825.1582454321], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2430000.0000, 
sim time next is 2430600.0000, 
raw observation next is [19.93333333333334, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5360229245361323, 6.911199999999999, 6.9112, 121.9260426156618, 385035.8896417869, 385035.8896417873, 118670.2383307043], 
processed observation next is [1.0, 0.13043478260869565, 0.29382716049382746, 0.69, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.42002865567016534, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13751281772920962, 0.13751281772920973, 0.22821199678981596], 
reward next is 0.7718, 
noisyNet noise sample is [array([0.69387245], dtype=float32), -0.4835879]. 
=============================================
[2019-03-23 02:30:20,038] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 7.6330557e-33 1.0313462e-22 5.4713113e-11 5.0785921e-08], sum to 1.0000
[2019-03-23 02:30:20,046] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6941
[2019-03-23 02:30:20,055] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 688329.4781918747 W.
[2019-03-23 02:30:20,060] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 49.0, 1.0, 2.0, 0.3019953817364268, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4807864830273363, 6.9112, 6.9112, 121.9260426156618, 688329.4781918747, 688329.4781918747, 195782.6316860087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2734800.0000, 
sim time next is 2735400.0000, 
raw observation next is [32.0, 49.0, 1.0, 2.0, 0.5992572573664701, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 687646.9500638543, 687646.9500638543, 158181.4237655486], 
processed observation next is [0.0, 0.6521739130434783, 0.7407407407407407, 0.49, 1.0, 1.0, 0.5229253063886549, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24558819645137656, 0.24558819645137656, 0.30419504570297806], 
reward next is 0.6958, 
noisyNet noise sample is [array([0.13585214], dtype=float32), 1.4005891]. 
=============================================
[2019-03-23 02:30:30,806] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.000000e+00 3.687634e-30 0.000000e+00 1.965662e-26 2.375825e-38], sum to 1.0000
[2019-03-23 02:30:30,818] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3208
[2019-03-23 02:30:30,827] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 699332.5315033136 W.
[2019-03-23 02:30:30,834] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.6105478331157889, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 699332.5315033136, 699332.5315033136, 160074.7286020558], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2648400.0000, 
sim time next is 2649000.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.3069790081210881, 1.0, 1.0, 0.3069790081210881, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 699693.6998976251, 699693.6998976256, 182143.8156696171], 
processed observation next is [0.0, 0.6521739130434783, 0.5555555555555556, 0.74, 1.0, 1.0, 0.174975009667962, 1.0, 0.5, 0.174975009667962, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24989060710629468, 0.24989060710629485, 0.3502765685954175], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4685137], dtype=float32), 1.3780274]. 
=============================================
[2019-03-23 02:30:30,848] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[57.31785 ]
 [57.823242]
 [58.72024 ]
 [61.49774 ]
 [70.29535 ]], R is [[56.30450821]
 [56.43362808]
 [56.44247437]
 [55.87805176]
 [55.97027588]].
[2019-03-23 02:30:41,992] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 02:30:41,996] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:30:41,997] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:30:41,998] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:30:41,998] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:30:42,000] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:30:42,001] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:30:42,000] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:30:42,003] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:30:41,999] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:30:42,005] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:30:42,029] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run72
[2019-03-23 02:30:42,030] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run72
[2019-03-23 02:30:42,087] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run72
[2019-03-23 02:30:42,115] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run72
[2019-03-23 02:30:42,143] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run72
[2019-03-23 02:30:51,433] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.1905078], dtype=float32), -0.17598598]
[2019-03-23 02:30:51,435] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.083985295, 66.178321805, 1.0, 2.0, 0.4518676766785559, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7297601764015879, 6.9112, 6.9112, 122.1615626641543, 1085011.528657962, 1085011.528657962, 239060.1336383756]
[2019-03-23 02:30:51,436] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:30:51,438] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 5.4273598e-21 5.2980943e-22 4.1279276e-20 3.7398489e-09], sampled 0.9620773939870375
[2019-03-23 02:30:51,439] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1085011.528657962 W.
[2019-03-23 02:31:05,452] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.1905078], dtype=float32), -0.17598598]
[2019-03-23 02:31:05,453] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.4522133, 53.98934025333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6087684314542982, 6.911200000000001, 6.9112, 121.9260426156618, 451644.7944578769, 451644.7944578764, 131062.7378799228]
[2019-03-23 02:31:05,454] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:31:05,458] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.07188724107834155
[2019-03-23 02:31:44,233] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.1905078], dtype=float32), -0.17598598]
[2019-03-23 02:31:44,234] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.85601244, 91.23076145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7784349755863732, 6.911200000000001, 6.9112, 121.9260426156618, 580164.1858841765, 580164.185884176, 156445.1925287749]
[2019-03-23 02:31:44,234] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:31:44,237] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9416216688674843
[2019-03-23 02:32:33,306] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8434.2708 2337461828.4809 494.0000
[2019-03-23 02:32:33,340] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7939.3240 2527267113.0279 664.0000
[2019-03-23 02:32:33,428] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8598.2107 2264335085.5730 435.0000
[2019-03-23 02:32:33,575] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8660.5395 2228829076.4153 443.0000
[2019-03-23 02:32:33,613] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8452.2689 2300964843.3940 548.0000
[2019-03-23 02:32:34,631] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1775000, evaluation results [1775000.0, 7939.323988186945, 2527267113.027893, 664.0, 8598.21072179203, 2264335085.5729847, 435.0, 8660.539536529894, 2228829076.41535, 443.0, 8434.270797786936, 2337461828.480886, 494.0, 8452.268894540552, 2300964843.3939686, 548.0]
[2019-03-23 02:32:36,596] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:32:36,603] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7567
[2019-03-23 02:32:36,608] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.16666666666667, 52.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8226541335113609, 6.911200000000001, 6.9112, 121.9260426156618, 614694.7138508662, 614694.7138508657, 159692.6209130822], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3127800.0000, 
sim time next is 3128400.0000, 
raw observation next is [27.2, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9000578500174509, 6.9112, 6.9112, 121.9260426156618, 672668.2219693161, 672668.2219693161, 168077.4927289846], 
processed observation next is [1.0, 0.21739130434782608, 0.5629629629629629, 0.51, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8750723125218135, 0.0, 0.0, 0.8094621288201359, 0.2402386507033272, 0.2402386507033272, 0.3232259475557396], 
reward next is 0.6768, 
noisyNet noise sample is [array([-2.305105], dtype=float32), -1.51831]. 
=============================================
[2019-03-23 02:32:39,983] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.2208709e-26 1.1105799e-28 0.0000000e+00 2.2057607e-12], sum to 1.0000
[2019-03-23 02:32:39,993] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7368
[2019-03-23 02:32:40,002] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 752037.1604080326 W.
[2019-03-23 02:32:40,006] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.41666666666667, 89.0, 1.0, 2.0, 0.2199550683492792, 1.0, 2.0, 0.2199550683492792, 1.0, 1.0, 0.3501756322485232, 6.9112, 6.9112, 121.94756008, 752037.1604080326, 752037.1604080326, 227224.02077619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2933400.0000, 
sim time next is 2934000.0000, 
raw observation next is [25.3, 89.0, 1.0, 2.0, 0.650725842433264, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 741616.2096387498, 741616.2096387498, 167023.2292510126], 
processed observation next is [1.0, 1.0, 0.49259259259259264, 0.89, 1.0, 1.0, 0.5841974314681715, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2648629320138392, 0.2648629320138392, 0.32119851779040887], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6606964], dtype=float32), -0.18328714]. 
=============================================
[2019-03-23 02:32:40,020] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[35.837936]
 [36.02835 ]
 [36.538746]
 [36.594707]
 [37.382236]], R is [[35.12740326]
 [35.33916092]
 [35.62257004]
 [35.90153885]
 [35.54252243]].
[2019-03-23 02:32:47,925] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.00000000e+00 1.18163325e-36 4.06004887e-31 9.20519743e-38
 6.35345847e-22], sum to 1.0000
[2019-03-23 02:32:47,933] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5694
[2019-03-23 02:32:47,941] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 734027.7007043931 W.
[2019-03-23 02:32:47,945] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6440705460113291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 734027.7007043931, 734027.7007043931, 165825.2976402733], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3326400.0000, 
sim time next is 3327000.0000, 
raw observation next is [27.0, 79.00000000000001, 1.0, 2.0, 0.3248361966316958, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5171498042140134, 6.9112, 6.9112, 121.9260426156618, 740415.0397378244, 740415.0397378244, 202039.2506260417], 
processed observation next is [0.0, 0.5217391304347826, 0.5555555555555556, 0.7900000000000001, 1.0, 1.0, 0.19623356741868545, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.39643725526751666, 0.0, 0.0, 0.8094621288201359, 0.2644339427635087, 0.2644339427635087, 0.38853702043469557], 
reward next is 0.6115, 
noisyNet noise sample is [array([-0.94088453], dtype=float32), -0.9119567]. 
=============================================
[2019-03-23 02:32:47,959] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[50.753532]
 [52.607307]
 [56.168957]
 [66.198006]
 [66.29548 ]], R is [[50.68732071]
 [50.86155319]
 [50.35293961]
 [50.49795914]
 [50.63635254]].
[2019-03-23 02:32:53,471] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.0571814e-31 5.4879752e-32 0.0000000e+00 2.3957398e-29], sum to 1.0000
[2019-03-23 02:32:53,480] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3628
[2019-03-23 02:32:53,490] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1721934.546626878 W.
[2019-03-23 02:32:53,496] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.16666666666666, 37.66666666666667, 1.0, 2.0, 0.503317824686289, 1.0, 2.0, 0.503317824686289, 1.0, 1.0, 0.8012983688177429, 6.911199999999999, 6.9112, 121.94756008, 1721934.546626878, 1721934.546626878, 345220.4531976944], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3154200.0000, 
sim time next is 3154800.0000, 
raw observation next is [33.33333333333334, 37.33333333333334, 1.0, 2.0, 0.7603724394598492, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9840644377013479, 6.911199999999999, 6.9112, 121.9260426156618, 1595184.580056013, 1595184.580056013, 326118.9816821234], 
processed observation next is [1.0, 0.5217391304347826, 0.7901234567901239, 0.3733333333333334, 1.0, 1.0, 0.7147290945950586, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9800805471266849, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5697087785914332, 0.5697087785914332, 0.6271518878502372], 
reward next is 0.3728, 
noisyNet noise sample is [array([-1.7832594], dtype=float32), 0.87522477]. 
=============================================
[2019-03-23 02:32:56,325] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 3.1809214e-27 4.1182366e-36 2.4404306e-21], sum to 1.0000
[2019-03-23 02:32:56,335] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7810
[2019-03-23 02:32:56,341] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.93333333333333, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8592957837900704, 6.9112, 6.9112, 121.9260426156618, 634960.381396709, 634960.381396709, 169042.8769574191], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3282000.0000, 
sim time next is 3282600.0000, 
raw observation next is [22.96666666666667, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.867681144458089, 6.911200000000001, 6.9112, 121.9260426156618, 640300.9767796063, 640300.9767796058, 170385.4912012098], 
processed observation next is [0.0, 1.0, 0.4061728395061729, 0.9333333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8346014305726113, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22867892027843081, 0.22867892027843065, 0.3276644061561727], 
reward next is 0.6723, 
noisyNet noise sample is [array([1.7626679], dtype=float32), 0.96025467]. 
=============================================
[2019-03-23 02:33:02,289] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1148976e-34], sum to 1.0000
[2019-03-23 02:33:02,296] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4215
[2019-03-23 02:33:02,301] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8908958127320139, 6.9112, 6.9112, 121.9260426156618, 658815.4632077446, 658815.4632077446, 172939.3200758677], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3553200.0000, 
sim time next is 3553800.0000, 
raw observation next is [22.16666666666667, 98.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9662142934385886, 7.020663695998165, 6.9112, 121.9255885912327, 770336.3321168574, 714281.3447482758, 183068.9384292119], 
processed observation next is [1.0, 0.13043478260869565, 0.3765432098765434, 0.9816666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9577678667982356, 0.010946369599816475, 0.0, 0.8094591145700788, 0.2751201186131634, 0.25510048026724136, 0.3520556508254075], 
reward next is 0.1006, 
noisyNet noise sample is [array([-0.51524884], dtype=float32), 0.029875956]. 
=============================================
[2019-03-23 02:33:04,073] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:33:04,088] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7991
[2019-03-23 02:33:04,094] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.7, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7137834656014542, 6.911199999999999, 6.9112, 121.9260426156618, 533378.8401937499, 533378.8401937503, 146705.3303875165], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4068000.0000, 
sim time next is 4068600.0000, 
raw observation next is [20.58333333333333, 95.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9557225793220616, 7.421630754825197, 6.9112, 122.0184049471481, 975960.9465008144, 714376.7710339089, 174930.9423219911], 
processed observation next is [1.0, 0.08695652173913043, 0.31790123456790104, 0.9583333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.944653224152577, 0.05104307548251974, 0.0, 0.8100753186511498, 0.348557480893148, 0.2551345610835389, 0.33640565831152136], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3685706], dtype=float32), 1.8573406]. 
=============================================
[2019-03-23 02:33:06,610] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.1142636e-25], sum to 1.0000
[2019-03-23 02:33:06,618] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6640
[2019-03-23 02:33:06,623] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.23333333333333, 77.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9346703707183711, 6.911200000000001, 6.9112, 121.9260426156618, 679719.5094523383, 679719.5094523379, 181386.1067764855], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3530400.0000, 
sim time next is 3531000.0000, 
raw observation next is [26.61666666666667, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9439459528587351, 6.9112, 6.9112, 121.9260426156618, 685026.1059558636, 685026.1059558636, 182880.6815712849], 
processed observation next is [1.0, 0.8695652173913043, 0.5413580246913582, 0.7566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9299324410734189, 0.0, 0.0, 0.8094621288201359, 0.2446521806985227, 0.2446521806985227, 0.3516936184063171], 
reward next is 0.6483, 
noisyNet noise sample is [array([-0.8952305], dtype=float32), -0.29977703]. 
=============================================
[2019-03-23 02:33:06,633] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[56.346695]
 [55.647507]
 [54.88523 ]
 [53.587963]
 [50.75296 ]], R is [[57.11558151]
 [57.19560623]
 [57.2779541 ]
 [57.36222839]
 [57.44772339]].
[2019-03-23 02:33:07,290] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7243271e-20 1.3865467e-38 6.9514771e-36 8.7292871e-29 1.0000000e+00], sum to 1.0000
[2019-03-23 02:33:07,301] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1969
[2019-03-23 02:33:07,306] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.4, 81.0, 1.0, 2.0, 0.4930700236753797, 1.0, 1.0, 0.4930700236753797, 1.0, 2.0, 0.7849835358607964, 6.9112, 6.9112, 121.94756008, 1686842.008473718, 1686842.008473718, 340200.7365924719], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3400200.0000, 
sim time next is 3400800.0000, 
raw observation next is [26.6, 80.33333333333334, 1.0, 2.0, 0.5022623543453646, 1.0, 2.0, 0.5022623543453646, 1.0, 2.0, 0.799618025660722, 6.911199999999999, 6.9112, 121.94756008, 1718320.13357948, 1718320.133579481, 344700.8172687151], 
processed observation next is [1.0, 0.34782608695652173, 0.5407407407407407, 0.8033333333333335, 1.0, 1.0, 0.40745518374448164, 1.0, 1.0, 0.40745518374448164, 1.0, 1.0, 0.7495225320759025, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6136857619926714, 0.6136857619926718, 0.6628861870552214], 
reward next is 0.3371, 
noisyNet noise sample is [array([-0.12261657], dtype=float32), 1.0127114]. 
=============================================
[2019-03-23 02:33:07,824] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.0674132e-37 1.2389688e-37 0.0000000e+00 2.5291774e-16], sum to 1.0000
[2019-03-23 02:33:07,830] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5182
[2019-03-23 02:33:07,837] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 816575.8401431678 W.
[2019-03-23 02:33:07,844] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.7164636182076453, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816575.8401431678, 816575.8401431678, 179279.9360932066], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3469800.0000, 
sim time next is 3470400.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.3603888730232253, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5737508228991631, 6.911199999999999, 6.9112, 121.9260426156618, 821495.4206475148, 821495.4206475152, 212191.1837884764], 
processed observation next is [1.0, 0.17391304347826086, 0.4444444444444444, 1.0, 1.0, 1.0, 0.23855818217050634, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.4671885286239539, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2933912216598267, 0.29339122165982684, 0.4080599688239931], 
reward next is 0.5919, 
noisyNet noise sample is [array([-0.92113644], dtype=float32), -0.19844629]. 
=============================================
[2019-03-23 02:33:11,312] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 3.0272291e-36 5.6390824e-37 0.0000000e+00 4.7223310e-09], sum to 1.0000
[2019-03-23 02:33:11,320] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7531
[2019-03-23 02:33:11,332] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 881862.3269407812 W.
[2019-03-23 02:33:11,337] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.3868565219529972, 1.0, 1.0, 0.3868565219529972, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 881862.3269407812, 881862.3269407817, 202609.9897389468], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3468000.0000, 
sim time next is 3468600.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.3785784107958188, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6027091594250202, 6.9112, 6.9112, 121.9260426156618, 862981.2586997676, 862981.2586997676, 217581.3984290056], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 1.0, 1.0, 1.0, 0.2602123938045462, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.5033864492812753, 0.0, 0.0, 0.8094621288201359, 0.3082075923927742, 0.3082075923927742, 0.4184257662096262], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3291934], dtype=float32), 1.305771]. 
=============================================
[2019-03-23 02:33:17,294] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:33:17,301] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3567
[2019-03-23 02:33:17,307] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.2, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8905256201749941, 6.9112, 6.9112, 121.9260426156618, 651198.7552344737, 651198.7552344737, 174796.3513965545], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3628200.0000, 
sim time next is 3628800.0000, 
raw observation next is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9047830622791535, 6.911200000000001, 6.9112, 121.9260426156618, 659829.4010331787, 659829.4010331782, 177024.5743231757], 
processed observation next is [1.0, 0.0, 0.4074074074074074, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8809788278489419, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23565335751184951, 0.23565335751184935, 0.3404318736984148], 
reward next is 0.6596, 
noisyNet noise sample is [array([0.67672616], dtype=float32), -1.6464194]. 
=============================================
[2019-03-23 02:33:18,227] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:33:18,237] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3350
[2019-03-23 02:33:18,241] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.03333333333333, 99.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9138596908875571, 6.9112, 6.9112, 121.9260426156618, 666203.5797305404, 666203.5797305404, 178286.4745434537], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3633000.0000, 
sim time next is 3633600.0000, 
raw observation next is [23.06666666666667, 98.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9089195303108247, 6.911200000000001, 6.9112, 121.9260426156618, 663324.7216760815, 663324.7216760811, 177493.5211560665], 
processed observation next is [1.0, 0.043478260869565216, 0.40987654320987665, 0.9833333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8861494128885308, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23690168631288627, 0.2369016863128861, 0.3413336945308971], 
reward next is 0.6587, 
noisyNet noise sample is [array([1.3125461], dtype=float32), -1.2357655]. 
=============================================
[2019-03-23 02:33:18,475] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.000000e+00 8.595582e-31 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 02:33:18,485] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9117
[2019-03-23 02:33:18,494] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 789585.0993187804 W.
[2019-03-23 02:33:18,499] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.1, 97.5, 1.0, 2.0, 0.6827503694842506, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260421485137, 789585.0993187804, 789585.0993187799, 173467.0555219267], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3637800.0000, 
sim time next is 3638400.0000, 
raw observation next is [23.06666666666667, 98.33333333333333, 1.0, 2.0, 0.2155997743568746, 1.0, 1.0, 0.2155997743568746, 1.0, 1.0, 0.3432687938773316, 6.911199999999999, 6.9112, 121.94756008, 738343.2896592813, 738343.2896592817, 225763.2645027804], 
processed observation next is [1.0, 0.08695652173913043, 0.40987654320987665, 0.9833333333333333, 1.0, 1.0, 0.06619020756770787, 1.0, 0.5, 0.06619020756770787, 1.0, 0.5, 0.1790859923466645, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.26369403202117186, 0.26369403202117203, 0.43416012404380844], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9624262], dtype=float32), 0.07000744]. 
=============================================
[2019-03-23 02:33:20,679] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9997759e-01 4.9734500e-25 9.0406640e-31 3.1924046e-23 2.2390765e-05], sum to 1.0000
[2019-03-23 02:33:20,691] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9089
[2019-03-23 02:33:20,700] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2418759.412974278 W.
[2019-03-23 02:33:20,708] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.2, 58.33333333333334, 1.0, 2.0, 0.7867163261093872, 1.0, 2.0, 0.7067228250311282, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2418759.412974278, 2418759.412974279, 453355.0689877162], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3766800.0000, 
sim time next is 3767400.0000, 
raw observation next is [33.4, 55.5, 1.0, 2.0, 0.7961742884891493, 1.0, 2.0, 0.7114518062210092, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2434966.426670997, 2434966.426670997, 456083.564581653], 
processed observation next is [1.0, 0.6086956521739131, 0.7925925925925925, 0.555, 1.0, 1.0, 0.7573503434394634, 1.0, 1.0, 0.6564902455012015, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.8696308666682132, 0.8696308666682132, 0.8770837780416404], 
reward next is 0.1229, 
noisyNet noise sample is [array([-0.8372214], dtype=float32), -0.051125705]. 
=============================================
[2019-03-23 02:33:29,697] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 02:33:29,699] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:33:29,700] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:33:29,703] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:33:29,703] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:33:29,703] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:33:29,705] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:33:29,705] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:33:29,706] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:33:29,707] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:33:29,708] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:33:29,736] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run73
[2019-03-23 02:33:29,763] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run73
[2019-03-23 02:33:29,788] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run73
[2019-03-23 02:33:29,814] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run73
[2019-03-23 02:33:29,839] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run73
[2019-03-23 02:33:33,496] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.18861541], dtype=float32), -0.23828615]
[2019-03-23 02:33:33,498] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.33333333333333, 31.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5929932918851337, 6.911200000000001, 6.9112, 121.9260426156618, 437406.34360575, 437406.3436057496, 128057.5441332686]
[2019-03-23 02:33:33,499] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:33:33,502] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.29363847442528423
[2019-03-23 02:33:34,805] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.18861541], dtype=float32), -0.23828615]
[2019-03-23 02:33:34,807] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.61666666666666, 31.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5815505557935311, 6.9112, 6.9112, 121.9260426156618, 420654.9027171928, 420654.9027171928, 123406.7982856741]
[2019-03-23 02:33:34,807] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:33:34,809] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.016445209786004278
[2019-03-23 02:33:50,289] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.18861541], dtype=float32), -0.23828615]
[2019-03-23 02:33:50,290] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.3, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6573752843559845, 6.911199999999999, 6.9112, 121.9260426156618, 489523.1114988198, 489523.1114988203, 137195.6095957377]
[2019-03-23 02:33:50,292] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:33:50,293] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.34277212677225244
[2019-03-23 02:33:52,230] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.18861541], dtype=float32), -0.23828615]
[2019-03-23 02:33:52,231] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.46666666666667, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8288207774294236, 6.911200000000001, 6.9112, 121.9260426156618, 618642.970867977, 618642.9708679765, 161687.2690104288]
[2019-03-23 02:33:52,232] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:33:52,233] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5090642348294606
[2019-03-23 02:33:59,291] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.18861541], dtype=float32), -0.23828615]
[2019-03-23 02:33:59,294] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.6560341, 98.30022569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8520983102020946, 6.9112, 6.9112, 121.9260426156618, 627224.2853316537, 627224.2853316537, 168843.9933489867]
[2019-03-23 02:33:59,295] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:33:59,300] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9009368725783027
[2019-03-23 02:34:09,977] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.18861541], dtype=float32), -0.23828615]
[2019-03-23 02:34:09,978] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.93333333333333, 97.33333333333334, 1.0, 2.0, 0.6317090091366381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 722920.0392548885, 722920.0392548881, 163766.5169099507]
[2019-03-23 02:34:09,980] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:34:09,984] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9993217e-01 0.0000000e+00 4.1371921e-24 8.5351904e-35 6.7766239e-05], sampled 0.10481756789761087
[2019-03-23 02:34:09,985] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 722920.0392548885 W.
[2019-03-23 02:34:17,630] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.18861541], dtype=float32), -0.23828615]
[2019-03-23 02:34:17,633] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.96315941, 91.27074892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7483143100695392, 6.911200000000001, 6.9112, 121.9260426156618, 555848.907359959, 555848.9073599585, 145598.8385089067]
[2019-03-23 02:34:17,634] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:34:17,636] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.13895262946918752
[2019-03-23 02:34:20,440] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.18861541], dtype=float32), -0.23828615]
[2019-03-23 02:34:20,442] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 70.0, 1.0, 2.0, 0.8394568590141059, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1671976.379464962, 1671976.379464962, 344206.9275380191]
[2019-03-23 02:34:20,444] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:34:20,448] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.7159572e-01 1.6344655e-30 6.6385687e-23 1.7470869e-06 2.2840257e-01], sampled 0.9841371314358409
[2019-03-23 02:34:28,492] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.18861541], dtype=float32), -0.23828615]
[2019-03-23 02:34:28,494] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7797918843426217, 6.911199999999999, 6.9112, 121.9260426156618, 579152.3398419583, 579152.3398419587, 157856.748458459]
[2019-03-23 02:34:28,497] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:34:28,501] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.04061668620721903
[2019-03-23 02:34:28,993] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.18861541], dtype=float32), -0.23828615]
[2019-03-23 02:34:28,993] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.30579148333333, 62.70664884833334, 1.0, 2.0, 0.7201990009870983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 820835.4516041738, 820835.4516041738, 180006.2068476348]
[2019-03-23 02:34:28,994] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:34:28,996] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.000000e+00 0.000000e+00 7.638816e-35 0.000000e+00 9.607162e-29], sampled 0.014203844717343928
[2019-03-23 02:34:28,998] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 820835.4516041738 W.
[2019-03-23 02:34:34,973] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.18861541], dtype=float32), -0.23828615]
[2019-03-23 02:34:34,974] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.087890935, 92.97649914666667, 1.0, 2.0, 0.8984773196463198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1041396.161655567, 1041396.161655567, 218047.6586105445]
[2019-03-23 02:34:34,975] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:34:34,978] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.00000000e+00 1.12613327e-22 1.37749160e-20 2.04465495e-15
 1.11446425e-11], sampled 0.23930986392106723
[2019-03-23 02:34:34,981] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1041396.161655567 W.
[2019-03-23 02:34:55,708] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.18861541], dtype=float32), -0.23828615]
[2019-03-23 02:34:55,709] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.82882118, 81.990744175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8775752363647128, 6.911200000000001, 6.9112, 121.9260426156618, 643949.5214220465, 643949.521422046, 172622.1045174642]
[2019-03-23 02:34:55,709] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:34:55,712] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.07590203480538227
[2019-03-23 02:35:16,083] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.18861541], dtype=float32), -0.23828615]
[2019-03-23 02:35:16,084] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4556433948851487, 6.911200000000001, 6.9112, 121.9260426156618, 325327.0816266658, 325327.0816266653, 107951.1296690388]
[2019-03-23 02:35:16,086] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:35:16,088] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.11031904423790495
[2019-03-23 02:35:18,693] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8594.2174 2267473104.9879 429.0000
[2019-03-23 02:35:19,825] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7930.2910 2530332472.2527 661.0000
[2019-03-23 02:35:19,988] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8666.2535 2227158054.2456 451.0000
[2019-03-23 02:35:20,008] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8449.1579 2300223706.3244 572.0000
[2019-03-23 02:35:20,037] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8417.8355 2339491839.0438 495.0000
[2019-03-23 02:35:21,052] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1800000, evaluation results [1800000.0, 7930.291036887271, 2530332472.2527432, 661.0, 8594.217359286524, 2267473104.987938, 429.0, 8666.253513662463, 2227158054.2456083, 451.0, 8417.835528918258, 2339491839.0437837, 495.0, 8449.157885157538, 2300223706.324409, 572.0]
[2019-03-23 02:35:28,680] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:35:28,688] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9782
[2019-03-23 02:35:28,691] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.33333333333334, 99.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7452132525854043, 6.9112, 6.9112, 121.9260426156618, 556863.2356760966, 556863.2356760966, 150313.9505728249], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4169400.0000, 
sim time next is 4170000.0000, 
raw observation next is [20.66666666666667, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.727351479464538, 6.911199999999999, 6.9112, 121.9260426156618, 543338.7417447858, 543338.7417447862, 148857.0976475441], 
processed observation next is [1.0, 0.2608695652173913, 0.3209876543209878, 0.98, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6591893493306724, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19404955062313778, 0.19404955062313792, 0.2862636493222002], 
reward next is 0.7137, 
noisyNet noise sample is [array([0.11837638], dtype=float32), -0.33747998]. 
=============================================
[2019-03-23 02:35:28,708] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[64.076805]
 [64.15439 ]
 [64.07879 ]
 [63.946453]
 [63.97708 ]], R is [[64.23665619]
 [64.30522919]
 [64.38657379]
 [64.4680481 ]
 [64.54947662]].
[2019-03-23 02:35:30,802] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9908470e-07 1.3169956e-27 2.0420641e-31 2.3457601e-17 9.9999905e-01], sum to 1.0000
[2019-03-23 02:35:30,810] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3444
[2019-03-23 02:35:30,814] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.6, 89.0, 1.0, 2.0, 0.5255998388093096, 1.0, 1.0, 0.5255998388093096, 1.0, 2.0, 0.8367720609761297, 6.9112, 6.9112, 121.94756008, 1798241.764036778, 1798241.764036778, 356331.3869148], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4012200.0000, 
sim time next is 4012800.0000, 
raw observation next is [25.8, 87.33333333333334, 1.0, 2.0, 0.5255424922224073, 1.0, 2.0, 0.5255424922224073, 1.0, 2.0, 0.8366807633421334, 6.911200000000002, 6.9112, 121.94756008, 1798045.365953011, 1798045.36595301, 356302.4458536078], 
processed observation next is [1.0, 0.43478260869565216, 0.5111111111111112, 0.8733333333333334, 1.0, 1.0, 0.43516963359810396, 1.0, 1.0, 0.43516963359810396, 1.0, 1.0, 0.7958509541776667, 1.7763568394002506e-16, 0.0, 0.8096049824067558, 0.6421590592689325, 0.6421590592689321, 0.6851970112569381], 
reward next is 0.3148, 
noisyNet noise sample is [array([0.2075024], dtype=float32), -0.53835773]. 
=============================================
[2019-03-23 02:35:33,857] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:35:33,865] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7087
[2019-03-23 02:35:33,871] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7155415280016725, 6.9112, 6.9112, 121.9260426156618, 534721.4216754317, 534721.4216754317, 146586.2698028262], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4062600.0000, 
sim time next is 4063200.0000, 
raw observation next is [20.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7129761130581705, 6.911199999999999, 6.9112, 121.9260426156618, 532803.6449466478, 532803.6449466483, 146300.9974996314], 
processed observation next is [1.0, 0.0, 0.2962962962962963, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6412201413227131, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19028701605237422, 0.19028701605237439, 0.2813480721146758], 
reward next is 0.7187, 
noisyNet noise sample is [array([-0.43653014], dtype=float32), 1.5310115]. 
=============================================
[2019-03-23 02:35:38,356] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 3.0062617e-36 2.4816960e-32 0.0000000e+00 3.7946597e-16], sum to 1.0000
[2019-03-23 02:35:38,365] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4217
[2019-03-23 02:35:38,373] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 685917.9100076356 W.
[2019-03-23 02:35:38,381] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.5, 88.0, 1.0, 2.0, 0.2006252234861837, 1.0, 2.0, 0.2006252234861837, 1.0, 1.0, 0.3194018896973776, 6.911199999999999, 6.9112, 121.94756008, 685917.9100076356, 685917.9100076361, 220799.0002677085], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4057200.0000, 
sim time next is 4057800.0000, 
raw observation next is [23.75, 90.0, 1.0, 2.0, 0.2879698723719371, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4592506804343789, 6.911199999999999, 6.9112, 121.9260426156618, 667166.8314679312, 667166.8314679316, 191808.1996086993], 
processed observation next is [1.0, 1.0, 0.4351851851851852, 0.9, 1.0, 1.0, 0.152345086157068, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.3240633505429736, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.238273868381404, 0.23827386838140416, 0.3688619223244217], 
reward next is 0.6311, 
noisyNet noise sample is [array([-0.4719813], dtype=float32), 0.18083897]. 
=============================================
[2019-03-23 02:35:39,975] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:35:39,986] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8537
[2019-03-23 02:35:39,996] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7389321470284195, 6.9112, 6.9112, 121.9260426156618, 551674.3193541915, 551674.3193541915, 150748.7744354657], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4170600.0000, 
sim time next is 4171200.0000, 
raw observation next is [21.33333333333334, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7512982496418321, 6.911199999999999, 6.9112, 121.9260426156618, 560446.5946044732, 560446.5946044737, 152740.434444339], 
processed observation next is [1.0, 0.2608695652173913, 0.3456790123456792, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6891228120522902, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20015949807302616, 0.20015949807302633, 0.2937316047006519], 
reward next is 0.7063, 
noisyNet noise sample is [array([0.04944535], dtype=float32), 0.9114673]. 
=============================================
[2019-03-23 02:35:42,088] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 9.6260445e-16 8.7838573e-24 0.0000000e+00 1.0595231e-16], sum to 1.0000
[2019-03-23 02:35:42,093] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9797
[2019-03-23 02:35:42,102] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1634080.696196061 W.
[2019-03-23 02:35:42,105] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.26666666666667, 61.0, 1.0, 2.0, 0.4736469509028166, 1.0, 2.0, 0.4736469509028166, 1.0, 1.0, 0.7545329668304667, 6.911199999999999, 6.9112, 121.94756008, 1634080.696196061, 1634080.696196061, 330923.1209872984], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4264800.0000, 
sim time next is 4265400.0000, 
raw observation next is [27.13333333333333, 63.5, 1.0, 2.0, 0.7217220290440544, 1.0, 2.0, 0.7217220290440544, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1666697.048271197, 1666697.048271197, 313520.0955678847], 
processed observation next is [1.0, 0.34782608695652173, 0.5604938271604937, 0.635, 1.0, 1.0, 0.6687167012429218, 1.0, 1.0, 0.6687167012429218, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5952489458111417, 0.5952489458111417, 0.6029232607074705], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.11118262], dtype=float32), -0.9852441]. 
=============================================
[2019-03-23 02:35:42,745] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.8938543e-01 1.6314862e-10 2.8226314e-28 0.0000000e+00 1.0614585e-02], sum to 1.0000
[2019-03-23 02:35:42,755] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0158
[2019-03-23 02:35:42,762] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1643701.185605704 W.
[2019-03-23 02:35:42,769] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [34.16666666666667, 29.66666666666666, 1.0, 2.0, 0.7835614001199641, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9674621301099632, 6.911200000000001, 6.9112, 121.9260426156618, 1643701.185605704, 1643701.185605703, 326839.0052113676], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4200000.0000, 
sim time next is 4200600.0000, 
raw observation next is [34.13333333333333, 30.33333333333334, 1.0, 2.0, 0.8184629986083929, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9672119490632997, 6.911199999999999, 6.9112, 121.9260426156618, 1685542.344811651, 1685542.344811652, 333820.8199073375], 
processed observation next is [1.0, 0.6086956521739131, 0.8197530864197531, 0.3033333333333334, 1.0, 1.0, 0.7838845221528487, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9590149363291245, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6019794088613039, 0.6019794088613043, 0.6419631152064182], 
reward next is 0.3580, 
noisyNet noise sample is [array([-0.38091362], dtype=float32), -0.4984887]. 
=============================================
[2019-03-23 02:35:45,116] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.3444376e-37 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 02:35:45,123] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9213
[2019-03-23 02:35:45,131] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 780748.162805031 W.
[2019-03-23 02:35:45,134] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 93.33333333333334, 1.0, 2.0, 0.2246021713409915, 1.0, 2.0, 0.2246021713409915, 1.0, 1.0, 0.3582050659300153, 6.911200000000001, 6.9112, 121.94756008, 780748.162805031, 780748.1628050306, 228787.9464194336], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4335000.0000, 
sim time next is 4335600.0000, 
raw observation next is [22.6, 92.66666666666667, 1.0, 2.0, 0.602557835592096, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 712720.1995581209, 712720.1995581209, 159698.4762985234], 
processed observation next is [1.0, 0.17391304347826086, 0.39259259259259266, 0.9266666666666667, 1.0, 1.0, 0.5268545661810666, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2545429284136146, 0.2545429284136146, 0.3071124544202373], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6987472], dtype=float32), -1.374076]. 
=============================================
[2019-03-23 02:35:52,583] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.4423742e-31 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 02:35:52,592] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7400
[2019-03-23 02:35:52,598] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 727293.993419351 W.
[2019-03-23 02:35:52,603] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 82.33333333333334, 1.0, 2.0, 0.3190824375373972, 1.0, 2.0, 0.3190824375373972, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 727293.993419351, 727293.9934193515, 185103.1950552745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4440000.0000, 
sim time next is 4440600.0000, 
raw observation next is [26.5, 81.5, 1.0, 2.0, 0.6425403585670685, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732282.959423982, 732282.959423982, 165550.1191035238], 
processed observation next is [0.0, 0.391304347826087, 0.5370370370370371, 0.815, 1.0, 1.0, 0.5744528078179386, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26152962836570787, 0.26152962836570787, 0.31836561366062266], 
reward next is 0.6816, 
noisyNet noise sample is [array([0.28934973], dtype=float32), 0.18919185]. 
=============================================
[2019-03-23 02:35:55,087] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:35:55,096] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0994
[2019-03-23 02:35:55,107] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 762239.0744023292 W.
[2019-03-23 02:35:55,113] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.83333333333333, 89.0, 1.0, 2.0, 0.2209668802641073, 1.0, 2.0, 0.2209668802641073, 1.0, 2.0, 0.3520232369798807, 6.9112, 6.9112, 121.94756008, 762239.0744023292, 762239.0744023292, 227578.0783787743], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4344600.0000, 
sim time next is 4345200.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.3294112431647086, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5251865683068238, 6.911199999999999, 6.9112, 121.9260426156618, 761872.1310321561, 761872.1310321565, 203098.4536262487], 
processed observation next is [1.0, 0.30434782608695654, 0.4444444444444444, 0.89, 1.0, 1.0, 0.20168005138655787, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.40648321038352964, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27209718965434143, 0.2720971896543416, 0.3905739492812475], 
reward next is 0.6094, 
noisyNet noise sample is [array([-0.08168782], dtype=float32), 0.09368958]. 
=============================================
[2019-03-23 02:35:56,693] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:35:56,698] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5532
[2019-03-23 02:35:56,703] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 815504.5577730461 W.
[2019-03-23 02:35:56,708] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.83333333333334, 84.83333333333333, 1.0, 2.0, 0.2385080806646556, 1.0, 2.0, 0.2385080806646556, 1.0, 1.0, 0.3797126320840299, 6.911200000000001, 6.9112, 121.94756008, 815504.5577730461, 815504.5577730456, 233587.4074651942], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4731000.0000, 
sim time next is 4731600.0000, 
raw observation next is [27.66666666666667, 85.66666666666667, 1.0, 2.0, 0.2434602297281917, 1.0, 2.0, 0.2434602297281917, 1.0, 2.0, 0.3875966146734149, 6.911199999999999, 6.9112, 121.94756008, 832446.0921614943, 832446.0921614948, 235318.4495087038], 
processed observation next is [1.0, 0.782608695652174, 0.580246913580247, 0.8566666666666667, 1.0, 1.0, 0.09935741634308536, 1.0, 1.0, 0.09935741634308536, 1.0, 1.0, 0.23449576834176858, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2973021757719623, 0.29730217577196244, 0.4525354798244304], 
reward next is 0.5475, 
noisyNet noise sample is [array([1.8537658], dtype=float32), -1.5729264]. 
=============================================
[2019-03-23 02:35:56,728] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.8087727e-28 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 02:35:56,733] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1580
[2019-03-23 02:35:56,742] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 687156.677926763 W.
[2019-03-23 02:35:56,750] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.16666666666667, 99.0, 1.0, 2.0, 0.5958183938586704, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 687156.677926763, 687156.677926763, 157754.4349690668], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4506600.0000, 
sim time next is 4507200.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.200230161359861, 1.0, 1.0, 0.200230161359861, 1.0, 1.0, 0.3187738940589245, 6.911199999999999, 6.9112, 121.94756008, 684615.1992637849, 684615.1992637854, 220670.0884005811], 
processed observation next is [0.0, 0.17391304347826086, 0.4074074074074074, 1.0, 1.0, 1.0, 0.04789304923792975, 1.0, 0.5, 0.04789304923792975, 1.0, 0.5, 0.14846736757365558, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.24450542830849462, 0.24450542830849478, 0.4243655546165021], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5225652], dtype=float32), 0.1138369]. 
=============================================
[2019-03-23 02:36:05,998] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 6.1955684e-36 9.1569356e-38 0.0000000e+00 2.2682992e-16], sum to 1.0000
[2019-03-23 02:36:06,006] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0829
[2019-03-23 02:36:06,014] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 699322.3406753825 W.
[2019-03-23 02:36:06,019] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 99.0, 1.0, 2.0, 0.2043091868065149, 1.0, 2.0, 0.2043091868065149, 1.0, 2.0, 0.3252841837651435, 6.9112, 6.9112, 121.94756008, 699322.3406753825, 699322.3406753825, 222010.7794831237], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4690200.0000, 
sim time next is 4690800.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.3052212331924495, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4862093297722228, 6.9112, 6.9112, 121.9260426156618, 701356.85438368, 701356.85438368, 196551.3343481441], 
processed observation next is [1.0, 0.30434782608695654, 0.4074074074074074, 1.0, 1.0, 1.0, 0.17288242046720176, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.3577616622152785, 0.0, 0.0, 0.8094621288201359, 0.2504845908513143, 0.2504845908513143, 0.3779833352848925], 
reward next is 0.6220, 
noisyNet noise sample is [array([0.27184826], dtype=float32), 0.8436561]. 
=============================================
[2019-03-23 02:36:08,949] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 3.0383556e-38 1.9893557e-34 3.6739140e-31 8.4228084e-15], sum to 1.0000
[2019-03-23 02:36:08,955] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9762
[2019-03-23 02:36:08,963] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 823626.4840073199 W.
[2019-03-23 02:36:08,968] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 93.83333333333334, 1.0, 2.0, 0.7226465308894803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823626.4840073199, 823626.4840073199, 180477.4272555135], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4828200.0000, 
sim time next is 4828800.0000, 
raw observation next is [26.0, 93.66666666666667, 1.0, 2.0, 0.3598406930355397, 1.0, 1.0, 0.3598406930355397, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 820245.1924964526, 820245.1924964531, 195441.8394881524], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.9366666666666668, 1.0, 1.0, 0.23790558694707112, 1.0, 0.5, 0.23790558694707112, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29294471160587593, 0.2929447116058761, 0.37584969132337], 
reward next is 0.6242, 
noisyNet noise sample is [array([-1.2982215], dtype=float32), 0.6449156]. 
=============================================
[2019-03-23 02:36:16,199] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 02:36:16,200] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:36:16,200] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:36:16,201] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:36:16,202] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:36:16,203] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:36:16,204] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:36:16,202] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:36:16,203] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:36:16,209] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:36:16,208] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:36:16,231] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run74
[2019-03-23 02:36:16,261] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run74
[2019-03-23 02:36:16,288] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run74
[2019-03-23 02:36:16,315] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run74
[2019-03-23 02:36:16,315] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run74
[2019-03-23 02:36:43,010] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07655644], dtype=float32), -0.2233718]
[2019-03-23 02:36:43,010] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.96540323, 77.66575503333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4684628316496824, 6.9112, 6.9112, 121.9260426156618, 336626.4377111652, 336626.4377111652, 113511.7374276628]
[2019-03-23 02:36:43,015] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:36:43,020] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4610956135552535
[2019-03-23 02:36:48,052] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07655644], dtype=float32), -0.2233718]
[2019-03-23 02:36:48,053] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.15899843, 85.36891754999999, 1.0, 2.0, 0.7745258033765252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 913294.4020949192, 913294.4020949188, 192215.1639344725]
[2019-03-23 02:36:48,053] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:36:48,055] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 2.7547734e-32 3.4053895e-33 5.5321731e-19], sampled 0.2449771547349593
[2019-03-23 02:36:48,058] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 913294.4020949192 W.
[2019-03-23 02:36:54,278] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.07655644], dtype=float32), -0.2233718]
[2019-03-23 02:36:54,279] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.25, 48.16666666666667, 1.0, 2.0, 0.6819352575464248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777202.8432547413, 777202.8432547413, 172754.6548088063]
[2019-03-23 02:36:54,280] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:36:54,284] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9998021e-01 0.0000000e+00 7.4095144e-30 1.3465546e-23 1.9788517e-05], sampled 0.10619919376819265
[2019-03-23 02:36:54,287] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 777202.8432547413 W.
[2019-03-23 02:37:02,341] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.07655644], dtype=float32), -0.2233718]
[2019-03-23 02:37:02,346] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.67998175, 72.98635646666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9424497600621059, 6.9112, 6.9112, 121.9260426156618, 680854.3000816255, 680854.3000816255, 183093.242198924]
[2019-03-23 02:37:02,348] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:37:02,352] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4322140883199238
[2019-03-23 02:37:31,122] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07655644], dtype=float32), -0.2233718]
[2019-03-23 02:37:31,123] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.76666666666667, 89.66666666666667, 1.0, 2.0, 0.6812874193148684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 776464.1268842993, 776464.1268842989, 172630.6815004795]
[2019-03-23 02:37:31,124] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:37:31,128] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.4901130e-01 1.4823252e-34 5.6735987e-21 1.2930133e-15 1.5098867e-01], sampled 0.42044432826928324
[2019-03-23 02:37:31,131] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 776464.1268842993 W.
[2019-03-23 02:37:37,120] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.07655644], dtype=float32), -0.2233718]
[2019-03-23 02:37:37,123] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.56673792666667, 44.92318053333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.612657439388239, 6.911200000000001, 6.9112, 121.9260426156618, 454981.9099764363, 454981.9099764358, 131751.2027882573]
[2019-03-23 02:37:37,125] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:37:37,128] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6951715350654767
[2019-03-23 02:37:50,346] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.07655644], dtype=float32), -0.2233718]
[2019-03-23 02:37:50,346] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.3, 52.0, 1.0, 2.0, 0.837444637711673, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1052201.172185786, 1052201.172185786, 207566.3146752655]
[2019-03-23 02:37:50,351] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:37:50,356] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.2218225e-31 4.4330008e-26 3.7080402e-14 2.1343020e-13], sampled 0.856407956814335
[2019-03-23 02:37:50,358] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1052201.172185786 W.
[2019-03-23 02:38:08,657] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8585.2681 2276619474.5605 408.0000
[2019-03-23 02:38:08,724] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8658.0753 2232272157.4416 426.0000
[2019-03-23 02:38:09,148] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8450.3238 2302142188.9981 536.0000
[2019-03-23 02:38:09,172] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8405.0198 2344323245.6334 478.0000
[2019-03-23 02:38:09,214] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7923.4739 2537500941.9324 626.0000
[2019-03-23 02:38:10,230] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1825000, evaluation results [1825000.0, 7923.4738717299615, 2537500941.9324384, 626.0, 8585.268111493997, 2276619474.5604916, 408.0, 8658.07530154157, 2232272157.441638, 426.0, 8405.019826913467, 2344323245.6334157, 478.0, 8450.323773075663, 2302142188.998108, 536.0]
[2019-03-23 02:38:14,649] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.9897442e-09 5.2054765e-19 5.1136459e-25 2.1291819e-06 9.9999785e-01], sum to 1.0000
[2019-03-23 02:38:14,660] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0004
[2019-03-23 02:38:14,664] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.06666666666667, 85.66666666666667, 1.0, 2.0, 0.5415073805827907, 1.0, 2.0, 0.5415073805827907, 1.0, 1.0, 0.8620973855519785, 6.9112, 6.9112, 121.94756008, 1852722.884854071, 1852722.884854071, 364428.1495810998], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4812000.0000, 
sim time next is 4812600.0000, 
raw observation next is [28.33333333333334, 84.83333333333333, 1.0, 2.0, 0.5540353554233655, 1.0, 2.0, 0.5540353554233655, 1.0, 2.0, 0.8820423295058297, 6.9112, 6.9112, 121.94756008, 1895631.797258848, 1895631.797258848, 370901.071298037], 
processed observation next is [1.0, 0.6956521739130435, 0.6049382716049385, 0.8483333333333333, 1.0, 1.0, 0.4690897088373398, 1.0, 1.0, 0.4690897088373398, 1.0, 1.0, 0.8525529118822872, 0.0, 0.0, 0.8096049824067558, 0.6770113561638743, 0.6770113561638743, 0.7132712909577635], 
reward next is 0.2867, 
noisyNet noise sample is [array([0.30655265], dtype=float32), 0.824791]. 
=============================================
[2019-03-23 02:38:15,133] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.2226965e-05 2.2909930e-16 8.5141067e-26 9.9993777e-01 1.7479199e-19], sum to 1.0000
[2019-03-23 02:38:15,144] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3106
[2019-03-23 02:38:15,151] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 87.33333333333333, 1.0, 2.0, 0.7797817685583882, 1.0, 2.0, 0.7797817685583882, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1778565.94817175, 1778565.94817175, 335470.4747835809], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4792200.0000, 
sim time next is 4792800.0000, 
raw observation next is [26.0, 87.66666666666667, 1.0, 2.0, 0.7442412122128893, 1.0, 2.0, 0.7442412122128893, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1697426.220650042, 1697426.220650042, 321252.4557549077], 
processed observation next is [1.0, 0.4782608695652174, 0.5185185185185185, 0.8766666666666667, 1.0, 1.0, 0.695525252634392, 1.0, 1.0, 0.695525252634392, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6062236502321579, 0.6062236502321579, 0.6177931841440533], 
reward next is 0.3822, 
noisyNet noise sample is [array([-0.50487465], dtype=float32), 0.119698316]. 
=============================================
[2019-03-23 02:38:15,408] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.3003466e-10 3.7701407e-26 3.3727323e-26 5.5912214e-10 1.0000000e+00], sum to 1.0000
[2019-03-23 02:38:15,416] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0402
[2019-03-23 02:38:15,427] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.8, 86.5, 1.0, 2.0, 0.5334754325800679, 1.0, 2.0, 0.5334754325800679, 1.0, 2.0, 0.8493102627493595, 6.911199999999999, 6.9112, 121.94756008, 1825214.163409895, 1825214.163409896, 360322.864912039], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4811400.0000, 
sim time next is 4812000.0000, 
raw observation next is [28.06666666666667, 85.66666666666667, 1.0, 2.0, 0.541495915980022, 1.0, 2.0, 0.541495915980022, 1.0, 2.0, 0.8620791335309949, 6.911199999999999, 6.9112, 121.94756008, 1852683.618985723, 1852683.618985723, 364422.2649348628], 
processed observation next is [1.0, 0.6956521739130435, 0.5950617283950619, 0.8566666666666667, 1.0, 1.0, 0.4541618047381214, 1.0, 1.0, 0.4541618047381214, 1.0, 1.0, 0.8275989169137434, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6616727210663297, 0.6616727210663297, 0.7008120479516592], 
reward next is 0.2992, 
noisyNet noise sample is [array([2.2780192], dtype=float32), -0.7677819]. 
=============================================
[2019-03-23 02:38:15,439] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[38.50534 ]
 [38.141514]
 [38.836926]
 [37.93665 ]
 [37.680965]], R is [[37.934021  ]
 [37.86175156]
 [37.78491974]
 [37.78893661]
 [37.70425797]].
[2019-03-23 02:38:16,048] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.8292295e-36 1.4362501e-34 2.5631503e-25 3.4163625e-23], sum to 1.0000
[2019-03-23 02:38:16,054] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0720
[2019-03-23 02:38:16,067] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 957364.3773674052 W.
[2019-03-23 02:38:16,072] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.33333333333333, 70.33333333333333, 1.0, 2.0, 0.4199571851530595, 1.0, 2.0, 0.4199571851530595, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 957364.3773674052, 957364.3773674048, 211741.3320779316], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5154000.0000, 
sim time next is 5154600.0000, 
raw observation next is [31.16666666666667, 70.16666666666667, 1.0, 2.0, 0.4146410440171817, 1.0, 2.0, 0.4146410440171817, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 945237.8483370399, 945237.8483370404, 210249.4390144756], 
processed observation next is [0.0, 0.6521739130434783, 0.7098765432098767, 0.7016666666666667, 1.0, 1.0, 0.3031441000204544, 1.0, 1.0, 0.3031441000204544, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33758494583465715, 0.3375849458346573, 0.4043258442586069], 
reward next is 0.5957, 
noisyNet noise sample is [array([2.0260425], dtype=float32), -1.1789538]. 
=============================================
[2019-03-23 02:38:30,721] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.1051932e-18 0.0000000e+00 0.0000000e+00 2.1660786e-23 1.0000000e+00], sum to 1.0000
[2019-03-23 02:38:30,726] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9145
[2019-03-23 02:38:30,734] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.528879601862016, 1.0, 2.0, 0.528879601862016, 1.0, 2.0, 0.8419935505704638, 6.9112, 6.9112, 121.94756008, 1809474.22500329, 1809474.22500329, 357989.5448964048], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5400600.0000, 
sim time next is 5401200.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.3759002953367564, 1.0, 2.0, 0.3759002953367564, 1.0, 2.0, 0.5984455123940616, 6.911199999999999, 6.9112, 121.94756008, 1285668.757995064, 1285668.757995064, 286686.132694836], 
processed observation next is [1.0, 0.5217391304347826, 0.5555555555555556, 0.84, 1.0, 1.0, 0.25702416111518617, 1.0, 1.0, 0.25702416111518617, 1.0, 1.0, 0.498056890492577, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.45916741356966567, 0.45916741356966567, 0.5513194859516077], 
reward next is 0.4487, 
noisyNet noise sample is [array([0.43437192], dtype=float32), 0.45982713]. 
=============================================
[2019-03-23 02:38:31,990] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0646733e-22 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 02:38:31,998] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1764
[2019-03-23 02:38:32,006] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.66666666666667, 72.33333333333334, 1.0, 2.0, 0.2721441738748857, 1.0, 2.0, 0.2721441738748857, 1.0, 2.0, 0.4332623879257948, 6.9112, 6.9112, 121.94756008, 930582.5774062434, 930582.5774062434, 245614.4682374871], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5066400.0000, 
sim time next is 5067000.0000, 
raw observation next is [31.5, 73.0, 1.0, 2.0, 0.2883130025890261, 1.0, 2.0, 0.2883130025890261, 1.0, 2.0, 0.4590036898206949, 6.9112, 6.9112, 121.94756008, 985906.589433276, 985906.589433276, 251620.5856483589], 
processed observation next is [0.0, 0.6521739130434783, 0.7222222222222222, 0.73, 1.0, 1.0, 0.15275357451074534, 1.0, 1.0, 0.15275357451074534, 1.0, 1.0, 0.3237546122758686, 0.0, 0.0, 0.8096049824067558, 0.35210949622617, 0.35210949622617, 0.4838857416314594], 
reward next is 0.5161, 
noisyNet noise sample is [array([-0.22512195], dtype=float32), -0.90227604]. 
=============================================
[2019-03-23 02:38:32,020] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[56.077522]
 [55.6007  ]
 [55.33632 ]
 [54.97444 ]
 [54.81244 ]], R is [[56.19593811]
 [56.16164398]
 [56.12485504]
 [56.08011246]
 [55.51931   ]].
[2019-03-23 02:38:37,569] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7899817e-23 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 02:38:37,579] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2209
[2019-03-23 02:38:37,585] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.95, 69.5, 1.0, 2.0, 0.3857386851660237, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6141085494162425, 6.911199999999999, 6.9112, 121.9260426156618, 879312.6900570507, 879312.6900570511, 219746.7298541922], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5157000.0000, 
sim time next is 5157600.0000, 
raw observation next is [30.93333333333333, 69.33333333333334, 1.0, 2.0, 0.2642587244676036, 1.0, 1.0, 0.2642587244676036, 1.0, 2.0, 0.4207084956582434, 6.9112, 6.9112, 121.94756008, 903602.8076399112, 903602.8076399112, 242738.2270810819], 
processed observation next is [0.0, 0.6956521739130435, 0.7012345679012344, 0.6933333333333335, 1.0, 1.0, 0.12411752912809955, 1.0, 0.5, 0.12411752912809955, 1.0, 1.0, 0.2758856195728042, 0.0, 0.0, 0.8096049824067558, 0.32271528844282543, 0.32271528844282543, 0.4668042828482344], 
reward next is 0.5332, 
noisyNet noise sample is [array([-1.0741013], dtype=float32), -1.2026209]. 
=============================================
[2019-03-23 02:38:39,060] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.4524913e-10], sum to 1.0000
[2019-03-23 02:38:39,067] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1823
[2019-03-23 02:38:39,074] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1097471.978226584 W.
[2019-03-23 02:38:39,080] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.25, 95.5, 1.0, 2.0, 0.4813727638868289, 0.0, 2.0, 0.0, 1.0, 2.0, 0.766361117324268, 6.911199999999999, 6.9112, 121.9260426156618, 1097471.978226584, 1097471.978226585, 250540.6779643957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5211000.0000, 
sim time next is 5211600.0000, 
raw observation next is [24.33333333333333, 94.0, 1.0, 2.0, 0.8283188032448036, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 944959.9731498975, 944959.9731498975, 201897.7370877488], 
processed observation next is [1.0, 0.30434782608695654, 0.45679012345678993, 0.94, 1.0, 1.0, 0.7956176229104804, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.337485704696392, 0.337485704696392, 0.38826487901490153], 
reward next is 0.6117, 
noisyNet noise sample is [array([0.2544408], dtype=float32), 0.81257826]. 
=============================================
[2019-03-23 02:38:39,773] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 6.0196139e-26 1.7787686e-35 0.0000000e+00 5.6878329e-33], sum to 1.0000
[2019-03-23 02:38:39,780] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6696
[2019-03-23 02:38:39,788] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1901608.6117717 W.
[2019-03-23 02:38:39,792] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.75, 74.83333333333333, 1.0, 2.0, 0.555780338664482, 1.0, 2.0, 0.555780338664482, 1.0, 2.0, 0.8848203996558237, 6.9112, 6.9112, 121.94756008, 1901608.6117717, 1901608.6117717, 371809.3939615453], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5223000.0000, 
sim time next is 5223600.0000, 
raw observation next is [27.9, 73.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.074496417899633, 6.9112, 121.9252905235853, 1961786.318041135, 1878164.472626867, 383545.8944276632], 
processed observation next is [1.0, 0.4782608695652174, 0.5888888888888888, 0.73, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.016329641789963302, 0.0, 0.8094571357108686, 0.7006379707289768, 0.6707730259381668, 0.7375882585147369], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05415983], dtype=float32), -2.0059712]. 
=============================================
[2019-03-23 02:38:41,173] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 7.809378e-36], sum to 1.0000
[2019-03-23 02:38:41,180] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6496
[2019-03-23 02:38:41,194] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1713243.768942645 W.
[2019-03-23 02:38:41,199] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.08333333333333, 74.0, 1.0, 2.0, 0.7505654308486206, 1.0, 2.0, 0.7505654308486206, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1713243.768942645, 1713243.768942645, 323821.8728852829], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5314200.0000, 
sim time next is 5314800.0000, 
raw observation next is [26.26666666666667, 73.0, 1.0, 2.0, 0.6034916510713414, 1.0, 2.0, 0.6034916510713414, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1378856.781627863, 1378856.781627865, 269379.2623783565], 
processed observation next is [1.0, 0.5217391304347826, 0.5283950617283951, 0.73, 1.0, 1.0, 0.5279662512754064, 1.0, 1.0, 0.5279662512754064, 0.0, 1.0, -0.25, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.4924488505813796, 0.4924488505813804, 0.518037043035301], 
reward next is 0.4820, 
noisyNet noise sample is [array([0.41829023], dtype=float32), -0.7592177]. 
=============================================
[2019-03-23 02:38:45,278] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4375265e-16 3.9932945e-38 1.8275638e-33 9.2277477e-35 1.0000000e+00], sum to 1.0000
[2019-03-23 02:38:45,285] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3519
[2019-03-23 02:38:45,294] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.46666666666667, 66.66666666666667, 1.0, 2.0, 0.5377537248648132, 1.0, 2.0, 0.5377537248648132, 1.0, 2.0, 0.8561214434009262, 6.911199999999999, 6.9112, 121.94756008, 1839866.835943282, 1839866.835943282, 362505.2401764389], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5330400.0000, 
sim time next is 5331000.0000, 
raw observation next is [28.48333333333333, 66.83333333333333, 1.0, 2.0, 0.5383570380574589, 1.0, 2.0, 0.5383570380574589, 1.0, 2.0, 0.8570819376521572, 6.9112, 6.9112, 121.94756008, 1841933.135480678, 1841933.135480678, 362813.7893671267], 
processed observation next is [1.0, 0.6956521739130435, 0.6104938271604937, 0.6683333333333333, 1.0, 1.0, 0.45042504530649874, 1.0, 1.0, 0.45042504530649874, 1.0, 1.0, 0.8213524220651965, 0.0, 0.0, 0.8096049824067558, 0.6578332626716707, 0.6578332626716707, 0.6977188257060128], 
reward next is 0.3023, 
noisyNet noise sample is [array([0.79113466], dtype=float32), -0.71438247]. 
=============================================
[2019-03-23 02:38:45,305] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[36.31543 ]
 [36.49537 ]
 [36.152943]
 [36.205204]
 [35.809864]], R is [[36.27475357]
 [36.2148819 ]
 [35.85273361]
 [35.77759552]
 [35.77178955]].
[2019-03-23 02:38:50,565] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1283292e-29 3.3372133e-36 0.0000000e+00 5.5985121e-13 1.0000000e+00], sum to 1.0000
[2019-03-23 02:38:50,577] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5726
[2019-03-23 02:38:50,585] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.5, 80.0, 1.0, 2.0, 0.5492528916528652, 1.0, 2.0, 0.5492528916528652, 1.0, 2.0, 0.874428491429222, 6.911200000000001, 6.9112, 121.94756008, 1879251.387119722, 1879251.387119722, 368420.070331319], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5398200.0000, 
sim time next is 5398800.0000, 
raw observation next is [27.33333333333334, 81.33333333333334, 1.0, 2.0, 0.5452187522578286, 1.0, 2.0, 0.5452187522578286, 1.0, 2.0, 0.8680060101295758, 6.9112, 6.9112, 121.94756008, 1865434.29531876, 1865434.29531876, 366336.8883598173], 
processed observation next is [1.0, 0.4782608695652174, 0.5679012345679014, 0.8133333333333335, 1.0, 1.0, 0.45859375268789115, 1.0, 1.0, 0.45859375268789115, 1.0, 1.0, 0.8350075126619696, 0.0, 0.0, 0.8096049824067558, 0.6662265340424143, 0.6662265340424143, 0.7044940160765718], 
reward next is 0.2955, 
noisyNet noise sample is [array([-1.2739167], dtype=float32), -1.417214]. 
=============================================
[2019-03-23 02:39:01,927] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:39:01,933] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7962
[2019-03-23 02:39:01,938] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.4, 69.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7930579899264463, 6.911200000000001, 6.9112, 121.9260426156618, 589979.5869789051, 589979.5869789047, 158968.8202473453], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5950200.0000, 
sim time next is 5950800.0000, 
raw observation next is [25.2, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7929679350284038, 6.911200000000001, 6.9112, 121.9260426156618, 589847.3569530859, 589847.3569530854, 158996.1852800627], 
processed observation next is [1.0, 0.9130434782608695, 0.4888888888888889, 0.71, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7412099187855048, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2106597703403878, 0.21065977034038763, 0.30576189476935134], 
reward next is 0.6942, 
noisyNet noise sample is [array([-0.7229762], dtype=float32), -0.8017762]. 
=============================================
[2019-03-23 02:39:05,101] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 02:39:05,102] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:39:05,102] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:39:05,105] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:39:05,105] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:39:05,107] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:39:05,106] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:39:05,108] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:39:05,110] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:39:05,109] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:39:05,112] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:39:05,132] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run75
[2019-03-23 02:39:05,164] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run75
[2019-03-23 02:39:05,165] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run75
[2019-03-23 02:39:05,219] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run75
[2019-03-23 02:39:05,219] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run75
[2019-03-23 02:39:11,483] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.14088917], dtype=float32), -0.1740689]
[2019-03-23 02:39:11,485] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.33333333333334, 37.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7688189988196943, 6.9112, 6.9112, 121.9260426156618, 557636.9891367252, 557636.9891367252, 141201.8752167497]
[2019-03-23 02:39:11,486] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:39:11,488] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5233496760554783
[2019-03-23 02:39:43,066] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.14088917], dtype=float32), -0.1740689]
[2019-03-23 02:39:43,067] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.18533799, 72.66847715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9166306221494798, 6.911199999999999, 6.9112, 121.9260426156618, 666436.0413563224, 666436.0413563228, 178955.7987650431]
[2019-03-23 02:39:43,068] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:39:43,073] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.0016343470818446226
[2019-03-23 02:40:18,489] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.14088917], dtype=float32), -0.1740689]
[2019-03-23 02:40:18,491] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.176496805, 75.47692329833333, 1.0, 2.0, 0.205856445351476, 1.0, 2.0, 0.205856445351476, 1.0, 2.0, 0.3277301652759249, 6.9112, 6.9112, 121.94756008, 703811.1519317356, 703811.1519317356, 222517.1605354525]
[2019-03-23 02:40:18,493] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:40:18,495] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.347195e-02 0.000000e+00 9.907931e-36 0.000000e+00 9.565280e-01], sampled 0.21847851485399483
[2019-03-23 02:40:19,394] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.14088917], dtype=float32), -0.1740689]
[2019-03-23 02:40:19,396] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.66666666666666, 90.66666666666666, 1.0, 2.0, 0.3672748940830559, 1.0, 2.0, 0.3672748940830559, 1.0, 2.0, 0.5847135926884628, 6.911200000000001, 6.9112, 121.94756008, 1256143.641973073, 1256143.641973073, 283043.6509812977]
[2019-03-23 02:40:19,397] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:40:19,399] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3688208e-03 3.1754363e-37 9.5069928e-33 3.0755186e-38 9.9863118e-01], sampled 0.019842170335169884
[2019-03-23 02:40:34,328] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.14088917], dtype=float32), -0.1740689]
[2019-03-23 02:40:34,329] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.66666666666667, 66.83333333333333, 1.0, 2.0, 0.2179979205793653, 1.0, 2.0, 0.2179979205793653, 1.0, 2.0, 0.3470597892589672, 6.9112, 6.9112, 121.94756008, 745342.323512249, 745342.323512249, 226563.9744084727]
[2019-03-23 02:40:34,330] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:40:34,333] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.938871e-01 0.000000e+00 5.059731e-38 0.000000e+00 6.112909e-03], sampled 0.09767479968004689
[2019-03-23 02:40:34,335] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 745342.323512249 W.
[2019-03-23 02:40:40,404] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.14088917], dtype=float32), -0.1740689]
[2019-03-23 02:40:40,405] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.91666666666667, 77.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5552023215998101, 6.911199999999999, 6.9112, 121.9260426156618, 406564.1003909286, 406564.1003909291, 123221.5532259476]
[2019-03-23 02:40:40,406] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:40:40,410] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.03150457298981868
[2019-03-23 02:40:57,063] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8391.9781 2422915701.6147 238.0000
[2019-03-23 02:40:57,671] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7856.4257 2673283697.7387 274.0000
[2019-03-23 02:40:57,724] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8456.0090 2362578243.1226 262.0000
[2019-03-23 02:40:57,757] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8298.0409 2474981646.5719 220.0000
[2019-03-23 02:40:57,841] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8334.7748 2420152354.2572 282.0000
[2019-03-23 02:40:58,857] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1850000, evaluation results [1850000.0, 7856.425701903417, 2673283697.738672, 274.0, 8391.978065428953, 2422915701.6147094, 238.0, 8456.009032957323, 2362578243.1225896, 262.0, 8298.040939333116, 2474981646.571875, 220.0, 8334.774824388714, 2420152354.2572484, 282.0]
[2019-03-23 02:41:00,527] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0299874e-34], sum to 1.0000
[2019-03-23 02:41:00,535] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3414
[2019-03-23 02:41:00,541] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.66666666666667, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7833309942659294, 6.911200000000001, 6.9112, 121.9260426156618, 582361.5866653157, 582361.5866653152, 157991.7268835223], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5748000.0000, 
sim time next is 5748600.0000, 
raw observation next is [26.83333333333333, 62.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7879280592625711, 6.911199999999999, 6.9112, 121.9260426156618, 585472.7702864391, 585472.7702864396, 158718.7114039269], 
processed observation next is [0.0, 0.5217391304347826, 0.5493827160493825, 0.625, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7349100740782138, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20909741795944253, 0.2090974179594427, 0.3052282911613979], 
reward next is 0.6948, 
noisyNet noise sample is [array([0.03974225], dtype=float32), 0.30208543]. 
=============================================
[2019-03-23 02:41:05,984] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3552285e-23 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 02:41:05,999] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9567
[2019-03-23 02:41:06,003] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.9, 45.0, 1.0, 2.0, 0.3659075150660129, 1.0, 2.0, 0.3659075150660129, 1.0, 2.0, 0.5899500568756904, 6.911199999999999, 6.9112, 121.94756008, 1314088.639824189, 1314088.63982419, 282053.2400912852], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5842800.0000, 
sim time next is 5843400.0000, 
raw observation next is [27.91666666666666, 44.66666666666666, 1.0, 2.0, 0.3348730185146201, 1.0, 2.0, 0.3348730185146201, 1.0, 2.0, 0.5407788648994976, 6.911199999999999, 6.9112, 121.94756008, 1206084.125066869, 1206084.12506687, 269190.3638748266], 
processed observation next is [1.0, 0.6521739130434783, 0.5895061728395059, 0.44666666666666655, 1.0, 1.0, 0.20818216489835725, 1.0, 1.0, 0.20818216489835725, 1.0, 1.0, 0.4259735811243719, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4307443303810246, 0.43074433038102494, 0.5176737766823588], 
reward next is 0.4823, 
noisyNet noise sample is [array([0.91687256], dtype=float32), 2.5673065]. 
=============================================
[2019-03-23 02:41:07,673] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 3.736935e-34], sum to 1.0000
[2019-03-23 02:41:07,684] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9598
[2019-03-23 02:41:07,698] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 698253.3441111607 W.
[2019-03-23 02:41:07,705] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.25, 87.0, 1.0, 2.0, 0.2949950421997732, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4732396795575937, 6.911200000000001, 6.9112, 121.9260425523097, 698253.3441111607, 698253.3441111604, 193107.5346969599], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6064200.0000, 
sim time next is 6064800.0000, 
raw observation next is [23.3, 86.66666666666666, 1.0, 2.0, 0.1968867095511523, 1.0, 1.0, 0.1968867095511523, 1.0, 2.0, 0.3148302456819998, 6.9112, 6.9112, 121.94756008, 692307.3479031782, 692307.3479031782, 219448.4357668251], 
processed observation next is [1.0, 0.17391304347826086, 0.41851851851851857, 0.8666666666666666, 1.0, 1.0, 0.043912749465657513, 1.0, 0.5, 0.043912749465657513, 1.0, 1.0, 0.14353780710249972, 0.0, 0.0, 0.8096049824067558, 0.24725262425113506, 0.24725262425113506, 0.4220162226285098], 
reward next is 0.5780, 
noisyNet noise sample is [array([-0.1264032], dtype=float32), -0.3905872]. 
=============================================
[2019-03-23 02:41:11,771] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:41:11,779] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6003
[2019-03-23 02:41:11,789] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.86666666666667, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.671933051042869, 6.9112, 6.9112, 121.9260426156618, 497637.2953880061, 497637.2953880061, 136654.3298328603], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5883600.0000, 
sim time next is 5884200.0000, 
raw observation next is [19.8, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6073533600549523, 6.9112, 6.9112, 121.9260426156618, 449493.3936937976, 449493.3936937976, 130221.6177659613], 
processed observation next is [1.0, 0.08695652173913043, 0.2888888888888889, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5091917000686904, 0.0, 0.0, 0.8094621288201359, 0.160533354890642, 0.160533354890642, 0.25042618801146405], 
reward next is 0.7496, 
noisyNet noise sample is [array([-0.02762954], dtype=float32), 1.9500248]. 
=============================================
[2019-03-23 02:41:12,883] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0126961e-01 4.0894123e-35 4.2910157e-28 3.1341096e-05 7.9869902e-01], sum to 1.0000
[2019-03-23 02:41:12,894] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8491
[2019-03-23 02:41:12,899] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 58.66666666666667, 1.0, 2.0, 0.8302081236964239, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9935610242775716, 6.9112, 6.9112, 121.9260426156618, 1665689.256337396, 1665689.256337396, 341654.465788878], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6013200.0000, 
sim time next is 6013800.0000, 
raw observation next is [29.0, 58.5, 1.0, 2.0, 0.4896003154780056, 1.0, 1.0, 0.4896003154780056, 1.0, 2.0, 0.7794596474100699, 6.9112, 6.9112, 121.94756008, 1674960.66275666, 1674960.66275666, 338514.0686762449], 
processed observation next is [1.0, 0.6086956521739131, 0.6296296296296297, 0.585, 1.0, 1.0, 0.3923813279500067, 1.0, 0.5, 0.3923813279500067, 1.0, 1.0, 0.7243245592625874, 0.0, 0.0, 0.8096049824067558, 0.5982002366988072, 0.5982002366988072, 0.6509885936081632], 
reward next is 0.3490, 
noisyNet noise sample is [array([0.1448265], dtype=float32), 0.18221883]. 
=============================================
[2019-03-23 02:41:15,008] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9755365e-01 2.2810060e-03 7.8594506e-17 1.6305150e-04 2.2397612e-06], sum to 1.0000
[2019-03-23 02:41:15,018] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4132
[2019-03-23 02:41:15,024] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1466440.633461346 W.
[2019-03-23 02:41:15,030] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.3, 72.0, 1.0, 2.0, 0.6400311793342087, 1.0, 2.0, 0.6400311793342087, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1466440.633461346, 1466440.633461346, 282432.5285209697], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6170400.0000, 
sim time next is 6171000.0000, 
raw observation next is [26.48333333333333, 71.16666666666667, 1.0, 2.0, 0.4283114932181166, 1.0, 2.0, 0.4283114932181166, 1.0, 1.0, 0.6818858463347361, 6.9112, 6.9112, 121.94756008, 1465098.990192318, 1465098.990192318, 309706.1241221916], 
processed observation next is [1.0, 0.43478260869565216, 0.5364197530864196, 0.7116666666666667, 1.0, 1.0, 0.3194184443072817, 1.0, 1.0, 0.3194184443072817, 1.0, 0.5, 0.6023573079184201, 0.0, 0.0, 0.8096049824067558, 0.5232496393543993, 0.5232496393543993, 0.5955887002349839], 
reward next is 0.4044, 
noisyNet noise sample is [array([-0.8540776], dtype=float32), 0.10852614]. 
=============================================
[2019-03-23 02:41:15,056] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[43.513584]
 [42.90882 ]
 [42.586445]
 [43.237335]
 [42.99384 ]], R is [[43.616436  ]
 [43.63713074]
 [43.20075989]
 [42.76875305]
 [42.78845978]].
[2019-03-23 02:41:15,831] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 8.859188e-27 4.999022e-36], sum to 1.0000
[2019-03-23 02:41:15,841] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9649
[2019-03-23 02:41:15,850] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1063364.27858464 W.
[2019-03-23 02:41:15,856] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.66666666666666, 63.33333333333333, 1.0, 2.0, 0.4664228310420026, 1.0, 2.0, 0.4664228310420026, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1063364.27858464, 1063364.27858464, 225193.253448098], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6007200.0000, 
sim time next is 6007800.0000, 
raw observation next is [28.83333333333334, 62.66666666666667, 1.0, 2.0, 0.447156569983857, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7118878222870977, 6.911199999999999, 6.9112, 121.9260426156618, 1019411.280289658, 1019411.280289659, 239096.8320120062], 
processed observation next is [1.0, 0.5217391304347826, 0.623456790123457, 0.6266666666666667, 1.0, 1.0, 0.34185305950459166, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.6398597778588722, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3640754572463064, 0.3640754572463068, 0.45980160002308884], 
reward next is 0.5402, 
noisyNet noise sample is [array([0.11727852], dtype=float32), 0.058909114]. 
=============================================
[2019-03-23 02:41:15,992] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.254875e-18 0.000000e+00 0.000000e+00 1.000000e+00 9.488252e-28], sum to 1.0000
[2019-03-23 02:41:16,002] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6311
[2019-03-23 02:41:16,009] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 61.0, 1.0, 2.0, 0.7579901148235931, 1.0, 1.0, 0.7579901148235931, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426135041, 1728814.337804836, 1728814.337804837, 326699.7207281635], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6009600.0000, 
sim time next is 6010200.0000, 
raw observation next is [29.0, 60.5, 1.0, 2.0, 0.7977181381428339, 1.0, 2.0, 0.7977181381428339, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156612, 1819517.800181451, 1819517.800181451, 342811.0619746128], 
processed observation next is [1.0, 0.5652173913043478, 0.6296296296296297, 0.605, 1.0, 1.0, 0.7591882596938498, 1.0, 1.0, 0.7591882596938498, 0.0, 1.0, -0.25, 0.0, 0.0, 0.809462128820132, 0.6498277857790896, 0.6498277857790896, 0.6592520422588708], 
reward next is 0.3407, 
noisyNet noise sample is [array([1.0127109], dtype=float32), 0.3752913]. 
=============================================
[2019-03-23 02:41:18,474] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.0168731e-28 0.0000000e+00 1.5838791e-30 1.2303980e-20], sum to 1.0000
[2019-03-23 02:41:18,483] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5904
[2019-03-23 02:41:18,491] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 720181.6508599033 W.
[2019-03-23 02:41:18,496] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.13333333333333, 82.0, 1.0, 2.0, 0.3159635364392053, 1.0, 2.0, 0.3159635364392053, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 720181.6508599033, 720181.6508599038, 184335.6685024399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6338400.0000, 
sim time next is 6339000.0000, 
raw observation next is [26.36666666666667, 81.0, 1.0, 2.0, 0.6365379162748412, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 725438.9285051927, 725438.9285051927, 164475.8868930712], 
processed observation next is [0.0, 0.34782608695652173, 0.5320987654320989, 0.81, 1.0, 1.0, 0.5673070431843348, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2590853316089974, 0.2590853316089974, 0.3162997824866754], 
reward next is 0.6837, 
noisyNet noise sample is [array([-1.069077], dtype=float32), 1.3717412]. 
=============================================
[2019-03-23 02:41:18,511] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[57.359894]
 [57.44539 ]
 [56.964676]
 [57.09966 ]
 [56.677166]], R is [[57.69182587]
 [57.11490631]
 [56.54375839]
 [56.66672516]
 [56.67176819]].
[2019-03-23 02:41:24,919] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:41:24,927] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5515
[2019-03-23 02:41:24,939] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1107117.567418901 W.
[2019-03-23 02:41:24,942] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.38333333333333, 83.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9701642173338683, 7.678034296145507, 6.9112, 121.9234474794465, 1107117.567418901, 714438.2270864538, 182751.1007611286], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6163800.0000, 
sim time next is 6164400.0000, 
raw observation next is [24.56666666666667, 82.66666666666667, 1.0, 1.0, 0.3909214835290414, 1.0, 1.0, 0.3909214835290414, 1.0, 2.0, 0.6224692994777634, 6.9112, 6.9112, 121.94756008, 1341446.462368981, 1341446.462368981, 293156.5052593719], 
processed observation next is [1.0, 0.34782608695652173, 0.46543209876543223, 0.8266666666666667, 1.0, 0.5, 0.27490652801076354, 1.0, 0.5, 0.27490652801076354, 1.0, 1.0, 0.5280866243472042, 0.0, 0.0, 0.8096049824067558, 0.47908802227463604, 0.47908802227463604, 0.5637625101141767], 
reward next is 0.4362, 
noisyNet noise sample is [array([1.5290122], dtype=float32), -2.471874]. 
=============================================
[2019-03-23 02:41:25,631] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.9876605e-30 3.3111056e-35 4.4501020e-16 1.9028072e-10], sum to 1.0000
[2019-03-23 02:41:25,642] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4575
[2019-03-23 02:41:25,651] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 718568.1236883663 W.
[2019-03-23 02:41:25,656] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.6, 67.0, 1.0, 2.0, 0.2101706635326313, 1.0, 1.0, 0.2101706635326313, 1.0, 1.0, 0.3345985411246014, 6.911199999999999, 6.9112, 121.94756008, 718568.1236883663, 718568.1236883667, 223945.6624839053], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6267600.0000, 
sim time next is 6268200.0000, 
raw observation next is [28.73333333333333, 66.5, 1.0, 2.0, 0.3142383163471493, 1.0, 2.0, 0.3142383163471493, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 716247.4870348921, 716247.4870348925, 183912.7185958372], 
processed observation next is [0.0, 0.5652173913043478, 0.619753086419753, 0.665, 1.0, 1.0, 0.18361704327041586, 1.0, 1.0, 0.18361704327041586, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2558026739410329, 0.25580267394103307, 0.35367830499199465], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3257831], dtype=float32), -0.12888679]. 
=============================================
[2019-03-23 02:41:29,126] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:41:29,134] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3854
[2019-03-23 02:41:29,139] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.3, 81.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7726952630302593, 6.911200000000001, 6.9112, 121.9260426156618, 575789.6235662407, 575789.6235662402, 155829.8978220792], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6232200.0000, 
sim time next is 6232800.0000, 
raw observation next is [23.2, 82.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7705667328881818, 6.911200000000001, 6.9112, 121.9260426156618, 574227.635243447, 574227.6352434466, 155554.8181527866], 
processed observation next is [0.0, 0.13043478260869565, 0.4148148148148148, 0.8233333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7132084161102272, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2050812983012311, 0.20508129830123092, 0.2991438810630512], 
reward next is 0.7009, 
noisyNet noise sample is [array([0.4537675], dtype=float32), 0.42643198]. 
=============================================
[2019-03-23 02:41:32,262] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:41:32,268] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1726
[2019-03-23 02:41:32,272] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.06666666666667, 68.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7039712704908042, 6.9112, 6.9112, 121.9260426156618, 526068.7254053588, 526068.7254053588, 145096.7749828047], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6993600.0000, 
sim time next is 6994200.0000, 
raw observation next is [23.93333333333334, 69.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7023733717727216, 6.911200000000001, 6.9112, 121.9260426156618, 524869.5953252534, 524869.595325253, 144855.8343582613], 
processed observation next is [0.0, 0.9565217391304348, 0.4419753086419756, 0.6933333333333332, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.627966714715902, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18745342690187622, 0.18745342690187605, 0.2785689122274255], 
reward next is 0.7214, 
noisyNet noise sample is [array([-1.2238299], dtype=float32), 0.006023081]. 
=============================================
[2019-03-23 02:41:37,301] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:41:37,309] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2146
[2019-03-23 02:41:37,315] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.9, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9133673637156452, 6.9112, 6.9112, 121.9260426156618, 668607.1020854072, 668607.1020854072, 177697.6029423482], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6303600.0000, 
sim time next is 6304200.0000, 
raw observation next is [24.86666666666667, 83.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9116338183377725, 6.911199999999999, 6.9112, 121.9260426156618, 667535.1545404652, 667535.1545404657, 177424.4716424084], 
processed observation next is [0.0, 1.0, 0.47654320987654336, 0.8316666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8895422729222154, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23840541233588045, 0.2384054123358806, 0.34120090700463157], 
reward next is 0.6588, 
noisyNet noise sample is [array([-0.11950074], dtype=float32), -0.5108527]. 
=============================================
[2019-03-23 02:41:37,321] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.5677533e-15 3.2858355e-30 1.2158841e-10 8.5120349e-27], sum to 1.0000
[2019-03-23 02:41:37,331] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3999
[2019-03-23 02:41:37,339] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2129057.275446296 W.
[2019-03-23 02:41:37,345] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.4, 55.0, 1.0, 2.0, 0.9332657357926043, 1.0, 2.0, 0.9332657357926043, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2129057.275446296, 2129057.275446297, 401898.5690581888], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6454800.0000, 
sim time next is 6455400.0000, 
raw observation next is [31.33333333333334, 55.5, 1.0, 2.0, 0.4334784506999988, 1.0, 2.0, 0.4334784506999988, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 988208.2944437509, 988208.2944437513, 215577.1181258225], 
processed observation next is [1.0, 0.7391304347826086, 0.7160493827160496, 0.555, 1.0, 1.0, 0.3255695841666652, 1.0, 1.0, 0.3255695841666652, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.35293153372991104, 0.3529315337299112, 0.4145713810111971], 
reward next is 0.5854, 
noisyNet noise sample is [array([0.5192457], dtype=float32), -0.81363726]. 
=============================================
[2019-03-23 02:41:39,128] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:41:39,136] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9261
[2019-03-23 02:41:39,144] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.33333333333333, 87.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9177419644745471, 6.911199999999999, 6.9112, 121.9260426156618, 671178.4487348794, 671178.4487348798, 178412.4651238628], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6313800.0000, 
sim time next is 6314400.0000, 
raw observation next is [24.3, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9185135001891824, 6.9112, 6.9112, 121.9260426156618, 671621.3679298783, 671621.3679298783, 178540.2981504675], 
processed observation next is [0.0, 0.08695652173913043, 0.4555555555555556, 0.88, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.898141875236478, 0.0, 0.0, 0.8094621288201359, 0.23986477426067082, 0.23986477426067082, 0.34334672721243753], 
reward next is 0.6567, 
noisyNet noise sample is [array([0.06219923], dtype=float32), 0.57439524]. 
=============================================
[2019-03-23 02:41:50,048] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:41:50,056] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3425
[2019-03-23 02:41:50,060] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.11666666666667, 48.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.681143310640041, 6.9112, 6.9112, 121.9260426156618, 501628.3440080048, 501628.3440080048, 135998.9100605127], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6588600.0000, 
sim time next is 6589200.0000, 
raw observation next is [25.03333333333333, 48.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6274276969712628, 6.9112, 6.9112, 121.9260426156618, 461993.3702396879, 461993.3702396879, 130822.4599024914], 
processed observation next is [1.0, 0.2608695652173913, 0.482716049382716, 0.4866666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5342846212140784, 0.0, 0.0, 0.8094621288201359, 0.16499763222845998, 0.16499763222845998, 0.2515816536586373], 
reward next is 0.7484, 
noisyNet noise sample is [array([2.042171], dtype=float32), 1.2263356]. 
=============================================
[2019-03-23 02:41:50,207] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:41:50,208] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.2525661e-20 0.0000000e+00 1.4050167e-16 0.0000000e+00], sum to 1.0000
[2019-03-23 02:41:50,214] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0657
[2019-03-23 02:41:50,216] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8768
[2019-03-23 02:41:50,218] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.33333333333333, 48.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8369667846551699, 6.911200000000001, 6.9112, 121.9260426156618, 618008.3107817458, 618008.3107817454, 166368.315369701], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6879000.0000, 
sim time next is 6879600.0000, 
raw observation next is [30.2, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8315420349400252, 6.9112, 6.9112, 121.9260426156618, 614544.7856228406, 614544.7856228406, 165512.8615310591], 
processed observation next is [0.0, 0.6521739130434783, 0.674074074074074, 0.49, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7894275436750314, 0.0, 0.0, 0.8094621288201359, 0.21948028057958593, 0.21948028057958593, 0.318293964482806], 
reward next is 0.6817, 
noisyNet noise sample is [array([0.27897292], dtype=float32), -0.2945398]. 
=============================================
[2019-03-23 02:41:50,226] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2047238.810468948 W.
[2019-03-23 02:41:50,231] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.36666666666667, 79.66666666666666, 1.0, 2.0, 0.89744192884566, 1.0, 2.0, 0.89744192884566, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2047238.810468948, 2047238.810468948, 385664.884670719], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6522000.0000, 
sim time next is 6522600.0000, 
raw observation next is [28.28333333333333, 79.83333333333334, 1.0, 2.0, 0.89308317092136, 1.0, 2.0, 0.89308317092136, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2037284.297325165, 2037284.297325166, 383719.8456039352], 
processed observation next is [1.0, 0.4782608695652174, 0.6030864197530863, 0.7983333333333335, 1.0, 1.0, 0.8727180606206667, 1.0, 1.0, 0.8727180606206667, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7276015347589875, 0.7276015347589878, 0.7379227800075676], 
reward next is 0.2621, 
noisyNet noise sample is [array([1.3196466], dtype=float32), 0.07231286]. 
=============================================
[2019-03-23 02:41:51,601] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:41:51,608] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2459
[2019-03-23 02:41:51,613] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.93333333333333, 44.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5323193141867786, 6.9112, 6.9112, 121.9260426156618, 380086.8635870015, 380086.8635870015, 110390.4025000821], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6669600.0000, 
sim time next is 6670200.0000, 
raw observation next is [22.91666666666666, 44.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.525195264051391, 6.911200000000001, 6.9112, 121.9260426156618, 374998.9026233833, 374998.9026233829, 109379.7214584735], 
processed observation next is [1.0, 0.17391304347826086, 0.4043209876543208, 0.4416666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.40649408006423876, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13392817950835118, 0.13392817950835104, 0.2103456181893721], 
reward next is 0.7897, 
noisyNet noise sample is [array([-0.9965104], dtype=float32), -0.6979244]. 
=============================================
[2019-03-23 02:41:53,722] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 02:41:53,725] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:41:53,726] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:41:53,727] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:41:53,728] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:41:53,729] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:41:53,729] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:41:53,730] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:41:53,730] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:41:53,732] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:41:53,734] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:41:53,760] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run76
[2019-03-23 02:41:53,789] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run76
[2019-03-23 02:41:53,814] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run76
[2019-03-23 02:41:53,815] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run76
[2019-03-23 02:41:53,864] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run76
[2019-03-23 02:41:55,817] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.18208528], dtype=float32), -0.15933521]
[2019-03-23 02:41:55,818] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.68333333333334, 26.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5744769485510381, 6.9112, 6.9112, 121.9260426156618, 410201.8340215663, 410201.8340215663, 117005.9552928179]
[2019-03-23 02:41:55,818] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:41:55,821] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7578944247194727
[2019-03-23 02:42:13,660] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.18208528], dtype=float32), -0.15933521]
[2019-03-23 02:42:13,662] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.15, 63.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6032254564117109, 6.911200000000001, 6.9112, 121.9260426156618, 447465.9499623754, 447465.9499623749, 130493.6383004982]
[2019-03-23 02:42:13,662] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:42:13,665] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5530475029390852
[2019-03-23 02:42:22,904] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.18208528], dtype=float32), -0.15933521]
[2019-03-23 02:42:22,905] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.45, 70.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5998920254416391, 6.9112, 6.9112, 121.9260426156618, 446505.5443126034, 446505.5443126034, 131343.5660440398]
[2019-03-23 02:42:22,905] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:42:22,910] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.671024273775608
[2019-03-23 02:42:28,075] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.18208528], dtype=float32), -0.15933521]
[2019-03-23 02:42:28,078] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.25, 74.0, 1.0, 2.0, 0.6518154443705652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 760527.7968833934, 760527.7968833934, 168067.7727330776]
[2019-03-23 02:42:28,080] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:42:28,081] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.00000000e+00 7.98474999e-38 0.00000000e+00 0.00000000e+00
 1.16295196e-10], sampled 0.8502981432115911
[2019-03-23 02:42:28,083] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 760527.7968833934 W.
[2019-03-23 02:42:29,055] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.18208528], dtype=float32), -0.15933521]
[2019-03-23 02:42:29,060] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.649459655, 31.65795761, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2330365480697291, 6.9112, 6.9112, 121.94756008, 517870.2472550839, 517870.2472550839, 200273.0990430253]
[2019-03-23 02:42:29,062] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:42:29,066] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.4662487e-08 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00], sampled 0.03157343068720897
[2019-03-23 02:42:34,671] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.18208528], dtype=float32), -0.15933521]
[2019-03-23 02:42:34,673] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.58333333333333, 69.16666666666667, 1.0, 2.0, 0.6549824997843192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 746469.7792538181, 746469.7792538181, 167795.13908331]
[2019-03-23 02:42:34,675] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:42:34,678] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9998605e-01 0.0000000e+00 3.2742683e-36 0.0000000e+00 1.3959045e-05], sampled 0.1380311417368444
[2019-03-23 02:42:34,680] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 746469.7792538181 W.
[2019-03-23 02:42:51,842] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.18208528], dtype=float32), -0.15933521]
[2019-03-23 02:42:51,844] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.06666666666667, 76.66666666666667, 1.0, 2.0, 0.9194057120512493, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1048033.407370877, 1048033.407370876, 221854.4822687561]
[2019-03-23 02:42:51,846] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:42:51,848] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9999428e-01 0.0000000e+00 1.2188150e-35 7.4404050e-38 5.7417465e-06], sampled 0.48816279275387486
[2019-03-23 02:42:51,850] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1048033.407370877 W.
[2019-03-23 02:43:18,495] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.18208528], dtype=float32), -0.15933521]
[2019-03-23 02:43:18,497] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.32916652333333, 68.95499443, 1.0, 2.0, 0.5713517814557468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 706745.5270017226, 706745.5270017221, 155340.8544571805]
[2019-03-23 02:43:18,499] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:43:18,502] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.2269732e-27], sampled 0.8983894204839001
[2019-03-23 02:43:18,503] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 706745.5270017226 W.
[2019-03-23 02:43:35,133] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.18208528], dtype=float32), -0.15933521]
[2019-03-23 02:43:35,134] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.36666666666667, 63.66666666666666, 1.0, 2.0, 0.6508773102327915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 814160.3285397113, 814160.3285397113, 169720.7353351419]
[2019-03-23 02:43:35,135] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:43:35,137] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.1150368e-02 0.0000000e+00 7.3963684e-33 0.0000000e+00 9.3884957e-01], sampled 0.36387028636913676
[2019-03-23 02:43:46,756] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7877.1867 2621103886.4342 438.0000
[2019-03-23 02:43:46,966] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8461.1226 2363010313.1699 322.0000
[2019-03-23 02:43:47,014] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8326.7483 2424741592.0955 324.0000
[2019-03-23 02:43:47,167] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8547.7600 2310143379.8079 320.0000
[2019-03-23 02:43:47,221] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8395.3191 2373524209.8119 369.0000
[2019-03-23 02:43:48,240] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1875000, evaluation results [1875000.0, 7877.186712156894, 2621103886.434221, 438.0, 8461.122583538407, 2363010313.1699095, 322.0, 8547.76002765958, 2310143379.807887, 320.0, 8326.748336096061, 2424741592.0954657, 324.0, 8395.31911542175, 2373524209.8118687, 369.0]
[2019-03-23 02:43:50,755] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:43:50,765] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5517
[2019-03-23 02:43:50,770] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.2, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6447574978272349, 6.9112, 6.9112, 121.9260426156618, 480676.0466058301, 480676.0466058301, 136487.3817095126], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7420800.0000, 
sim time next is 7421400.0000, 
raw observation next is [20.2, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6434556111617146, 6.911199999999999, 6.9112, 121.9260426156618, 479705.2298708201, 479705.2298708205, 136356.1849895938], 
processed observation next is [1.0, 0.9130434782608695, 0.3037037037037037, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5543195139521432, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17132329638243576, 0.17132329638243587, 0.2622234326722958], 
reward next is 0.7378, 
noisyNet noise sample is [array([0.98079556], dtype=float32), 1.0839237]. 
=============================================
[2019-03-23 02:43:58,216] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7404625e-20 2.0920121e-27 1.4020456e-38 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 02:43:58,229] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1232
[2019-03-23 02:43:58,234] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.16666666666667, 53.00000000000001, 1.0, 2.0, 0.2756674576307191, 1.0, 2.0, 0.2756674576307191, 1.0, 2.0, 0.4513793531854999, 6.9112, 6.9112, 121.94756008, 1011994.449562151, 1011994.449562151, 245528.1543459613], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6776400.0000, 
sim time next is 6777000.0000, 
raw observation next is [25.35, 52.5, 1.0, 2.0, 0.277286869683221, 1.0, 2.0, 0.277286869683221, 1.0, 2.0, 0.4535430382601462, 6.911199999999999, 6.9112, 121.94756008, 1016702.624698078, 1016702.624698078, 246189.1673771152], 
processed observation next is [1.0, 0.43478260869565216, 0.4944444444444445, 0.525, 1.0, 1.0, 0.13962722581335837, 1.0, 1.0, 0.13962722581335837, 1.0, 1.0, 0.3169287978251827, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.36310808024931357, 0.36310808024931357, 0.4734407064944523], 
reward next is 0.5266, 
noisyNet noise sample is [array([-0.6469682], dtype=float32), 0.7925844]. 
=============================================
[2019-03-23 02:43:58,250] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[55.33305 ]
 [54.366253]
 [53.48939 ]
 [53.064293]
 [52.26257 ]], R is [[55.70154953]
 [55.6723671 ]
 [55.64587021]
 [55.61653519]
 [55.59363556]].
[2019-03-23 02:44:03,951] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:44:03,960] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0249
[2019-03-23 02:44:03,963] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.06666666666667, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7287838521620836, 6.9112, 6.9112, 121.9260426156618, 544338.124545585, 544338.124545585, 149173.3698149614], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6826800.0000, 
sim time next is 6827400.0000, 
raw observation next is [23.0, 78.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7219102108017817, 6.911199999999999, 6.9112, 121.9260426156618, 539301.0913668656, 539301.091366866, 148171.4325393511], 
processed observation next is [0.0, 0.0, 0.4074074074074074, 0.785, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.652387763502227, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19260753263102343, 0.1926075326310236, 0.2849450625756752], 
reward next is 0.7151, 
noisyNet noise sample is [array([-0.29743373], dtype=float32), 1.0659091]. 
=============================================
[2019-03-23 02:44:07,664] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:44:07,677] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4339
[2019-03-23 02:44:07,684] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.7, 76.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6886314310387547, 6.9112, 6.9112, 121.9260426156618, 514544.3807063419, 514544.3807063419, 143012.288699516], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6919800.0000, 
sim time next is 6920400.0000, 
raw observation next is [22.6, 77.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6887675157150619, 6.9112, 6.9112, 121.9260426156618, 514643.9057697994, 514643.9057697994, 143017.0096567707], 
processed observation next is [0.0, 0.08695652173913043, 0.39259259259259266, 0.7733333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6109593946438273, 0.0, 0.0, 0.8094621288201359, 0.18380139491778552, 0.18380139491778552, 0.2750327108784052], 
reward next is 0.7250, 
noisyNet noise sample is [array([0.9748788], dtype=float32), -0.80801857]. 
=============================================
[2019-03-23 02:44:14,099] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.09977624e-10 0.00000000e+00 0.00000000e+00 0.00000000e+00
 1.00000000e+00], sum to 1.0000
[2019-03-23 02:44:14,107] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1913
[2019-03-23 02:44:14,112] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.78333333333333, 94.83333333333334, 1.0, 2.0, 0.2246127801976243, 1.0, 2.0, 0.2246127801976243, 1.0, 2.0, 0.3661433276628914, 6.911199999999997, 6.9112, 121.94756008, 820105.7000439753, 820105.7000439767, 227654.7736588629], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7384200.0000, 
sim time next is 7384800.0000, 
raw observation next is [19.86666666666667, 94.66666666666667, 1.0, 2.0, 0.2457850089819124, 1.0, 2.0, 0.2457850089819124, 1.0, 2.0, 0.3999904126185063, 6.9112, 6.9112, 121.94756008, 895522.2821870705, 895522.2821870705, 235089.313630241], 
processed observation next is [1.0, 0.4782608695652174, 0.2913580246913582, 0.9466666666666668, 1.0, 1.0, 0.10212501069275287, 1.0, 1.0, 0.10212501069275287, 1.0, 1.0, 0.24998801577313287, 0.0, 0.0, 0.8096049824067558, 0.3198293864953823, 0.3198293864953823, 0.4520948339043096], 
reward next is 0.5479, 
noisyNet noise sample is [array([1.1487848], dtype=float32), 0.25345942]. 
=============================================
[2019-03-23 02:44:16,371] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1500865e-34], sum to 1.0000
[2019-03-23 02:44:16,381] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2474
[2019-03-23 02:44:16,387] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.83333333333333, 78.33333333333334, 1.0, 2.0, 0.2360723758336923, 1.0, 1.0, 0.2360723758336923, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156585, 563570.6377575268, 563570.6377575268, 167035.8233984414], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7060800.0000, 
sim time next is 7061400.0000, 
raw observation next is [23.8, 78.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7491548562824896, 6.911200000000001, 6.9112, 121.9260426156618, 557155.6461970677, 557155.6461970672, 153746.3119640575], 
processed observation next is [1.0, 0.7391304347826086, 0.43703703703703706, 0.785, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.6864435703531119, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1989841593560956, 0.19898415935609542, 0.2956659845462644], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.32216588], dtype=float32), 1.0598438]. 
=============================================
[2019-03-23 02:44:20,954] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:44:20,963] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4621
[2019-03-23 02:44:20,969] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.43333333333333, 91.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7837100918363279, 6.911199999999999, 6.9112, 121.9260426156618, 582422.0066525214, 582422.0066525219, 158156.4411301012], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7506600.0000, 
sim time next is 7507200.0000, 
raw observation next is [22.36666666666667, 91.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7816561010862101, 6.9112, 6.9112, 121.9260426156618, 581004.6217878967, 581004.6217878967, 157846.8589020929], 
processed observation next is [0.0, 0.9130434782608695, 0.38395061728395075, 0.9166666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7270701263577625, 0.0, 0.0, 0.8094621288201359, 0.20750165063853454, 0.20750165063853454, 0.30355165173479404], 
reward next is 0.6964, 
noisyNet noise sample is [array([-0.7758946], dtype=float32), -0.61689913]. 
=============================================
[2019-03-23 02:44:21,559] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.8742865e-24 0.0000000e+00 3.6042322e-29 5.2872338e-29], sum to 1.0000
[2019-03-23 02:44:21,566] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1545
[2019-03-23 02:44:21,574] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1125172.349306374 W.
[2019-03-23 02:44:21,580] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 69.83333333333333, 1.0, 2.0, 0.4674598275615824, 1.0, 2.0, 0.4674598275615824, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1125172.349306374, 1125172.349306375, 228003.0916837564], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7222200.0000, 
sim time next is 7222800.0000, 
raw observation next is [24.0, 70.66666666666667, 1.0, 2.0, 0.4781819541547376, 1.0, 2.0, 0.4781819541547376, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1149086.8468545, 1149086.846854501, 231212.0003332546], 
processed observation next is [1.0, 0.6086956521739131, 0.4444444444444444, 0.7066666666666667, 1.0, 1.0, 0.3787880406604019, 1.0, 1.0, 0.3787880406604019, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.41038815959089286, 0.4103881595908932, 0.4446384621793358], 
reward next is 0.5554, 
noisyNet noise sample is [array([-0.96217996], dtype=float32), 0.1781471]. 
=============================================
[2019-03-23 02:44:22,557] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:44:22,558] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:44:22,637] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run10
[2019-03-23 02:44:24,306] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:44:24,315] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8792
[2019-03-23 02:44:24,321] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.41666666666666, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8242344502305092, 6.911199999999999, 6.9112, 121.9260426156618, 609676.6512104865, 609676.651210487, 164420.3829775096], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7577400.0000, 
sim time next is 7578000.0000, 
raw observation next is [27.3, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8159998955025508, 6.9112, 6.9112, 121.9260426156618, 604229.4878441992, 604229.4878441992, 163136.4181643959], 
processed observation next is [0.0, 0.7391304347826086, 0.5666666666666667, 0.62, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7699998693781884, 0.0, 0.0, 0.8094621288201359, 0.21579624565864255, 0.21579624565864255, 0.31372388108537674], 
reward next is 0.6863, 
noisyNet noise sample is [array([-0.94993335], dtype=float32), -1.9004594]. 
=============================================
[2019-03-23 02:44:24,346] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[71.67663]
 [71.5661 ]
 [71.46643]
 [71.37711]
 [71.30754]], R is [[71.76674652]
 [71.73288727]
 [71.69687653]
 [71.6587677 ]
 [71.61878967]].
[2019-03-23 02:44:35,077] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:44:35,083] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2349
[2019-03-23 02:44:35,087] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.46666666666667, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6442197649567291, 6.9112, 6.9112, 121.9260426156618, 481037.2848531926, 481037.2848531926, 137494.8328883965], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7459800.0000, 
sim time next is 7460400.0000, 
raw observation next is [20.63333333333333, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6494472452926935, 6.911200000000001, 6.9112, 121.9260426156618, 485072.165829177, 485072.1658291765, 138300.1057142224], 
processed observation next is [0.0, 0.34782608695652173, 0.3197530864197529, 0.91, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5618090566158668, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1732400592247061, 0.1732400592247059, 0.26596174175812], 
reward next is 0.7340, 
noisyNet noise sample is [array([-1.5419295], dtype=float32), -1.3951372]. 
=============================================
[2019-03-23 02:44:37,026] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:44:37,036] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7115
[2019-03-23 02:44:37,040] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.6, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7911610056042853, 6.9112, 6.9112, 121.9260426156618, 587572.2678126887, 587572.2678126887, 159269.0703894597], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7504800.0000, 
sim time next is 7505400.0000, 
raw observation next is [22.55, 90.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7883624762275334, 6.9112, 6.9112, 121.9260426156618, 585628.8329057413, 585628.8329057413, 158856.6303382211], 
processed observation next is [0.0, 0.8695652173913043, 0.3907407407407408, 0.9083333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7354530952844168, 0.0, 0.0, 0.8094621288201359, 0.20915315460919331, 0.20915315460919331, 0.3054935198811944], 
reward next is 0.6945, 
noisyNet noise sample is [array([0.42897588], dtype=float32), -0.50515467]. 
=============================================
[2019-03-23 02:44:38,651] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:44:38,659] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9271
[2019-03-23 02:44:38,666] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.3, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6731343788120792, 6.911199999999999, 6.9112, 121.9260426156618, 503020.7948164151, 503020.7948164156, 141854.4789759575], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7462800.0000, 
sim time next is 7463400.0000, 
raw observation next is [21.45, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6788014717298921, 6.911199999999999, 6.9112, 121.9260426156618, 507249.6834899749, 507249.6834899753, 142696.4129326668], 
processed observation next is [0.0, 0.391304347826087, 0.35, 0.885, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5985018396623651, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1811606012464196, 0.18116060124641975, 0.27441617871666696], 
reward next is 0.7256, 
noisyNet noise sample is [array([-2.5428607], dtype=float32), -0.37562177]. 
=============================================
[2019-03-23 02:44:42,280] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 02:44:42,281] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:44:42,282] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:44:42,283] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:44:42,284] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:44:42,286] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:44:42,287] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:44:42,288] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:44:42,289] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:44:42,290] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:44:42,292] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:44:42,314] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run77
[2019-03-23 02:44:42,342] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run77
[2019-03-23 02:44:42,343] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run77
[2019-03-23 02:44:42,343] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run77
[2019-03-23 02:44:42,395] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run77
[2019-03-23 02:44:45,215] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.32571375], dtype=float32), -0.13802837]
[2019-03-23 02:44:45,216] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [39.91330664666667, 6.827240125666667, 1.0, 2.0, 0.8365380515930778, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156328, 1054556.929817357, 1054556.929817357, 207423.477430238]
[2019-03-23 02:44:45,217] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:44:45,219] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9999809e-01 1.8072082e-38 5.2997674e-35 1.0556181e-08 1.9164113e-06], sampled 0.6277982449634764
[2019-03-23 02:44:45,221] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1054556.929817357 W.
[2019-03-23 02:44:54,901] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.32571375], dtype=float32), -0.13802837]
[2019-03-23 02:44:54,902] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.64117555, 41.45322216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7115019669579403, 6.911199999999999, 6.9112, 121.9260426156618, 531023.1640311033, 531023.1640311037, 147837.7811063472]
[2019-03-23 02:44:54,904] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:44:54,908] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6402117881230232
[2019-03-23 02:44:57,040] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.32571375], dtype=float32), -0.13802837]
[2019-03-23 02:44:57,042] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.16666666666667, 36.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.588837285404752, 6.911200000000001, 6.9112, 121.9260426156618, 420453.0434956088, 420453.0434956083, 118579.6670934211]
[2019-03-23 02:44:57,045] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:44:57,047] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9434965417805241
[2019-03-23 02:44:59,662] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.32571375], dtype=float32), -0.13802837]
[2019-03-23 02:44:59,664] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.2, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5922139902882784, 6.9112, 6.9112, 121.9260426156618, 437959.4448598131, 437959.4448598131, 128618.251471843]
[2019-03-23 02:44:59,665] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:44:59,667] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.33875997395854884
[2019-03-23 02:45:12,561] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.32571375], dtype=float32), -0.13802837]
[2019-03-23 02:45:12,562] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.93013244833333, 48.60521442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.88259941143145, 6.911199999999999, 6.9112, 121.9260426156618, 641995.3218236432, 641995.3218236435, 174354.1825792679]
[2019-03-23 02:45:12,562] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:45:12,566] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.1496470962597105
[2019-03-23 02:45:25,557] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.32571375], dtype=float32), -0.13802837]
[2019-03-23 02:45:25,558] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.92593603, 96.74960156333333, 1.0, 2.0, 0.6085641992605648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 697586.9054530787, 697586.9054530787, 159756.4591076588]
[2019-03-23 02:45:25,559] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:45:25,561] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.7967592e-35 5.6109113e-36 2.4414213e-33 2.1422999e-13], sampled 0.86907213112393
[2019-03-23 02:45:25,562] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 697586.9054530787 W.
[2019-03-23 02:45:29,868] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.32571375], dtype=float32), -0.13802837]
[2019-03-23 02:45:29,869] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.86666666666667, 80.66666666666667, 1.0, 2.0, 0.6547832706294856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 746242.6114527322, 746242.6114527322, 167759.7292045172]
[2019-03-23 02:45:29,871] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:45:29,875] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.4572926e-01 0.0000000e+00 1.0480223e-36 2.3679265e-20 5.4270733e-02], sampled 0.38737785517550727
[2019-03-23 02:45:29,876] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 746242.6114527322 W.
[2019-03-23 02:45:31,417] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.32571375], dtype=float32), -0.13802837]
[2019-03-23 02:45:31,419] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.33333333333334, 54.0, 1.0, 2.0, 0.6171850498711867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 703373.0573193575, 703373.0573193571, 161058.093102758]
[2019-03-23 02:45:31,421] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:45:31,425] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 6.664761e-25 0.000000e+00], sampled 0.9798793272482038
[2019-03-23 02:45:31,426] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 703373.0573193575 W.
[2019-03-23 02:45:38,558] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.32571375], dtype=float32), -0.13802837]
[2019-03-23 02:45:38,560] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.84127068333333, 80.44435932333334, 1.0, 2.0, 0.7648597588245784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 871765.7943743422, 871765.7943743422, 188792.5881593775]
[2019-03-23 02:45:38,562] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:45:38,565] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9592316e-01 4.3330540e-34 3.8725423e-33 5.8862607e-31 4.0768776e-03], sampled 0.5547935476461879
[2019-03-23 02:45:38,567] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 871765.7943743422 W.
[2019-03-23 02:45:52,964] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.32571375], dtype=float32), -0.13802837]
[2019-03-23 02:45:52,965] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.79108522333333, 70.62865237, 1.0, 2.0, 0.5953793179308998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 729488.1768946552, 729488.1768946552, 159324.4151689362]
[2019-03-23 02:45:52,966] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:45:52,968] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 6.000455e-31], sampled 0.660307106318486
[2019-03-23 02:45:52,970] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 729488.1768946552 W.
[2019-03-23 02:46:09,062] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.32571375], dtype=float32), -0.13802837]
[2019-03-23 02:46:09,064] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.06878502333333, 86.99325341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9120306273762766, 6.911200000000001, 6.9112, 121.9260426156618, 662262.4756580391, 662262.4756580386, 178461.2295922967]
[2019-03-23 02:46:09,066] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:46:09,069] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.13141848439393078
[2019-03-23 02:46:25,444] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.32571375], dtype=float32), -0.13802837]
[2019-03-23 02:46:25,445] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 100.0, 1.0, 2.0, 0.6250359552714535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 712324.4747361025, 712324.474736102, 162437.7211744319]
[2019-03-23 02:46:25,447] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:46:25,450] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 1.8800427e-37 4.5236217e-20 8.1825990e-13], sampled 0.33099542219750977
[2019-03-23 02:46:25,451] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 712324.4747361025 W.
[2019-03-23 02:46:26,056] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.32571375], dtype=float32), -0.13802837]
[2019-03-23 02:46:26,058] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.18333333333334, 47.66666666666667, 1.0, 2.0, 0.542854563693294, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8654769650012357, 6.911200000000001, 6.9112, 121.9256179289574, 1255876.537692666, 1255876.537692665, 271995.0800980792]
[2019-03-23 02:46:26,058] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:46:26,061] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.9227287e-03 0.0000000e+00 1.4414583e-33 9.9103677e-01 4.0506467e-05], sampled 0.44569759917485263
[2019-03-23 02:46:35,103] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7960.9642 2523052039.4025 607.0000
[2019-03-23 02:46:35,767] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8605.1911 2264336399.1381 411.0000
[2019-03-23 02:46:35,895] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8658.9464 2229028128.9976 430.0000
[2019-03-23 02:46:35,947] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8466.4641 2298581702.1870 503.0000
[2019-03-23 02:46:36,001] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8458.6859 2333829569.5464 439.0000
[2019-03-23 02:46:37,017] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1900000, evaluation results [1900000.0, 7960.964230625183, 2523052039.4024997, 607.0, 8605.191117795994, 2264336399.1380925, 411.0, 8658.946411112473, 2229028128.9976277, 430.0, 8458.685874200999, 2333829569.546425, 439.0, 8466.46414557296, 2298581702.187033, 503.0]
[2019-03-23 02:46:41,788] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:46:41,788] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:46:41,872] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run10
[2019-03-23 02:46:44,446] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2596047e-29 0.0000000e+00 0.0000000e+00 1.0000000e+00 1.0158360e-24], sum to 1.0000
[2019-03-23 02:46:44,455] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0003
[2019-03-23 02:46:44,460] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.61666666666667, 40.5, 1.0, 2.0, 0.5051347543632464, 1.0, 2.0, 0.5051347543632464, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156509, 1231714.032350474, 1231714.032350473, 240202.1631399792], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7815000.0000, 
sim time next is 7815600.0000, 
raw observation next is [28.8, 40.0, 1.0, 2.0, 0.4814127863964316, 1.0, 2.0, 0.4814127863964316, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1173685.257743807, 1173685.257743807, 232754.4757798085], 
processed observation next is [1.0, 0.4782608695652174, 0.6222222222222222, 0.4, 1.0, 1.0, 0.3826342695195614, 1.0, 1.0, 0.3826342695195614, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.41917330633707395, 0.41917330633707395, 0.44760476111501635], 
reward next is 0.5524, 
noisyNet noise sample is [array([0.1733017], dtype=float32), 0.116253406]. 
=============================================
[2019-03-23 02:46:47,740] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:46:47,740] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:46:47,827] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run10
[2019-03-23 02:46:48,563] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:46:48,564] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:46:48,618] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run10
[2019-03-23 02:46:52,492] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:46:52,493] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:46:52,558] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run10
[2019-03-23 02:46:54,208] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:46:54,209] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:46:54,293] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run10
[2019-03-23 02:46:56,209] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.2104579e-20 2.1522708e-26], sum to 1.0000
[2019-03-23 02:46:56,217] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4956
[2019-03-23 02:46:56,221] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1465402.698029475 W.
[2019-03-23 02:46:56,226] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.03333333333333, 36.83333333333334, 1.0, 2.0, 0.4089733863670562, 1.0, 2.0, 0.4089733863670562, 1.0, 2.0, 0.6585853157574715, 6.9112, 6.9112, 121.94756008, 1465402.698029475, 1465402.698029475, 300736.8792061575], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 53400.0000, 
sim time next is 54000.0000, 
raw observation next is [30.0, 37.0, 1.0, 2.0, 0.6161089339547718, 1.0, 2.0, 0.6161089339547718, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1485988.084124031, 1485988.084124032, 277124.514392938], 
processed observation next is [1.0, 0.6521739130434783, 0.6666666666666666, 0.37, 1.0, 1.0, 0.5429868261366332, 1.0, 1.0, 0.5429868261366332, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5307100300442968, 0.5307100300442972, 0.5329317584479577], 
reward next is 0.4671, 
noisyNet noise sample is [array([0.24128515], dtype=float32), 0.1828631]. 
=============================================
[2019-03-23 02:46:56,237] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[50.363   ]
 [50.242046]
 [50.446022]
 [50.1268  ]
 [49.408035]], R is [[50.54798508]
 [50.46416855]
 [50.39015198]
 [50.34856033]
 [50.30197525]].
[2019-03-23 02:46:56,311] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:46:56,312] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:46:56,340] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:46:56,341] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:46:56,386] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run10
[2019-03-23 02:46:56,458] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run10
[2019-03-23 02:46:56,545] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:46:56,546] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:46:56,607] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run10
[2019-03-23 02:46:56,894] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:46:56,894] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:46:56,942] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run10
[2019-03-23 02:46:58,290] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:46:58,291] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:46:58,370] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run10
[2019-03-23 02:46:59,034] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:46:59,035] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:46:59,099] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run10
[2019-03-23 02:46:59,242] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:46:59,243] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:46:59,284] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run10
[2019-03-23 02:46:59,607] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:46:59,607] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:46:59,636] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run10
[2019-03-23 02:46:59,778] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:46:59,779] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:46:59,819] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run10
[2019-03-23 02:46:59,936] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 02:46:59,936] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:46:59,980] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run10
[2019-03-23 02:47:00,076] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.27862970e-09 1.07804035e-24 4.87963317e-33 1.09602316e-26
 1.00000000e+00], sum to 1.0000
[2019-03-23 02:47:00,080] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3423
[2019-03-23 02:47:00,084] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 53.0, 1.0, 2.0, 0.393226589156078, 1.0, 2.0, 0.393226589156078, 1.0, 2.0, 0.6281257919151777, 6.911199999999999, 6.9112, 121.94756008, 1377809.537177813, 1377809.537177813, 294170.4305916951], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 122400.0000, 
sim time next is 123000.0000, 
raw observation next is [28.41666666666667, 51.83333333333334, 1.0, 2.0, 0.37961507556034, 1.0, 2.0, 0.37961507556034, 1.0, 2.0, 0.6060790141622922, 6.911199999999999, 6.9112, 121.94756008, 1327224.325483751, 1327224.325483751, 288312.9354959466], 
processed observation next is [1.0, 0.43478260869565216, 0.6080246913580248, 0.5183333333333334, 1.0, 1.0, 0.2614465185242143, 1.0, 1.0, 0.2614465185242143, 1.0, 1.0, 0.5075987677028652, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4740086876727682, 0.4740086876727682, 0.5544479528768204], 
reward next is 0.4456, 
noisyNet noise sample is [array([1.6987894], dtype=float32), -0.6043532]. 
=============================================
[2019-03-23 02:47:00,099] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[50.15665 ]
 [49.84911 ]
 [49.390293]
 [48.85561 ]
 [48.782433]], R is [[50.85661316]
 [50.78233719]
 [50.71603012]
 [50.65671539]
 [50.60336304]].
[2019-03-23 02:47:00,246] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:00,250] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5792
[2019-03-23 02:47:00,257] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.3, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6659435076736601, 6.9112, 6.9112, 121.9260426156618, 497365.5482958551, 497365.5482958551, 139945.6124585553], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 813600.0000, 
sim time next is 814200.0000, 
raw observation next is [27.58333333333333, 48.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6719439251736244, 6.911199999999999, 6.9112, 121.9260426156618, 501968.0350457384, 501968.0350457389, 140867.9255122298], 
processed observation next is [0.0, 0.43478260869565216, 0.5771604938271603, 0.48333333333333345, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5899299064670305, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17927429823062085, 0.17927429823062105, 0.27089985675428807], 
reward next is 0.7291, 
noisyNet noise sample is [array([0.23314834], dtype=float32), -0.56544745]. 
=============================================
[2019-03-23 02:47:00,418] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.1502307e-35 0.0000000e+00 1.8219724e-20 6.4374780e-30], sum to 1.0000
[2019-03-23 02:47:00,422] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1150
[2019-03-23 02:47:00,427] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1233534.767644673 W.
[2019-03-23 02:47:00,430] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.48333333333333, 22.5, 1.0, 2.0, 0.3449044591337265, 1.0, 2.0, 0.3449044591337265, 1.0, 2.0, 0.5549539014835437, 6.9112, 6.9112, 121.94756008, 1233534.767644673, 1233534.767644673, 273459.1703220098], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 133800.0000, 
sim time next is 134400.0000, 
raw observation next is [35.86666666666667, 21.0, 1.0, 2.0, 0.3739638111808584, 1.0, 2.0, 0.3739638111808584, 1.0, 2.0, 0.601903926179345, 6.911199999999999, 6.9112, 121.94756008, 1338458.792828677, 1338458.792828678, 285549.7951032909], 
processed observation next is [1.0, 0.5652173913043478, 0.8839506172839506, 0.21, 1.0, 1.0, 0.25471882283435526, 1.0, 1.0, 0.25471882283435526, 1.0, 1.0, 0.5023799077241812, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4780209974388132, 0.47802099743881354, 0.5491342213524825], 
reward next is 0.4509, 
noisyNet noise sample is [array([-1.2220768], dtype=float32), -1.584684]. 
=============================================
[2019-03-23 02:47:02,004] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:02,013] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3818
[2019-03-23 02:47:02,018] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.1, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.659075429119885, 6.9112, 6.9112, 121.9260426156618, 492399.0682072404, 492399.0682072404, 139660.6372991092], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 64800.0000, 
sim time next is 65400.0000, 
raw observation next is [28.98333333333333, 42.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6667657216382137, 6.9112, 6.9112, 121.9260426156618, 498155.0731854548, 498155.0731854548, 140497.8944153307], 
processed observation next is [1.0, 0.782608695652174, 0.6290123456790122, 0.425, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.583457152047767, 0.0, 0.0, 0.8094621288201359, 0.17791252613766242, 0.17791252613766242, 0.27018825849102057], 
reward next is 0.7298, 
noisyNet noise sample is [array([-1.0401319], dtype=float32), -1.6138088]. 
=============================================
[2019-03-23 02:47:03,318] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:03,327] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9134
[2019-03-23 02:47:03,331] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.25, 71.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5071712940491072, 6.911200000000001, 6.9112, 121.9260426156618, 362167.6150971625, 362167.6150971621, 115368.7137994512], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 444600.0000, 
sim time next is 445200.0000, 
raw observation next is [19.1, 72.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5001615125337052, 6.9112, 6.9112, 121.9260426156618, 357123.3558342952, 357123.3558342952, 114355.4353530827], 
processed observation next is [1.0, 0.13043478260869565, 0.262962962962963, 0.7233333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3752018906671315, 0.0, 0.0, 0.8094621288201359, 0.12754405565510543, 0.12754405565510543, 0.21991429875592827], 
reward next is 0.7801, 
noisyNet noise sample is [array([0.7949115], dtype=float32), 0.6437463]. 
=============================================
[2019-03-23 02:47:06,842] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9997628e-01 8.0579578e-25 1.0487886e-25 1.5901616e-06 2.2114960e-05], sum to 1.0000
[2019-03-23 02:47:06,860] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3449
[2019-03-23 02:47:06,868] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1111970.047340315 W.
[2019-03-23 02:47:06,874] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.6, 34.0, 1.0, 2.0, 0.4372754282418603, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7568478083998192, 6.911200000000001, 6.9112, 121.9260358399034, 1111970.047340315, 1111970.047340314, 229117.0193445297], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 379200.0000, 
sim time next is 379800.0000, 
raw observation next is [26.8, 33.5, 1.0, 2.0, 0.2940072216189319, 1.0, 1.0, 0.2940072216189319, 1.0, 2.0, 0.498635212956979, 6.911199999999999, 6.9112, 121.94756008, 1109989.073089899, 1109989.0730899, 250379.2214183628], 
processed observation next is [1.0, 0.391304347826087, 0.5481481481481482, 0.335, 1.0, 1.0, 0.15953240668920463, 1.0, 0.5, 0.15953240668920463, 1.0, 1.0, 0.3732940161962237, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.39642466896067824, 0.3964246689606786, 0.4814985027276208], 
reward next is 0.5185, 
noisyNet noise sample is [array([1.768969], dtype=float32), 0.39309433]. 
=============================================
[2019-03-23 02:47:09,555] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 5.2227044e-37 0.0000000e+00 3.4213672e-25], sum to 1.0000
[2019-03-23 02:47:09,560] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1215
[2019-03-23 02:47:09,566] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.7, 44.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5280255175135138, 6.911199999999999, 6.9112, 121.9260426156618, 377022.3170129617, 377022.3170129622, 115615.3708897531], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 255600.0000, 
sim time next is 256200.0000, 
raw observation next is [23.55, 44.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5239918434096792, 6.911200000000001, 6.9112, 121.9260426156618, 374139.5886065595, 374139.588606559, 114517.5248218611], 
processed observation next is [0.0, 1.0, 0.4277777777777778, 0.4433333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.40498980426209896, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13362128164519982, 0.13362128164519962, 0.2202260092728098], 
reward next is 0.7798, 
noisyNet noise sample is [array([-0.6956669], dtype=float32), -0.645364]. 
=============================================
[2019-03-23 02:47:11,803] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:11,812] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1775
[2019-03-23 02:47:11,815] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.23333333333333, 21.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6470719481421124, 6.911199999999999, 6.9112, 121.9260426156618, 469375.2921667987, 469375.2921667991, 129614.1478880409], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 240600.0000, 
sim time next is 241200.0000, 
raw observation next is [31.0, 22.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6452002525575543, 6.9112, 6.9112, 121.9260426156618, 468137.9320081045, 468137.9320081045, 129490.7040893265], 
processed observation next is [0.0, 0.8260869565217391, 0.7037037037037037, 0.22, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5565003156969428, 0.0, 0.0, 0.8094621288201359, 0.16719211857432303, 0.16719211857432303, 0.24902058478716632], 
reward next is 0.7510, 
noisyNet noise sample is [array([0.7812391], dtype=float32), -0.442765]. 
=============================================
[2019-03-23 02:47:12,361] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:12,372] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2119
[2019-03-23 02:47:12,378] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.81666666666667, 67.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6028581840534812, 6.9112, 6.9112, 121.9260426156618, 447758.4551323607, 447758.4551323607, 130858.4992002402], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 201000.0000, 
sim time next is 201600.0000, 
raw observation next is [23.0, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6180140983003876, 6.9112, 6.9112, 121.9260426156618, 459907.0458982203, 459907.0458982203, 133014.5102415868], 
processed observation next is [0.0, 0.34782608695652173, 0.4074074074074074, 0.68, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5225176228754844, 0.0, 0.0, 0.8094621288201359, 0.16425251639222155, 0.16425251639222155, 0.25579713507997465], 
reward next is 0.7442, 
noisyNet noise sample is [array([1.248778], dtype=float32), 1.5670851]. 
=============================================
[2019-03-23 02:47:12,419] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:12,430] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1542
[2019-03-23 02:47:12,435] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.5, 21.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6383425920231847, 6.9112, 6.9112, 121.9260426156618, 464232.3123215231, 464232.3123215231, 129287.268758409], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 217800.0000, 
sim time next is 218400.0000, 
raw observation next is [31.7, 20.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6429206353690446, 6.9112, 6.9112, 121.9260426156618, 466548.8411511186, 466548.8411511186, 129309.5737593225], 
processed observation next is [0.0, 0.5217391304347826, 0.7296296296296296, 0.2, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5536507942113058, 0.0, 0.0, 0.8094621288201359, 0.16662458612539952, 0.16662458612539952, 0.24867225722946637], 
reward next is 0.7513, 
noisyNet noise sample is [array([1.5055691], dtype=float32), 1.941172]. 
=============================================
[2019-03-23 02:47:13,736] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:13,743] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8333
[2019-03-23 02:47:13,750] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.66666666666667, 52.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4443480202505292, 6.911200000000001, 6.9112, 121.9260426156618, 317260.5706232856, 317260.5706232851, 92799.4238829953], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 276000.0000, 
sim time next is 276600.0000, 
raw observation next is [19.58333333333333, 52.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4424483657625031, 6.9112, 6.9112, 121.9260426156618, 315903.9547290361, 315903.9547290361, 92402.3543950334], 
processed observation next is [0.0, 0.17391304347826086, 0.280864197530864, 0.5283333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.30306045720312885, 0.0, 0.0, 0.8094621288201359, 0.11282284097465574, 0.11282284097465574, 0.17769683537506423], 
reward next is 0.8223, 
noisyNet noise sample is [array([1.2746007], dtype=float32), -1.3557161]. 
=============================================
[2019-03-23 02:47:20,461] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:20,469] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9390
[2019-03-23 02:47:20,472] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 45.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.52560645893888, 6.911200000000001, 6.9112, 121.9260426156618, 375294.9561756047, 375294.9561756043, 116548.0007630147], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 342000.0000, 
sim time next is 342600.0000, 
raw observation next is [23.45, 45.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5204845766123368, 6.911200000000001, 6.9112, 121.9260426156618, 371634.7554156821, 371634.7554156816, 115646.6610770056], 
processed observation next is [0.0, 1.0, 0.42407407407407405, 0.455, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.400605720765421, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13272669836274362, 0.13272669836274342, 0.2223974251480877], 
reward next is 0.7776, 
noisyNet noise sample is [array([-1.8219078], dtype=float32), 0.5988804]. 
=============================================
[2019-03-23 02:47:21,199] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.2785111e-27 2.5617774e-36 3.0932391e-23 9.3171549e-15], sum to 1.0000
[2019-03-23 02:47:21,204] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6511
[2019-03-23 02:47:21,209] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 923614.0465099833 W.
[2019-03-23 02:47:21,214] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.56666666666666, 49.66666666666667, 1.0, 2.0, 0.3683094573980595, 1.0, 1.0, 0.3683094573980595, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 923614.0465099833, 923614.0465099837, 200625.9085482217], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 463200.0000, 
sim time next is 463800.0000, 
raw observation next is [24.88333333333333, 48.83333333333333, 1.0, 2.0, 0.2598440177184018, 1.0, 2.0, 0.2598440177184018, 1.0, 1.0, 0.432959319467332, 6.911199999999999, 6.9112, 121.94756008, 969383.7094687216, 969383.7094687221, 238760.6505546279], 
processed observation next is [1.0, 0.34782608695652173, 0.47716049382716036, 0.4883333333333333, 1.0, 1.0, 0.11886192585524026, 1.0, 1.0, 0.11886192585524026, 1.0, 0.5, 0.29119914933416496, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3462084676674006, 0.34620846766740077, 0.4591550972204383], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.06510333], dtype=float32), -2.3912868]. 
=============================================
[2019-03-23 02:47:21,440] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:21,451] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3399
[2019-03-23 02:47:21,455] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.78333333333333, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4339487488342347, 6.9112, 6.9112, 121.9260426156618, 309834.0827249566, 309834.0827249566, 96552.48103113184], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 366600.0000, 
sim time next is 367200.0000, 
raw observation next is [20.2, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4364617573686563, 6.9112, 6.9112, 121.9260426156618, 311628.7045019438, 311628.7045019438, 97444.03086170756], 
processed observation next is [1.0, 0.2608695652173913, 0.3037037037037037, 0.56, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.29557719671082033, 0.0, 0.0, 0.8094621288201359, 0.11129596589355135, 0.11129596589355135, 0.1873923670417453], 
reward next is 0.8126, 
noisyNet noise sample is [array([-0.11047396], dtype=float32), 1.0947263]. 
=============================================
[2019-03-23 02:47:21,769] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:21,779] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0356
[2019-03-23 02:47:21,784] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.86666666666667, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5938681126709487, 6.9112, 6.9112, 121.9260426156618, 439595.796725734, 439595.796725734, 129017.9347640877], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1205400.0000, 
sim time next is 1206000.0000, 
raw observation next is [18.8, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5927611118586197, 6.9112, 6.9112, 121.9260426156618, 438816.0934933135, 438816.0934933135, 128939.930960829], 
processed observation next is [1.0, 1.0, 0.2518518518518519, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4909513898232746, 0.0, 0.0, 0.8094621288201359, 0.1567200333904691, 0.1567200333904691, 0.24796140569390193], 
reward next is 0.7520, 
noisyNet noise sample is [array([-1.0956012], dtype=float32), -1.2402947]. 
=============================================
[2019-03-23 02:47:21,800] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[68.12909 ]
 [68.13012 ]
 [68.142075]
 [68.16698 ]
 [68.21604 ]], R is [[68.17923737]
 [68.24933624]
 [68.31848145]
 [68.38673401]
 [68.45431519]].
[2019-03-23 02:47:28,245] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:47:28,254] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4586
[2019-03-23 02:47:28,258] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.8, 28.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6190937424970192, 6.911199999999999, 6.9112, 121.9260426156618, 457671.9909176746, 457671.990917675, 131024.9517878597], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 498000.0000, 
sim time next is 498600.0000, 
raw observation next is [30.55, 29.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6123655690439593, 6.911199999999999, 6.9112, 121.9260426156618, 452962.0783216755, 452962.078321676, 130547.7877648745], 
processed observation next is [1.0, 0.782608695652174, 0.6870370370370371, 0.29, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5154569613049491, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1617721708291698, 0.16177217082917, 0.2510534380093741], 
reward next is 0.7489, 
noisyNet noise sample is [array([-0.04931316], dtype=float32), 1.1696237]. 
=============================================
[2019-03-23 02:47:28,459] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 02:47:28,461] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:47:28,461] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:47:28,463] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:47:28,464] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:47:28,464] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:47:28,465] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:47:28,464] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:47:28,465] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:47:28,467] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:47:28,467] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:47:28,497] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run78
[2019-03-23 02:47:28,527] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run78
[2019-03-23 02:47:28,557] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run78
[2019-03-23 02:47:28,593] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run78
[2019-03-23 02:47:28,625] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run78
[2019-03-23 02:47:38,702] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.3161129], dtype=float32), -0.07301812]
[2019-03-23 02:47:38,705] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.81029301333333, 44.85342109333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6130752503567746, 6.911200000000001, 6.9112, 121.9260426156618, 458126.2730638697, 458126.2730638693, 135591.8866165148]
[2019-03-23 02:47:38,707] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:47:38,712] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.22331129665050886
[2019-03-23 02:47:44,283] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.3161129], dtype=float32), -0.07301812]
[2019-03-23 02:47:44,284] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.28742097, 59.013378405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5263626941713211, 6.9112, 6.9112, 121.9260426156618, 385361.4280938167, 385361.4280938167, 120745.6356733711]
[2019-03-23 02:47:44,285] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:47:44,287] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.08822935043160018
[2019-03-23 02:48:00,463] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.3161129], dtype=float32), -0.07301812]
[2019-03-23 02:48:00,464] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.73693076, 94.27360211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.814773715410981, 6.911200000000001, 6.9112, 121.9260426156618, 602083.5501941796, 602083.5501941792, 163412.497892453]
[2019-03-23 02:48:00,465] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:48:00,470] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5909250287517293
[2019-03-23 02:48:05,962] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.3161129], dtype=float32), -0.07301812]
[2019-03-23 02:48:05,963] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.86666666666667, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8846666447708594, 6.9112, 6.9112, 121.9260426156618, 648497.5957186549, 648497.5957186549, 173695.7483835378]
[2019-03-23 02:48:05,965] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:48:05,969] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.21431525402891805
[2019-03-23 02:48:12,454] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.3161129], dtype=float32), -0.07301812]
[2019-03-23 02:48:12,456] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.85059434666667, 52.76693330666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9558089277291996, 13.12167322132351, 6.9112, 126.9985798946664, 4028203.251050852, 715573.8768067051, 162147.8412553936]
[2019-03-23 02:48:12,457] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:48:12,459] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.1078660e-33 4.9863412e-27], sampled 0.28263739376286034
[2019-03-23 02:48:12,462] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 4028203.251050852 W.
[2019-03-23 02:48:12,784] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.3161129], dtype=float32), -0.07301812]
[2019-03-23 02:48:12,785] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.35, 97.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9166583816660043, 6.9112, 6.9112, 121.9260426156618, 666851.2437939715, 666851.2437939715, 178896.7280473092]
[2019-03-23 02:48:12,785] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:48:12,787] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.5114908e-26], sampled 0.3898589399009261
[2019-03-23 02:48:14,805] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.3161129], dtype=float32), -0.07301812]
[2019-03-23 02:48:14,806] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.0, 60.33333333333334, 1.0, 2.0, 0.2397258574031473, 1.0, 2.0, 0.2397258574031473, 1.0, 2.0, 0.3816513723119282, 6.911200000000001, 6.9112, 121.94756008, 819670.5944407362, 819670.5944407358, 234011.8151718798]
[2019-03-23 02:48:14,808] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:48:14,811] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1546929e-01 0.0000000e+00 2.7643202e-36 0.0000000e+00 8.8453072e-01], sampled 0.05500219369796966
[2019-03-23 02:48:14,815] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 819670.5944407362 W.
[2019-03-23 02:48:32,319] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.3161129], dtype=float32), -0.07301812]
[2019-03-23 02:48:32,320] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.6, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8278642439443195, 6.911199999999999, 6.9112, 121.9260426156618, 611997.9694155718, 611997.9694155722, 164996.8165098899]
[2019-03-23 02:48:32,321] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:48:32,324] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.992343351977191
[2019-03-23 02:48:45,665] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.3161129], dtype=float32), -0.07301812]
[2019-03-23 02:48:45,666] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.85, 91.0, 1.0, 2.0, 0.7273797538775442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 831228.4440848877, 831228.4440848877, 181501.3349821288]
[2019-03-23 02:48:45,667] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:48:45,669] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.6874874e-12], sampled 0.3218651103629244
[2019-03-23 02:48:45,671] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 831228.4440848877 W.
[2019-03-23 02:48:57,264] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.3161129], dtype=float32), -0.07301812]
[2019-03-23 02:48:57,267] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.75, 79.83333333333334, 1.0, 2.0, 0.8029018000146583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 915150.9385254177, 915150.9385254177, 196539.5847223066]
[2019-03-23 02:48:57,268] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:48:57,270] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9999988e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3734132e-07], sampled 0.05127151923924156
[2019-03-23 02:48:57,272] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 915150.9385254177 W.
[2019-03-23 02:49:05,131] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.3161129], dtype=float32), -0.07301812]
[2019-03-23 02:49:05,135] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.0, 49.0, 1.0, 2.0, 0.6033837618888677, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9615618534828336, 6.9112, 6.9112, 121.9255129066908, 1391855.675795742, 1391855.675795742, 294942.3366266521]
[2019-03-23 02:49:05,136] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:49:05,139] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.4358806e-02 0.0000000e+00 1.1868125e-34 8.0238698e-12 9.4564116e-01], sampled 0.5859054094629262
[2019-03-23 02:49:21,897] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.3161129], dtype=float32), -0.07301812]
[2019-03-23 02:49:21,898] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.45, 54.5, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.802725931348031, 6.9112, 121.92247481956, 1684809.797885416, 1228282.196639203, 248871.9622680254]
[2019-03-23 02:49:21,899] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:49:21,902] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.9343866e-06 0.0000000e+00 1.6274716e-32 5.9601969e-11 9.9999106e-01], sampled 0.7249014654629221
[2019-03-23 02:49:22,078] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.1312 2260391905.1462 399.0000
[2019-03-23 02:49:22,089] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8562.0289 2294738876.6718 403.0000
[2019-03-23 02:49:22,156] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8430.0549 2332284003.9247 475.0000
[2019-03-23 02:49:22,262] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7917.0175 2561518685.0577 572.0000
[2019-03-23 02:49:22,380] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8408.6897 2366135692.6391 427.0000
[2019-03-23 02:49:23,398] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1925000, evaluation results [1925000.0, 7917.017535336983, 2561518685.057712, 572.0, 8562.028877144092, 2294738876.6717663, 403.0, 8633.131247522171, 2260391905.1461515, 399.0, 8408.689659133319, 2366135692.6391068, 427.0, 8430.054904873388, 2332284003.9247103, 475.0]
[2019-03-23 02:49:23,892] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:49:23,896] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0452
[2019-03-23 02:49:23,902] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.1, 35.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6409621118391771, 6.9112, 6.9112, 121.9260426156618, 478208.0778363843, 478208.0778363843, 136545.6572347255], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 588000.0000, 
sim time next is 588600.0000, 
raw observation next is [29.95, 36.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6391258800016318, 6.9112, 6.9112, 121.9260426156618, 476751.3385225848, 476751.3385225848, 136247.6025683655], 
processed observation next is [1.0, 0.8260869565217391, 0.6648148148148147, 0.36, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5489073500020397, 0.0, 0.0, 0.8094621288201359, 0.17026833518663745, 0.17026833518663745, 0.2620146203237798], 
reward next is 0.7380, 
noisyNet noise sample is [array([0.47787288], dtype=float32), -1.5453091]. 
=============================================
[2019-03-23 02:49:30,668] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:49:30,677] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5044
[2019-03-23 02:49:30,681] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.7, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6618477483716104, 6.911199999999999, 6.9112, 121.9260426156618, 477855.862380466, 477855.8623804664, 130135.5713439822], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 705600.0000, 
sim time next is 706200.0000, 
raw observation next is [23.53333333333333, 48.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5938907677389764, 6.911200000000001, 6.9112, 121.9260426156618, 428747.2011372604, 428747.20113726, 124153.2610657077], 
processed observation next is [1.0, 0.17391304347826086, 0.4271604938271604, 0.4883333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.49236345967372047, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15312400040616445, 0.15312400040616428, 0.23875627128020713], 
reward next is 0.7612, 
noisyNet noise sample is [array([-0.9569867], dtype=float32), -0.61753166]. 
=============================================
[2019-03-23 02:49:31,234] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:49:31,242] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5916
[2019-03-23 02:49:31,247] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.9, 32.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6083772488069384, 6.911200000000001, 6.9112, 121.9260426156618, 450803.696640365, 450803.6966403645, 130661.1606339901], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1458000.0000, 
sim time next is 1458600.0000, 
raw observation next is [29.75, 32.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6081681514654229, 6.9112, 6.9112, 121.9260426156618, 450683.9714171498, 450683.9714171498, 130664.0738090644], 
processed observation next is [0.0, 0.9130434782608695, 0.6574074074074074, 0.325, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5102101893317786, 0.0, 0.0, 0.8094621288201359, 0.16095856122041066, 0.16095856122041066, 0.2512770650174315], 
reward next is 0.7487, 
noisyNet noise sample is [array([-0.11125166], dtype=float32), -0.74015254]. 
=============================================
[2019-03-23 02:49:33,998] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:49:34,010] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8334
[2019-03-23 02:49:34,014] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.4, 27.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6155551898072705, 6.9112, 6.9112, 121.9260426156618, 452293.3754125643, 452293.3754125643, 129248.5914838275], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 680400.0000, 
sim time next is 681000.0000, 
raw observation next is [30.21666666666667, 27.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6151807857822075, 6.911199999999999, 6.9112, 121.9260426156618, 452090.0485100799, 452090.0485100803, 129248.7309027358], 
processed observation next is [1.0, 0.9130434782608695, 0.6746913580246914, 0.2766666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5189759822277593, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1614607316107428, 0.16146073161074298, 0.24855525173603038], 
reward next is 0.7514, 
noisyNet noise sample is [array([1.3256886], dtype=float32), -1.3230884]. 
=============================================
[2019-03-23 02:49:34,033] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.60091 ]
 [68.44943 ]
 [68.21858 ]
 [68.090385]
 [68.181816]], R is [[68.77011108]
 [68.83385468]
 [68.89642334]
 [68.95783997]
 [69.01799011]].
[2019-03-23 02:49:34,448] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:49:34,458] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8796
[2019-03-23 02:49:34,463] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [35.0, 24.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.676339914948356, 6.911199999999999, 6.9112, 121.9260426156618, 505403.7672326127, 505403.7672326132, 141982.4840743811], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1515600.0000, 
sim time next is 1516200.0000, 
raw observation next is [35.13333333333333, 23.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6943367918999912, 6.9112, 6.9112, 121.9260426156618, 518829.0113772424, 518829.0113772424, 143729.3197096301], 
processed observation next is [0.0, 0.5652173913043478, 0.8567901234567901, 0.23333333333333328, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.617920989874989, 0.0, 0.0, 0.8094621288201359, 0.18529607549187227, 0.18529607549187227, 0.2764025379031348], 
reward next is 0.7236, 
noisyNet noise sample is [array([-0.56923765], dtype=float32), 1.1082338]. 
=============================================
[2019-03-23 02:49:41,628] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:49:41,639] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9813
[2019-03-23 02:49:41,647] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.53333333333333, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5248514116682296, 6.9112, 6.9112, 121.9260426156618, 382225.608405514, 382225.608405514, 119746.6751959143], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 787200.0000, 
sim time next is 787800.0000, 
raw observation next is [23.46666666666667, 52.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5256319648149052, 6.9112, 6.9112, 121.9260426156618, 382939.9539687388, 382939.9539687388, 119870.7360821485], 
processed observation next is [0.0, 0.08695652173913043, 0.42469135802469143, 0.525, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4070399560186314, 0.0, 0.0, 0.8094621288201359, 0.13676426927454957, 0.13676426927454957, 0.23052064631182406], 
reward next is 0.7695, 
noisyNet noise sample is [array([-0.33568308], dtype=float32), 1.2311428]. 
=============================================
[2019-03-23 02:49:46,981] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 6.917692e-11], sum to 1.0000
[2019-03-23 02:49:46,990] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9529
[2019-03-23 02:49:46,994] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.3, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6193364296906178, 6.911200000000001, 6.9112, 121.9260426156618, 460425.8846916248, 460425.8846916244, 132757.9276326433], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 936000.0000, 
sim time next is 936600.0000, 
raw observation next is [25.2, 52.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6162141147411683, 6.911200000000001, 6.9112, 121.9260426156618, 457813.4915812082, 457813.4915812078, 132232.2009835325], 
processed observation next is [0.0, 0.8695652173913043, 0.4888888888888889, 0.5283333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5202676434264603, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16350481842186007, 0.16350481842185993, 0.25429269419910094], 
reward next is 0.7457, 
noisyNet noise sample is [array([0.12385504], dtype=float32), 0.37192866]. 
=============================================
[2019-03-23 02:49:53,368] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 9.886888e-09], sum to 1.0000
[2019-03-23 02:49:53,378] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5808
[2019-03-23 02:49:53,386] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1032011.158019575 W.
[2019-03-23 02:49:53,393] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.76666666666667, 41.33333333333334, 1.0, 2.0, 0.4142813140642533, 1.0, 1.0, 0.4142813140642533, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1032011.158019575, 1032011.158019575, 213332.9711877927], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1089600.0000, 
sim time next is 1090200.0000, 
raw observation next is [26.73333333333333, 41.66666666666666, 1.0, 2.0, 0.422427922900603, 1.0, 2.0, 0.422427922900603, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1050721.776336956, 1050721.776336956, 215650.4790714338], 
processed observation next is [1.0, 0.6086956521739131, 0.545679012345679, 0.4166666666666666, 1.0, 1.0, 0.3124141939292893, 1.0, 1.0, 0.3124141939292893, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3752577772631986, 0.3752577772631986, 0.41471245975275733], 
reward next is 0.5853, 
noisyNet noise sample is [array([-0.44446972], dtype=float32), -0.6614446]. 
=============================================
[2019-03-23 02:49:55,752] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:49:55,759] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4164
[2019-03-23 02:49:55,766] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.3, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5232388268212232, 6.9112, 6.9112, 121.9260426156618, 380953.050154114, 380953.050154114, 119574.5291648363], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1044000.0000, 
sim time next is 1044600.0000, 
raw observation next is [21.23333333333333, 65.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8137767500359171, 6.9112, 6.9112, 121.9260426156618, 592773.0574587536, 592773.0574587536, 146780.7677328203], 
processed observation next is [1.0, 0.08695652173913043, 0.34197530864197523, 0.655, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7672209375448963, 0.0, 0.0, 0.8094621288201359, 0.21170466337812627, 0.21170466337812627, 0.28227070717850056], 
reward next is 0.7177, 
noisyNet noise sample is [array([-1.2166915], dtype=float32), -0.8108219]. 
=============================================
[2019-03-23 02:50:03,758] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 8.880596e-37], sum to 1.0000
[2019-03-23 02:50:03,766] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5461
[2019-03-23 02:50:03,770] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.66666666666667, 86.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.595461989061399, 6.911200000000001, 6.9112, 121.9260426156618, 440654.1275842121, 440654.1275842116, 129091.6800928548], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1198200.0000, 
sim time next is 1198800.0000, 
raw observation next is [19.6, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5949785050898091, 6.911199999999999, 6.9112, 121.9260426156618, 440360.8727622697, 440360.8727622702, 129086.0431246647], 
processed observation next is [1.0, 0.9130434782608695, 0.28148148148148155, 0.87, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4937231313622613, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15727174027223917, 0.15727174027223936, 0.2482423906243552], 
reward next is 0.7518, 
noisyNet noise sample is [array([-0.7031309], dtype=float32), -0.6658254]. 
=============================================
[2019-03-23 02:50:10,074] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 3.3150959e-37 0.0000000e+00 2.3725283e-08], sum to 1.0000
[2019-03-23 02:50:10,079] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5274
[2019-03-23 02:50:10,087] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 80.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6599242786417951, 6.911200000000001, 6.9112, 121.9260426156618, 492677.7867240984, 492677.7867240979, 138954.5656639212], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1289400.0000, 
sim time next is 1290000.0000, 
raw observation next is [21.6, 81.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6576795810007297, 6.911200000000001, 6.9112, 121.9260426156618, 490937.0195801846, 490937.0195801841, 138616.3835236553], 
processed observation next is [1.0, 0.9565217391304348, 0.3555555555555556, 0.8133333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5720994762509121, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17533464985006592, 0.17533464985006575, 0.26656996831472174], 
reward next is 0.7334, 
noisyNet noise sample is [array([-2.1387205], dtype=float32), -2.057593]. 
=============================================
[2019-03-23 02:50:10,097] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[68.955795]
 [69.0178  ]
 [69.03565 ]
 [69.00281 ]
 [69.01467 ]], R is [[68.97468567]
 [69.01772308]
 [69.05971527]
 [69.10071564]
 [69.14073944]].
[2019-03-23 02:50:17,397] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 02:50:17,399] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:50:17,400] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:50:17,400] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:50:17,401] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:50:17,402] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:50:17,401] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:50:17,402] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:50:17,405] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:50:17,406] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:50:17,405] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:50:17,425] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run79
[2019-03-23 02:50:17,452] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run79
[2019-03-23 02:50:17,481] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run79
[2019-03-23 02:50:17,506] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run79
[2019-03-23 02:50:17,506] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run79
[2019-03-23 02:51:00,263] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.46938258], dtype=float32), -0.027651645]
[2019-03-23 02:51:00,265] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.8, 65.33333333333334, 1.0, 2.0, 0.7337655001885726, 1.0, 2.0, 0.7337655001885726, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1673511.388469647, 1673511.388469647, 317146.1207062177]
[2019-03-23 02:51:00,266] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:51:00,268] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0546760e-02 0.0000000e+00 0.0000000e+00 5.4026673e-06 9.8944783e-01], sampled 0.9334681794484655
[2019-03-23 02:51:30,863] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.46938258], dtype=float32), -0.027651645]
[2019-03-23 02:51:30,865] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.83739905666667, 97.84265113333333, 1.0, 2.0, 0.6252229391228438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 715536.3532329546, 715536.3532329542, 162619.3215156809]
[2019-03-23 02:51:30,868] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:51:30,870] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.6263073e-09], sampled 0.22883250406356614
[2019-03-23 02:51:30,872] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 715536.3532329546 W.
[2019-03-23 02:51:44,967] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.46938258], dtype=float32), -0.027651645]
[2019-03-23 02:51:44,968] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.4, 91.0, 1.0, 2.0, 0.5698375947548651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 683403.2033450967, 683403.2033450962, 154434.2690113898]
[2019-03-23 02:51:44,970] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:51:44,972] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 8.627786e-10], sampled 0.7743921472528461
[2019-03-23 02:52:10,559] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7895.5871 2586350286.3313 526.0000
[2019-03-23 02:52:10,851] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8519.6874 2319128522.3761 395.0000
[2019-03-23 02:52:11,019] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8598.5780 2280616130.8198 366.0000
[2019-03-23 02:52:11,085] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8407.0409 2349777547.4569 448.0000
[2019-03-23 02:52:11,133] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8358.5183 2388962510.7673 409.0000
[2019-03-23 02:52:12,150] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1950000, evaluation results [1950000.0, 7895.587113078931, 2586350286.3313427, 526.0, 8519.687402327923, 2319128522.3760962, 395.0, 8598.577976125209, 2280616130.8197722, 366.0, 8358.51828143435, 2388962510.767344, 409.0, 8407.040923776758, 2349777547.4569035, 448.0]
[2019-03-23 02:52:12,520] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 7.629826e-25 1.116257e-12], sum to 1.0000
[2019-03-23 02:52:12,529] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9043
[2019-03-23 02:52:12,536] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1169992.532536423 W.
[2019-03-23 02:52:12,544] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.8, 68.33333333333333, 1.0, 2.0, 0.3240650683694928, 1.0, 1.0, 0.3240650683694928, 1.0, 2.0, 0.5240744406690463, 6.9112, 6.9112, 121.94756008, 1169992.532536423, 1169992.532536423, 264787.9122626123], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1701600.0000, 
sim time next is 1702200.0000, 
raw observation next is [23.85, 68.16666666666667, 1.0, 2.0, 0.3338873364761415, 1.0, 2.0, 0.3338873364761415, 1.0, 2.0, 0.5385362631148507, 6.911200000000001, 6.9112, 121.94756008, 1199895.510042822, 1199895.510042821, 268860.5305444709], 
processed observation next is [1.0, 0.6956521739130435, 0.43888888888888894, 0.6816666666666668, 1.0, 1.0, 0.20700873390016844, 1.0, 1.0, 0.20700873390016844, 1.0, 1.0, 0.4231703288935633, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.42853411072957925, 0.428534110729579, 0.5170394818162901], 
reward next is 0.4830, 
noisyNet noise sample is [array([0.09096438], dtype=float32), 0.94443125]. 
=============================================
[2019-03-23 02:52:18,077] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:52:18,087] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8632
[2019-03-23 02:52:18,094] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 756781.4275773963 W.
[2019-03-23 02:52:18,099] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [19.08333333333334, 83.66666666666667, 1.0, 1.0, 0.300313966297894, 1.0, 1.0, 0.300313966297894, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9259787569562, 756781.4275773963, 756781.4275773963, 183078.7512752729], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1674600.0000, 
sim time next is 1675200.0000, 
raw observation next is [19.16666666666667, 83.33333333333334, 1.0, 2.0, 0.1932072523549947, 1.0, 2.0, 0.1932072523549947, 1.0, 1.0, 0.3254614253524535, 6.9112, 6.9112, 121.94756008, 726231.0531798858, 726231.0531798858, 215459.697831412], 
processed observation next is [1.0, 0.391304347826087, 0.2654320987654323, 0.8333333333333335, 1.0, 1.0, 0.03953244327975559, 1.0, 1.0, 0.03953244327975559, 1.0, 0.5, 0.15682678169056682, 0.0, 0.0, 0.8096049824067558, 0.25936823327853065, 0.25936823327853065, 0.4143455727527154], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8544691], dtype=float32), -1.0855482]. 
=============================================
[2019-03-23 02:52:20,493] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:52:20,501] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2738
[2019-03-23 02:52:20,508] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.8, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6370643206652238, 6.9112, 6.9112, 121.9260426156618, 465393.8590127878, 465393.8590127878, 130025.4307172869], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1654200.0000, 
sim time next is 1654800.0000, 
raw observation next is [19.6, 78.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5998440799547066, 6.9112, 6.9112, 121.9260426156618, 438030.4692188021, 438030.4692188021, 126597.2313087339], 
processed observation next is [1.0, 0.13043478260869565, 0.28148148148148155, 0.7833333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4998050999433832, 0.0, 0.0, 0.8094621288201359, 0.15643945329242934, 0.15643945329242934, 0.2434562140552575], 
reward next is 0.7565, 
noisyNet noise sample is [array([-1.6143137], dtype=float32), -0.5098276]. 
=============================================
[2019-03-23 02:52:24,673] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 3.072677e-26 0.000000e+00], sum to 1.0000
[2019-03-23 02:52:24,673] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1971
[2019-03-23 02:52:24,715] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.9, 91.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.69279087744144, 6.9112, 6.9112, 121.9260426156618, 517713.452597391, 517713.452597391, 143929.4345385077], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1896600.0000, 
sim time next is 1897200.0000, 
raw observation next is [20.9, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6899752110381743, 6.9112, 6.9112, 121.9260426156618, 515609.9587998397, 515609.9587998397, 143675.5036923166], 
processed observation next is [1.0, 1.0, 0.32962962962962955, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6124690137977178, 0.0, 0.0, 0.8094621288201359, 0.1841464138570856, 0.1841464138570856, 0.2762990455621473], 
reward next is 0.7237, 
noisyNet noise sample is [array([0.8486726], dtype=float32), 1.1950595]. 
=============================================
[2019-03-23 02:52:27,310] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.6510657e-01 0.0000000e+00 8.4076482e-37 0.0000000e+00 4.3489343e-01], sum to 1.0000
[2019-03-23 02:52:27,320] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7275
[2019-03-23 02:52:27,325] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.3, 76.33333333333333, 1.0, 2.0, 0.197344735356854, 1.0, 2.0, 0.197344735356854, 1.0, 2.0, 0.314179245757445, 6.911200000000001, 6.9112, 121.94756008, 674697.3090065678, 674697.3090065675, 219729.3619239689], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2061600.0000, 
sim time next is 2062200.0000, 
raw observation next is [26.15, 76.66666666666667, 1.0, 2.0, 0.1958134343266437, 1.0, 2.0, 0.1958134343266437, 1.0, 2.0, 0.3117413646463575, 6.9112, 6.9112, 121.94756008, 669459.6941190846, 669459.6941190846, 219232.1277086126], 
processed observation next is [0.0, 0.8695652173913043, 0.524074074074074, 0.7666666666666667, 1.0, 1.0, 0.042635040865052015, 1.0, 1.0, 0.042635040865052015, 1.0, 1.0, 0.13967670580794683, 0.0, 0.0, 0.8096049824067558, 0.23909274789967308, 0.23909274789967308, 0.42160024559348575], 
reward next is 0.5784, 
noisyNet noise sample is [array([0.38966042], dtype=float32), -0.34120136]. 
=============================================
[2019-03-23 02:52:28,620] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:52:28,630] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6520
[2019-03-23 02:52:28,636] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.35, 74.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7013746661610836, 6.9112, 6.9112, 121.9260426156618, 524120.9759386799, 524120.9759386799, 145187.0764319748], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1709400.0000, 
sim time next is 1710000.0000, 
raw observation next is [23.3, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7001147658691725, 6.911200000000001, 6.9112, 121.9260426156618, 523172.8795674267, 523172.8795674262, 145107.2989399732], 
processed observation next is [1.0, 0.8260869565217391, 0.41851851851851857, 0.75, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6251434573364656, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18684745698836666, 0.1868474569883665, 0.27905249796148696], 
reward next is 0.7209, 
noisyNet noise sample is [array([-1.4318057], dtype=float32), 0.7012573]. 
=============================================
[2019-03-23 02:52:28,653] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[70.165504]
 [70.41001 ]
 [70.72244 ]
 [70.965454]
 [71.098976]], R is [[70.10755157]
 [70.12727356]
 [70.14661407]
 [70.1658783 ]
 [70.18548584]].
[2019-03-23 02:52:34,160] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:52:34,172] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1640
[2019-03-23 02:52:34,178] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.13333333333333, 95.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7506215849164478, 6.911200000000001, 6.9112, 121.9260426156618, 560278.8899265549, 560278.8899265544, 152275.8040411626], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2619600.0000, 
sim time next is 2620200.0000, 
raw observation next is [21.16666666666667, 94.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7452378707088749, 6.9112, 6.9112, 121.9260426156618, 556452.3208468297, 556452.3208468297, 151376.1157259623], 
processed observation next is [0.0, 0.30434782608695654, 0.33950617283950635, 0.9416666666666665, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6815473383860937, 0.0, 0.0, 0.8094621288201359, 0.1987329717310106, 0.1987329717310106, 0.29110791485761983], 
reward next is 0.7089, 
noisyNet noise sample is [array([-1.4031678], dtype=float32), -0.05243366]. 
=============================================
[2019-03-23 02:52:38,763] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:52:38,775] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9683
[2019-03-23 02:52:38,782] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 855664.0010887461 W.
[2019-03-23 02:52:38,786] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.86666666666667, 82.66666666666667, 1.0, 2.0, 0.6953060275680232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 855664.0010887461, 855664.0010887457, 177821.5420804182], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1862400.0000, 
sim time next is 1863000.0000, 
raw observation next is [21.85, 83.0, 1.0, 2.0, 0.3816413840148634, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6229506731817271, 6.911199999999999, 6.9112, 121.9260426156618, 930575.1409589602, 930575.1409589605, 216118.3919615057], 
processed observation next is [1.0, 0.5652173913043478, 0.36481481481481487, 0.83, 1.0, 1.0, 0.263858790493885, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.5286883414771589, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33234826462820005, 0.33234826462820016, 0.4156122922336648], 
reward next is 0.5844, 
noisyNet noise sample is [array([0.8202617], dtype=float32), -0.33949065]. 
=============================================
[2019-03-23 02:52:38,796] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[57.45264 ]
 [57.629726]
 [57.254726]
 [57.020912]
 [57.199993]], R is [[57.09197235]
 [57.17908859]
 [57.3110466 ]
 [56.73793793]
 [56.74458313]].
[2019-03-23 02:52:39,714] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:52:39,721] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1685
[2019-03-23 02:52:39,728] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.9, 91.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6958595158364655, 6.911199999999999, 6.9112, 121.9260426156618, 520004.9313856512, 520004.9313856516, 144210.9821607316], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1896000.0000, 
sim time next is 1896600.0000, 
raw observation next is [20.9, 91.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.69279087744144, 6.9112, 6.9112, 121.9260426156618, 517713.452597391, 517713.452597391, 143929.4345385077], 
processed observation next is [1.0, 0.9565217391304348, 0.32962962962962955, 0.9183333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6159885968018, 0.0, 0.0, 0.8094621288201359, 0.18489766164192534, 0.18489766164192534, 0.2767873741125148], 
reward next is 0.7232, 
noisyNet noise sample is [array([-0.37710693], dtype=float32), 0.8120448]. 
=============================================
[2019-03-23 02:52:40,351] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 6.6126748e-38 5.3281107e-37 6.5392391e-19 3.1128541e-15], sum to 1.0000
[2019-03-23 02:52:40,359] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6405
[2019-03-23 02:52:40,370] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 716685.5455514598 W.
[2019-03-23 02:52:40,374] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.13333333333333, 55.0, 1.0, 2.0, 0.2096202942042211, 1.0, 2.0, 0.2096202942042211, 1.0, 2.0, 0.3337223352294946, 6.911200000000001, 6.9112, 121.94756008, 716685.5455514598, 716685.5455514594, 223762.8473167497], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2730000.0000, 
sim time next is 2730600.0000, 
raw observation next is [31.35, 53.5, 1.0, 2.0, 0.2096869646456404, 1.0, 2.0, 0.2096869646456404, 1.0, 2.0, 0.3338284767435387, 6.9112, 6.9112, 121.94756008, 716913.5963774915, 716913.5963774915, 223784.9840909269], 
processed observation next is [0.0, 0.6086956521739131, 0.7166666666666667, 0.535, 1.0, 1.0, 0.05915114838766715, 1.0, 1.0, 0.05915114838766715, 1.0, 1.0, 0.16728559592942338, 0.0, 0.0, 0.8096049824067558, 0.2560405701348184, 0.2560405701348184, 0.4303557386363979], 
reward next is 0.5696, 
noisyNet noise sample is [array([-1.8283073], dtype=float32), 0.039302997]. 
=============================================
[2019-03-23 02:52:42,296] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:52:42,304] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6056
[2019-03-23 02:52:42,309] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.4, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.780696329988872, 6.9112, 6.9112, 121.9260426156618, 579452.9529284044, 579452.9529284044, 158143.1660933926], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2030400.0000, 
sim time next is 2031000.0000, 
raw observation next is [26.53333333333333, 65.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7886011914243943, 6.9112, 6.9112, 121.9260426156618, 584752.217192639, 584752.217192639, 159367.015281823], 
processed observation next is [0.0, 0.5217391304347826, 0.5382716049382715, 0.6583333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7357514892804928, 0.0, 0.0, 0.8094621288201359, 0.20884007756879966, 0.20884007756879966, 0.30647502938812116], 
reward next is 0.6935, 
noisyNet noise sample is [array([-0.82710886], dtype=float32), 0.2240373]. 
=============================================
[2019-03-23 02:52:42,322] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.65921 ]
 [68.706085]
 [68.75902 ]
 [68.80636 ]
 [68.853615]], R is [[68.58197021]
 [68.59202576]
 [68.60475159]
 [68.61998749]
 [68.63764954]].
[2019-03-23 02:52:43,692] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.0392051e-01 0.0000000e+00 1.0620122e-21 3.9225827e-18 1.9607949e-01], sum to 1.0000
[2019-03-23 02:52:43,703] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3903
[2019-03-23 02:52:43,711] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 713781.252587194 W.
[2019-03-23 02:52:43,716] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.2, 74.5, 1.0, 2.0, 0.2087712251925163, 1.0, 1.0, 0.2087712251925163, 1.0, 1.0, 0.3323705897106133, 6.9112, 6.9112, 121.94756008, 713781.252587194, 713781.252587194, 223481.1461149891], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2151000.0000, 
sim time next is 2151600.0000, 
raw observation next is [27.03333333333333, 75.0, 1.0, 2.0, 0.3113608579169441, 1.0, 2.0, 0.3113608579169441, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 709685.8225743677, 709685.8225743682, 183209.3063337458], 
processed observation next is [0.0, 0.9130434782608695, 0.55679012345679, 0.75, 1.0, 1.0, 0.18019149752017158, 1.0, 1.0, 0.18019149752017158, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25345922234798846, 0.2534592223479886, 0.3523255891033573], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.4594767], dtype=float32), 1.5281276]. 
=============================================
[2019-03-23 02:52:47,401] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:52:47,408] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9734
[2019-03-23 02:52:47,412] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.25, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7714713724951292, 6.911200000000001, 6.9112, 121.9260426156618, 573243.596312825, 573243.5963128245, 156704.102655904], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2029800.0000, 
sim time next is 2030400.0000, 
raw observation next is [26.4, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.780696329988872, 6.9112, 6.9112, 121.9260426156618, 579452.9529284044, 579452.9529284044, 158143.1660933926], 
processed observation next is [0.0, 0.5217391304347826, 0.5333333333333333, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7258704124860899, 0.0, 0.0, 0.8094621288201359, 0.20694748318871586, 0.20694748318871586, 0.3041214732565242], 
reward next is 0.6959, 
noisyNet noise sample is [array([1.62286], dtype=float32), 0.7712994]. 
=============================================
[2019-03-23 02:52:55,100] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:52:55,105] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1793
[2019-03-23 02:52:55,109] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.1, 89.0, 1.0, 2.0, 0.295160197834198, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4706655535172011, 6.9112, 6.9112, 121.9260426156618, 683388.0042711346, 683388.0042711346, 193724.6003075439], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2183400.0000, 
sim time next is 2184000.0000, 
raw observation next is [24.13333333333333, 89.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9255204561186154, 6.9112, 6.9112, 121.9260426156618, 675303.7692857292, 675303.7692857292, 179757.8779979219], 
processed observation next is [1.0, 0.2608695652173913, 0.44938271604938257, 0.89, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9069005701482693, 0.0, 0.0, 0.8094621288201359, 0.24117991760204613, 0.24117991760204613, 0.3456882269190806], 
reward next is 0.6543, 
noisyNet noise sample is [array([-0.31111744], dtype=float32), 0.3422625]. 
=============================================
[2019-03-23 02:52:55,117] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[52.66878 ]
 [52.294075]
 [51.242054]
 [50.922916]
 [50.973083]], R is [[60.06375885]
 [60.09057617]
 [59.4896698 ]
 [59.4530983 ]
 [58.85856628]].
[2019-03-23 02:52:58,521] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1165442e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 02:52:58,530] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7652
[2019-03-23 02:52:58,535] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.7, 95.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8567248619601676, 6.9112, 6.9112, 121.9260426156618, 631915.1346269575, 631915.1346269575, 169074.4799591606], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2237400.0000, 
sim time next is 2238000.0000, 
raw observation next is [22.7, 95.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8574762503737381, 6.9112, 6.9112, 121.9260426156618, 632312.6618941586, 632312.6618941586, 169216.4812938306], 
processed observation next is [1.0, 0.9130434782608695, 0.39629629629629626, 0.9566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8218453129671727, 0.0, 0.0, 0.8094621288201359, 0.2258259506764852, 0.2258259506764852, 0.3254163101804435], 
reward next is 0.6746, 
noisyNet noise sample is [array([0.10070246], dtype=float32), -0.8904408]. 
=============================================
[2019-03-23 02:52:58,547] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[66.947945]
 [66.79205 ]
 [66.60586 ]
 [66.56972 ]
 [66.41682 ]], R is [[67.08351898]
 [67.08753967]
 [67.09197998]
 [67.09729004]
 [67.10351562]].
[2019-03-23 02:53:03,281] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3418105e-11 0.0000000e+00 0.0000000e+00 1.0000000e+00 9.8694505e-37], sum to 1.0000
[2019-03-23 02:53:03,286] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5241
[2019-03-23 02:53:03,295] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 43.0, 1.0, 2.0, 0.6167294233226467, 1.0, 2.0, 0.6167294233226467, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1438103.111666902, 1438103.111666902, 275361.1089632909], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3146400.0000, 
sim time next is 3147000.0000, 
raw observation next is [31.31666666666667, 41.16666666666667, 1.0, 2.0, 0.7657290230415744, 1.0, 2.0, 0.7657290230415744, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1787986.55615353, 1787986.55615353, 331880.3599029832], 
processed observation next is [1.0, 0.43478260869565216, 0.7154320987654322, 0.41166666666666674, 1.0, 1.0, 0.7211059798113981, 1.0, 1.0, 0.7211059798113981, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6385666271976893, 0.6385666271976893, 0.6382314613518907], 
reward next is 0.3618, 
noisyNet noise sample is [array([0.19185762], dtype=float32), -1.4904655]. 
=============================================
[2019-03-23 02:53:03,309] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[49.625935]
 [49.32224 ]
 [48.8957  ]
 [48.58337 ]
 [48.58848 ]], R is [[48.78723526]
 [48.76982117]
 [48.28212357]
 [48.2277298 ]
 [48.16021347]].
[2019-03-23 02:53:04,056] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 02:53:04,062] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:53:04,063] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:53:04,063] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:53:04,063] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:53:04,063] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:53:04,066] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:53:04,064] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:53:04,068] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:53:04,068] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:53:04,068] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:53:04,083] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run80
[2019-03-23 02:53:04,105] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run80
[2019-03-23 02:53:04,125] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run80
[2019-03-23 02:53:04,150] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run80
[2019-03-23 02:53:04,150] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run80
[2019-03-23 02:53:14,276] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.5360709], dtype=float32), -0.037269]
[2019-03-23 02:53:14,277] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.70581858666667, 38.35293001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.523951600271293, 6.911200000000001, 6.9112, 121.9260426156618, 374110.6876805868, 374110.6876805864, 113204.8354115666]
[2019-03-23 02:53:14,280] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:53:14,282] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9344954842472911
[2019-03-23 02:53:17,472] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.5360709], dtype=float32), -0.037269]
[2019-03-23 02:53:17,474] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.4376259, 37.70090982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6403945224094093, 6.911200000000001, 6.9112, 121.9260426156618, 477661.9768493213, 477661.9768493208, 136330.3549609217]
[2019-03-23 02:53:17,475] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:53:17,480] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.019188201125177384
[2019-03-23 02:53:19,211] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.5360709], dtype=float32), -0.037269]
[2019-03-23 02:53:19,214] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.0, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4392808346040195, 6.9112, 6.9112, 121.9260426156618, 313641.9049694932, 313641.9049694932, 95591.73602042183]
[2019-03-23 02:53:19,215] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:53:19,218] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5099297545291621
[2019-03-23 02:53:30,154] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.5360709], dtype=float32), -0.037269]
[2019-03-23 02:53:30,156] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.0, 83.0, 1.0, 2.0, 0.6166700536337074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 756861.5113790258, 756861.5113790258, 163130.9927022176]
[2019-03-23 02:53:30,159] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:53:30,161] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 6.4386408e-20 1.1309846e-23], sampled 0.5060034038747794
[2019-03-23 02:53:30,164] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 756861.5113790258 W.
[2019-03-23 02:53:41,559] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.5360709], dtype=float32), -0.037269]
[2019-03-23 02:53:41,561] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8951521839189528, 6.911199999999999, 6.9112, 121.9260426156618, 654737.6951999413, 654737.6951999418, 175378.1434033572]
[2019-03-23 02:53:41,562] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:53:41,563] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.16484315301906527
[2019-03-23 02:53:42,619] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.5360709], dtype=float32), -0.037269]
[2019-03-23 02:53:42,620] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.83333333333334, 62.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8638759955821548, 6.9112, 6.9112, 121.9260426156618, 635787.9942267128, 635787.9942267128, 170380.456616447]
[2019-03-23 02:53:42,622] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:53:42,623] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.0580642194321187
[2019-03-23 02:53:56,275] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.5360709], dtype=float32), -0.037269]
[2019-03-23 02:53:56,277] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 75.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 1.0, 2.0, 0.9977734948820727, 19.81191832846829, 6.9112, 137.6437613801577, 10507544.71283215, 3049590.452839629, 515669.0094699394]
[2019-03-23 02:53:56,280] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:53:56,285] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0. 0. 0. 1. 0.], sampled 0.6589019952832597
[2019-03-23 02:53:56,286] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 0, 0, 1, 0] has been changed to [0, 0, 0, 0, 1] for the demand 10507544.71283215 W.
[2019-03-23 02:54:05,345] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.5360709], dtype=float32), -0.037269]
[2019-03-23 02:54:05,346] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.91666666666667, 93.33333333333334, 1.0, 2.0, 0.7165955738571737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816726.3142240206, 816726.3142240206, 179310.6490134971]
[2019-03-23 02:54:05,348] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:54:05,352] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9998868e-01 0.0000000e+00 2.7239491e-38 1.7717372e-15 1.1334159e-05], sampled 0.20753357228116442
[2019-03-23 02:54:05,354] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 816726.3142240206 W.
[2019-03-23 02:54:45,850] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.5360709], dtype=float32), -0.037269]
[2019-03-23 02:54:45,855] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.50198632333333, 82.95895459666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5954896626087716, 6.9112, 6.9112, 121.9260426156618, 442564.2744623629, 442564.2744623629, 130373.1098332668]
[2019-03-23 02:54:45,857] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:54:45,861] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.16122819811220757
[2019-03-23 02:54:55,384] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8479.9104 2326578325.8637 336.0000
[2019-03-23 02:54:55,601] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8413.9069 2363953226.5950 320.0000
[2019-03-23 02:54:55,614] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7966.9461 2553561918.3019 414.0000
[2019-03-23 02:54:55,734] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8589.5545 2266051721.0206 322.0000
[2019-03-23 02:54:55,805] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8509.4468 2301275401.8263 322.0000
[2019-03-23 02:54:56,822] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1975000, evaluation results [1975000.0, 7966.946096422576, 2553561918.3018966, 414.0, 8509.446773132122, 2301275401.8262954, 322.0, 8589.55448666675, 2266051721.020607, 322.0, 8413.906898732253, 2363953226.5950403, 320.0, 8479.910373364733, 2326578325.8637414, 336.0]
[2019-03-23 02:54:57,229] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1758185e-01 4.6267072e-34 4.0347021e-26 6.6932371e-06 8.8241154e-01], sum to 1.0000
[2019-03-23 02:54:57,236] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4060
[2019-03-23 02:54:57,244] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.46666666666667, 40.33333333333333, 1.0, 2.0, 0.2975468017038427, 1.0, 1.0, 0.2975468017038427, 1.0, 1.0, 0.4861347264425105, 6.9112, 6.9112, 121.94756008, 1089610.558873887, 1089610.558873887, 253873.1747640007], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2367600.0000, 
sim time next is 2368200.0000, 
raw observation next is [28.58333333333334, 40.16666666666667, 1.0, 2.0, 0.3057342492631636, 1.0, 2.0, 0.3057342492631636, 1.0, 2.0, 0.497265887306916, 6.911200000000001, 6.9112, 121.94756008, 1113248.655106405, 1113248.655106404, 257280.0084784072], 
processed observation next is [1.0, 0.391304347826087, 0.6141975308641977, 0.4016666666666667, 1.0, 1.0, 0.1734931538847186, 1.0, 1.0, 0.1734931538847186, 1.0, 1.0, 0.37158235913364496, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.39758880539514463, 0.3975888053951443, 0.49476924707386], 
reward next is 0.5052, 
noisyNet noise sample is [array([-1.3453461], dtype=float32), -0.7142625]. 
=============================================
[2019-03-23 02:55:03,164] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:55:03,173] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0656
[2019-03-23 02:55:03,176] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.53333333333333, 76.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8727724676551368, 6.911200000000001, 6.9112, 121.9260426156618, 641960.2780370902, 641960.2780370897, 171625.9702968804], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2641200.0000, 
sim time next is 2641800.0000, 
raw observation next is [25.66666666666666, 76.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8782767922664978, 6.911200000000001, 6.9112, 121.9260426156618, 645336.6819356454, 645336.6819356449, 172508.2021865121], 
processed observation next is [0.0, 0.5652173913043478, 0.5061728395061726, 0.7633333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8478459903331222, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23047738640558765, 0.2304773864055875, 0.3317465426663694], 
reward next is 0.6683, 
noisyNet noise sample is [array([-3.0472538], dtype=float32), 0.036716167]. 
=============================================
[2019-03-23 02:55:06,298] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.2276137e-18 1.1262155e-36 1.8732376e-34 1.0000000e+00 2.9333039e-16], sum to 1.0000
[2019-03-23 02:55:06,308] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9295
[2019-03-23 02:55:06,314] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.08333333333333, 33.33333333333334, 1.0, 2.0, 0.5993101609553694, 1.0, 1.0, 0.5993101609553694, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1449758.126584264, 1449758.126584264, 271338.2188782744], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2542200.0000, 
sim time next is 2542800.0000, 
raw observation next is [31.26666666666667, 32.66666666666667, 1.0, 2.0, 0.5959137609252034, 1.0, 2.0, 0.5959137609252034, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1440483.808812174, 1440483.808812174, 270113.9063990609], 
processed observation next is [1.0, 0.43478260869565216, 0.7135802469135804, 0.3266666666666667, 1.0, 1.0, 0.518944953482385, 1.0, 1.0, 0.518944953482385, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.514458503147205, 0.514458503147205, 0.5194498199981941], 
reward next is 0.4806, 
noisyNet noise sample is [array([0.10934786], dtype=float32), 0.5578535]. 
=============================================
[2019-03-23 02:55:10,461] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.8137645e-37 1.1546198e-17 9.2992301e-36], sum to 1.0000
[2019-03-23 02:55:10,468] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4285
[2019-03-23 02:55:10,473] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.53333333333333, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9016344595766309, 6.9112, 6.9112, 121.9260426156618, 660217.2488969385, 660217.2488969385, 176089.3315760645], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2676000.0000, 
sim time next is 2676600.0000, 
raw observation next is [23.4, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9075982111374282, 6.9112, 6.9112, 121.9260426156618, 663790.8289512346, 663790.8289512346, 177045.2129943848], 
processed observation next is [0.0, 1.0, 0.42222222222222217, 0.95, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8844977639217851, 0.0, 0.0, 0.8094621288201359, 0.2370681531968695, 0.2370681531968695, 0.34047156345074003], 
reward next is 0.6595, 
noisyNet noise sample is [array([0.29545182], dtype=float32), 0.90976256]. 
=============================================
[2019-03-23 02:55:11,955] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.7381412e-37 3.5998510e-28 5.7121537e-14 3.2230775e-17], sum to 1.0000
[2019-03-23 02:55:11,964] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7413
[2019-03-23 02:55:11,969] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 766017.2587380873 W.
[2019-03-23 02:55:11,973] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.2240419116536703, 1.0, 1.0, 0.2240419116536703, 1.0, 2.0, 0.356682019888308, 6.9112, 6.9112, 121.94756008, 766017.2587380873, 766017.2587380873, 228609.2133282245], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2844000.0000, 
sim time next is 2844600.0000, 
raw observation next is [27.91666666666667, 73.5, 1.0, 2.0, 0.6659541514711091, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758980.1304544274, 758980.1304544274, 169797.0367423891], 
processed observation next is [1.0, 0.9565217391304348, 0.5895061728395063, 0.735, 1.0, 1.0, 0.6023263707989395, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27106433230515264, 0.27106433230515264, 0.3265327629661329], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4074622], dtype=float32), 2.6107824]. 
=============================================
[2019-03-23 02:55:14,299] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.000000e+00 6.359402e-36 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 02:55:14,307] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0044
[2019-03-23 02:55:14,313] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1753878.43091262 W.
[2019-03-23 02:55:14,318] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.9112078064535505, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1753878.43091262, 1753878.43091262, 359401.8498629187], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2973600.0000, 
sim time next is 2974200.0000, 
raw observation next is [28.06666666666667, 83.33333333333333, 1.0, 2.0, 0.8441611360680201, 1.0, 1.0, 0.8441611360680201, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1925563.969745494, 1925563.969745494, 362341.4419774737], 
processed observation next is [1.0, 0.43478260869565216, 0.5950617283950619, 0.8333333333333333, 1.0, 1.0, 0.8144775429381191, 1.0, 0.5, 0.8144775429381191, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6877014177662478, 0.6877014177662478, 0.6968104653412955], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6347341], dtype=float32), 1.2504857]. 
=============================================
[2019-03-23 02:55:15,044] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:55:15,050] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5576
[2019-03-23 02:55:15,053] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.16666666666666, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8678653486724999, 6.911200000000001, 6.9112, 121.9260426156618, 637845.5614362201, 637845.5614362196, 171117.9906397863], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2722200.0000, 
sim time next is 2722800.0000, 
raw observation next is [30.33333333333334, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8770522333728006, 6.911199999999999, 6.9112, 121.9260426156618, 643384.4951159642, 643384.4951159647, 172595.0256056431], 
processed observation next is [0.0, 0.5217391304347826, 0.6790123456790126, 0.52, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8463152917160007, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22978017682713006, 0.22978017682713023, 0.3319135107800829], 
reward next is 0.6681, 
noisyNet noise sample is [array([0.74265534], dtype=float32), 0.8153913]. 
=============================================
[2019-03-23 02:55:20,568] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 4.8852466e-30 0.0000000e+00 2.9103628e-18 0.0000000e+00], sum to 1.0000
[2019-03-23 02:55:20,579] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3128
[2019-03-23 02:55:20,587] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1053860.630968307 W.
[2019-03-23 02:55:20,592] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.65, 52.5, 1.0, 2.0, 0.46225711659513, 1.0, 2.0, 0.46225711659513, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1053860.630968307, 1053860.630968307, 223957.8141675667], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2826600.0000, 
sim time next is 2827200.0000, 
raw observation next is [32.5, 53.0, 1.0, 2.0, 0.3219999970501309, 1.0, 2.0, 0.3219999970501309, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 733947.2563341674, 733947.2563341679, 185824.6983017184], 
processed observation next is [1.0, 0.7391304347826086, 0.7592592592592593, 0.53, 1.0, 1.0, 0.19285713934539392, 1.0, 1.0, 0.19285713934539392, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2621240201193455, 0.26212402011934566, 0.35735518904176616], 
reward next is 0.6426, 
noisyNet noise sample is [array([0.4247009], dtype=float32), 0.37672046]. 
=============================================
[2019-03-23 02:55:23,358] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 8.8421926e-30 4.7681435e-25 2.0538542e-24 0.0000000e+00], sum to 1.0000
[2019-03-23 02:55:23,366] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1290
[2019-03-23 02:55:23,374] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1119940.000863933 W.
[2019-03-23 02:55:23,379] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 89.0, 1.0, 2.0, 0.3274803638644603, 1.0, 1.0, 0.3274803638644603, 1.0, 2.0, 0.521359404563089, 6.911199999999999, 6.9112, 121.94756008, 1119940.000863933, 1119940.000863934, 266773.7301539112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2895600.0000, 
sim time next is 2896200.0000, 
raw observation next is [25.0, 89.0, 1.0, 2.0, 0.9212727001970241, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1050163.05131929, 1050163.05131929, 222262.6011461953], 
processed observation next is [1.0, 0.5217391304347826, 0.48148148148148145, 0.89, 1.0, 1.0, 0.9062770240440763, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.37505823261403215, 0.37505823261403215, 0.42742807912729863], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1284733], dtype=float32), 0.29789603]. 
=============================================
[2019-03-23 02:55:29,525] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:55:29,533] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0362
[2019-03-23 02:55:29,541] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 704850.515258011 W.
[2019-03-23 02:55:29,545] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 93.5, 1.0, 2.0, 0.3092404356806397, 1.0, 1.0, 0.3092404356806397, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 704850.515258011, 704850.5152580114, 182692.9745365204], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3029400.0000, 
sim time next is 3030000.0000, 
raw observation next is [24.53333333333333, 93.33333333333334, 1.0, 2.0, 0.6247904560153466, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 712164.5384646951, 712164.5384646951, 162398.9699590973], 
processed observation next is [1.0, 0.043478260869565216, 0.46419753086419746, 0.9333333333333335, 1.0, 1.0, 0.5533219714468411, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2543444780231054, 0.2543444780231054, 0.3123057114598025], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3246905], dtype=float32), -0.1701102]. 
=============================================
[2019-03-23 02:55:29,557] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[43.212307]
 [44.658493]
 [46.196438]
 [47.404312]
 [49.63111 ]], R is [[41.61919403]
 [41.85166931]
 [42.12534714]
 [42.32608795]
 [42.52606583]].
[2019-03-23 02:55:35,306] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:55:35,315] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8706
[2019-03-23 02:55:35,319] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.25, 83.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9119754365861875, 6.911200000000001, 6.9112, 121.9260426156618, 665288.9219030776, 665288.9219030772, 177951.89183102], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3203400.0000, 
sim time next is 3204000.0000, 
raw observation next is [25.1, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9438370672631166, 6.9112, 6.9112, 121.9260426156618, 684177.88552758, 684177.88552758, 182976.5521336563], 
processed observation next is [0.0, 0.08695652173913043, 0.4851851851851852, 0.87, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9297963340788956, 0.0, 0.0, 0.8094621288201359, 0.2443492448312786, 0.2443492448312786, 0.351877984872416], 
reward next is 0.6481, 
noisyNet noise sample is [array([-0.6154369], dtype=float32), -0.12313508]. 
=============================================
[2019-03-23 02:55:35,330] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[71.6943  ]
 [71.234055]
 [70.843414]
 [70.813866]
 [70.90231 ]], R is [[71.94830322]
 [71.88660431]
 [71.83472443]
 [71.79251099]
 [71.75913239]].
[2019-03-23 02:55:39,331] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 7.1820989e-23 2.4044626e-16 1.0585823e-30], sum to 1.0000
[2019-03-23 02:55:39,338] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3268
[2019-03-23 02:55:39,347] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 798727.8541575233 W.
[2019-03-23 02:55:39,352] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 73.33333333333334, 1.0, 2.0, 0.2336040051344239, 1.0, 2.0, 0.2336040051344239, 1.0, 1.0, 0.3719051841253114, 6.911199999999999, 6.9112, 121.94756008, 798727.8541575233, 798727.8541575237, 231886.6765793341], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3337800.0000, 
sim time next is 3338400.0000, 
raw observation next is [29.0, 72.66666666666667, 1.0, 2.0, 0.3469036710213663, 1.0, 2.0, 0.3469036710213663, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790740.4586888972, 790740.4586888972, 192098.0744594907], 
processed observation next is [0.0, 0.6521739130434783, 0.6296296296296297, 0.7266666666666667, 1.0, 1.0, 0.22250437026353134, 1.0, 1.0, 0.22250437026353134, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2824073066746061, 0.2824073066746061, 0.369419373960559], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2984902], dtype=float32), -1.3991992]. 
=============================================
[2019-03-23 02:55:39,942] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 2.478679e-31 5.889604e-24 0.000000e+00], sum to 1.0000
[2019-03-23 02:55:39,950] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3206
[2019-03-23 02:55:39,958] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 758329.965271871 W.
[2019-03-23 02:55:39,962] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6653839571878843, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 758329.965271871, 758329.9652718705, 169693.0023690848], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3458400.0000, 
sim time next is 3459000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.2218418777672654, 1.0, 1.0, 0.2218418777672654, 1.0, 1.0, 0.3531794942910499, 6.911199999999999, 6.9112, 121.94756008, 758491.4454788793, 758491.4454788797, 227862.374104868], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.07362128305626835, 1.0, 0.5, 0.07362128305626835, 1.0, 0.5, 0.19147436786381233, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2708898019567426, 0.2708898019567428, 0.4381968732785923], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8694796], dtype=float32), 0.5405722]. 
=============================================
[2019-03-23 02:55:39,973] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[40.420773]
 [40.568882]
 [41.72294 ]
 [42.808514]
 [43.118916]], R is [[38.48678589]
 [38.10191727]
 [37.72089767]
 [38.01777649]
 [38.24565506]].
[2019-03-23 02:55:42,376] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4664673e-01 5.4619322e-34 4.3286729e-22 7.5335324e-01 0.0000000e+00], sum to 1.0000
[2019-03-23 02:55:42,382] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8557
[2019-03-23 02:55:42,385] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.45, 78.5, 1.0, 2.0, 0.3415709598758103, 1.0, 1.0, 0.3415709598758103, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 778578.7767991646, 778578.7767991651, 190736.2246806336], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3439800.0000, 
sim time next is 3440400.0000, 
raw observation next is [27.26666666666667, 78.33333333333334, 1.0, 2.0, 0.3366126403905184, 1.0, 2.0, 0.3366126403905184, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 767271.0986843529, 767271.0986843529, 189479.0745034818], 
processed observation next is [1.0, 0.8260869565217391, 0.5654320987654322, 0.7833333333333334, 1.0, 1.0, 0.21025314332204573, 1.0, 1.0, 0.21025314332204573, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2740253923872689, 0.2740253923872689, 0.36438283558361884], 
reward next is 0.6356, 
noisyNet noise sample is [array([1.0327544], dtype=float32), 1.1184788]. 
=============================================
[2019-03-23 02:55:44,061] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 5.1562744e-35 2.5560759e-14 1.2962305e-15 1.6264057e-14], sum to 1.0000
[2019-03-23 02:55:44,071] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4274
[2019-03-23 02:55:44,080] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 92.66666666666667, 1.0, 2.0, 0.2941731876913186, 1.0, 2.0, 0.2941731876913186, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 677966.8790338462, 677966.8790338467, 179437.3448494127], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3277200.0000, 
sim time next is 3277800.0000, 
raw observation next is [23.4, 92.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9097882329476635, 6.911199999999999, 6.9112, 121.9260426156618, 665466.1411258855, 665466.141125886, 177323.5163462459], 
processed observation next is [0.0, 0.9565217391304348, 0.42222222222222217, 0.92, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.8872352911845793, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23766647897353055, 0.23766647897353071, 0.341006762204319], 
reward next is 0.6590, 
noisyNet noise sample is [array([0.79423034], dtype=float32), -0.020236336]. 
=============================================
[2019-03-23 02:55:45,553] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 02:55:45,555] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:55:45,557] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:55:45,557] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:55:45,558] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:55:45,559] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:55:45,558] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:55:45,561] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:55:45,562] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:55:45,565] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:55:45,567] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:55:46,279] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run81
[2019-03-23 02:55:46,417] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run81
[2019-03-23 02:55:46,771] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run81
[2019-03-23 02:55:47,014] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run81
[2019-03-23 02:55:47,381] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run81
[2019-03-23 02:55:47,773] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.39069265], dtype=float32), -0.061333425]
[2019-03-23 02:55:47,773] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.3, 45.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6724437327130762, 6.911200000000001, 6.9112, 121.9260426156618, 502417.1201627714, 502417.120162771, 141165.0454814764]
[2019-03-23 02:55:47,773] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:55:47,774] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.03522937277996807
[2019-03-23 02:56:08,571] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.39069265], dtype=float32), -0.061333425]
[2019-03-23 02:56:08,572] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.65, 42.5, 1.0, 2.0, 0.5061543419169042, 1.0, 1.0, 0.5061543419169042, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9258539265206, 1243624.215960816, 1243624.215960816, 240795.9890538619]
[2019-03-23 02:56:08,574] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:56:08,580] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.8974050e-11 0.0000000e+00 8.1552907e-23 1.0000000e+00 6.8893107e-35], sampled 0.24765030792914577
[2019-03-23 02:56:31,074] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.39069265], dtype=float32), -0.061333425]
[2019-03-23 02:56:31,075] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.17261996333334, 66.28355370833333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.903669450416033, 6.9112, 6.9112, 121.9260426156618, 657682.9511956153, 657682.9511956153, 177101.7198305265]
[2019-03-23 02:56:31,076] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 02:56:31,079] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 6.683375e-24 0.000000e+00], sampled 0.140707032884821
[2019-03-23 02:56:33,511] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.39069265], dtype=float32), -0.061333425]
[2019-03-23 02:56:33,515] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.33333333333334, 70.66666666666667, 1.0, 2.0, 0.3700580316781332, 1.0, 2.0, 0.3700580316781332, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 843548.1011351862, 843548.1011351866, 198124.1385735308]
[2019-03-23 02:56:33,516] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:56:33,519] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9221933e-01 0.0000000e+00 2.3135693e-13 7.7806907e-03 4.1679285e-15], sampled 0.5828073378497138
[2019-03-23 02:56:33,520] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 843548.1011351862 W.
[2019-03-23 02:57:18,311] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.39069265], dtype=float32), -0.061333425]
[2019-03-23 02:57:18,313] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.238686885, 91.96845569, 1.0, 2.0, 0.7881735764823201, 1.0, 2.0, 0.7881735764823201, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426141056, 1797725.671798194, 1797725.671798194, 338889.9010088817]
[2019-03-23 02:57:18,314] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:57:18,316] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0. 0. 0. 1. 0.], sampled 0.8662989433733495
[2019-03-23 02:57:38,055] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8076.3273 2511339198.8993 413.0000
[2019-03-23 02:57:38,989] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8500.7619 2322492686.9941 323.0000
[2019-03-23 02:57:38,995] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8611.2753 2259359329.3449 309.0000
[2019-03-23 02:57:39,038] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8689.2180 2224497866.9093 318.0000
[2019-03-23 02:57:39,325] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8535.5781 2287522395.8071 371.0000
[2019-03-23 02:57:40,341] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2000000, evaluation results [2000000.0, 8076.327330170361, 2511339198.8993335, 413.0, 8611.275307868238, 2259359329.344932, 309.0, 8689.217951262155, 2224497866.9093037, 318.0, 8500.761852134441, 2322492686.9941125, 323.0, 8535.57813235819, 2287522395.8071003, 371.0]
[2019-03-23 02:57:44,933] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9939477e-01 5.7251837e-29 7.5201122e-34 6.0527079e-04 0.0000000e+00], sum to 1.0000
[2019-03-23 02:57:44,939] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9295
[2019-03-23 02:57:44,947] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1866245.339356213 W.
[2019-03-23 02:57:44,952] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.41666666666667, 79.0, 1.0, 2.0, 0.8181831778459973, 1.0, 2.0, 0.8181831778459973, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1866245.339356213, 1866245.339356213, 351325.1911952221], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3495000.0000, 
sim time next is 3495600.0000, 
raw observation next is [27.5, 77.0, 1.0, 2.0, 0.5028972022743965, 1.0, 2.0, 0.5028972022743965, 1.0, 1.0, 0.8006287242392944, 6.911199999999999, 6.9112, 121.94756008, 1720494.141412015, 1720494.141412016, 345013.2972743911], 
processed observation next is [1.0, 0.4782608695652174, 0.5740740740740741, 0.77, 1.0, 1.0, 0.40821095508856725, 1.0, 1.0, 0.40821095508856725, 1.0, 0.5, 0.750785905299118, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6144621933614339, 0.6144621933614343, 0.6634871101430598], 
reward next is 0.3365, 
noisyNet noise sample is [array([-1.1633865], dtype=float32), 0.7290959]. 
=============================================
[2019-03-23 02:57:48,337] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9999964e-01 0.0000000e+00 3.6890265e-07 6.8513831e-13 3.1677149e-31], sum to 1.0000
[2019-03-23 02:57:48,341] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8515
[2019-03-23 02:57:48,343] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 737427.823879866 W.
[2019-03-23 02:57:48,352] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.25, 89.5, 1.0, 2.0, 0.2156841983585838, 1.0, 2.0, 0.2156841983585838, 1.0, 1.0, 0.343376268130811, 6.911200000000001, 6.9112, 121.94756008, 737427.823879866, 737427.8238798656, 225786.4376301417], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3454200.0000, 
sim time next is 3454800.0000, 
raw observation next is [25.16666666666666, 91.0, 1.0, 2.0, 0.2167106211437617, 1.0, 2.0, 0.2167106211437617, 1.0, 2.0, 0.3450103666330706, 6.9112, 6.9112, 121.94756008, 740938.8760510056, 740938.8760510056, 226131.0020255882], 
processed observation next is [1.0, 1.0, 0.4876543209876541, 0.91, 1.0, 1.0, 0.06751264421876392, 1.0, 1.0, 0.06751264421876392, 1.0, 1.0, 0.18126295829133823, 0.0, 0.0, 0.8096049824067558, 0.26462102716107344, 0.26462102716107344, 0.4348673115876696], 
reward next is 0.5651, 
noisyNet noise sample is [array([-0.6452982], dtype=float32), 0.17853725]. 
=============================================
[2019-03-23 02:57:48,865] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:57:48,874] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4400
[2019-03-23 02:57:48,878] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6452807257989337, 6.911200000000001, 6.9112, 121.9260426156618, 481497.8439906183, 481497.8439906178, 137074.4005129373], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4253400.0000, 
sim time next is 4254000.0000, 
raw observation next is [21.53333333333333, 80.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6387014826474319, 6.911200000000001, 6.9112, 121.9260426156618, 476429.3078101988, 476429.3078101983, 136198.0033244288], 
processed observation next is [1.0, 0.21739130434782608, 0.35308641975308636, 0.8033333333333332, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5483768533092898, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17015332421792814, 0.17015332421792795, 0.2619192371623631], 
reward next is 0.7381, 
noisyNet noise sample is [array([2.8736062], dtype=float32), 0.2051743]. 
=============================================
[2019-03-23 02:57:48,891] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[63.135464]
 [62.744457]
 [62.068573]
 [61.206493]
 [60.929962]], R is [[63.18975449]
 [63.2942543 ]
 [63.39598846]
 [63.48765945]
 [63.56123352]].
[2019-03-23 02:57:52,842] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0855864e-04 3.7947113e-35 5.1381871e-22 9.9969149e-01 0.0000000e+00], sum to 1.0000
[2019-03-23 02:57:52,849] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0452
[2019-03-23 02:57:52,857] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.3864152709056226, 1.0, 1.0, 0.3864152709056226, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 880855.8910360511, 880855.8910360511, 202490.7976442229], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3737400.0000, 
sim time next is 3738000.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.3580889833893342, 1.0, 2.0, 0.3580889833893342, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 816250.1009798943, 816250.1009798946, 194984.5816479944], 
processed observation next is [1.0, 0.2608695652173913, 0.4444444444444444, 1.0, 1.0, 1.0, 0.23582021832063596, 1.0, 1.0, 0.23582021832063596, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2915178932071051, 0.29151789320710525, 0.37497034932306617], 
reward next is 0.6250, 
noisyNet noise sample is [array([-1.6862164], dtype=float32), 1.6098969]. 
=============================================
[2019-03-23 02:57:52,875] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[45.431988]
 [45.47525 ]
 [45.640747]
 [45.43361 ]
 [45.2772  ]], R is [[45.79749298]
 [45.3395195 ]
 [45.48412323]
 [45.58420181]
 [45.7558136 ]].
[2019-03-23 02:57:55,721] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.7532370e-04 0.0000000e+00 6.2325836e-20 9.9952471e-01 3.1176841e-22], sum to 1.0000
[2019-03-23 02:57:55,730] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2180
[2019-03-23 02:57:55,734] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.6, 94.0, 1.0, 2.0, 0.8716257641740431, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1708695.514067654, 1708695.514067654, 350908.2522636401], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3745200.0000, 
sim time next is 3745800.0000, 
raw observation next is [25.7, 94.0, 1.0, 2.0, 0.8048995588106189, 1.0, 1.0, 0.8048995588106189, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1835914.75923622, 1835914.75923622, 345783.4252634256], 
processed observation next is [1.0, 0.34782608695652173, 0.5074074074074074, 0.94, 1.0, 1.0, 0.7677375700126415, 1.0, 0.5, 0.7677375700126415, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6556838425843643, 0.6556838425843643, 0.6649681255065878], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4290986], dtype=float32), -0.19897133]. 
=============================================
[2019-03-23 02:57:57,331] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:57:57,337] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0032
[2019-03-23 02:57:57,346] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1134177.15116122 W.
[2019-03-23 02:57:57,350] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 96.66666666666667, 1.0, 1.0, 0.4941103638047118, 1.0, 1.0, 0.4941103638047118, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9245083926471, 1134177.15116122, 1134177.15116122, 233935.7480432292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3637200.0000, 
sim time next is 3637800.0000, 
raw observation next is [23.1, 97.5, 1.0, 2.0, 0.680793189903505, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260421477982, 789607.7626770047, 789607.7626770047, 173209.8883523486], 
processed observation next is [1.0, 0.08695652173913043, 0.41111111111111115, 0.975, 1.0, 1.0, 0.6199918927422678, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621257140082, 0.28200277238464455, 0.28200277238464455, 0.3330959391391319], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.340717], dtype=float32), -0.18609445]. 
=============================================
[2019-03-23 02:58:00,240] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.7792575e-17 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 02:58:00,245] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4203
[2019-03-23 02:58:00,251] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.9, 84.0, 1.0, 2.0, 0.6699846522815411, 1.0, 1.0, 0.6699846522815411, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1527913.272374701, 1527913.272374701, 292958.9393444263], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3690000.0000, 
sim time next is 3690600.0000, 
raw observation next is [26.91666666666667, 84.83333333333333, 1.0, 2.0, 0.3944153391718238, 1.0, 2.0, 0.3944153391718238, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 899103.2052491646, 899103.2052491646, 204661.9594060694], 
processed observation next is [1.0, 0.7391304347826086, 0.5524691358024693, 0.8483333333333333, 1.0, 1.0, 0.27906587996645693, 1.0, 1.0, 0.27906587996645693, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32110828758898735, 0.32110828758898735, 0.3935806911655181], 
reward next is 0.6064, 
noisyNet noise sample is [array([-0.04830189], dtype=float32), -1.2205139]. 
=============================================
[2019-03-23 02:58:03,622] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 4.0036177e-32 7.2629663e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 02:58:03,628] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0757
[2019-03-23 02:58:03,643] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 792599.1074031197 W.
[2019-03-23 02:58:03,649] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.75, 74.0, 1.0, 2.0, 0.6954373050946391, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 792599.1074031197, 792599.1074031192, 175283.2410657011], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3797400.0000, 
sim time next is 3798000.0000, 
raw observation next is [28.5, 77.0, 1.0, 2.0, 0.3546862842392234, 1.0, 1.0, 0.3546862842392234, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808489.688008882, 808489.688008882, 194102.7518114096], 
processed observation next is [1.0, 1.0, 0.6111111111111112, 0.77, 1.0, 1.0, 0.23176938599907546, 1.0, 0.5, 0.23176938599907546, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2887463171460293, 0.2887463171460293, 0.3732745227142492], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9262787], dtype=float32), -0.12823513]. 
=============================================
[2019-03-23 02:58:03,658] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[38.982346]
 [38.944378]
 [38.794064]
 [38.864933]
 [39.098892]], R is [[38.49250793]
 [38.10758209]
 [37.72650528]
 [37.34923935]
 [36.97574615]].
[2019-03-23 02:58:13,521] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 4.9903221e-33 1.3524318e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 02:58:13,529] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4562
[2019-03-23 02:58:13,539] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 696549.7614794603 W.
[2019-03-23 02:58:13,545] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.35, 83.5, 1.0, 2.0, 0.6112005673202702, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696549.7614794603, 696549.7614794603, 160015.8404711923], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4037400.0000, 
sim time next is 4038000.0000, 
raw observation next is [26.23333333333333, 85.33333333333333, 1.0, 2.0, 0.3112670627678105, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4955473011868697, 6.911199999999999, 6.9112, 121.9260426156618, 709471.936052064, 709471.9360520644, 198298.7030385602], 
processed observation next is [1.0, 0.7391304347826086, 0.5271604938271603, 0.8533333333333333, 1.0, 1.0, 0.18007983662834587, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.3694341264835871, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2533828343043086, 0.2533828343043087, 0.3813436596895388], 
reward next is 0.6187, 
noisyNet noise sample is [array([0.66971457], dtype=float32), -1.0547464]. 
=============================================
[2019-03-23 02:58:13,553] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[36.11882 ]
 [36.74286 ]
 [37.404278]
 [36.8802  ]
 [35.84285 ]], R is [[36.46467972]
 [36.79230881]
 [37.07508087]
 [37.3159256 ]
 [36.9427681 ]].
[2019-03-23 02:58:16,331] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:58:16,342] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5599
[2019-03-23 02:58:16,345] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.760514005083216, 6.9112, 6.9112, 121.9260426156618, 567381.7504105831, 567381.7504105831, 153766.0448662109], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4146000.0000, 
sim time next is 4146600.0000, 
raw observation next is [21.9, 89.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7528741603496774, 6.9112, 6.9112, 121.9260426156618, 561876.6619051371, 561876.6619051371, 152643.9621057231], 
processed observation next is [1.0, 1.0, 0.36666666666666664, 0.895, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6910927004370967, 0.0, 0.0, 0.8094621288201359, 0.20067023639469184, 0.20067023639469184, 0.2935460809725444], 
reward next is 0.7065, 
noisyNet noise sample is [array([0.7759247], dtype=float32), 0.77108365]. 
=============================================
[2019-03-23 02:58:16,971] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.3877641e-03 1.3494675e-22 1.5865950e-15 9.9361223e-01 6.6632300e-20], sum to 1.0000
[2019-03-23 02:58:16,979] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2944
[2019-03-23 02:58:16,987] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.5, 39.0, 1.0, 2.0, 0.8863585017983294, 1.0, 2.0, 0.8863585017983294, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2021926.74372512, 2021926.74372512, 380729.5130580483], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4289400.0000, 
sim time next is 4290000.0000, 
raw observation next is [33.33333333333334, 40.66666666666666, 1.0, 2.0, 0.931312576241024, 1.0, 2.0, 0.931312576241024, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2124596.235361236, 2124596.235361236, 401000.8265324002], 
processed observation next is [1.0, 0.6521739130434783, 0.7901234567901239, 0.40666666666666657, 1.0, 1.0, 0.9182292574297906, 1.0, 1.0, 0.9182292574297906, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.75878436977187, 0.75878436977187, 0.7711554356392312], 
reward next is 0.2288, 
noisyNet noise sample is [array([-0.19176966], dtype=float32), -0.14223464]. 
=============================================
[2019-03-23 02:58:17,005] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[33.699238]
 [33.166073]
 [32.817657]
 [32.622337]
 [32.568058]], R is [[33.9335289 ]
 [33.86201859]
 [33.78924179]
 [33.68960571]
 [33.64543152]].
[2019-03-23 02:58:21,618] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 4.2848715e-28 3.1217370e-30 2.0084132e-09], sum to 1.0000
[2019-03-23 02:58:21,629] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4303
[2019-03-23 02:58:21,634] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1469306.733516254 W.
[2019-03-23 02:58:21,638] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.66666666666666, 81.66666666666667, 1.0, 2.0, 0.6395346073295864, 1.0, 2.0, 0.6395346073295864, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1469306.733516254, 1469306.733516255, 282452.6720709265], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4094400.0000, 
sim time next is 4095000.0000, 
raw observation next is [25.0, 81.0, 1.0, 2.0, 0.6734013179701624, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9880432334432151, 6.911200000000001, 6.9112, 121.9260426156618, 1490699.705293334, 1490699.705293333, 310752.6707279652], 
processed observation next is [1.0, 0.391304347826087, 0.48148148148148145, 0.81, 1.0, 1.0, 0.6111920452025743, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9850540418040188, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5323927518904764, 0.5323927518904761, 0.5976012898614715], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3847263], dtype=float32), 0.38837457]. 
=============================================
[2019-03-23 02:58:21,650] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[33.46338 ]
 [33.922016]
 [33.483562]
 [34.35177 ]
 [35.562458]], R is [[32.68405914]
 [32.81404114]
 [32.91440582]
 [33.00881195]
 [33.10470581]].
[2019-03-23 02:58:24,333] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:58:24,339] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4990
[2019-03-23 02:58:24,345] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7958220762978734, 6.911200000000001, 6.9112, 121.9260426156618, 591918.4025396048, 591918.4025396043, 159378.80963676], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4419000.0000, 
sim time next is 4419600.0000, 
raw observation next is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7951173284121424, 6.9112, 6.9112, 121.9260426156618, 591394.028087887, 591394.028087887, 159291.8145244208], 
processed observation next is [0.0, 0.13043478260869565, 0.37037037037037035, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7438966605151781, 0.0, 0.0, 0.8094621288201359, 0.21121215288853107, 0.21121215288853107, 0.3063304125469631], 
reward next is 0.6937, 
noisyNet noise sample is [array([0.6084584], dtype=float32), 0.34614286]. 
=============================================
[2019-03-23 02:58:24,551] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:58:24,560] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1957
[2019-03-23 02:58:24,568] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.16666666666666, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7264524917520816, 6.911200000000001, 6.9112, 121.9260426156618, 542653.5568961147, 542653.5568961143, 148785.8538220107], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4150200.0000, 
sim time next is 4150800.0000, 
raw observation next is [21.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7236397544869493, 6.911200000000001, 6.9112, 121.9260426156618, 540600.4585407507, 540600.4585407502, 148349.4140380509], 
processed observation next is [1.0, 0.043478260869565216, 0.3333333333333333, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6545496931086866, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1930715923359824, 0.19307159233598223, 0.2852873346885594], 
reward next is 0.7147, 
noisyNet noise sample is [array([-0.75625527], dtype=float32), 0.77095944]. 
=============================================
[2019-03-23 02:58:27,652] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 02:58:27,664] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8751
[2019-03-23 02:58:27,670] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8034680888703764, 6.9112, 6.9112, 121.9260426156618, 597595.7453125396, 597595.7453125396, 160332.5853341889], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4407000.0000, 
sim time next is 4407600.0000, 
raw observation next is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8023987176755497, 6.911200000000001, 6.9112, 121.9260426156618, 596810.2266118738, 596810.2266118734, 160193.9215159235], 
processed observation next is [0.0, 0.0, 0.37037037037037035, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.752998397094437, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21314650950424066, 0.2131465095042405, 0.30806523368446825], 
reward next is 0.6919, 
noisyNet noise sample is [array([0.79625684], dtype=float32), 0.43920028]. 
=============================================
[2019-03-23 02:58:29,253] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 02:58:29,255] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 02:58:29,256] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 02:58:29,257] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:58:29,257] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:58:29,257] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 02:58:29,258] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 02:58:29,259] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:58:29,260] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 02:58:29,261] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:58:29,263] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 02:58:29,282] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run82
[2019-03-23 02:58:29,310] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run82
[2019-03-23 02:58:29,337] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run82
[2019-03-23 02:58:29,362] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run82
[2019-03-23 02:58:29,391] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run82
[2019-03-23 02:58:30,354] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.35258514], dtype=float32), -0.039208822]
[2019-03-23 02:58:30,354] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [15.21589662166667, 88.52890381833333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3803821645573925, 6.9112, 6.9112, 121.9260426156618, 271581.4279589308, 271581.4279589308, 87984.68194530536]
[2019-03-23 02:58:30,355] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 02:58:30,355] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.24397724475029425
[2019-03-23 02:58:38,223] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.35258514], dtype=float32), -0.039208822]
[2019-03-23 02:58:38,227] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.4, 27.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7831452580276279, 6.9112, 6.9112, 121.9260426156618, 574730.7276851796, 574730.7276851796, 145443.7463477091]
[2019-03-23 02:58:38,229] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:58:38,235] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.24037193882575103
[2019-03-23 02:59:02,675] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.35258514], dtype=float32), -0.039208822]
[2019-03-23 02:59:02,676] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.06666666666667, 92.0, 1.0, 2.0, 0.2720145401786737, 1.0, 2.0, 0.2720145401786737, 1.0, 2.0, 0.4352227184045138, 6.911199999999999, 6.9112, 121.94756008, 958590.065809901, 958590.0658099015, 245452.4643893734]
[2019-03-23 02:59:02,679] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:59:02,682] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.6454106e-02 0.0000000e+00 9.5526229e-31 0.0000000e+00 9.7354591e-01], sampled 0.7756562457271512
[2019-03-23 02:59:47,844] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.35258514], dtype=float32), -0.039208822]
[2019-03-23 02:59:47,845] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [35.45, 48.0, 1.0, 2.0, 0.6420860300006048, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1446702.637852107, 1446702.637852107, 307020.5582365833]
[2019-03-23 02:59:47,846] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 02:59:47,850] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.4955379e-01 0.0000000e+00 1.1021775e-24 5.6480292e-07 5.0445646e-02], sampled 0.4850688233084878
[2019-03-23 02:59:47,851] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1446702.637852107 W.
[2019-03-23 02:59:54,107] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.35258514], dtype=float32), -0.039208822]
[2019-03-23 02:59:54,108] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.33333333333334, 67.66666666666667, 1.0, 2.0, 0.6363519198357545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 725226.8549092936, 725226.8549092936, 164446.1489785376]
[2019-03-23 02:59:54,109] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:59:54,111] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 4.1074373e-31 0.0000000e+00 3.7358704e-13], sampled 0.8708726928403934
[2019-03-23 02:59:54,114] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 725226.8549092936 W.
[2019-03-23 02:59:54,687] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.35258514], dtype=float32), -0.039208822]
[2019-03-23 02:59:54,689] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.08333333333334, 79.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7812712506938031, 6.911199999999999, 6.9112, 121.9260426156618, 583640.3014564455, 583640.301456446, 152885.2684752708]
[2019-03-23 02:59:54,691] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 02:59:54,694] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.14163401947759602
[2019-03-23 02:59:55,404] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.35258514], dtype=float32), -0.039208822]
[2019-03-23 02:59:55,405] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.06666666666667, 76.33333333333334, 1.0, 2.0, 0.6161828128699067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 703596.51995536, 703596.5199553595, 160951.4494538555]
[2019-03-23 02:59:55,407] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 02:59:55,410] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.1232914e-01 0.0000000e+00 1.7656538e-28 0.0000000e+00 8.7670878e-02], sampled 0.7857755506458164
[2019-03-23 02:59:55,413] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 703596.51995536 W.
[2019-03-23 03:00:21,498] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8503.0849 2332461761.1223 317.0000
[2019-03-23 03:00:21,501] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8447.7552 2377343008.0244 322.0000
[2019-03-23 03:00:21,517] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8331.1344 2436765802.7671 301.0000
[2019-03-23 03:00:21,538] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7857.5914 2630061805.6572 437.0000
[2019-03-23 03:00:21,593] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8351.5267 2395589525.1701 354.0000
[2019-03-23 03:00:22,613] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2025000, evaluation results [2025000.0, 7857.5914321024775, 2630061805.657177, 437.0, 8447.755227147321, 2377343008.024403, 322.0, 8503.08487708699, 2332461761.12226, 317.0, 8331.134352351624, 2436765802.767069, 301.0, 8351.526680062163, 2395589525.170142, 354.0]
[2019-03-23 03:00:25,100] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999976e-01 0.0000000e+00 4.8914530e-31 0.0000000e+00 2.7006286e-07], sum to 1.0000
[2019-03-23 03:00:25,107] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5485
[2019-03-23 03:00:25,112] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 781695.171803608 W.
[2019-03-23 03:00:25,118] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.66666666666667, 89.83333333333333, 1.0, 2.0, 0.2286249934884819, 1.0, 2.0, 0.2286249934884819, 1.0, 1.0, 0.363978435429883, 6.911199999999999, 6.9112, 121.94756008, 781695.171803608, 781695.1718036084, 230173.7117779226], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4661400.0000, 
sim time next is 4662000.0000, 
raw observation next is [25.6, 89.0, 1.0, 2.0, 0.3371426474851573, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5367420747658475, 6.911199999999999, 6.9112, 121.9260426156618, 768479.7965429473, 768479.7965429478, 205496.1292552022], 
processed observation next is [1.0, 1.0, 0.5037037037037038, 0.89, 1.0, 1.0, 0.2108841041489968, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.4209275934573093, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27445707019390975, 0.2744570701939099, 0.3951848639523119], 
reward next is 0.6048, 
noisyNet noise sample is [array([1.3359315], dtype=float32), -0.4464531]. 
=============================================
[2019-03-23 03:00:25,133] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[49.02558 ]
 [48.39499 ]
 [48.75337 ]
 [48.586224]
 [47.718468]], R is [[48.87874603]
 [48.38995743]
 [48.53623199]
 [48.60416412]
 [48.1181221 ]].
[2019-03-23 03:00:34,067] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4177062e-04 1.2993054e-28 5.7706964e-13 9.9985826e-01 5.1859359e-29], sum to 1.0000
[2019-03-23 03:00:34,072] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5135
[2019-03-23 03:00:34,076] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.16666666666666, 71.5, 1.0, 2.0, 0.4129819442340306, 1.0, 1.0, 0.4129819442340306, 1.0, 2.0, 0.6574807051035152, 6.911200000000001, 6.9112, 121.94756008, 1412613.785275899, 1412613.785275899, 302815.6341990872], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4619400.0000, 
sim time next is 4620000.0000, 
raw observation next is [27.33333333333334, 72.0, 1.0, 2.0, 0.6096377079411702, 1.0, 2.0, 0.6096377079411702, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1390165.959736838, 1390165.959736838, 271371.1991374544], 
processed observation next is [1.0, 0.4782608695652174, 0.5679012345679014, 0.72, 1.0, 1.0, 0.5352829856442503, 1.0, 1.0, 0.5352829856442503, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.49648784276315644, 0.49648784276315644, 0.5218676906489508], 
reward next is 0.4781, 
noisyNet noise sample is [array([1.7437288], dtype=float32), 0.2665684]. 
=============================================
[2019-03-23 03:00:34,087] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[31.07148 ]
 [30.628433]
 [31.474815]
 [31.644613]
 [31.563694]], R is [[31.43270493]
 [31.11837769]
 [30.80719376]
 [30.91166496]
 [30.6025486 ]].
[2019-03-23 03:00:36,090] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9998891e-01 0.0000000e+00 2.2322650e-38 1.1117929e-05 0.0000000e+00], sum to 1.0000
[2019-03-23 03:00:36,100] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8163
[2019-03-23 03:00:36,109] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1007144.769497272 W.
[2019-03-23 03:00:36,115] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.13333333333334, 92.66666666666667, 1.0, 2.0, 0.8749918454720731, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1007144.769497272, 1007144.769497272, 212443.6319090745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4760400.0000, 
sim time next is 4761000.0000, 
raw observation next is [24.1, 93.0, 1.0, 2.0, 0.797863704537407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 921062.8442199151, 921062.8442199151, 196100.5277098992], 
processed observation next is [1.0, 0.08695652173913043, 0.4481481481481482, 0.93, 1.0, 1.0, 0.7593615530207226, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3289510157928268, 0.3289510157928268, 0.37711639944211384], 
reward next is 0.6229, 
noisyNet noise sample is [array([-1.9946446], dtype=float32), -0.68747675]. 
=============================================
[2019-03-23 03:00:36,124] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[44.707947]
 [43.254784]
 [44.265507]
 [43.418724]
 [43.357895]], R is [[45.12889481]
 [44.67760468]
 [44.23082733]
 [43.78852081]
 [43.92599487]].
[2019-03-23 03:00:36,628] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:00:36,633] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8393
[2019-03-23 03:00:36,639] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.2, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.932094809256069, 6.9112, 6.9112, 121.9260426156618, 678714.7462341245, 678714.7462341245, 180892.3775134531], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4525200.0000, 
sim time next is 4525800.0000, 
raw observation next is [24.33333333333334, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9398230535284579, 6.911200000000001, 6.9112, 121.9260426156618, 683203.0712258479, 683203.0712258475, 182134.7338345134], 
processed observation next is [0.0, 0.391304347826087, 0.4567901234567903, 0.9066666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9247788169105722, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24400109686637425, 0.24400109686637408, 0.3502591035279104], 
reward next is 0.6497, 
noisyNet noise sample is [array([0.42334422], dtype=float32), -0.11134639]. 
=============================================
[2019-03-23 03:00:36,989] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:00:36,996] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4113
[2019-03-23 03:00:37,003] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.05, 98.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9154247592686947, 6.9112, 6.9112, 121.9260426156618, 668888.4367742698, 668888.4367742698, 178216.3648771083], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4513800.0000, 
sim time next is 4514400.0000, 
raw observation next is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9287644262220557, 6.9112, 6.9112, 121.9260426156618, 677172.8066893412, 677172.8066893412, 180287.1536491388], 
processed observation next is [0.0, 0.2608695652173913, 0.4074074074074074, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9109555327775695, 0.0, 0.0, 0.8094621288201359, 0.241847430960479, 0.241847430960479, 0.34670606470988236], 
reward next is 0.6533, 
noisyNet noise sample is [array([0.29983407], dtype=float32), -0.8341789]. 
=============================================
[2019-03-23 03:00:42,081] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 3.170644e-22 2.021296e-38 7.018497e-19], sum to 1.0000
[2019-03-23 03:00:42,084] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8574
[2019-03-23 03:00:42,090] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 771885.0110457757 W.
[2019-03-23 03:00:42,094] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.73333333333333, 82.66666666666667, 1.0, 2.0, 0.3386358100655258, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5391192382227044, 6.911199999999999, 6.9112, 121.9260426156618, 771885.0110457757, 771885.0110457762, 205920.322296691], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4650000.0000, 
sim time next is 4650600.0000, 
raw observation next is [26.66666666666667, 82.33333333333334, 1.0, 2.0, 0.2239179457146784, 1.0, 1.0, 0.2239179457146784, 1.0, 2.0, 0.3564846620761441, 6.9112, 6.9112, 121.94756008, 765593.1976205619, 765593.1976205619, 228567.0589956852], 
processed observation next is [1.0, 0.8260869565217391, 0.5432098765432101, 0.8233333333333335, 1.0, 1.0, 0.07609279251747429, 1.0, 0.5, 0.07609279251747429, 1.0, 1.0, 0.1956058275951801, 0.0, 0.0, 0.8096049824067558, 0.27342614200734355, 0.27342614200734355, 0.43955203653016384], 
reward next is 0.5604, 
noisyNet noise sample is [array([0.4536091], dtype=float32), -0.049551222]. 
=============================================
[2019-03-23 03:00:43,291] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 6.7345636e-38 2.2267276e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 03:00:43,295] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6883
[2019-03-23 03:00:43,300] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 772632.6217130723 W.
[2019-03-23 03:00:43,303] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 89.83333333333334, 1.0, 2.0, 0.3389636311905043, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5396411401300588, 6.9112, 6.9112, 121.9260426156618, 772632.6217130723, 772632.6217130723, 206013.6873230548], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4741800.0000, 
sim time next is 4742400.0000, 
raw observation next is [25.66666666666667, 90.66666666666667, 1.0, 2.0, 0.6756232100291595, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 770005.3779618301, 770005.3779618297, 171579.8648507708], 
processed observation next is [1.0, 0.9130434782608695, 0.506172839506173, 0.9066666666666667, 1.0, 1.0, 0.6138371547966184, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2750019207006536, 0.27500192070065343, 0.3299612785591746], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5662542], dtype=float32), 0.21874726]. 
=============================================
[2019-03-23 03:00:44,223] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4565133e-07 0.0000000e+00 0.0000000e+00 9.9999988e-01 0.0000000e+00], sum to 1.0000
[2019-03-23 03:00:44,230] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0860
[2019-03-23 03:00:44,237] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.5500799137273574, 1.0, 1.0, 0.5500799137273574, 1.0, 2.0, 0.8757451375060421, 6.911200000000001, 6.9112, 121.94756008, 1882083.997819598, 1882083.997819598, 368848.2211674435], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4807200.0000, 
sim time next is 4807800.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.874998990143254, 1.0, 2.0, 0.874998990143254, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1995984.906003669, 1995984.906003669, 375720.5847628284], 
processed observation next is [1.0, 0.6521739130434783, 0.5555555555555556, 0.89, 1.0, 1.0, 0.8511892739800643, 1.0, 1.0, 0.8511892739800643, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7128517521441675, 0.7128517521441675, 0.7225395860823624], 
reward next is 0.2775, 
noisyNet noise sample is [array([0.10501767], dtype=float32), 2.1129737]. 
=============================================
[2019-03-23 03:00:44,376] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:00:44,384] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8284
[2019-03-23 03:00:44,392] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 880605.961606524 W.
[2019-03-23 03:00:44,398] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.8, 81.0, 1.0, 2.0, 0.3863056944165255, 1.0, 2.0, 0.3863056944165255, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 880605.961606524, 880605.9616065244, 202463.2332280537], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5428800.0000, 
sim time next is 5429400.0000, 
raw observation next is [28.71666666666667, 81.5, 1.0, 2.0, 0.2578453872714618, 1.0, 2.0, 0.2578453872714618, 1.0, 1.0, 0.4104982539741749, 6.9112, 6.9112, 121.94756008, 881660.5148990008, 881660.5148990008, 240424.5359775742], 
processed observation next is [1.0, 0.8695652173913043, 0.6191358024691359, 0.815, 1.0, 1.0, 0.11648260389459736, 1.0, 1.0, 0.11648260389459736, 1.0, 0.5, 0.2631228174677186, 0.0, 0.0, 0.8096049824067558, 0.3148787553210717, 0.3148787553210717, 0.4623548768799504], 
reward next is 0.5376, 
noisyNet noise sample is [array([-1.5970277], dtype=float32), -1.1367397]. 
=============================================
[2019-03-23 03:00:48,843] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:00:48,849] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3594
[2019-03-23 03:00:48,857] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 716035.2980224871 W.
[2019-03-23 03:00:48,863] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.3141452663996009, 1.0, 2.0, 0.3141452663996009, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716035.2980224871, 716035.2980224871, 183889.4927672613], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4766400.0000, 
sim time next is 4767000.0000, 
raw observation next is [23.91666666666667, 94.33333333333334, 1.0, 2.0, 0.272354210528741, 1.0, 2.0, 0.272354210528741, 1.0, 1.0, 0.4335967731191487, 6.911199999999999, 6.9112, 121.94756008, 931301.2229342705, 931301.222934271, 245691.5541577743], 
processed observation next is [1.0, 0.17391304347826086, 0.4413580246913582, 0.9433333333333335, 1.0, 1.0, 0.13375501253421546, 1.0, 1.0, 0.13375501253421546, 1.0, 0.5, 0.2919959663989358, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3326075796193823, 0.3326075796193825, 0.47248375799571984], 
reward next is 0.5275, 
noisyNet noise sample is [array([-0.1545562], dtype=float32), 0.3958867]. 
=============================================
[2019-03-23 03:00:48,875] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[32.93655 ]
 [33.26025 ]
 [33.879623]
 [34.28874 ]
 [34.11619 ]], R is [[31.98344421]
 [32.30997849]
 [32.63299942]
 [32.87520981]
 [32.5464592 ]].
[2019-03-23 03:01:00,998] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:01:01,006] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5188
[2019-03-23 03:01:01,014] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 742147.9466914404 W.
[2019-03-23 03:01:01,018] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.2, 90.33333333333334, 1.0, 2.0, 0.3255960927784332, 1.0, 2.0, 0.3255960927784332, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 742147.9466914404, 742147.9466914409, 186716.6085843891], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4995600.0000, 
sim time next is 4996200.0000, 
raw observation next is [25.0, 90.66666666666667, 1.0, 2.0, 0.3218144196498524, 1.0, 2.0, 0.3218144196498524, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 733524.0600815524, 733524.0600815524, 185777.9887691739], 
processed observation next is [1.0, 0.8260869565217391, 0.48148148148148145, 0.9066666666666667, 1.0, 1.0, 0.19263621386887192, 1.0, 1.0, 0.19263621386887192, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2619728786005544, 0.2619728786005544, 0.35726536301764217], 
reward next is 0.6427, 
noisyNet noise sample is [array([-0.86782086], dtype=float32), 0.6595671]. 
=============================================
[2019-03-23 03:01:01,169] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:01:01,177] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8772
[2019-03-23 03:01:01,184] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.16666666666667, 65.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9282749996464009, 6.911200000000001, 6.9112, 121.9260426156618, 675081.3223817138, 675081.3223817133, 180509.8826960902], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5761200.0000, 
sim time next is 5761800.0000, 
raw observation next is [28.2, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.936209461879219, 6.911199999999999, 6.9112, 121.9260426156618, 679828.8831369927, 679828.8831369932, 181753.0828517481], 
processed observation next is [0.0, 0.6956521739130435, 0.6, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9202618273490237, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2427960296917831, 0.24279602969178327, 0.34952515933028483], 
reward next is 0.6505, 
noisyNet noise sample is [array([-0.02749257], dtype=float32), -0.9128916]. 
=============================================
[2019-03-23 03:01:01,324] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.863853e-01 0.000000e+00 1.463153e-27 0.000000e+00 6.136146e-01], sum to 1.0000
[2019-03-23 03:01:01,330] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5121
[2019-03-23 03:01:01,335] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 99.00000000000001, 1.0, 2.0, 0.2152262506907347, 1.0, 2.0, 0.2152262506907347, 1.0, 2.0, 0.3426472005292809, 6.9112, 6.9112, 121.94756008, 735861.3418683785, 735861.3418683785, 225632.8973125162], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5001000.0000, 
sim time next is 5001600.0000, 
raw observation next is [24.0, 98.0, 1.0, 2.0, 0.21373918797913, 1.0, 2.0, 0.21373918797913, 1.0, 2.0, 0.3402797482621548, 6.911199999999999, 6.9112, 121.94756008, 730774.6320894859, 730774.6320894863, 225135.1252897934], 
processed observation next is [1.0, 0.9130434782608695, 0.4444444444444444, 0.98, 1.0, 1.0, 0.06397522378467857, 1.0, 1.0, 0.06397522378467857, 1.0, 1.0, 0.17534968532769346, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2609909400319592, 0.2609909400319594, 0.43295216401883346], 
reward next is 0.5670, 
noisyNet noise sample is [array([-0.42029896], dtype=float32), 0.63263667]. 
=============================================
[2019-03-23 03:01:02,462] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.9481896e-14], sum to 1.0000
[2019-03-23 03:01:02,468] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8377
[2019-03-23 03:01:02,475] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 802827.8376186099 W.
[2019-03-23 03:01:02,479] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.25, 74.0, 1.0, 2.0, 0.2348025000992047, 1.0, 1.0, 0.2348025000992047, 1.0, 2.0, 0.3738132271414984, 6.9112, 6.9112, 121.94756008, 802827.8376186099, 802827.8376186099, 232301.0728262529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5051400.0000, 
sim time next is 5052000.0000, 
raw observation next is [29.4, 75.0, 1.0, 2.0, 0.718106547828421, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818449.3378172131, 818449.3378172131, 179605.1735464117], 
processed observation next is [0.0, 0.4782608695652174, 0.6444444444444444, 0.75, 1.0, 1.0, 0.6644125569385964, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.292303334934719, 0.292303334934719, 0.3453945645123302], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5840801], dtype=float32), 2.2007382]. 
=============================================
[2019-03-23 03:01:02,489] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[52.6799  ]
 [52.459408]
 [51.755146]
 [51.125614]
 [50.75149 ]], R is [[51.94561386]
 [51.97942734]
 [52.05490875]
 [52.1296196 ]
 [52.20360947]].
[2019-03-23 03:01:06,030] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:01:06,039] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1963
[2019-03-23 03:01:06,044] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.33333333333334, 67.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9420628653297873, 6.911200000000001, 6.9112, 121.9260426156618, 678167.7190707006, 678167.7190707001, 183322.908710433], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5334600.0000, 
sim time next is 5335200.0000, 
raw observation next is [28.3, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9523513070840006, 6.911199999999999, 6.9112, 121.9260426156618, 685651.4561927243, 685651.4561927248, 184746.6268922829], 
processed observation next is [1.0, 0.782608695652174, 0.6037037037037037, 0.68, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9404391338550008, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2448755200688301, 0.24487552006883026, 0.35528197479285173], 
reward next is 0.6447, 
noisyNet noise sample is [array([0.84143525], dtype=float32), 0.40541628]. 
=============================================
[2019-03-23 03:01:09,960] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9999988e-01 0.0000000e+00 3.7695165e-29 1.9278085e-29 1.4182484e-07], sum to 1.0000
[2019-03-23 03:01:09,967] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9382
[2019-03-23 03:01:09,973] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1947524.224541463 W.
[2019-03-23 03:01:09,980] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.26666666666667, 81.33333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.046674608896017, 6.9112, 121.9253847066984, 1947524.224541463, 1878149.49054939, 383650.2553853303], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5409600.0000, 
sim time next is 5410200.0000, 
raw observation next is [28.13333333333333, 82.66666666666666, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.239166506719615, 6.9112, 121.9245384727302, 2046199.248577983, 1878253.155719512, 382960.679440769], 
processed observation next is [1.0, 0.6086956521739131, 0.5975308641975308, 0.8266666666666665, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.03279665067196147, 0.0, 0.8094521428752686, 0.7307854459207082, 0.6708046984712542, 0.736462845078402], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.69403714], dtype=float32), -1.4470465]. 
=============================================
[2019-03-23 03:01:11,314] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2997963e-14 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 03:01:11,325] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2514
[2019-03-23 03:01:11,331] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.33333333333334, 87.33333333333334, 1.0, 2.0, 0.2160493075026693, 1.0, 2.0, 0.2160493075026693, 1.0, 2.0, 0.3439575337789697, 6.9112, 6.9112, 121.94756008, 738676.7394148273, 738676.7394148273, 225908.9351877877], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5178000.0000, 
sim time next is 5178600.0000, 
raw observation next is [25.2, 87.5, 1.0, 2.0, 0.2147504352577598, 1.0, 2.0, 0.2147504352577598, 1.0, 2.0, 0.3418896868637581, 6.911200000000001, 6.9112, 121.94756008, 734233.743746914, 734233.7437469135, 225473.4905967478], 
processed observation next is [0.0, 0.9565217391304348, 0.4888888888888889, 0.875, 1.0, 1.0, 0.0651790895925712, 1.0, 1.0, 0.0651790895925712, 1.0, 1.0, 0.17736210857969759, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2622263370524693, 0.2622263370524691, 0.4336028665322073], 
reward next is 0.5664, 
noisyNet noise sample is [array([0.7560154], dtype=float32), -0.4375034]. 
=============================================
[2019-03-23 03:01:11,813] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 03:01:11,816] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:01:11,817] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:01:11,818] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:01:11,819] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:01:11,820] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:01:11,821] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:01:11,823] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:01:11,823] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:01:11,819] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:01:11,823] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:01:11,844] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run83
[2019-03-23 03:01:11,878] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run83
[2019-03-23 03:01:11,903] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run83
[2019-03-23 03:01:11,905] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run83
[2019-03-23 03:01:11,906] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run83
[2019-03-23 03:01:24,744] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.39037865], dtype=float32), -0.018658511]
[2019-03-23 03:01:24,745] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.93333333333333, 36.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7303162020547906, 6.911200000000001, 6.9112, 121.9260426156618, 545137.7748510197, 545137.7748510193, 149897.1512503247]
[2019-03-23 03:01:24,747] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:01:24,751] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9735757157174073
[2019-03-23 03:01:42,416] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.39037865], dtype=float32), -0.018658511]
[2019-03-23 03:01:42,416] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5342260020068992, 6.911200000000001, 6.9112, 121.9260426156618, 391863.1051914039, 391863.1051914035, 121745.1500512282]
[2019-03-23 03:01:42,417] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:01:42,420] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5116724126256158
[2019-03-23 03:01:49,427] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.39037865], dtype=float32), -0.018658511]
[2019-03-23 03:01:49,429] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.110742315, 50.806110345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6562932230230376, 6.9112, 6.9112, 121.9260426156618, 490157.2921077486, 490157.2921077486, 138942.8594059513]
[2019-03-23 03:01:49,432] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:01:49,434] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.14352054500727685
[2019-03-23 03:02:08,469] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.39037865], dtype=float32), -0.018658511]
[2019-03-23 03:02:08,471] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.55163234333333, 72.65213963333332, 1.0, 2.0, 0.2642388137194413, 1.0, 2.0, 0.2642388137194413, 1.0, 2.0, 0.4206767970987212, 6.9112, 6.9112, 121.94756008, 903534.6849628545, 903534.6849628545, 242731.0084999099]
[2019-03-23 03:02:08,473] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:02:08,479] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.699801e-10 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00], sampled 0.03218689559522614
[2019-03-23 03:02:52,239] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.39037865], dtype=float32), -0.018658511]
[2019-03-23 03:02:52,241] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.93333333333334, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8640161155936301, 6.9112, 6.9112, 121.9260426156618, 645433.9186486356, 645433.9186486356, 162448.9403088439]
[2019-03-23 03:02:52,245] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:02:52,246] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5361361451540178
[2019-03-23 03:02:57,173] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.39037865], dtype=float32), -0.018658511]
[2019-03-23 03:02:57,174] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.66666666666667, 37.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7422241145644807, 6.911199999999999, 6.9112, 121.9260426156618, 541528.3205548862, 541528.3205548867, 139824.3201941749]
[2019-03-23 03:02:57,176] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:02:57,178] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4967188152212493
[2019-03-23 03:03:04,097] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7868.5753 2664426680.1268 332.0000
[2019-03-23 03:03:04,151] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8279.4563 2469855648.1027 253.0000
[2019-03-23 03:03:04,155] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8425.6645 2369921856.9792 269.0000
[2019-03-23 03:03:04,253] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8396.7565 2418919030.2407 251.0000
[2019-03-23 03:03:04,259] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8290.7706 2429026540.7062 302.0000
[2019-03-23 03:03:05,277] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2050000, evaluation results [2050000.0, 7868.5752651565745, 2664426680.1267867, 332.0, 8396.756523839325, 2418919030.2406554, 251.0, 8425.664477209755, 2369921856.979153, 269.0, 8279.45628788859, 2469855648.102728, 253.0, 8290.770590591426, 2429026540.7062116, 302.0]
[2019-03-23 03:03:06,850] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 5.1164327e-38 0.0000000e+00 0.0000000e+00 3.2244993e-20], sum to 1.0000
[2019-03-23 03:03:06,857] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7687
[2019-03-23 03:03:06,866] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1419728.294020973 W.
[2019-03-23 03:03:06,871] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.3, 78.5, 1.0, 2.0, 0.6191560417358725, 1.0, 2.0, 0.6191560417358725, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1419728.294020973, 1419728.294020973, 275083.0877520431], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5311800.0000, 
sim time next is 5312400.0000, 
raw observation next is [25.5, 77.33333333333334, 1.0, 2.0, 0.3840391041681869, 1.0, 2.0, 0.3840391041681869, 1.0, 1.0, 0.6114027611161975, 6.911199999999999, 6.9112, 121.94756008, 1313529.290826116, 1313529.290826117, 290160.9860708953], 
processed observation next is [1.0, 0.4782608695652174, 0.5, 0.7733333333333334, 1.0, 1.0, 0.2667132192478415, 1.0, 1.0, 0.2667132192478415, 1.0, 0.5, 0.5142534513952468, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.46911760386647, 0.46911760386647033, 0.5580018962901833], 
reward next is 0.4420, 
noisyNet noise sample is [array([0.07898518], dtype=float32), 0.5835995]. 
=============================================
[2019-03-23 03:03:10,420] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8080931e-01 3.8496001e-28 2.2099857e-17 7.1919066e-01 9.3920522e-22], sum to 1.0000
[2019-03-23 03:03:10,426] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7852
[2019-03-23 03:03:10,432] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.7, 76.16666666666666, 1.0, 2.0, 0.3801118275594695, 1.0, 2.0, 0.3801118275594695, 1.0, 2.0, 0.6051504088526497, 6.911199999999999, 6.9112, 121.94756008, 1300085.42567836, 1300085.425678361, 288479.6524266945], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5313000.0000, 
sim time next is 5313600.0000, 
raw observation next is [25.9, 75.0, 1.0, 2.0, 0.6255577858757136, 1.0, 2.0, 0.6255577858757136, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1430342.81315129, 1430342.81315129, 277136.2695332171], 
processed observation next is [1.0, 0.5217391304347826, 0.5148148148148147, 0.75, 1.0, 1.0, 0.5542354593758496, 1.0, 1.0, 0.5542354593758496, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5108367189826035, 0.5108367189826035, 0.532954364486956], 
reward next is 0.4670, 
noisyNet noise sample is [array([-0.22272106], dtype=float32), 0.0922427]. 
=============================================
[2019-03-23 03:03:13,077] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0. 0. 0. 0. 1.], sum to 1.0000
[2019-03-23 03:03:13,084] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0735
[2019-03-23 03:03:13,088] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.9, 73.0, 1.0, 2.0, 0.1821279070124313, 1.0, 2.0, 0.1821279070124313, 1.0, 2.0, 0.2904313089131613, 6.9112, 6.9112, 121.94756008, 632610.0075821747, 632610.0075821747, 214822.8307559529], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6130800.0000, 
sim time next is 6131400.0000, 
raw observation next is [25.76666666666667, 73.83333333333334, 1.0, 2.0, 0.1819160539624582, 1.0, 2.0, 0.1819160539624582, 1.0, 2.0, 0.2900986290162353, 6.9112, 6.9112, 121.94756008, 631940.0872538595, 631940.0872538595, 214755.0799005356], 
processed observation next is [1.0, 1.0, 0.5098765432098766, 0.7383333333333334, 1.0, 1.0, 0.026090540431497843, 1.0, 1.0, 0.026090540431497843, 1.0, 1.0, 0.1126232862702941, 0.0, 0.0, 0.8096049824067558, 0.22569288830494982, 0.22569288830494982, 0.4129905382702608], 
reward next is 0.5870, 
noisyNet noise sample is [array([-0.33620864], dtype=float32), -0.076908216]. 
=============================================
[2019-03-23 03:03:14,684] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 5.385279e-32 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 03:03:14,695] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8914
[2019-03-23 03:03:14,708] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 780619.5006247599 W.
[2019-03-23 03:03:14,714] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.3, 91.5, 1.0, 2.0, 0.2283105484428002, 1.0, 1.0, 0.2283105484428002, 1.0, 1.0, 0.3634778286763975, 6.911199999999999, 6.9112, 121.94756008, 780619.5006247599, 780619.5006247604, 230065.9963235656], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5549400.0000, 
sim time next is 5550000.0000, 
raw observation next is [25.3, 91.0, 1.0, 2.0, 0.3366786172301332, 1.0, 2.0, 0.3366786172301332, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 767421.560839516, 767421.5608395165, 189495.6423873509], 
processed observation next is [1.0, 0.21739130434782608, 0.49259259259259264, 0.91, 1.0, 1.0, 0.21033168717873002, 1.0, 1.0, 0.21033168717873002, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27407912887125574, 0.2740791288712559, 0.3644146968987517], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1504261], dtype=float32), 0.5987465]. 
=============================================
[2019-03-23 03:03:14,723] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[34.984486]
 [34.31284 ]
 [34.237965]
 [34.325706]
 [34.48853 ]], R is [[34.25518036]
 [33.91262817]
 [34.2389679 ]
 [34.5170517 ]
 [34.79390335]].
[2019-03-23 03:03:17,907] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4373864e-15 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 03:03:17,915] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3504
[2019-03-23 03:03:17,918] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.2, 86.0, 1.0, 2.0, 0.2225758725124802, 1.0, 2.0, 0.2225758725124802, 1.0, 2.0, 0.3543480378299718, 6.9112, 6.9112, 121.94756008, 761002.2655861612, 761002.2655861612, 228111.2402867062], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5521200.0000, 
sim time next is 5521800.0000, 
raw observation next is [26.15, 86.5, 1.0, 2.0, 0.2232651220804078, 1.0, 2.0, 0.2232651220804078, 1.0, 2.0, 0.3554453455894038, 6.9112, 6.9112, 121.94756008, 763360.0306524036, 763360.0306524036, 228345.2096248164], 
processed observation next is [1.0, 0.9130434782608695, 0.524074074074074, 0.865, 1.0, 1.0, 0.075315621524295, 1.0, 1.0, 0.075315621524295, 1.0, 1.0, 0.19430668198675477, 0.0, 0.0, 0.8096049824067558, 0.2726285823758584, 0.2726285823758584, 0.43912540312464693], 
reward next is 0.5609, 
noisyNet noise sample is [array([-0.4105571], dtype=float32), 0.92393076]. 
=============================================
[2019-03-23 03:03:23,554] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:03:23,560] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3637
[2019-03-23 03:03:23,569] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 848397.8227705923 W.
[2019-03-23 03:03:23,576] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.9, 72.0, 1.0, 2.0, 0.3721843901940359, 1.0, 2.0, 0.3721843901940359, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 848397.8227705923, 848397.8227705928, 198686.6213776428], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5680800.0000, 
sim time next is 5681400.0000, 
raw observation next is [29.73333333333333, 73.0, 1.0, 2.0, 0.3671791134435549, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5845611067910196, 6.911199999999999, 6.9112, 121.9260426156618, 836982.0173983827, 836982.017398383, 214193.0272813767], 
processed observation next is [0.0, 0.782608695652174, 0.65679012345679, 0.73, 1.0, 1.0, 0.24664180171851777, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.48070138348877445, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29892214907085096, 0.2989221490708511, 0.41190966784880134], 
reward next is 0.5881, 
noisyNet noise sample is [array([1.2249691], dtype=float32), -0.75033844]. 
=============================================
[2019-03-23 03:03:30,043] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:03:30,050] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3143
[2019-03-23 03:03:30,058] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 858244.6265609927 W.
[2019-03-23 03:03:30,066] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.73333333333333, 79.33333333333333, 1.0, 2.0, 0.2510011421129291, 1.0, 2.0, 0.2510011421129291, 1.0, 2.0, 0.3996019927802877, 6.911200000000001, 6.9112, 121.94756008, 858244.6265609927, 858244.6265609922, 237980.7217190331], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5685000.0000, 
sim time next is 5685600.0000, 
raw observation next is [28.56666666666667, 80.66666666666667, 1.0, 2.0, 0.2519729180573416, 1.0, 2.0, 0.2519729180573416, 1.0, 2.0, 0.4011490917323253, 6.9112, 6.9112, 121.94756008, 861569.2735125348, 861569.2735125348, 238326.1116649531], 
processed observation next is [0.0, 0.8260869565217391, 0.6135802469135804, 0.8066666666666668, 1.0, 1.0, 0.10949156911588288, 1.0, 1.0, 0.10949156911588288, 1.0, 1.0, 0.25143636466540664, 0.0, 0.0, 0.8096049824067558, 0.30770331196876244, 0.30770331196876244, 0.4583194455095252], 
reward next is 0.5417, 
noisyNet noise sample is [array([1.141174], dtype=float32), -0.10723782]. 
=============================================
[2019-03-23 03:03:42,284] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 7.2958669e-16 1.1028745e-29], sum to 1.0000
[2019-03-23 03:03:42,294] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8481
[2019-03-23 03:03:42,303] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1341446.462368981 W.
[2019-03-23 03:03:42,312] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.56666666666667, 82.66666666666667, 1.0, 1.0, 0.3909214777614029, 1.0, 1.0, 0.3909214777614029, 1.0, 2.0, 0.6224692909038205, 6.9112, 6.9112, 121.94756008, 1341446.462368981, 1341446.462368981, 293156.5028748183], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6164400.0000, 
sim time next is 6165000.0000, 
raw observation next is [24.75, 81.5, 1.0, 2.0, 0.6073331294902639, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9679127755817931, 6.9112, 6.9112, 121.9260424750569, 1401592.041779093, 1401592.041779093, 296474.5916851063], 
processed observation next is [1.0, 0.34782608695652173, 0.4722222222222222, 0.815, 1.0, 1.0, 0.5325394398693617, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9598909694772414, 0.0, 0.0, 0.8094621278866656, 0.500568586349676, 0.500568586349676, 0.5701434455482813], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.24633032], dtype=float32), 2.2949576]. 
=============================================
[2019-03-23 03:03:42,339] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[54.47091 ]
 [63.052402]
 [63.87101 ]
 [62.719048]
 [60.554398]], R is [[49.33953857]
 [49.28237915]
 [48.7895546 ]
 [48.96126938]
 [49.13505554]].
[2019-03-23 03:03:46,025] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:03:46,031] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0062
[2019-03-23 03:03:46,035] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.4, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9084491633511532, 6.9112, 6.9112, 121.9260426156618, 664742.6879426183, 664742.6879426183, 177093.0737671663], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6328800.0000, 
sim time next is 6329400.0000, 
raw observation next is [24.46666666666667, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9136168126468145, 6.911200000000001, 6.9112, 121.9260426156618, 667934.2820802875, 667934.282080287, 177902.4512983353], 
processed observation next is [0.0, 0.2608695652173913, 0.46172839506172847, 0.87, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8920210158085181, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23854795788581695, 0.23854795788581679, 0.3421200986506448], 
reward next is 0.6579, 
noisyNet noise sample is [array([-1.1178067], dtype=float32), -0.9411181]. 
=============================================
[2019-03-23 03:03:50,359] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:03:50,371] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1907
[2019-03-23 03:03:50,378] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.7, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9059703233818636, 6.9112, 6.9112, 121.9260426156618, 663858.251045723, 663858.251045723, 176568.1779353226], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6307200.0000, 
sim time next is 6307800.0000, 
raw observation next is [24.66666666666666, 84.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9059774085352122, 6.9112, 6.9112, 121.9260426156618, 663814.5876128008, 663814.5876128008, 176579.6030150471], 
processed observation next is [0.0, 0.0, 0.4691358024691356, 0.8433333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8824717606690152, 0.0, 0.0, 0.8094621288201359, 0.23707663843314314, 0.23707663843314314, 0.3395761596443213], 
reward next is 0.6604, 
noisyNet noise sample is [array([0.14186579], dtype=float32), -0.28789327]. 
=============================================
[2019-03-23 03:03:50,918] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:03:50,932] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1021
[2019-03-23 03:03:50,939] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.93333333333334, 83.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.835695070802024, 6.911199999999999, 6.9112, 121.9260426156618, 618765.0352844838, 618765.0352844843, 165622.7292101535], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6070800.0000, 
sim time next is 6071400.0000, 
raw observation next is [24.0, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.822981314423022, 6.911199999999999, 6.9112, 121.9260426156618, 609231.5549521815, 609231.554952182, 164089.3181420472], 
processed observation next is [1.0, 0.2608695652173913, 0.4444444444444444, 0.83, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7787266430287776, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21758269819720769, 0.21758269819720785, 0.31555638104239847], 
reward next is 0.6844, 
noisyNet noise sample is [array([1.9807162], dtype=float32), -0.5190861]. 
=============================================
[2019-03-23 03:03:52,479] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.5063915e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 03:03:52,486] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3412
[2019-03-23 03:03:52,494] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 698253.3441111617 W.
[2019-03-23 03:03:52,498] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.25, 87.0, 1.0, 2.0, 0.5871081358251502, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425523097, 698253.3441111617, 698253.3441111617, 157171.6005541663], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6064200.0000, 
sim time next is 6064800.0000, 
raw observation next is [23.3, 86.66666666666666, 1.0, 2.0, 0.2929256924763131, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4696468672690908, 6.9112, 6.9112, 121.9260426156425, 692289.5879067996, 692289.5879067996, 192609.4302851815], 
processed observation next is [1.0, 0.17391304347826086, 0.41851851851851857, 0.8666666666666666, 1.0, 1.0, 0.15824487199561085, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.3370585840863634, 0.0, 0.0, 0.8094621288200078, 0.2472462813952856, 0.2472462813952856, 0.370402750548426], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.1932585], dtype=float32), 0.93762803]. 
=============================================
[2019-03-23 03:03:54,415] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 03:03:54,417] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:03:54,418] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:03:54,418] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:03:54,419] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:03:54,421] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:03:54,422] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:03:54,423] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:03:54,424] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:03:54,425] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:03:54,425] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:03:54,448] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run84
[2019-03-23 03:03:54,479] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run84
[2019-03-23 03:03:54,480] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run84
[2019-03-23 03:03:54,481] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run84
[2019-03-23 03:03:54,540] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run84
[2019-03-23 03:04:04,402] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.4279668], dtype=float32), 0.026554404]
[2019-03-23 03:04:04,403] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.570115165, 62.90126504000001, 1.0, 2.0, 0.5885708070626756, 1.0, 2.0, 0.5885708070626756, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1418763.521450038, 1418763.521450038, 267422.4429719604]
[2019-03-23 03:04:04,405] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:04:04,410] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.4187887e-16 1.1432973e-27], sampled 0.05401527677665685
[2019-03-23 03:04:04,411] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1418763.521450038 W.
[2019-03-23 03:04:27,508] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.4279668], dtype=float32), 0.026554404]
[2019-03-23 03:04:27,510] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.15, 96.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.828142229109314, 6.9112, 6.9112, 121.9260426156618, 617637.9175474164, 617637.9175474164, 162153.1777733606]
[2019-03-23 03:04:27,512] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:04:27,514] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.2796260227985844
[2019-03-23 03:05:02,746] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.4279668], dtype=float32), 0.026554404]
[2019-03-23 03:05:02,747] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8820609029906682, 6.911200000000001, 6.9112, 121.9260426156618, 646557.1789136587, 646557.1789136583, 173360.5981293329]
[2019-03-23 03:05:02,749] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:05:02,751] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.23059404689338436
[2019-03-23 03:05:11,974] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.4279668], dtype=float32), 0.026554404]
[2019-03-23 03:05:11,975] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.97077904, 94.01418573166666, 1.0, 2.0, 0.619453692168267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 711967.290965634, 711967.290965634, 161750.9052415563]
[2019-03-23 03:05:11,977] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:05:11,979] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 8.974124e-19], sampled 0.5284002300766046
[2019-03-23 03:05:11,983] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 711967.290965634 W.
[2019-03-23 03:05:46,613] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8433.7713 2292207170.6942 560.0000
[2019-03-23 03:05:46,630] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8396.7382 2328734575.1812 502.0000
[2019-03-23 03:05:46,652] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7898.0552 2516733914.1504 650.0000
[2019-03-23 03:05:46,707] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8589.7704 2257713721.0489 447.0000
[2019-03-23 03:05:46,737] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8648.6020 2223098607.4435 456.0000
[2019-03-23 03:05:47,752] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 2075000, evaluation results [2075000.0, 7898.055164947388, 2516733914.1504416, 650.0, 8589.770358136042, 2257713721.0488763, 447.0, 8648.601958236031, 2223098607.4435425, 456.0, 8396.738199603573, 2328734575.181227, 502.0, 8433.771344821533, 2292207170.694196, 560.0]
[2019-03-23 03:05:48,012] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:05:48,019] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2187
[2019-03-23 03:05:48,023] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.33333333333333, 69.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8554217909555516, 6.911200000000001, 6.9112, 121.9260426156618, 631304.4438086707, 631304.4438086703, 168802.7426589312], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6213000.0000, 
sim time next is 6213600.0000, 
raw observation next is [26.2, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8550634269725675, 6.9112, 6.9112, 121.9260426156618, 631375.388271421, 631375.388271421, 168652.7518019361], 
processed observation next is [1.0, 0.9565217391304348, 0.5259259259259259, 0.7, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8188292837157093, 0.0, 0.0, 0.8094621288201359, 0.22549121009693607, 0.22549121009693607, 0.3243322150037233], 
reward next is 0.6757, 
noisyNet noise sample is [array([-0.1290068], dtype=float32), 0.6612448]. 
=============================================
[2019-03-23 03:05:49,731] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:05:49,743] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5403
[2019-03-23 03:05:49,751] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1118589.692818593 W.
[2019-03-23 03:05:49,754] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 91.0, 1.0, 2.0, 0.3270858098191015, 1.0, 2.0, 0.3270858098191015, 1.0, 2.0, 0.5207312616731498, 6.911200000000001, 6.9112, 121.94756008, 1118589.692818593, 1118589.692818593, 266616.825614411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6408000.0000, 
sim time next is 6408600.0000, 
raw observation next is [24.95, 91.16666666666667, 1.0, 2.0, 0.9809526377141305, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.027309313663674, 6.9112, 121.9255057483094, 1177743.615022919, 1118285.530502682, 236156.6458135014], 
processed observation next is [1.0, 0.17391304347826086, 0.47962962962962963, 0.9116666666666667, 1.0, 1.0, 0.9773245687072982, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.011610931366367438, 0.0, 0.8094585645792187, 0.4206227196510425, 0.3993876894652436, 0.45414739579519503], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.42334464], dtype=float32), 0.5543601]. 
=============================================
[2019-03-23 03:05:52,313] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:05:52,319] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0691
[2019-03-23 03:05:52,330] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 764044.2878544505 W.
[2019-03-23 03:05:52,333] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 57.66666666666667, 1.0, 2.0, 0.2234651517830822, 1.0, 2.0, 0.2234651517830822, 1.0, 1.0, 0.3557637993905741, 6.911199999999999, 6.9112, 121.94756008, 764044.2878544505, 764044.287854451, 228413.1604878194], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6358800.0000, 
sim time next is 6359400.0000, 
raw observation next is [31.55, 57.5, 1.0, 2.0, 0.6713178440852237, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 765096.1187791338, 765096.1187791338, 170785.8426596292], 
processed observation next is [0.0, 0.6086956521739131, 0.7240740740740741, 0.575, 1.0, 1.0, 0.6087117191490757, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2732486138496906, 0.2732486138496906, 0.32843431280697927], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0515505], dtype=float32), 0.7084988]. 
=============================================
[2019-03-23 03:05:54,030] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:05:54,036] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2391
[2019-03-23 03:05:54,041] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.6, 48.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7304469585864024, 6.911200000000001, 6.9112, 121.9260426156618, 540539.7301076353, 540539.7301076348, 142351.791292244], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6580200.0000, 
sim time next is 6580800.0000, 
raw observation next is [25.6, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6890578064508145, 6.9112, 6.9112, 121.9260426156618, 509590.2867997358, 509590.2867997358, 137930.3322587004], 
processed observation next is [1.0, 0.17391304347826086, 0.5037037037037038, 0.48, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.611322258063518, 0.0, 0.0, 0.8094621288201359, 0.18199653099990565, 0.18199653099990565, 0.2652506389590392], 
reward next is 0.7347, 
noisyNet noise sample is [array([-1.5411377], dtype=float32), 0.13234383]. 
=============================================
[2019-03-23 03:05:58,110] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.7216653e-28 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 03:05:58,118] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1488
[2019-03-23 03:05:58,123] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.43333333333333, 85.0, 1.0, 2.0, 0.2064518391625463, 1.0, 1.0, 0.2064518391625463, 1.0, 1.0, 0.3286780516137717, 6.9112, 6.9112, 121.94756008, 705847.7055781772, 705847.7055781772, 222713.6846718451], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6336600.0000, 
sim time next is 6337200.0000, 
raw observation next is [25.66666666666667, 84.0, 1.0, 2.0, 0.2077610630041877, 1.0, 2.0, 0.2077610630041877, 1.0, 2.0, 0.3307623786081085, 6.911199999999999, 6.9112, 121.94756008, 710325.9447991407, 710325.9447991411, 223146.5235317585], 
processed observation next is [0.0, 0.34782608695652173, 0.506172839506173, 0.84, 1.0, 1.0, 0.05685840833831869, 1.0, 1.0, 0.05685840833831869, 1.0, 1.0, 0.16345297326013558, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2536878374282645, 0.2536878374282647, 0.4291279298687663], 
reward next is 0.5709, 
noisyNet noise sample is [array([0.2330261], dtype=float32), 0.4932393]. 
=============================================
[2019-03-23 03:05:58,515] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:05:58,525] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3484
[2019-03-23 03:05:58,531] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.6, 49.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7825377912291367, 6.9112, 6.9112, 121.9260426156618, 580078.5884446373, 580078.5884446373, 148505.2529536964], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6578400.0000, 
sim time next is 6579000.0000, 
raw observation next is [25.6, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8239602009155629, 6.9112, 6.9112, 121.9260426156618, 610469.1675760496, 610469.1675760496, 152901.1953831404], 
processed observation next is [1.0, 0.13043478260869565, 0.5037037037037038, 0.49, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7799502511444536, 0.0, 0.0, 0.8094621288201359, 0.218024702705732, 0.218024702705732, 0.2940407603521931], 
reward next is 0.7060, 
noisyNet noise sample is [array([-0.1543089], dtype=float32), 1.1999369]. 
=============================================
[2019-03-23 03:05:58,549] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[61.174797]
 [60.2281  ]
 [59.343765]
 [58.46083 ]
 [57.038643]], R is [[61.51833725]
 [61.61756897]
 [61.70656204]
 [61.81415558]
 [61.92296219]].
[2019-03-23 03:05:58,882] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0697925e-34], sum to 1.0000
[2019-03-23 03:05:58,891] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9576
[2019-03-23 03:05:58,896] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.18333333333333, 88.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9101113262514275, 6.9112, 6.9112, 121.9260426156618, 666527.6851197616, 666527.6851197616, 177198.2763400695], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6318600.0000, 
sim time next is 6319200.0000, 
raw observation next is [24.16666666666667, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9077089852243281, 6.911200000000001, 6.9112, 121.9260426156618, 664930.0563520615, 664930.0563520611, 176843.1665385218], 
processed observation next is [0.0, 0.13043478260869565, 0.45061728395061745, 0.88, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8846362315304102, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23747502012573624, 0.2374750201257361, 0.34008301257408036], 
reward next is 0.6599, 
noisyNet noise sample is [array([-1.0148621], dtype=float32), -1.022463]. 
=============================================
[2019-03-23 03:06:06,986] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:06:06,994] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9087
[2019-03-23 03:06:06,999] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.86666666666667, 49.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6093021351811286, 6.9112, 6.9112, 121.9260426156618, 448491.2238487536, 448491.2238487536, 129065.5517129291], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6590400.0000, 
sim time next is 6591000.0000, 
raw observation next is [24.78333333333333, 49.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6024642982360379, 6.9112, 6.9112, 121.9260426156618, 443377.477635954, 443377.477635954, 128399.9030705725], 
processed observation next is [1.0, 0.2608695652173913, 0.4734567901234567, 0.4966666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5030803727950472, 0.0, 0.0, 0.8094621288201359, 0.15834909915569786, 0.15834909915569786, 0.24692289052033173], 
reward next is 0.7531, 
noisyNet noise sample is [array([1.2269285], dtype=float32), 0.36883634]. 
=============================================
[2019-03-23 03:06:07,014] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[78.1477  ]
 [77.72858 ]
 [77.612175]
 [77.34171 ]
 [77.44703 ]], R is [[78.25024414]
 [78.21954346]
 [78.1861496 ]
 [78.15270996]
 [78.10964966]].
[2019-03-23 03:06:16,889] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4073796e-35], sum to 1.0000
[2019-03-23 03:06:16,900] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7310
[2019-03-23 03:06:16,908] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.06666666666667, 70.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7725567110176941, 6.9112, 6.9112, 121.9260426156618, 575316.5880734173, 575316.5880734173, 156085.1809238354], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6945000.0000, 
sim time next is 6945600.0000, 
raw observation next is [25.33333333333334, 69.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7782059058292708, 6.9112, 6.9112, 121.9260426156618, 579256.8421304319, 579256.8421304319, 156947.1539185903], 
processed observation next is [0.0, 0.391304347826087, 0.49382716049382736, 0.6966666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7227573822865885, 0.0, 0.0, 0.8094621288201359, 0.2068774436180114, 0.2068774436180114, 0.3018214498434429], 
reward next is 0.6982, 
noisyNet noise sample is [array([-1.8773811], dtype=float32), -0.1143594]. 
=============================================
[2019-03-23 03:06:30,690] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:06:30,701] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9162
[2019-03-23 03:06:30,706] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.5, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7228708713927282, 6.9112, 6.9112, 121.9260426156618, 540128.8008461375, 540128.8008461375, 147936.8266605098], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6987600.0000, 
sim time next is 6988200.0000, 
raw observation next is [25.35, 62.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7224665410462296, 6.911199999999999, 6.9112, 121.9260426156618, 539840.9103484998, 539840.9103485002, 147829.6125289667], 
processed observation next is [0.0, 0.9130434782608695, 0.4944444444444445, 0.6266666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6530831763077871, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1928003251244642, 0.19280032512446438, 0.28428771640185907], 
reward next is 0.7157, 
noisyNet noise sample is [array([-0.3682286], dtype=float32), 0.65393054]. 
=============================================
[2019-03-23 03:06:36,466] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:06:36,473] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3087
[2019-03-23 03:06:36,478] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.16666666666667, 71.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6100182871502791, 6.9112, 6.9112, 121.9260426156618, 453553.2962301691, 453553.2962301691, 131904.5760027024], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7149000.0000, 
sim time next is 7149600.0000, 
raw observation next is [22.0, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6124259624183283, 6.911199999999999, 6.9112, 121.9260426156618, 455359.2047939844, 455359.2047939849, 132148.376330239], 
processed observation next is [1.0, 0.782608695652174, 0.37037037037037035, 0.73, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5155324530229103, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16262828742642302, 0.16262828742642318, 0.2541314929427673], 
reward next is 0.7459, 
noisyNet noise sample is [array([-0.5878183], dtype=float32), -0.21044831]. 
=============================================
[2019-03-23 03:06:37,028] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 03:06:37,030] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:06:37,031] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:06:37,033] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:06:37,034] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:06:37,035] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:06:37,035] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:06:37,036] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:06:37,036] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:06:37,035] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:06:37,046] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:06:37,062] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run85
[2019-03-23 03:06:37,090] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run85
[2019-03-23 03:06:37,117] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run85
[2019-03-23 03:06:37,146] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run85
[2019-03-23 03:06:37,173] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run85
[2019-03-23 03:07:34,694] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.49864274], dtype=float32), 0.043072436]
[2019-03-23 03:07:34,695] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.99233858, 88.34311335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.812440872200793, 6.911200000000001, 6.9112, 121.9260426156618, 606200.0305318602, 606200.0305318597, 159965.8765493064]
[2019-03-23 03:07:34,698] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:07:34,700] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7229869241154325
[2019-03-23 03:08:16,573] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.49864274], dtype=float32), 0.043072436]
[2019-03-23 03:08:16,574] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.63461675666667, 90.84071714333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8591006592162659, 6.911199999999999, 6.9112, 121.9260426156618, 632039.6704021848, 632039.6704021853, 169828.1824077932]
[2019-03-23 03:08:16,576] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:08:16,579] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4196387297366697
[2019-03-23 03:08:20,275] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.49864274], dtype=float32), 0.043072436]
[2019-03-23 03:08:20,276] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.0, 65.0, 1.0, 2.0, 0.9394325856661564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1091769.287094698, 1091769.287094698, 227560.5177345212]
[2019-03-23 03:08:20,278] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:08:20,282] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2208535e-06 0.0000000e+00 0.0000000e+00 5.2336274e-37 9.9999881e-01], sampled 0.7369647595710749
[2019-03-23 03:08:28,618] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8584.0850 2283422229.0733 373.0000
[2019-03-23 03:08:29,025] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8477.0428 2333802085.1971 381.0000
[2019-03-23 03:08:29,130] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8343.5616 2391032678.3452 390.0000
[2019-03-23 03:08:29,135] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8417.1904 2347511178.6834 414.0000
[2019-03-23 03:08:29,146] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7875.5991 2582104762.4991 520.0000
[2019-03-23 03:08:30,164] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 2100000, evaluation results [2100000.0, 7875.599148690342, 2582104762.49906, 520.0, 8477.042755288585, 2333802085.197081, 381.0, 8584.084998722466, 2283422229.073281, 373.0, 8343.561629582673, 2391032678.3452044, 390.0, 8417.190379814461, 2347511178.683444, 414.0]
[2019-03-23 03:08:30,614] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:08:30,621] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1164
[2019-03-23 03:08:30,625] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.8, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6086357897816972, 6.9112, 6.9112, 121.9260426156618, 452254.5932892781, 452254.5932892781, 131560.8086708155], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7167600.0000, 
sim time next is 7168200.0000, 
raw observation next is [19.8, 89.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6091083755893358, 6.911199999999999, 6.9112, 121.9260426156618, 452693.1203808878, 452693.1203808883, 131672.9734953427], 
processed observation next is [1.0, 1.0, 0.2888888888888889, 0.8933333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5113854694866697, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16167611442174565, 0.16167611442174581, 0.2532172567218129], 
reward next is 0.7468, 
noisyNet noise sample is [array([-0.7994918], dtype=float32), 0.37270346]. 
=============================================
[2019-03-23 03:08:34,523] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:08:34,523] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:08:34,588] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run11
[2019-03-23 03:08:35,852] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:08:35,860] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1590
[2019-03-23 03:08:35,864] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7125556077174383, 6.9112, 6.9112, 121.9260426156618, 532175.3883648764, 532175.3883648764, 147410.0793047195], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7532400.0000, 
sim time next is 7533000.0000, 
raw observation next is [20.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7118070302867981, 6.9112, 6.9112, 121.9260426156618, 531616.1355725428, 531616.1355725428, 147325.8768758198], 
processed observation next is [0.0, 0.17391304347826086, 0.32962962962962955, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6397587878584976, 0.0, 0.0, 0.8094621288201359, 0.1898629055616224, 0.1898629055616224, 0.2833189939919612], 
reward next is 0.7167, 
noisyNet noise sample is [array([-0.50457495], dtype=float32), -0.49923295]. 
=============================================
[2019-03-23 03:08:35,878] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[65.72199 ]
 [65.707115]
 [65.962166]
 [66.184074]
 [66.51085 ]], R is [[65.81781006]
 [65.87615204]
 [65.93371582]
 [65.9905777 ]
 [66.04690552]].
[2019-03-23 03:08:36,293] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2103279: loss 57.6245
[2019-03-23 03:08:36,296] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2103281: learning rate 0.0010
[2019-03-23 03:08:42,010] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 3.406584e-26 0.000000e+00], sum to 1.0000
[2019-03-23 03:08:42,017] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3719
[2019-03-23 03:08:42,026] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1327979.726282908 W.
[2019-03-23 03:08:42,030] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.13333333333333, 56.0, 1.0, 2.0, 0.5588359830184376, 1.0, 2.0, 0.5588359830184376, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1327979.726282908, 1327979.726282908, 256574.7676139259], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 121200.0000, 
sim time next is 121800.0000, 
raw observation next is [27.56666666666667, 54.5, 1.0, 2.0, 0.5698317594774099, 1.0, 2.0, 0.5698317594774099, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1351063.092261229, 1351063.09226123, 260153.1873621683], 
processed observation next is [1.0, 0.391304347826087, 0.5765432098765433, 0.545, 1.0, 1.0, 0.48789495175882136, 1.0, 1.0, 0.48789495175882136, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4825225329504389, 0.48252253295043934, 0.5002945910810929], 
reward next is 0.4997, 
noisyNet noise sample is [array([0.37068826], dtype=float32), 0.30659875]. 
=============================================
[2019-03-23 03:08:50,861] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.00000e+00 0.00000e+00 0.00000e+00 7.17572e-30 0.00000e+00], sum to 1.0000
[2019-03-23 03:08:50,864] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1256
[2019-03-23 03:08:50,873] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8782010928003052, 6.9112, 6.9112, 121.9260426156618, 642699.1485445413, 642699.1485445413, 173071.6552664675], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7561800.0000, 
sim time next is 7562400.0000, 
raw observation next is [27.33333333333333, 68.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8856115690876952, 6.911199999999999, 6.9112, 121.9260426156618, 647134.6803561307, 647134.6803561312, 174238.8673054833], 
processed observation next is [0.0, 0.5217391304347826, 0.5679012345679011, 0.6866666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8570144613596189, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2311195286986181, 0.23111952869861827, 0.3350747448182371], 
reward next is 0.6649, 
noisyNet noise sample is [array([-0.43335113], dtype=float32), 0.7260496]. 
=============================================
[2019-03-23 03:08:51,806] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2111262: loss 0.0043
[2019-03-23 03:08:51,808] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2111263: learning rate 0.0010
[2019-03-23 03:08:52,719] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:08:52,729] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3121
[2019-03-23 03:08:52,732] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7112867496182608, 6.911200000000001, 6.9112, 121.9260426156618, 531227.4441082298, 531227.4441082294, 147267.3788165992], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7533600.0000, 
sim time next is 7534200.0000, 
raw observation next is [20.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7109167920392201, 6.9112, 6.9112, 121.9260426156618, 530951.0567205758, 530951.0567205758, 147225.7970273613], 
processed observation next is [0.0, 0.17391304347826086, 0.32962962962962955, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6386459900490251, 0.0, 0.0, 0.8094621288201359, 0.18962537740020563, 0.18962537740020563, 0.28312653274492555], 
reward next is 0.7169, 
noisyNet noise sample is [array([0.39047572], dtype=float32), 0.26740384]. 
=============================================
[2019-03-23 03:08:57,615] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:08:57,625] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7864
[2019-03-23 03:08:57,629] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.93333333333334, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7259730273158881, 6.911200000000001, 6.9112, 121.9260426156618, 542240.0995821464, 542240.0995821459, 148849.2432781466], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7946400.0000, 
sim time next is 7947000.0000, 
raw observation next is [23.85, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7245773958085663, 6.9112, 6.9112, 121.9260426156618, 541205.5876885328, 541205.5876885328, 148673.9205865743], 
processed observation next is [1.0, 1.0, 0.43888888888888894, 0.735, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6557217447607078, 0.0, 0.0, 0.8094621288201359, 0.1932877098887617, 0.1932877098887617, 0.2859113857434121], 
reward next is 0.7141, 
noisyNet noise sample is [array([-1.3401623], dtype=float32), -0.5856701]. 
=============================================
[2019-03-23 03:08:57,639] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[72.0112 ]
 [72.04515]
 [72.11273]
 [72.10368]
 [72.09165]], R is [[71.98960876]
 [71.9834671 ]
 [71.97699738]
 [71.97016907]
 [71.96276855]].
[2019-03-23 03:08:58,757] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:08:58,758] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:08:58,806] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run11
[2019-03-23 03:09:00,453] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2115817: loss 29.1120
[2019-03-23 03:09:00,454] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2115817: learning rate 0.0010
[2019-03-23 03:09:02,707] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.6315163e-37 0.0000000e+00 0.0000000e+00 7.7072211e-27], sum to 1.0000
[2019-03-23 03:09:02,713] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5868
[2019-03-23 03:09:02,720] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 991383.7297553982 W.
[2019-03-23 03:09:02,728] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 44.66666666666666, 1.0, 2.0, 0.7899597584639011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 991383.7297553982, 991383.7297553982, 197343.2902931723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7809000.0000, 
sim time next is 7809600.0000, 
raw observation next is [26.9, 44.33333333333334, 1.0, 2.0, 0.7832070942507119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 981608.8916058941, 981608.8916058941, 195901.3850735618], 
processed observation next is [1.0, 0.391304347826087, 0.5518518518518518, 0.4433333333333334, 1.0, 1.0, 0.7419132074413237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.35057460414496217, 0.35057460414496217, 0.3767334328337727], 
reward next is 0.6233, 
noisyNet noise sample is [array([-1.4710051], dtype=float32), 1.7044954]. 
=============================================
[2019-03-23 03:09:03,019] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:09:03,020] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:03,083] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run11
[2019-03-23 03:09:03,885] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:09:03,885] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:03,931] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run11
[2019-03-23 03:09:04,650] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2118136: loss 25.8094
[2019-03-23 03:09:04,651] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2118136: learning rate 0.0010
[2019-03-23 03:09:05,618] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2118693: loss 22.4235
[2019-03-23 03:09:05,620] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2118694: learning rate 0.0010
[2019-03-23 03:09:06,078] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:09:06,079] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:06,098] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2118938: loss 0.0359
[2019-03-23 03:09:06,100] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2118939: learning rate 0.0010
[2019-03-23 03:09:06,148] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run11
[2019-03-23 03:09:06,677] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:09:06,682] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9394
[2019-03-23 03:09:06,685] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5978944581368648, 6.911200000000001, 6.9112, 121.9260426156618, 443374.1757696708, 443374.1757696703, 129900.1586456842], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7774200.0000, 
sim time next is 7774800.0000, 
raw observation next is [21.46666666666667, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5953752813900749, 6.911200000000001, 6.9112, 121.9260426156618, 441379.1841220652, 441379.1841220647, 129580.4906692986], 
processed observation next is [1.0, 1.0, 0.35061728395061736, 0.74, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4942191017375936, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15763542290073757, 0.15763542290073737, 0.2491932512871127], 
reward next is 0.7508, 
noisyNet noise sample is [array([-0.95545465], dtype=float32), -1.1479369]. 
=============================================
[2019-03-23 03:09:07,712] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2119934: loss 26.3469
[2019-03-23 03:09:07,716] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2119938: learning rate 0.0010
[2019-03-23 03:09:07,909] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:09:07,910] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:07,960] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run11
[2019-03-23 03:09:09,504] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:09:09,505] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:09,558] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run11
[2019-03-23 03:09:09,621] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2121037: loss 29.2131
[2019-03-23 03:09:09,625] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2121037: learning rate 0.0010
[2019-03-23 03:09:09,727] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:09:09,727] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:09,790] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run11
[2019-03-23 03:09:09,913] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:09:09,914] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:09,950] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run11
[2019-03-23 03:09:10,294] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:09:10,294] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:10,347] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run11
[2019-03-23 03:09:11,037] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2121867: loss 18.4365
[2019-03-23 03:09:11,043] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2121870: learning rate 0.0010
[2019-03-23 03:09:11,307] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2122036: loss 11.7912
[2019-03-23 03:09:11,308] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2122036: learning rate 0.0010
[2019-03-23 03:09:11,497] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2122149: loss 14.9408
[2019-03-23 03:09:11,498] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2122149: learning rate 0.0010
[2019-03-23 03:09:11,935] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:09:11,936] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:11,999] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run11
[2019-03-23 03:09:12,080] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2122407: loss 13.5628
[2019-03-23 03:09:12,082] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2122409: learning rate 0.0010
[2019-03-23 03:09:12,175] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:09:12,175] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:12,232] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run11
[2019-03-23 03:09:12,669] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2122731: loss 0.0077
[2019-03-23 03:09:12,670] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2122731: learning rate 0.0010
[2019-03-23 03:09:13,365] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:09:13,366] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:13,411] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run11
[2019-03-23 03:09:13,488] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2123234: loss 2.8436
[2019-03-23 03:09:13,493] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2123234: learning rate 0.0010
[2019-03-23 03:09:13,720] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:09:13,721] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:13,787] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run11
[2019-03-23 03:09:13,832] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2123418: loss 2.7848
[2019-03-23 03:09:13,833] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2123418: learning rate 0.0010
[2019-03-23 03:09:14,144] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:09:14,145] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:14,163] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run11
[2019-03-23 03:09:14,298] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:09:14,298] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:14,327] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run11
[2019-03-23 03:09:14,847] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2124017: loss 1.7895
[2019-03-23 03:09:14,850] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2124019: learning rate 0.0010
[2019-03-23 03:09:15,311] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2124318: loss 6.8229
[2019-03-23 03:09:15,315] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2124319: learning rate 0.0010
[2019-03-23 03:09:15,805] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2124594: loss 1.2738
[2019-03-23 03:09:15,808] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2124594: learning rate 0.0010
[2019-03-23 03:09:16,078] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2124717: loss 1.9190
[2019-03-23 03:09:16,079] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2124717: learning rate 0.0010
[2019-03-23 03:09:16,371] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2124849: loss 0.0122
[2019-03-23 03:09:16,374] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2124850: learning rate 0.0010
[2019-03-23 03:09:16,694] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 03:09:16,696] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:09:16,698] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:09:16,701] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:16,700] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:09:16,702] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:09:16,705] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:16,705] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:09:16,707] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:16,709] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:16,710] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:09:16,738] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run86
[2019-03-23 03:09:16,768] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run86
[2019-03-23 03:09:16,769] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run86
[2019-03-23 03:09:16,797] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run86
[2019-03-23 03:09:16,798] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run86
[2019-03-23 03:09:28,214] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.75838125], dtype=float32), 0.12250195]
[2019-03-23 03:09:28,218] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.98333333333333, 24.0, 1.0, 2.0, 0.5388692773168551, 1.0, 1.0, 0.5388692773168551, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9257416208621, 1336272.728121158, 1336272.728121158, 251727.1025736191]
[2019-03-23 03:09:28,219] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:09:28,221] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.2165866e-13 0.0000000e+00 0.0000000e+00 1.0000000e+00 2.3104711e-16], sampled 0.6466859208015077
[2019-03-23 03:09:44,096] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.75838125], dtype=float32), 0.12250195]
[2019-03-23 03:09:44,098] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.21666666666667, 89.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6995306600933131, 6.911199999999999, 6.9112, 121.9260426156618, 522750.7584975074, 522750.7584975079, 144866.9844421681]
[2019-03-23 03:09:44,100] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:09:44,102] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9155061924593135
[2019-03-23 03:09:56,755] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.75838125], dtype=float32), 0.12250195]
[2019-03-23 03:09:56,758] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.25, 46.5, 1.0, 2.0, 0.1992043287299285, 1.0, 1.0, 0.1992043287299285, 1.0, 1.0, 0.3171397789701077, 6.9112, 6.9112, 121.94756008, 681057.8530203744, 681057.8530203744, 220334.9625648322]
[2019-03-23 03:09:56,760] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:09:56,763] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.6804848e-09 0.0000000e+00 0.0000000e+00 5.7036374e-15 1.0000000e+00], sampled 0.6981228020819132
[2019-03-23 03:09:56,904] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.75838125], dtype=float32), 0.12250195]
[2019-03-23 03:09:56,907] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5919033845115209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695883.2625586883, 695883.2625586883, 157674.5175870407]
[2019-03-23 03:09:56,908] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:09:56,912] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.1429435e-36 2.9406947e-26], sampled 0.3461004138876166
[2019-03-23 03:09:56,913] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 695883.2625586883 W.
[2019-03-23 03:10:00,143] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.75838125], dtype=float32), 0.12250195]
[2019-03-23 03:10:00,145] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.11946593, 78.306597715, 1.0, 2.0, 0.628556553341522, 1.0, 2.0, 0.628556553341522, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1433347.255003096, 1433347.255003097, 278005.2127834387]
[2019-03-23 03:10:00,147] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:10:00,149] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.3473267e-21 0.0000000e+00 0.0000000e+00 1.0000000e+00 7.0419685e-25], sampled 0.21226141399345655
[2019-03-23 03:10:40,945] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.75838125], dtype=float32), 0.12250195]
[2019-03-23 03:10:40,946] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [34.0, 39.83333333333333, 1.0, 2.0, 0.7131772457901635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 825755.418956422, 825755.418956422, 179295.5307859723]
[2019-03-23 03:10:40,947] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:10:40,952] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2887892e-13 2.0704640e-13], sampled 0.4783784990612808
[2019-03-23 03:10:40,953] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 825755.418956422 W.
[2019-03-23 03:10:41,303] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.75838125], dtype=float32), 0.12250195]
[2019-03-23 03:10:41,304] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.11625655666667, 76.56134781333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5507470138175395, 6.9112, 6.9112, 121.9260426156618, 404727.2115785937, 404727.2115785937, 123506.9108130081]
[2019-03-23 03:10:41,306] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:10:41,310] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6583463561081558
[2019-03-23 03:10:51,730] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.75838125], dtype=float32), 0.12250195]
[2019-03-23 03:10:51,731] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.0, 61.83333333333333, 1.0, 2.0, 0.7298612898882564, 1.0, 2.0, 0.7298612898882564, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1664598.694187681, 1664598.694187681, 315625.5121195326]
[2019-03-23 03:10:51,733] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:10:51,735] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.5082465e-09 0.0000000e+00 0.0000000e+00 1.0000000e+00 1.7230121e-32], sampled 0.7592391624093897
[2019-03-23 03:11:07,803] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8593.6207 2235176779.5719 333.0000
[2019-03-23 03:11:07,873] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8475.5296 2275294322.5326 332.0000
[2019-03-23 03:11:07,877] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7911.3344 2526999199.8107 460.0000
[2019-03-23 03:11:08,116] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8446.8235 2296553999.9940 378.0000
[2019-03-23 03:11:08,146] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8369.1480 2338029679.7765 350.0000
[2019-03-23 03:11:09,163] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2125000, evaluation results [2125000.0, 7911.334437732042, 2526999199.810714, 460.0, 8475.52959647532, 2275294322.532559, 332.0, 8593.62069410316, 2235176779.5718875, 333.0, 8369.147956421826, 2338029679.776466, 350.0, 8446.823541680033, 2296553999.9940324, 378.0]
[2019-03-23 03:11:10,060] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2125465: loss 0.0018
[2019-03-23 03:11:10,063] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2125466: learning rate 0.0010
[2019-03-23 03:11:10,558] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2125731: loss 0.0278
[2019-03-23 03:11:10,559] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2125731: learning rate 0.0010
[2019-03-23 03:11:11,458] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:11:11,471] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5693
[2019-03-23 03:11:11,477] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.8, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6763036950578262, 6.911199999999999, 6.9112, 121.9260426156618, 505236.1574292886, 505236.1574292891, 141358.3611607514], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 93600.0000, 
sim time next is 94200.0000, 
raw observation next is [22.7, 75.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9560717618773237, 7.82080580930857, 6.9112, 121.9710347439843, 1180443.537023943, 714472.1775878199, 171847.3409855269], 
processed observation next is [1.0, 0.08695652173913043, 0.39629629629629626, 0.7516666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9450897023466545, 0.09096058093085704, 0.0, 0.8097608297636816, 0.42158697750855106, 0.2551686348527928, 0.3304756557413979], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.60065615], dtype=float32), 1.1808386]. 
=============================================
[2019-03-23 03:11:12,742] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2126864: loss 0.0107
[2019-03-23 03:11:12,746] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2126865: learning rate 0.0010
[2019-03-23 03:11:14,221] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:11:14,231] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4087
[2019-03-23 03:11:14,235] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.2, 34.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5215196868363798, 6.9112, 6.9112, 121.9260426156618, 372373.8369667396, 372373.8369667396, 103763.9562676234], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 289800.0000, 
sim time next is 290400.0000, 
raw observation next is [24.33333333333333, 33.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5244528290156921, 6.911200000000001, 6.9112, 121.9260426156618, 374468.6611776749, 374468.6611776745, 104284.3839298457], 
processed observation next is [0.0, 0.34782608695652173, 0.45679012345678993, 0.3366666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4055660362696151, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13373880756345533, 0.13373880756345516, 0.20054689217278018], 
reward next is 0.7995, 
noisyNet noise sample is [array([-1.0152025], dtype=float32), -1.4769692]. 
=============================================
[2019-03-23 03:11:15,282] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2128187: loss 0.0129
[2019-03-23 03:11:15,283] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2128188: learning rate 0.0010
[2019-03-23 03:11:16,802] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:11:16,808] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4748
[2019-03-23 03:11:16,813] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.16666666666667, 61.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4623769063048732, 6.911200000000001, 6.9112, 121.9260426156618, 331972.5556729705, 331972.5556729701, 112959.8393675916], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 195600.0000, 
sim time next is 196200.0000, 
raw observation next is [21.35, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4690846719524353, 6.9112, 6.9112, 121.9260426156618, 338521.8370633307, 338521.8370633307, 114085.8913915173], 
processed observation next is [0.0, 0.2608695652173913, 0.3462962962962963, 0.62, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3363558399405441, 0.0, 0.0, 0.8094621288201359, 0.12090065609404668, 0.12090065609404668, 0.2193959449836871], 
reward next is 0.7806, 
noisyNet noise sample is [array([-0.7719071], dtype=float32), -0.26451236]. 
=============================================
[2019-03-23 03:11:17,180] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2129185: loss 0.0054
[2019-03-23 03:11:17,184] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2129186: learning rate 0.0010
[2019-03-23 03:11:17,611] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2129406: loss 0.0020
[2019-03-23 03:11:17,619] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2129406: learning rate 0.0010
[2019-03-23 03:11:18,027] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2129623: loss 0.0013
[2019-03-23 03:11:18,030] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2129623: learning rate 0.0010
[2019-03-23 03:11:18,410] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2129818: loss 0.0006
[2019-03-23 03:11:18,410] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2129818: learning rate 0.0010
[2019-03-23 03:11:19,644] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2130457: loss 0.0755
[2019-03-23 03:11:19,646] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2130457: learning rate 0.0010
[2019-03-23 03:11:20,445] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2130869: loss 0.0264
[2019-03-23 03:11:20,448] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2130870: learning rate 0.0010
[2019-03-23 03:11:21,012] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2131162: loss 0.0014
[2019-03-23 03:11:21,018] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2131163: learning rate 0.0010
[2019-03-23 03:11:22,521] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2131935: loss 0.0011
[2019-03-23 03:11:22,526] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2131936: learning rate 0.0010
[2019-03-23 03:11:23,066] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2132218: loss 0.0236
[2019-03-23 03:11:23,070] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2132219: learning rate 0.0010
[2019-03-23 03:11:23,889] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2132645: loss 0.0015
[2019-03-23 03:11:23,894] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2132646: learning rate 0.0010
[2019-03-23 03:11:23,927] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2132662: loss 0.0008
[2019-03-23 03:11:23,929] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2132662: learning rate 0.0010
[2019-03-23 03:11:24,609] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2133013: loss 0.0084
[2019-03-23 03:11:24,611] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2133014: learning rate 0.0010
[2019-03-23 03:11:25,883] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2133667: loss 0.0139
[2019-03-23 03:11:25,884] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2133667: learning rate 0.0010
[2019-03-23 03:11:26,314] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2133885: loss 2.5655
[2019-03-23 03:11:26,317] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2133885: learning rate 0.0010
[2019-03-23 03:11:28,281] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2134893: loss 0.0038
[2019-03-23 03:11:28,284] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2134893: learning rate 0.0010
[2019-03-23 03:11:30,994] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2136291: loss 0.0072
[2019-03-23 03:11:30,996] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2136292: learning rate 0.0010
[2019-03-23 03:11:32,888] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2137237: loss 0.0961
[2019-03-23 03:11:32,889] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2137237: learning rate 0.0010
[2019-03-23 03:11:33,395] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2137489: loss 0.1088
[2019-03-23 03:11:33,397] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2137489: learning rate 0.0010
[2019-03-23 03:11:33,687] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2137640: loss 0.0521
[2019-03-23 03:11:33,689] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2137640: learning rate 0.0010
[2019-03-23 03:11:34,261] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2137939: loss 0.1407
[2019-03-23 03:11:34,266] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2137940: learning rate 0.0010
[2019-03-23 03:11:35,012] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2138329: loss 0.0107
[2019-03-23 03:11:35,015] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2138330: learning rate 0.0010
[2019-03-23 03:11:36,057] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2138866: loss 0.0062
[2019-03-23 03:11:36,063] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2138867: learning rate 0.0010
[2019-03-23 03:11:36,470] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2139075: loss 0.0223
[2019-03-23 03:11:36,472] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2139076: learning rate 0.0010
[2019-03-23 03:11:37,966] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2139848: loss 0.0044
[2019-03-23 03:11:37,975] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2139850: learning rate 0.0010
[2019-03-23 03:11:38,736] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2140245: loss 0.0506
[2019-03-23 03:11:38,741] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2140245: learning rate 0.0010
[2019-03-23 03:11:39,181] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:11:39,189] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0029
[2019-03-23 03:11:39,196] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.33333333333334, 43.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7029482772520211, 6.9112, 6.9112, 121.9260426156618, 525214.684342132, 525214.684342132, 145799.685148417], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 817800.0000, 
sim time next is 818400.0000, 
raw observation next is [29.66666666666667, 42.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7069969916529347, 6.9112, 6.9112, 121.9260426156618, 528209.1043038398, 528209.1043038398, 146352.2840467463], 
processed observation next is [0.0, 0.4782608695652174, 0.6543209876543211, 0.4266666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6337462395661683, 0.0, 0.0, 0.8094621288201359, 0.1886461086799428, 0.1886461086799428, 0.2814467000898967], 
reward next is 0.7186, 
noisyNet noise sample is [array([0.34574232], dtype=float32), 0.02507423]. 
=============================================
[2019-03-23 03:11:39,447] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2140602: loss 0.0859
[2019-03-23 03:11:39,448] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2140603: learning rate 0.0010
[2019-03-23 03:11:39,618] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2140688: loss 0.0733
[2019-03-23 03:11:39,622] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2140690: learning rate 0.0010
[2019-03-23 03:11:40,097] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2140935: loss 0.0131
[2019-03-23 03:11:40,100] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2140936: learning rate 0.0010
[2019-03-23 03:11:41,284] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2141549: loss 0.0165
[2019-03-23 03:11:41,287] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2141549: learning rate 0.0010
[2019-03-23 03:11:41,651] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2141735: loss 0.6112
[2019-03-23 03:11:41,660] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2141739: learning rate 0.0010
[2019-03-23 03:11:43,938] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2142928: loss 0.0208
[2019-03-23 03:11:43,941] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2142928: learning rate 0.0010
[2019-03-23 03:11:46,295] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2144205: loss 0.0409
[2019-03-23 03:11:46,299] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2144210: learning rate 0.0010
[2019-03-23 03:11:48,167] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2145178: loss 0.0348
[2019-03-23 03:11:48,168] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2145178: learning rate 0.0010
[2019-03-23 03:11:48,652] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2145404: loss 0.0275
[2019-03-23 03:11:48,654] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2145404: learning rate 0.0010
[2019-03-23 03:11:49,023] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2145571: loss 0.0013
[2019-03-23 03:11:49,025] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2145571: learning rate 0.0010
[2019-03-23 03:11:49,298] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:11:49,306] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6200
[2019-03-23 03:11:49,311] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.86666666666667, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8798087388478986, 6.911199999999999, 6.9112, 121.9260426156618, 644773.0474337838, 644773.0474337842, 155407.3732560897], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1066800.0000, 
sim time next is 1067400.0000, 
raw observation next is [22.95, 57.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9745061583182715, 7.089909144452831, 6.9112, 121.9253337693488, 805812.3898523501, 714297.8670951562, 166088.4545687993], 
processed observation next is [1.0, 0.34782608695652173, 0.4055555555555555, 0.575, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9681326978978394, 0.01787091444528306, 0.0, 0.8094574228177658, 0.2877901392329822, 0.25510638110541295, 0.31940087417076785], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.36342078], dtype=float32), 0.8811422]. 
=============================================
[2019-03-23 03:11:49,825] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2145934: loss 0.0069
[2019-03-23 03:11:49,828] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2145934: learning rate 0.0010
[2019-03-23 03:11:50,797] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2146376: loss 0.8137
[2019-03-23 03:11:50,801] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2146377: learning rate 0.0010
[2019-03-23 03:11:51,826] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2146857: loss 0.0501
[2019-03-23 03:11:51,828] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2146857: learning rate 0.0010
[2019-03-23 03:11:52,255] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:11:52,267] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4489
[2019-03-23 03:11:52,273] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.1, 65.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5468817771611149, 6.9112, 6.9112, 121.9260426156618, 397449.5981047476, 397449.5981047476, 121238.3171149965], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 881400.0000, 
sim time next is 882000.0000, 
raw observation next is [21.0, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5393230003071848, 6.911200000000001, 6.9112, 121.9260426156618, 391163.1675133273, 391163.1675133269, 120302.4098529039], 
processed observation next is [0.0, 0.21739130434782608, 0.3333333333333333, 0.65, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.424153750383981, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13970113125475975, 0.1397011312547596, 0.23135078817866137], 
reward next is 0.7686, 
noisyNet noise sample is [array([1.7753066], dtype=float32), 0.084761925]. 
=============================================
[2019-03-23 03:11:52,283] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.348206]
 [71.30297 ]
 [71.27184 ]
 [71.2468  ]
 [71.24907 ]], R is [[71.46054077]
 [71.51277924]
 [71.56272888]
 [71.61052704]
 [71.65618134]].
[2019-03-23 03:11:52,440] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2147143: loss 0.0231
[2019-03-23 03:11:52,442] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2147144: learning rate 0.0010
[2019-03-23 03:11:54,000] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2147855: loss 0.0027
[2019-03-23 03:11:54,002] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2147855: learning rate 0.0010
[2019-03-23 03:11:54,749] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2148203: loss 0.0006
[2019-03-23 03:11:54,751] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2148203: learning rate 0.0010
[2019-03-23 03:11:55,610] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2148601: loss 0.0014
[2019-03-23 03:11:55,614] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2148602: learning rate 0.0010
[2019-03-23 03:11:55,643] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:11:55,651] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6935
[2019-03-23 03:11:55,660] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.66666666666667, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.643286912344794, 6.911199999999999, 6.9112, 121.9260426156618, 479570.661264212, 479570.6612642125, 136329.4054259556], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1293600.0000, 
sim time next is 1294200.0000, 
raw observation next is [20.6, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6385435536347789, 6.911199999999999, 6.9112, 121.9260426156618, 475872.3288495681, 475872.3288495686, 135678.5620182967], 
processed observation next is [1.0, 1.0, 0.3185185185185186, 0.86, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5481794420434736, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16995440316056004, 0.1699544031605602, 0.26092031157364753], 
reward next is 0.7391, 
noisyNet noise sample is [array([0.74147195], dtype=float32), -1.4205022]. 
=============================================
[2019-03-23 03:11:55,719] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:11:55,728] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1034
[2019-03-23 03:11:55,732] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.86666666666667, 45.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5072190014181528, 6.911199999999999, 6.9112, 121.9260426156618, 364448.2163075396, 364448.2163075401, 116446.1894127479], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1025400.0000, 
sim time next is 1026000.0000, 
raw observation next is [23.8, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5031619893916606, 6.9112, 6.9112, 121.9260426156618, 361536.5445528956, 361536.5445528956, 116133.8976339411], 
processed observation next is [1.0, 0.9130434782608695, 0.43703703703703706, 0.46, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.37895248673957566, 0.0, 0.0, 0.8094621288201359, 0.129120194483177, 0.129120194483177, 0.22333441852680982], 
reward next is 0.7767, 
noisyNet noise sample is [array([-0.39816135], dtype=float32), 0.29684448]. 
=============================================
[2019-03-23 03:11:55,751] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[72.14921 ]
 [71.948395]
 [71.77018 ]
 [71.62326 ]
 [71.503815]], R is [[72.3736496 ]
 [72.42597961]
 [72.47750092]
 [72.52876282]
 [72.57959747]].
[2019-03-23 03:11:55,965] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2148760: loss 0.0002
[2019-03-23 03:11:55,968] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2148760: learning rate 0.0010
[2019-03-23 03:11:56,692] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2149087: loss 0.0654
[2019-03-23 03:11:56,694] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2149088: learning rate 0.0010
[2019-03-23 03:11:58,112] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2149738: loss 0.1824
[2019-03-23 03:11:58,114] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2149738: learning rate 0.0010
[2019-03-23 03:11:58,626] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2149971: loss 0.1032
[2019-03-23 03:11:58,629] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2149972: learning rate 0.0010
[2019-03-23 03:11:58,700] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 03:11:58,703] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:11:58,704] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:11:58,705] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:11:58,705] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:11:58,706] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:11:58,707] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:11:58,709] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:11:58,706] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:11:58,713] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:11:58,713] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:11:58,740] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run87
[2019-03-23 03:11:58,767] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run87
[2019-03-23 03:11:58,770] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run87
[2019-03-23 03:11:58,826] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run87
[2019-03-23 03:11:58,827] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run87
[2019-03-23 03:12:04,962] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.6562103], dtype=float32), 0.12739976]
[2019-03-23 03:12:04,963] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.46857505666667, 59.82204269666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6540243086600878, 6.9112, 6.9112, 121.92604261565, 479734.2569244895, 479734.2569244895, 132449.7764738015]
[2019-03-23 03:12:04,967] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:12:04,969] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.47996828410933534
[2019-03-23 03:12:16,840] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.6562103], dtype=float32), 0.12739976]
[2019-03-23 03:12:16,841] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.95, 24.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6099397056949342, 6.9112, 6.9112, 121.9260426156618, 447122.2266331556, 447122.2266331556, 128247.5605166831]
[2019-03-23 03:12:16,842] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:12:16,846] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8603470519584031
[2019-03-23 03:12:20,169] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.6562103], dtype=float32), 0.12739976]
[2019-03-23 03:12:20,171] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [36.20306531166666, 6.649045448333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7181655684817615, 6.9112, 6.9112, 121.9260426156618, 513113.3721433611, 513113.3721433611, 128125.3433989699]
[2019-03-23 03:12:20,172] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:12:20,174] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8127533658568309
[2019-03-23 03:12:21,198] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.6562103], dtype=float32), 0.12739976]
[2019-03-23 03:12:21,200] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [34.40000000000001, 26.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6795174969465132, 6.911199999999999, 6.9112, 121.9260426156618, 507791.8597542069, 507791.8597542074, 142645.1827476621]
[2019-03-23 03:12:21,202] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:12:21,205] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.332415898167852
[2019-03-23 03:12:22,859] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.6562103], dtype=float32), 0.12739976]
[2019-03-23 03:12:22,861] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 45.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5980249735280562, 6.911200000000001, 6.9112, 121.9260426156618, 444337.4355634493, 444337.4355634489, 130527.7529468592]
[2019-03-23 03:12:22,864] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:12:22,867] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7528600052502855
[2019-03-23 03:12:26,378] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.6562103], dtype=float32), 0.12739976]
[2019-03-23 03:12:26,379] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5969680860994607, 6.9112, 6.9112, 121.9260426156618, 442782.2600508108, 442782.2600508108, 129877.4027860627]
[2019-03-23 03:12:26,381] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:12:26,388] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.14946633791596453
[2019-03-23 03:12:46,441] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.6562103], dtype=float32), 0.12739976]
[2019-03-23 03:12:46,441] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.08333333333333, 92.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8075370482880918, 6.9112, 6.9112, 121.9260426156618, 600775.8536863801, 600775.8536863801, 160749.2219083892]
[2019-03-23 03:12:46,442] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:12:46,444] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7150131915394318
[2019-03-23 03:12:52,221] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.6562103], dtype=float32), 0.12739976]
[2019-03-23 03:12:52,222] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.0, 90.66666666666667, 1.0, 2.0, 0.7017913058679535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 799844.6247119415, 799844.6247119415, 176483.4245743322]
[2019-03-23 03:12:52,225] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:12:52,228] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.9856155  0.         0.         0.         0.01438455], sampled 0.3526651389512322
[2019-03-23 03:12:52,229] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 799844.6247119415 W.
[2019-03-23 03:13:00,465] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.6562103], dtype=float32), 0.12739976]
[2019-03-23 03:13:00,467] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.8, 36.0, 1.0, 2.0, 0.7012701006086806, 1.0, 1.0, 0.7012701006086806, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1641956.002463398, 1641956.002463398, 306720.3047328453]
[2019-03-23 03:13:00,468] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:13:00,470] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.280954e-19 0.000000e+00 0.000000e+00 1.000000e+00 3.327051e-32], sampled 0.5446327072505295
[2019-03-23 03:13:16,891] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.6562103], dtype=float32), 0.12739976]
[2019-03-23 03:13:16,892] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.85331136, 88.23549269833335, 1.0, 2.0, 0.258928771634121, 1.0, 2.0, 0.258928771634121, 1.0, 2.0, 0.4122230371628938, 6.9112, 6.9112, 121.94756008, 885367.1115339986, 885367.1115339986, 240813.7684682368]
[2019-03-23 03:13:16,894] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:13:16,898] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9997663e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.3358640e-05], sampled 0.28867458778878485
[2019-03-23 03:13:16,899] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 885367.1115339986 W.
[2019-03-23 03:13:21,498] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.6562103], dtype=float32), 0.12739976]
[2019-03-23 03:13:21,499] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.25, 30.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.810843667297335, 6.911200000000001, 6.9112, 121.9260426156618, 600239.9098770042, 600239.9098770038, 162545.4230469402]
[2019-03-23 03:13:21,500] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:13:21,504] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.677793603438005
[2019-03-23 03:13:50,239] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8564.3826 2288924545.8690 419.0000
[2019-03-23 03:13:50,463] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8632.6366 2253202653.6262 417.0000
[2019-03-23 03:13:50,492] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7911.9004 2548620106.6805 619.0000
[2019-03-23 03:13:50,525] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8423.6083 2323644346.4118 514.0000
[2019-03-23 03:13:50,537] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8412.5077 2356631978.7822 442.0000
[2019-03-23 03:13:51,556] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2150000, evaluation results [2150000.0, 7911.900441956037, 2548620106.680545, 619.0, 8564.382613253632, 2288924545.8689556, 419.0, 8632.636612752473, 2253202653.6262484, 417.0, 8412.50770733789, 2356631978.7822447, 442.0, 8423.60834944526, 2323644346.411841, 514.0]
[2019-03-23 03:13:53,499] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2151012: loss 1.8986
[2019-03-23 03:13:53,502] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2151014: learning rate 0.0010
[2019-03-23 03:13:54,403] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.8903122e-35], sum to 1.0000
[2019-03-23 03:13:54,410] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7400
[2019-03-23 03:13:54,418] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.7, 52.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4883769088176405, 6.911200000000001, 6.9112, 121.9260426156618, 351433.6545951898, 351433.6545951894, 115187.1337518965], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1035600.0000, 
sim time next is 1036200.0000, 
raw observation next is [22.6, 53.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4881047982311058, 6.9112, 6.9112, 121.9260426156618, 351545.9629580886, 351545.9629580886, 115277.2843374168], 
processed observation next is [1.0, 1.0, 0.39259259259259266, 0.5316666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.36013099778888225, 0.0, 0.0, 0.8094621288201359, 0.12555212962788878, 0.12555212962788878, 0.2216870852642631], 
reward next is 0.7783, 
noisyNet noise sample is [array([-1.1943028], dtype=float32), -0.89063746]. 
=============================================
[2019-03-23 03:13:55,848] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2152230: loss 1.1062
[2019-03-23 03:13:55,850] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2152230: learning rate 0.0010
[2019-03-23 03:13:57,150] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3395966e-13 0.0000000e+00 0.0000000e+00 1.3402151e-25 1.0000000e+00], sum to 1.0000
[2019-03-23 03:13:57,159] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7804
[2019-03-23 03:13:57,164] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.86666666666667, 51.33333333333334, 1.0, 2.0, 0.257019855226275, 1.0, 1.0, 0.257019855226275, 1.0, 1.0, 0.4207853113137037, 6.9112, 6.9112, 121.94756008, 943344.0386316977, 943344.0386316977, 238746.1853399837], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1332600.0000, 
sim time next is 1333200.0000, 
raw observation next is [26.13333333333334, 49.66666666666667, 1.0, 2.0, 0.2498059537195425, 1.0, 2.0, 0.2498059537195425, 1.0, 2.0, 0.4083304397597051, 6.911199999999999, 6.9112, 121.94756008, 915195.3072010118, 915195.3072010122, 236261.7036817239], 
processed observation next is [1.0, 0.43478260869565216, 0.523456790123457, 0.4966666666666667, 1.0, 1.0, 0.10691184966612204, 1.0, 1.0, 0.10691184966612204, 1.0, 1.0, 0.26041304969963136, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3268554668575042, 0.32685546685750433, 0.4543494301571614], 
reward next is 0.5457, 
noisyNet noise sample is [array([1.26655], dtype=float32), 0.5190355]. 
=============================================
[2019-03-23 03:13:57,639] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2153156: loss 3.1839
[2019-03-23 03:13:57,641] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2153156: learning rate 0.0010
[2019-03-23 03:13:58,051] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2153365: loss 2.1823
[2019-03-23 03:13:58,053] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2153365: learning rate 0.0010
[2019-03-23 03:13:58,532] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2153612: loss 2.3933
[2019-03-23 03:13:58,534] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2153613: learning rate 0.0010
[2019-03-23 03:13:58,925] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:13:58,933] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3048
[2019-03-23 03:13:58,937] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.03333333333333, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5559324341144355, 6.911199999999999, 6.9112, 121.9260426156618, 407124.4579192352, 407124.4579192356, 123295.7074979062], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1219200.0000, 
sim time next is 1219800.0000, 
raw observation next is [18.01666666666667, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5537356064160053, 6.9112, 6.9112, 121.9260426156618, 405412.9230549557, 405412.9230549557, 123061.3342332381], 
processed observation next is [1.0, 0.08695652173913043, 0.2228395061728396, 0.93, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44216950802000654, 0.0, 0.0, 0.8094621288201359, 0.14479032966248417, 0.14479032966248417, 0.23665641198699636], 
reward next is 0.7633, 
noisyNet noise sample is [array([-1.1218853], dtype=float32), 0.22314854]. 
=============================================
[2019-03-23 03:13:59,180] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2153945: loss 2.4432
[2019-03-23 03:13:59,182] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2153946: learning rate 0.0010
[2019-03-23 03:13:59,779] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2154254: loss 0.3397
[2019-03-23 03:13:59,781] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2154255: learning rate 0.0010
[2019-03-23 03:14:00,696] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:14:00,704] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9036
[2019-03-23 03:14:00,709] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.16666666666667, 87.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.578269216505968, 6.911200000000001, 6.9112, 121.9260426156618, 426416.4743057946, 426416.4743057942, 126656.3706790683], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1306200.0000, 
sim time next is 1306800.0000, 
raw observation next is [19.1, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5745284288495386, 6.9112, 6.9112, 121.9260426156618, 423521.5679498543, 423521.5679498543, 126248.9275774709], 
processed observation next is [1.0, 0.13043478260869565, 0.262962962962963, 0.88, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4681605360619232, 0.0, 0.0, 0.8094621288201359, 0.15125770283923368, 0.15125770283923368, 0.24278639918744402], 
reward next is 0.7572, 
noisyNet noise sample is [array([-0.83666676], dtype=float32), -1.1883683]. 
=============================================
[2019-03-23 03:14:01,157] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2154957: loss 2.7729
[2019-03-23 03:14:01,158] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2154957: learning rate 0.0010
[2019-03-23 03:14:01,346] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2155055: loss 0.2387
[2019-03-23 03:14:01,349] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2155055: learning rate 0.0010
[2019-03-23 03:14:02,943] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2155878: loss 1.4048
[2019-03-23 03:14:02,947] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2155878: learning rate 0.0010
[2019-03-23 03:14:03,695] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2156279: loss 2.5628
[2019-03-23 03:14:03,697] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2156279: learning rate 0.0010
[2019-03-23 03:14:04,206] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2156544: loss 0.4236
[2019-03-23 03:14:04,208] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2156544: learning rate 0.0010
[2019-03-23 03:14:04,620] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2156762: loss 1.6650
[2019-03-23 03:14:04,622] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2156763: learning rate 0.0010
[2019-03-23 03:14:05,221] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2157018: loss 0.5011
[2019-03-23 03:14:05,226] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2157019: learning rate 0.0010
[2019-03-23 03:14:05,569] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:14:05,575] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6642
[2019-03-23 03:14:05,580] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.93333333333334, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5271181406408343, 6.911199999999999, 6.9112, 121.9260426156618, 384868.847151042, 384868.8471510424, 120348.9192428546], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1228800.0000, 
sim time next is 1229400.0000, 
raw observation next is [18.0, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5300211957602288, 6.911199999999999, 6.9112, 121.9260426156618, 387166.442070602, 387166.4420706025, 120665.7451499473], 
processed observation next is [1.0, 0.21739130434782608, 0.2222222222222222, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4125264947002859, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13827372931092927, 0.13827372931092946, 0.2320495099037448], 
reward next is 0.7680, 
noisyNet noise sample is [array([0.17932439], dtype=float32), -0.9016105]. 
=============================================
[2019-03-23 03:14:06,398] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2157624: loss 0.4314
[2019-03-23 03:14:06,405] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2157627: learning rate 0.0010
[2019-03-23 03:14:06,967] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2157915: loss 0.0151
[2019-03-23 03:14:06,972] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2157917: learning rate 0.0010
[2019-03-23 03:14:08,915] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2158926: loss 0.2711
[2019-03-23 03:14:08,918] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2158927: learning rate 0.0010
[2019-03-23 03:14:09,759] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:14:09,767] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8458
[2019-03-23 03:14:09,771] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.03333333333334, 40.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8432483176199643, 6.9112, 6.9112, 121.9260426156618, 620386.7180681559, 620386.7180681559, 167803.2365047126], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1528800.0000, 
sim time next is 1529400.0000, 
raw observation next is [32.86666666666667, 41.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8598129636384608, 6.911200000000001, 6.9112, 121.9260426156618, 631151.4689898092, 631151.4689898087, 170265.1464986718], 
processed observation next is [0.0, 0.6956521739130435, 0.7728395061728395, 0.41666666666666674, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.824766204548076, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22541123892493184, 0.22541123892493167, 0.32743297403590726], 
reward next is 0.6726, 
noisyNet noise sample is [array([-0.23370454], dtype=float32), 0.2288383]. 
=============================================
[2019-03-23 03:14:09,908] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:14:09,918] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2973
[2019-03-23 03:14:09,923] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.83333333333333, 31.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5906947390562522, 6.9112, 6.9112, 121.9260426156618, 437305.0886046739, 437305.0886046739, 128760.6017544019], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1417800.0000, 
sim time next is 1418400.0000, 
raw observation next is [30.0, 31.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5944964679641691, 6.9112, 6.9112, 121.9260426156618, 440013.3892923223, 440013.3892923223, 129047.0879892557], 
processed observation next is [0.0, 0.43478260869565216, 0.6666666666666666, 0.31, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4931205849552113, 0.0, 0.0, 0.8094621288201359, 0.15714763903297224, 0.15714763903297224, 0.2481674769024148], 
reward next is 0.7518, 
noisyNet noise sample is [array([1.0509952], dtype=float32), -1.4123315]. 
=============================================
[2019-03-23 03:14:11,311] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2160151: loss 0.4490
[2019-03-23 03:14:11,314] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2160152: learning rate 0.0010
[2019-03-23 03:14:13,099] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2161074: loss 0.3069
[2019-03-23 03:14:13,102] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2161075: learning rate 0.0010
[2019-03-23 03:14:13,662] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2161367: loss 0.2327
[2019-03-23 03:14:13,664] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2161367: learning rate 0.0010
[2019-03-23 03:14:14,012] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2161547: loss 0.5762
[2019-03-23 03:14:14,013] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2161547: learning rate 0.0010
[2019-03-23 03:14:14,635] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2161862: loss 0.3855
[2019-03-23 03:14:14,639] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2161863: learning rate 0.0010
[2019-03-23 03:14:15,593] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2162356: loss 0.1580
[2019-03-23 03:14:15,595] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2162356: learning rate 0.0010
[2019-03-23 03:14:16,691] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2162922: loss 0.3385
[2019-03-23 03:14:16,693] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2162922: learning rate 0.0010
[2019-03-23 03:14:17,028] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2163094: loss 0.1735
[2019-03-23 03:14:17,031] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2163094: learning rate 0.0010
[2019-03-23 03:14:18,596] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2163904: loss 0.4426
[2019-03-23 03:14:18,597] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2163904: learning rate 0.0010
[2019-03-23 03:14:19,099] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2164166: loss 0.3851
[2019-03-23 03:14:19,101] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2164166: learning rate 0.0010
[2019-03-23 03:14:19,734] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2164495: loss 0.1866
[2019-03-23 03:14:19,736] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2164497: learning rate 0.0010
[2019-03-23 03:14:20,031] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2164646: loss 0.3434
[2019-03-23 03:14:20,032] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2164646: learning rate 0.0010
[2019-03-23 03:14:20,986] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2165134: loss 0.0344
[2019-03-23 03:14:20,988] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2165134: learning rate 0.0010
[2019-03-23 03:14:21,717] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:14:21,723] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4992
[2019-03-23 03:14:21,728] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.75, 83.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5476338106279607, 6.9112, 6.9112, 121.9260426156618, 399414.5190662225, 399414.5190662225, 121878.0506595951], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1799400.0000, 
sim time next is 1800000.0000, 
raw observation next is [18.3, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5347929904750881, 6.911199999999999, 6.9112, 121.9260426156618, 388187.6273831076, 388187.6273831081, 120052.4290250093], 
processed observation next is [1.0, 0.8695652173913043, 0.23333333333333336, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4184912380938601, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13863843835110987, 0.13863843835111003, 0.2308700558173256], 
reward next is 0.7691, 
noisyNet noise sample is [array([2.271938], dtype=float32), 0.14823721]. 
=============================================
[2019-03-23 03:14:21,740] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.0974  ]
 [69.9913  ]
 [69.566154]
 [69.41809 ]
 [69.24928 ]], R is [[70.25106049]
 [70.31417084]
 [70.37315369]
 [70.42810822]
 [70.47906494]].
[2019-03-23 03:14:22,330] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2165817: loss 0.0886
[2019-03-23 03:14:22,331] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2165818: learning rate 0.0010
[2019-03-23 03:14:22,750] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2166039: loss 0.0053
[2019-03-23 03:14:22,754] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2166039: learning rate 0.0010
[2019-03-23 03:14:24,609] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2166993: loss 0.0534
[2019-03-23 03:14:24,611] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2166993: learning rate 0.0010
[2019-03-23 03:14:25,871] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:14:25,877] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0637
[2019-03-23 03:14:25,885] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.33333333333333, 88.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6969340633120411, 6.9112, 6.9112, 121.9260426156618, 520809.917261218, 520809.917261218, 144577.5213668539], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1878600.0000, 
sim time next is 1879200.0000, 
raw observation next is [21.3, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6970389538623364, 6.911199999999999, 6.9112, 121.9260426156618, 520889.5199799223, 520889.5199799227, 144557.0162060823], 
processed observation next is [1.0, 0.782608695652174, 0.3444444444444445, 0.89, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6212986923279205, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18603197142140082, 0.18603197142140096, 0.27799426193477367], 
reward next is 0.7220, 
noisyNet noise sample is [array([-1.0765625], dtype=float32), -1.314441]. 
=============================================
[2019-03-23 03:14:26,445] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:14:26,449] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1810
[2019-03-23 03:14:26,455] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.81666666666667, 73.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8304512572918904, 6.9112, 6.9112, 121.9260426156618, 620150.0185629986, 620150.0185629986, 158088.236179922], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1757400.0000, 
sim time next is 1758000.0000, 
raw observation next is [22.93333333333333, 73.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9562444536282083, 7.479083950644021, 6.9112, 121.9241886241027, 1005193.657443824, 714390.7398011502, 172546.8247877032], 
processed observation next is [1.0, 0.34782608695652173, 0.40493827160493817, 0.7333333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9453055670352603, 0.05678839506440214, 0.0, 0.8094498202441989, 0.3589977348013657, 0.2551395499289822, 0.3318208168994292], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4178483], dtype=float32), -1.2684149]. 
=============================================
[2019-03-23 03:14:26,475] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[69.86698 ]
 [70.32897 ]
 [70.65919 ]
 [70.63655 ]
 [70.568085]], R is [[66.94415283]
 [66.9706955 ]
 [67.01150513]
 [67.06414032]
 [67.11550903]].
[2019-03-23 03:14:27,002] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2168224: loss 0.0577
[2019-03-23 03:14:27,003] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2168225: learning rate 0.0010
[2019-03-23 03:14:28,555] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2169154: loss 0.0758
[2019-03-23 03:14:28,556] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2169154: learning rate 0.0010
[2019-03-23 03:14:28,841] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:14:28,852] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4996
[2019-03-23 03:14:28,856] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.9, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6899752110381743, 6.9112, 6.9112, 121.9260426156618, 515609.9587998397, 515609.9587998397, 143675.5036923166], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1897200.0000, 
sim time next is 1897800.0000, 
raw observation next is [20.81666666666667, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6861329767841442, 6.911200000000001, 6.9112, 121.9260426156618, 512733.1545130583, 512733.1545130578, 143141.0903971765], 
processed observation next is [1.0, 1.0, 0.32654320987654334, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6076662209801802, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18311898375466368, 0.18311898375466348, 0.2752713276868779], 
reward next is 0.7247, 
noisyNet noise sample is [array([0.9514186], dtype=float32), -1.2098986]. 
=============================================
[2019-03-23 03:14:29,101] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2169403: loss 0.0516
[2019-03-23 03:14:29,105] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2169404: learning rate 0.0010
[2019-03-23 03:14:29,527] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2169598: loss 0.0796
[2019-03-23 03:14:29,532] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2169599: learning rate 0.0010
[2019-03-23 03:14:30,255] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2169926: loss 0.0730
[2019-03-23 03:14:30,258] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2169927: learning rate 0.0010
[2019-03-23 03:14:30,411] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8437504e-10 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 03:14:30,421] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4411
[2019-03-23 03:14:30,426] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.03333333333333, 67.16666666666667, 1.0, 2.0, 0.5349280264685609, 1.0, 2.0, 0.5349280264685609, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1273424.742662924, 1273424.742662924, 248766.264264279], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1770600.0000, 
sim time next is 1771200.0000, 
raw observation next is [25.1, 67.0, 1.0, 2.0, 0.5289456441502153, 1.0, 2.0, 0.5289456441502153, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1258468.348205814, 1258468.348205815, 246793.4844802846], 
processed observation next is [1.0, 0.5217391304347826, 0.4851851851851852, 0.67, 1.0, 1.0, 0.43922100494073246, 1.0, 1.0, 0.43922100494073246, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4494529815020764, 0.4494529815020768, 0.47460285476977804], 
reward next is 0.5254, 
noisyNet noise sample is [array([0.5442288], dtype=float32), -0.61133844]. 
=============================================
[2019-03-23 03:14:30,994] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2170265: loss 0.0356
[2019-03-23 03:14:30,996] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2170265: learning rate 0.0010
[2019-03-23 03:14:32,430] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2170923: loss 0.1068
[2019-03-23 03:14:32,433] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2170924: learning rate 0.0010
[2019-03-23 03:14:32,850] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2171120: loss 0.1289
[2019-03-23 03:14:32,854] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2171120: learning rate 0.0010
[2019-03-23 03:14:34,724] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2171979: loss 0.0430
[2019-03-23 03:14:34,731] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2171979: learning rate 0.0010
[2019-03-23 03:14:35,067] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2172139: loss 0.0407
[2019-03-23 03:14:35,070] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2172140: learning rate 0.0010
[2019-03-23 03:14:35,765] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2172463: loss 0.0899
[2019-03-23 03:14:35,767] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2172464: learning rate 0.0010
[2019-03-23 03:14:35,997] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2172570: loss 0.0472
[2019-03-23 03:14:35,999] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2172570: learning rate 0.0010
[2019-03-23 03:14:37,139] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2173096: loss 0.0155
[2019-03-23 03:14:37,140] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2173096: learning rate 0.0010
[2019-03-23 03:14:38,555] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2173746: loss 0.0634
[2019-03-23 03:14:38,559] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2173746: learning rate 0.0010
[2019-03-23 03:14:38,982] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2173942: loss 0.0215
[2019-03-23 03:14:38,989] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2173943: learning rate 0.0010
[2019-03-23 03:14:39,762] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 8.862008e-24 0.000000e+00], sum to 1.0000
[2019-03-23 03:14:39,772] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1602
[2019-03-23 03:14:39,777] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.46666666666667, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8998577417493949, 6.911200000000001, 6.9112, 121.9260426156618, 656329.5663150832, 656329.5663150827, 176349.9554814312], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2041800.0000, 
sim time next is 2042400.0000, 
raw observation next is [28.53333333333333, 63.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9063810209935762, 6.9112, 6.9112, 121.9260426156618, 660437.3479950965, 660437.3479950965, 177335.2767437428], 
processed observation next is [0.0, 0.6521739130434783, 0.6123456790123456, 0.6300000000000001, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8829762762419702, 0.0, 0.0, 0.8094621288201359, 0.23587048142682016, 0.23587048142682016, 0.34102937835335156], 
reward next is 0.6590, 
noisyNet noise sample is [array([3.1122267], dtype=float32), 0.69188136]. 
=============================================
[2019-03-23 03:14:41,065] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2174895: loss 0.0121
[2019-03-23 03:14:41,069] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2174896: learning rate 0.0010
[2019-03-23 03:14:41,300] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 03:14:41,301] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:14:41,303] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:14:41,304] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:14:41,304] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:14:41,305] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:14:41,306] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:14:41,308] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:14:41,308] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:14:41,309] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:14:41,310] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:14:41,337] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run88
[2019-03-23 03:14:41,366] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run88
[2019-03-23 03:14:41,397] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run88
[2019-03-23 03:14:41,425] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run88
[2019-03-23 03:14:41,450] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run88
[2019-03-23 03:14:51,836] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.7261852], dtype=float32), 0.14611468]
[2019-03-23 03:14:51,838] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [35.81738776333334, 15.902310075, 1.0, 2.0, 0.2483228893049743, 1.0, 2.0, 0.2483228893049743, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 620224.6220865723, 620224.6220865723, 170622.255556348]
[2019-03-23 03:14:51,839] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:14:51,843] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 9.5848131e-18 8.4265406e-14], sampled 0.4252158263875204
[2019-03-23 03:14:55,223] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.7261852], dtype=float32), 0.14611468]
[2019-03-23 03:14:55,223] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.7, 18.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5586599898733058, 6.9112, 6.9112, 121.9260426156618, 398899.5355248585, 398899.5355248585, 103527.6923984618]
[2019-03-23 03:14:55,224] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:14:55,229] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.0040573278094652165
[2019-03-23 03:14:58,069] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.7261852], dtype=float32), 0.14611468]
[2019-03-23 03:14:58,070] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.20132956333333, 53.02710918666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6353457526062816, 6.911199999999999, 6.9112, 121.9260426156618, 472319.3295836167, 472319.3295836172, 134309.9347920319]
[2019-03-23 03:14:58,070] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:14:58,072] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3847666719659566
[2019-03-23 03:14:59,124] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.7261852], dtype=float32), 0.14611468]
[2019-03-23 03:14:59,124] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.39393076833333, 71.462961925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8596946442739678, 6.911199999999999, 6.9112, 121.9260426156618, 640734.4146303671, 640734.4146303675, 159809.1582633316]
[2019-03-23 03:14:59,126] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:14:59,130] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1223507e-37], sampled 0.6383316077104655
[2019-03-23 03:15:04,106] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.7261852], dtype=float32), 0.14611468]
[2019-03-23 03:15:04,109] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [35.60910297, 15.8843631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6877541763783304, 6.911200000000001, 6.9112, 121.9260426156618, 508499.9222406308, 508499.9222406304, 137726.5762605057]
[2019-03-23 03:15:04,113] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:15:04,119] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.10119822920916488
[2019-03-23 03:15:05,895] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.7261852], dtype=float32), 0.14611468]
[2019-03-23 03:15:05,896] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.47099566, 60.61696602333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4895485495148252, 6.911200000000001, 6.9112, 121.9260426156618, 350953.3391732185, 350953.339173218, 110997.4714922078]
[2019-03-23 03:15:05,896] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:15:05,899] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.22356018978711867
[2019-03-23 03:15:09,481] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.7261852], dtype=float32), 0.14611468]
[2019-03-23 03:15:09,481] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.0, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6281865006466054, 6.911200000000001, 6.9112, 121.9260426156618, 466665.9414741698, 466665.9414741693, 133356.7209666549]
[2019-03-23 03:15:09,482] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:15:09,489] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3425782124761504
[2019-03-23 03:15:15,622] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.7261852], dtype=float32), 0.14611468]
[2019-03-23 03:15:15,624] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.779678283048797, 6.911200000000001, 6.9112, 121.9260426156618, 579985.465078437, 579985.4650784365, 157352.2170752288]
[2019-03-23 03:15:15,625] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:15:15,627] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.40034436457282896
[2019-03-23 03:15:37,049] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.7261852], dtype=float32), 0.14611468]
[2019-03-23 03:15:37,050] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.16666666666667, 99.00000000000001, 1.0, 2.0, 0.7003892861184153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 798245.8846198156, 798245.8846198156, 176219.1954761983]
[2019-03-23 03:15:37,051] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:15:37,053] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 8.9627200e-29 1.3064724e-14], sampled 0.9738979498396587
[2019-03-23 03:15:37,055] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 798245.8846198156 W.
[2019-03-23 03:16:24,197] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.7261852], dtype=float32), 0.14611468]
[2019-03-23 03:16:24,198] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.42320867, 71.44311111333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7735880461378281, 6.911199999999999, 6.9112, 121.9260426156618, 576971.1358271821, 576971.1358271824, 155489.9544108055]
[2019-03-23 03:16:24,200] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:16:24,202] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.779243161288229
[2019-03-23 03:16:26,246] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.7261852], dtype=float32), 0.14611468]
[2019-03-23 03:16:26,249] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.01447260666666, 95.23834624, 1.0, 2.0, 0.355867429606651, 1.0, 2.0, 0.355867429606651, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 840827.5613910981, 840827.5613910985, 195738.8461225525]
[2019-03-23 03:16:26,252] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:16:26,253] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9991918e-01 0.0000000e+00 0.0000000e+00 8.0814978e-05 1.1210781e-16], sampled 0.40717488829160087
[2019-03-23 03:16:26,255] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 840827.5613910981 W.
[2019-03-23 03:16:32,506] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8525.3452 2265977827.3189 323.0000
[2019-03-23 03:16:32,828] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8651.3957 2228470093.2318 328.0000
[2019-03-23 03:16:32,862] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8482.9279 2291895338.3121 380.0000
[2019-03-23 03:16:32,964] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8427.3709 2330441194.1571 330.0000
[2019-03-23 03:16:32,998] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7996.8539 2519683421.8383 432.0000
[2019-03-23 03:16:34,015] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2175000, evaluation results [2175000.0, 7996.853850486899, 2519683421.838284, 432.0, 8525.345223279483, 2265977827.31894, 323.0, 8651.395744317137, 2228470093.2317567, 328.0, 8427.370931522115, 2330441194.157138, 330.0, 8482.92790981287, 2291895338.3120675, 380.0]
[2019-03-23 03:16:35,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9999118e-01 5.3330892e-36 3.1931909e-38 8.7726930e-06 0.0000000e+00], sum to 1.0000
[2019-03-23 03:16:35,918] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3589
[2019-03-23 03:16:35,925] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 720723.5012017823 W.
[2019-03-23 03:16:35,930] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.16666666666667, 94.0, 1.0, 2.0, 0.2087868602590049, 1.0, 2.0, 0.2087868602590049, 1.0, 1.0, 0.3326464198175147, 6.9112, 6.9112, 121.94756008, 720723.5012017823, 720723.5012017823, 223494.3586702776], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2782200.0000, 
sim time next is 2782800.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.2004133926136731, 1.0, 2.0, 0.2004133926136731, 1.0, 2.0, 0.3194061444794186, 6.911199999999999, 6.9112, 121.94756008, 693530.3057022255, 693530.305702226, 220729.1464821418], 
processed observation next is [1.0, 0.21739130434782608, 0.4074074074074074, 0.94, 1.0, 1.0, 0.048111181682944176, 1.0, 1.0, 0.048111181682944176, 1.0, 1.0, 0.14925768059927325, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.24768939489365197, 0.24768939489365213, 0.4244791278502727], 
reward next is 0.5755, 
noisyNet noise sample is [array([-0.56007385], dtype=float32), 0.33958867]. 
=============================================
[2019-03-23 03:16:36,117] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2176095: loss 0.0082
[2019-03-23 03:16:36,120] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2176095: learning rate 0.0010
[2019-03-23 03:16:36,134] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.348911e-16 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 03:16:36,140] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7461
[2019-03-23 03:16:36,145] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.38333333333333, 91.33333333333334, 1.0, 2.0, 0.6088597218692657, 1.0, 2.0, 0.6088597218692657, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1388390.29850631, 1388390.29850631, 271101.0817652238], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2196600.0000, 
sim time next is 2197200.0000, 
raw observation next is [24.36666666666667, 91.66666666666667, 1.0, 2.0, 0.6310524552989533, 1.0, 2.0, 0.6310524552989533, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1439044.205128321, 1439044.205128321, 278886.9050526374], 
processed observation next is [1.0, 0.43478260869565216, 0.4580246913580248, 0.9166666666666667, 1.0, 1.0, 0.5607767324987538, 1.0, 1.0, 0.5607767324987538, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5139443589744004, 0.5139443589744004, 0.5363209712550719], 
reward next is 0.4637, 
noisyNet noise sample is [array([-1.32093], dtype=float32), -0.26344454]. 
=============================================
[2019-03-23 03:16:37,989] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2177059: loss 0.0266
[2019-03-23 03:16:37,993] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2177060: learning rate 0.0010
[2019-03-23 03:16:38,648] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2177396: loss 0.0590
[2019-03-23 03:16:38,649] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2177396: learning rate 0.0010
[2019-03-23 03:16:38,950] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2177550: loss 0.0305
[2019-03-23 03:16:38,952] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2177550: learning rate 0.0010
[2019-03-23 03:16:39,651] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2177912: loss 0.0755
[2019-03-23 03:16:39,655] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2177914: learning rate 0.0010
[2019-03-23 03:16:40,298] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:16:40,306] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6496
[2019-03-23 03:16:40,313] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.2, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6910479551688617, 6.9112, 6.9112, 121.9260426156618, 516351.4824249492, 516351.4824249492, 144365.9016832899], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2023200.0000, 
sim time next is 2023800.0000, 
raw observation next is [24.41666666666667, 69.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6961816717629389, 6.911200000000001, 6.9112, 121.9260426156618, 520117.1807673948, 520117.1807673944, 145180.2087295867], 
processed observation next is [0.0, 0.43478260869565216, 0.4598765432098767, 0.6933333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6202270897036736, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18575613598835528, 0.18575613598835516, 0.27919270909535904], 
reward next is 0.7208, 
noisyNet noise sample is [array([-1.3110948], dtype=float32), -0.5894308]. 
=============================================
[2019-03-23 03:16:40,511] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2178353: loss 0.1049
[2019-03-23 03:16:40,514] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2178355: learning rate 0.0010
[2019-03-23 03:16:41,645] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2178936: loss 0.0120
[2019-03-23 03:16:41,648] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2178936: learning rate 0.0010
[2019-03-23 03:16:41,794] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 5.1958866e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 03:16:41,805] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4813
[2019-03-23 03:16:41,812] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1880206.993528073 W.
[2019-03-23 03:16:41,816] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.26666666666667, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9785530182996313, 9.178831985855728, 6.9112, 122.3671100041136, 1880206.993528073, 714775.9883474447, 180232.9432272504], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2167800.0000, 
sim time next is 2168400.0000, 
raw observation next is [24.23333333333333, 89.0, 1.0, 1.0, 0.4906203088557248, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7816776367553611, 6.911199999999999, 6.9112, 121.9246770624549, 1129423.426038249, 1129423.42603825, 253549.6418657709], 
processed observation next is [1.0, 0.08695652173913043, 0.45308641975308633, 0.89, 1.0, 0.5, 0.3935956057806248, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7270970459442013, -8.881784197001253e-17, 0.0, 0.8094530629669174, 0.4033655092993746, 0.40336550929937504, 0.4875954651264825], 
reward next is 0.5124, 
noisyNet noise sample is [array([1.7965063], dtype=float32), 1.6791481]. 
=============================================
[2019-03-23 03:16:41,934] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2179087: loss 0.0134
[2019-03-23 03:16:41,939] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2179088: learning rate 0.0010
[2019-03-23 03:16:42,207] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:16:42,220] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9198
[2019-03-23 03:16:42,226] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.5, 70.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7971571321287091, 6.9112, 6.9112, 121.9260426156618, 592101.8856008622, 592101.8856008622, 159975.5896622414], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2311800.0000, 
sim time next is 2312400.0000, 
raw observation next is [25.4, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7929459077004654, 6.9112, 6.9112, 121.9260426156618, 589056.2479019145, 589056.2479019145, 159412.0243048609], 
processed observation next is [1.0, 0.782608695652174, 0.49629629629629624, 0.71, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7411823846255816, 0.0, 0.0, 0.8094621288201359, 0.2103772313935409, 0.2103772313935409, 0.3065615852016556], 
reward next is 0.6934, 
noisyNet noise sample is [array([-0.20195247], dtype=float32), 1.0019939]. 
=============================================
[2019-03-23 03:16:42,606] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:16:42,611] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0923
[2019-03-23 03:16:42,623] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.66666666666667, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8827662985968827, 6.911200000000001, 6.9112, 121.9260426156618, 645753.6824039025, 645753.682403902, 173728.021069475], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2132400.0000, 
sim time next is 2133000.0000, 
raw observation next is [31.75, 46.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8797118421845408, 6.911200000000001, 6.9112, 121.9260426156618, 643850.1647604437, 643850.1647604433, 173260.3469926669], 
processed observation next is [0.0, 0.6956521739130435, 0.7314814814814815, 0.465, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8496398027306759, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22994648741444418, 0.229946487414444, 0.3331929749858979], 
reward next is 0.6668, 
noisyNet noise sample is [array([1.1619629], dtype=float32), -0.26546532]. 
=============================================
[2019-03-23 03:16:42,637] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.624214]
 [71.576584]
 [71.54434 ]
 [71.45875 ]
 [71.39983 ]], R is [[71.62112427]
 [71.57082367]
 [71.52010345]
 [71.46893311]
 [71.41736603]].
[2019-03-23 03:16:43,386] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2179868: loss 0.0067
[2019-03-23 03:16:43,388] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2179868: learning rate 0.0010
[2019-03-23 03:16:44,113] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.007346e-34 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 03:16:44,113] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9828
[2019-03-23 03:16:44,158] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2180051: loss 0.0031
[2019-03-23 03:16:44,159] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2180051: learning rate 0.0010
[2019-03-23 03:16:44,168] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.96666666666667, 82.33333333333334, 1.0, 2.0, 0.6782915626172741, 1.0, 2.0, 0.6782915626172741, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1546876.480446959, 1546876.480446959, 296028.9984631939], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2209200.0000, 
sim time next is 2209800.0000, 
raw observation next is [27.13333333333333, 81.66666666666666, 1.0, 2.0, 0.6775658326767212, 1.0, 2.0, 0.6775658326767212, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1545219.748541659, 1545219.748541659, 295759.8689797461], 
processed observation next is [1.0, 0.5652173913043478, 0.5604938271604937, 0.8166666666666665, 1.0, 1.0, 0.6161498008056204, 1.0, 1.0, 0.6161498008056204, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5518641959077354, 0.5518641959077354, 0.5687689788072041], 
reward next is 0.4312, 
noisyNet noise sample is [array([-1.5484973], dtype=float32), 2.2384758]. 
=============================================
[2019-03-23 03:16:44,957] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2180322: loss 0.0359
[2019-03-23 03:16:44,966] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2180322: learning rate 0.0010
[2019-03-23 03:16:45,324] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2180562: loss 0.0740
[2019-03-23 03:16:45,328] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2180564: learning rate 0.0010
[2019-03-23 03:16:46,379] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2181132: loss 0.0612
[2019-03-23 03:16:46,380] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2181132: learning rate 0.0010
[2019-03-23 03:16:47,733] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2181831: loss 0.0282
[2019-03-23 03:16:47,736] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2181831: learning rate 0.0010
[2019-03-23 03:16:49,029] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2182498: loss -118.2181
[2019-03-23 03:16:49,031] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2182498: learning rate 0.0010
[2019-03-23 03:16:49,761] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2182868: loss 0.0034
[2019-03-23 03:16:49,762] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2182868: learning rate 0.0010
[2019-03-23 03:16:52,431] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2184237: loss 0.0048
[2019-03-23 03:16:52,433] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2184240: learning rate 0.0010
[2019-03-23 03:16:54,076] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2185082: loss 0.1493
[2019-03-23 03:16:54,078] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2185082: learning rate 0.0010
[2019-03-23 03:16:54,233] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:16:54,240] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1073
[2019-03-23 03:16:54,246] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.2, 44.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6553595797268602, 6.911200000000001, 6.9112, 121.9260426156618, 489248.6588234357, 489248.6588234353, 138448.7340738756], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2403000.0000, 
sim time next is 2403600.0000, 
raw observation next is [28.03333333333333, 44.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6534768393524901, 6.9112, 6.9112, 121.9260426156618, 487723.7987279632, 487723.7987279632, 138067.2831342476], 
processed observation next is [1.0, 0.8260869565217391, 0.5938271604938271, 0.4433333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5668460491906127, 0.0, 0.0, 0.8094621288201359, 0.17418707097427255, 0.17418707097427255, 0.2655140060273993], 
reward next is 0.7345, 
noisyNet noise sample is [array([1.0662886], dtype=float32), 0.12088083]. 
=============================================
[2019-03-23 03:16:54,635] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2185372: loss 0.0307
[2019-03-23 03:16:54,637] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2185373: learning rate 0.0010
[2019-03-23 03:16:54,980] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2185547: loss 0.0104
[2019-03-23 03:16:54,982] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2185547: learning rate 0.0010
[2019-03-23 03:16:55,677] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2185902: loss 0.0273
[2019-03-23 03:16:55,678] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2185902: learning rate 0.0010
[2019-03-23 03:16:56,203] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2186176: loss 0.0122
[2019-03-23 03:16:56,208] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2186176: learning rate 0.0010
[2019-03-23 03:16:57,826] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2187011: loss 0.0203
[2019-03-23 03:16:57,831] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2187013: learning rate 0.0010
[2019-03-23 03:16:58,041] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2187124: loss 0.0134
[2019-03-23 03:16:58,042] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2187124: learning rate 0.0010
[2019-03-23 03:16:59,753] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2188002: loss 0.0252
[2019-03-23 03:16:59,756] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2188003: learning rate 0.0010
[2019-03-23 03:16:59,863] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2188063: loss 0.0570
[2019-03-23 03:16:59,866] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2188063: learning rate 0.0010
[2019-03-23 03:17:00,767] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2188527: loss 0.0061
[2019-03-23 03:17:00,771] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2188528: learning rate 0.0010
[2019-03-23 03:17:00,997] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2188646: loss 0.0283
[2019-03-23 03:17:01,005] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2188647: learning rate 0.0010
[2019-03-23 03:17:01,587] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2188945: loss 0.0556
[2019-03-23 03:17:01,589] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2188945: learning rate 0.0010
[2019-03-23 03:17:02,745] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2189540: loss 0.0870
[2019-03-23 03:17:02,748] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2189542: learning rate 0.0010
[2019-03-23 03:17:04,897] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2190651: loss 0.0141
[2019-03-23 03:17:04,899] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2190652: learning rate 0.0010
[2019-03-23 03:17:04,981] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2190689: loss 0.0523
[2019-03-23 03:17:04,983] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2190689: learning rate 0.0010
[2019-03-23 03:17:07,529] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2191998: loss 0.0038
[2019-03-23 03:17:07,532] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2191999: learning rate 0.0010
[2019-03-23 03:17:09,237] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2192885: loss 0.0324
[2019-03-23 03:17:09,238] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2192886: learning rate 0.0010
[2019-03-23 03:17:09,937] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2193246: loss 0.0699
[2019-03-23 03:17:09,939] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2193246: learning rate 0.0010
[2019-03-23 03:17:10,210] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2193384: loss 0.0747
[2019-03-23 03:17:10,212] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2193385: learning rate 0.0010
[2019-03-23 03:17:10,801] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2193714: loss 0.0170
[2019-03-23 03:17:10,802] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2193714: learning rate 0.0010
[2019-03-23 03:17:10,861] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:17:10,867] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2089
[2019-03-23 03:17:10,870] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.66666666666666, 86.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8478265612029088, 6.9112, 6.9112, 121.9260426156618, 626340.9963300426, 626340.9963300426, 167635.8284109542], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2630400.0000, 
sim time next is 2631000.0000, 
raw observation next is [23.58333333333334, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8356139129789883, 6.9112, 6.9112, 121.9260426156618, 618440.391247483, 618440.391247483, 165711.4021184869], 
processed observation next is [0.0, 0.43478260869565216, 0.4290123456790126, 0.8566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7945173912237354, 0.0, 0.0, 0.8094621288201359, 0.2208715683026725, 0.2208715683026725, 0.31867577330478253], 
reward next is 0.6813, 
noisyNet noise sample is [array([0.44812742], dtype=float32), 0.95810705]. 
=============================================
[2019-03-23 03:17:10,879] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[65.894226]
 [65.73405 ]
 [65.616646]
 [65.56051 ]
 [65.59279 ]], R is [[66.10429382]
 [66.1208725 ]
 [66.13368225]
 [66.14307404]
 [66.1496582 ]].
[2019-03-23 03:17:12,312] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.7414977e-21], sum to 1.0000
[2019-03-23 03:17:12,319] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1585
[2019-03-23 03:17:12,329] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 748246.1342871712 W.
[2019-03-23 03:17:12,337] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.66666666666667, 87.33333333333333, 1.0, 2.0, 0.2188468136774402, 1.0, 2.0, 0.2188468136774402, 1.0, 2.0, 0.3484112547176205, 6.9112, 6.9112, 121.94756008, 748246.1342871712, 748246.1342871712, 226849.9997230172], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2760000.0000, 
sim time next is 2760600.0000, 
raw observation next is [25.58333333333333, 88.16666666666667, 1.0, 2.0, 0.2191569943314781, 1.0, 2.0, 0.2191569943314781, 1.0, 2.0, 0.3489050724207275, 6.911200000000001, 6.9112, 121.94756008, 749307.1727812209, 749307.1727812204, 226954.6122865356], 
processed observation next is [0.0, 0.9565217391304348, 0.5030864197530862, 0.8816666666666667, 1.0, 1.0, 0.07042499325175963, 1.0, 1.0, 0.07042499325175963, 1.0, 1.0, 0.18613134052590935, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2676097045647217, 0.26760970456472155, 0.4364511774741069], 
reward next is 0.5635, 
noisyNet noise sample is [array([0.4365416], dtype=float32), -2.2706926]. 
=============================================
[2019-03-23 03:17:12,506] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2194668: loss 0.0564
[2019-03-23 03:17:12,508] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2194670: learning rate 0.0010
[2019-03-23 03:17:12,852] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2194830: loss -17.7556
[2019-03-23 03:17:12,855] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2194830: learning rate 0.0010
[2019-03-23 03:17:12,939] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2194869: loss 0.0175
[2019-03-23 03:17:12,941] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2194870: learning rate 0.0010
[2019-03-23 03:17:12,978] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.1573573e-20], sum to 1.0000
[2019-03-23 03:17:12,985] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9727
[2019-03-23 03:17:12,997] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 703627.3806175201 W.
[2019-03-23 03:17:13,009] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.46666666666667, 91.33333333333334, 1.0, 2.0, 0.3084558333460747, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4910895125158033, 6.911199999999999, 6.9112, 121.9260426156618, 703627.3806175201, 703627.3806175205, 197521.9218811871], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2770800.0000, 
sim time next is 2771400.0000, 
raw observation next is [24.58333333333333, 90.66666666666666, 1.0, 2.0, 0.6130529958086993, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 703871.1012615726, 703871.1012615726, 160593.5432881495], 
processed observation next is [1.0, 0.043478260869565216, 0.46604938271604923, 0.9066666666666666, 1.0, 1.0, 0.5393488045341659, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25138253616484735, 0.25138253616484735, 0.30883373709259515], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.53108287], dtype=float32), 0.2328425]. 
=============================================
[2019-03-23 03:17:13,842] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.2340994e-19], sum to 1.0000
[2019-03-23 03:17:13,851] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6322
[2019-03-23 03:17:13,859] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 703824.9264379553 W.
[2019-03-23 03:17:13,862] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.23333333333333, 92.66666666666667, 1.0, 2.0, 0.3087906835738067, 1.0, 1.0, 0.3087906835738067, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 703824.9264379553, 703824.9264379553, 182583.4080402232], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2769600.0000, 
sim time next is 2770200.0000, 
raw observation next is [24.35, 92.0, 1.0, 2.0, 0.2057133877968814, 1.0, 2.0, 0.2057133877968814, 1.0, 1.0, 0.3275024129899512, 6.9112, 6.9112, 121.94756008, 703321.822182022, 703321.822182022, 222469.9704929034], 
processed observation next is [1.0, 0.043478260869565216, 0.4574074074074075, 0.92, 1.0, 1.0, 0.05442069975819213, 1.0, 1.0, 0.05442069975819213, 1.0, 0.5, 0.15937801623743897, 0.0, 0.0, 0.8096049824067558, 0.25118636506500785, 0.25118636506500785, 0.42782686633250655], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04118828], dtype=float32), 1.0560528]. 
=============================================
[2019-03-23 03:17:14,888] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2195756: loss 0.1597
[2019-03-23 03:17:14,895] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2195757: learning rate 0.0010
[2019-03-23 03:17:14,975] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2195797: loss 0.1538
[2019-03-23 03:17:14,977] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2195797: learning rate 0.0010
[2019-03-23 03:17:15,836] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2196189: loss 0.1480
[2019-03-23 03:17:15,836] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2196189: learning rate 0.0010
[2019-03-23 03:17:16,302] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2196398: loss 0.3307
[2019-03-23 03:17:16,304] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2196398: learning rate 0.0010
[2019-03-23 03:17:18,625] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2197466: loss 73.1686
[2019-03-23 03:17:18,629] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2197466: learning rate 0.0010
[2019-03-23 03:17:19,966] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2198075: loss 98.0696
[2019-03-23 03:17:19,967] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2198075: learning rate 0.0010
[2019-03-23 03:17:20,636] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.2143528e-24], sum to 1.0000
[2019-03-23 03:17:20,649] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9155
[2019-03-23 03:17:20,658] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 733875.3117054786 W.
[2019-03-23 03:17:20,665] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.33333333333334, 88.66666666666666, 1.0, 2.0, 0.6439368966885308, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 733875.3117054786, 733875.3117054786, 165800.095630413], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2943600.0000, 
sim time next is 2944200.0000, 
raw observation next is [25.41666666666666, 87.33333333333333, 1.0, 2.0, 0.2129965377336241, 1.0, 1.0, 0.2129965377336241, 1.0, 1.0, 0.3390974248848795, 6.9112, 6.9112, 121.94756008, 728234.3037990388, 728234.3037990388, 224886.9974764401], 
processed observation next is [1.0, 0.043478260869565216, 0.49691358024691334, 0.8733333333333333, 1.0, 1.0, 0.06309111634955249, 1.0, 0.5, 0.06309111634955249, 1.0, 0.5, 0.17387178110609933, 0.0, 0.0, 0.8096049824067558, 0.2600836799282281, 0.2600836799282281, 0.43247499514700016], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5953904], dtype=float32), 0.2816224]. 
=============================================
[2019-03-23 03:17:21,784] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2198899: loss 3.7875
[2019-03-23 03:17:21,789] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2198900: learning rate 0.0010
[2019-03-23 03:17:22,036] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2199017: loss 166.7851
[2019-03-23 03:17:22,038] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2199017: learning rate 0.0010
[2019-03-23 03:17:24,203] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 03:17:24,207] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:17:24,209] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:17:24,210] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:17:24,212] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:17:24,213] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:17:24,215] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:17:24,215] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:17:24,211] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:17:24,216] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:17:24,218] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:17:24,237] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run89
[2019-03-23 03:17:24,266] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run89
[2019-03-23 03:17:24,297] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run89
[2019-03-23 03:17:24,298] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run89
[2019-03-23 03:17:24,333] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run89
[2019-03-23 03:17:32,175] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.6200511], dtype=float32), 0.095473215]
[2019-03-23 03:17:32,177] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.23333333333333, 74.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5358203078951937, 6.911200000000001, 6.9112, 121.9260426156618, 382587.2681479158, 382587.2681479153, 111176.0200989]
[2019-03-23 03:17:32,178] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:17:32,180] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6265801643710631
[2019-03-23 03:17:34,305] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.6200511], dtype=float32), 0.095473215]
[2019-03-23 03:17:34,306] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.620694985, 59.89497305166667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7080503061840789, 6.9112, 6.9112, 121.9260426156618, 527918.458063365, 527918.458063365, 143097.4189944704]
[2019-03-23 03:17:34,308] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:17:34,310] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.840644922055776
[2019-03-23 03:18:37,137] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.6200511], dtype=float32), 0.095473215]
[2019-03-23 03:18:37,138] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.25, 92.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9424901924086654, 6.9112, 6.9112, 121.9260426156618, 683084.6467424227, 683084.6467424227, 182806.8956211357]
[2019-03-23 03:18:37,139] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:18:37,140] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.05804119879526326
[2019-03-23 03:19:06,853] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.6200511], dtype=float32), 0.095473215]
[2019-03-23 03:19:06,856] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.83333333333333, 74.0, 1.0, 2.0, 0.2031281859038662, 1.0, 2.0, 0.2031281859038662, 1.0, 2.0, 0.3233866873821231, 6.911200000000001, 6.9112, 121.94756008, 694479.1679065586, 694479.1679065581, 221619.1703559454]
[2019-03-23 03:19:06,858] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:19:06,860] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.6500553e-05 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.9998355e-01], sampled 0.01837528439485614
[2019-03-23 03:19:15,451] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8291.8951 2436997800.4076 346.0000
[2019-03-23 03:19:15,475] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8441.8858 2377874604.3887 324.0000
[2019-03-23 03:19:15,713] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8383.0544 2388231221.8604 345.0000
[2019-03-23 03:19:15,827] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8518.0731 2325805750.5290 314.0000
[2019-03-23 03:19:15,864] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7840.9562 2631559628.4167 450.0000
[2019-03-23 03:19:16,880] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2200000, evaluation results [2200000.0, 7840.956208641725, 2631559628.4166713, 450.0, 8441.88577557262, 2377874604.3886847, 324.0, 8518.073133457987, 2325805750.5290203, 314.0, 8291.895146389164, 2436997800.40757, 346.0, 8383.054422273643, 2388231221.8603992, 345.0]
[2019-03-23 03:19:17,299] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2200222: loss 59.9516
[2019-03-23 03:19:17,300] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2200222: learning rate 0.0010
[2019-03-23 03:19:18,824] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:19:18,831] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9745
[2019-03-23 03:19:18,835] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1402392.48660399 W.
[2019-03-23 03:19:18,843] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 89.0, 1.0, 2.0, 0.614994574721762, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9790913919320483, 6.9112, 6.9112, 121.9260426156618, 1402392.48660399, 1402392.48660399, 299738.366992035], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2894400.0000, 
sim time next is 2895000.0000, 
raw observation next is [25.0, 89.0, 1.0, 2.0, 0.6080153190129325, 1.0, 1.0, 0.6080153190129325, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1386463.05347645, 1386463.05347645, 270808.4677688471], 
processed observation next is [1.0, 0.5217391304347826, 0.48148148148148145, 0.89, 1.0, 1.0, 0.533351570253491, 1.0, 0.5, 0.533351570253491, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4951653762415893, 0.4951653762415893, 0.5207855149400906], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0879809], dtype=float32), 0.56314236]. 
=============================================
[2019-03-23 03:19:18,854] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2201015: loss 36.3611
[2019-03-23 03:19:18,854] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[37.953262]
 [38.21755 ]
 [38.92127 ]
 [37.730843]
 [38.661938]], R is [[36.97077942]
 [36.6010704 ]
 [36.23506165]
 [35.87271118]
 [35.51398468]].
[2019-03-23 03:19:18,855] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2201015: learning rate 0.0010
[2019-03-23 03:19:19,673] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2201435: loss 82.5967
[2019-03-23 03:19:19,675] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2201436: learning rate 0.0010
[2019-03-23 03:19:19,849] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2201521: loss -51.2627
[2019-03-23 03:19:19,851] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2201521: learning rate 0.0010
[2019-03-23 03:19:20,397] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2201810: loss 8.8089
[2019-03-23 03:19:20,399] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2201810: learning rate 0.0010
[2019-03-23 03:19:21,626] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2202437: loss 0.0378
[2019-03-23 03:19:21,627] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2202437: learning rate 0.0010
[2019-03-23 03:19:22,398] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2202835: loss 1.2895
[2019-03-23 03:19:22,400] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2202835: learning rate 0.0010
[2019-03-23 03:19:22,717] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2202996: loss 2.3534
[2019-03-23 03:19:22,719] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2202997: learning rate 0.0010
[2019-03-23 03:19:24,120] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 0. 0. 0. 1.], sum to 1.0000
[2019-03-23 03:19:24,131] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4392
[2019-03-23 03:19:24,136] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.5, 84.0, 1.0, 2.0, 0.2265418125019119, 1.0, 2.0, 0.2265418125019119, 1.0, 2.0, 0.3606619434547954, 6.9112, 6.9112, 121.94756008, 774568.9380286119, 774568.9380286119, 229461.1330128809], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3009600.0000, 
sim time next is 3010200.0000, 
raw observation next is [26.25, 85.66666666666667, 1.0, 2.0, 0.2249534186831598, 1.0, 2.0, 0.2249534186831598, 1.0, 2.0, 0.3581331687649667, 6.911199999999999, 6.9112, 121.94756008, 769135.3376689163, 769135.3376689167, 228919.4331223868], 
processed observation next is [1.0, 0.8695652173913043, 0.5277777777777778, 0.8566666666666667, 1.0, 1.0, 0.07732549843233309, 1.0, 1.0, 0.07732549843233309, 1.0, 1.0, 0.19766646095620835, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.27469119202461295, 0.2746911920246131, 0.4402296790815131], 
reward next is 0.5598, 
noisyNet noise sample is [array([0.77024204], dtype=float32), -0.04209707]. 
=============================================
[2019-03-23 03:19:24,231] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2203766: loss 0.9735
[2019-03-23 03:19:24,232] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2203766: learning rate 0.0010
[2019-03-23 03:19:24,506] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2203908: loss -14.7120
[2019-03-23 03:19:24,509] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2203908: learning rate 0.0010
[2019-03-23 03:19:24,995] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2204163: loss 0.1316
[2019-03-23 03:19:24,997] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2204163: learning rate 0.0010
[2019-03-23 03:19:25,562] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2204458: loss 2.6391
[2019-03-23 03:19:25,564] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2204459: learning rate 0.0010
[2019-03-23 03:19:27,087] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2205249: loss 0.0107
[2019-03-23 03:19:27,088] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2205249: learning rate 0.0010
[2019-03-23 03:19:27,894] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.8705724e-16 5.3657839e-22 4.1613761e-38 9.2483822e-16], sum to 1.0000
[2019-03-23 03:19:27,899] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2530
[2019-03-23 03:19:27,910] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1878200.764002911 W.
[2019-03-23 03:19:27,914] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.85, 32.0, 1.0, 2.0, 0.5489461462189935, 1.0, 2.0, 0.5489461462189935, 1.0, 2.0, 0.873940142708497, 6.9112, 6.9112, 121.94756008, 1878200.764002911, 1878200.764002911, 368261.3616319006], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3169800.0000, 
sim time next is 3170400.0000, 
raw observation next is [34.8, 32.0, 1.0, 2.0, 0.8168096377884029, 1.0, 2.0, 0.8168096377884029, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1877275.970788514, 1877275.970788514, 351503.4981364964], 
processed observation next is [1.0, 0.6956521739130435, 0.8444444444444443, 0.32, 1.0, 1.0, 0.7819162354623843, 1.0, 1.0, 0.7819162354623843, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6704557038530408, 0.6704557038530408, 0.6759682656471084], 
reward next is 0.3240, 
noisyNet noise sample is [array([1.2617259], dtype=float32), -0.54657924]. 
=============================================
[2019-03-23 03:19:28,265] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2205866: loss 0.0837
[2019-03-23 03:19:28,271] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2205867: learning rate 0.0010
[2019-03-23 03:19:30,069] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2206790: loss 0.0566
[2019-03-23 03:19:30,071] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2206791: learning rate 0.0010
[2019-03-23 03:19:30,592] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2207060: loss -100.0500
[2019-03-23 03:19:30,597] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2207061: learning rate 0.0010
[2019-03-23 03:19:31,759] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1026917e-25 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 03:19:31,769] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8935
[2019-03-23 03:19:31,774] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.86666666666667, 72.66666666666666, 1.0, 2.0, 0.2320462621696212, 1.0, 2.0, 0.2320462621696212, 1.0, 2.0, 0.3694252065931989, 6.9112, 6.9112, 121.94756008, 793398.9363866837, 793398.9363866837, 231349.2654204693], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3343200.0000, 
sim time next is 3343800.0000, 
raw observation next is [28.83333333333333, 73.33333333333334, 1.0, 2.0, 0.2342560539296375, 1.0, 2.0, 0.2342560539296375, 1.0, 2.0, 0.372943267043038, 6.911200000000001, 6.9112, 121.94756008, 800958.4734719732, 800958.4734719727, 232112.0319012829], 
processed observation next is [0.0, 0.6956521739130435, 0.6234567901234566, 0.7333333333333334, 1.0, 1.0, 0.0884000642019494, 1.0, 1.0, 0.0884000642019494, 1.0, 1.0, 0.21617908380379747, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.28605659766856184, 0.2860565976685617, 0.4463692921178517], 
reward next is 0.5536, 
noisyNet noise sample is [array([-0.36203036], dtype=float32), -0.18718916]. 
=============================================
[2019-03-23 03:19:32,487] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2208026: loss 0.0291
[2019-03-23 03:19:32,489] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2208026: learning rate 0.0010
[2019-03-23 03:19:33,860] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2208734: loss 0.0196
[2019-03-23 03:19:33,862] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2208735: learning rate 0.0010
[2019-03-23 03:19:35,036] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2209333: loss 0.0443
[2019-03-23 03:19:35,037] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2209333: learning rate 0.0010
[2019-03-23 03:19:35,053] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2209342: loss 0.0297
[2019-03-23 03:19:35,055] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2209342: learning rate 0.0010
[2019-03-23 03:19:35,532] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2209588: loss 0.0036
[2019-03-23 03:19:35,533] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2209588: learning rate 0.0010
[2019-03-23 03:19:37,163] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.2419983e-13], sum to 1.0000
[2019-03-23 03:19:37,169] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4286
[2019-03-23 03:19:37,176] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 724965.9137733532 W.
[2019-03-23 03:19:37,182] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 63.0, 1.0, 2.0, 0.3180615323370536, 1.0, 2.0, 0.3180615323370536, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 724965.9137733532, 724965.9137733537, 184851.5792588306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3258000.0000, 
sim time next is 3258600.0000, 
raw observation next is [29.75, 60.66666666666666, 1.0, 2.0, 0.6284617603346545, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716230.5297351296, 716230.5297351296, 163041.0698194133], 
processed observation next is [0.0, 0.7391304347826086, 0.6574074074074074, 0.6066666666666666, 1.0, 1.0, 0.5576925718269696, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25579661776254625, 0.25579661776254625, 0.3135405188834871], 
reward next is 0.6865, 
noisyNet noise sample is [array([0.87619275], dtype=float32), -0.10303515]. 
=============================================
[2019-03-23 03:19:37,607] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2210666: loss 5.1388
[2019-03-23 03:19:37,608] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2210666: learning rate 0.0010
[2019-03-23 03:19:37,673] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2210701: loss 0.0012
[2019-03-23 03:19:37,675] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2210701: learning rate 0.0010
[2019-03-23 03:19:38,090] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2210907: loss 0.0013
[2019-03-23 03:19:38,091] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2210908: learning rate 0.0010
[2019-03-23 03:19:39,712] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2211740: loss 0.0032
[2019-03-23 03:19:39,714] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2211740: learning rate 0.0010
[2019-03-23 03:19:39,884] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2211827: loss 0.0074
[2019-03-23 03:19:39,887] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2211828: learning rate 0.0010
[2019-03-23 03:19:40,346] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2212062: loss 0.0037
[2019-03-23 03:19:40,347] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2212063: learning rate 0.0010
[2019-03-23 03:19:40,882] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2212340: loss 0.0229
[2019-03-23 03:19:40,884] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2212340: learning rate 0.0010
[2019-03-23 03:19:43,174] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2213510: loss 3.6225
[2019-03-23 03:19:43,175] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2213511: learning rate 0.0010
[2019-03-23 03:19:44,257] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:19:44,264] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5674
[2019-03-23 03:19:44,270] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.08333333333333, 82.33333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9144487637896891, 6.9112, 6.9112, 121.9260426156618, 665290.3077185291, 665290.3077185291, 178590.4074198496], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3528600.0000, 
sim time next is 3529200.0000, 
raw observation next is [25.46666666666667, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9161791808962828, 6.9112, 6.9112, 121.9260426156618, 668813.3748287937, 668813.3748287937, 178435.1118052208], 
processed observation next is [1.0, 0.8695652173913043, 0.4987654320987655, 0.8066666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8952239761203534, 0.0, 0.0, 0.8094621288201359, 0.23886191958171205, 0.23886191958171205, 0.3431444457792708], 
reward next is 0.6569, 
noisyNet noise sample is [array([-2.1609511], dtype=float32), 0.13175754]. 
=============================================
[2019-03-23 03:19:44,318] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2214103: loss 4.3677
[2019-03-23 03:19:44,319] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2214103: learning rate 0.0010
[2019-03-23 03:19:45,925] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2214919: loss 0.0018
[2019-03-23 03:19:45,926] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2214919: learning rate 0.0010
[2019-03-23 03:19:46,447] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2215193: loss 344.0859
[2019-03-23 03:19:46,450] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2215193: learning rate 0.0010
[2019-03-23 03:19:48,497] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2216218: loss 2.8426
[2019-03-23 03:19:48,498] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2216218: learning rate 0.0010
[2019-03-23 03:19:49,790] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2216879: loss 3.8161
[2019-03-23 03:19:49,794] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2216881: learning rate 0.0010
[2019-03-23 03:19:50,858] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2217429: loss 1.5761
[2019-03-23 03:19:50,859] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2217429: learning rate 0.0010
[2019-03-23 03:19:50,860] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2217429: loss 1.0980
[2019-03-23 03:19:50,862] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2217430: learning rate 0.0010
[2019-03-23 03:19:51,027] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2217516: loss 3.6464
[2019-03-23 03:19:51,030] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2217516: learning rate 0.0010
[2019-03-23 03:19:52,726] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:19:52,733] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1775
[2019-03-23 03:19:52,741] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1023631.524690147 W.
[2019-03-23 03:19:52,744] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.33333333333334, 80.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9575555793428432, 7.514706717205551, 6.9112, 121.9982811843335, 1023631.524690147, 714399.0395245847, 177324.5059956925], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3550200.0000, 
sim time next is 3550800.0000, 
raw observation next is [23.06666666666667, 84.66666666666666, 1.0, 1.0, 0.2159888216997785, 1.0, 1.0, 0.2159888216997785, 1.0, 2.0, 0.3463114883789318, 6.9112, 6.9112, 121.94756008, 765829.4011445136, 765829.4011445136, 225635.7348036343], 
processed observation next is [1.0, 0.08695652173913043, 0.40987654320987665, 0.8466666666666666, 1.0, 0.5, 0.06665335916640298, 1.0, 0.5, 0.06665335916640298, 1.0, 1.0, 0.1828893604736647, 0.0, 0.0, 0.8096049824067558, 0.27351050040875485, 0.27351050040875485, 0.43391487462237366], 
reward next is 0.5661, 
noisyNet noise sample is [array([-0.7210451], dtype=float32), -0.2102838]. 
=============================================
[2019-03-23 03:19:53,286] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2218802: loss 5.5258
[2019-03-23 03:19:53,290] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2218802: learning rate 0.0010
[2019-03-23 03:19:53,448] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2218873: loss 62.5199
[2019-03-23 03:19:53,450] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2218874: learning rate 0.0010
[2019-03-23 03:19:53,708] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2218993: loss 1.1218
[2019-03-23 03:19:53,712] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2218993: learning rate 0.0010
[2019-03-23 03:19:54,204] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:19:54,214] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2365
[2019-03-23 03:19:54,221] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1013814.323714206 W.
[2019-03-23 03:19:54,227] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 87.0, 1.0, 2.0, 0.4371751655581801, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6972913014943494, 6.911199999999999, 6.9112, 121.9260426156618, 1013814.323714206, 1013814.323714206, 235538.4961699448], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3588000.0000, 
sim time next is 3588600.0000, 
raw observation next is [24.0, 88.0, 1.0, 2.0, 0.3009703256377124, 1.0, 1.0, 0.3009703256377124, 1.0, 2.0, 0.4792434861303051, 6.9112, 6.9112, 121.94756008, 1032718.413585893, 1032718.413585893, 256442.0949812945], 
processed observation next is [1.0, 0.5217391304347826, 0.4444444444444444, 0.88, 1.0, 1.0, 0.16782181623537193, 1.0, 0.5, 0.16782181623537193, 1.0, 1.0, 0.34905435766288134, 0.0, 0.0, 0.8096049824067558, 0.36882800485210465, 0.36882800485210465, 0.4931578749640279], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.1510941], dtype=float32), -1.4620807]. 
=============================================
[2019-03-23 03:19:55,275] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2219706: loss 1.3287
[2019-03-23 03:19:55,278] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2219706: learning rate 0.0010
[2019-03-23 03:19:55,498] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2219805: loss 0.2546
[2019-03-23 03:19:55,502] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2219807: learning rate 0.0010
[2019-03-23 03:19:56,233] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.72923666 0.         0.         0.         0.27076334], sum to 1.0000
[2019-03-23 03:19:56,238] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2220147: loss 1.5766
[2019-03-23 03:19:56,241] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2220147: learning rate 0.0010
[2019-03-23 03:19:56,243] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5116
[2019-03-23 03:19:56,252] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 752849.012766681 W.
[2019-03-23 03:19:56,259] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.05, 94.0, 1.0, 2.0, 0.2201924015777288, 1.0, 2.0, 0.2201924015777288, 1.0, 2.0, 0.3505534744776184, 6.9112, 6.9112, 121.94756008, 752849.012766681, 752849.012766681, 227304.2068697598], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3709800.0000, 
sim time next is 3710400.0000, 
raw observation next is [25.06666666666667, 94.0, 1.0, 2.0, 0.2222162755670643, 1.0, 2.0, 0.2222162755670643, 1.0, 2.0, 0.3537755477816148, 6.911200000000001, 6.9112, 121.94756008, 759772.1695928263, 759772.1695928258, 227989.2787130012], 
processed observation next is [1.0, 0.9565217391304348, 0.4839506172839507, 0.94, 1.0, 1.0, 0.0740669947226956, 1.0, 1.0, 0.0740669947226956, 1.0, 1.0, 0.19221943472701847, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2713472034260094, 0.2713472034260092, 0.4384409206019254], 
reward next is 0.5616, 
noisyNet noise sample is [array([0.62721497], dtype=float32), -0.041960258]. 
=============================================
[2019-03-23 03:19:56,772] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2220389: loss 0.1744
[2019-03-23 03:19:56,775] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2220390: learning rate 0.0010
[2019-03-23 03:19:59,402] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2221590: loss 28.5543
[2019-03-23 03:19:59,404] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2221590: learning rate 0.0010
[2019-03-23 03:19:59,521] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:19:59,526] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9198
[2019-03-23 03:19:59,532] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 815254.8512396492 W.
[2019-03-23 03:19:59,535] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.3576525993318851, 1.0, 2.0, 0.3576525993318851, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 815254.8512396492, 815254.8512396492, 194872.5154091632], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4461000.0000, 
sim time next is 4461600.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.3575884346456044, 0.0, 1.0, 0.0, 1.0, 1.0, 0.56929243379808, 6.911200000000001, 6.9112, 121.9260426156618, 815108.5126218502, 815108.5126218498, 211377.4799457828], 
processed observation next is [0.0, 0.6521739130434783, 0.6666666666666666, 0.7, 1.0, 1.0, 0.23522432695905288, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4616155422476, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29111018307923225, 0.2911101830792321, 0.40649515374189], 
reward next is 0.5935, 
noisyNet noise sample is [array([-0.8699989], dtype=float32), 1.2145618]. 
=============================================
[2019-03-23 03:20:00,618] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2222143: loss 99.0910
[2019-03-23 03:20:00,620] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2222144: learning rate 0.0010
[2019-03-23 03:20:01,195] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.9971113  0.         0.         0.         0.00288868], sum to 1.0000
[2019-03-23 03:20:01,203] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6389
[2019-03-23 03:20:01,214] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 766170.1390766624 W.
[2019-03-23 03:20:01,219] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.83333333333334, 59.0, 1.0, 2.0, 0.3361298751750711, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5351297082644988, 6.911199999999999, 6.9112, 121.9260426156618, 766170.1390766624, 766170.1390766628, 205209.8729835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3791400.0000, 
sim time next is 3792000.0000, 
raw observation next is [30.66666666666667, 59.0, 1.0, 2.0, 0.669489475163272, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763011.3027412394, 763011.3027412394, 170446.6277014769], 
processed observation next is [1.0, 0.9130434782608695, 0.6913580246913582, 0.59, 1.0, 1.0, 0.6065350894800856, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2725040366932998, 0.2725040366932998, 0.32778197634899403], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5169093], dtype=float32), -0.6433219]. 
=============================================
[2019-03-23 03:20:01,233] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[45.438465]
 [45.09976 ]
 [44.949444]
 [45.54273 ]
 [45.064514]], R is [[45.18082428]
 [45.3343811 ]
 [44.88103867]
 [45.05373001]
 [45.23968124]].
[2019-03-23 03:20:02,443] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2222975: loss 5.7932
[2019-03-23 03:20:02,447] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2222975: learning rate 0.0010
[2019-03-23 03:20:02,645] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2223066: loss 28.0707
[2019-03-23 03:20:02,647] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2223066: learning rate 0.0010
[2019-03-23 03:20:05,197] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2224227: loss 0.6060
[2019-03-23 03:20:05,202] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2224227: learning rate 0.0010
[2019-03-23 03:20:05,931] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:20:05,939] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7306
[2019-03-23 03:20:05,943] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.91666666666666, 95.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8738003734273139, 6.9112, 6.9112, 121.9260426156618, 642579.8966563198, 642579.8966563198, 171793.9165764659], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4575000.0000, 
sim time next is 4575600.0000, 
raw observation next is [22.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.876086033727478, 6.911200000000001, 6.9112, 121.9260426156618, 644049.208679685, 644049.2086796846, 172143.727768486], 
processed observation next is [0.0, 1.0, 0.4037037037037037, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8451075421593474, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23001757452845895, 0.23001757452845878, 0.3310456303240115], 
reward next is 0.6690, 
noisyNet noise sample is [array([-0.1052133], dtype=float32), 0.10079034]. 
=============================================
[2019-03-23 03:20:06,790] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2224962: loss -41.4067
[2019-03-23 03:20:06,794] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2224963: learning rate 0.0010
[2019-03-23 03:20:06,887] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 03:20:06,891] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:20:06,892] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:20:06,893] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:20:06,894] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:20:06,894] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:20:06,895] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:20:06,896] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:20:06,897] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:20:06,898] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:20:06,899] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:20:06,921] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run90
[2019-03-23 03:20:06,956] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run90
[2019-03-23 03:20:06,957] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run90
[2019-03-23 03:20:07,011] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run90
[2019-03-23 03:20:07,044] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run90
[2019-03-23 03:20:29,918] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.6525582], dtype=float32), 0.10439429]
[2019-03-23 03:20:29,919] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.9, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6491306008966338, 6.911200000000001, 6.9112, 121.9260426156618, 483148.8994580892, 483148.8994580887, 136153.1880884294]
[2019-03-23 03:20:29,922] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:20:29,925] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7110887567598326
[2019-03-23 03:20:30,134] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.6525582], dtype=float32), 0.10439429]
[2019-03-23 03:20:30,135] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.16666666666667, 84.33333333333334, 1.0, 2.0, 0.5165467012120348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 648033.2477078073, 648033.2477078073, 146402.576627902]
[2019-03-23 03:20:30,136] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:20:30,143] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5572297235375537
[2019-03-23 03:21:02,209] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.6525582], dtype=float32), 0.10439429]
[2019-03-23 03:21:02,210] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.66088747333333, 66.45062334333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8578624475732296, 6.9112, 6.9112, 121.9260426156618, 630053.6410124479, 630053.6410124479, 169935.8366642847]
[2019-03-23 03:21:02,212] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:21:02,217] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.05883990673847572
[2019-03-23 03:21:11,920] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.6525582], dtype=float32), 0.10439429]
[2019-03-23 03:21:11,922] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.06666666666667, 91.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9220313579167114, 6.9112, 6.9112, 121.9260426156618, 672625.6280909295, 672625.6280909295, 179308.7919581498]
[2019-03-23 03:21:11,924] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:21:11,927] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3430706088226132
[2019-03-23 03:21:21,662] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.6525582], dtype=float32), 0.10439429]
[2019-03-23 03:21:21,663] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.0, 100.0, 1.0, 2.0, 0.2550993097800886, 1.0, 2.0, 0.2550993097800886, 1.0, 2.0, 0.4061264091744086, 6.911199999999999, 6.9112, 121.94756008, 872265.4055055724, 872265.4055055729, 239440.8759801727]
[2019-03-23 03:21:21,664] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:21:21,671] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.01821237 0.         0.         0.         0.9817877 ], sampled 0.38311109967626833
[2019-03-23 03:21:41,006] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.6525582], dtype=float32), 0.10439429]
[2019-03-23 03:21:41,008] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.0, 89.0, 1.0, 2.0, 0.6659243175535119, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758946.112255986, 758946.112255986, 169793.6490486377]
[2019-03-23 03:21:41,008] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:21:41,010] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.999813e-01 0.000000e+00 0.000000e+00 0.000000e+00 1.869568e-05], sampled 0.9305322609674378
[2019-03-23 03:21:41,011] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 758946.112255986 W.
[2019-03-23 03:21:42,280] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.6525582], dtype=float32), 0.10439429]
[2019-03-23 03:21:42,283] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.6, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7087842486397962, 6.911200000000001, 6.9112, 121.9260426156618, 529529.9694260817, 529529.9694260813, 146595.2254439498]
[2019-03-23 03:21:42,284] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:21:42,285] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.09360770063576784
[2019-03-23 03:21:58,252] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7881.4586 2605391285.0963 448.0000
[2019-03-23 03:21:58,358] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8354.4079 2405581404.5557 354.0000
[2019-03-23 03:21:58,360] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8408.8076 2351595082.6884 418.0000
[2019-03-23 03:21:58,362] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8594.3717 2283492809.1858 353.0000
[2019-03-23 03:21:58,365] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8486.7850 2343578165.3015 330.0000
[2019-03-23 03:21:59,386] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2225000, evaluation results [2225000.0, 7881.458558296895, 2605391285.0963416, 448.0, 8486.78500141062, 2343578165.3014746, 330.0, 8594.37173524558, 2283492809.185824, 353.0, 8354.407923657955, 2405581404.5556517, 354.0, 8408.80759381858, 2351595082.688398, 418.0]
[2019-03-23 03:22:00,351] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2225496: loss -70.6399
[2019-03-23 03:22:00,354] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2225496: learning rate 0.0010
[2019-03-23 03:22:00,450] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2225549: loss 11.0273
[2019-03-23 03:22:00,451] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2225549: learning rate 0.0010
[2019-03-23 03:22:00,516] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2225580: loss -58.8505
[2019-03-23 03:22:00,522] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2225580: learning rate 0.0010
[2019-03-23 03:22:02,440] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7066856e-08 5.5892001e-31 2.1516179e-30 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-23 03:22:02,446] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3561
[2019-03-23 03:22:02,450] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.01666666666667, 33.5, 1.0, 2.0, 0.4826902638002256, 1.0, 2.0, 0.4826902638002256, 1.0, 1.0, 0.768718446807324, 6.9112, 6.9112, 121.94756008, 1660278.779921899, 1660278.779921899, 335233.3288701138], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4204200.0000, 
sim time next is 4204800.0000, 
raw observation next is [34.0, 34.0, 1.0, 2.0, 0.4785507297652853, 1.0, 2.0, 0.4785507297652853, 1.0, 2.0, 0.7618963592737554, 6.9112, 6.9112, 121.94756008, 1638462.325443927, 1638462.325443927, 333196.3380798392], 
processed observation next is [1.0, 0.6956521739130435, 0.8148148148148148, 0.34, 1.0, 1.0, 0.37922705924438727, 1.0, 1.0, 0.37922705924438727, 1.0, 1.0, 0.7023704490921941, 0.0, 0.0, 0.8096049824067558, 0.5851651162299739, 0.5851651162299739, 0.6407621886150754], 
reward next is 0.3592, 
noisyNet noise sample is [array([-0.79023886], dtype=float32), 1.1803373]. 
=============================================
[2019-03-23 03:22:02,813] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2226766: loss 310.2147
[2019-03-23 03:22:02,816] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2226766: learning rate 0.0010
[2019-03-23 03:22:02,875] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2226794: loss 2.2062
[2019-03-23 03:22:02,878] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2226796: learning rate 0.0010
[2019-03-23 03:22:03,357] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2227041: loss -190.6071
[2019-03-23 03:22:03,359] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2227041: learning rate 0.0010
[2019-03-23 03:22:04,440] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2227598: loss -41.9318
[2019-03-23 03:22:04,441] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2227598: learning rate 0.0010
[2019-03-23 03:22:04,718] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2227734: loss -18.2073
[2019-03-23 03:22:04,720] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2227734: learning rate 0.0010
[2019-03-23 03:22:05,380] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2228069: loss 0.9749
[2019-03-23 03:22:05,382] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2228070: learning rate 0.0010
[2019-03-23 03:22:05,860] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2228317: loss -165.1829
[2019-03-23 03:22:05,863] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2228318: learning rate 0.0010
[2019-03-23 03:22:06,595] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8969814e-11 0.0000000e+00 0.0000000e+00 1.0720977e-32 1.0000000e+00], sum to 1.0000
[2019-03-23 03:22:06,604] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8115
[2019-03-23 03:22:06,609] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.13333333333333, 85.66666666666666, 1.0, 2.0, 0.538334379342787, 1.0, 2.0, 0.538334379342787, 1.0, 2.0, 0.8570458642404567, 6.9112, 6.9112, 121.94756008, 1841855.531104827, 1841855.531104827, 362802.1975857136], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4027200.0000, 
sim time next is 4027800.0000, 
raw observation next is [26.06666666666667, 87.33333333333334, 1.0, 2.0, 0.5463678927262816, 1.0, 2.0, 0.5463678927262816, 1.0, 2.0, 0.8698354791802454, 6.9112, 6.9112, 121.94756008, 1869370.126477655, 1869370.126477655, 366929.3949727673], 
processed observation next is [1.0, 0.6086956521739131, 0.5209876543209878, 0.8733333333333334, 1.0, 1.0, 0.4599617770550971, 1.0, 1.0, 0.4599617770550971, 1.0, 1.0, 0.8372943489753067, 0.0, 0.0, 0.8096049824067558, 0.6676321880277339, 0.6676321880277339, 0.7056334518707063], 
reward next is 0.2944, 
noisyNet noise sample is [array([0.97283036], dtype=float32), 0.85734296]. 
=============================================
[2019-03-23 03:22:07,903] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2229356: loss 331.3587
[2019-03-23 03:22:07,909] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2229356: learning rate 0.0010
[2019-03-23 03:22:09,245] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2230051: loss 412.4799
[2019-03-23 03:22:09,247] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2230052: learning rate 0.0010
[2019-03-23 03:22:10,831] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2230863: loss -8.3091
[2019-03-23 03:22:10,832] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2230863: learning rate 0.0010
[2019-03-23 03:22:10,912] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2230910: loss 416.3224
[2019-03-23 03:22:10,913] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2230910: learning rate 0.0010
[2019-03-23 03:22:13,446] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2232214: loss 421.3998
[2019-03-23 03:22:13,449] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2232215: learning rate 0.0010
[2019-03-23 03:22:14,883] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2232948: loss 443.6366
[2019-03-23 03:22:14,888] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2232951: learning rate 0.0010
[2019-03-23 03:22:15,851] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2233437: loss 522.3917
[2019-03-23 03:22:15,853] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2233437: learning rate 0.0010
[2019-03-23 03:22:15,945] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2233487: loss 431.9105
[2019-03-23 03:22:15,946] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2233487: learning rate 0.0010
[2019-03-23 03:22:16,075] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2233555: loss 440.6978
[2019-03-23 03:22:16,076] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2233555: learning rate 0.0010
[2019-03-23 03:22:18,434] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2234782: loss 503.3190
[2019-03-23 03:22:18,435] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2234782: learning rate 0.0010
[2019-03-23 03:22:18,508] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2234822: loss 21.9431
[2019-03-23 03:22:18,509] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2234822: learning rate 0.0010
[2019-03-23 03:22:19,214] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2235181: loss 512.1619
[2019-03-23 03:22:19,216] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2235181: learning rate 0.0010
[2019-03-23 03:22:20,182] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2235683: loss 400.3683
[2019-03-23 03:22:20,186] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2235684: learning rate 0.0010
[2019-03-23 03:22:20,465] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2235825: loss 392.2123
[2019-03-23 03:22:20,468] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2235826: learning rate 0.0010
[2019-03-23 03:22:21,133] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2236166: loss 372.0467
[2019-03-23 03:22:21,134] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2236167: learning rate 0.0010
[2019-03-23 03:22:21,586] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6793095e-12 0.0000000e+00 2.1982465e-35 1.0000000e+00 5.4605633e-22], sum to 1.0000
[2019-03-23 03:22:21,596] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3347
[2019-03-23 03:22:21,600] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.93333333333334, 36.66666666666667, 1.0, 2.0, 0.6288744299785606, 1.0, 1.0, 0.6288744299785606, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1487125.862071081, 1487125.862071081, 280564.8910576686], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4274400.0000, 
sim time next is 4275000.0000, 
raw observation next is [31.95, 37.0, 1.0, 2.0, 0.623472692105024, 1.0, 2.0, 0.623472692105024, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1471912.356811463, 1471912.356811464, 278532.2719430823], 
processed observation next is [1.0, 0.4782608695652174, 0.7388888888888888, 0.37, 1.0, 1.0, 0.5517532048869332, 1.0, 1.0, 0.5517532048869332, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5256829845755224, 0.5256829845755229, 0.5356389845059275], 
reward next is 0.4644, 
noisyNet noise sample is [array([1.9776133], dtype=float32), 1.5399381]. 
=============================================
[2019-03-23 03:22:21,612] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[45.840923]
 [44.975674]
 [45.871323]
 [45.528202]
 [45.21338 ]], R is [[45.89413452]
 [45.43519211]
 [45.36233521]
 [45.33733368]
 [45.31075668]].
[2019-03-23 03:22:21,698] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2236460: loss 316.7719
[2019-03-23 03:22:21,699] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2236460: learning rate 0.0010
[2019-03-23 03:22:23,773] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2237490: loss 4.3042
[2019-03-23 03:22:23,774] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2237490: learning rate 0.0010
[2019-03-23 03:22:24,980] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2238101: loss 3.6112
[2019-03-23 03:22:24,981] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2238102: learning rate 0.0010
[2019-03-23 03:22:26,742] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2239007: loss 0.2651
[2019-03-23 03:22:26,745] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2239008: learning rate 0.0010
[2019-03-23 03:22:27,372] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2239329: loss 24.7069
[2019-03-23 03:22:27,376] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2239329: learning rate 0.0010
[2019-03-23 03:22:28,020] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 9.7615084e-36 4.6924574e-36 3.5376807e-08 1.3397506e-09], sum to 1.0000
[2019-03-23 03:22:28,028] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1352
[2019-03-23 03:22:28,037] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1914582.449237399 W.
[2019-03-23 03:22:28,043] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.4, 74.66666666666667, 1.0, 2.0, 0.8393520270350591, 1.0, 2.0, 0.8393520270350591, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156447, 1914582.449237399, 1914582.449237399, 360283.741242955], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4357200.0000, 
sim time next is 4357800.0000, 
raw observation next is [28.6, 72.5, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.631108356165086, 6.9112, 121.922208535754, 2247110.108778582, 1878464.278525218, 381548.9180410777], 
processed observation next is [1.0, 0.43478260869565216, 0.6148148148148148, 0.725, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.07199083561650861, 0.0, 0.8094366745167102, 0.8025393245637793, 0.6708800994732921, 0.7337479193097648], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1648692], dtype=float32), 0.3750064]. 
=============================================
[2019-03-23 03:22:29,299] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2240310: loss 0.4631
[2019-03-23 03:22:29,303] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2240311: learning rate 0.0010
[2019-03-23 03:22:30,429] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2240893: loss 1.7578
[2019-03-23 03:22:30,431] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2240893: learning rate 0.0010
[2019-03-23 03:22:31,530] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2241459: loss 0.0121
[2019-03-23 03:22:31,533] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2241460: learning rate 0.0010
[2019-03-23 03:22:31,536] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2241461: loss 0.0866
[2019-03-23 03:22:31,537] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2241461: learning rate 0.0010
[2019-03-23 03:22:31,756] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2241572: loss 1.0655
[2019-03-23 03:22:31,760] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2241573: learning rate 0.0010
[2019-03-23 03:22:32,437] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:22:32,446] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1487
[2019-03-23 03:22:32,456] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 816160.9871925784 W.
[2019-03-23 03:22:32,462] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.6, 96.0, 1.0, 2.0, 0.3576669781485564, 1.0, 2.0, 0.3576669781485564, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 816160.9871925784, 816160.9871925788, 194917.0963678869], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5202000.0000, 
sim time next is 5202600.0000, 
raw observation next is [23.5, 96.66666666666666, 1.0, 2.0, 0.4117886718154842, 1.0, 2.0, 0.4117886718154842, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 938980.7368509178, 938980.7368509178, 209462.0448376155], 
processed observation next is [1.0, 0.21739130434782608, 0.42592592592592593, 0.9666666666666666, 1.0, 1.0, 0.29974841882795733, 1.0, 1.0, 0.29974841882795733, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33535026316104205, 0.33535026316104205, 0.40281162468772214], 
reward next is 0.5972, 
noisyNet noise sample is [array([0.49539062], dtype=float32), 1.3122092]. 
=============================================
[2019-03-23 03:22:33,716] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2242660: loss 1.5117
[2019-03-23 03:22:33,719] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2242661: learning rate 0.0010
[2019-03-23 03:22:34,260] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2242989: loss 27.8179
[2019-03-23 03:22:34,263] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2242990: learning rate 0.0010
[2019-03-23 03:22:34,668] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 4.107574e-18 0.000000e+00], sum to 1.0000
[2019-03-23 03:22:34,677] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8057
[2019-03-23 03:22:34,683] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1282587.675152106 W.
[2019-03-23 03:22:34,688] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.46666666666667, 70.66666666666667, 1.0, 2.0, 0.3750002102309657, 1.0, 1.0, 0.3750002102309657, 1.0, 2.0, 0.5970125475919174, 6.9112, 6.9112, 121.94756008, 1282587.675152106, 1282587.675152106, 286304.0996949897], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4624800.0000, 
sim time next is 4625400.0000, 
raw observation next is [28.58333333333334, 69.83333333333333, 1.0, 2.0, 0.5558470196818632, 1.0, 2.0, 0.5558470196818632, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1267404.769398906, 1267404.769398907, 253194.3157118003], 
processed observation next is [1.0, 0.5217391304347826, 0.6141975308641977, 0.6983333333333333, 1.0, 1.0, 0.4712464520022181, 1.0, 1.0, 0.4712464520022181, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.45264456049960927, 0.4526445604996096, 0.486912145599616], 
reward next is 0.5131, 
noisyNet noise sample is [array([0.5186636], dtype=float32), 1.9786475]. 
=============================================
[2019-03-23 03:22:34,770] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2243220: loss 1.4192
[2019-03-23 03:22:34,773] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2243221: learning rate 0.0010
[2019-03-23 03:22:35,780] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2243681: loss 0.9144
[2019-03-23 03:22:35,781] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2243681: learning rate 0.0010
[2019-03-23 03:22:35,963] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2243761: loss 1.1652
[2019-03-23 03:22:35,966] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2243762: learning rate 0.0010
[2019-03-23 03:22:36,171] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1495701e-32], sum to 1.0000
[2019-03-23 03:22:36,184] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7114
[2019-03-23 03:22:36,195] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 737502.4239716227 W.
[2019-03-23 03:22:36,202] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.26666666666667, 88.66666666666667, 1.0, 2.0, 0.3235589831034454, 1.0, 2.0, 0.3235589831034454, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737502.4239716227, 737502.4239716227, 186210.302646144], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4490400.0000, 
sim time next is 4491000.0000, 
raw observation next is [25.2, 90.0, 1.0, 2.0, 0.3254599937943331, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5181429096125871, 6.911199999999999, 6.9112, 121.9260426156618, 741837.5791553209, 741837.5791553213, 202212.3964892293], 
processed observation next is [0.0, 1.0, 0.4888888888888889, 0.9, 1.0, 1.0, 0.1969761830884918, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.39767863701573386, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26494199255547174, 0.2649419925554719, 0.38886999324851784], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2546356], dtype=float32), -0.08841534]. 
=============================================
[2019-03-23 03:22:36,219] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[49.124825]
 [49.35631 ]
 [49.60208 ]
 [49.083805]
 [49.28131 ]], R is [[48.96718979]
 [48.47751999]
 [48.55894089]
 [48.75387573]
 [48.26633835]].
[2019-03-23 03:22:36,695] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2244094: loss 0.1546
[2019-03-23 03:22:36,699] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2244096: learning rate 0.0010
[2019-03-23 03:22:37,437] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2244436: loss 1.6714
[2019-03-23 03:22:37,439] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2244436: learning rate 0.0010
[2019-03-23 03:22:39,985] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2245600: loss -20.9331
[2019-03-23 03:22:39,990] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2245601: learning rate 0.0010
[2019-03-23 03:22:41,141] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2246123: loss -23.9985
[2019-03-23 03:22:41,146] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2246123: learning rate 0.0010
[2019-03-23 03:22:41,595] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:22:41,603] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1655
[2019-03-23 03:22:41,609] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 691482.0546585986 W.
[2019-03-23 03:22:41,614] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666666, 86.0, 1.0, 2.0, 0.3029838433158134, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4823895209780836, 6.911199999999999, 6.9112, 121.9260426156618, 691482.0546585986, 691482.0546585991, 196035.0575154719], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5362800.0000, 
sim time next is 5363400.0000, 
raw observation next is [25.08333333333334, 86.5, 1.0, 2.0, 0.6012291999565795, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691173.5231319373, 691173.5231319373, 158582.3989270072], 
processed observation next is [1.0, 0.043478260869565216, 0.4845679012345681, 0.865, 1.0, 1.0, 0.5252728570911661, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24684768683283473, 0.24684768683283473, 0.30496615178270614], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0537801], dtype=float32), -0.440961]. 
=============================================
[2019-03-23 03:22:42,941] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2246952: loss -34.5057
[2019-03-23 03:22:42,943] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2246952: learning rate 0.0010
[2019-03-23 03:22:44,457] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2247645: loss -59.5540
[2019-03-23 03:22:44,460] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2247645: learning rate 0.0010
[2019-03-23 03:22:45,303] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3705344e-26 0.0000000e+00], sum to 1.0000
[2019-03-23 03:22:45,310] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3484
[2019-03-23 03:22:45,318] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1907461.691226713 W.
[2019-03-23 03:22:45,324] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.16666666666667, 89.0, 1.0, 2.0, 0.5574891850585781, 1.0, 2.0, 0.5574891850585781, 1.0, 1.0, 0.8875409387684666, 6.9112, 6.9112, 121.94756008, 1907461.691226713, 1907461.691226713, 372700.5001977092], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4882200.0000, 
sim time next is 4882800.0000, 
raw observation next is [28.33333333333334, 89.0, 1.0, 2.0, 0.4624108438836673, 1.0, 2.0, 0.4624108438836673, 1.0, 2.0, 0.7361731231326133, 6.911200000000001, 6.9112, 121.94756008, 1581861.013331156, 1581861.013331156, 325499.5797573737], 
processed observation next is [1.0, 0.5217391304347826, 0.6049382716049385, 0.89, 1.0, 1.0, 0.36001290938531827, 1.0, 1.0, 0.36001290938531827, 1.0, 1.0, 0.6702164039157665, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5649503619039843, 0.5649503619039843, 0.6259607303026418], 
reward next is 0.3740, 
noisyNet noise sample is [array([-1.6979961], dtype=float32), 0.31214887]. 
=============================================
[2019-03-23 03:22:45,665] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1955109e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 03:22:45,673] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3811
[2019-03-23 03:22:45,686] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 790593.1290411595 W.
[2019-03-23 03:22:45,691] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.3468390697347801, 1.0, 2.0, 0.3468390697347801, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790593.1290411595, 790593.1290411595, 192079.969471069], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4762800.0000, 
sim time next is 4763400.0000, 
raw observation next is [24.0, 94.00000000000001, 1.0, 2.0, 0.3529179684799725, 1.0, 2.0, 0.3529179684799725, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 804456.785193713, 804456.7851937135, 193643.6949495683], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.9400000000000002, 1.0, 1.0, 0.22966424819044343, 1.0, 1.0, 0.22966424819044343, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2873059947120404, 0.28730599471204055, 0.37239172105686213], 
reward next is 0.6276, 
noisyNet noise sample is [array([-0.5797444], dtype=float32), 1.0192187]. 
=============================================
[2019-03-23 03:22:45,816] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2248255: loss -8.7876
[2019-03-23 03:22:45,818] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2248256: learning rate 0.0010
[2019-03-23 03:22:47,213] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2248887: loss 69.4768
[2019-03-23 03:22:47,218] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2248887: learning rate 0.0010
[2019-03-23 03:22:48,326] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2249395: loss 0.2111
[2019-03-23 03:22:48,329] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2249397: learning rate 0.0010
[2019-03-23 03:22:48,540] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2249494: loss 0.4881
[2019-03-23 03:22:48,544] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2249495: learning rate 0.0010
[2019-03-23 03:22:48,625] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2249537: loss 0.0758
[2019-03-23 03:22:48,627] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2249537: learning rate 0.0010
[2019-03-23 03:22:49,645] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 03:22:49,647] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:22:49,647] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:22:49,648] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:22:49,648] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:22:49,649] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:22:49,651] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:22:49,652] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:22:49,652] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:22:49,654] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:22:49,656] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:22:49,681] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run91
[2019-03-23 03:22:49,712] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run91
[2019-03-23 03:22:49,713] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run91
[2019-03-23 03:22:49,768] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run91
[2019-03-23 03:22:49,806] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run91
[2019-03-23 03:22:56,287] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.555786], dtype=float32), 0.076841965]
[2019-03-23 03:22:56,288] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.58333333333333, 31.5, 1.0, 2.0, 0.8574485204175927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.912057744659273, 6.9112, 121.92561940148, 1097341.034294013, 1096901.793888758, 212185.965765211]
[2019-03-23 03:22:56,289] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:22:56,292] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1251954e-25 2.4184831e-30], sampled 0.4191114614592504
[2019-03-23 03:22:56,293] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1097341.034294013 W.
[2019-03-23 03:23:04,794] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.555786], dtype=float32), 0.076841965]
[2019-03-23 03:23:04,795] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.1, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4898277039805555, 6.9112, 6.9112, 121.9260426156618, 350437.1718881117, 350437.1718881117, 114588.0768141119]
[2019-03-23 03:23:04,796] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:23:04,800] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.559574913524427
[2019-03-23 03:23:11,629] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.555786], dtype=float32), 0.076841965]
[2019-03-23 03:23:11,630] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.35, 27.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6301431864007885, 6.911200000000001, 6.9112, 121.9260426156618, 467163.2539017937, 467163.2539017932, 132880.3584337604]
[2019-03-23 03:23:11,632] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:23:11,634] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.013702776116412463
[2019-03-23 03:23:14,740] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.555786], dtype=float32), 0.076841965]
[2019-03-23 03:23:14,742] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [34.0, 28.0, 1.0, 2.0, 0.6716520949475208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 820455.7191272115, 820455.7191272115, 173128.6713477563]
[2019-03-23 03:23:14,744] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:23:14,748] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3073972707570536
[2019-03-23 03:23:14,750] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 820455.7191272115 W.
[2019-03-23 03:23:28,428] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.555786], dtype=float32), 0.076841965]
[2019-03-23 03:23:28,429] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.0, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9525616561222904, 6.9112, 6.9112, 121.9260405836304, 690025.0664217412, 690025.0664217412, 184252.441262691]
[2019-03-23 03:23:28,429] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:23:28,432] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.11829981212159979
[2019-03-23 03:23:28,433] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 690025.0664217412 W.
[2019-03-23 03:23:36,975] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.555786], dtype=float32), 0.076841965]
[2019-03-23 03:23:36,978] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.66666666666667, 89.0, 1.0, 2.0, 0.7271463701174491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 828757.8868927468, 828757.8868927468, 181348.5612160248]
[2019-03-23 03:23:36,980] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:23:36,984] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2739689e-09 2.0544425e-16], sampled 0.1143009554900849
[2019-03-23 03:23:36,986] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 828757.8868927468 W.
[2019-03-23 03:24:28,274] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.555786], dtype=float32), 0.076841965]
[2019-03-23 03:24:28,275] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.85, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8270656312996189, 6.911200000000001, 6.9112, 121.9260426156618, 610639.1958355705, 610639.19583557, 165148.3882749474]
[2019-03-23 03:24:28,275] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:24:28,277] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.743326274247545
[2019-03-23 03:24:36,784] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.555786], dtype=float32), 0.076841965]
[2019-03-23 03:24:36,784] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.33097595, 72.01290835, 1.0, 1.0, 0.689635694656482, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9259613382051, 798428.7070019968, 798428.7070019973, 174805.9707928115]
[2019-03-23 03:24:36,785] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:24:36,788] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 3.975939e-14 0.000000e+00], sampled 0.40321375766125367
[2019-03-23 03:24:36,790] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 798428.7070019968 W.
[2019-03-23 03:24:40,520] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8649.1773 2216110812.9993 439.0000
[2019-03-23 03:24:40,570] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8433.8198 2322267275.5568 447.0000
[2019-03-23 03:24:40,647] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8595.9131 2256437524.2968 379.0000
[2019-03-23 03:24:40,742] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8463.1437 2282465607.6468 524.0000
[2019-03-23 03:24:40,776] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7965.9082 2510763939.6176 570.0000
[2019-03-23 03:24:41,791] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2250000, evaluation results [2250000.0, 7965.908196364684, 2510763939.617615, 570.0, 8595.91311341445, 2256437524.2968, 379.0, 8649.1773254459, 2216110812.999254, 439.0, 8433.819835804446, 2322267275.556831, 447.0, 8463.143745260062, 2282465607.64677, 524.0]
[2019-03-23 03:24:42,657] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2250451: loss 33.7420
[2019-03-23 03:24:42,660] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2250451: learning rate 0.0010
[2019-03-23 03:24:42,838] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6191362e-01 9.4590438e-26 2.3169729e-30 6.3808638e-01 1.2737515e-26], sum to 1.0000
[2019-03-23 03:24:42,849] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8460
[2019-03-23 03:24:42,853] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.83333333333334, 91.5, 1.0, 2.0, 0.5831132785491496, 1.0, 1.0, 0.5831132785491496, 0.0, 1.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1329629.407795504, 1329629.407795505, 262282.7798550073], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4975800.0000, 
sim time next is 4976400.0000, 
raw observation next is [25.46666666666667, 88.0, 1.0, 2.0, 0.6715769948349479, 1.0, 2.0, 0.6715769948349479, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1531548.272600081, 1531548.272600082, 293544.7977029977], 
processed observation next is [1.0, 0.6086956521739131, 0.4987654320987655, 0.88, 1.0, 1.0, 0.6090202319463666, 1.0, 1.0, 0.6090202319463666, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5469815259286004, 0.5469815259286007, 0.5645092263519186], 
reward next is 0.4355, 
noisyNet noise sample is [array([-0.56202334], dtype=float32), -0.5572843]. 
=============================================
[2019-03-23 03:24:43,795] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2251034: loss 0.0809
[2019-03-23 03:24:43,797] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2251034: learning rate 0.0010
[2019-03-23 03:24:43,853] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2251063: loss -25.3794
[2019-03-23 03:24:43,857] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2251064: learning rate 0.0010
[2019-03-23 03:24:43,980] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.4334132e-10 0.0000000e+00], sum to 1.0000
[2019-03-23 03:24:43,991] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3491
[2019-03-23 03:24:43,991] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1404324.1564536 W.
[2019-03-23 03:24:43,998] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.9, 93.5, 1.0, 2.0, 0.4105606654640738, 1.0, 2.0, 0.4105606654640738, 1.0, 2.0, 0.6536259504461996, 6.9112, 6.9112, 121.94756008, 1404324.1564536, 1404324.1564536, 301739.1896024554], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4869000.0000, 
sim time next is 4869600.0000, 
raw observation next is [25.93333333333333, 93.66666666666667, 1.0, 2.0, 0.6795460351243192, 1.0, 2.0, 0.6795460351243192, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1549740.260271011, 1549740.260271012, 296495.2362078613], 
processed observation next is [1.0, 0.34782608695652173, 0.5160493827160493, 0.9366666666666668, 1.0, 1.0, 0.6185071846718085, 1.0, 1.0, 0.6185071846718085, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5534786643825039, 0.5534786643825044, 0.5701831465535794], 
reward next is 0.4298, 
noisyNet noise sample is [array([0.33213606], dtype=float32), -0.044683244]. 
=============================================
[2019-03-23 03:24:44,521] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2251397: loss 0.8258
[2019-03-23 03:24:44,522] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2251397: learning rate 0.0010
[2019-03-23 03:24:44,678] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2251475: loss -13.7190
[2019-03-23 03:24:44,679] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2251475: learning rate 0.0010
[2019-03-23 03:24:45,535] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2251914: loss -77.9609
[2019-03-23 03:24:45,537] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2251914: learning rate 0.0010
[2019-03-23 03:24:46,242] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2252276: loss -13.2496
[2019-03-23 03:24:46,243] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2252276: learning rate 0.0010
[2019-03-23 03:24:48,774] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2253578: loss -178.8791
[2019-03-23 03:24:48,778] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2253578: learning rate 0.0010
[2019-03-23 03:24:49,837] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2254123: loss -160.2365
[2019-03-23 03:24:49,842] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2254125: learning rate 0.0010
[2019-03-23 03:24:51,385] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2254921: loss -180.4253
[2019-03-23 03:24:51,387] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2254921: learning rate 0.0010
[2019-03-23 03:24:52,639] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.0123968e-01 4.2868278e-32 1.0473965e-37 3.9876035e-01 0.0000000e+00], sum to 1.0000
[2019-03-23 03:24:52,649] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1288
[2019-03-23 03:24:52,658] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1671497.951872575 W.
[2019-03-23 03:24:52,665] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.36666666666667, 77.5, 1.0, 2.0, 0.8390377093681912, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999997, 6.9112, 121.9260426156618, 1671497.951872575, 1671497.951872576, 344119.7683661738], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4978200.0000, 
sim time next is 4978800.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.8676617891578848, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1704170.760916681, 1704170.760916681, 350071.3963284448], 
processed observation next is [1.0, 0.6521739130434783, 0.5925925925925926, 0.74, 1.0, 1.0, 0.8424545109022439, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6086324146131004, 0.6086324146131004, 0.6732142237085478], 
reward next is 0.3268, 
noisyNet noise sample is [array([-0.73989105], dtype=float32), 0.5312492]. 
=============================================
[2019-03-23 03:24:52,693] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2255591: loss 0.6772
[2019-03-23 03:24:52,694] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2255591: learning rate 0.0010
[2019-03-23 03:24:53,654] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999857e-01 0.0000000e+00 0.0000000e+00 1.4591870e-06 0.0000000e+00], sum to 1.0000
[2019-03-23 03:24:53,661] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6957
[2019-03-23 03:24:53,669] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1628909.08552435 W.
[2019-03-23 03:24:53,674] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 76.5, 1.0, 2.0, 0.7142270482406144, 1.0, 1.0, 0.7142270482406144, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1628909.08552435, 1628909.085524349, 309586.41002771], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4980600.0000, 
sim time next is 4981200.0000, 
raw observation next is [28.0, 77.33333333333333, 1.0, 2.0, 0.9962878316214715, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1851005.049681554, 1851005.049681554, 378566.9428492166], 
processed observation next is [1.0, 0.6521739130434783, 0.5925925925925926, 0.7733333333333333, 1.0, 1.0, 0.9955807519303232, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6610732320291265, 0.6610732320291265, 0.7280133516331088], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0666308], dtype=float32), -1.4626328]. 
=============================================
[2019-03-23 03:24:53,979] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2256245: loss 9.0024
[2019-03-23 03:24:53,980] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2256245: learning rate 0.0010
[2019-03-23 03:24:55,337] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2256937: loss -153.7553
[2019-03-23 03:24:55,341] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2256938: learning rate 0.0010
[2019-03-23 03:24:55,554] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.9673512e-06 2.2908120e-27 0.0000000e+00 9.9999404e-01 2.4424210e-34], sum to 1.0000
[2019-03-23 03:24:55,560] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1192
[2019-03-23 03:24:55,567] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.7306707084038347, 1.0, 2.0, 0.7306707084038347, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1666446.461263514, 1666446.461263515, 315939.3888528103], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5219400.0000, 
sim time next is 5220000.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.7969162652806236, 1.0, 2.0, 0.7969162652806236, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1817686.944848255, 1817686.944848255, 342481.9957885028], 
processed observation next is [1.0, 0.43478260869565216, 0.5555555555555556, 0.84, 1.0, 1.0, 0.7582336491435996, 1.0, 1.0, 0.7582336491435996, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6491739088743768, 0.6491739088743768, 0.6586192226701977], 
reward next is 0.3414, 
noisyNet noise sample is [array([-0.24098913], dtype=float32), 0.51278573]. 
=============================================
[2019-03-23 03:24:55,581] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[41.221024]
 [41.418682]
 [41.57247 ]
 [41.307487]
 [41.45588 ]], R is [[40.70520782]
 [40.69058228]
 [40.68122482]
 [40.66661453]
 [40.6673851 ]].
[2019-03-23 03:24:56,325] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2257440: loss -94.4742
[2019-03-23 03:24:56,328] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2257441: learning rate 0.0010
[2019-03-23 03:24:56,389] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.7179645e-01 0.0000000e+00 1.5820768e-36 1.2696042e-09 2.8203575e-02], sum to 1.0000
[2019-03-23 03:24:56,397] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1735
[2019-03-23 03:24:56,406] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 945261.0971902185 W.
[2019-03-23 03:24:56,410] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.16666666666667, 70.16666666666667, 1.0, 2.0, 0.2764341874954112, 1.0, 1.0, 0.2764341874954112, 1.0, 1.0, 0.4400922293256608, 6.911200000000001, 6.9112, 121.94756008, 945261.0971902185, 945261.097190218, 247193.8363363667], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5154600.0000, 
sim time next is 5155200.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.2722897605836207, 1.0, 2.0, 0.2722897605836207, 1.0, 2.0, 0.433494166707529, 6.9112, 6.9112, 121.94756008, 931080.7058052719, 931080.7058052719, 245667.8976528291], 
processed observation next is [0.0, 0.6956521739130435, 0.7037037037037037, 0.7, 1.0, 1.0, 0.13367828640907226, 1.0, 1.0, 0.13367828640907226, 1.0, 1.0, 0.29186770838441123, 0.0, 0.0, 0.8096049824067558, 0.3325288235018828, 0.3325288235018828, 0.47243826471697903], 
reward next is 0.5276, 
noisyNet noise sample is [array([0.02665355], dtype=float32), 1.6216311]. 
=============================================
[2019-03-23 03:24:56,419] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2257488: loss -44.7399
[2019-03-23 03:24:56,420] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2257488: learning rate 0.0010
[2019-03-23 03:24:56,536] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2257547: loss 31.6780
[2019-03-23 03:24:56,537] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2257547: learning rate 0.0010
[2019-03-23 03:24:56,751] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9998784e-01 0.0000000e+00 0.0000000e+00 1.3979374e-31 1.2191699e-05], sum to 1.0000
[2019-03-23 03:24:56,761] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5141
[2019-03-23 03:24:56,770] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 884531.3153072686 W.
[2019-03-23 03:24:56,779] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.45, 70.5, 1.0, 2.0, 0.7760533640051998, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 884531.3153072686, 884531.3153072686, 191047.5208905071], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5059800.0000, 
sim time next is 5060400.0000, 
raw observation next is [30.6, 69.0, 1.0, 2.0, 0.2580183028832753, 1.0, 1.0, 0.2580183028832753, 1.0, 1.0, 0.4107735412596503, 6.911199999999999, 6.9112, 121.94756008, 882252.1120686566, 882252.112068657, 240486.6162147304], 
processed observation next is [0.0, 0.5652173913043478, 0.688888888888889, 0.69, 1.0, 1.0, 0.116688455813423, 1.0, 0.5, 0.116688455813423, 1.0, 0.5, 0.2634669265745629, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.31509004002452023, 0.31509004002452035, 0.4624742619514046], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4600012], dtype=float32), 0.5727632]. 
=============================================
[2019-03-23 03:24:58,321] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2258456: loss -8.2716
[2019-03-23 03:24:58,327] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2258456: learning rate 0.0010
[2019-03-23 03:24:59,523] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2259067: loss -185.1921
[2019-03-23 03:24:59,527] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2259067: learning rate 0.0010
[2019-03-23 03:24:59,618] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2259114: loss 0.0311
[2019-03-23 03:24:59,619] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2259114: learning rate 0.0010
[2019-03-23 03:25:00,297] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2259467: loss -60.9042
[2019-03-23 03:25:00,298] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2259467: learning rate 0.0010
[2019-03-23 03:25:00,396] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2259514: loss -75.6608
[2019-03-23 03:25:00,400] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2259515: learning rate 0.0010
[2019-03-23 03:25:01,157] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.5551797e-16 1.4806300e-30 1.1016972e-37 9.9104172e-01 8.9583462e-03], sum to 1.0000
[2019-03-23 03:25:01,168] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3306
[2019-03-23 03:25:01,172] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.35, 65.0, 1.0, 2.0, 0.804114219798257, 1.0, 2.0, 0.804114219798257, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1834121.621430018, 1834121.621430018, 345456.1792331819], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5326200.0000, 
sim time next is 5326800.0000, 
raw observation next is [28.36666666666667, 65.33333333333334, 1.0, 2.0, 0.8042299366234155, 1.0, 2.0, 0.8042299366234155, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1834385.833487675, 1834385.833487675, 345504.2196984027], 
processed observation next is [1.0, 0.6521739130434783, 0.606172839506173, 0.6533333333333334, 1.0, 1.0, 0.7669404007421613, 1.0, 1.0, 0.7669404007421613, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6551377976741697, 0.6551377976741697, 0.6644311917276975], 
reward next is 0.3356, 
noisyNet noise sample is [array([1.2835407], dtype=float32), -0.39213035]. 
=============================================
[2019-03-23 03:25:01,387] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2260000: loss -84.5873
[2019-03-23 03:25:01,390] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2260004: learning rate 0.0010
[2019-03-23 03:25:01,759] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2260197: loss -95.7578
[2019-03-23 03:25:01,761] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2260197: learning rate 0.0010
[2019-03-23 03:25:04,607] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2261662: loss -26.9486
[2019-03-23 03:25:04,608] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2261662: learning rate 0.0010
[2019-03-23 03:25:05,630] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2262178: loss 27.5356
[2019-03-23 03:25:05,635] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2262181: learning rate 0.0010
[2019-03-23 03:25:07,040] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2262897: loss -23.1132
[2019-03-23 03:25:07,043] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2262898: learning rate 0.0010
[2019-03-23 03:25:07,131] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2262946: loss -42.8890
[2019-03-23 03:25:07,134] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2262946: learning rate 0.0010
[2019-03-23 03:25:09,767] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2264303: loss 0.3219
[2019-03-23 03:25:09,771] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2264303: learning rate 0.0010
[2019-03-23 03:25:10,996] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2264941: loss 0.0227
[2019-03-23 03:25:10,999] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2264942: learning rate 0.0010
[2019-03-23 03:25:11,912] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2265413: loss 0.0184
[2019-03-23 03:25:11,914] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2265413: learning rate 0.0010
[2019-03-23 03:25:12,227] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2265575: loss 0.3206
[2019-03-23 03:25:12,231] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2265576: learning rate 0.0010
[2019-03-23 03:25:12,234] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2265577: loss 0.0669
[2019-03-23 03:25:12,237] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2265577: learning rate 0.0010
[2019-03-23 03:25:12,408] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:25:12,418] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1175
[2019-03-23 03:25:12,423] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.31666666666666, 66.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8812830888970145, 6.911200000000001, 6.9112, 121.9260426156618, 647149.4047619713, 647149.4047619709, 172995.1849308939], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6120600.0000, 
sim time next is 6121200.0000, 
raw observation next is [27.23333333333333, 66.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8768666847380426, 6.9112, 6.9112, 121.9260426156618, 644101.3192592422, 644101.3192592422, 172372.676585163], 
processed observation next is [1.0, 0.8695652173913043, 0.5641975308641974, 0.6666666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8460833559225533, 0.0, 0.0, 0.8094621288201359, 0.23003618544972934, 0.23003618544972934, 0.3314859165099288], 
reward next is 0.6685, 
noisyNet noise sample is [array([0.41091505], dtype=float32), -0.98590684]. 
=============================================
[2019-03-23 03:25:13,036] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 9.9987920e-36 0.0000000e+00 5.8950137e-34 4.6390992e-28], sum to 1.0000
[2019-03-23 03:25:13,042] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6580
[2019-03-23 03:25:13,052] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 829857.8134994878 W.
[2019-03-23 03:25:13,056] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.3, 93.0, 1.0, 2.0, 0.3640554579267395, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5795881454778915, 6.911199999999999, 6.9112, 121.9260426156618, 829857.8134994878, 829857.8134994883, 213271.2010307983], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5450400.0000, 
sim time next is 5451000.0000, 
raw observation next is [26.28333333333333, 93.16666666666667, 1.0, 2.0, 0.6037182964313105, 1.0, 1.0, 0.6037182964313105, 0.0, 1.0, 0.0, 6.9112, 6.9112, 123.1534849849428, 1376643.37541959, 1376643.37541959, 269506.8517532306], 
processed observation next is [1.0, 0.08695652173913043, 0.5290123456790122, 0.9316666666666668, 1.0, 1.0, 0.5282360671801315, 1.0, 0.5, 0.5282360671801315, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8176110697020621, 0.49165834836413924, 0.49165834836413924, 0.5182824072177512], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.16007258], dtype=float32), -1.1355234]. 
=============================================
[2019-03-23 03:25:13,067] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[39.291855]
 [38.95088 ]
 [39.01069 ]
 [38.902973]
 [38.423645]], R is [[38.31389999]
 [37.93076324]
 [38.20113754]
 [38.40716553]
 [38.61026382]].
[2019-03-23 03:25:14,063] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2266510: loss 1.2144
[2019-03-23 03:25:14,069] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2266510: learning rate 0.0010
[2019-03-23 03:25:15,014] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2267087: loss -6.1212
[2019-03-23 03:25:15,016] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2267088: learning rate 0.0010
[2019-03-23 03:25:15,125] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2267159: loss 4.1607
[2019-03-23 03:25:15,126] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2267160: learning rate 0.0010
[2019-03-23 03:25:15,746] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2267512: loss -13.0578
[2019-03-23 03:25:15,752] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2267512: learning rate 0.0010
[2019-03-23 03:25:16,058] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.9535375e-33 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 03:25:16,067] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9960
[2019-03-23 03:25:16,075] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 975862.0827174245 W.
[2019-03-23 03:25:16,082] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.2, 94.0, 1.0, 2.0, 0.4280662200804077, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6814953635115152, 6.911199999999999, 6.9112, 121.9260426156618, 975862.0827174245, 975862.082717425, 232923.4390360196], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5455200.0000, 
sim time next is 5455800.0000, 
raw observation next is [26.2, 94.0, 1.0, 2.0, 0.458942219151686, 1.0, 1.0, 0.458942219151686, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1046298.118763099, 1046298.118763099, 222978.4964125329], 
processed observation next is [1.0, 0.13043478260869565, 0.5259259259259259, 0.94, 1.0, 1.0, 0.3558835942281976, 1.0, 0.5, 0.3558835942281976, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.37367789955824965, 0.37367789955824965, 0.4288048007933325], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3636898], dtype=float32), -0.9543774]. 
=============================================
[2019-03-23 03:25:16,115] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2267677: loss -33.0173
[2019-03-23 03:25:16,116] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2267677: learning rate 0.0010
[2019-03-23 03:25:17,020] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2268088: loss -59.0023
[2019-03-23 03:25:17,022] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2268088: learning rate 0.0010
[2019-03-23 03:25:17,306] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:25:17,313] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7243
[2019-03-23 03:25:17,324] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 735153.4002993034 W.
[2019-03-23 03:25:17,330] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.38333333333333, 87.5, 1.0, 2.0, 0.6450578145423984, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 735153.4002993034, 735153.4002993034, 166000.9423815602], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5554200.0000, 
sim time next is 5554800.0000, 
raw observation next is [25.4, 87.0, 1.0, 2.0, 0.6539356544287879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 746813.552183487, 746813.5521834865, 167681.8282664527], 
processed observation next is [1.0, 0.30434782608695654, 0.49629629629629624, 0.87, 1.0, 1.0, 0.5880186362247475, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26671912577981677, 0.2667191257798166, 0.3224650543585629], 
reward next is 0.6775, 
noisyNet noise sample is [array([0.8140882], dtype=float32), -0.23088047]. 
=============================================
[2019-03-23 03:25:17,382] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2268254: loss -23.6026
[2019-03-23 03:25:17,387] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2268254: learning rate 0.0010
[2019-03-23 03:25:17,601] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.7109815e-38], sum to 1.0000
[2019-03-23 03:25:17,610] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2576
[2019-03-23 03:25:17,619] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 743953.5150944041 W.
[2019-03-23 03:25:17,622] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.61666666666667, 81.0, 1.0, 2.0, 0.6527756996658243, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 743953.5150944041, 743953.5150944041, 167394.8512186125], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5514600.0000, 
sim time next is 5515200.0000, 
raw observation next is [26.6, 81.0, 1.0, 2.0, 0.3252830371492073, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5178611888704712, 6.911199999999999, 6.9112, 121.9260426156618, 741434.0377715599, 741434.0377715604, 202163.4700980551], 
processed observation next is [1.0, 0.8695652173913043, 0.5407407407407407, 0.81, 1.0, 1.0, 0.19676552041572298, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.3973264860880889, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26479787063269994, 0.2647978706327001, 0.3887759040347214], 
reward next is 0.6112, 
noisyNet noise sample is [array([1.0668037], dtype=float32), -0.37487593]. 
=============================================
[2019-03-23 03:25:18,082] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.5410035e-30], sum to 1.0000
[2019-03-23 03:25:18,091] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7152
[2019-03-23 03:25:18,098] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 834922.2194152767 W.
[2019-03-23 03:25:18,104] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.4, 76.5, 1.0, 2.0, 0.3662759840318174, 0.0, 2.0, 0.0, 1.0, 1.0, 0.583123295354662, 6.911199999999999, 6.9112, 121.9260426156618, 834922.2194152767, 834922.2194152771, 213927.2407930823], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5423400.0000, 
sim time next is 5424000.0000, 
raw observation next is [29.33333333333334, 77.0, 1.0, 2.0, 0.3680870667371886, 1.0, 1.0, 0.3680870667371886, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 839052.8229532002, 839052.8229532007, 197604.136745085], 
processed observation next is [1.0, 0.782608695652174, 0.6419753086419755, 0.77, 1.0, 1.0, 0.2477226984966531, 1.0, 0.5, 0.2477226984966531, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29966172248328576, 0.29966172248328593, 0.38000795527900966], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.15590398], dtype=float32), -1.1475703]. 
=============================================
[2019-03-23 03:25:18,119] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[43.730003]
 [43.501385]
 [42.84004 ]
 [42.47456 ]
 [42.110744]], R is [[42.76638031]
 [42.92731857]
 [43.14693451]
 [43.36197281]
 [43.58119965]].
[2019-03-23 03:25:20,498] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2269669: loss 4.7108
[2019-03-23 03:25:20,501] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2269669: learning rate 0.0010
[2019-03-23 03:25:21,779] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2270250: loss 2.3531
[2019-03-23 03:25:21,782] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2270251: learning rate 0.0010
[2019-03-23 03:25:22,137] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2270412: loss 0.4366
[2019-03-23 03:25:22,138] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2270412: learning rate 0.0010
[2019-03-23 03:25:23,352] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2270973: loss 2.6592
[2019-03-23 03:25:23,354] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2270973: learning rate 0.0010
[2019-03-23 03:25:24,795] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.5224514e-09], sum to 1.0000
[2019-03-23 03:25:24,803] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7625
[2019-03-23 03:25:24,814] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 735153.400297575 W.
[2019-03-23 03:25:24,820] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.38333333333333, 87.5, 1.0, 2.0, 0.3225289072704414, 1.0, 1.0, 0.3225289072704414, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 735153.400297575, 735153.400297575, 185954.9127514767], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5554200.0000, 
sim time next is 5554800.0000, 
raw observation next is [25.4, 87.0, 1.0, 2.0, 0.3276419965305437, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5216167290315024, 6.911199999999999, 6.9112, 121.9260426156618, 746813.5521834852, 746813.5521834857, 202820.8678429931], 
processed observation next is [1.0, 0.30434782608695654, 0.49629629629629624, 0.87, 1.0, 1.0, 0.19957380539350442, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4020209112893779, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26671912577981616, 0.2667191257798163, 0.3900401304672944], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.56616336], dtype=float32), 1.1488485]. 
=============================================
[2019-03-23 03:25:26,489] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2272405: loss 0.9170
[2019-03-23 03:25:26,493] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2272406: learning rate 0.0010
[2019-03-23 03:25:27,806] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2273006: loss 0.3015
[2019-03-23 03:25:27,811] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2273007: learning rate 0.0010
[2019-03-23 03:25:28,973] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2273546: loss 0.4487
[2019-03-23 03:25:28,976] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2273546: learning rate 0.0010
[2019-03-23 03:25:29,087] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:25:29,097] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1948
[2019-03-23 03:25:29,102] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.5, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8151633355804764, 6.911200000000001, 6.9112, 121.9260426156618, 608338.4231012223, 608338.4231012218, 160180.5336270023], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5817600.0000, 
sim time next is 5818200.0000, 
raw observation next is [23.66666666666667, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9465120034635427, 6.9112, 6.9112, 121.9260426156618, 706586.9649667003, 706586.9649667003, 176334.9543001504], 
processed observation next is [1.0, 0.34782608695652173, 0.43209876543209896, 0.76, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9331400043294282, 0.0, 0.0, 0.8094621288201359, 0.25235248748810724, 0.25235248748810724, 0.3391056813464431], 
reward next is 0.6609, 
noisyNet noise sample is [array([-1.7396342], dtype=float32), -0.33669722]. 
=============================================
[2019-03-23 03:25:29,299] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2273692: loss 0.3694
[2019-03-23 03:25:29,302] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2273693: learning rate 0.0010
[2019-03-23 03:25:29,346] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2273715: loss 0.6960
[2019-03-23 03:25:29,351] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2273716: learning rate 0.0010
[2019-03-23 03:25:30,295] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999738e-01 1.2533129e-28 6.0698291e-38 2.6179609e-06 1.3431380e-08], sum to 1.0000
[2019-03-23 03:25:30,303] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8821
[2019-03-23 03:25:30,309] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1176032.499329352 W.
[2019-03-23 03:25:30,314] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.2, 72.0, 1.0, 2.0, 0.4937003622199191, 1.0, 2.0, 0.4937003622199191, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425738269, 1176032.499329352, 1176032.499329352, 235643.6678315712], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5994000.0000, 
sim time next is 5994600.0000, 
raw observation next is [24.36666666666667, 71.83333333333333, 1.0, 2.0, 0.5610442360812907, 1.0, 2.0, 0.5610442360812907, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156491, 1334006.8356057, 1334006.835605701, 257344.5990498018], 
processed observation next is [1.0, 0.391304347826087, 0.4580246913580248, 0.7183333333333333, 1.0, 1.0, 0.47743361438248894, 1.0, 1.0, 0.47743361438248894, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288200516, 0.47643101271632143, 0.47643101271632177, 0.4948934597111573], 
reward next is 0.5051, 
noisyNet noise sample is [array([1.691141], dtype=float32), -0.7522085]. 
=============================================
[2019-03-23 03:25:31,354] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2274633: loss 4.4858
[2019-03-23 03:25:31,361] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2274635: learning rate 0.0010
[2019-03-23 03:25:31,431] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2274672: loss 0.6810
[2019-03-23 03:25:31,433] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2274672: learning rate 0.0010
[2019-03-23 03:25:32,166] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 03:25:32,168] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:25:32,169] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:25:32,171] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:25:32,171] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:25:32,171] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:25:32,173] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:25:32,174] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:25:32,172] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:25:32,177] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:25:32,178] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:25:32,203] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run92
[2019-03-23 03:25:32,233] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run92
[2019-03-23 03:25:32,234] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run92
[2019-03-23 03:25:32,290] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run92
[2019-03-23 03:25:32,290] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run92
[2019-03-23 03:25:40,567] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.7050787], dtype=float32), 0.037413616]
[2019-03-23 03:25:40,568] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.214773295, 47.88791071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4434214907168016, 6.911199999999999, 6.9112, 121.9260426156618, 316598.9001631101, 316598.9001631105, 91768.90938246202]
[2019-03-23 03:25:40,570] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:25:40,575] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.061571227087628966
[2019-03-23 03:25:47,028] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.7050787], dtype=float32), 0.037413616]
[2019-03-23 03:25:47,030] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.5, 28.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4728462107677242, 6.911200000000001, 6.9112, 121.9260426156618, 337612.5059923602, 337612.5059923598, 91873.6189605762]
[2019-03-23 03:25:47,030] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:25:47,033] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.35959163389130644
[2019-03-23 03:26:02,294] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.7050787], dtype=float32), 0.037413616]
[2019-03-23 03:26:02,295] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.08900377, 61.41184964, 1.0, 1.0, 0.6471592978362601, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737549.5511463955, 737549.5511463955, 166385.2617779562]
[2019-03-23 03:26:02,298] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:26:02,300] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.47642641065289126
[2019-03-23 03:26:02,301] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 737549.5511463955 W.
[2019-03-23 03:26:06,005] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.7050787], dtype=float32), 0.037413616]
[2019-03-23 03:26:06,005] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.0, 34.0, 1.0, 2.0, 0.8133275523492717, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9896550431086805, 6.9112, 6.9112, 121.9260426156618, 1650393.372493496, 1650393.372493496, 337583.4123911372]
[2019-03-23 03:26:06,006] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:26:06,009] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5849492e-06 0.0000000e+00 2.2218802e-37 9.9999845e-01 2.5412445e-11], sampled 0.8167586144763169
[2019-03-23 03:26:16,719] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.7050787], dtype=float32), 0.037413616]
[2019-03-23 03:26:16,724] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 89.0, 1.0, 2.0, 0.3233403034588597, 1.0, 2.0, 0.3233403034588597, 1.0, 2.0, 0.5147682935650187, 6.9112, 6.9112, 122.2539727072155, 1105769.321014208, 1105769.321014208, 265191.5976724355]
[2019-03-23 03:26:16,724] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:26:16,727] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.7348558e-04 0.0000000e+00 0.0000000e+00 3.5448967e-27 9.9922657e-01], sampled 0.5629134565836706
[2019-03-23 03:26:40,433] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.7050787], dtype=float32), 0.037413616]
[2019-03-23 03:26:40,434] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.0, 94.0, 1.0, 2.0, 0.6068294036401853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 699649.6851057602, 699649.6851057598, 159649.9984368968]
[2019-03-23 03:26:40,435] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:26:40,437] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 2.057848e-11], sampled 0.6330047568534989
[2019-03-23 03:26:40,439] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 699649.6851057602 W.
[2019-03-23 03:27:22,926] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7877.4380 2574849780.2699 539.0000
[2019-03-23 03:27:23,181] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8419.5084 2332806709.1870 465.0000
[2019-03-23 03:27:23,389] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8600.8004 2272376316.0706 379.0000
[2019-03-23 03:27:23,461] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8346.2381 2382485758.1089 400.0000
[2019-03-23 03:27:23,507] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8491.3940 2328131137.4180 365.0000
[2019-03-23 03:27:24,524] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2275000, evaluation results [2275000.0, 7877.438033098642, 2574849780.2698665, 539.0, 8491.39403281505, 2328131137.418034, 365.0, 8600.800363890554, 2272376316.070552, 379.0, 8346.238137197062, 2382485758.108931, 400.0, 8419.508380753816, 2332806709.1870317, 465.0]
[2019-03-23 03:27:24,683] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:27:24,692] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2294
[2019-03-23 03:27:24,698] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.6, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.666968693390435, 6.9112, 6.9112, 121.9260426156618, 497826.582589575, 497826.582589575, 139506.235935907], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5873400.0000, 
sim time next is 5874000.0000, 
raw observation next is [21.5, 81.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6609649511509902, 6.9112, 6.9112, 121.9260426156618, 493247.1960383186, 493247.1960383186, 138740.4742486221], 
processed observation next is [1.0, 1.0, 0.35185185185185186, 0.8133333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5762061889387377, 0.0, 0.0, 0.8094621288201359, 0.17615971287082807, 0.17615971287082807, 0.2668086043242733], 
reward next is 0.7332, 
noisyNet noise sample is [array([0.99135965], dtype=float32), 0.4397271]. 
=============================================
[2019-03-23 03:27:24,710] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[66.239075]
 [66.23093 ]
 [66.233315]
 [66.2607  ]
 [66.18339 ]], R is [[66.30779266]
 [66.37643433]
 [66.44296265]
 [66.50782776]
 [66.57145691]].
[2019-03-23 03:27:25,165] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2275332: loss 3.7078
[2019-03-23 03:27:25,166] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2275333: learning rate 0.0010
[2019-03-23 03:27:26,052] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2275789: loss 0.9889
[2019-03-23 03:27:26,056] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2275789: learning rate 0.0010
[2019-03-23 03:27:26,372] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2275950: loss 1.7508
[2019-03-23 03:27:26,374] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2275951: learning rate 0.0010
[2019-03-23 03:27:26,536] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:27:26,543] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4790
[2019-03-23 03:27:26,549] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.6, 82.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7358977833524565, 6.9112, 6.9112, 121.9260426156618, 549577.7700985565, 549577.7700985565, 150128.85739761], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5963400.0000, 
sim time next is 5964000.0000, 
raw observation next is [22.6, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7304456190225678, 6.911199999999999, 6.9112, 121.9260426156618, 545593.1030755366, 545593.103075537, 149335.6316025392], 
processed observation next is [1.0, 0.0, 0.39259259259259266, 0.82, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6630570237782096, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19485467966983447, 0.19485467966983464, 0.28718390692796], 
reward next is 0.7128, 
noisyNet noise sample is [array([0.21824156], dtype=float32), -1.5704103]. 
=============================================
[2019-03-23 03:27:26,570] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[61.889168]
 [62.25577 ]
 [62.945778]
 [64.260735]
 [66.72065 ]], R is [[61.75333405]
 [61.84709167]
 [61.93851089]
 [62.02781296]
 [62.11487579]].
[2019-03-23 03:27:26,616] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:27:26,622] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8875
[2019-03-23 03:27:26,626] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.13333333333333, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7390380336039349, 6.9112, 6.9112, 121.9260426156618, 551950.4732177648, 551950.4732177648, 150441.4787396239], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5722800.0000, 
sim time next is 5723400.0000, 
raw observation next is [21.16666666666667, 93.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7350864134907036, 6.9112, 6.9112, 121.9260426156618, 549034.5074374175, 549034.5074374175, 149918.520205336], 
processed observation next is [0.0, 0.21739130434782608, 0.33950617283950635, 0.935, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6688580168633795, 0.0, 0.0, 0.8094621288201359, 0.19608375265622055, 0.19608375265622055, 0.2883048465487231], 
reward next is 0.7117, 
noisyNet noise sample is [array([1.2326018], dtype=float32), 2.0008082]. 
=============================================
[2019-03-23 03:27:27,339] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2276444: loss 0.8264
[2019-03-23 03:27:27,341] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2276444: learning rate 0.0010
[2019-03-23 03:27:27,821] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2276686: loss 2.0838
[2019-03-23 03:27:27,824] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2276686: learning rate 0.0010
[2019-03-23 03:27:29,065] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2277328: loss -18.5924
[2019-03-23 03:27:29,069] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2277328: learning rate 0.0010
[2019-03-23 03:27:30,385] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2277996: loss -61.0285
[2019-03-23 03:27:30,387] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2277996: learning rate 0.0010
[2019-03-23 03:27:31,788] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2278726: loss 4.2889
[2019-03-23 03:27:31,791] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2278726: learning rate 0.0010
[2019-03-23 03:27:31,918] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2278790: loss -23.2156
[2019-03-23 03:27:31,924] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2278791: learning rate 0.0010
[2019-03-23 03:27:34,868] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2280307: loss -26.3210
[2019-03-23 03:27:34,871] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2280308: learning rate 0.0010
[2019-03-23 03:27:36,040] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2280908: loss -13.0594
[2019-03-23 03:27:36,042] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2280908: learning rate 0.0010
[2019-03-23 03:27:36,429] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:27:36,440] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0801
[2019-03-23 03:27:36,443] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.6, 90.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8003974946524082, 6.9112, 6.9112, 121.9260426156618, 594634.0881802021, 594634.0881802021, 160316.4371510854], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6153600.0000, 
sim time next is 6154200.0000, 
raw observation next is [22.7, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.790316316246402, 6.911200000000001, 6.9112, 121.9260426156618, 587007.2083268887, 587007.2083268883, 159134.1112676287], 
processed observation next is [1.0, 0.21739130434782608, 0.39629629629629626, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7378953953080025, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2096454315453174, 0.20964543154531723, 0.3060271370531321], 
reward next is 0.6940, 
noisyNet noise sample is [array([-0.14910017], dtype=float32), -2.780497]. 
=============================================
[2019-03-23 03:27:37,132] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.5605690e-30 0.0000000e+00 3.6771322e-27 0.0000000e+00], sum to 1.0000
[2019-03-23 03:27:37,141] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0677
[2019-03-23 03:27:37,148] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1025075.575514023 W.
[2019-03-23 03:27:37,151] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.83333333333334, 62.66666666666667, 1.0, 2.0, 0.449639506787183, 1.0, 2.0, 0.449639506787183, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260424830727, 1025075.575514023, 1025075.575514023, 220246.9572557667], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6007800.0000, 
sim time next is 6008400.0000, 
raw observation next is [29.0, 62.0, 1.0, 2.0, 0.4819114573712942, 1.0, 2.0, 0.4819114573712942, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156214, 1098701.015136566, 1098701.015136565, 229844.6294955078], 
processed observation next is [1.0, 0.5652173913043478, 0.6296296296296297, 0.62, 1.0, 1.0, 0.38322792544201695, 1.0, 1.0, 0.38322792544201695, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288198677, 0.3923932196916307, 0.3923932196916304, 0.44200890287597655], 
reward next is 0.5580, 
noisyNet noise sample is [array([0.01434357], dtype=float32), -0.025119023]. 
=============================================
[2019-03-23 03:27:37,246] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2281527: loss -23.7889
[2019-03-23 03:27:37,250] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2281527: learning rate 0.0010
[2019-03-23 03:27:37,342] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2281577: loss 9.1137
[2019-03-23 03:27:37,344] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2281577: learning rate 0.0010
[2019-03-23 03:27:37,448] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2281629: loss 1.8582
[2019-03-23 03:27:37,451] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2281629: learning rate 0.0010
[2019-03-23 03:27:38,338] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.1003272e-23 1.1638197e-36 0.0000000e+00 1.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 03:27:38,346] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5851
[2019-03-23 03:27:38,352] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.3, 78.0, 1.0, 2.0, 0.6541768436366987, 1.0, 2.0, 0.6541768436366987, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1499913.029732094, 1499913.029732095, 287589.0573088959], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6166800.0000, 
sim time next is 6167400.0000, 
raw observation next is [25.46666666666667, 77.0, 1.0, 2.0, 0.6607075831944814, 1.0, 2.0, 0.6607075831944814, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1514144.437973833, 1514144.437973833, 289932.1272457058], 
processed observation next is [1.0, 0.391304347826087, 0.4987654320987655, 0.77, 1.0, 1.0, 0.5960804561839065, 1.0, 1.0, 0.5960804561839065, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5407658707049403, 0.5407658707049403, 0.5575617831648189], 
reward next is 0.4424, 
noisyNet noise sample is [array([0.73785454], dtype=float32), -0.79973394]. 
=============================================
[2019-03-23 03:27:39,248] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1857284e-28 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 03:27:39,255] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0707
[2019-03-23 03:27:39,259] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 60.5, 1.0, 2.0, 0.7996884824501747, 1.0, 2.0, 0.7996884824501747, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260425096062, 1824016.553458216, 1824016.553458216, 343624.3611221357], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6010200.0000, 
sim time next is 6010800.0000, 
raw observation next is [29.0, 60.0, 1.0, 2.0, 0.740909655921613, 1.0, 2.0, 0.740909655921613, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156295, 1689820.595685925, 1689820.595685926, 319940.9171743689], 
processed observation next is [1.0, 0.5652173913043478, 0.6296296296296297, 0.6, 1.0, 1.0, 0.6915591141923964, 1.0, 1.0, 0.6915591141923964, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288199215, 0.6035073556021161, 0.6035073556021164, 0.6152709945660941], 
reward next is 0.3847, 
noisyNet noise sample is [array([0.29597113], dtype=float32), 2.1427402]. 
=============================================
[2019-03-23 03:27:39,312] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2282579: loss 32.1965
[2019-03-23 03:27:39,319] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2282581: learning rate 0.0010
[2019-03-23 03:27:39,511] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2282681: loss 0.0624
[2019-03-23 03:27:39,513] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2282682: learning rate 0.0010
[2019-03-23 03:27:40,879] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2283344: loss -61.9673
[2019-03-23 03:27:40,880] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2283344: learning rate 0.0010
[2019-03-23 03:27:41,642] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2283741: loss -133.6770
[2019-03-23 03:27:41,642] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2283741: learning rate 0.0010
[2019-03-23 03:27:41,942] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2283901: loss -100.2907
[2019-03-23 03:27:41,946] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2283903: learning rate 0.0010
[2019-03-23 03:27:42,801] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:27:42,812] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9309
[2019-03-23 03:27:42,818] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.7, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8509705992051805, 6.9112, 6.9112, 121.9260426156618, 627423.8748038121, 627423.8748038121, 168414.5334304283], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6033600.0000, 
sim time next is 6034200.0000, 
raw observation next is [26.58333333333333, 68.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8509231618119151, 6.9112, 6.9112, 121.9260426156618, 627501.3068747489, 627501.3068747489, 168375.7374586675], 
processed observation next is [1.0, 0.8695652173913043, 0.5401234567901233, 0.685, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8136539522648939, 0.0, 0.0, 0.8094621288201359, 0.22410760959812462, 0.22410760959812462, 0.32379949511282213], 
reward next is 0.6762, 
noisyNet noise sample is [array([-0.39277464], dtype=float32), -0.6854386]. 
=============================================
[2019-03-23 03:27:42,842] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2284361: loss 40.6642
[2019-03-23 03:27:42,843] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2284361: learning rate 0.0010
[2019-03-23 03:27:43,258] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2284577: loss 38.5970
[2019-03-23 03:27:43,260] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2284578: learning rate 0.0010
[2019-03-23 03:27:44,184] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0256012e-17 0.0000000e+00 0.0000000e+00 5.2009821e-34 1.0000000e+00], sum to 1.0000
[2019-03-23 03:27:44,194] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1482
[2019-03-23 03:27:44,200] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.88333333333333, 81.5, 1.0, 2.0, 0.2251571192334774, 1.0, 2.0, 0.2251571192334774, 1.0, 2.0, 0.3584574666751362, 6.911200000000002, 6.9112, 121.94756008, 769832.1572807134, 769832.1572807125, 228988.8235285823], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6394200.0000, 
sim time next is 6394800.0000, 
raw observation next is [26.76666666666667, 82.0, 1.0, 2.0, 0.2273951113036128, 1.0, 2.0, 0.2273951113036128, 1.0, 2.0, 0.3620204229371051, 6.911199999999997, 6.9112, 121.94756008, 777487.9307107596, 777487.930710761, 229752.7213951027], 
processed observation next is [1.0, 0.0, 0.5469135802469137, 0.82, 1.0, 1.0, 0.08023227536144382, 1.0, 1.0, 0.08023227536144382, 1.0, 1.0, 0.20252552867138138, -2.6645352591003756e-16, 0.0, 0.8096049824067558, 0.2776742609681284, 0.2776742609681289, 0.4418321565290437], 
reward next is 0.5582, 
noisyNet noise sample is [array([0.39633054], dtype=float32), 1.1416522]. 
=============================================
[2019-03-23 03:27:44,660] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2285302: loss 0.0056
[2019-03-23 03:27:44,661] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2285302: learning rate 0.0010
[2019-03-23 03:27:45,917] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2285954: loss 0.0015
[2019-03-23 03:27:45,918] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2285954: learning rate 0.0010
[2019-03-23 03:27:46,551] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9978012e-01 2.8597903e-15 7.3206909e-38 2.1988753e-04 1.3953775e-31], sum to 1.0000
[2019-03-23 03:27:46,563] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1910
[2019-03-23 03:27:46,570] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1802461.993215753 W.
[2019-03-23 03:27:46,575] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.85, 54.5, 1.0, 2.0, 0.7902480201814122, 1.0, 2.0, 0.7902480201814122, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1802461.993215753, 1802461.993215754, 339739.6260768273], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6186600.0000, 
sim time next is 6187200.0000, 
raw observation next is [29.86666666666667, 54.33333333333334, 1.0, 2.0, 0.5260077574909718, 1.0, 2.0, 0.5260077574909718, 1.0, 1.0, 0.8374214808023198, 6.9112, 6.9112, 121.94756008, 1799638.78735036, 1799638.78735036, 356537.3023167718], 
processed observation next is [1.0, 0.6086956521739131, 0.6617283950617285, 0.5433333333333334, 1.0, 1.0, 0.4357235208225855, 1.0, 1.0, 0.4357235208225855, 1.0, 0.5, 0.7967768510028996, 0.0, 0.0, 0.8096049824067558, 0.6427281383394143, 0.6427281383394143, 0.6856486583014842], 
reward next is 0.3144, 
noisyNet noise sample is [array([-0.15719709], dtype=float32), 0.811554]. 
=============================================
[2019-03-23 03:27:47,191] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2286600: loss 3.1580
[2019-03-23 03:27:47,193] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2286601: learning rate 0.0010
[2019-03-23 03:27:47,564] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2286790: loss 0.3540
[2019-03-23 03:27:47,566] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2286790: learning rate 0.0010
[2019-03-23 03:27:50,436] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2288263: loss 0.2098
[2019-03-23 03:27:50,438] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2288263: learning rate 0.0010
[2019-03-23 03:27:51,425] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.6807064e-30], sum to 1.0000
[2019-03-23 03:27:51,430] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5483
[2019-03-23 03:27:51,437] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 743201.9829587493 W.
[2019-03-23 03:27:51,444] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.18333333333333, 60.33333333333333, 1.0, 2.0, 0.3260582968456132, 1.0, 1.0, 0.3260582968456132, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 743201.9829587493, 743201.9829587498, 186831.7040966804], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6282600.0000, 
sim time next is 6283200.0000, 
raw observation next is [30.06666666666667, 60.66666666666667, 1.0, 2.0, 0.2137769025537681, 1.0, 2.0, 0.2137769025537681, 1.0, 1.0, 0.3403397910932565, 6.911200000000001, 6.9112, 121.94756008, 730903.639745889, 730903.6397458885, 225147.7343879942], 
processed observation next is [0.0, 0.7391304347826086, 0.669135802469136, 0.6066666666666667, 1.0, 1.0, 0.06402012208781917, 1.0, 1.0, 0.06402012208781917, 1.0, 0.5, 0.17542473886657062, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.26103701419496034, 0.26103701419496017, 0.4329764122846042], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0438367], dtype=float32), -0.46304032]. 
=============================================
[2019-03-23 03:27:51,479] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2288797: loss 0.0899
[2019-03-23 03:27:51,482] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2288798: learning rate 0.0010
[2019-03-23 03:27:52,683] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2289422: loss 0.0137
[2019-03-23 03:27:52,685] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2289422: learning rate 0.0010
[2019-03-23 03:27:52,879] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2289525: loss 0.1312
[2019-03-23 03:27:52,881] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2289525: learning rate 0.0010
[2019-03-23 03:27:52,901] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2289533: loss 0.0552
[2019-03-23 03:27:52,902] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2289533: learning rate 0.0010
[2019-03-23 03:27:54,768] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2290488: loss 0.0186
[2019-03-23 03:27:54,769] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2290488: learning rate 0.0010
[2019-03-23 03:27:56,096] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2291223: loss 0.1000
[2019-03-23 03:27:56,097] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2291223: learning rate 0.0010
[2019-03-23 03:27:56,108] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2291231: loss 140.4872
[2019-03-23 03:27:56,110] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2291231: learning rate 0.0010
[2019-03-23 03:27:56,619] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2291550: loss 0.4457
[2019-03-23 03:27:56,624] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2291550: learning rate 0.0010
[2019-03-23 03:27:56,834] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2291694: loss 1.6302
[2019-03-23 03:27:56,836] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2291695: learning rate 0.0010
[2019-03-23 03:27:57,804] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2292144: loss 0.2066
[2019-03-23 03:27:57,805] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2292145: learning rate 0.0010
[2019-03-23 03:27:58,339] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2292383: loss 0.9994
[2019-03-23 03:27:58,339] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2292383: learning rate 0.0010
[2019-03-23 03:28:01,330] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.999994e-01 0.000000e+00 0.000000e+00 0.000000e+00 6.486926e-07], sum to 1.0000
[2019-03-23 03:28:01,337] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0042
[2019-03-23 03:28:01,345] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 767236.9565529232 W.
[2019-03-23 03:28:01,348] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.96666666666667, 65.0, 1.0, 2.0, 0.2243984659722814, 1.0, 2.0, 0.2243984659722814, 1.0, 1.0, 0.3572496659757003, 6.9112, 6.9112, 121.94756008, 767236.9565529232, 767236.9565529232, 228730.5067140464], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6466800.0000, 
sim time next is 6467400.0000, 
raw observation next is [29.85, 65.5, 1.0, 2.0, 0.3411074140797937, 0.0, 1.0, 0.0, 1.0, 2.0, 0.543054112307942, 6.911199999999999, 6.9112, 121.9260426156618, 777521.6319909458, 777521.6319909461, 206623.9209198496], 
processed observation next is [1.0, 0.8695652173913043, 0.6611111111111112, 0.655, 1.0, 1.0, 0.2156040643807068, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.4288176403849274, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2776862971396235, 0.2776862971396236, 0.39735369407663385], 
reward next is 0.6026, 
noisyNet noise sample is [array([-0.7378526], dtype=float32), -0.58436817]. 
=============================================
[2019-03-23 03:28:01,384] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2293741: loss 13.9472
[2019-03-23 03:28:01,393] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2293743: learning rate 0.0010
[2019-03-23 03:28:02,356] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2294192: loss 64.0019
[2019-03-23 03:28:02,360] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2294195: learning rate 0.0010
[2019-03-23 03:28:02,517] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2294267: loss 33.0097
[2019-03-23 03:28:02,524] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2294267: learning rate 0.0010
[2019-03-23 03:28:04,499] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2295177: loss 4.4845
[2019-03-23 03:28:04,501] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2295177: learning rate 0.0010
[2019-03-23 03:28:04,768] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.7519665e-34], sum to 1.0000
[2019-03-23 03:28:04,777] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5720
[2019-03-23 03:28:04,781] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.06666666666667, 75.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9166168223724321, 6.911199999999999, 6.9112, 121.9260426156618, 666581.3403291394, 666581.3403291398, 178929.1639589762], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6565200.0000, 
sim time next is 6565800.0000, 
raw observation next is [26.03333333333333, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.889385734283133, 6.9112, 6.9112, 121.9260426156618, 652738.5717197552, 652738.5717197552, 174140.9172507425], 
processed observation next is [1.0, 1.0, 0.519753086419753, 0.735, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.861732167853916, 0.0, 0.0, 0.8094621288201359, 0.23312091847134114, 0.23312091847134114, 0.33488637932835097], 
reward next is 0.6651, 
noisyNet noise sample is [array([0.9956032], dtype=float32), 1.3339788]. 
=============================================
[2019-03-23 03:28:07,339] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2296479: loss -38.7424
[2019-03-23 03:28:07,340] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2296479: learning rate 0.0010
[2019-03-23 03:28:08,107] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7506148e-03 8.0440875e-21 7.5190272e-20 9.9622911e-01 2.0212517e-05], sum to 1.0000
[2019-03-23 03:28:08,114] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0906
[2019-03-23 03:28:08,117] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.16666666666667, 39.16666666666667, 1.0, 2.0, 0.52987464121591, 1.0, 2.0, 0.52987464121591, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425617062, 1301742.830833926, 1301742.830833926, 248454.8300832107], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6610200.0000, 
sim time next is 6610800.0000, 
raw observation next is [28.33333333333334, 38.33333333333334, 1.0, 2.0, 0.4263012444063691, 1.0, 2.0, 0.4263012444063691, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156454, 1049587.508913762, 1049587.508913762, 216521.1929417704], 
processed observation next is [1.0, 0.5217391304347826, 0.6049382716049385, 0.3833333333333334, 1.0, 1.0, 0.3170252909599632, 1.0, 1.0, 0.3170252909599632, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288200271, 0.374852681754915, 0.374852681754915, 0.4163869095034046], 
reward next is 0.5836, 
noisyNet noise sample is [array([1.9726005], dtype=float32), 0.99524295]. 
=============================================
[2019-03-23 03:28:08,194] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2296869: loss 31.2754
[2019-03-23 03:28:08,200] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2296871: learning rate 0.0010
[2019-03-23 03:28:09,616] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2297517: loss 31.6284
[2019-03-23 03:28:09,617] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2297518: learning rate 0.0010
[2019-03-23 03:28:09,892] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2297646: loss 16.2127
[2019-03-23 03:28:09,895] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2297646: learning rate 0.0010
[2019-03-23 03:28:10,057] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2297722: loss 8.9145
[2019-03-23 03:28:10,059] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2297722: learning rate 0.0010
[2019-03-23 03:28:11,906] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2298561: loss 95.9257
[2019-03-23 03:28:11,908] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2298561: learning rate 0.0010
[2019-03-23 03:28:11,966] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:28:11,971] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8414
[2019-03-23 03:28:11,977] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.25, 62.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7096876053874992, 6.9112, 6.9112, 121.9260426156618, 530333.20189525, 530333.20189525, 146125.0715145734], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6901800.0000, 
sim time next is 6902400.0000, 
raw observation next is [25.1, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7066999311397091, 6.911200000000001, 6.9112, 121.9260426156618, 528110.4046949175, 528110.404694917, 145649.1846605656], 
processed observation next is [0.0, 0.9130434782608695, 0.4851851851851852, 0.63, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6333749139246364, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1886108588196134, 0.18861085881961323, 0.2800945858857031], 
reward next is 0.7199, 
noisyNet noise sample is [array([0.22470105], dtype=float32), -0.12230818]. 
=============================================
[2019-03-23 03:28:12,484] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2298835: loss 13.0965
[2019-03-23 03:28:12,485] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2298836: learning rate 0.0010
[2019-03-23 03:28:13,468] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2299291: loss -33.4331
[2019-03-23 03:28:13,470] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2299291: learning rate 0.0010
[2019-03-23 03:28:14,417] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2299725: loss 3.8042
[2019-03-23 03:28:14,420] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2299727: learning rate 0.0010
[2019-03-23 03:28:14,685] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2299847: loss 33.7736
[2019-03-23 03:28:14,688] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2299848: learning rate 0.0010
[2019-03-23 03:28:15,020] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 03:28:15,025] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:28:15,026] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:28:15,027] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:28:15,027] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:28:15,028] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:28:15,028] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:28:15,028] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:28:15,031] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:28:15,029] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:28:15,035] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:28:15,054] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run93
[2019-03-23 03:28:15,086] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run93
[2019-03-23 03:28:15,087] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run93
[2019-03-23 03:28:15,124] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run93
[2019-03-23 03:28:15,126] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run93
[2019-03-23 03:29:00,331] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.6224634], dtype=float32), -0.010475699]
[2019-03-23 03:29:00,334] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.06666666666667, 88.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7492877398938007, 6.911200000000001, 6.9112, 121.9260426156618, 559109.8892705375, 559109.8892705371, 152328.5490571969]
[2019-03-23 03:29:00,335] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:29:00,339] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6755025299104576
[2019-03-23 03:29:01,440] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.6224634], dtype=float32), -0.010475699]
[2019-03-23 03:29:01,441] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [34.55008554, 41.27062134, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.912088246505364, 6.9112, 121.9260397684879, 1878531.877371148, 1878077.015780452, 384126.5178309904]
[2019-03-23 03:29:01,443] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:29:01,445] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.8047807e-13 4.6701791e-32 1.7834876e-38 9.9999976e-01 2.7055626e-07], sampled 0.8905262865900282
[2019-03-23 03:29:51,600] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.6224634], dtype=float32), -0.010475699]
[2019-03-23 03:29:51,602] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.75, 41.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5547936051821715, 6.911200000000001, 6.9112, 121.9260426156618, 408677.2588036188, 408677.2588036184, 124346.7449465657]
[2019-03-23 03:29:51,604] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:29:51,606] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.10517200316659503
[2019-03-23 03:29:55,598] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.6224634], dtype=float32), -0.010475699]
[2019-03-23 03:29:55,599] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.66666666666666, 56.0, 1.0, 2.0, 0.3833016210764407, 1.0, 1.0, 0.3833016210764407, 1.0, 1.0, 0.6102286640159902, 6.911200000000001, 6.9112, 121.94756008, 1311004.718487871, 1311004.718487871, 289844.6045839333]
[2019-03-23 03:29:55,600] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:29:55,602] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.1059577e-18 0.0000000e+00 0.0000000e+00 2.0213592e-29 1.0000000e+00], sampled 0.8278583737926604
[2019-03-23 03:30:01,650] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.6224634], dtype=float32), -0.010475699]
[2019-03-23 03:30:01,650] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7103788548366305, 6.911200000000001, 6.9112, 121.9260426156618, 530549.150233149, 530549.1502331485, 147165.405628414]
[2019-03-23 03:30:01,651] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:30:01,655] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.10150859041961768
[2019-03-23 03:30:02,123] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.6224634], dtype=float32), -0.010475699]
[2019-03-23 03:30:02,125] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.559853805, 60.58240347, 1.0, 2.0, 0.1787483516776395, 1.0, 2.0, 0.1787483516776395, 1.0, 2.0, 0.2851931848119907, 6.911199999999999, 6.9112, 121.94756008, 622679.0339589912, 622679.0339589916, 213735.2613624502]
[2019-03-23 03:30:02,129] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:30:02,132] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.948242e-18 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00], sampled 0.8982142239602927
[2019-03-23 03:30:06,557] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8426.4296 2370366962.9774 278.0000
[2019-03-23 03:30:06,723] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8351.2088 2424962211.4867 272.0000
[2019-03-23 03:30:06,724] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7813.5526 2665741952.3918 353.0000
[2019-03-23 03:30:06,734] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8274.2997 2426906051.2921 310.0000
[2019-03-23 03:30:06,936] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8254.5923 2470441387.7300 273.0000
[2019-03-23 03:30:07,953] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2300000, evaluation results [2300000.0, 7813.552602139837, 2665741952.3917956, 353.0, 8351.20876254563, 2424962211.48671, 272.0, 8426.42957356647, 2370366962.977438, 278.0, 8254.59228745538, 2470441387.7299857, 273.0, 8274.29973995096, 2426906051.2920637, 310.0]
[2019-03-23 03:30:08,164] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5036030e-02 1.2824001e-26 1.2696930e-37 2.4330242e-15 9.7496402e-01], sum to 1.0000
[2019-03-23 03:30:08,169] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2064
[2019-03-23 03:30:08,173] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.16666666666667, 28.0, 1.0, 2.0, 0.3429424622849946, 1.0, 2.0, 0.3429424622849946, 1.0, 2.0, 0.5645837703109703, 6.9112, 6.9112, 121.94756008, 1266330.332413011, 1266330.332413011, 271331.4093589554], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6709800.0000, 
sim time next is 6710400.0000, 
raw observation next is [30.2, 28.0, 1.0, 2.0, 0.3302996496133215, 1.0, 2.0, 0.3302996496133215, 1.0, 2.0, 0.5438302381668297, 6.911200000000001, 6.9112, 121.94756008, 1219741.634613231, 1219741.634613231, 266222.3814806208], 
processed observation next is [1.0, 0.6956521739130435, 0.674074074074074, 0.28, 1.0, 1.0, 0.202737678111097, 1.0, 1.0, 0.202737678111097, 1.0, 1.0, 0.42978779770853714, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.43562201236186826, 0.43562201236186826, 0.5119661182319631], 
reward next is 0.4880, 
noisyNet noise sample is [array([1.7472247], dtype=float32), 0.3154577]. 
=============================================
[2019-03-23 03:30:08,654] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2300361: loss 9.6651
[2019-03-23 03:30:08,655] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2300361: learning rate 0.0010
[2019-03-23 03:30:09,061] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2300566: loss 8.8542
[2019-03-23 03:30:09,062] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2300567: learning rate 0.0010
[2019-03-23 03:30:10,812] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2301475: loss 10.3177
[2019-03-23 03:30:10,814] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2301476: learning rate 0.0010
[2019-03-23 03:30:11,777] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2301959: loss 0.0171
[2019-03-23 03:30:11,779] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2301960: learning rate 0.0010
[2019-03-23 03:30:11,857] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2302000: loss 6.2845
[2019-03-23 03:30:11,860] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2302000: learning rate 0.0010
[2019-03-23 03:30:13,782] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2302976: loss 6.2805
[2019-03-23 03:30:13,792] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2302976: learning rate 0.0010
[2019-03-23 03:30:16,438] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2304338: loss 3.1318
[2019-03-23 03:30:16,442] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2304338: learning rate 0.0010
[2019-03-23 03:30:17,328] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2304796: loss 4.3212
[2019-03-23 03:30:17,332] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2304796: learning rate 0.0010
[2019-03-23 03:30:18,687] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2305492: loss 2.2931
[2019-03-23 03:30:18,691] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2305492: learning rate 0.0010
[2019-03-23 03:30:18,799] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2305550: loss 2.2879
[2019-03-23 03:30:18,800] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2305550: learning rate 0.0010
[2019-03-23 03:30:19,196] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2305751: loss 3.2916
[2019-03-23 03:30:19,198] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2305752: learning rate 0.0010
[2019-03-23 03:30:20,852] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2306597: loss 1.7398
[2019-03-23 03:30:20,855] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2306599: learning rate 0.0010
[2019-03-23 03:30:21,164] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:30:21,170] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7828
[2019-03-23 03:30:21,175] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.7, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4691331103139398, 6.911200000000001, 6.9112, 121.9260426156618, 334976.5147017079, 334976.5147017075, 108560.8104443203], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7694400.0000, 
sim time next is 7695000.0000, 
raw observation next is [19.7, 64.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4565474279702196, 6.9112, 6.9112, 121.9260426156618, 325973.8848272386, 325973.8848272386, 105338.4409356286], 
processed observation next is [1.0, 0.043478260869565216, 0.28518518518518515, 0.645, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.32068428496277446, 0.0, 0.0, 0.8094621288201359, 0.11641924458115666, 0.11641924458115666, 0.20257392487620884], 
reward next is 0.7974, 
noisyNet noise sample is [array([0.5943548], dtype=float32), -0.80238986]. 
=============================================
[2019-03-23 03:30:21,190] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[68.4938  ]
 [68.10529 ]
 [67.75674 ]
 [67.19833 ]
 [66.655334]], R is [[68.95256042]
 [69.05426788]
 [69.14825439]
 [69.2358551 ]
 [69.32071686]].
[2019-03-23 03:30:21,442] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2306902: loss -140.5363
[2019-03-23 03:30:21,444] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2306903: learning rate 0.0010
[2019-03-23 03:30:22,354] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2307370: loss 2.6976
[2019-03-23 03:30:22,356] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2307370: learning rate 0.0010
[2019-03-23 03:30:22,974] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2307692: loss 1.1270
[2019-03-23 03:30:22,976] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2307692: learning rate 0.0010
[2019-03-23 03:30:23,308] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2307860: loss 1.4721
[2019-03-23 03:30:23,310] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2307860: learning rate 0.0010
[2019-03-23 03:30:23,705] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:30:23,711] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6055
[2019-03-23 03:30:23,715] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.9, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6174770818624168, 6.911200000000001, 6.9112, 121.9260426156618, 459180.6708072195, 459180.670807219, 132688.1018884638], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7254000.0000, 
sim time next is 7254600.0000, 
raw observation next is [20.88333333333333, 81.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6152415203793438, 6.911200000000001, 6.9112, 121.9260426156618, 457482.9436839242, 457482.9436839237, 132443.7261126269], 
processed observation next is [1.0, 1.0, 0.3290123456790122, 0.8116666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5190519004741797, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1633867656014015, 0.1633867656014013, 0.2546994732935133], 
reward next is 0.7453, 
noisyNet noise sample is [array([-0.91456664], dtype=float32), 0.43976113]. 
=============================================
[2019-03-23 03:30:24,300] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2308374: loss 0.8250
[2019-03-23 03:30:24,301] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2308374: learning rate 0.0010
[2019-03-23 03:30:24,691] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2308577: loss 1.4065
[2019-03-23 03:30:24,695] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2308578: learning rate 0.0010
[2019-03-23 03:30:26,652] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2309589: loss -56.8100
[2019-03-23 03:30:26,654] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2309589: learning rate 0.0010
[2019-03-23 03:30:26,750] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:30:26,757] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1270
[2019-03-23 03:30:26,762] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.75, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7333801444959389, 6.9112, 6.9112, 121.9260426156618, 545862.8281153429, 545862.8281153429, 144889.7545047463], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7111800.0000, 
sim time next is 7112400.0000, 
raw observation next is [20.73333333333333, 82.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7658897991098967, 6.911200000000001, 6.9112, 121.9260426156618, 569848.1066440182, 569848.1066440177, 148243.6145485624], 
processed observation next is [1.0, 0.30434782608695654, 0.3234567901234567, 0.8266666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.707362248887371, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20351718094429222, 0.20351718094429205, 0.28508387413185077], 
reward next is 0.7149, 
noisyNet noise sample is [array([-0.58335096], dtype=float32), -1.0595076]. 
=============================================
[2019-03-23 03:30:27,111] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:30:27,121] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9467
[2019-03-23 03:30:27,129] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1626114.167735703 W.
[2019-03-23 03:30:27,135] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.11666666666667, 79.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9560153003795288, 8.689419005682478, 6.9112, 122.0372492819628, 1626114.167735703, 714676.5522232375, 169442.5798363363], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7006200.0000, 
sim time next is 7006800.0000, 
raw observation next is [22.03333333333333, 80.33333333333334, 1.0, 1.0, 0.4421808296729, 1.0, 1.0, 0.4421808296729, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9249717933685, 1074631.17778363, 1074631.17778363, 220780.3985222766], 
processed observation next is [1.0, 0.08695652173913043, 0.37160493827160485, 0.8033333333333335, 1.0, 0.5, 0.3359295591344048, 1.0, 0.5, 0.3359295591344048, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094550196736852, 0.3837968492084393, 0.3837968492084393, 0.42457768946591656], 
reward next is 0.5754, 
noisyNet noise sample is [array([-0.15127064], dtype=float32), -0.30160657]. 
=============================================
[2019-03-23 03:30:27,383] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2309960: loss -141.8293
[2019-03-23 03:30:27,386] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2309962: learning rate 0.0010
[2019-03-23 03:30:27,750] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2310146: loss -2.1788
[2019-03-23 03:30:27,754] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2310148: learning rate 0.0010
[2019-03-23 03:30:27,812] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.9611647e-02 2.4474931e-34 3.0029438e-34 4.5285134e-12 9.7038841e-01], sum to 1.0000
[2019-03-23 03:30:27,822] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5439
[2019-03-23 03:30:27,827] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.7, 74.5, 1.0, 2.0, 0.3822615532798959, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6250977915348126, 6.911199999999999, 6.9112, 121.9260426156618, 934099.6569732078, 934099.6569732083, 216159.6590503421], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7212600.0000, 
sim time next is 7213200.0000, 
raw observation next is [22.8, 74.0, 1.0, 2.0, 0.2647160356213225, 1.0, 1.0, 0.2647160356213225, 1.0, 2.0, 0.4296390841310733, 6.911200000000001, 6.9112, 121.94756008, 960937.882396621, 960937.8823966206, 242020.9718619421], 
processed observation next is [1.0, 0.4782608695652174, 0.4, 0.74, 1.0, 1.0, 0.12466194716824108, 1.0, 0.5, 0.12466194716824108, 1.0, 1.0, 0.2870488551638416, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3431921008559361, 0.34319210085593593, 0.46542494588835015], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.11748916], dtype=float32), -0.5435437]. 
=============================================
[2019-03-23 03:30:28,047] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:30:28,061] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6679
[2019-03-23 03:30:28,064] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.68333333333334, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8600968312143407, 6.911200000000001, 6.9112, 121.9260426156618, 642792.285785404, 642792.2857854036, 163273.0970825971], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7024200.0000, 
sim time next is 7024800.0000, 
raw observation next is [21.76666666666667, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8880330341456603, 6.911200000000001, 6.9112, 121.9260426156618, 663680.1257801718, 663680.1257801714, 166794.1883191149], 
processed observation next is [1.0, 0.30434782608695654, 0.3617283950617285, 0.8533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8600412926820752, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23702861635006137, 0.2370286163500612, 0.32075805445983635], 
reward next is 0.6792, 
noisyNet noise sample is [array([-1.0790058], dtype=float32), -0.27399394]. 
=============================================
[2019-03-23 03:30:28,941] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:30:28,947] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3056
[2019-03-23 03:30:28,953] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.83333333333334, 84.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6736079277167443, 6.9112, 6.9112, 121.9260426156618, 502058.3452419374, 502058.3452419374, 139290.1949775111], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7108800.0000, 
sim time next is 7109400.0000, 
raw observation next is [20.81666666666667, 84.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6679332927188707, 6.911199999999999, 6.9112, 121.9260426156618, 497728.3717399008, 497728.3717399013, 138602.0235371225], 
processed observation next is [1.0, 0.2608695652173913, 0.32654320987654334, 0.8416666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5849166158985883, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1777601327642503, 0.17776013276425046, 0.2665423529560048], 
reward next is 0.7335, 
noisyNet noise sample is [array([-0.30618623], dtype=float32), -1.2815228]. 
=============================================
[2019-03-23 03:30:29,448] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2311020: loss 38.6767
[2019-03-23 03:30:29,452] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2311021: learning rate 0.0010
[2019-03-23 03:30:31,102] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9588263e-01 6.4104005e-33 0.0000000e+00 0.0000000e+00 4.1173701e-03], sum to 1.0000
[2019-03-23 03:30:31,109] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5989
[2019-03-23 03:30:31,115] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.83333333333334, 67.16666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2471121235955163, 6.9112, 6.9112, 121.94756008, 554004.8437963828, 554004.8437963828, 201715.9565985695], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7146600.0000, 
sim time next is 7147200.0000, 
raw observation next is [22.66666666666667, 68.33333333333334, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6076895875706518, 6.9112, 6.9112, 121.9260426156618, 453004.7744450778, 453004.7744450778, 132777.1404240367], 
processed observation next is [1.0, 0.7391304347826086, 0.39506172839506193, 0.6833333333333335, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.5096119844633148, 0.0, 0.0, 0.8094621288201359, 0.16178741944467065, 0.16178741944467065, 0.25534065466160905], 
reward next is 0.7447, 
noisyNet noise sample is [array([-2.3397305], dtype=float32), 0.24908625]. 
=============================================
[2019-03-23 03:30:31,969] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9930521e-05 7.1950696e-29 6.2756525e-36 7.2932448e-16 9.9998009e-01], sum to 1.0000
[2019-03-23 03:30:31,974] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8271
[2019-03-23 03:30:31,978] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.46666666666667, 66.33333333333334, 1.0, 2.0, 0.5016851822141639, 1.0, 2.0, 0.5016851822141639, 1.0, 2.0, 0.7987277958025868, 6.9112, 6.9112, 121.94756008, 1717713.963614356, 1717713.963614356, 344427.408289535], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7053600.0000, 
sim time next is 7054200.0000, 
raw observation next is [26.2, 67.5, 1.0, 2.0, 0.5131334152673908, 1.0, 2.0, 0.5131334152673908, 1.0, 2.0, 0.8169251086943247, 6.911200000000001, 6.9112, 121.94756008, 1755548.317123574, 1755548.317123574, 350081.8513032509], 
processed observation next is [1.0, 0.6521739130434783, 0.5259259259259259, 0.675, 1.0, 1.0, 0.4203969229373699, 1.0, 1.0, 0.4203969229373699, 1.0, 1.0, 0.7711563858679057, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6269815418298479, 0.6269815418298479, 0.6732343294293286], 
reward next is 0.3268, 
noisyNet noise sample is [array([-1.5396262], dtype=float32), -0.3091117]. 
=============================================
[2019-03-23 03:30:32,048] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2312349: loss 34.0349
[2019-03-23 03:30:32,050] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2312349: learning rate 0.0010
[2019-03-23 03:30:33,071] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2312874: loss -11.9359
[2019-03-23 03:30:33,075] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2312874: learning rate 0.0010
[2019-03-23 03:30:34,319] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2313515: loss -14.8969
[2019-03-23 03:30:34,321] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2313515: learning rate 0.0010
[2019-03-23 03:30:34,441] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2313574: loss 3.9315
[2019-03-23 03:30:34,444] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2313574: learning rate 0.0010
[2019-03-23 03:30:34,578] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2313642: loss -5.9012
[2019-03-23 03:30:34,579] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2313642: learning rate 0.0010
[2019-03-23 03:30:35,566] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:30:35,567] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:30:35,629] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run12
[2019-03-23 03:30:35,738] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:30:35,746] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3471
[2019-03-23 03:30:35,750] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.23333333333333, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6210168654672152, 6.911200000000001, 6.9112, 121.9260426156618, 462284.9926170888, 462284.9926170883, 133433.1913499802], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7368000.0000, 
sim time next is 7368600.0000, 
raw observation next is [19.21666666666667, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.618610092824022, 6.911199999999999, 6.9112, 121.9260426156618, 460442.8929499286, 460442.8929499291, 133153.5213687394], 
processed observation next is [1.0, 0.2608695652173913, 0.267283950617284, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5232626160300274, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1644438903392602, 0.1644438903392604, 0.2560644641706527], 
reward next is 0.7439, 
noisyNet noise sample is [array([-1.723852], dtype=float32), 0.29996812]. 
=============================================
[2019-03-23 03:30:36,105] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2314447: loss 48.4411
[2019-03-23 03:30:36,108] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2314448: learning rate 0.0010
[2019-03-23 03:30:36,519] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:30:36,525] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4556
[2019-03-23 03:30:36,533] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.8, 94.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6407771205679045, 6.911200000000001, 6.9112, 121.9260426156618, 477927.2161300212, 477927.2161300208, 136343.9072356057], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7177200.0000, 
sim time next is 7177800.0000, 
raw observation next is [19.8, 94.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.641889699133506, 6.911200000000001, 6.9112, 121.9260426156618, 478838.4914127259, 478838.4914127255, 136558.5222151428], 
processed observation next is [1.0, 0.043478260869565216, 0.2888888888888889, 0.9466666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5523621239168824, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17101374693311638, 0.17101374693311625, 0.2626125427214284], 
reward next is 0.7374, 
noisyNet noise sample is [array([-0.926048], dtype=float32), -0.4245007]. 
=============================================
[2019-03-23 03:30:36,623] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2314771: loss 0.0365
[2019-03-23 03:30:36,627] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2314774: learning rate 0.0010
[2019-03-23 03:30:36,822] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:30:36,830] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4818
[2019-03-23 03:30:36,834] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.71666666666667, 83.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6148477485933103, 6.911200000000001, 6.9112, 121.9260426156618, 457640.6342994961, 457640.6342994956, 132786.5256649448], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7260600.0000, 
sim time next is 7261200.0000, 
raw observation next is [20.7, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6157246528025868, 6.911200000000001, 6.9112, 121.9260426156618, 458368.1614068943, 458368.1614068938, 132938.6965094823], 
processed observation next is [1.0, 0.043478260869565216, 0.3222222222222222, 0.84, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5196558160032335, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16370291478817653, 0.16370291478817636, 0.25565133944131213], 
reward next is 0.7443, 
noisyNet noise sample is [array([0.13347061], dtype=float32), 0.71621865]. 
=============================================
[2019-03-23 03:30:37,415] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2315264: loss -43.3844
[2019-03-23 03:30:37,417] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2315264: learning rate 0.0010
[2019-03-23 03:30:37,999] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2315645: loss 38.1144
[2019-03-23 03:30:37,999] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2315645: learning rate 0.0010
[2019-03-23 03:30:38,199] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2315768: loss 13.2119
[2019-03-23 03:30:38,203] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2315769: learning rate 0.0010
[2019-03-23 03:30:39,198] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2316228: loss 90.9748
[2019-03-23 03:30:39,200] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2316229: learning rate 0.0010
[2019-03-23 03:30:39,469] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.6572882e-38 7.9639857e-35 2.9588794e-33 9.0970467e-09], sum to 1.0000
[2019-03-23 03:30:39,475] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1384
[2019-03-23 03:30:39,486] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 913514.2435794857 W.
[2019-03-23 03:30:39,490] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.8, 70.0, 1.0, 2.0, 0.2531957336758962, 1.0, 2.0, 0.2531957336758962, 1.0, 2.0, 0.4093416559855907, 6.911200000000001, 6.9112, 121.94756008, 913514.2435794857, 913514.2435794852, 238089.9768021426], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7232400.0000, 
sim time next is 7233000.0000, 
raw observation next is [23.73333333333333, 70.33333333333334, 1.0, 2.0, 0.2460585236621823, 1.0, 2.0, 0.2460585236621823, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 596754.5377521699, 596754.5377521699, 169610.5356671638], 
processed observation next is [1.0, 0.7391304347826086, 0.4345679012345678, 0.7033333333333335, 1.0, 1.0, 0.10245062340735989, 1.0, 1.0, 0.10245062340735989, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21312662062577495, 0.21312662062577495, 0.32617410705223804], 
reward next is 0.6738, 
noisyNet noise sample is [array([0.8529531], dtype=float32), 0.78461903]. 
=============================================
[2019-03-23 03:30:39,505] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[62.666946]
 [62.855904]
 [62.415756]
 [62.70581 ]
 [62.21734 ]], R is [[62.94141388]
 [62.85413361]
 [62.22559357]
 [61.60333633]
 [60.98730469]].
[2019-03-23 03:30:39,664] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2316439: loss -11.6940
[2019-03-23 03:30:39,666] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2316439: learning rate 0.0010
[2019-03-23 03:30:40,880] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:30:40,890] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5049
[2019-03-23 03:30:40,898] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.83333333333334, 85.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6442001673133613, 6.911200000000001, 6.9112, 121.9260426156618, 480386.9931750802, 480386.9931750797, 136576.3841598018], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7347000.0000, 
sim time next is 7347600.0000, 
raw observation next is [20.8, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6408360226170791, 6.911199999999999, 6.9112, 121.9260426156618, 477753.9902285848, 477753.9902285853, 136095.0916653586], 
processed observation next is [1.0, 0.043478260869565216, 0.32592592592592595, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5510450282713488, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17062642508163742, 0.1706264250816376, 0.2617213301256896], 
reward next is 0.7383, 
noisyNet noise sample is [array([-0.28291512], dtype=float32), -1.7606204]. 
=============================================
[2019-03-23 03:30:41,985] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2317502: loss 0.0072
[2019-03-23 03:30:41,988] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2317503: learning rate 0.0010
[2019-03-23 03:30:43,066] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2317996: loss 59.9546
[2019-03-23 03:30:43,068] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2317996: learning rate 0.0010
[2019-03-23 03:30:45,230] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2319000: loss 0.1500
[2019-03-23 03:30:45,232] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2319000: learning rate 0.0010
[2019-03-23 03:30:47,260] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:30:47,273] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6438
[2019-03-23 03:30:47,277] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.18333333333333, 94.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.716100277912865, 6.911200000000001, 6.9112, 121.9260426156618, 534754.4986671219, 534754.4986671214, 147932.3969201597], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7546200.0000, 
sim time next is 7546800.0000, 
raw observation next is [21.36666666666667, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7228733637916154, 6.911200000000001, 6.9112, 121.9260426156618, 539650.2029755574, 539650.2029755571, 148950.6328990881], 
processed observation next is [0.0, 0.34782608695652173, 0.3469135802469137, 0.9366666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6535917047395192, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19273221534841337, 0.19273221534841323, 0.28644352480593865], 
reward next is 0.7136, 
noisyNet noise sample is [array([0.54301405], dtype=float32), -2.3450134]. 
=============================================
[2019-03-23 03:30:47,909] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2320234: loss 0.0111
[2019-03-23 03:30:47,911] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2320234: learning rate 0.0010
[2019-03-23 03:30:48,398] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:30:48,407] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0652
[2019-03-23 03:30:48,413] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.26666666666667, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6218217104410563, 6.9112, 6.9112, 121.9260426156618, 462983.9629358673, 462983.9629358673, 133602.6792665643], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7366800.0000, 
sim time next is 7367400.0000, 
raw observation next is [19.25, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.621368495881273, 6.911199999999999, 6.9112, 121.9260426156618, 462596.6022728196, 462596.60227282, 133512.624312126], 
processed observation next is [1.0, 0.2608695652173913, 0.26851851851851855, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5267106198515912, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16521307224029272, 0.16521307224029286, 0.25675504675408845], 
reward next is 0.7432, 
noisyNet noise sample is [array([-1.0981524], dtype=float32), 1.681274]. 
=============================================
[2019-03-23 03:30:48,918] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2320692: loss 0.0009
[2019-03-23 03:30:48,920] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2320692: learning rate 0.0010
[2019-03-23 03:30:50,245] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2321301: loss 0.0008
[2019-03-23 03:30:50,249] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2321301: learning rate 0.0010
[2019-03-23 03:30:50,421] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2321378: loss 0.0007
[2019-03-23 03:30:50,423] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2321380: learning rate 0.0010
[2019-03-23 03:30:50,698] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:30:50,706] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5045
[2019-03-23 03:30:50,712] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.55, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7537317641524119, 6.9112, 6.9112, 121.9260426156618, 561694.9564563495, 561694.9564563495, 153534.8581931034], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7516200.0000, 
sim time next is 7516800.0000, 
raw observation next is [21.5, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.749913208136754, 6.911200000000001, 6.9112, 121.9260426156618, 558998.2359981152, 558998.2359981147, 152961.3304392721], 
processed observation next is [0.0, 0.0, 0.35185185185185186, 0.95, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6873915101709424, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.199642227142184, 0.19964222714218383, 0.29415640469090787], 
reward next is 0.7058, 
noisyNet noise sample is [array([1.9827527], dtype=float32), -0.8890188]. 
=============================================
[2019-03-23 03:30:50,742] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2321522: loss 0.0075
[2019-03-23 03:30:50,744] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2321523: learning rate 0.0010
[2019-03-23 03:30:51,453] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:30:51,462] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9241
[2019-03-23 03:30:51,469] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.7, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.627649682359925, 6.911200000000001, 6.9112, 121.9260426156618, 467689.6465647605, 467689.64656476, 134529.8385306333], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7438800.0000, 
sim time next is 7439400.0000, 
raw observation next is [19.65, 93.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6263582388516441, 6.9112, 6.9112, 121.9260426156618, 466647.3483365031, 466647.3483365031, 134321.2177482813], 
processed observation next is [0.0, 0.08695652173913043, 0.28333333333333327, 0.935, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5329477985645551, 0.0, 0.0, 0.8094621288201359, 0.16665976726303683, 0.16665976726303683, 0.2583100341313102], 
reward next is 0.7417, 
noisyNet noise sample is [array([-2.6642685], dtype=float32), 1.3507634]. 
=============================================
[2019-03-23 03:30:52,753] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2322447: loss 0.0027
[2019-03-23 03:30:52,756] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2322447: learning rate 0.0010
[2019-03-23 03:30:53,221] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2322655: loss -40.8587
[2019-03-23 03:30:53,227] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2322655: learning rate 0.0010
[2019-03-23 03:30:54,693] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2323330: loss 0.0056
[2019-03-23 03:30:54,694] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2323330: learning rate 0.0010
[2019-03-23 03:30:55,620] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2323754: loss 0.0017
[2019-03-23 03:30:55,622] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2323755: learning rate 0.0010
[2019-03-23 03:30:55,646] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2323763: loss 0.0004
[2019-03-23 03:30:55,648] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2323763: learning rate 0.0010
[2019-03-23 03:30:57,088] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2324426: loss 0.0018
[2019-03-23 03:30:57,089] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2324427: learning rate 0.0010
[2019-03-23 03:30:57,319] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2324536: loss 0.0012
[2019-03-23 03:30:57,321] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2324537: learning rate 0.0010
[2019-03-23 03:30:58,332] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 03:30:58,335] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:30:58,339] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:30:58,341] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:30:58,342] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:30:58,343] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:30:58,343] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:30:58,344] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:30:58,345] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:30:58,346] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:30:58,347] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:30:58,372] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run94
[2019-03-23 03:30:58,402] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run94
[2019-03-23 03:30:58,404] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run94
[2019-03-23 03:30:58,404] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run94
[2019-03-23 03:30:58,404] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run94
[2019-03-23 03:31:01,641] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.30587366], dtype=float32), -0.07197179]
[2019-03-23 03:31:01,644] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [35.01883824000001, 9.44377232166667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7500860104402721, 6.911199999999999, 6.9112, 121.9260426156618, 536962.380641764, 536962.3806417645, 134182.1694565996]
[2019-03-23 03:31:01,646] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:31:01,648] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5653298633972914
[2019-03-23 03:31:07,333] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.30587366], dtype=float32), -0.07197179]
[2019-03-23 03:31:07,335] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.51666666666667, 24.0, 1.0, 2.0, 0.5837882869822013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156574, 739546.6529958431, 739546.6529958431, 157789.4682588344]
[2019-03-23 03:31:07,336] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:31:07,340] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.1244239e-25 1.4181930e-24], sampled 0.6612829597902233
[2019-03-23 03:31:07,341] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 739546.6529958431 W.
[2019-03-23 03:32:49,066] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8561.0473 2280765093.9471 383.0000
[2019-03-23 03:32:49,104] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8317.3772 2387193843.1321 397.0000
[2019-03-23 03:32:49,287] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8397.4210 2341165534.4018 449.0000
[2019-03-23 03:32:49,340] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7842.5048 2577856687.2296 527.0000
[2019-03-23 03:32:49,443] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8475.4489 2329442486.6813 389.0000
[2019-03-23 03:32:50,461] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2325000, evaluation results [2325000.0, 7842.504788252383, 2577856687.229572, 527.0, 8475.448938340478, 2329442486.6813498, 389.0, 8561.047291108072, 2280765093.9471345, 383.0, 8317.377233402343, 2387193843.1320944, 397.0, 8397.421004072548, 2341165534.4017725, 449.0]
[2019-03-23 03:32:51,669] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2325629: loss -174.1207
[2019-03-23 03:32:51,670] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2325629: learning rate 0.0010
[2019-03-23 03:32:52,621] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2326117: loss 18.5294
[2019-03-23 03:32:52,626] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2326118: learning rate 0.0010
[2019-03-23 03:32:53,500] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.631246e-14 0.000000e+00 0.000000e+00 1.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 03:32:53,507] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3410
[2019-03-23 03:32:53,512] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.73333333333333, 36.66666666666667, 1.0, 2.0, 0.5312472231127642, 1.0, 1.0, 0.5312472231127642, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1277969.008194419, 1277969.00819442, 248055.6935492519], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7827600.0000, 
sim time next is 7828200.0000, 
raw observation next is [30.8, 36.5, 1.0, 2.0, 0.5296300643798708, 1.0, 2.0, 0.5296300643798708, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1273534.063732586, 1273534.063732586, 247509.8872702289], 
processed observation next is [1.0, 0.6086956521739131, 0.6962962962962963, 0.365, 1.0, 1.0, 0.4400357909284176, 1.0, 1.0, 0.4400357909284176, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4548335941902093, 0.4548335941902093, 0.4759805524427479], 
reward next is 0.5240, 
noisyNet noise sample is [array([-0.4540836], dtype=float32), 0.34395447]. 
=============================================
[2019-03-23 03:32:54,086] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:32:54,087] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:32:54,148] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run12
[2019-03-23 03:32:54,398] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2327023: loss -47.8949
[2019-03-23 03:32:54,401] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2327024: learning rate 0.0010
[2019-03-23 03:32:56,119] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:32:56,125] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6467
[2019-03-23 03:32:56,127] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.93333333333333, 76.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5397267850311164, 6.911199999999999, 6.9112, 121.9260426156618, 394503.4325814692, 394503.4325814696, 121582.1805181828], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7677600.0000, 
sim time next is 7678200.0000, 
raw observation next is [19.91666666666666, 77.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.544518707132612, 6.911200000000001, 6.9112, 121.9260426156618, 398424.6568671672, 398424.6568671668, 122169.2836427285], 
processed observation next is [1.0, 0.8695652173913043, 0.2932098765432097, 0.7733333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43064838391576493, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14229452030970258, 0.14229452030970244, 0.23494093008217018], 
reward next is 0.7651, 
noisyNet noise sample is [array([0.5925259], dtype=float32), 0.16561584]. 
=============================================
[2019-03-23 03:32:56,434] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2328191: loss 121.2251
[2019-03-23 03:32:56,437] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2328191: learning rate 0.0010
[2019-03-23 03:32:57,377] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2328676: loss -4.3721
[2019-03-23 03:32:57,381] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2328677: learning rate 0.0010
[2019-03-23 03:32:58,383] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2329195: loss -14.7913
[2019-03-23 03:32:58,385] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2329196: learning rate 0.0010
[2019-03-23 03:32:58,595] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2329308: loss -171.3560
[2019-03-23 03:32:58,599] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2329308: learning rate 0.0010
[2019-03-23 03:32:58,680] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2329350: loss -90.4881
[2019-03-23 03:32:58,682] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2329351: learning rate 0.0010
[2019-03-23 03:32:58,923] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:32:58,933] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3649
[2019-03-23 03:32:58,937] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.1, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6982600130968206, 6.911199999999999, 6.9112, 121.9260426156618, 521785.3798909961, 521785.3798909966, 144314.142217532], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7857000.0000, 
sim time next is 7857600.0000, 
raw observation next is [24.0, 68.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6982787144169178, 6.911200000000001, 6.9112, 121.9260426156618, 521783.3696408105, 521783.36964081, 144202.9332465554], 
processed observation next is [1.0, 0.9565217391304348, 0.4444444444444444, 0.6833333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6228483930211473, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1863512034431466, 0.18635120344314643, 0.2773133331664527], 
reward next is 0.7227, 
noisyNet noise sample is [array([-0.67376155], dtype=float32), -0.074449144]. 
=============================================
[2019-03-23 03:32:59,475] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:32:59,475] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:32:59,539] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run12
[2019-03-23 03:32:59,615] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9789029e-03 5.1711369e-30 3.1880091e-30 9.9602109e-01 1.9418654e-17], sum to 1.0000
[2019-03-23 03:32:59,619] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7345
[2019-03-23 03:32:59,624] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.2, 50.0, 1.0, 2.0, 0.6704779531121849, 1.0, 2.0, 0.6704779531121849, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1568068.608342447, 1568068.608342447, 295024.2591117388], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7747200.0000, 
sim time next is 7747800.0000, 
raw observation next is [29.16666666666666, 50.33333333333334, 1.0, 2.0, 0.6621658426263832, 1.0, 2.0, 0.6621658426263832, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1547391.044775874, 1547391.044775874, 291891.1130774338], 
processed observation next is [1.0, 0.6956521739130435, 0.6358024691358023, 0.5033333333333334, 1.0, 1.0, 0.5978164793171229, 1.0, 1.0, 0.5978164793171229, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5526396588485264, 0.5526396588485264, 0.5613290636104495], 
reward next is 0.4387, 
noisyNet noise sample is [array([0.31473878], dtype=float32), -1.8394636]. 
=============================================
[2019-03-23 03:33:00,214] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2330171: loss -100.1048
[2019-03-23 03:33:00,215] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2330171: learning rate 0.0010
[2019-03-23 03:33:00,317] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:33:00,317] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:00,365] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run12
[2019-03-23 03:33:00,524] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:33:00,530] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6990
[2019-03-23 03:33:00,533] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.65, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7053665150697953, 6.9112, 6.9112, 121.9260426156618, 527106.5209327815, 527106.5209327815, 145610.5183126413], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7853400.0000, 
sim time next is 7854000.0000, 
raw observation next is [24.56666666666667, 66.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7030829869433866, 6.9112, 6.9112, 121.9260426156618, 525404.3844410321, 525404.3844410321, 145292.8072977656], 
processed observation next is [1.0, 0.9130434782608695, 0.46543209876543223, 0.6633333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6288537336792333, 0.0, 0.0, 0.8094621288201359, 0.1876444230146543, 0.1876444230146543, 0.2794092448033954], 
reward next is 0.7206, 
noisyNet noise sample is [array([-0.5685619], dtype=float32), 0.8173832]. 
=============================================
[2019-03-23 03:33:00,539] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[65.505615]
 [65.40161 ]
 [65.44532 ]
 [65.39882 ]
 [65.4204  ]], R is [[65.59640503]
 [65.66042328]
 [65.72286224]
 [65.78356171]
 [65.84302521]].
[2019-03-23 03:33:01,502] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2330974: loss -8.6871
[2019-03-23 03:33:01,504] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2330974: learning rate 0.0010
[2019-03-23 03:33:01,758] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:33:01,758] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:01,790] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run12
[2019-03-23 03:33:02,209] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2331361: loss -59.9534
[2019-03-23 03:33:02,212] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2331362: learning rate 0.0010
[2019-03-23 03:33:02,312] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2331424: loss -152.3614
[2019-03-23 03:33:02,313] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2331424: learning rate 0.0010
[2019-03-23 03:33:03,066] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2331893: loss 19.0206
[2019-03-23 03:33:03,068] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2331893: learning rate 0.0010
[2019-03-23 03:33:03,321] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2332028: loss -35.9352
[2019-03-23 03:33:03,322] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2332029: learning rate 0.0010
[2019-03-23 03:33:03,602] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:33:03,602] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:03,671] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run12
[2019-03-23 03:33:04,275] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:33:04,277] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:04,316] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run12
[2019-03-23 03:33:05,280] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:33:05,281] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:05,324] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run12
[2019-03-23 03:33:05,357] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:33:05,357] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:05,396] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run12
[2019-03-23 03:33:05,530] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:33:05,530] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:05,576] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run12
[2019-03-23 03:33:06,636] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:33:06,636] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:06,681] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run12
[2019-03-23 03:33:07,625] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:33:07,626] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:07,671] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run12
[2019-03-23 03:33:08,161] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:33:08,161] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:08,213] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:33:08,214] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:08,226] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run12
[2019-03-23 03:33:08,289] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run12
[2019-03-23 03:33:08,968] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:33:08,969] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:08,975] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run12
[2019-03-23 03:33:09,102] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 03:33:09,103] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:09,133] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run12
[2019-03-23 03:33:10,041] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:33:10,046] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2147
[2019-03-23 03:33:10,049] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.9, 12.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6820061137392914, 6.9112, 6.9112, 121.9260426156618, 487000.2339408462, 487000.2339408462, 128512.990408171], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 154800.0000, 
sim time next is 155400.0000, 
raw observation next is [33.61666666666667, 12.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6860617504090909, 6.9112, 6.9112, 121.9260426156618, 489897.1683008014, 489897.1683008014, 128775.1949118474], 
processed observation next is [1.0, 0.8260869565217391, 0.8006172839506173, 0.125, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6075771880113636, 0.0, 0.0, 0.8094621288201359, 0.17496327439314335, 0.17496327439314335, 0.24764460559970655], 
reward next is 0.7524, 
noisyNet noise sample is [array([-1.1538761], dtype=float32), 0.8802967]. 
=============================================
[2019-03-23 03:33:10,377] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:33:10,382] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4476
[2019-03-23 03:33:10,388] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.63333333333333, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4864745957414491, 6.9112, 6.9112, 121.9260426156618, 347346.6718483305, 347346.6718483305, 111815.8798103255], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6000.0000, 
sim time next is 6600.0000, 
raw observation next is [18.61666666666667, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4835863749942547, 6.911200000000001, 6.9112, 121.9260426156618, 345282.8161442537, 345282.8161442532, 111386.4760581619], 
processed observation next is [1.0, 0.043478260869565216, 0.24506172839506188, 0.75, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.35448296874281837, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12331529148009061, 0.12331529148009042, 0.21420476165031135], 
reward next is 0.7858, 
noisyNet noise sample is [array([-0.48295724], dtype=float32), -0.1959025]. 
=============================================
[2019-03-23 03:33:15,643] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:33:15,650] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3046
[2019-03-23 03:33:15,656] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.05, 30.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5900025230061887, 6.9112, 6.9112, 121.9260426156618, 427462.4809789796, 427462.4809789796, 124383.3307763877], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 318600.0000, 
sim time next is 319200.0000, 
raw observation next is [28.06666666666667, 30.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5905840183986253, 6.911200000000001, 6.9112, 121.9260426156618, 427698.666470898, 427698.6664708975, 124363.6951589924], 
processed observation next is [0.0, 0.6956521739130435, 0.5950617283950619, 0.3033333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.48823002299828155, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15274952373960643, 0.15274952373960626, 0.23916095222883155], 
reward next is 0.7608, 
noisyNet noise sample is [array([-0.0184042], dtype=float32), -0.50701123]. 
=============================================
[2019-03-23 03:33:17,336] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:33:17,343] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0675
[2019-03-23 03:33:17,346] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.13333333333333, 24.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6258479521855763, 6.9112, 6.9112, 121.9260426156618, 454595.9906852821, 454595.9906852821, 127948.1073365761], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 243600.0000, 
sim time next is 244200.0000, 
raw observation next is [29.91666666666666, 25.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6226073525000188, 6.9112, 6.9112, 121.9260426156618, 452309.9849383434, 452309.9849383434, 127685.9347243085], 
processed observation next is [0.0, 0.8260869565217391, 0.66358024691358, 0.2533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5282591906250234, 0.0, 0.0, 0.8094621288201359, 0.16153928033512263, 0.16153928033512263, 0.24554987446982404], 
reward next is 0.7545, 
noisyNet noise sample is [array([0.14413238], dtype=float32), -0.23482761]. 
=============================================
[2019-03-23 03:33:18,785] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:33:18,798] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2131
[2019-03-23 03:33:18,803] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.56666666666667, 14.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6779479518507947, 6.911199999999999, 6.9112, 121.9260426156618, 488900.2328060353, 488900.2328060357, 131395.9383360685], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 229800.0000, 
sim time next is 230400.0000, 
raw observation next is [33.6, 15.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6773733600542856, 6.9112, 6.9112, 121.9260426156618, 489139.6940978997, 489139.6940978997, 131576.0374668101], 
processed observation next is [0.0, 0.6956521739130435, 0.8, 0.15, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5967167000678569, 0.0, 0.0, 0.8094621288201359, 0.17469274789210704, 0.17469274789210704, 0.25303084128232717], 
reward next is 0.7470, 
noisyNet noise sample is [array([-0.4926913], dtype=float32), -0.43604934]. 
=============================================
[2019-03-23 03:33:26,252] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:33:26,263] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9437
[2019-03-23 03:33:26,268] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.05, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6100786772629319, 6.911200000000001, 6.9112, 121.9260426156618, 446445.5500425329, 446445.5500425324, 127912.4803791334], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 541800.0000, 
sim time next is 542400.0000, 
raw observation next is [21.23333333333333, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5978311601861148, 6.911200000000001, 6.9112, 121.9260426156618, 437700.01137077, 437700.0113707695, 126912.7221703092], 
processed observation next is [1.0, 0.2608695652173913, 0.34197530864197523, 0.68, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.49728895023264347, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15632143263241785, 0.15632143263241768, 0.2440629272505946], 
reward next is 0.7559, 
noisyNet noise sample is [array([0.80865896], dtype=float32), -0.21019427]. 
=============================================
[2019-03-23 03:33:29,042] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9995577e-01 0.0000000e+00 2.3238875e-28 3.5040518e-21 4.4167999e-05], sum to 1.0000
[2019-03-23 03:33:29,050] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1244
[2019-03-23 03:33:29,058] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1293061.941241161 W.
[2019-03-23 03:33:29,064] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.2, 44.66666666666667, 1.0, 2.0, 0.5317254153034068, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8659203863626409, 6.9112, 6.9112, 121.9260426156541, 1293061.941241161, 1293061.941241161, 265647.2565466594], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 555600.0000, 
sim time next is 556200.0000, 
raw observation next is [27.9, 46.0, 1.0, 2.0, 0.5371168390897977, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8748791645230376, 6.911199999999999, 6.9112, 121.9260426156618, 1306530.614616934, 1306530.614616934, 267568.8608172169], 
processed observation next is [1.0, 0.43478260869565216, 0.5888888888888888, 0.46, 1.0, 1.0, 0.44894861796404484, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8435989556537971, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.466618076648905, 0.466618076648905, 0.514555501571571], 
reward next is 0.4854, 
noisyNet noise sample is [array([-2.7712765], dtype=float32), 0.4478486]. 
=============================================
[2019-03-23 03:33:30,817] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.0082849e-37 2.8820663e-12], sum to 1.0000
[2019-03-23 03:33:30,827] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4943
[2019-03-23 03:33:30,833] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1142741.787197148 W.
[2019-03-23 03:33:30,837] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.35, 25.0, 1.0, 2.0, 0.4546970535585696, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7692064428523657, 6.911199999999999, 6.9112, 121.9260426156618, 1142741.787197148, 1142741.787197149, 236238.6390136773], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 394200.0000, 
sim time next is 394800.0000, 
raw observation next is [30.46666666666667, 24.66666666666667, 1.0, 2.0, 0.4814741137207311, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8156362225308839, 6.911200000000001, 6.9112, 121.9260426156618, 1211093.527630332, 1211093.527630331, 244994.0043735478], 
processed observation next is [1.0, 0.5652173913043478, 0.6839506172839507, 0.2466666666666667, 1.0, 1.0, 0.3827072782389656, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7695452781636047, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.43253340272511853, 0.4325334027251182, 0.4711423161029765], 
reward next is 0.5289, 
noisyNet noise sample is [array([1.0933298], dtype=float32), -0.9308882]. 
=============================================
[2019-03-23 03:33:32,149] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:33:32,155] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8706
[2019-03-23 03:33:32,159] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.3, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6532611805749444, 6.9112, 6.9112, 121.9260426156618, 475514.505404903, 475514.505404903, 130817.4438425588], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 460800.0000, 
sim time next is 461400.0000, 
raw observation next is [23.61666666666667, 52.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6358011139889523, 6.911199999999999, 6.9112, 121.9260426156618, 463675.9452744444, 463675.9452744449, 129577.718139685], 
processed observation next is [1.0, 0.34782608695652173, 0.4302469135802471, 0.5216666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5447513924861904, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16559855188373016, 0.16559855188373032, 0.24918791949939426], 
reward next is 0.7508, 
noisyNet noise sample is [array([0.35349452], dtype=float32), -0.3613552]. 
=============================================
[2019-03-23 03:33:33,115] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:33:33,122] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0264
[2019-03-23 03:33:33,127] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.93333333333333, 56.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.501489069501265, 6.911200000000001, 6.9112, 121.9260426156618, 360887.1799558208, 360887.1799558203, 116200.4767859805], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 436200.0000, 
sim time next is 436800.0000, 
raw observation next is [21.66666666666667, 58.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5022071423336402, 6.911200000000001, 6.9112, 121.9260426156618, 361484.5634428379, 361484.5634428374, 116284.7779208222], 
processed observation next is [1.0, 0.043478260869565216, 0.3580246913580249, 0.5833333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3777589279170502, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12910162980101353, 0.12910162980101336, 0.2236245729246581], 
reward next is 0.7764, 
noisyNet noise sample is [array([0.4127849], dtype=float32), 0.13145761]. 
=============================================
[2019-03-23 03:33:36,834] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 6.6253195e-32 2.0828231e-27 1.4131599e-24 7.4647320e-14], sum to 1.0000
[2019-03-23 03:33:36,842] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6354
[2019-03-23 03:33:36,852] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1494385.938080268 W.
[2019-03-23 03:33:36,856] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.1, 30.66666666666667, 1.0, 2.0, 0.6217306816037577, 1.0, 2.0, 0.6217306816037577, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1494385.938080268, 1494385.938080268, 278948.6469723175], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 578400.0000, 
sim time next is 579000.0000, 
raw observation next is [32.2, 30.33333333333333, 1.0, 2.0, 0.6407668586616869, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9579200448512917, 6.9112, 6.9112, 121.9260426156618, 1490957.495648614, 1490957.495648614, 296150.1720573299], 
processed observation next is [1.0, 0.6956521739130435, 0.7481481481481482, 0.3033333333333333, 1.0, 1.0, 0.5723414984067702, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9474000560641146, 0.0, 0.0, 0.8094621288201359, 0.5324848198745049, 0.5324848198745049, 0.5695195616487113], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.587079], dtype=float32), 0.5815608]. 
=============================================
[2019-03-23 03:33:36,868] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[50.062244]
 [50.482513]
 [50.343372]
 [50.742058]
 [50.803543]], R is [[49.31124878]
 [49.28170013]
 [49.19517899]
 [48.703228  ]
 [48.64702606]].
[2019-03-23 03:33:38,421] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:33:38,429] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8490
[2019-03-23 03:33:38,436] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.8, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.58954321552635, 6.911199999999999, 6.9112, 121.9260426156618, 436376.7417234749, 436376.7417234753, 128607.8990358373], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 507600.0000, 
sim time next is 508200.0000, 
raw observation next is [26.53333333333333, 43.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.587708001311178, 6.9112, 6.9112, 121.9260426156618, 434750.182432936, 434750.182432936, 128277.391083961], 
processed observation next is [1.0, 0.9130434782608695, 0.5382716049382715, 0.4383333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4846350016389724, 0.0, 0.0, 0.8094621288201359, 0.15526792229747713, 0.15526792229747713, 0.24668729054607885], 
reward next is 0.7533, 
noisyNet noise sample is [array([0.5398982], dtype=float32), -0.0502331]. 
=============================================
[2019-03-23 03:33:38,877] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:33:38,887] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1636
[2019-03-23 03:33:38,892] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.36666666666667, 77.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5366232406861386, 6.9112, 6.9112, 121.9260426156618, 389873.3271422607, 389873.3271422607, 120342.7004674529], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 535800.0000, 
sim time next is 536400.0000, 
raw observation next is [19.3, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5338524601938635, 6.9112, 6.9112, 121.9260426156618, 387705.05735794, 387705.05735794, 120054.0815768482], 
processed observation next is [1.0, 0.21739130434782608, 0.27037037037037037, 0.78, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.41731557524232926, 0.0, 0.0, 0.8094621288201359, 0.13846609191355, 0.13846609191355, 0.23087323380163116], 
reward next is 0.7691, 
noisyNet noise sample is [array([-0.57169515], dtype=float32), -0.9703786]. 
=============================================
[2019-03-23 03:33:39,192] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 03:33:39,194] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:33:39,197] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:39,198] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:33:39,199] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:33:39,200] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:39,201] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:39,201] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:33:39,202] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:33:39,202] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:39,203] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:33:39,230] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run95
[2019-03-23 03:33:39,262] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run95
[2019-03-23 03:33:39,293] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run95
[2019-03-23 03:33:39,329] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run95
[2019-03-23 03:33:39,330] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run95
[2019-03-23 03:33:42,304] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.35841393], dtype=float32), -0.15009849]
[2019-03-23 03:33:42,306] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [37.75276918, 18.95713632, 1.0, 2.0, 0.4104346928100876, 1.0, 2.0, 0.4104346928100876, 1.0, 2.0, 0.6573145607752778, 6.911200000000001, 6.9112, 121.94756008, 1451128.833810887, 1451128.833810887, 301650.4951685146]
[2019-03-23 03:33:42,307] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:33:42,310] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.9862548e-09 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00], sampled 0.949529124734981
[2019-03-23 03:33:53,166] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.35841393], dtype=float32), -0.15009849]
[2019-03-23 03:33:53,168] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.43333333333333, 46.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7141551367145207, 6.911199999999999, 6.9112, 121.9260426156618, 533660.5469159131, 533660.5469159136, 146720.7940856188]
[2019-03-23 03:33:53,169] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:33:53,170] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 1.02149754e-32], sampled 0.6878156164606054
[2019-03-23 03:33:57,334] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.35841393], dtype=float32), -0.15009849]
[2019-03-23 03:33:57,336] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.0, 23.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6115644388165552, 6.911200000000001, 6.9112, 121.9260426156618, 446032.9908840214, 446032.9908840209, 127408.0218683325]
[2019-03-23 03:33:57,337] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:33:57,340] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.9368567e-33], sampled 0.1570273750076907
[2019-03-23 03:33:59,602] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.35841393], dtype=float32), -0.15009849]
[2019-03-23 03:33:59,603] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.75, 46.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6062472885624866, 6.911200000000001, 6.9112, 121.9260426156618, 450914.5900464834, 450914.590046483, 131677.7710123553]
[2019-03-23 03:33:59,604] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:33:59,607] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7743268843303167
[2019-03-23 03:34:06,747] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.35841393], dtype=float32), -0.15009849]
[2019-03-23 03:34:06,748] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.73333333333333, 85.33333333333333, 1.0, 2.0, 0.2496554297535146, 1.0, 2.0, 0.2496554297535146, 1.0, 2.0, 0.402757088211036, 6.9112, 6.9112, 121.94756008, 897347.803479348, 897347.803479348, 236947.3261346071]
[2019-03-23 03:34:06,750] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:34:06,752] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.00555322 0.         0.         0.         0.99444675], sampled 0.039585941187273765
[2019-03-23 03:35:18,894] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.35841393], dtype=float32), -0.15009849]
[2019-03-23 03:35:18,895] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.58333333333333, 61.33333333333334, 1.0, 2.0, 0.3490398911611424, 1.0, 2.0, 0.3490398911611424, 1.0, 2.0, 0.555944112072326, 6.9112, 6.9112, 121.94756008, 1202002.477837265, 1202002.477837265, 275520.2288990612]
[2019-03-23 03:35:18,897] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:35:18,898] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.9975193  0.         0.         0.         0.00248062], sampled 0.15453079278432114
[2019-03-23 03:35:18,899] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1202002.477837265 W.
[2019-03-23 03:35:29,360] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8090.2700 2472336488.5516 293.0000
[2019-03-23 03:35:29,388] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8210.3557 2500098759.7064 268.0000
[2019-03-23 03:35:29,505] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8179.4801 2421921095.8282 263.0000
[2019-03-23 03:35:29,637] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8335.6615 2450884647.7974 246.0000
[2019-03-23 03:35:29,671] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7792.2654 2690672852.3300 346.0000
[2019-03-23 03:35:30,687] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2350000, evaluation results [2350000.0, 7792.265416541058, 2690672852.3299737, 346.0, 8335.661472766495, 2450884647.797417, 246.0, 8179.480090065627, 2421921095.8282366, 263.0, 8210.355719057045, 2500098759.706361, 268.0, 8090.270009415278, 2472336488.5515885, 293.0]
[2019-03-23 03:35:31,063] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:35:31,069] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7339
[2019-03-23 03:35:31,075] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.75, 33.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5900714475522318, 6.9112, 6.9112, 121.9260426156618, 434285.8874366322, 434285.8874366322, 127291.735064351], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 685800.0000, 
sim time next is 686400.0000, 
raw observation next is [28.56666666666666, 33.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5864769049301373, 6.911199999999999, 6.9112, 121.9260426156618, 431662.0317630786, 431662.031763079, 126979.3178614227], 
processed observation next is [1.0, 0.9565217391304348, 0.6135802469135799, 0.33666666666666656, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4830961311626715, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15416501134395663, 0.15416501134395677, 0.24419099588735135], 
reward next is 0.7558, 
noisyNet noise sample is [array([-0.31530127], dtype=float32), 1.1625857]. 
=============================================
[2019-03-23 03:35:32,438] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.4559205e-01 0.0000000e+00 4.7406401e-33 1.8292568e-17 5.4407954e-02], sum to 1.0000
[2019-03-23 03:35:32,451] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3931
[2019-03-23 03:35:32,459] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1556845.59909775 W.
[2019-03-23 03:35:32,465] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.05, 22.0, 1.0, 2.0, 0.4355459240562633, 1.0, 2.0, 0.4355459240562633, 1.0, 2.0, 0.7005462913897355, 6.911199999999999, 6.9112, 121.94756008, 1556845.59909775, 1556845.59909775, 312801.6048023498], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 653400.0000, 
sim time next is 654000.0000, 
raw observation next is [35.26666666666667, 21.33333333333333, 1.0, 2.0, 0.4376290301362368, 1.0, 2.0, 0.4376290301362368, 1.0, 2.0, 0.7038076833459179, 6.9112, 6.9112, 121.94756008, 1563868.268408283, 1563868.268408283, 313765.5563813453], 
processed observation next is [1.0, 0.5652173913043478, 0.8617283950617286, 0.2133333333333333, 1.0, 1.0, 0.3305107501621866, 1.0, 1.0, 0.3305107501621866, 1.0, 1.0, 0.6297596041823974, 0.0, 0.0, 0.8096049824067558, 0.5585243815743868, 0.5585243815743868, 0.6033953007333563], 
reward next is 0.3966, 
noisyNet noise sample is [array([-0.3114975], dtype=float32), -2.4423814]. 
=============================================
[2019-03-23 03:35:32,476] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[53.207905]
 [52.886044]
 [53.383232]
 [54.172237]
 [55.232967]], R is [[53.56952667]
 [53.43228912]
 [52.89796829]
 [52.36898804]
 [52.41507721]].
[2019-03-23 03:35:36,233] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:35:36,241] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5550
[2019-03-23 03:35:36,248] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.58333333333333, 64.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6417552484851872, 6.911199999999999, 6.9112, 121.9260426156618, 468535.1334868274, 468535.1334868279, 130335.8706769731], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 618600.0000, 
sim time next is 619200.0000, 
raw observation next is [21.4, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6209980107053924, 6.911199999999999, 6.9112, 121.9260426156618, 453017.5670554137, 453017.5670554141, 128295.446744554], 
processed observation next is [1.0, 0.17391304347826086, 0.3481481481481481, 0.65, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5262475133817405, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1617919882340763, 0.16179198823407645, 0.24672201297029617], 
reward next is 0.7533, 
noisyNet noise sample is [array([-0.70699084], dtype=float32), -2.0612493]. 
=============================================
[2019-03-23 03:35:36,287] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:35:36,298] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3633
[2019-03-23 03:35:36,301] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.21666666666667, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5677539986704065, 6.911200000000001, 6.9112, 121.9260426156618, 413914.1876815262, 413914.1876815257, 123511.745707523], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 619800.0000, 
sim time next is 620400.0000, 
raw observation next is [21.03333333333333, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5473977836436864, 6.911199999999999, 6.9112, 121.9260426156618, 398861.2292857512, 398861.2292857517, 121699.9577828536], 
processed observation next is [1.0, 0.17391304347826086, 0.3345679012345678, 0.67, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.434247229554608, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14245043903062543, 0.1424504390306256, 0.23403838035164154], 
reward next is 0.7660, 
noisyNet noise sample is [array([-0.70699084], dtype=float32), -2.0612493]. 
=============================================
[2019-03-23 03:35:44,850] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:35:44,858] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0874
[2019-03-23 03:35:44,861] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.66666666666667, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5628023126390469, 6.911199999999999, 6.9112, 121.9260426156618, 412682.6512575391, 412682.6512575395, 124126.8572534501], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 888000.0000, 
sim time next is 888600.0000, 
raw observation next is [21.73333333333333, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5665432742332903, 6.9112, 6.9112, 121.9260426156618, 415783.3863912292, 415783.3863912292, 124618.1808920117], 
processed observation next is [0.0, 0.2608695652173913, 0.3604938271604937, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45817909279161284, 0.0, 0.0, 0.8094621288201359, 0.14849406656829614, 0.14849406656829614, 0.23965034786925327], 
reward next is 0.7603, 
noisyNet noise sample is [array([0.9982409], dtype=float32), -0.3527276]. 
=============================================
[2019-03-23 03:35:50,533] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5282238e-17 0.0000000e+00 2.0754137e-36 1.9153835e-37 1.0000000e+00], sum to 1.0000
[2019-03-23 03:35:50,544] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1227
[2019-03-23 03:35:50,551] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.2, 48.0, 1.0, 2.0, 0.2543074368298882, 1.0, 1.0, 0.2543074368298882, 1.0, 1.0, 0.4172126352554964, 6.911200000000001, 6.9112, 121.94756008, 935510.7839246388, 935510.7839246384, 237656.0422421749], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1005600.0000, 
sim time next is 1006200.0000, 
raw observation next is [26.3, 47.5, 1.0, 2.0, 0.2349721707845444, 1.0, 2.0, 0.2349721707845444, 1.0, 2.0, 0.3853672018624914, 6.911199999999999, 6.9112, 121.94756008, 864044.6391842862, 864044.6391842867, 230871.7303006303], 
processed observation next is [1.0, 0.6521739130434783, 0.5296296296296297, 0.475, 1.0, 1.0, 0.08925258426731478, 1.0, 1.0, 0.08925258426731478, 1.0, 1.0, 0.23170900232811423, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3085873711372451, 0.30858737113724527, 0.44398409673198136], 
reward next is 0.5560, 
noisyNet noise sample is [array([-0.8738413], dtype=float32), -1.6464537]. 
=============================================
[2019-03-23 03:35:52,535] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:35:52,543] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2472
[2019-03-23 03:35:52,549] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.76666666666667, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5773352210900693, 6.911200000000001, 6.9112, 121.9260426156618, 424774.758244315, 424774.7582443145, 126082.1889931233], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1315200.0000, 
sim time next is 1315800.0000, 
raw observation next is [19.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5873306530041851, 6.9112, 6.9112, 121.9260426156618, 432761.9445291423, 432761.9445291423, 127296.703626406], 
processed observation next is [1.0, 0.21739130434782608, 0.25925925925925924, 0.89, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4841633162552313, 0.0, 0.0, 0.8094621288201359, 0.15455783733183653, 0.15455783733183653, 0.24480135312770385], 
reward next is 0.7552, 
noisyNet noise sample is [array([0.6538324], dtype=float32), -0.66107523]. 
=============================================
[2019-03-23 03:35:56,399] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:35:56,409] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8699
[2019-03-23 03:35:56,416] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.53333333333333, 62.33333333333333, 1.0, 2.0, 0.2735755959934631, 1.0, 1.0, 0.2735755959934631, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 670464.4465214629, 670464.4465214633, 176178.6299769806], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1255200.0000, 
sim time next is 1255800.0000, 
raw observation next is [24.71666666666667, 61.66666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.877788325742629, 6.911200000000001, 6.9112, 121.9260426156618, 655927.2220231631, 655927.2220231626, 164710.9744396797], 
processed observation next is [1.0, 0.5217391304347826, 0.4709876543209877, 0.6166666666666666, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.8472354071782862, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23425972215112967, 0.2342597221511295, 0.31675187392246096], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14584237], dtype=float32), -0.63231695]. 
=============================================
[2019-03-23 03:35:57,277] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:35:57,283] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8209
[2019-03-23 03:35:57,288] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.26666666666667, 71.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5476572892411139, 6.911199999999999, 6.9112, 121.9260426156618, 398497.7701074296, 398497.7701074301, 121496.4397482653], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1054200.0000, 
sim time next is 1054800.0000, 
raw observation next is [20.2, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5471349075604096, 6.9112, 6.9112, 121.9260426156618, 397986.9881579595, 397986.9881579595, 121400.2979346189], 
processed observation next is [1.0, 0.21739130434782608, 0.3037037037037037, 0.72, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.433918634450512, 0.0, 0.0, 0.8094621288201359, 0.1421382100564141, 0.1421382100564141, 0.23346211141272866], 
reward next is 0.7665, 
noisyNet noise sample is [array([0.25988656], dtype=float32), 0.5626705]. 
=============================================
[2019-03-23 03:36:00,641] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:36:00,648] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8435
[2019-03-23 03:36:00,654] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.5, 38.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5813473231276329, 6.9112, 6.9112, 121.9260426156618, 431580.8006293143, 431580.8006293143, 128693.7799733715], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1363200.0000, 
sim time next is 1363800.0000, 
raw observation next is [28.25, 39.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5866810334737361, 6.9112, 6.9112, 121.9260426156618, 435570.1032520838, 435570.1032520838, 129210.6264567281], 
processed observation next is [1.0, 0.782608695652174, 0.6018518518518519, 0.39, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4833512918421701, 0.0, 0.0, 0.8094621288201359, 0.1555607511614585, 0.1555607511614585, 0.24848197395524635], 
reward next is 0.7515, 
noisyNet noise sample is [array([0.63995665], dtype=float32), -0.18405053]. 
=============================================
[2019-03-23 03:36:02,330] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:36:02,341] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2040
[2019-03-23 03:36:02,346] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.33333333333334, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4950311532013145, 6.911200000000001, 6.9112, 121.9260426156618, 355351.2188606191, 355351.2188606187, 115389.2617273835], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1146000.0000, 
sim time next is 1146600.0000, 
raw observation next is [19.4, 72.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5090089601822156, 6.9112, 6.9112, 121.9260426156618, 365379.4659833665, 365379.4659833665, 116461.3202733516], 
processed observation next is [1.0, 0.2608695652173913, 0.274074074074074, 0.725, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3862612002277695, 0.0, 0.0, 0.8094621288201359, 0.13049266642263088, 0.13049266642263088, 0.22396407744875307], 
reward next is 0.7760, 
noisyNet noise sample is [array([-0.32690182], dtype=float32), -0.08109868]. 
=============================================
[2019-03-23 03:36:04,844] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 0. 0. 0. 1.], sum to 1.0000
[2019-03-23 03:36:04,852] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2816
[2019-03-23 03:36:04,857] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.83333333333334, 65.0, 1.0, 2.0, 0.2120770706267496, 1.0, 2.0, 0.2120770706267496, 1.0, 2.0, 0.3457597251995982, 6.9112, 6.9112, 121.94756008, 774456.2062471729, 774456.2062471729, 223419.7153957028], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1327800.0000, 
sim time next is 1328400.0000, 
raw observation next is [24.1, 63.0, 1.0, 2.0, 0.2357738668268734, 1.0, 2.0, 0.2357738668268734, 1.0, 2.0, 0.3844164534771061, 6.911199999999999, 6.9112, 121.94756008, 861103.8537993431, 861103.8537993436, 231481.1385985088], 
processed observation next is [1.0, 0.391304347826087, 0.4481481481481482, 0.63, 1.0, 1.0, 0.09020698431770643, 1.0, 1.0, 0.09020698431770643, 1.0, 1.0, 0.23052056684638264, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3075370906426225, 0.3075370906426227, 0.4451560357663631], 
reward next is 0.5548, 
noisyNet noise sample is [array([0.07003834], dtype=float32), -1.2818426]. 
=============================================
[2019-03-23 03:36:07,571] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:36:07,580] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7660
[2019-03-23 03:36:07,589] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.06666666666667, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5853187074672613, 6.9112, 6.9112, 121.9260426156618, 428873.8842380997, 428873.8842380997, 125954.3032008927], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1218000.0000, 
sim time next is 1218600.0000, 
raw observation next is [18.05, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5589798122497406, 6.9112, 6.9112, 121.9260426156618, 409462.8708974149, 409462.8708974149, 123605.5893590961], 
processed observation next is [1.0, 0.08695652173913043, 0.2240740740740741, 0.93, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4487247653121757, 0.0, 0.0, 0.8094621288201359, 0.1462367396062196, 0.1462367396062196, 0.2377030564598002], 
reward next is 0.7623, 
noisyNet noise sample is [array([0.02769342], dtype=float32), -0.9598712]. 
=============================================
[2019-03-23 03:36:09,565] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:36:09,573] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2920
[2019-03-23 03:36:09,577] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.5, 46.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5474881852203336, 6.9112, 6.9112, 121.9260426156618, 402611.0206456096, 402611.0206456096, 123362.813634825], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1408800.0000, 
sim time next is 1409400.0000, 
raw observation next is [25.85, 45.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5544876219540175, 6.911199999999999, 6.9112, 121.9260426156618, 408501.5092546438, 408501.5092546442, 124345.7712436462], 
processed observation next is [0.0, 0.30434782608695654, 0.5129629629629631, 0.455, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4431095274425218, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1458933961623728, 0.14589339616237293, 0.23912648316085808], 
reward next is 0.7609, 
noisyNet noise sample is [array([-1.0239223], dtype=float32), 0.1543921]. 
=============================================
[2019-03-23 03:36:11,087] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:36:11,095] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1116
[2019-03-23 03:36:11,106] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.9, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9082875109736519, 6.9112, 6.9112, 121.9260426156618, 661069.2286146615, 661069.2286146615, 177717.5979346576], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2138400.0000, 
sim time next is 2139000.0000, 
raw observation next is [30.71666666666667, 53.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9179977514391188, 6.9112, 6.9112, 121.9260426156618, 666852.7176442231, 666852.7176442231, 179230.1093356016], 
processed observation next is [0.0, 0.782608695652174, 0.69320987654321, 0.535, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8974971892988983, 0.0, 0.0, 0.8094621288201359, 0.23816168487293682, 0.23816168487293682, 0.3446732871838492], 
reward next is 0.6553, 
noisyNet noise sample is [array([0.9724224], dtype=float32), -1.3004158]. 
=============================================
[2019-03-23 03:36:11,128] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[69.91756 ]
 [69.906944]
 [69.892944]
 [69.85781 ]
 [69.8036  ]], R is [[69.80072784]
 [69.76095581]
 [69.72406769]
 [69.68994904]
 [69.65825653]].
[2019-03-23 03:36:11,646] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:36:11,656] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1949
[2019-03-23 03:36:11,662] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.53333333333334, 36.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8030067889156888, 6.911200000000001, 6.9112, 121.9260426156618, 594454.5911940134, 594454.5911940129, 161549.0452945043], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1527000.0000, 
sim time next is 1527600.0000, 
raw observation next is [33.36666666666667, 37.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8136429970947743, 6.911199999999999, 6.9112, 121.9260426156618, 601149.6201116801, 601149.6201116806, 163300.0244894749], 
processed observation next is [0.0, 0.6956521739130435, 0.7913580246913581, 0.3766666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7670537463684679, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21469629289702863, 0.2146962928970288, 0.31403850863360555], 
reward next is 0.6860, 
noisyNet noise sample is [array([0.69559], dtype=float32), 1.1887908]. 
=============================================
[2019-03-23 03:36:13,972] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:36:13,984] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5679
[2019-03-23 03:36:13,991] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 73.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.739401943273713, 6.911199999999999, 6.9112, 121.9260426156618, 552490.8291008882, 552490.8291008887, 149787.0555111804], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1545600.0000, 
sim time next is 1546200.0000, 
raw observation next is [23.6, 72.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7330205625486588, 6.9112, 6.9112, 121.9260426156618, 547774.7669585983, 547774.7669585983, 148744.6493784097], 
processed observation next is [0.0, 0.9130434782608695, 0.4296296296296297, 0.725, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6662757031858235, 0.0, 0.0, 0.8094621288201359, 0.19563384534235653, 0.19563384534235653, 0.2860474026507879], 
reward next is 0.7140, 
noisyNet noise sample is [array([-1.3500676], dtype=float32), -0.56509995]. 
=============================================
[2019-03-23 03:36:14,984] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:36:14,996] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2093
[2019-03-23 03:36:15,006] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 969972.6702268993 W.
[2019-03-23 03:36:15,011] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.03333333333333, 57.33333333333334, 1.0, 2.0, 0.26169555283209, 1.0, 1.0, 0.26169555283209, 1.0, 1.0, 0.4326517500713574, 6.9112, 6.9112, 121.94756008, 969972.6702268993, 969972.6702268993, 239870.9432079502], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1586400.0000, 
sim time next is 1587000.0000, 
raw observation next is [24.16666666666666, 57.16666666666666, 1.0, 2.0, 0.3959530460315611, 1.0, 2.0, 0.3959530460315611, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156238, 978800.1239832039, 978800.1239832039, 207961.7252217999], 
processed observation next is [1.0, 0.34782608695652173, 0.45061728395061706, 0.5716666666666665, 1.0, 1.0, 0.2808964833709061, 1.0, 1.0, 0.2808964833709061, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288198837, 0.34957147285114426, 0.34957147285114426, 0.3999263946573075], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.11779457], dtype=float32), -0.44928706]. 
=============================================
[2019-03-23 03:36:15,022] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[54.155113]
 [56.62302 ]
 [64.37224 ]
 [65.8238  ]
 [66.06151 ]], R is [[52.80176544]
 [52.27374649]
 [52.37171555]
 [51.84799957]
 [52.02842712]].
[2019-03-23 03:36:15,594] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:36:15,604] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0740
[2019-03-23 03:36:15,612] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.1, 26.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6372046956566509, 6.911200000000001, 6.9112, 121.9260426156618, 473309.7977726229, 473309.7977726224, 134194.1953554509], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1449600.0000, 
sim time next is 1450200.0000, 
raw observation next is [31.95, 26.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6352942104782301, 6.9112, 6.9112, 121.9260426156618, 471808.0741199728, 471808.0741199728, 133946.9618278385], 
processed observation next is [0.0, 0.782608695652174, 0.7388888888888888, 0.2666666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5441177630977876, 0.0, 0.0, 0.8094621288201359, 0.168502883614276, 0.168502883614276, 0.25759031120738174], 
reward next is 0.7424, 
noisyNet noise sample is [array([0.9375319], dtype=float32), 0.42717522]. 
=============================================
[2019-03-23 03:36:19,336] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:36:19,346] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1004
[2019-03-23 03:36:19,349] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.4, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6939510771021318, 6.9112, 6.9112, 121.9260426156618, 518580.7199765248, 518580.7199765248, 144054.9242564823], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2271000.0000, 
sim time next is 2271600.0000, 
raw observation next is [20.4, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6920993613781956, 6.911199999999999, 6.9112, 121.9260426156618, 517196.4885496756, 517196.488549676, 143853.4381114055], 
processed observation next is [1.0, 0.30434782608695654, 0.31111111111111106, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6151242017227445, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18471303162488414, 0.18471303162488428, 0.27664122713731826], 
reward next is 0.7234, 
noisyNet noise sample is [array([-0.57884306], dtype=float32), 1.4342192]. 
=============================================
[2019-03-23 03:36:21,694] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 03:36:21,700] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:36:21,702] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:36:21,703] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:36:21,705] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:36:21,705] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:36:21,705] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:36:21,706] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:36:21,708] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:36:21,708] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:36:21,710] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:36:21,731] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run96
[2019-03-23 03:36:21,759] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run96
[2019-03-23 03:36:21,786] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run96
[2019-03-23 03:36:21,787] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run96
[2019-03-23 03:36:21,787] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run96
[2019-03-23 03:36:25,770] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.32537377], dtype=float32), -0.1648718]
[2019-03-23 03:36:25,771] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.694143555, 43.85266936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5877026770570818, 6.9112, 6.9112, 121.9260426156618, 430110.383791997, 430110.383791997, 125937.0946832221]
[2019-03-23 03:36:25,774] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:36:25,777] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.028465756353804106
[2019-03-23 03:36:50,577] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.32537377], dtype=float32), -0.1648718]
[2019-03-23 03:36:50,578] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.0, 83.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7254100740534514, 6.9112, 6.9112, 121.9260426156618, 541010.5468175417, 541010.5468175417, 145129.775016913]
[2019-03-23 03:36:50,581] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:36:50,584] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.2582366472435831
[2019-03-23 03:37:13,306] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.32537377], dtype=float32), -0.1648718]
[2019-03-23 03:37:13,307] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.46156881333333, 83.20791851333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8741755146104616, 6.911199999999999, 6.9112, 121.9260426156618, 640592.7617238356, 640592.761723836, 172369.8167238756]
[2019-03-23 03:37:13,308] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:37:13,311] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.4295616e-22], sampled 0.30430394331957933
[2019-03-23 03:37:40,674] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.32537377], dtype=float32), -0.1648718]
[2019-03-23 03:37:40,675] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.45, 92.00000000000001, 1.0, 2.0, 0.6120699713377776, 1.0, 1.0, 0.6120699713377776, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1395717.339935744, 1395717.339935744, 272218.6450637248]
[2019-03-23 03:37:40,675] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:37:40,679] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.2000497e-19 0.0000000e+00 0.0000000e+00 1.0000000e+00 2.5910065e-28], sampled 0.1581329331991741
[2019-03-23 03:37:49,302] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.32537377], dtype=float32), -0.1648718]
[2019-03-23 03:37:49,302] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.0, 81.5, 1.0, 2.0, 0.2859590881135137, 1.0, 2.0, 0.2859590881135137, 1.0, 2.0, 0.4552561813140367, 6.9112, 6.9112, 121.94756008, 977852.0784391136, 977852.0784391136, 250737.1264391901]
[2019-03-23 03:37:49,303] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:37:49,305] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.596734e-15 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00], sampled 0.14561259297266782
[2019-03-23 03:37:54,830] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.32537377], dtype=float32), -0.1648718]
[2019-03-23 03:37:54,831] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.99352682, 91.72565471000001, 1.0, 2.0, 0.7084588863950212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 807447.793138936, 807447.7931389356, 177752.0840708907]
[2019-03-23 03:37:54,832] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:37:54,834] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.7842389e-01 0.0000000e+00 0.0000000e+00 7.7324835e-36 2.1576079e-02], sampled 0.891262313101122
[2019-03-23 03:37:54,838] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 807447.793138936 W.
[2019-03-23 03:37:57,708] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.32537377], dtype=float32), -0.1648718]
[2019-03-23 03:37:57,710] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.11502386333333, 49.67827594666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6435655453871268, 6.9112, 6.9112, 121.9260426156618, 468550.7890759509, 468550.7890759509, 129967.515875848]
[2019-03-23 03:37:57,711] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:37:57,713] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6547274143061781
[2019-03-23 03:38:11,201] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8456.6518 2363844644.8817 340.0000
[2019-03-23 03:38:11,886] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8355.7894 2378393438.4772 389.0000
[2019-03-23 03:38:11,952] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8318.6557 2417552866.6910 351.0000
[2019-03-23 03:38:11,953] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8506.1718 2322215556.5146 350.0000
[2019-03-23 03:38:11,988] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7864.1719 2609254209.0227 465.0000
[2019-03-23 03:38:13,006] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2375000, evaluation results [2375000.0, 7864.1719409292855, 2609254209.022661, 465.0, 8456.651811337646, 2363844644.8816776, 340.0, 8506.171830503357, 2322215556.514621, 350.0, 8318.65568653615, 2417552866.6909857, 351.0, 8355.789377731284, 2378393438.477173, 389.0]
[2019-03-23 03:38:14,477] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:38:14,485] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8232
[2019-03-23 03:38:14,490] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [34.1, 27.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6838808550268088, 6.9112, 6.9112, 121.9260426156618, 511041.1909135991, 511041.1909135991, 143303.6000659147], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1512000.0000, 
sim time next is 1512600.0000, 
raw observation next is [34.25, 26.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6823003392513746, 6.911200000000001, 6.9112, 121.9260426156618, 509869.0754663933, 509869.0754663928, 143017.8914601427], 
processed observation next is [0.0, 0.5217391304347826, 0.8240740740740741, 0.265, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6028754240642181, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18209609838085475, 0.18209609838085458, 0.2750344066541206], 
reward next is 0.7250, 
noisyNet noise sample is [array([0.8719876], dtype=float32), 0.7729641]. 
=============================================
[2019-03-23 03:38:22,265] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:38:22,272] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0388
[2019-03-23 03:38:22,277] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.53333333333333, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6130616530463185, 6.911199999999999, 6.9112, 121.9260426156618, 455942.6097195659, 455942.6097195664, 132299.2459977762], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2006400.0000, 
sim time next is 2007000.0000, 
raw observation next is [19.65, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6135546324297374, 6.9112, 6.9112, 121.9260426156618, 456371.6234671082, 456371.6234671082, 132398.165637473], 
processed observation next is [0.0, 0.21739130434782608, 0.28333333333333327, 0.915, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5169432905371717, 0.0, 0.0, 0.8094621288201359, 0.16298986552396721, 0.16298986552396721, 0.2546118569951404], 
reward next is 0.7454, 
noisyNet noise sample is [array([-0.02229728], dtype=float32), -0.67755693]. 
=============================================
[2019-03-23 03:38:22,286] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[78.52798 ]
 [78.56717 ]
 [78.62478 ]
 [78.588745]
 [78.57911 ]], R is [[78.4544754 ]
 [78.41550446]
 [78.3771286 ]
 [78.33931732]
 [78.30197144]].
[2019-03-23 03:38:22,360] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:38:22,368] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3048
[2019-03-23 03:38:22,376] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.66666666666667, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5758392407625482, 6.9112, 6.9112, 121.9260426156618, 424842.2911265926, 424842.2911265926, 126555.2534699749], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1631400.0000, 
sim time next is 1632000.0000, 
raw observation next is [24.53333333333333, 52.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5842776278888772, 6.9112, 6.9112, 121.9260426156618, 430909.8144955377, 430909.8144955377, 127230.5885649499], 
processed observation next is [1.0, 0.9130434782608695, 0.46419753086419746, 0.52, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4803470348610964, 0.0, 0.0, 0.8094621288201359, 0.1538963623198349, 0.1538963623198349, 0.2446742087787498], 
reward next is 0.7553, 
noisyNet noise sample is [array([-0.555083], dtype=float32), -0.018581184]. 
=============================================
[2019-03-23 03:38:22,391] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[84.15906]
 [84.19339]
 [84.00296]
 [83.86567]
 [83.76688]], R is [[84.12756348]
 [84.04290771]
 [83.95912933]
 [83.87545013]
 [83.7917099 ]].
[2019-03-23 03:38:34,812] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:38:34,818] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4711
[2019-03-23 03:38:34,823] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.9, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6183580862529127, 6.9112, 6.9112, 121.9260426156618, 460791.4616364426, 460791.4616364426, 133642.2573933527], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1921200.0000, 
sim time next is 1921800.0000, 
raw observation next is [19.95, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6208843650743676, 6.9112, 6.9112, 121.9260426156618, 462797.0089833165, 462797.0089833165, 134020.6430667271], 
processed observation next is [1.0, 0.21739130434782608, 0.2944444444444444, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5261054563429595, 0.0, 0.0, 0.8094621288201359, 0.16528464606547016, 0.16528464606547016, 0.2577320058975521], 
reward next is 0.7423, 
noisyNet noise sample is [array([-0.18687344], dtype=float32), -0.08853986]. 
=============================================
[2019-03-23 03:38:36,742] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.2921904e-25 0.0000000e+00 2.1894708e-32 1.0778723e-23], sum to 1.0000
[2019-03-23 03:38:36,773] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9929
[2019-03-23 03:38:36,774] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1419990.151882033 W.
[2019-03-23 03:38:36,817] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.4, 90.0, 1.0, 2.0, 0.4151364504985517, 1.0, 2.0, 0.4151364504985517, 1.0, 1.0, 0.6609107492440033, 6.911200000000001, 6.9112, 121.94756008, 1419990.151882033, 1419990.151882033, 303776.207656956], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2192400.0000, 
sim time next is 2193000.0000, 
raw observation next is [24.4, 90.16666666666667, 1.0, 2.0, 0.6160499832952924, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9807716367533662, 6.9112, 6.9112, 121.9260426156618, 1404801.376931543, 1404801.376931543, 300154.4426246156], 
processed observation next is [1.0, 0.391304347826087, 0.4592592592592592, 0.9016666666666667, 1.0, 1.0, 0.54291664678011, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9759645459417077, 0.0, 0.0, 0.8094621288201359, 0.501714777475551, 0.501714777475551, 0.5772200819704146], 
reward next is 0.4228, 
noisyNet noise sample is [array([-0.56690353], dtype=float32), 0.114002995]. 
=============================================
[2019-03-23 03:38:36,856] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[54.352547]
 [54.734184]
 [54.446953]
 [54.71628 ]
 [54.186234]], R is [[53.15107346]
 [53.0353775 ]
 [52.98766708]
 [52.94424438]
 [52.41480255]].
[2019-03-23 03:38:53,996] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:38:54,006] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1116
[2019-03-23 03:38:54,011] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.95, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7649706026578578, 6.9112, 6.9112, 121.9260426156618, 569893.5320236493, 569893.5320236493, 155009.2177966414], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2334600.0000, 
sim time next is 2335200.0000, 
raw observation next is [21.96666666666667, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7670867109898121, 6.9112, 6.9112, 121.9260426156618, 571345.3749862874, 571345.3749862874, 155353.9780332947], 
processed observation next is [1.0, 0.0, 0.36913580246913585, 0.9266666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7088583887372651, 0.0, 0.0, 0.8094621288201359, 0.2040519196379598, 0.2040519196379598, 0.29875765006402827], 
reward next is 0.7012, 
noisyNet noise sample is [array([0.2710675], dtype=float32), 0.6690076]. 
=============================================
[2019-03-23 03:38:55,150] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:38:55,160] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8731
[2019-03-23 03:38:55,166] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.43333333333334, 39.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6211369717573625, 6.911200000000001, 6.9112, 121.9260426156618, 462118.4389293519, 462118.4389293514, 133221.5314876337], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2497200.0000, 
sim time next is 2497800.0000, 
raw observation next is [28.26666666666667, 40.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6214026128861021, 6.911199999999999, 6.9112, 121.9260426156618, 462322.4798551124, 462322.4798551129, 133252.7967382637], 
processed observation next is [1.0, 0.9130434782608695, 0.6024691358024692, 0.40333333333333343, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5267532661076276, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16511517137682585, 0.16511517137682605, 0.2562553783428148], 
reward next is 0.7437, 
noisyNet noise sample is [array([-0.51693153], dtype=float32), 0.61401176]. 
=============================================
[2019-03-23 03:39:03,685] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 03:39:03,687] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:39:03,688] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:39:03,689] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:39:03,690] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:39:03,690] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:39:03,691] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:39:03,692] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:39:03,691] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:39:03,695] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:39:03,693] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:39:03,723] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run97
[2019-03-23 03:39:03,754] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run97
[2019-03-23 03:39:03,755] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run97
[2019-03-23 03:39:03,816] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run97
[2019-03-23 03:39:03,846] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run97
[2019-03-23 03:39:27,608] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.294131], dtype=float32), -0.14730908]
[2019-03-23 03:39:27,609] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.70198956666667, 44.63289711666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5598995209053474, 6.9112, 6.9112, 121.9260426156618, 414272.2717850595, 414272.2717850595, 125815.6803419764]
[2019-03-23 03:39:27,610] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:39:27,611] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5134008618810624
[2019-03-23 03:39:36,985] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.294131], dtype=float32), -0.14730908]
[2019-03-23 03:39:36,987] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.66666666666667, 68.83333333333333, 1.0, 2.0, 0.5291376534258313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 633980.7093892366, 633980.7093892366, 147652.4365937635]
[2019-03-23 03:39:36,989] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:39:36,992] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 3.861113e-16], sampled 0.46988040098496076
[2019-03-23 03:39:57,748] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.294131], dtype=float32), -0.14730908]
[2019-03-23 03:39:57,750] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.93888292833334, 58.396532585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8850600625904566, 6.911199999999999, 6.9112, 121.9260426156618, 650814.339552492, 650814.3395524925, 173271.666130055]
[2019-03-23 03:39:57,751] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 03:39:57,755] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4943513e-36], sampled 0.1483281214408847
[2019-03-23 03:40:52,911] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8443.2576 2297939355.8863 592.0000
[2019-03-23 03:40:53,279] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8586.7999 2267612963.1535 449.0000
[2019-03-23 03:40:53,423] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7911.6062 2528010555.5564 675.0000
[2019-03-23 03:40:53,470] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8401.2348 2337249838.4909 515.0000
[2019-03-23 03:40:53,493] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8651.3779 2228057287.0447 473.0000
[2019-03-23 03:40:54,512] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2400000, evaluation results [2400000.0, 7911.606221694684, 2528010555.5564466, 675.0, 8586.79989731674, 2267612963.1534877, 449.0, 8651.377858269057, 2228057287.0447426, 473.0, 8401.23483445484, 2337249838.4909263, 515.0, 8443.25762761589, 2297939355.886262, 592.0]
[2019-03-23 03:40:55,604] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:40:55,612] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3010
[2019-03-23 03:40:55,625] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.0, 78.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8681322621651957, 6.9112, 6.9112, 121.9260426156618, 639520.6459540965, 639520.6459540965, 170766.7641544401], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2638200.0000, 
sim time next is 2638800.0000, 
raw observation next is [25.0, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8612131357023639, 6.9112, 6.9112, 121.9260426156618, 635339.1946563706, 635339.1946563706, 169613.8946188188], 
processed observation next is [0.0, 0.5652173913043478, 0.48148148148148145, 0.78, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8265164196279547, 0.0, 0.0, 0.8094621288201359, 0.22690685523441806, 0.22690685523441806, 0.32618056657465155], 
reward next is 0.6738, 
noisyNet noise sample is [array([0.49790177], dtype=float32), -0.7601577]. 
=============================================
[2019-03-23 03:40:57,868] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2591117e-13 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 03:40:57,877] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7765
[2019-03-23 03:40:57,882] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.56666666666667, 31.33333333333334, 1.0, 2.0, 0.7227536202136993, 1.0, 2.0, 0.7227536202136993, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1701935.515907684, 1701935.515907685, 315454.1533627927], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2560200.0000, 
sim time next is 2560800.0000, 
raw observation next is [33.53333333333333, 31.66666666666667, 1.0, 2.0, 0.7398281675440227, 1.0, 2.0, 0.7398281675440227, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1740579.505939298, 1740579.505939298, 322109.9872071403], 
processed observation next is [1.0, 0.6521739130434783, 0.7975308641975308, 0.3166666666666667, 1.0, 1.0, 0.6902716280285984, 1.0, 1.0, 0.6902716280285984, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6216355378354635, 0.6216355378354635, 0.6194422830906544], 
reward next is 0.3806, 
noisyNet noise sample is [array([-0.7269662], dtype=float32), 1.0327715]. 
=============================================
[2019-03-23 03:41:00,346] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 1.028564e-23 3.683163e-30], sum to 1.0000
[2019-03-23 03:41:00,357] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7074
[2019-03-23 03:41:00,363] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 721735.9611800059 W.
[2019-03-23 03:41:00,370] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.91666666666666, 56.5, 1.0, 2.0, 0.633290268674575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 721735.9611800059, 721735.9611800055, 163898.5287402246], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2729400.0000, 
sim time next is 2730000.0000, 
raw observation next is [31.13333333333333, 55.0, 1.0, 2.0, 0.209624776902629, 1.0, 1.0, 0.209624776902629, 1.0, 1.0, 0.3337294718313513, 6.911199999999999, 6.9112, 121.94756008, 716700.8789272587, 716700.8789272591, 223764.3356417047], 
processed observation next is [0.0, 0.6086956521739131, 0.7086419753086418, 0.55, 1.0, 1.0, 0.05907711536027263, 1.0, 0.5, 0.05907711536027263, 1.0, 0.5, 0.16716183978918914, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2559645996168781, 0.2559645996168783, 0.43031603008020136], 
reward next is 0.5697, 
noisyNet noise sample is [array([-0.12952796], dtype=float32), 0.31756356]. 
=============================================
[2019-03-23 03:41:00,383] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[55.2033  ]
 [55.286896]
 [56.521713]
 [58.479813]
 [65.87073 ]], R is [[54.8852005 ]
 [55.02116013]
 [55.15502548]
 [54.60347748]
 [54.62966919]].
[2019-03-23 03:41:02,636] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:41:02,642] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3127
[2019-03-23 03:41:02,646] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 69.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9077825501231741, 6.911199999999999, 6.9112, 121.9260426156618, 664653.7289836227, 664653.7289836232, 176922.2641457149], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2653800.0000, 
sim time next is 2654400.0000, 
raw observation next is [27.0, 70.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.915038837699426, 6.9112, 6.9112, 121.9260426156618, 668702.9797772092, 668702.9797772092, 178145.9733282392], 
processed observation next is [0.0, 0.7391304347826086, 0.5555555555555556, 0.7066666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8937985471242823, 0.0, 0.0, 0.8094621288201359, 0.23882249277757472, 0.23882249277757472, 0.34258841024661385], 
reward next is 0.6574, 
noisyNet noise sample is [array([1.9327376], dtype=float32), -1.403331]. 
=============================================
[2019-03-23 03:41:04,273] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:41:04,284] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6916
[2019-03-23 03:41:04,290] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.85, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8006021379945293, 6.9112, 6.9112, 121.9260426156618, 594851.7500852933, 594851.7500852933, 160308.626429586], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2586600.0000, 
sim time next is 2587200.0000, 
raw observation next is [25.6, 69.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7982093564135557, 6.911200000000001, 6.9112, 121.9260426156618, 593186.2515630496, 593186.2515630492, 159952.9434153], 
processed observation next is [1.0, 0.9565217391304348, 0.5037037037037038, 0.6933333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7477616955169447, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21185223270108916, 0.211852232701089, 0.3076018142601923], 
reward next is 0.6924, 
noisyNet noise sample is [array([-1.0229502], dtype=float32), 0.7072469]. 
=============================================
[2019-03-23 03:41:04,476] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:41:04,488] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8852
[2019-03-23 03:41:04,491] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.06666666666667, 97.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7600445544830192, 6.911199999999999, 6.9112, 121.9260426156618, 566827.7682872423, 566827.7682872427, 153914.5834322585], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2618400.0000, 
sim time next is 2619000.0000, 
raw observation next is [21.1, 96.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7555360021473448, 6.911200000000001, 6.9112, 121.9260426156618, 563720.9689343624, 563720.9689343619, 153120.2317825545], 
processed observation next is [0.0, 0.30434782608695654, 0.3370370370370371, 0.965, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6944200026841809, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.201328917476558, 0.20132891747655784, 0.2944619841972202], 
reward next is 0.7055, 
noisyNet noise sample is [array([-0.865088], dtype=float32), -0.35201913]. 
=============================================
[2019-03-23 03:41:04,504] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[67.31892 ]
 [67.315346]
 [67.34677 ]
 [67.3373  ]
 [67.36707 ]], R is [[67.37677002]
 [67.40701294]
 [67.43550873]
 [67.46330261]
 [67.49300385]].
[2019-03-23 03:41:11,612] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:41:11,620] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2254
[2019-03-23 03:41:11,625] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.66666666666666, 90.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8681331420348836, 6.911199999999999, 6.9112, 121.9260426156618, 644537.1895767213, 644537.1895767218, 168968.1167044899], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2879400.0000, 
sim time next is 2880000.0000, 
raw observation next is [22.8, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8857344615876671, 6.911200000000001, 6.9112, 121.9260426156618, 657356.1636778126, 657356.1636778121, 171328.3369936869], 
processed observation next is [1.0, 0.34782608695652173, 0.4, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8571680769845837, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23477005845636162, 0.23477005845636145, 0.3294775711417056], 
reward next is 0.6705, 
noisyNet noise sample is [array([-1.0098219], dtype=float32), -0.45767802]. 
=============================================
[2019-03-23 03:41:11,633] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[49.349274]
 [48.408993]
 [47.42775 ]
 [41.321472]
 [49.18689 ]], R is [[50.46292877]
 [50.63336182]
 [50.79961777]
 [50.29162216]
 [50.37036514]].
[2019-03-23 03:41:12,025] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:41:12,031] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0125
[2019-03-23 03:41:12,038] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 768674.5028633042 W.
[2019-03-23 03:41:12,046] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.33333333333334, 68.0, 1.0, 2.0, 0.3372280250143354, 1.0, 2.0, 0.3372280250143354, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768674.5028633042, 768674.5028633042, 189634.8721824531], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2838000.0000, 
sim time next is 2838600.0000, 
raw observation next is [29.25, 68.5, 1.0, 2.0, 0.3395645777530564, 0.0, 1.0, 0.0, 1.0, 1.0, 0.540597866629105, 6.911200000000001, 6.9112, 121.9260426156618, 774003.1089914998, 774003.1089914993, 206184.6311227073], 
processed observation next is [1.0, 0.8695652173913043, 0.6388888888888888, 0.685, 1.0, 1.0, 0.21376735446792425, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.42574733328638126, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27642968178267846, 0.2764296817826783, 0.39650890600520633], 
reward next is 0.6035, 
noisyNet noise sample is [array([-1.012019], dtype=float32), -0.77497953]. 
=============================================
[2019-03-23 03:41:13,484] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:41:13,492] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9221
[2019-03-23 03:41:13,506] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.3448374e-05 9.7333339e-16 0.0000000e+00 9.9995661e-01 0.0000000e+00], sum to 1.0000
[2019-03-23 03:41:13,507] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 767362.1077329145 W.
[2019-03-23 03:41:13,513] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.5, 82.33333333333334, 1.0, 2.0, 0.2244350513904264, 1.0, 2.0, 0.2244350513904264, 1.0, 2.0, 0.357307911152891, 6.9112, 6.9112, 121.94756008, 767362.1077329145, 767362.1077329145, 228742.9564392315], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2914800.0000, 
sim time next is 2915400.0000, 
raw observation next is [27.25, 83.16666666666666, 1.0, 2.0, 0.3366543187646824, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5359646395390952, 6.9112, 6.9112, 121.9260426156618, 767366.1474592008, 767366.1474592008, 205360.0999635817], 
processed observation next is [1.0, 0.7391304347826086, 0.5648148148148148, 0.8316666666666666, 1.0, 1.0, 0.2103027604341457, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.419955799423869, 0.0, 0.0, 0.8094621288201359, 0.274059338378286, 0.274059338378286, 0.39492326916073406], 
reward next is 0.6051, 
noisyNet noise sample is [array([-1.4171453], dtype=float32), 0.002180763]. 
=============================================
[2019-03-23 03:41:13,513] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7321
[2019-03-23 03:41:13,519] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.5, 56.33333333333334, 1.0, 2.0, 0.6997223507715848, 1.0, 2.0, 0.6632258373622272, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2269701.718949038, 2269701.718949037, 429165.4725766461], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2814600.0000, 
sim time next is 2815200.0000, 
raw observation next is [32.6, 55.0, 1.0, 2.0, 1.015498337258295, 1.0, 2.0, 1.015498337258295, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2316897.761078018, 2316897.761078017, 440848.4118648436], 
processed observation next is [1.0, 0.6086956521739131, 0.7629629629629631, 0.55, 1.0, 1.0, 1.0184504014979703, 1.0, 1.0, 1.0184504014979703, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.8274634860992922, 0.8274634860992918, 0.8477854074323916], 
reward next is 0.1522, 
noisyNet noise sample is [array([-0.62012535], dtype=float32), -1.0797004]. 
=============================================
[2019-03-23 03:41:16,161] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.6218168e-23], sum to 1.0000
[2019-03-23 03:41:16,167] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2250
[2019-03-23 03:41:16,175] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 787731.1336886341 W.
[2019-03-23 03:41:16,180] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.6690982457125896, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 787731.1336886341, 787731.1336886341, 171556.5275498586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2865000.0000, 
sim time next is 2865600.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.6545948037825118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 775051.8011035244, 775051.8011035253, 169060.7456748507], 
processed observation next is [1.0, 0.17391304347826086, 0.37037037037037035, 1.0, 1.0, 1.0, 0.5888033378363235, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.27680421467983013, 0.27680421467983046, 0.32511681860548214], 
reward next is 0.6749, 
noisyNet noise sample is [array([0.07560679], dtype=float32), -0.17635173]. 
=============================================
[2019-03-23 03:41:26,789] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:41:26,803] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3933
[2019-03-23 03:41:26,811] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8131142705464163, 6.9112, 6.9112, 121.9260426156618, 602698.475924039, 602698.475924039, 162533.2312594236], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3114000.0000, 
sim time next is 3114600.0000, 
raw observation next is [28.06666666666667, 55.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7995029648970744, 6.911200000000001, 6.9112, 121.9260426156618, 593677.2994905453, 593677.2994905448, 160348.6191295544], 
processed observation next is [1.0, 0.043478260869565216, 0.5950617283950619, 0.5583333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.749378706121343, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21202760696090903, 0.21202760696090886, 0.30836272909529694], 
reward next is 0.6916, 
noisyNet noise sample is [array([1.6759831], dtype=float32), 2.5615425]. 
=============================================
[2019-03-23 03:41:32,974] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.8737073e-01 6.5236049e-17 3.4472294e-26 1.2629217e-02 1.5142133e-28], sum to 1.0000
[2019-03-23 03:41:32,982] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0896
[2019-03-23 03:41:32,991] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1734845.861064445 W.
[2019-03-23 03:41:32,997] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.58333333333334, 33.83333333333334, 1.0, 2.0, 0.7356309902088823, 1.0, 2.0, 0.7356309902088823, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1734845.861064445, 1734845.861064445, 320630.4332389277], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3149400.0000, 
sim time next is 3150000.0000, 
raw observation next is [32.9, 32.0, 1.0, 2.0, 0.4889728308159808, 1.0, 2.0, 0.4889728308159808, 1.0, 1.0, 0.7810020457869886, 6.911200000000001, 6.9112, 121.94756008, 1713053.979858082, 1713053.979858082, 338309.0092451784], 
processed observation next is [1.0, 0.4782608695652174, 0.774074074074074, 0.32, 1.0, 1.0, 0.3916343223999772, 1.0, 1.0, 0.3916343223999772, 1.0, 0.5, 0.7262525572337358, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6118049928064578, 0.6118049928064578, 0.65059424854842], 
reward next is 0.3494, 
noisyNet noise sample is [array([-0.6014737], dtype=float32), -2.6846597]. 
=============================================
[2019-03-23 03:41:33,009] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[38.659176]
 [37.696964]
 [38.225456]
 [38.98949 ]
 [38.017902]], R is [[38.79560471]
 [38.79105377]
 [38.40314484]
 [38.37417984]
 [38.37067413]].
[2019-03-23 03:41:34,966] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 4.230401e-34], sum to 1.0000
[2019-03-23 03:41:34,973] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7580
[2019-03-23 03:41:34,986] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 874588.9922713722 W.
[2019-03-23 03:41:34,992] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.2, 75.0, 1.0, 2.0, 0.2557784693812936, 1.0, 2.0, 0.2557784693812936, 1.0, 2.0, 0.407207653378211, 6.9112, 6.9112, 121.94756008, 874588.9922713722, 874588.9922713722, 239683.7627376686], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3958800.0000, 
sim time next is 3959400.0000, 
raw observation next is [29.25, 74.0, 1.0, 2.0, 0.2532422251245351, 1.0, 2.0, 0.2532422251245351, 1.0, 2.0, 0.4031698699217426, 6.911200000000001, 6.9112, 121.94756008, 865911.857829957, 865911.8578299566, 238778.0449118398], 
processed observation next is [0.0, 0.8260869565217391, 0.6388888888888888, 0.74, 1.0, 1.0, 0.11100264895777986, 1.0, 1.0, 0.11100264895777986, 1.0, 1.0, 0.2539623374021782, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.30925423493927034, 0.3092542349392702, 0.4591885479073842], 
reward next is 0.5408, 
noisyNet noise sample is [array([-0.15007217], dtype=float32), -0.52251846]. 
=============================================
[2019-03-23 03:41:36,361] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.7359734e-30], sum to 1.0000
[2019-03-23 03:41:36,370] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8243
[2019-03-23 03:41:36,380] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 750228.9576975147 W.
[2019-03-23 03:41:36,386] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 86.66666666666667, 1.0, 2.0, 0.658279340239721, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 750228.9576975147, 750228.9576975147, 168393.27381236], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3980400.0000, 
sim time next is 3981000.0000, 
raw observation next is [25.55, 86.83333333333333, 1.0, 2.0, 0.6563696812531066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 748051.4922117024, 748051.4922117024, 168045.8269468251], 
processed observation next is [1.0, 0.043478260869565216, 0.5018518518518519, 0.8683333333333333, 1.0, 1.0, 0.5909162872060792, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2671612472184651, 0.2671612472184651, 0.3231650518208175], 
reward next is 0.6768, 
noisyNet noise sample is [array([0.4315502], dtype=float32), 0.24454702]. 
=============================================
[2019-03-23 03:41:36,400] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[31.798729]
 [32.42854 ]
 [32.807846]
 [33.488594]
 [34.14415 ]], R is [[32.05875397]
 [32.41433334]
 [32.72882843]
 [32.40153885]
 [32.07752228]].
[2019-03-23 03:41:42,865] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:41:42,873] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7024
[2019-03-23 03:41:42,877] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.66666666666667, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8058863476941287, 6.911200000000001, 6.9112, 121.9260426156618, 598117.5111781516, 598117.5111781511, 161286.5639694739], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3543600.0000, 
sim time next is 3544200.0000, 
raw observation next is [22.5, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8044040974798128, 6.911200000000001, 6.9112, 121.9260426156618, 597315.7428835197, 597315.7428835194, 160961.2719831663], 
processed observation next is [1.0, 0.0, 0.3888888888888889, 0.915, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.755505121849766, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2133270510298285, 0.21332705102982835, 0.3095409076599352], 
reward next is 0.6905, 
noisyNet noise sample is [array([-0.73271286], dtype=float32), 0.029446304]. 
=============================================
[2019-03-23 03:41:43,292] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.0023317e-26 1.5816038e-29 1.9717667e-27 9.1274688e-30], sum to 1.0000
[2019-03-23 03:41:43,299] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9881
[2019-03-23 03:41:43,306] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1741823.438506939 W.
[2019-03-23 03:41:43,311] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.8, 79.66666666666667, 1.0, 2.0, 0.9006473467793442, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1741823.438506939, 1741823.438506939, 357104.763915745], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3401400.0000, 
sim time next is 3402000.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.5189929816754468, 1.0, 1.0, 0.5189929816754468, 1.0, 2.0, 0.8262537292487051, 6.911199999999999, 6.9112, 121.94756008, 1775615.172602656, 1775615.172602657, 353008.8235330936], 
processed observation next is [1.0, 0.391304347826087, 0.5555555555555556, 0.79, 1.0, 1.0, 0.4273725972326748, 1.0, 0.5, 0.4273725972326748, 1.0, 1.0, 0.7828171615608814, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6341482759295201, 0.6341482759295204, 0.6788631221790262], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0593992], dtype=float32), -0.041345213]. 
=============================================
[2019-03-23 03:41:43,337] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[28.054455]
 [28.497461]
 [28.490215]
 [29.034498]
 [31.641472]], R is [[28.24770737]
 [28.27849197]
 [28.33282089]
 [28.04949379]
 [28.16272736]].
[2019-03-23 03:41:45,495] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 03:41:45,499] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:41:45,499] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:41:45,500] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:41:45,500] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:41:45,501] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:41:45,501] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:41:45,502] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:41:45,503] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:41:45,503] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:41:45,508] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:41:45,530] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run98
[2019-03-23 03:41:45,531] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run98
[2019-03-23 03:41:45,556] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run98
[2019-03-23 03:41:45,612] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run98
[2019-03-23 03:41:45,640] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run98
[2019-03-23 03:42:59,347] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.28997183], dtype=float32), -0.104749925]
[2019-03-23 03:42:59,348] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.66666666666666, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6226798689326084, 6.9112, 6.9112, 121.9260426156618, 462782.3346484934, 462782.3346484934, 132980.7561284614]
[2019-03-23 03:42:59,350] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:42:59,352] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.16092593203398586
[2019-03-23 03:43:34,933] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8241.1079 2477291576.1597 283.0000
[2019-03-23 03:43:35,175] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8258.5229 2434978783.0721 322.0000
[2019-03-23 03:43:35,479] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7815.0296 2671798641.5457 375.0000
[2019-03-23 03:43:35,553] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8353.2353 2429994978.0080 269.0000
[2019-03-23 03:43:35,598] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8366.2625 2382241257.2146 274.0000
[2019-03-23 03:43:36,616] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2425000, evaluation results [2425000.0, 7815.02963182163, 2671798641.545656, 375.0, 8353.235289813156, 2429994978.0079975, 269.0, 8366.262499705887, 2382241257.2146297, 274.0, 8241.107945360673, 2477291576.159737, 283.0, 8258.522853624918, 2434978783.0721474, 322.0]
[2019-03-23 03:43:37,165] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.6186962e-37 0.0000000e+00 1.1694453e-13], sum to 1.0000
[2019-03-23 03:43:37,174] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8375
[2019-03-23 03:43:37,183] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 783767.9163017988 W.
[2019-03-23 03:43:37,191] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.45, 94.0, 1.0, 2.0, 0.6721686545762466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783767.9163017988, 783767.9163017988, 171795.3672861507], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3385800.0000, 
sim time next is 3386400.0000, 
raw observation next is [23.26666666666667, 94.0, 1.0, 2.0, 0.3214605342284167, 0.0, 2.0, 0.0, 1.0, 1.0, 0.512894452666953, 6.911199999999999, 6.9112, 121.9260426156618, 746638.4551621339, 746638.4551621344, 200799.953104147], 
processed observation next is [1.0, 0.17391304347826086, 0.41728395061728407, 0.94, 1.0, 1.0, 0.19221492170049606, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.3911180658336912, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26665659112933354, 0.2666565911293337, 0.38615375596951346], 
reward next is 0.6138, 
noisyNet noise sample is [array([0.51233745], dtype=float32), 1.0468827]. 
=============================================
[2019-03-23 03:43:38,258] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.8007448e-36], sum to 1.0000
[2019-03-23 03:43:38,263] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8594
[2019-03-23 03:43:38,273] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.8, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.872812182337677, 6.911200000000001, 6.9112, 121.9260426156618, 641986.4578980875, 641986.4578980871, 171631.8500284369], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3624000.0000, 
sim time next is 3624600.0000, 
raw observation next is [24.0, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8573181993221219, 6.911200000000001, 6.9112, 121.9260426156618, 632176.4500010482, 632176.4500010477, 169202.0182398881], 
processed observation next is [1.0, 0.9565217391304348, 0.4444444444444444, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8216477491526525, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22577730357180292, 0.22577730357180276, 0.32538849661516944], 
reward next is 0.6746, 
noisyNet noise sample is [array([0.46863645], dtype=float32), 0.38381544]. 
=============================================
[2019-03-23 03:43:49,045] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1247878e-10 6.5833759e-31 6.1744517e-21 5.9003608e-29 1.0000000e+00], sum to 1.0000
[2019-03-23 03:43:49,051] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9534
[2019-03-23 03:43:49,054] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.16666666666667, 86.5, 1.0, 2.0, 0.4815505439865923, 1.0, 2.0, 0.4815505439865923, 1.0, 2.0, 0.766644149032985, 6.9112, 6.9112, 121.94756008, 1647396.383146661, 1647396.383146661, 334626.1439133234], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3679800.0000, 
sim time next is 3680400.0000, 
raw observation next is [26.33333333333334, 87.0, 1.0, 2.0, 0.503391213190153, 1.0, 2.0, 0.503391213190153, 1.0, 2.0, 0.801415205705991, 6.911199999999999, 6.9112, 121.94756008, 1722185.862963728, 1722185.862963728, 345256.6067579656], 
processed observation next is [1.0, 0.6086956521739131, 0.5308641975308644, 0.87, 1.0, 1.0, 0.4087990633216107, 1.0, 1.0, 0.4087990633216107, 1.0, 1.0, 0.7517690071324886, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6150663796299028, 0.6150663796299028, 0.6639550129960876], 
reward next is 0.3360, 
noisyNet noise sample is [array([0.6161043], dtype=float32), -0.6242815]. 
=============================================
[2019-03-23 03:43:52,152] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:43:52,157] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1288
[2019-03-23 03:43:52,162] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.66666666666667, 58.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9368454526546379, 6.911200000000001, 6.9112, 121.9260426156618, 680264.0793679003, 680264.0793678998, 181844.4423360495], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3832800.0000, 
sim time next is 3833400.0000, 
raw observation next is [29.83333333333333, 58.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9536766114540661, 6.911200000000001, 6.9112, 121.9260426156618, 690236.9111943071, 690236.9111943067, 184488.4993059133], 
processed observation next is [0.0, 0.34782608695652173, 0.6604938271604937, 0.5883333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9420957643175826, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24651318256939542, 0.24651318256939525, 0.3547855755882948], 
reward next is 0.6452, 
noisyNet noise sample is [array([0.19132753], dtype=float32), 0.77806133]. 
=============================================
[2019-03-23 03:43:52,906] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:43:52,914] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1130
[2019-03-23 03:43:52,925] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 819356.0043144303 W.
[2019-03-23 03:43:52,931] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.55, 95.0, 1.0, 2.0, 0.7189016310374937, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819356.0043144303, 819356.0043144303, 179753.4089544872], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3904200.0000, 
sim time next is 3904800.0000, 
raw observation next is [25.4, 95.33333333333334, 1.0, 2.0, 0.3568607458149839, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5681339294805615, 6.9112, 6.9112, 121.9260426156618, 813448.8948729323, 813448.8948729323, 211163.3609949162], 
processed observation next is [0.0, 0.17391304347826086, 0.49629629629629624, 0.9533333333333335, 1.0, 1.0, 0.2343580307321237, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.46016741185070187, 0.0, 0.0, 0.8094621288201359, 0.2905174624546187, 0.2905174624546187, 0.40608338652868503], 
reward next is 0.5939, 
noisyNet noise sample is [array([-1.2801075], dtype=float32), 0.31301728]. 
=============================================
[2019-03-23 03:43:54,280] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999964e-01 1.0811274e-19 5.3949778e-26 9.3530895e-21 3.2110384e-07], sum to 1.0000
[2019-03-23 03:43:54,293] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1244
[2019-03-23 03:43:54,300] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1712089.948330765 W.
[2019-03-23 03:43:54,303] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 94.0, 1.0, 2.0, 0.8745994939054702, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1712089.948330765, 1712089.948330766, 351539.4759019798], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3749400.0000, 
sim time next is 3750000.0000, 
raw observation next is [26.66666666666667, 94.0, 1.0, 2.0, 0.738307434181677, 1.0, 1.0, 0.738307434181677, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1683880.016916652, 1683880.016916652, 318922.6673529745], 
processed observation next is [1.0, 0.391304347826087, 0.5432098765432101, 0.94, 1.0, 1.0, 0.6884612311686631, 1.0, 0.5, 0.6884612311686631, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6013857203273757, 0.6013857203273757, 0.6133128218326432], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.0524266], dtype=float32), 1.7038566]. 
=============================================
[2019-03-23 03:43:54,313] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[42.946987]
 [43.029602]
 [43.155983]
 [42.792946]
 [42.860374]], R is [[43.25740814]
 [43.14879608]
 [43.0794754 ]
 [43.0030098 ]
 [42.86720276]].
[2019-03-23 03:43:57,706] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.84228027e-01 0.00000000e+00 1.04331136e-35 0.00000000e+00
 2.15771958e-01], sum to 1.0000
[2019-03-23 03:43:57,714] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6583
[2019-03-23 03:43:57,719] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1133445.823920994 W.
[2019-03-23 03:43:57,723] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.65, 92.5, 1.0, 2.0, 0.4971399361378882, 1.0, 1.0, 0.4971399361378882, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9259813288658, 1133445.823920994, 1133445.823920994, 234499.2918931961], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3994200.0000, 
sim time next is 3994800.0000, 
raw observation next is [24.63333333333333, 92.66666666666667, 1.0, 2.0, 0.3146145317912287, 1.0, 2.0, 0.3146145317912287, 1.0, 1.0, 0.5008765808916065, 6.9112, 6.9112, 121.94756008, 1075909.650719967, 1075909.650719967, 261701.9492198463], 
processed observation next is [1.0, 0.21739130434782608, 0.46790123456790106, 0.9266666666666667, 1.0, 1.0, 0.18406491879908182, 1.0, 1.0, 0.18406491879908182, 1.0, 0.5, 0.37609572611450803, 0.0, 0.0, 0.8096049824067558, 0.3842534466857025, 0.3842534466857025, 0.5032729792689352], 
reward next is 0.4967, 
noisyNet noise sample is [array([-0.2561829], dtype=float32), 1.3737706]. 
=============================================
[2019-03-23 03:44:00,177] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.2890767e-14], sum to 1.0000
[2019-03-23 03:44:00,183] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6623
[2019-03-23 03:44:00,190] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 808514.3104822761 W.
[2019-03-23 03:44:00,194] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.98333333333333, 49.33333333333334, 1.0, 2.0, 0.3546970804806615, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5646893038026597, 6.911199999999999, 6.9112, 121.9260426156618, 808514.3104822761, 808514.3104822765, 210534.9950449931], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3859800.0000, 
sim time next is 3860400.0000, 
raw observation next is [33.96666666666667, 48.66666666666667, 1.0, 2.0, 0.2291948823231905, 1.0, 1.0, 0.2291948823231905, 1.0, 2.0, 0.3648857170147228, 6.9112, 6.9112, 121.94756008, 783644.6832128618, 783644.6832128618, 230369.0722692534], 
processed observation next is [0.0, 0.6956521739130435, 0.8135802469135803, 0.4866666666666667, 1.0, 1.0, 0.08237485990856011, 1.0, 0.5, 0.08237485990856011, 1.0, 1.0, 0.20610714626840346, 0.0, 0.0, 0.8096049824067558, 0.2798731011474506, 0.2798731011474506, 0.44301744667164117], 
reward next is 0.5570, 
noisyNet noise sample is [array([1.3851639], dtype=float32), -0.13327204]. 
=============================================
[2019-03-23 03:44:03,263] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 5.9749577e-33 0.0000000e+00 3.4590800e-12], sum to 1.0000
[2019-03-23 03:44:03,275] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8365
[2019-03-23 03:44:03,282] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 723302.7412843265 W.
[2019-03-23 03:44:03,286] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 88.66666666666667, 1.0, 2.0, 0.3173321991003594, 1.0, 1.0, 0.3173321991003594, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 723302.7412843265, 723302.7412843269, 184671.9843971034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4047600.0000, 
sim time next is 4048200.0000, 
raw observation next is [25.15, 90.0, 1.0, 2.0, 0.6394236303301003, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 728729.234263295, 728729.234263295, 164991.3837766664], 
processed observation next is [1.0, 0.8695652173913043, 0.487037037037037, 0.9, 1.0, 1.0, 0.5707424170596432, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2602604408083196, 0.2602604408083196, 0.31729112264743536], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.01233942], dtype=float32), 0.8260612]. 
=============================================
[2019-03-23 03:44:05,458] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.7564602  0.         0.         0.         0.24353983], sum to 1.0000
[2019-03-23 03:44:05,463] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9850
[2019-03-23 03:44:05,469] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.23333333333333, 85.33333333333333, 1.0, 2.0, 0.2075167068239374, 1.0, 1.0, 0.2075167068239374, 1.0, 1.0, 0.3303733556110248, 6.9112, 6.9112, 121.94756008, 709490.1152069756, 709490.1152069756, 223065.664794097], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4038000.0000, 
sim time next is 4038600.0000, 
raw observation next is [26.11666666666667, 87.16666666666667, 1.0, 2.0, 0.2115999023788907, 1.0, 2.0, 0.2115999023788907, 1.0, 2.0, 0.3368739359149059, 6.911200000000001, 6.9112, 121.94756008, 723456.9602339056, 723456.9602339051, 224421.2017956303], 
processed observation next is [1.0, 0.7391304347826086, 0.5228395061728397, 0.8716666666666667, 1.0, 1.0, 0.06142845521296512, 1.0, 1.0, 0.06142845521296512, 1.0, 1.0, 0.17109241989363233, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.25837748579782344, 0.25837748579782327, 0.431579234222366], 
reward next is 0.5684, 
noisyNet noise sample is [array([-0.9602643], dtype=float32), 0.5971718]. 
=============================================
[2019-03-23 03:44:05,505] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:44:05,510] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8688
[2019-03-23 03:44:05,515] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7236397544869493, 6.911200000000001, 6.9112, 121.9260426156618, 540600.4585407507, 540600.4585407502, 148349.4140380509], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4150800.0000, 
sim time next is 4151400.0000, 
raw observation next is [20.95, 94.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7227488034136073, 6.911200000000001, 6.9112, 121.9260426156618, 539944.9223391169, 539944.9223391166, 148221.7747471858], 
processed observation next is [1.0, 0.043478260869565216, 0.33148148148148143, 0.945, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.653436004267009, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19283747226397033, 0.19283747226397022, 0.28504187451381885], 
reward next is 0.7150, 
noisyNet noise sample is [array([0.12181388], dtype=float32), -0.14814638]. 
=============================================
[2019-03-23 03:44:06,547] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.99680877e-01 1.22529825e-36 0.00000000e+00 0.00000000e+00
 3.19084298e-04], sum to 1.0000
[2019-03-23 03:44:06,551] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1788
[2019-03-23 03:44:06,554] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 734677.2890283169 W.
[2019-03-23 03:44:06,567] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.16666666666666, 96.0, 1.0, 2.0, 0.2148801023115, 1.0, 2.0, 0.2148801023115, 1.0, 2.0, 0.3420961210362735, 6.9112, 6.9112, 121.94756008, 734677.2890283169, 734677.2890283169, 225516.9188322411], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4054800.0000, 
sim time next is 4055400.0000, 
raw observation next is [24.25, 94.0, 1.0, 2.0, 0.2105338678283672, 1.0, 2.0, 0.2105338678283672, 1.0, 2.0, 0.335176774192151, 6.9112, 6.9112, 121.94756008, 719810.4928113262, 719810.4928113262, 224066.4002327036], 
processed observation next is [1.0, 0.9565217391304348, 0.4537037037037037, 0.94, 1.0, 1.0, 0.06015936646234189, 1.0, 1.0, 0.06015936646234189, 1.0, 1.0, 0.1689709677401887, 0.0, 0.0, 0.8096049824067558, 0.25707517600404506, 0.25707517600404506, 0.43089692352443], 
reward next is 0.5691, 
noisyNet noise sample is [array([2.39866], dtype=float32), 0.45976993]. 
=============================================
[2019-03-23 03:44:17,359] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.0935371e-01 0.0000000e+00 0.0000000e+00 6.7857428e-07 1.9064559e-01], sum to 1.0000
[2019-03-23 03:44:17,366] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1576
[2019-03-23 03:44:17,378] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1786738.156825048 W.
[2019-03-23 03:44:17,382] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 68.16666666666666, 1.0, 2.0, 0.7833611535464259, 1.0, 1.0, 0.7833611535464259, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1786738.156825048, 1786738.156825049, 336926.6563581299], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4359000.0000, 
sim time next is 4359600.0000, 
raw observation next is [29.2, 66.0, 1.0, 2.0, 0.9415800083928186, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1788549.861074371, 1788549.861074371, 366095.7084432368], 
processed observation next is [1.0, 0.4782608695652174, 0.637037037037037, 0.66, 1.0, 1.0, 0.9304523909438317, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.638767807526561, 0.638767807526561, 0.7040302085446862], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3648207], dtype=float32), -2.2733648]. 
=============================================
[2019-03-23 03:44:25,099] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:44:25,108] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3599
[2019-03-23 03:44:25,112] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7906922141812998, 6.911200000000001, 6.9112, 121.9260426156618, 589190.8895323277, 589190.8895323272, 158020.7021616061], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4591800.0000, 
sim time next is 4592400.0000, 
raw observation next is [21.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7912957650998189, 6.911199999999999, 6.9112, 121.9260426156618, 589640.9569290928, 589640.9569290932, 158094.2249269689], 
processed observation next is [1.0, 0.13043478260869565, 0.3333333333333333, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7391197063747736, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21058605604610456, 0.21058605604610472, 0.30402735562878636], 
reward next is 0.6960, 
noisyNet noise sample is [array([0.35355842], dtype=float32), -0.43725652]. 
=============================================
[2019-03-23 03:44:27,614] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 03:44:27,616] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:44:27,617] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:44:27,617] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:44:27,620] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:44:27,620] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:44:27,621] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:44:27,622] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:44:27,622] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:44:27,624] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:44:27,624] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:44:27,650] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run99
[2019-03-23 03:44:27,679] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run99
[2019-03-23 03:44:27,680] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run99
[2019-03-23 03:44:27,741] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run99
[2019-03-23 03:44:27,771] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run99
[2019-03-23 03:44:30,297] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.26209784], dtype=float32), -0.14619625]
[2019-03-23 03:44:30,297] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.41666666666667, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4010412514261827, 6.9112, 6.9112, 121.9260426156618, 286334.1475508369, 286334.1475508369, 86787.91793847675]
[2019-03-23 03:44:30,299] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:44:30,304] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8617833482353352
[2019-03-23 03:44:42,234] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.26209784], dtype=float32), -0.14619625]
[2019-03-23 03:44:42,235] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.01666666666667, 58.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6515775088481724, 6.9112, 6.9112, 121.9260426156618, 472300.0001678134, 472300.0001678134, 129892.8618062837]
[2019-03-23 03:44:42,236] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:44:42,241] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.1741225639820918
[2019-03-23 03:44:58,995] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.26209784], dtype=float32), -0.14619625]
[2019-03-23 03:44:58,997] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.36666666666667, 45.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6967312462501735, 6.911200000000001, 6.9112, 121.9260426156618, 520196.2420944381, 520196.2420944376, 145904.1191070264]
[2019-03-23 03:44:58,997] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:44:59,000] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.46284232886199894
[2019-03-23 03:45:12,290] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.26209784], dtype=float32), -0.14619625]
[2019-03-23 03:45:12,292] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.0, 59.33333333333334, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9250034630518646, 6.911200000000001, 6.9112, 121.9260426156618, 671112.5515880367, 671112.5515880362, 180305.5282479107]
[2019-03-23 03:45:12,292] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:45:12,294] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.4188073e-29], sampled 0.69919927758917
[2019-03-23 03:45:17,550] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.26209784], dtype=float32), -0.14619625]
[2019-03-23 03:45:17,550] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.2, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.893777190272146, 6.9112, 6.9112, 121.9260426156618, 653118.7113731734, 653118.7113731734, 175315.3287800656]
[2019-03-23 03:45:17,553] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:45:17,557] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4835363294442473
[2019-03-23 03:45:33,390] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.26209784], dtype=float32), -0.14619625]
[2019-03-23 03:45:33,391] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.83333333333334, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8810973715681105, 6.9112, 6.9112, 121.9260426156618, 644522.0629561032, 644522.0629561032, 173510.9452246885]
[2019-03-23 03:45:33,392] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:45:33,396] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.01130506077132265
[2019-03-23 03:46:04,533] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.26209784], dtype=float32), -0.14619625]
[2019-03-23 03:46:04,535] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.26666666666667, 51.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.812504499898583, 6.911200000000001, 6.9112, 121.9260426156618, 602611.8830765653, 602611.883076565, 162303.6319119596]
[2019-03-23 03:46:04,536] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:46:04,545] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.28244259707274266
[2019-03-23 03:46:17,630] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8437.5359 2360206345.3938 363.0000
[2019-03-23 03:46:17,685] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7830.2362 2604401988.5712 546.0000
[2019-03-23 03:46:17,695] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8368.9847 2361048410.2462 443.0000
[2019-03-23 03:46:17,830] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8531.1257 2303015841.0229 383.0000
[2019-03-23 03:46:17,906] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8311.9328 2415423818.3736 391.0000
[2019-03-23 03:46:18,924] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2450000, evaluation results [2450000.0, 7830.236188883534, 2604401988.571158, 546.0, 8437.535921950222, 2360206345.3937645, 363.0, 8531.125716953135, 2303015841.022944, 383.0, 8311.932839577506, 2415423818.3736024, 391.0, 8368.984670176573, 2361048410.2461867, 443.0]
[2019-03-23 03:46:35,547] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:46:35,555] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0760
[2019-03-23 03:46:35,563] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 849924.7235816466 W.
[2019-03-23 03:46:35,566] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.46666666666667, 86.66666666666666, 1.0, 2.0, 0.2485692619457074, 1.0, 1.0, 0.2485692619457074, 1.0, 2.0, 0.395730360353263, 6.911199999999999, 6.9112, 121.94756008, 849924.7235816466, 849924.723581647, 237118.6911768549], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4938000.0000, 
sim time next is 4938600.0000, 
raw observation next is [24.23333333333333, 87.83333333333334, 1.0, 2.0, 0.3504302356377748, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5584726435990064, 6.911200000000003, 6.9112, 121.9260426156618, 808280.7899325993, 808280.7899325979, 209122.984169402], 
processed observation next is [1.0, 0.13043478260869565, 0.45308641975308633, 0.8783333333333334, 1.0, 1.0, 0.22670266147354146, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.44809080449875793, 2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.288671710690214, 0.2886717106902135, 0.4021595849411577], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8707072], dtype=float32), 2.4691758]. 
=============================================
[2019-03-23 03:46:40,632] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5757397e-22 0.0000000e+00 4.9564824e-38 1.9238334e-30 1.0000000e+00], sum to 1.0000
[2019-03-23 03:46:40,638] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2374
[2019-03-23 03:46:40,643] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.5, 86.5, 1.0, 2.0, 0.2446835027878364, 1.0, 1.0, 0.2446835027878364, 1.0, 1.0, 0.3895441052235915, 6.9112, 6.9112, 121.94756008, 836631.0243823455, 836631.0243823455, 235748.1597089573], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4732200.0000, 
sim time next is 4732800.0000, 
raw observation next is [27.33333333333334, 87.33333333333333, 1.0, 2.0, 0.2449536072030301, 1.0, 2.0, 0.2449536072030301, 1.0, 2.0, 0.3899741202492665, 6.9112, 6.9112, 121.94756008, 837555.0800770209, 837555.0800770209, 235843.1544168726], 
processed observation next is [1.0, 0.782608695652174, 0.5679012345679014, 0.8733333333333333, 1.0, 1.0, 0.10113524667027395, 1.0, 1.0, 0.10113524667027395, 1.0, 1.0, 0.23746765031158307, 0.0, 0.0, 0.8096049824067558, 0.29912681431322174, 0.29912681431322174, 0.453544527724755], 
reward next is 0.5465, 
noisyNet noise sample is [array([-2.574024], dtype=float32), -0.059717756]. 
=============================================
[2019-03-23 03:46:43,423] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.3155557e-29 2.0120111e-30 1.0773763e-13 2.3949186e-13], sum to 1.0000
[2019-03-23 03:46:43,435] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3976
[2019-03-23 03:46:43,443] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1320511.357613155 W.
[2019-03-23 03:46:43,446] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.93333333333333, 94.0, 1.0, 2.0, 0.5791179721140984, 1.0, 2.0, 0.5791179721140984, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1320511.357613155, 1320511.357613155, 260934.4237250743], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4785600.0000, 
sim time next is 4786200.0000, 
raw observation next is [23.95, 94.0, 1.0, 2.0, 0.544340441947599, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8666077115111206, 6.911199999999999, 6.9112, 121.9260426156618, 1241146.994522683, 1241146.994522683, 272827.8630786266], 
processed observation next is [1.0, 0.391304347826087, 0.4425925925925926, 0.94, 1.0, 1.0, 0.4575481451757131, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.8332596393889008, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4432667837581011, 0.4432667837581011, 0.5246689674588972], 
reward next is 0.4753, 
noisyNet noise sample is [array([-1.1013625], dtype=float32), -1.4945259]. 
=============================================
[2019-03-23 03:46:44,421] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:46:44,427] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9202
[2019-03-23 03:46:44,432] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8632021155011205, 6.9112, 6.9112, 121.9260426156618, 635675.5588871599, 635675.5588871599, 170191.1714353747], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5022000.0000, 
sim time next is 5022600.0000, 
raw observation next is [23.0, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8668085277150269, 6.9112, 6.9112, 121.9260426156618, 637724.9725979008, 637724.9725979008, 170815.8961995634], 
processed observation next is [0.0, 0.13043478260869565, 0.4074074074074074, 0.95, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8335106596437836, 0.0, 0.0, 0.8094621288201359, 0.22775891878496457, 0.22775891878496457, 0.3284921080760835], 
reward next is 0.6715, 
noisyNet noise sample is [array([-0.07236402], dtype=float32), -1.2807783]. 
=============================================
[2019-03-23 03:46:45,793] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0452310e-19 9.3081315e-30 3.0642922e-36 1.0000000e+00 1.3109655e-29], sum to 1.0000
[2019-03-23 03:46:45,801] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7685
[2019-03-23 03:46:45,810] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 88.0, 1.0, 2.0, 0.7415586147603312, 1.0, 2.0, 0.7415586147603312, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1691302.101683377, 1691302.101683377, 320197.078186819], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4793400.0000, 
sim time next is 4794000.0000, 
raw observation next is [26.0, 88.33333333333333, 1.0, 2.0, 0.7601679388442625, 1.0, 2.0, 0.7601679388442625, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1733786.311833072, 1733786.311833072, 327569.9247954356], 
processed observation next is [1.0, 0.4782608695652174, 0.5185185185185185, 0.8833333333333333, 1.0, 1.0, 0.7144856414812648, 1.0, 1.0, 0.7144856414812648, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.61920939708324, 0.61920939708324, 0.6299421630681454], 
reward next is 0.3701, 
noisyNet noise sample is [array([0.8111536], dtype=float32), -1.4860328]. 
=============================================
[2019-03-23 03:46:45,829] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[39.35894 ]
 [39.573177]
 [39.50184 ]
 [38.71037 ]
 [38.596016]], R is [[38.83979034]
 [38.83562851]
 [38.82947922]
 [38.441185  ]
 [38.38296509]].
[2019-03-23 03:46:47,290] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.6268191e-02 3.3200404e-38 1.7169575e-29 0.0000000e+00 9.3373179e-01], sum to 1.0000
[2019-03-23 03:46:47,302] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4249
[2019-03-23 03:46:47,307] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6847681161061626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 780433.1009167392, 780433.1009167392, 173278.3931058588], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4861200.0000, 
sim time next is 4861800.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.2259363645418184, 1.0, 1.0, 0.2259363645418184, 1.0, 1.0, 0.359698050584263, 6.9112, 6.9112, 121.94756008, 772497.808419999, 772497.808419999, 229254.4869025723], 
processed observation next is [1.0, 0.2608695652173913, 0.48148148148148145, 0.94, 1.0, 1.0, 0.07849567207359333, 1.0, 0.5, 0.07849567207359333, 1.0, 0.5, 0.19962256323032876, 0.0, 0.0, 0.8096049824067558, 0.2758920744357139, 0.2758920744357139, 0.4408740132741775], 
reward next is 0.5591, 
noisyNet noise sample is [array([0.77281666], dtype=float32), -0.87059224]. 
=============================================
[2019-03-23 03:46:50,830] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.01798203 0.         0.         0.         0.982018  ], sum to 1.0000
[2019-03-23 03:46:50,841] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0852
[2019-03-23 03:46:50,846] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.95, 84.0, 1.0, 2.0, 0.2171856958557443, 1.0, 1.0, 0.2171856958557443, 1.0, 1.0, 0.34576670104665, 6.911199999999999, 6.9112, 121.94756008, 742563.9546348612, 742563.9546348617, 226290.681490867], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4989000.0000, 
sim time next is 4989600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.2201121315455781, 1.0, 2.0, 0.2201121315455781, 1.0, 2.0, 0.3504256819722222, 6.9112, 6.9112, 121.94756008, 752574.4307446422, 752574.4307446422, 227277.0830775615], 
processed observation next is [1.0, 0.782608695652174, 0.5555555555555556, 0.84, 1.0, 1.0, 0.07156206136378344, 1.0, 1.0, 0.07156206136378344, 1.0, 1.0, 0.1880321024652777, 0.0, 0.0, 0.8096049824067558, 0.26877658240880076, 0.26877658240880076, 0.4370713136106952], 
reward next is 0.5629, 
noisyNet noise sample is [array([0.44983673], dtype=float32), -0.623383]. 
=============================================
[2019-03-23 03:46:54,199] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 0. 0. 0. 1.], sum to 1.0000
[2019-03-23 03:46:54,209] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2505
[2019-03-23 03:46:54,215] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.26666666666667, 86.66666666666666, 1.0, 2.0, 0.2723330632158135, 1.0, 2.0, 0.2723330632158135, 1.0, 1.0, 0.4335631059082481, 6.911200000000001, 6.9112, 121.94756008, 931228.8668573983, 931228.8668573978, 245683.7917310266], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5085600.0000, 
sim time next is 5086200.0000, 
raw observation next is [28.13333333333333, 87.83333333333334, 1.0, 2.0, 0.2735285053007567, 1.0, 2.0, 0.2735285053007567, 1.0, 2.0, 0.4354662886403083, 6.911200000000001, 6.9112, 121.94756008, 935319.113519014, 935319.1135190135, 246122.9876425189], 
processed observation next is [0.0, 0.8695652173913043, 0.5975308641975308, 0.8783333333333334, 1.0, 1.0, 0.1351529825009008, 1.0, 1.0, 0.1351529825009008, 1.0, 1.0, 0.29433286080038534, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.334042540542505, 0.3340425405425048, 0.4733134377740748], 
reward next is 0.5267, 
noisyNet noise sample is [array([-0.94921166], dtype=float32), -0.4444183]. 
=============================================
[2019-03-23 03:46:57,833] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.3390876e-27], sum to 1.0000
[2019-03-23 03:46:57,840] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5531
[2019-03-23 03:46:57,850] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 830820.6085206355 W.
[2019-03-23 03:46:57,855] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.1, 86.33333333333334, 1.0, 2.0, 0.3644776036303669, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5802602151863919, 6.911199999999999, 6.9112, 121.9260426156618, 830820.6085206355, 830820.608520636, 213394.8963923387], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5256600.0000, 
sim time next is 5257200.0000, 
raw observation next is [27.0, 86.66666666666667, 1.0, 2.0, 0.7235819483324515, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 824693.1867926775, 824693.1867926775, 180658.1983950258], 
processed observation next is [1.0, 0.8695652173913043, 0.5555555555555556, 0.8666666666666667, 1.0, 1.0, 0.670930890871966, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2945332809973848, 0.2945332809973848, 0.3474196122981265], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3624402], dtype=float32), 0.60870856]. 
=============================================
[2019-03-23 03:46:59,002] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:46:59,008] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2401
[2019-03-23 03:46:59,013] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.56666666666667, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.748685301138324, 6.911200000000001, 6.9112, 121.9260426156618, 558960.1968251583, 558960.1968251579, 151876.821995051], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5802600.0000, 
sim time next is 5803200.0000, 
raw observation next is [21.5, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7502922781883613, 6.9112, 6.9112, 121.9260426156618, 560169.4985570945, 560169.4985570945, 152050.733977629], 
processed observation next is [1.0, 0.17391304347826086, 0.35185185185185186, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6878653477354515, 0.0, 0.0, 0.8094621288201359, 0.2000605351989623, 0.2000605351989623, 0.29240525764928654], 
reward next is 0.7076, 
noisyNet noise sample is [array([1.2154201], dtype=float32), 0.1388601]. 
=============================================
[2019-03-23 03:47:01,233] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.2808106e-24], sum to 1.0000
[2019-03-23 03:47:01,242] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1521
[2019-03-23 03:47:01,253] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 827551.9419880126 W.
[2019-03-23 03:47:01,259] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.2, 98.66666666666666, 1.0, 2.0, 0.2420296408454294, 1.0, 1.0, 0.2420296408454294, 1.0, 2.0, 0.3853190705810301, 6.9112, 6.9112, 121.94756008, 827551.9419880126, 827551.9419880126, 234816.9742691575], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5204400.0000, 
sim time next is 5205000.0000, 
raw observation next is [23.1, 99.33333333333334, 1.0, 2.0, 0.2381710007626241, 1.0, 2.0, 0.2381710007626241, 1.0, 2.0, 0.3791759899020699, 6.911199999999999, 6.9112, 121.94756008, 814351.4052160407, 814351.4052160411, 233470.078110807], 
processed observation next is [1.0, 0.21739130434782608, 0.41111111111111115, 0.9933333333333334, 1.0, 1.0, 0.09306071519360011, 1.0, 1.0, 0.09306071519360011, 1.0, 1.0, 0.22396998737758736, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2908397875771574, 0.29083978757715756, 0.4489809194438596], 
reward next is 0.5510, 
noisyNet noise sample is [array([-1.8696488], dtype=float32), 0.15457596]. 
=============================================
[2019-03-23 03:47:01,272] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[31.064404]
 [30.852968]
 [30.935223]
 [30.33141 ]
 [30.742008]], R is [[31.25489044]
 [30.94234276]
 [30.63291931]
 [30.32658958]
 [30.02332306]].
[2019-03-23 03:47:03,321] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.6812195e-01 6.9962936e-37 0.0000000e+00 0.0000000e+00 5.3187811e-01], sum to 1.0000
[2019-03-23 03:47:03,331] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4221
[2019-03-23 03:47:03,340] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1083811.925144634 W.
[2019-03-23 03:47:03,343] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.06666666666667, 93.66666666666667, 1.0, 2.0, 0.3169236601996602, 1.0, 2.0, 0.3169236601996602, 1.0, 2.0, 0.5045527885208916, 6.9112, 6.9112, 121.94756008, 1083811.925144634, 1083811.925144634, 262605.4359733358], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5194200.0000, 
sim time next is 5194800.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.4573567039453019, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7281267677488893, 6.911199999999999, 6.9112, 121.9260426156618, 1042680.996112487, 1042680.996112487, 242458.7751338637], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.3539960761253594, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.6601584596861115, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.37238607004017393, 0.37238607004017393, 0.4662668752574302], 
reward next is 0.5337, 
noisyNet noise sample is [array([-0.71646005], dtype=float32), -0.72709394]. 
=============================================
[2019-03-23 03:47:03,595] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.999541e-01 0.000000e+00 0.000000e+00 0.000000e+00 4.589130e-05], sum to 1.0000
[2019-03-23 03:47:03,606] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6344
[2019-03-23 03:47:03,612] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 701133.2967930906 W.
[2019-03-23 03:47:03,615] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.98333333333333, 80.66666666666666, 1.0, 2.0, 0.6094229904032844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 701133.2967930906, 701133.2967930906, 160029.8939426672], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5356200.0000, 
sim time next is 5356800.0000, 
raw observation next is [25.9, 81.0, 1.0, 2.0, 0.2042944714040967, 1.0, 1.0, 0.2042944714040967, 1.0, 1.0, 0.325243451881757, 6.911199999999999, 6.9112, 121.94756008, 698468.4218412483, 698468.4218412488, 222002.5363366725], 
processed observation next is [1.0, 0.0, 0.5148148148148147, 0.81, 1.0, 1.0, 0.0527315135763056, 1.0, 0.5, 0.0527315135763056, 1.0, 0.5, 0.15655431485219626, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.24945300780044583, 0.249453007800446, 0.42692795449360094], 
reward next is 0.5731, 
noisyNet noise sample is [array([-0.98176503], dtype=float32), 0.768975]. 
=============================================
[2019-03-23 03:47:07,938] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 5.6536055e-35 9.1969260e-28 1.3606642e-13 0.0000000e+00], sum to 1.0000
[2019-03-23 03:47:07,951] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6151
[2019-03-23 03:47:07,959] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1879870.180828429 W.
[2019-03-23 03:47:07,964] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.66666666666667, 78.66666666666667, 1.0, 2.0, 0.549433557739739, 1.0, 2.0, 0.549433557739739, 1.0, 2.0, 0.8747161177234088, 6.9112, 6.9112, 121.94756008, 1879870.180828429, 1879870.180828429, 368513.569941343], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5397600.0000, 
sim time next is 5398200.0000, 
raw observation next is [27.5, 80.0, 1.0, 2.0, 0.549252887960674, 1.0, 2.0, 0.549252887960674, 1.0, 2.0, 0.8744284855511333, 6.911199999999999, 6.9112, 121.94756008, 1879251.374473718, 1879251.374473719, 368420.06842069], 
processed observation next is [1.0, 0.4782608695652174, 0.5740740740740741, 0.8, 1.0, 1.0, 0.4633962951912785, 1.0, 1.0, 0.4633962951912785, 1.0, 1.0, 0.8430356069389167, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.671161205169185, 0.6711612051691853, 0.70850013157825], 
reward next is 0.2915, 
noisyNet noise sample is [array([0.6170203], dtype=float32), -1.2881558]. 
=============================================
[2019-03-23 03:47:10,098] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 03:47:10,099] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:47:10,100] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:47:10,101] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:47:10,101] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:47:10,103] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:47:10,103] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:47:10,103] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:47:10,104] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:47:10,106] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:47:10,102] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:47:10,130] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run100
[2019-03-23 03:47:10,165] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run100
[2019-03-23 03:47:10,166] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run100
[2019-03-23 03:47:10,194] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run100
[2019-03-23 03:47:10,224] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run100
[2019-03-23 03:47:54,158] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.23534285], dtype=float32), -0.15194577]
[2019-03-23 03:47:54,161] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.9, 85.0, 1.0, 2.0, 0.8792760241143958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426126608, 1020649.663985795, 1020649.663985795, 213834.4886641012]
[2019-03-23 03:47:54,162] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:47:54,166] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.9310219e-16 1.4184961e-24], sampled 0.7161551020520711
[2019-03-23 03:47:54,167] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1020649.663985795 W.
[2019-03-23 03:48:31,522] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.23534285], dtype=float32), -0.15194577]
[2019-03-23 03:48:31,523] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.5, 90.0, 1.0, 2.0, 0.217803492372848, 1.0, 2.0, 0.217803492372848, 1.0, 2.0, 0.346750253222107, 6.9112, 6.9112, 121.94756008, 744677.244000787, 744677.244000787, 226498.5206739439]
[2019-03-23 03:48:31,525] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:48:31,528] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.03301527 0.         0.         0.         0.96698475], sampled 0.19575084544102395
[2019-03-23 03:48:33,568] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.23534285], dtype=float32), -0.15194577]
[2019-03-23 03:48:33,571] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 78.0, 1.0, 2.0, 0.5540862175259426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 677168.7241743333, 677168.7241743336, 152193.231737826]
[2019-03-23 03:48:33,571] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:48:33,576] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 1.09712826e-32], sampled 0.22364443909017373
[2019-03-23 03:48:59,773] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8534.4879 2291140690.0904 385.0000
[2019-03-23 03:49:00,212] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8453.9478 2351002774.4423 340.0000
[2019-03-23 03:49:00,315] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8308.2410 2401760143.4116 384.0000
[2019-03-23 03:49:00,336] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7891.5908 2589365192.0626 506.0000
[2019-03-23 03:49:00,371] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8374.4111 2349088398.7892 445.0000
[2019-03-23 03:49:01,388] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2475000, evaluation results [2475000.0, 7891.590801937817, 2589365192.062581, 506.0, 8453.947770648907, 2351002774.4422994, 340.0, 8534.487946927713, 2291140690.09045, 385.0, 8308.240964597291, 2401760143.4115953, 384.0, 8374.411143076133, 2349088398.789194, 445.0]
[2019-03-23 03:49:01,907] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.7637013e-35 1.8907268e-18 4.3726425e-17], sum to 1.0000
[2019-03-23 03:49:01,915] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3194
[2019-03-23 03:49:01,924] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 808233.6324947434 W.
[2019-03-23 03:49:01,930] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.26666666666667, 89.33333333333334, 1.0, 2.0, 0.354574011291901, 1.0, 2.0, 0.354574011291901, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 808233.6324947434, 808233.6324947439, 194073.3213922145], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5262000.0000, 
sim time next is 5262600.0000, 
raw observation next is [26.18333333333334, 89.66666666666666, 1.0, 2.0, 0.2359297815108872, 1.0, 2.0, 0.2359297815108872, 1.0, 1.0, 0.3756078958618895, 6.9112, 6.9112, 121.94756008, 806684.2235558913, 806684.2235558913, 232691.5787660559], 
processed observation next is [1.0, 0.9130434782608695, 0.5253086419753089, 0.8966666666666666, 1.0, 1.0, 0.09039259703677048, 1.0, 1.0, 0.09039259703677048, 1.0, 0.5, 0.21950986982736181, 0.0, 0.0, 0.8096049824067558, 0.28810150841281834, 0.28810150841281834, 0.4474838053193383], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5328095], dtype=float32), 0.3419728]. 
=============================================
[2019-03-23 03:49:05,460] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.7586723e-09 0.0000000e+00], sum to 1.0000
[2019-03-23 03:49:05,467] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3985
[2019-03-23 03:49:05,477] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 812201.6480884292 W.
[2019-03-23 03:49:05,483] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.76666666666667, 84.66666666666667, 1.0, 2.0, 0.6988527797791844, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 812201.6480884292, 812201.6480884292, 176696.3157166901], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5283600.0000, 
sim time next is 5284200.0000, 
raw observation next is [24.68333333333334, 84.83333333333334, 1.0, 2.0, 0.3428179877388223, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5465803983827132, 6.911199999999999, 6.9112, 121.9260426156618, 793071.1890626173, 793071.1890626177, 206883.8250896558], 
processed observation next is [1.0, 0.13043478260869565, 0.4697530864197534, 0.8483333333333334, 1.0, 1.0, 0.2176404615938361, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.4332254979783915, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2832397103795062, 0.28323971037950635, 0.3978535097877996], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.71960753], dtype=float32), -1.0127121]. 
=============================================
[2019-03-23 03:49:10,085] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 0. 0. 1. 0.], sum to 1.0000
[2019-03-23 03:49:10,090] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2495
[2019-03-23 03:49:10,096] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.73333333333333, 77.33333333333334, 1.0, 2.0, 0.8493984381539043, 1.0, 2.0, 0.7380638810533867, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2526175.968995342, 2526175.968995343, 471798.6480348972], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5485200.0000, 
sim time next is 5485800.0000, 
raw observation next is [30.91666666666667, 76.16666666666666, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 8.373620967084172, 6.9112, 121.9202062517389, 3077012.956371855, 2328158.559450022, 443050.4501223686], 
processed observation next is [1.0, 0.4782608695652174, 0.7006172839506175, 0.7616666666666666, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.25, 0.14624209670841717, 0.0, 0.8094233814330786, 1.098933198704234, 0.8314851998035793, 0.8520200963891703], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6895726], dtype=float32), 1.374031]. 
=============================================
[2019-03-23 03:49:12,572] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.9719929  0.         0.         0.02800711 0.        ], sum to 1.0000
[2019-03-23 03:49:12,581] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2553
[2019-03-23 03:49:12,586] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1434784.696499639 W.
[2019-03-23 03:49:12,590] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.55, 80.0, 1.0, 2.0, 0.6291863153972231, 1.0, 2.0, 0.6291863153972231, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1434784.696499639, 1434784.696499639, 278226.0584130022], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5567400.0000, 
sim time next is 5568000.0000, 
raw observation next is [26.63333333333333, 79.66666666666667, 1.0, 2.0, 0.6052933284726522, 1.0, 2.0, 0.6052933284726522, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1380250.47991135, 1380250.479911349, 269866.2823931288], 
processed observation next is [1.0, 0.43478260869565216, 0.5419753086419752, 0.7966666666666667, 1.0, 1.0, 0.5301111053245859, 1.0, 1.0, 0.5301111053245859, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4929465999683393, 0.49294659996833895, 0.5189736199867861], 
reward next is 0.4810, 
noisyNet noise sample is [array([-1.6451432], dtype=float32), -1.3959414]. 
=============================================
[2019-03-23 03:49:12,604] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[35.22383 ]
 [35.093388]
 [35.373344]
 [35.317577]
 [35.322186]], R is [[35.59455872]
 [35.70356369]
 [35.3465271 ]
 [35.42012787]
 [35.46089554]].
[2019-03-23 03:49:14,906] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:49:14,914] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8164
[2019-03-23 03:49:14,923] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 831764.4459655223 W.
[2019-03-23 03:49:14,927] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.4, 93.0, 1.0, 2.0, 0.3648914367079693, 1.0, 2.0, 0.3648914367079693, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 831764.4459655223, 831764.4459655223, 196762.2432443705], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5542800.0000, 
sim time next is 5543400.0000, 
raw observation next is [25.4, 93.0, 1.0, 2.0, 0.3626201345807113, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5773030639657967, 6.911199999999999, 6.9112, 121.9260426156618, 826584.2557199948, 826584.2557199952, 212846.5293218138], 
processed observation next is [1.0, 0.13043478260869565, 0.49629629629629624, 0.93, 1.0, 1.0, 0.2412144459294182, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4716288299572458, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29520866275714097, 0.29520866275714114, 0.4093202486957958], 
reward next is 0.5907, 
noisyNet noise sample is [array([2.5579882], dtype=float32), 0.23570946]. 
=============================================
[2019-03-23 03:49:26,247] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:49:26,254] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5230
[2019-03-23 03:49:26,265] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.1, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7857432917554784, 6.911199999999999, 6.9112, 121.9260426156618, 584490.0187378175, 584490.018737818, 158098.0352219072], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5788800.0000, 
sim time next is 5789400.0000, 
raw observation next is [23.03333333333334, 85.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.781546945916065, 6.911200000000001, 6.9112, 121.9260426156618, 581595.902271298, 581595.9022712975, 157447.230452327], 
processed observation next is [1.0, 0.0, 0.40864197530864216, 0.8516666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7269336823950812, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2077128222397493, 0.20771282223974913, 0.3027831354852442], 
reward next is 0.6972, 
noisyNet noise sample is [array([-1.089648], dtype=float32), -1.2186079]. 
=============================================
[2019-03-23 03:49:32,307] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:49:32,312] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8100
[2019-03-23 03:49:32,319] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.08333333333333, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.676517152400754, 6.911200000000001, 6.9112, 121.9260426156618, 505257.300997895, 505257.3009978945, 141040.6028450884], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5871000.0000, 
sim time next is 5871600.0000, 
raw observation next is [21.9, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6779166430412503, 6.911200000000001, 6.9112, 121.9260426156618, 506245.6168396535, 506245.6168396531, 141071.2741821689], 
processed observation next is [1.0, 1.0, 0.36666666666666664, 0.8, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5973958038015629, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18080200601416196, 0.18080200601416183, 0.27129091188878635], 
reward next is 0.7287, 
noisyNet noise sample is [array([0.6101095], dtype=float32), 1.0209675]. 
=============================================
[2019-03-23 03:49:33,181] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.992612e-01 6.870517e-30 0.000000e+00 7.388203e-04 3.881187e-30], sum to 1.0000
[2019-03-23 03:49:33,188] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9781
[2019-03-23 03:49:33,196] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1773971.109253803 W.
[2019-03-23 03:49:33,203] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.2, 63.0, 1.0, 2.0, 0.9272018313012246, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9961304396296838, 6.9112, 6.9112, 121.9260426156618, 1773971.109253803, 1773971.109253803, 362665.6124083992], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6177600.0000, 
sim time next is 6178200.0000, 
raw observation next is [28.33333333333333, 62.33333333333333, 1.0, 2.0, 0.4692356808118179, 1.0, 1.0, 0.4692356808118179, 1.0, 2.0, 0.7470384857916503, 6.911200000000001, 6.9112, 121.94756008, 1605229.088429211, 1605229.088429211, 328737.7281818537], 
processed observation next is [1.0, 0.5217391304347826, 0.6049382716049381, 0.6233333333333333, 1.0, 1.0, 0.3681377152521641, 1.0, 0.5, 0.3681377152521641, 1.0, 1.0, 0.6837981072395629, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5732961030104324, 0.5732961030104324, 0.6321879388112571], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.28735524], dtype=float32), 1.2607831]. 
=============================================
[2019-03-23 03:49:37,673] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 7.0068766e-37 1.1186941e-33 1.6490397e-14 8.0585826e-13], sum to 1.0000
[2019-03-23 03:49:37,685] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7861
[2019-03-23 03:49:37,696] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1013766.533953811 W.
[2019-03-23 03:49:37,701] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.25, 30.0, 1.0, 2.0, 0.4037551987199826, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6820744246439159, 6.911199999999999, 6.9112, 121.9260426156618, 1013766.533953811, 1013766.533953812, 220281.4634716134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6701400.0000, 
sim time next is 6702000.0000, 
raw observation next is [29.4, 29.66666666666666, 1.0, 2.0, 0.7677656833641784, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 970971.5326083645, 970971.5326083645, 192821.61210808], 
processed observation next is [1.0, 0.5652173913043478, 0.6444444444444444, 0.29666666666666663, 1.0, 1.0, 0.7235305754335457, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.34677554736013017, 0.34677554736013017, 0.3708107925155385], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7596336], dtype=float32), 1.1262673]. 
=============================================
[2019-03-23 03:49:37,713] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[47.14057 ]
 [47.842056]
 [47.832634]
 [47.606453]
 [47.59285 ]], R is [[47.54182053]
 [47.64278412]
 [47.78315353]
 [47.96347046]
 [48.15917206]].
[2019-03-23 03:49:42,200] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:49:42,210] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9999
[2019-03-23 03:49:42,216] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8659156464247921, 6.911200000000001, 6.9112, 121.9260426156618, 637197.4257888222, 637197.4257888218, 170667.085864107], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6210000.0000, 
sim time next is 6210600.0000, 
raw observation next is [26.86666666666667, 67.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.862746362046582, 6.911200000000001, 6.9112, 121.9260426156618, 635332.6529971688, 635332.6529971684, 170134.6075428972], 
processed observation next is [1.0, 0.9130434782608695, 0.5506172839506175, 0.675, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8284329525582274, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2269045189275603, 0.22690451892756014, 0.3271819375824946], 
reward next is 0.6728, 
noisyNet noise sample is [array([-0.38083622], dtype=float32), -1.9159575]. 
=============================================
[2019-03-23 03:49:48,458] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-23 03:49:48,465] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8069
[2019-03-23 03:49:48,468] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.4, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7883433583790923, 6.911199999999999, 6.9112, 121.9260426156618, 586428.1359185899, 586428.1359185904, 158414.7672787553], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6224400.0000, 
sim time next is 6225000.0000, 
raw observation next is [24.33333333333333, 76.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7907347860147801, 6.911200000000001, 6.9112, 121.9260426156618, 588295.8213506897, 588295.8213506893, 158656.0926052511], 
processed observation next is [0.0, 0.043478260869565216, 0.45679012345678993, 0.7633333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.738418482518475, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2101056504823892, 0.21010565048238902, 0.30510787039471365], 
reward next is 0.6949, 
noisyNet noise sample is [array([-0.08190805], dtype=float32), -0.12685433]. 
=============================================
[2019-03-23 03:49:48,485] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[67.96511]
 [67.43893]
 [66.93955]
 [66.32746]
 [65.7267 ]], R is [[68.09216309]
 [68.1065979 ]
 [68.12052155]
 [68.1337204 ]
 [68.14603424]].
[2019-03-23 03:49:52,341] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 03:49:52,346] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 03:49:52,347] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:49:52,348] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 03:49:52,350] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:49:52,350] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 03:49:52,351] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 03:49:52,353] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:49:52,353] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 03:49:52,363] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:49:52,380] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 03:49:53,129] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run101
[2019-03-23 03:49:53,215] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run101
[2019-03-23 03:49:53,277] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run101
[2019-03-23 03:49:53,361] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run101
[2019-03-23 03:49:53,419] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run101
[2019-03-23 03:50:00,021] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.31926784], dtype=float32), -0.17236568]
[2019-03-23 03:50:00,022] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.7, 24.16666666666666, 1.0, 2.0, 0.9228608507505087, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.289988022126935, 6.9112, 121.9244336217884, 1360996.485059187, 1167025.721804902, 227049.7607036419]
[2019-03-23 03:50:00,024] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:50:00,027] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 6.3213745e-38 1.1292052e-10], sampled 0.02948490111398816
[2019-03-23 03:50:00,028] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1360996.485059187 W.
[2019-03-23 03:50:15,420] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.31926784], dtype=float32), -0.17236568]
[2019-03-23 03:50:15,421] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.73333333333333, 59.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5651282498901853, 6.911200000000001, 6.9112, 121.9260426156618, 414566.9071984945, 414566.9071984941, 124411.5364960041]
[2019-03-23 03:50:15,425] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:50:15,428] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.06799300916292228
[2019-03-23 03:50:19,043] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.31926784], dtype=float32), -0.17236568]
[2019-03-23 03:50:19,045] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.0, 28.0, 1.0, 2.0, 0.52755867710101, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8528542172422975, 6.911200000000001, 6.9112, 121.9260424994911, 1269101.073386829, 1269101.073386829, 264860.1603220575]
[2019-03-23 03:50:19,051] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:50:19,055] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 4.266491e-20 6.719700e-32], sampled 0.6648383286889777
[2019-03-23 03:50:19,057] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1269101.073386829 W.
[2019-03-23 03:50:40,221] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.31926784], dtype=float32), -0.17236568]
[2019-03-23 03:50:40,222] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.66666666666667, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.707836538183652, 6.9112, 6.9112, 121.9260426156618, 528909.2615326311, 528909.2615326311, 146176.6267420478]
[2019-03-23 03:50:40,224] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 03:50:40,228] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.19219462593303172
[2019-03-23 03:50:51,286] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.31926784], dtype=float32), -0.17236568]
[2019-03-23 03:50:51,287] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.68658569, 101.2598824866667, 1.0, 2.0, 0.8052293329568599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 917805.4592157124, 917805.4592157128, 197032.3847833037]
[2019-03-23 03:50:51,288] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:50:51,292] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0.4321214  0.         0.         0.         0.56787854], sampled 0.013704835014418881
[2019-03-23 03:50:51,294] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 917805.4592157124 W.
[2019-03-23 03:51:22,526] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.31926784], dtype=float32), -0.17236568]
[2019-03-23 03:51:22,528] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.18333333333333, 82.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8354115024651093, 6.9112, 6.9112, 121.9260426156618, 617793.9123620167, 617793.9123620167, 165863.8036262137]
[2019-03-23 03:51:22,529] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 03:51:22,530] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7205903875082466
[2019-03-23 03:51:32,997] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.31926784], dtype=float32), -0.17236568]
[2019-03-23 03:51:32,998] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.36771959666667, 75.64942750333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7999399017509013, 6.9112, 6.9112, 121.9260426156618, 595137.5324785851, 595137.5324785851, 159796.6493413727]
[2019-03-23 03:51:32,999] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 03:51:33,002] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8355811472855823
[2019-03-23 03:51:33,746] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.31926784], dtype=float32), -0.17236568]
[2019-03-23 03:51:33,747] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.13333333333333, 84.0, 1.0, 2.0, 0.2416620726302094, 1.0, 2.0, 0.2416620726302094, 1.0, 2.0, 0.3847338900115389, 6.911199999999999, 6.9112, 121.94756008, 826294.4690354258, 826294.4690354263, 234688.3124371128]
[2019-03-23 03:51:33,748] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 03:51:33,750] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.9897899  0.         0.         0.         0.01021013], sampled 0.8488816619431458
[2019-03-23 03:51:33,751] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 826294.4690354258 W.
[2019-03-23 03:51:43,566] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7815.1039 2576410480.8419 670.0000
[2019-03-23 03:51:43,737] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8370.1256 2331308351.5237 560.0000
[2019-03-23 03:51:43,757] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8556.2612 2268833734.8915 446.0000
[2019-03-23 03:51:43,795] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8458.5524 2326256606.7126 434.0000
[2019-03-23 03:51:43,828] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8310.7956 2385286234.5373 498.0000
[2019-03-23 03:51:44,845] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2500000, evaluation results [2500000.0, 7815.103945112414, 2576410480.841911, 670.0, 8458.552448737733, 2326256606.7125897, 434.0, 8556.26118137062, 2268833734.891545, 446.0, 8310.795634981761, 2385286234.537343, 498.0, 8370.12557339705, 2331308351.52367, 560.0]
