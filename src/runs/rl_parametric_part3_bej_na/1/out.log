Using TensorFlow backend.
[2019-03-22 23:12:36,331] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='linear', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Bej-Train-v1', eval_act_func='part3_bej_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=0.001, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[19, 1], model_type='nn', num_threads=16, output='./Part3-NA-Bej-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Bej-Test-v1', 'Part3-NA-Bej-Test-v2', 'Part3-NA-Bej-Test-v3', 'Part3-NA-Bej-Test-v4'], test_mode='Multiple', train_act_func='part3_bej_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=26)
[2019-03-22 23:12:36,331] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-22 23:12:36.369460: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-22 23:12:53,923] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-22 23:12:53,923] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Bej-Train-v1', 'Part3-NA-Bej-Test-v1', 'Part3-NA-Bej-Test-v2', 'Part3-NA-Bej-Test-v3', 'Part3-NA-Bej-Test-v4'] ...
[2019-03-22 23:12:53,936] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation worker starts!
[2019-03-22 23:12:53,938] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation worker starts!
[2019-03-22 23:12:53,942] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation worker starts!
[2019-03-22 23:12:53,945] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation worker starts!
[2019-03-22 23:12:53,951] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation worker starts!
[2019-03-22 23:12:53,951] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:12:53,951] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-22 23:12:54,008] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:54,008] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run1
[2019-03-22 23:12:54,952] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:12:54,954] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-22 23:12:55,036] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:55,037] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run1
[2019-03-22 23:12:55,259] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-22 23:12:55,259] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:12:55,260] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:12:55,260] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:55,261] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:12:55,261] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:12:55,261] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:55,262] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:12:55,262] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:55,262] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:55,262] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:55,266] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run1
[2019-03-22 23:12:55,267] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run1
[2019-03-22 23:12:55,276] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run1
[2019-03-22 23:12:55,276] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run1
[2019-03-22 23:12:55,298] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run1
[2019-03-22 23:12:55,955] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:12:55,956] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-22 23:12:56,030] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:56,031] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run1
[2019-03-22 23:12:56,959] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:12:56,963] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-22 23:12:57,043] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:57,070] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run1
[2019-03-22 23:12:57,964] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:12:57,974] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-22 23:12:58,050] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:58,064] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run1
[2019-03-22 23:12:58,969] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:12:58,971] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-22 23:12:59,047] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:12:59,047] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run1
[2019-03-22 23:12:59,972] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:12:59,976] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-22 23:13:00,053] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:00,053] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run1
[2019-03-22 23:13:00,977] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:13:00,982] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-22 23:13:01,042] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:01,043] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run1
[2019-03-22 23:13:01,981] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:13:01,986] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-22 23:13:02,044] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:02,046] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run1
[2019-03-22 23:13:02,986] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:13:02,991] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-22 23:13:03,050] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:03,051] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run1
[2019-03-22 23:13:03,989] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:13:03,992] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-22 23:13:04,055] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:04,056] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run1
[2019-03-22 23:13:04,992] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:13:04,995] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-22 23:13:05,060] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:05,061] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run1
[2019-03-22 23:13:05,994] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:13:05,998] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-22 23:13:06,053] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:06,054] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run1
[2019-03-22 23:13:06,998] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:13:07,003] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-22 23:13:07,065] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:07,066] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run1
[2019-03-22 23:13:08,004] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:13:08,012] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-22 23:13:08,075] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:08,076] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run1
[2019-03-22 23:13:09,009] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-22 23:13:09,013] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-22 23:13:09,104] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:13:09,106] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run1
[2019-03-22 23:13:12,179] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 23:13:12,179] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.24011501333333, 57.80190995333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7435522280995139, 6.911199999999999, 6.9112, 121.9260426156618, 531080.4908274694, 531080.4908274699, 128816.5463121004]
[2019-03-22 23:13:12,182] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:13:12,185] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0.309706   0.15656269 0.28052586 0.1517201  0.10148533], sampled 0.9050638408952578
[2019-03-22 23:13:21,548] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 23:13:21,550] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.6020723, 30.86774558, 1.0, 2.0, 0.559555277442978, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 715449.8229788356, 715449.8229788356, 153659.3179641138]
[2019-03-22 23:13:21,551] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:13:21,554] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.2383397  0.2463558  0.1465965  0.25871035 0.10999766], sampled 0.26894096728167727
[2019-03-22 23:13:34,949] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 23:13:34,950] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.8, 49.0, 1.0, 2.0, 0.6903617323747183, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 786811.4409156886, 786811.4409156886, 174324.2336880488]
[2019-03-22 23:13:34,951] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:13:34,954] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0.20847258 0.26835266 0.15069911 0.33175752 0.04071807], sampled 0.15707077505299238
[2019-03-22 23:13:34,956] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 786811.4409156886 W.
[2019-03-22 23:13:45,688] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 23:13:45,689] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.0, 100.0, 1.0, 2.0, 0.5329463765282144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 631303.5221515656, 631303.5221515656, 148000.7062165095]
[2019-03-22 23:13:45,690] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:13:45,693] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.2747074  0.18799286 0.16973494 0.30383563 0.06372912], sampled 0.6062481482035482
[2019-03-22 23:14:18,272] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 23:14:18,273] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.05, 97.0, 1.0, 2.0, 0.3180940382262405, 1.0, 2.0, 0.3180940382262405, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 725040.0403305569, 725040.0403305573, 184859.4341917003]
[2019-03-22 23:14:18,274] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:14:18,277] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.08621983 0.38770986 0.2809052  0.18222283 0.06294234], sampled 0.13071709164787393
[2019-03-22 23:14:24,033] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 23:14:24,035] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.922606325, 51.685823425, 1.0, 2.0, 0.4960290087226106, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 585192.0708488493, 585192.0708488493, 142025.0237120041]
[2019-03-22 23:14:24,037] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:14:24,041] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.17473514 0.25279197 0.30508003 0.19078343 0.07660947], sampled 0.450818969048963
[2019-03-22 23:14:34,157] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 23:14:34,158] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.5, 56.66666666666667, 1.0, 2.0, 0.2866445401709738, 1.0, 1.0, 0.2866445401709738, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 660606.7025403681, 660606.7025403684, 177648.2245205629]
[2019-03-22 23:14:34,158] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:14:34,161] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0.2548527  0.22993177 0.17047405 0.27247608 0.07226546], sampled 0.25603157309440705
[2019-03-22 23:14:38,462] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-22 23:14:38,463] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.4, 67.0, 1.0, 2.0, 0.6998231524766508, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9766869934987698, 6.911199999999999, 6.9112, 121.9260426156618, 1532741.902392242, 1532741.902392243, 313185.1135502088]
[2019-03-22 23:14:38,464] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:14:38,470] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.25528708 0.15422778 0.36233613 0.1717582  0.05639086], sampled 0.23136967937056974
[2019-03-22 23:14:38,472] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1532741.902392242 W.
[2019-03-22 23:14:50,588] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4615.4464 2360014393.6276 276.0000
[2019-03-22 23:14:50,630] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4460.3257 2419553023.9831 361.0000
[2019-03-22 23:14:50,800] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4353.0493 2645520865.5756 497.0000
[2019-03-22 23:14:50,850] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4454.7632 2395037841.5476 298.0000
[2019-03-22 23:14:50,965] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4442.3566 2459845558.5365 348.0000
[2019-03-22 23:14:51,979] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 4353.049290569168, 2645520865.575612, 497.0, 4454.763170082297, 2395037841.547604, 298.0, 4615.446386552132, 2360014393.6275587, 276.0, 4442.356564666999, 2459845558.5365148, 348.0, 4460.325691190856, 2419553023.983067, 361.0]
[2019-03-22 23:14:58,149] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2501962e-11 3.0984578e-04 4.2941068e-09 9.9882716e-01 8.6302607e-04], sum to 1.0000
[2019-03-22 23:14:58,155] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3887
[2019-03-22 23:14:58,260] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.3, 50.5, 1.0, 2.0, 0.2089654430892563, 1.0, 2.0, 0.2089654430892563, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 509659.4113895294, 509659.4113895294, 161575.4736855325], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 73800.0000, 
sim time next is 74400.0000, 
raw observation next is [27.13333333333333, 51.33333333333333, 1.0, 2.0, 0.2086779371908966, 1.0, 2.0, 0.2086779371908966, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 508903.1912247504, 508903.1912247508, 161512.3721180832], 
processed observation next is [1.0, 0.8695652173913043, 0.5604938271604937, 0.5133333333333333, 1.0, 1.0, 0.05794992522725787, 1.0, 1.0, 0.05794992522725787, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18175113972312515, 0.1817511397231253, 0.3106007156116985], 
reward next is 0.6894, 
noisyNet noise sample is [array([-1.2247863], dtype=float32), -0.7261835]. 
=============================================
[2019-03-22 23:15:01,736] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0823113e-12 5.7074340e-05 2.0451612e-09 9.9988592e-01 5.6981666e-05], sum to 1.0000
[2019-03-22 23:15:01,743] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3801
[2019-03-22 23:15:01,849] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.4, 15.0, 1.0, 2.0, 0.645663349887818, 1.0, 2.0, 0.645663349887818, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1572331.78599953, 1572331.78599953, 288310.0341351776], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 136800.0000, 
sim time next is 137400.0000, 
raw observation next is [37.4, 14.5, 1.0, 2.0, 0.7034222566604662, 1.0, 2.0, 0.7034222566604662, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1714641.260415463, 1714641.260415463, 310183.1241575367], 
processed observation next is [1.0, 0.6086956521739131, 0.9407407407407407, 0.145, 1.0, 1.0, 0.6469312579291264, 1.0, 1.0, 0.6469312579291264, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6123718787198082, 0.6123718787198082, 0.5965060079952629], 
reward next is 0.4035, 
noisyNet noise sample is [array([-0.755665], dtype=float32), 0.99727345]. 
=============================================
[2019-03-22 23:15:02,714] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0029904e-13 1.3845998e-05 2.5421854e-10 9.9995422e-01 3.1977925e-05], sum to 1.0000
[2019-03-22 23:15:02,726] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4439
[2019-03-22 23:15:02,822] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.75, 10.0, 1.0, 2.0, 0.1932196086084632, 1.0, 2.0, 0.1932196086084632, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 495983.6781783893, 495983.6781783898, 158740.3931156684], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 153000.0000, 
sim time next is 153600.0000, 
raw observation next is [34.46666666666667, 10.66666666666667, 1.0, 2.0, 0.192112336243494, 1.0, 2.0, 0.192112336243494, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 492915.3041479611, 492915.3041479616, 158509.7749939331], 
processed observation next is [1.0, 0.782608695652174, 0.8320987654320988, 0.1066666666666667, 1.0, 1.0, 0.038228971718445234, 1.0, 1.0, 0.038228971718445234, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17604118005284325, 0.17604118005284344, 0.3048264903729483], 
reward next is 0.6952, 
noisyNet noise sample is [array([-1.8389494], dtype=float32), 0.2097247]. 
=============================================
[2019-03-22 23:15:05,052] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4671079e-17 9.9998665e-01 2.2182164e-11 3.6443043e-07 1.2951473e-05], sum to 1.0000
[2019-03-22 23:15:05,059] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2889
[2019-03-22 23:15:05,169] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.98333333333333, 60.66666666666666, 1.0, 2.0, 0.2550939688492486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 328602.1487773325, 328602.1487773325, 110198.2797349269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 195000.0000, 
sim time next is 195600.0000, 
raw observation next is [21.16666666666667, 61.33333333333334, 1.0, 2.0, 0.2582619160811342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 331972.5556729705, 331972.5556729705, 110570.5709980322], 
processed observation next is [0.0, 0.2608695652173913, 0.33950617283950635, 0.6133333333333334, 1.0, 1.0, 0.11697847152515975, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11856162702606089, 0.11856162702606089, 0.21263571345775423], 
reward next is 0.7874, 
noisyNet noise sample is [array([-0.7092042], dtype=float32), -1.0994911]. 
=============================================
[2019-03-22 23:15:09,290] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.3466974e-21 9.9999118e-01 2.4933996e-12 3.1714342e-06 5.5851669e-06], sum to 1.0000
[2019-03-22 23:15:09,293] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2781
[2019-03-22 23:15:09,297] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 50.0, 1.0, 2.0, 0.262818821898978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 339017.3225872531, 339017.3225872531, 96178.00989858127], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 266400.0000, 
sim time next is 267000.0000, 
raw observation next is [20.81666666666667, 50.16666666666667, 1.0, 2.0, 0.2614181102133714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 337210.1083365334, 337210.1083365334, 95667.19530007259], 
processed observation next is [0.0, 0.08695652173913043, 0.32654320987654334, 0.5016666666666667, 1.0, 1.0, 0.12073584549210882, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12043218154876194, 0.12043218154876194, 0.18397537557706267], 
reward next is 0.8160, 
noisyNet noise sample is [array([-0.0077749], dtype=float32), -0.71969914]. 
=============================================
[2019-03-22 23:15:09,328] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[65.581406]
 [65.6956  ]
 [65.67761 ]
 [65.756905]
 [65.84205 ]], R is [[65.8319931 ]
 [65.98871613]
 [66.14265442]
 [66.29370117]
 [66.44151306]].
[2019-03-22 23:15:10,861] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7918: loss 0.0837
[2019-03-22 23:15:10,914] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 7918: learning rate 0.0010
[2019-03-22 23:15:10,938] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7936: loss 0.0582
[2019-03-22 23:15:10,940] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7936: learning rate 0.0010
[2019-03-22 23:15:10,964] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7949: loss 0.2414
[2019-03-22 23:15:10,969] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7951: learning rate 0.0010
[2019-03-22 23:15:10,975] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 7954: loss 0.1338
[2019-03-22 23:15:10,977] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 7954: learning rate 0.0010
[2019-03-22 23:15:10,980] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7956: loss 0.3039
[2019-03-22 23:15:10,983] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 7957: learning rate 0.0010
[2019-03-22 23:15:10,994] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 7962: loss 0.3695
[2019-03-22 23:15:10,999] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 7962: learning rate 0.0010
[2019-03-22 23:15:11,015] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7968: loss 0.2584
[2019-03-22 23:15:11,018] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7969: learning rate 0.0010
[2019-03-22 23:15:11,038] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 7981: loss 0.3104
[2019-03-22 23:15:11,041] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 7981: loss 0.2385
[2019-03-22 23:15:11,041] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 7981: learning rate 0.0010
[2019-03-22 23:15:11,042] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 7981: learning rate 0.0010
[2019-03-22 23:15:11,055] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 7988: loss 0.2575
[2019-03-22 23:15:11,060] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7989: loss 0.2095
[2019-03-22 23:15:11,062] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 7989: learning rate 0.0010
[2019-03-22 23:15:11,065] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7989: learning rate 0.0010
[2019-03-22 23:15:11,119] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 8017: loss 0.0968
[2019-03-22 23:15:11,122] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 8019: learning rate 0.0010
[2019-03-22 23:15:11,131] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 8024: loss 0.0311
[2019-03-22 23:15:11,133] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 8025: learning rate 0.0010
[2019-03-22 23:15:11,168] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 8042: loss 0.0002
[2019-03-22 23:15:11,169] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 8042: learning rate 0.0010
[2019-03-22 23:15:11,200] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 8054: loss 0.0003
[2019-03-22 23:15:11,201] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 8054: learning rate 0.0010
[2019-03-22 23:15:11,254] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 8079: loss 0.0241
[2019-03-22 23:15:11,255] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 8079: learning rate 0.0010
[2019-03-22 23:15:15,378] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.6962965e-21 9.9999976e-01 3.5164847e-14 2.2415830e-07 6.6391048e-10], sum to 1.0000
[2019-03-22 23:15:15,386] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5323
[2019-03-22 23:15:15,491] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 33.5, 1.0, 2.0, 0.870702272697101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.014367677136711, 6.9112, 121.9254632867497, 1168715.346787564, 1115884.526096896, 215158.7570369703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 379800.0000, 
sim time next is 380400.0000, 
raw observation next is [27.0, 33.0, 1.0, 2.0, 0.8785276766560056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.065579698004341, 6.9112, 121.9252469810476, 1204442.6346488, 1125386.946855037, 216928.3481791435], 
processed observation next is [1.0, 0.391304347826087, 0.5555555555555556, 0.33, 1.0, 1.0, 0.8553900912571495, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.015437969800434104, 0.0, 0.8094568466336993, 0.4301580838031428, 0.40192390959108465, 0.41716990034450674], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.23370446], dtype=float32), -0.020599283]. 
=============================================
[2019-03-22 23:15:15,645] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.9372374e-25 1.0000000e+00 2.3852869e-16 5.7350313e-08 1.0048891e-11], sum to 1.0000
[2019-03-22 23:15:15,656] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5208
[2019-03-22 23:15:15,755] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 34.0, 1.0, 2.0, 0.8664285141071355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.988044668033963, 6.9112, 121.9256190318753, 1150351.335440977, 1111000.133819749, 214196.4493788135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 379200.0000, 
sim time next is 379800.0000, 
raw observation next is [26.8, 33.5, 1.0, 2.0, 0.870702272697101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.014367677136711, 6.9112, 121.9254632867497, 1168715.346787564, 1115884.526096896, 215158.7570369703], 
processed observation next is [1.0, 0.391304347826087, 0.5481481481481482, 0.335, 1.0, 1.0, 0.8460741341632154, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.010316767713671116, 0.0, 0.8094582826786192, 0.4173983381384157, 0.3985301878917486, 0.4137668404557121], 
reward next is 0.0704, 
noisyNet noise sample is [array([2.1451752], dtype=float32), -2.0165272]. 
=============================================
[2019-03-22 23:15:20,308] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 8.2124813e-31 3.4776107e-30 3.5409394e-24], sum to 1.0000
[2019-03-22 23:15:20,317] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3500
[2019-03-22 23:15:20,416] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 48.0, 1.0, 2.0, 0.7383933792942095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 933654.3363187202, 933654.3363187202, 186820.4754391763], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 464400.0000, 
sim time next is 465000.0000, 
raw observation next is [25.51666666666667, 47.16666666666666, 1.0, 2.0, 0.8359322475745078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1055477.113075319, 1055477.113075319, 207317.6418971136], 
processed observation next is [1.0, 0.391304347826087, 0.5006172839506173, 0.47166666666666657, 1.0, 1.0, 0.8046812471125093, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3769561118126139, 0.3769561118126139, 0.3986877728790646], 
reward next is 0.6013, 
noisyNet noise sample is [array([-1.7872723], dtype=float32), -0.33843207]. 
=============================================
[2019-03-22 23:15:20,433] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.12359 ]
 [63.116276]
 [63.158108]
 [63.18367 ]
 [63.17661 ]], R is [[63.16847229]
 [63.17751694]
 [63.17578506]
 [63.18862152]
 [63.23982239]].
[2019-03-22 23:15:24,043] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 2.0763138e-31 5.1150044e-32 3.6283866e-22], sum to 1.0000
[2019-03-22 23:15:24,051] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5911
[2019-03-22 23:15:24,057] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.86666666666667, 75.0, 1.0, 2.0, 0.3293455430465352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 420313.636904403, 420313.636904403, 119278.4122688979], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 531600.0000, 
sim time next is 532200.0000, 
raw observation next is [19.78333333333333, 75.5, 1.0, 2.0, 0.3246235054713112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 414361.1856674658, 414361.1856674658, 118672.409002684], 
processed observation next is [1.0, 0.13043478260869565, 0.28827160493827153, 0.755, 1.0, 1.0, 0.19598036365632285, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14798613773838065, 0.14798613773838065, 0.2282161711590077], 
reward next is 0.7718, 
noisyNet noise sample is [array([-0.6907072], dtype=float32), -0.31383234]. 
=============================================
[2019-03-22 23:15:27,443] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15840: loss 1.7264
[2019-03-22 23:15:27,447] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 15842: learning rate 0.0010
[2019-03-22 23:15:27,523] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15884: loss 1.1138
[2019-03-22 23:15:27,525] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 15885: learning rate 0.0010
[2019-03-22 23:15:27,592] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 15916: loss 0.7144
[2019-03-22 23:15:27,594] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 15917: learning rate 0.0010
[2019-03-22 23:15:27,654] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 15941: loss 0.5912
[2019-03-22 23:15:27,658] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 15942: learning rate 0.0010
[2019-03-22 23:15:27,658] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 15943: loss 0.3356
[2019-03-22 23:15:27,664] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 15943: learning rate 0.0010
[2019-03-22 23:15:27,683] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 15957: loss 0.2910
[2019-03-22 23:15:27,685] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 15957: learning rate 0.0010
[2019-03-22 23:15:27,703] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15964: loss 0.2475
[2019-03-22 23:15:27,704] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15964: learning rate 0.0010
[2019-03-22 23:15:27,763] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15993: loss 0.3034
[2019-03-22 23:15:27,767] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15993: learning rate 0.0010
[2019-03-22 23:15:27,779] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 16000: loss 0.1235
[2019-03-22 23:15:27,781] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 16000: learning rate 0.0010
[2019-03-22 23:15:27,783] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 16000: loss 0.1507
[2019-03-22 23:15:27,783] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 16000: learning rate 0.0010
[2019-03-22 23:15:27,799] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 16007: loss 0.1683
[2019-03-22 23:15:27,801] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 16007: learning rate 0.0010
[2019-03-22 23:15:27,807] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 16008: loss 0.0582
[2019-03-22 23:15:27,808] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 16008: learning rate 0.0010
[2019-03-22 23:15:27,898] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 16050: loss 0.0445
[2019-03-22 23:15:27,903] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 16053: learning rate 0.0010
[2019-03-22 23:15:27,948] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 16075: loss 0.0005
[2019-03-22 23:15:27,952] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 16076: learning rate 0.0010
[2019-03-22 23:15:27,965] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 16082: loss 0.0009
[2019-03-22 23:15:27,969] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 16082: learning rate 0.0010
[2019-03-22 23:15:28,116] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 16151: loss 0.0483
[2019-03-22 23:15:28,118] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 16151: learning rate 0.0010
[2019-03-22 23:15:32,999] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.8586199e-37 1.0000000e+00 1.7023946e-30 8.0704379e-29 6.2018548e-22], sum to 1.0000
[2019-03-22 23:15:33,002] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3545
[2019-03-22 23:15:33,103] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 35.5, 1.0, 2.0, 0.3315409882164033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 420734.7684051611, 420734.7684051611, 119548.7886606814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 689400.0000, 
sim time next is 690000.0000, 
raw observation next is [27.66666666666666, 35.66666666666667, 1.0, 2.0, 0.329818417077115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 418860.1419106686, 418860.1419106686, 119328.9234228422], 
processed observation next is [1.0, 1.0, 0.5802469135802467, 0.3566666666666667, 1.0, 1.0, 0.20216478223466072, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1495929078252388, 0.1495929078252388, 0.22947869889008116], 
reward next is 0.7705, 
noisyNet noise sample is [array([1.6075568], dtype=float32), 1.4748105]. 
=============================================
[2019-03-22 23:15:33,135] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[87.26233 ]
 [87.21465 ]
 [87.158745]
 [87.06681 ]
 [86.979706]], R is [[87.21089172]
 [87.10887909]
 [87.00744629]
 [86.90657043]
 [86.80625916]].
[2019-03-22 23:15:33,824] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.3695983e-27 1.0000000e+00 3.8129272e-24 2.2251091e-20 1.0270017e-19], sum to 1.0000
[2019-03-22 23:15:33,831] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1509
[2019-03-22 23:15:33,843] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 43.0, 1.0, 2.0, 0.4006480586043558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513632.9194004771, 513632.9194004771, 128916.9836723836], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 702000.0000, 
sim time next is 702600.0000, 
raw observation next is [24.53333333333333, 43.83333333333334, 1.0, 2.0, 0.4276211817263025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 548200.8541776899, 548200.8541776894, 132799.4714397267], 
processed observation next is [1.0, 0.13043478260869565, 0.46419753086419746, 0.4383333333333334, 1.0, 1.0, 0.3185966449122648, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19578601934917494, 0.19578601934917478, 0.25538359892255136], 
reward next is 0.7446, 
noisyNet noise sample is [array([0.6135272], dtype=float32), -0.85310155]. 
=============================================
[2019-03-22 23:15:35,126] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.9961330e-36 1.0000000e+00 8.8769266e-32 7.6304334e-26 1.6159059e-24], sum to 1.0000
[2019-03-22 23:15:35,135] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8358
[2019-03-22 23:15:35,145] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1385270.989209614 W.
[2019-03-22 23:15:35,242] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.23333333333333, 52.83333333333334, 1.0, 2.0, 0.9512285807572877, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.324784125403762, 6.9112, 121.924400151268, 1385270.989209614, 1173481.804321464, 233129.9327234861], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 727800.0000, 
sim time next is 728400.0000, 
raw observation next is [26.36666666666667, 52.66666666666667, 1.0, 2.0, 0.5275654244676703, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8621491726156671, 6.911200000000001, 6.9112, 121.9257935624547, 1288490.246152001, 1288490.246152001, 263838.3196897332], 
processed observation next is [1.0, 0.43478260869565216, 0.5320987654320989, 0.5266666666666667, 1.0, 1.0, 0.43757788627103605, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.8276864657695839, 8.881784197001253e-17, 0.0, 0.8094604753658379, 0.4601750879114289, 0.4601750879114289, 0.5073813840187177], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2913278], dtype=float32), -1.1538241]. 
=============================================
[2019-03-22 23:15:43,322] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 9.8104543e-35 7.3680828e-31 7.9594376e-33], sum to 1.0000
[2019-03-22 23:15:43,332] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1751
[2019-03-22 23:15:43,438] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.76666666666667, 63.33333333333334, 1.0, 2.0, 0.3861053772508486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 481392.2799525632, 481392.2799525632, 126741.4162570162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 867000.0000, 
sim time next is 867600.0000, 
raw observation next is [23.6, 64.0, 1.0, 2.0, 0.3840885448886922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479198.7986880673, 479198.7986880673, 126468.4495059791], 
processed observation next is [0.0, 0.043478260869565216, 0.4296296296296297, 0.64, 1.0, 1.0, 0.2667720772484431, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1711424281028812, 0.1711424281028812, 0.2432085567422675], 
reward next is 0.7568, 
noisyNet noise sample is [array([-0.10084916], dtype=float32), -0.50409806]. 
=============================================
[2019-03-22 23:15:45,021] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23835: loss 0.0038
[2019-03-22 23:15:45,024] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 23836: learning rate 0.0010
[2019-03-22 23:15:45,096] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23864: loss 0.0054
[2019-03-22 23:15:45,101] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 23866: learning rate 0.0010
[2019-03-22 23:15:45,230] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23929: loss 0.0558
[2019-03-22 23:15:45,238] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23932: learning rate 0.0010
[2019-03-22 23:15:45,242] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23933: loss 0.0366
[2019-03-22 23:15:45,242] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 23933: loss 0.0764
[2019-03-22 23:15:45,243] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 23933: learning rate 0.0010
[2019-03-22 23:15:45,247] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 23933: learning rate 0.0010
[2019-03-22 23:15:45,253] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 23937: loss 0.0550
[2019-03-22 23:15:45,255] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 23937: learning rate 0.0010
[2019-03-22 23:15:45,339] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23979: loss 0.0015
[2019-03-22 23:15:45,341] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23979: learning rate 0.0010
[2019-03-22 23:15:45,346] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23982: loss 0.0066
[2019-03-22 23:15:45,349] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23983: learning rate 0.0010
[2019-03-22 23:15:45,369] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23992: loss 0.0007
[2019-03-22 23:15:45,374] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 23995: learning rate 0.0010
[2019-03-22 23:15:45,394] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 24000: loss 0.0078
[2019-03-22 23:15:45,398] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 24000: learning rate 0.0010
[2019-03-22 23:15:45,404] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 24005: loss 0.0017
[2019-03-22 23:15:45,407] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 24006: learning rate 0.0010
[2019-03-22 23:15:45,471] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 24035: loss 0.0759
[2019-03-22 23:15:45,473] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 24035: learning rate 0.0010
[2019-03-22 23:15:45,502] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24048: loss 0.0763
[2019-03-22 23:15:45,503] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 24049: learning rate 0.0010
[2019-03-22 23:15:45,526] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 24059: loss 0.1041
[2019-03-22 23:15:45,530] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 24060: learning rate 0.0010
[2019-03-22 23:15:45,598] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 24092: loss 0.0511
[2019-03-22 23:15:45,601] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 24093: learning rate 0.0010
[2019-03-22 23:15:45,718] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 24143: loss 0.0129
[2019-03-22 23:15:45,725] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 24145: learning rate 0.0010
[2019-03-22 23:15:46,880] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0772163e-35 3.1048971e-37], sum to 1.0000
[2019-03-22 23:15:46,887] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4581
[2019-03-22 23:15:46,894] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.96666666666667, 43.0, 1.0, 2.0, 0.3880240223850213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 482812.4040356968, 482812.4040356964, 126988.3287908639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 926400.0000, 
sim time next is 927000.0000, 
raw observation next is [27.8, 43.5, 1.0, 2.0, 0.3857729844325536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 480264.8425212643, 480264.8425212643, 126681.3181981347], 
processed observation next is [0.0, 0.7391304347826086, 0.5851851851851853, 0.435, 1.0, 1.0, 0.2687773624197067, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17152315804330867, 0.17152315804330867, 0.2436179196117975], 
reward next is 0.7564, 
noisyNet noise sample is [array([1.1691339], dtype=float32), 0.9435045]. 
=============================================
[2019-03-22 23:15:46,908] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[90.96801 ]
 [90.928856]
 [90.865295]
 [90.80778 ]
 [90.775894]], R is [[90.84682465]
 [90.6941452 ]
 [90.54303741]
 [90.39330292]
 [90.24414825]].
[2019-03-22 23:15:47,615] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-22 23:15:47,617] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:15:47,618] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:47,619] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:15:47,620] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:15:47,621] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:15:47,623] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:47,621] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:47,623] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:15:47,624] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:47,627] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:15:47,649] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run2
[2019-03-22 23:15:47,650] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run2
[2019-03-22 23:15:47,650] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run2
[2019-03-22 23:15:47,685] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run2
[2019-03-22 23:15:47,700] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run2
[2019-03-22 23:16:09,564] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05358668], dtype=float32), 0.16995448]
[2019-03-22 23:16:09,566] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.42642964666667, 21.02502261933333, 1.0, 2.0, 0.3562484119139931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 456725.0377882027, 456725.0377882027, 122809.8869062553]
[2019-03-22 23:16:09,567] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:16:09,570] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.9355912e-36 2.1322602e-31 3.1378653e-31], sampled 0.053723252895716
[2019-03-22 23:16:53,674] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05358668], dtype=float32), 0.16995448]
[2019-03-22 23:16:53,676] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.1, 85.0, 1.0, 2.0, 0.6313265955507101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 719496.9900452038, 719496.9900452034, 163550.6605561363]
[2019-03-22 23:16:53,678] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:16:53,681] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.2451323e-38 6.7279816e-33 9.3423332e-34], sampled 0.5886891437413931
[2019-03-22 23:16:58,096] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05358668], dtype=float32), 0.16995448]
[2019-03-22 23:16:58,099] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.5, 76.0, 1.0, 2.0, 0.5321121364491066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 648504.4763684667, 648504.4763684663, 148496.7846109266]
[2019-03-22 23:16:58,100] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:16:58,103] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.4788983e-37 7.1025637e-32 1.1577910e-32], sampled 0.4582185190899478
[2019-03-22 23:17:17,232] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05358668], dtype=float32), 0.16995448]
[2019-03-22 23:17:17,233] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.62309655166667, 59.98144514, 1.0, 2.0, 0.6956346228477598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 792824.109366317, 792824.109366317, 175321.8143336294]
[2019-03-22 23:17:17,236] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:17:17,239] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 3.1140170e-38 1.7436150e-32 1.7649146e-33], sampled 0.029304193225808906
[2019-03-22 23:17:29,364] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05358668], dtype=float32), 0.16995448]
[2019-03-22 23:17:29,487] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.84531932333333, 64.51218290333334, 1.0, 2.0, 0.3244005121079515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 409673.08895136, 409673.08895136, 118612.8456670451]
[2019-03-22 23:17:29,488] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:17:29,490] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 4.8303386e-38 9.6183635e-33 2.7097571e-33], sampled 0.42011900608052744
[2019-03-22 23:17:31,293] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05358668], dtype=float32), 0.16995448]
[2019-03-22 23:17:31,294] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.66666666666666, 79.83333333333333, 1.0, 2.0, 0.66548083181821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758440.4267257828, 758440.4267257828, 169713.8585576351]
[2019-03-22 23:17:31,296] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:17:31,298] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.6020274e-33 3.7200665e-34], sampled 0.1492747634044741
[2019-03-22 23:17:40,797] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-22 23:17:40,807] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-22 23:17:40,927] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-22 23:17:40,951] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-22 23:17:41,047] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-22 23:17:42,064] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 25000, evaluation results [25000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-22 23:17:42,712] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 8.0665969e-35 4.5042694e-34 4.8240139e-34], sum to 1.0000
[2019-03-22 23:17:42,722] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2100
[2019-03-22 23:17:42,728] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 50.66666666666666, 1.0, 2.0, 0.3155582554593788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 401685.9050461983, 401685.9050461983, 117515.3837797811], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 943800.0000, 
sim time next is 944400.0000, 
raw observation next is [23.9, 50.33333333333334, 1.0, 2.0, 0.3105440754145342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 395872.7629029261, 395872.7629029261, 116886.7774657219], 
processed observation next is [0.0, 0.9565217391304348, 0.4407407407407407, 0.5033333333333334, 1.0, 1.0, 0.179219137398255, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14138312960818789, 0.14138312960818789, 0.2247822643571575], 
reward next is 0.7752, 
noisyNet noise sample is [array([0.01914995], dtype=float32), 0.8176006]. 
=============================================
[2019-03-22 23:17:45,872] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1777192e-05 2.0998558e-01 1.1150832e-11 7.8998268e-01 1.3607355e-08], sum to 1.0000
[2019-03-22 23:17:45,881] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8701
[2019-03-22 23:17:45,887] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.4, 52.5, 1.0, 2.0, 0.9319877643940766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.277537834466557, 6.9112, 121.9244095997842, 1352311.035618621, 1164715.834056748, 228955.2333611739], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 999000.0000, 
sim time next is 999600.0000, 
raw observation next is [25.43333333333334, 52.33333333333333, 1.0, 2.0, 0.5109901687658591, 1.0, 1.0, 0.5109901687658591, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9258219866142, 1252512.440277405, 1252512.440277405, 242259.4103685364], 
processed observation next is [1.0, 0.5652173913043478, 0.4975308641975311, 0.5233333333333333, 1.0, 1.0, 0.41784543900697513, 1.0, 0.5, 0.41784543900697513, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094606640726979, 0.4473258715276447, 0.4473258715276447, 0.4658834814779546], 
reward next is 0.5341, 
noisyNet noise sample is [array([-0.78716975], dtype=float32), -1.4241605]. 
=============================================
[2019-03-22 23:17:49,160] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4771372e-32 1.0000000e+00 7.4948406e-35 6.5443552e-19 2.9735007e-24], sum to 1.0000
[2019-03-22 23:17:49,167] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3264
[2019-03-22 23:17:49,174] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.86666666666667, 58.0, 1.0, 2.0, 0.5073950354691001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 644773.0474337838, 644773.0474337838, 145025.0184797199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1066800.0000, 
sim time next is 1067400.0000, 
raw observation next is [22.95, 57.5, 1.0, 2.0, 0.582992669229168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740556.7014213348, 740556.7014213348, 157668.4962910326], 
processed observation next is [1.0, 0.34782608695652173, 0.4055555555555555, 0.575, 1.0, 1.0, 0.5035627014632953, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26448453622190526, 0.26448453622190526, 0.30320864671352427], 
reward next is 0.6968, 
noisyNet noise sample is [array([-1.149884], dtype=float32), -1.9926386]. 
=============================================
[2019-03-22 23:17:51,445] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5753227e-30 1.0000000e+00 1.2973132e-31 5.4608008e-19 1.4043505e-26], sum to 1.0000
[2019-03-22 23:17:51,455] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6938
[2019-03-22 23:17:51,571] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 55.5, 1.0, 2.0, 0.3372974182459268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 425629.8820564277, 425629.8820564277, 120271.1059797575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1103400.0000, 
sim time next is 1104000.0000, 
raw observation next is [23.8, 56.66666666666666, 1.0, 2.0, 0.3361432072150966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424338.2679815418, 424338.2679815418, 120123.0199096853], 
processed observation next is [1.0, 0.782608695652174, 0.43703703703703706, 0.5666666666666665, 1.0, 1.0, 0.20969429430368644, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1515493814219792, 0.1515493814219792, 0.2310058075186256], 
reward next is 0.7690, 
noisyNet noise sample is [array([0.12518995], dtype=float32), 0.6558057]. 
=============================================
[2019-03-22 23:17:51,599] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[55.391426]
 [55.213753]
 [54.778145]
 [54.789803]
 [54.751373]], R is [[55.6150322 ]
 [55.82759476]
 [56.03778839]
 [56.24593735]
 [56.45241547]].
[2019-03-22 23:17:54,918] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.5228152e-33 1.0000000e+00 6.1200374e-32 2.8109057e-18 2.3086080e-27], sum to 1.0000
[2019-03-22 23:17:54,926] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8023
[2019-03-22 23:17:54,931] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.53333333333333, 66.66666666666667, 1.0, 2.0, 0.5398338731661454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691632.0835058815, 691632.0835058815, 150345.0981167547], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1156800.0000, 
sim time next is 1157400.0000, 
raw observation next is [20.6, 66.5, 1.0, 2.0, 0.5397508969684752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 691292.0731469521, 691292.0731469516, 150331.4407642356], 
processed observation next is [1.0, 0.391304347826087, 0.3185185185185186, 0.665, 1.0, 1.0, 0.4520844011529467, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24689002612391145, 0.24689002612391128, 0.2890989245466069], 
reward next is 0.7109, 
noisyNet noise sample is [array([-2.047042], dtype=float32), 1.6193581]. 
=============================================
[2019-03-22 23:17:56,534] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31819: loss 0.0228
[2019-03-22 23:17:56,538] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31819: learning rate 0.0010
[2019-03-22 23:17:56,646] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31871: loss 0.2877
[2019-03-22 23:17:56,651] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 31873: learning rate 0.0010
[2019-03-22 23:17:56,682] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 31887: loss 0.4127
[2019-03-22 23:17:56,684] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 31887: learning rate 0.0010
[2019-03-22 23:17:56,719] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 31901: loss 0.2083
[2019-03-22 23:17:56,721] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 31901: learning rate 0.0010
[2019-03-22 23:17:56,746] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31911: loss 0.1956
[2019-03-22 23:17:56,747] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31912: learning rate 0.0010
[2019-03-22 23:17:56,858] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 31967: loss 0.0840
[2019-03-22 23:17:56,861] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 31968: learning rate 0.0010
[2019-03-22 23:17:56,863] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31969: loss 0.0707
[2019-03-22 23:17:56,865] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31970: learning rate 0.0010
[2019-03-22 23:17:56,902] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 31984: loss 0.0066
[2019-03-22 23:17:56,904] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 31984: learning rate 0.0010
[2019-03-22 23:17:56,956] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 32007: loss 0.0046
[2019-03-22 23:17:56,959] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 32009: learning rate 0.0010
[2019-03-22 23:17:56,979] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 32022: loss 0.0037
[2019-03-22 23:17:56,982] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 32024: learning rate 0.0010
[2019-03-22 23:17:56,987] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 32025: loss 0.0086
[2019-03-22 23:17:56,987] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 32025: loss 0.0071
[2019-03-22 23:17:56,990] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 32025: learning rate 0.0010
[2019-03-22 23:17:56,991] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 32026: learning rate 0.0010
[2019-03-22 23:17:57,020] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32042: loss 0.0677
[2019-03-22 23:17:57,022] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 32043: learning rate 0.0010
[2019-03-22 23:17:57,058] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 32057: loss 0.1375
[2019-03-22 23:17:57,059] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 32057: learning rate 0.0010
[2019-03-22 23:17:57,175] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 32114: loss 0.2163
[2019-03-22 23:17:57,179] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 32115: learning rate 0.0010
[2019-03-22 23:17:57,346] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 32190: loss 0.0126
[2019-03-22 23:17:57,347] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 32191: learning rate 0.0010
[2019-03-22 23:17:57,570] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.4948515e-38 8.1564442e-30 2.7398169e-33], sum to 1.0000
[2019-03-22 23:17:57,580] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7955
[2019-03-22 23:17:57,683] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.55, 94.00000000000001, 1.0, 2.0, 0.3404153296644923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 429795.7249121654, 429795.7249121654, 120680.3698541822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1210200.0000, 
sim time next is 1210800.0000, 
raw observation next is [18.5, 94.0, 1.0, 2.0, 0.3388871369528024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428115.8957466062, 428115.8957466062, 120483.7563998804], 
processed observation next is [1.0, 0.0, 0.24074074074074073, 0.94, 1.0, 1.0, 0.2129608773247648, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1528985341952165, 0.1528985341952165, 0.23169953153823153], 
reward next is 0.7683, 
noisyNet noise sample is [array([-0.49002925], dtype=float32), -1.175441]. 
=============================================
[2019-03-22 23:17:59,423] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4851985e-34 1.0000000e+00 4.0903411e-34 1.3077279e-23 1.2973201e-28], sum to 1.0000
[2019-03-22 23:17:59,433] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5758
[2019-03-22 23:17:59,437] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 79.83333333333333, 1.0, 2.0, 0.7094311881356203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 892798.8648029665, 892798.8648029665, 180997.4508746515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1242600.0000, 
sim time next is 1243200.0000, 
raw observation next is [20.7, 78.66666666666667, 1.0, 2.0, 0.6267874899171222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 788290.6235061765, 788290.6235061765, 165368.7629141376], 
processed observation next is [1.0, 0.391304347826087, 0.3222222222222222, 0.7866666666666667, 1.0, 1.0, 0.5556993927584788, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28153236553792016, 0.28153236553792016, 0.3180168517579569], 
reward next is 0.6820, 
noisyNet noise sample is [array([-0.00143037], dtype=float32), 0.04034261]. 
=============================================
[2019-03-22 23:18:00,395] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.33370065e-35 1.00000000e+00 8.72615066e-38 1.07428005e-24
 7.49697148e-31], sum to 1.0000
[2019-03-22 23:18:00,403] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9059
[2019-03-22 23:18:00,409] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.45, 59.5, 1.0, 2.0, 0.772467980965938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 950788.594820052, 950788.5948200516, 193253.9840431349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1258200.0000, 
sim time next is 1258800.0000, 
raw observation next is [25.63333333333333, 59.0, 1.0, 2.0, 0.8955258088455921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.932903453313346, 6.9112, 121.9259655174369, 1111882.399962135, 1100768.299060907, 220000.3828075718], 
processed observation next is [1.0, 0.5652173913043478, 0.5049382716049381, 0.59, 1.0, 1.0, 0.8756259629114191, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0021703453313345555, 0.0, 0.809461616968099, 0.3971008571293339, 0.39313153537889534, 0.42307765924533036], 
reward next is 0.4684, 
noisyNet noise sample is [array([2.089887], dtype=float32), -1.0885903]. 
=============================================
[2019-03-22 23:18:04,291] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.03797095e-34 1.00000000e+00 1.39968463e-29 1.92833895e-21
 1.27879275e-26], sum to 1.0000
[2019-03-22 23:18:04,300] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0028
[2019-03-22 23:18:04,305] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 69.0, 1.0, 2.0, 0.6920993785692447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 857696.0909672761, 857696.0909672761, 177357.1961154197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1326600.0000, 
sim time next is 1327200.0000, 
raw observation next is [23.56666666666667, 67.0, 1.0, 2.0, 0.6332658917267273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 785193.8662210786, 785193.8662210786, 166330.889950004], 
processed observation next is [1.0, 0.34782608695652173, 0.4283950617283952, 0.67, 1.0, 1.0, 0.5634117758651516, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28042638079324234, 0.28042638079324234, 0.3198670960577], 
reward next is 0.6801, 
noisyNet noise sample is [array([-1.0242294], dtype=float32), 0.17051929]. 
=============================================
[2019-03-22 23:18:06,820] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 8.8455193e-33 7.1025945e-31], sum to 1.0000
[2019-03-22 23:18:06,829] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9977
[2019-03-22 23:18:06,927] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 67.0, 1.0, 2.0, 0.3135996714947867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 399236.7643035961, 399236.7643035961, 117268.5953055231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1388400.0000, 
sim time next is 1389000.0000, 
raw observation next is [21.18333333333334, 67.0, 1.0, 2.0, 0.31087256059901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396080.9093634709, 396080.9093634709, 116927.1945497177], 
processed observation next is [0.0, 0.043478260869565216, 0.34012345679012373, 0.67, 1.0, 1.0, 0.17961019118929758, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14145746762981104, 0.14145746762981104, 0.22485998951868788], 
reward next is 0.7751, 
noisyNet noise sample is [array([-0.49067697], dtype=float32), 0.36779156]. 
=============================================
[2019-03-22 23:18:06,942] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[79.556496]
 [79.83246 ]
 [80.248116]
 [80.69938 ]
 [81.2832  ]], R is [[79.3920517 ]
 [79.372612  ]
 [79.35280609]
 [79.33263397]
 [79.31208038]].
[2019-03-22 23:18:13,355] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39835: loss 0.0289
[2019-03-22 23:18:13,356] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39835: learning rate 0.0010
[2019-03-22 23:18:13,385] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39851: loss 0.0022
[2019-03-22 23:18:13,387] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 39851: learning rate 0.0010
[2019-03-22 23:18:13,444] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 39874: loss 0.0022
[2019-03-22 23:18:13,451] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39875: loss 0.0001
[2019-03-22 23:18:13,451] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 39875: learning rate 0.0010
[2019-03-22 23:18:13,453] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39875: learning rate 0.0010
[2019-03-22 23:18:13,495] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39894: loss 0.0068
[2019-03-22 23:18:13,498] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 39894: learning rate 0.0010
[2019-03-22 23:18:13,646] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 39962: loss 0.0248
[2019-03-22 23:18:13,648] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 39963: learning rate 0.0010
[2019-03-22 23:18:13,664] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39967: loss 0.0082
[2019-03-22 23:18:13,666] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39967: learning rate 0.0010
[2019-03-22 23:18:13,712] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 39990: loss 0.0068
[2019-03-22 23:18:13,714] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 39990: learning rate 0.0010
[2019-03-22 23:18:13,755] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 40015: loss 0.0002
[2019-03-22 23:18:13,759] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 40017: learning rate 0.0010
[2019-03-22 23:18:13,768] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 40025: loss 0.0024
[2019-03-22 23:18:13,769] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 40025: learning rate 0.0010
[2019-03-22 23:18:13,776] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 40029: loss 0.0016
[2019-03-22 23:18:13,780] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 40031: learning rate 0.0010
[2019-03-22 23:18:13,789] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 40035: loss 0.0281
[2019-03-22 23:18:13,792] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 40035: learning rate 0.0010
[2019-03-22 23:18:13,909] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 40089: loss 0.0745
[2019-03-22 23:18:13,911] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 40090: learning rate 0.0010
[2019-03-22 23:18:13,958] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 40111: loss 0.0914
[2019-03-22 23:18:13,965] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 40113: learning rate 0.0010
[2019-03-22 23:18:13,988] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 40121: loss 0.1131
[2019-03-22 23:18:13,992] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 40123: learning rate 0.0010
[2019-03-22 23:18:14,104] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 40171: loss 0.0002
[2019-03-22 23:18:14,109] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 40176: learning rate 0.0010
[2019-03-22 23:18:18,848] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4251904e-30 1.0000000e+00 4.9833418e-25 1.5909201e-17 6.8270579e-24], sum to 1.0000
[2019-03-22 23:18:18,856] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6459
[2019-03-22 23:18:18,862] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.41666666666666, 56.83333333333333, 1.0, 2.0, 0.903747372332612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.100682974307579, 6.9112, 121.9252580994238, 1228931.445787422, 1131899.851486251, 222420.2483603908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1588200.0000, 
sim time next is 1588800.0000, 
raw observation next is [24.53333333333333, 56.66666666666667, 1.0, 2.0, 0.9283891748720788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.26086351454961, 6.9112, 121.9244223533735, 1340678.678472953, 1161622.085949005, 228137.9952638324], 
processed observation next is [1.0, 0.391304347826087, 0.46419753086419746, 0.5666666666666668, 1.0, 1.0, 0.9147490177048557, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.034966351454960964, 0.0, 0.8094513719634957, 0.4788138137403403, 0.4148650306960732, 0.43872691396890845], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.0152016], dtype=float32), 0.45435032]. 
=============================================
[2019-03-22 23:18:25,330] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.9679196e-26 2.9846475e-10 2.0510462e-29 1.0000000e+00 1.3707670e-19], sum to 1.0000
[2019-03-22 23:18:25,344] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2852
[2019-03-22 23:18:25,353] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.1, 69.0, 1.0, 2.0, 0.3946670270315484, 1.0, 2.0, 0.3946670270315484, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 966567.9933523152, 966567.9933523147, 207364.4613690676], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1692000.0000, 
sim time next is 1692600.0000, 
raw observation next is [23.15, 69.0, 1.0, 2.0, 0.4426843350270827, 1.0, 2.0, 0.4426843350270827, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1082083.92529159, 1082083.92529159, 221115.9316356316], 
processed observation next is [1.0, 0.6086956521739131, 0.4129629629629629, 0.69, 1.0, 1.0, 0.3365289702703365, 1.0, 1.0, 0.3365289702703365, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3864585447469964, 0.3864585447469964, 0.4252229454531377], 
reward next is 0.5748, 
noisyNet noise sample is [array([-0.96953297], dtype=float32), -0.6327698]. 
=============================================
[2019-03-22 23:18:29,932] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7416684e-21 2.0228472e-05 9.7339608e-25 9.9997973e-01 1.0421186e-13], sum to 1.0000
[2019-03-22 23:18:29,940] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9824
[2019-03-22 23:18:29,948] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.2, 66.33333333333334, 1.0, 2.0, 0.4685678344223592, 1.0, 2.0, 0.4685678344223592, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1115342.965401036, 1115342.965401036, 227887.3213255785], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1772400.0000, 
sim time next is 1773000.0000, 
raw observation next is [25.25, 66.0, 1.0, 2.0, 0.4336651969018376, 1.0, 2.0, 0.4336651969018376, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1034861.060321599, 1034861.060321599, 217626.9274961613], 
processed observation next is [1.0, 0.5217391304347826, 0.49074074074074076, 0.66, 1.0, 1.0, 0.32579190107361616, 1.0, 1.0, 0.32579190107361616, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3695932358291425, 0.3695932358291425, 0.4185133221080025], 
reward next is 0.5815, 
noisyNet noise sample is [array([0.4557253], dtype=float32), 0.7852418]. 
=============================================
[2019-03-22 23:18:29,963] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[51.943676]
 [51.898705]
 [51.99476 ]
 [52.015884]
 [52.043785]], R is [[52.02357864]
 [52.06509781]
 [52.03128052]
 [52.03636551]
 [52.03760529]].
[2019-03-22 23:18:30,824] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47842: loss 0.9731
[2019-03-22 23:18:30,826] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47842: learning rate 0.0010
[2019-03-22 23:18:30,827] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 47843: loss 0.7942
[2019-03-22 23:18:30,829] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 47843: learning rate 0.0010
[2019-03-22 23:18:30,866] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 47859: loss 1.2181
[2019-03-22 23:18:30,871] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 47860: learning rate 0.0010
[2019-03-22 23:18:30,956] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 47901: loss 1.3929
[2019-03-22 23:18:30,958] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 47901: learning rate 0.0010
[2019-03-22 23:18:31,050] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 47944: loss -1.5060
[2019-03-22 23:18:31,056] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 47944: learning rate 0.0010
[2019-03-22 23:18:31,085] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 47961: loss 1.5347
[2019-03-22 23:18:31,090] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 47962: learning rate 0.0010
[2019-03-22 23:18:31,090] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47962: loss 1.6994
[2019-03-22 23:18:31,096] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 47962: learning rate 0.0010
[2019-03-22 23:18:31,096] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 47962: loss 1.6354
[2019-03-22 23:18:31,102] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 47965: learning rate 0.0010
[2019-03-22 23:18:31,111] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 47969: loss 2.2833
[2019-03-22 23:18:31,114] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 47969: learning rate 0.0010
[2019-03-22 23:18:31,115] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 47969: loss 1.9511
[2019-03-22 23:18:31,121] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 47970: learning rate 0.0010
[2019-03-22 23:18:31,234] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 48026: loss 1.6402
[2019-03-22 23:18:31,238] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 48026: learning rate 0.0010
[2019-03-22 23:18:31,337] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 48069: loss 0.8927
[2019-03-22 23:18:31,340] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 48069: learning rate 0.0010
[2019-03-22 23:18:31,367] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 48085: loss 0.3104
[2019-03-22 23:18:31,369] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 48085: learning rate 0.0010
[2019-03-22 23:18:31,458] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 48127: loss 0.3333
[2019-03-22 23:18:31,462] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 48127: learning rate 0.0010
[2019-03-22 23:18:31,508] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 48148: loss 0.4436
[2019-03-22 23:18:31,512] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 48148: learning rate 0.0010
[2019-03-22 23:18:31,519] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 48151: loss 0.4533
[2019-03-22 23:18:31,522] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 48151: learning rate 0.0010
[2019-03-22 23:18:31,660] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.8387693e-22 4.9490208e-15 4.8347027e-25 1.0000000e+00 4.6744604e-16], sum to 1.0000
[2019-03-22 23:18:31,673] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3382
[2019-03-22 23:18:31,681] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.5, 86.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 393388.49851155, 393388.4985115504, 150010.5213915214], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1805400.0000, 
sim time next is 1806000.0000, 
raw observation next is [18.53333333333333, 86.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 397169.929215304, 397169.9292153044, 150605.6971425651], 
processed observation next is [1.0, 0.9130434782608695, 0.24197530864197525, 0.8666666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14184640329117998, 0.14184640329118015, 0.289626340658779], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3197145], dtype=float32), 2.2040234]. 
=============================================
[2019-03-22 23:18:31,690] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[40.146477]
 [40.12988 ]
 [39.910225]
 [39.72057 ]
 [39.595913]], R is [[39.71141815]
 [39.31430435]
 [38.92116165]
 [38.5319519 ]
 [38.14663315]].
[2019-03-22 23:18:35,542] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-22 23:18:35,543] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:18:35,545] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:35,546] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:18:35,547] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:35,552] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:18:35,552] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:18:35,553] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:35,553] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:35,554] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:18:35,557] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:18:35,568] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run3
[2019-03-22 23:18:35,587] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run3
[2019-03-22 23:18:35,588] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run3
[2019-03-22 23:18:35,589] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run3
[2019-03-22 23:18:35,643] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run3
[2019-03-22 23:18:36,998] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.14570631], dtype=float32), 0.23823021]
[2019-03-22 23:18:36,999] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.91666666666667, 38.16666666666666, 1.0, 2.0, 0.3649147398759075, 1.0, 2.0, 0.3649147398759075, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 897914.8041308036, 897914.804130804, 199332.1281564926]
[2019-03-22 23:18:37,001] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:18:37,003] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.4020470e-25 3.6136669e-08 4.3039520e-30 1.0000000e+00 1.1027948e-21], sampled 0.9677408881179752
[2019-03-22 23:19:34,874] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.14570631], dtype=float32), 0.23823021]
[2019-03-22 23:19:34,876] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.90583530666667, 71.94529380333333, 1.0, 2.0, 0.3595616961086238, 1.0, 2.0, 0.3595616961086238, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 819608.8880149823, 819608.8880149828, 195368.6346700416]
[2019-03-22 23:19:34,878] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:19:34,881] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.0836035e-25 2.1806210e-07 8.7224562e-30 9.9999976e-01 2.4577885e-21], sampled 0.11733525923887134
[2019-03-22 23:19:58,664] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.14570631], dtype=float32), 0.23823021]
[2019-03-22 23:19:58,665] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.33895276, 93.88966104, 1.0, 2.0, 0.3161986551612198, 1.0, 2.0, 0.3161986551612198, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 720717.8133310755, 720717.813331076, 184394.0743992777]
[2019-03-22 23:19:58,667] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:19:58,669] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.0671263e-26 9.8242005e-08 4.4699077e-30 9.9999988e-01 1.7078594e-21], sampled 0.40528362059557044
[2019-03-22 23:20:28,289] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6906.7263 2495408102.1756 47.0000
[2019-03-22 23:20:28,435] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.3485 2410652606.9095 22.0000
[2019-03-22 23:20:28,436] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.0885 2668495691.4595 68.0000
[2019-03-22 23:20:28,437] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7124.7550 2438729605.8140 34.0000
[2019-03-22 23:20:28,683] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7480.0274 2465856778.9468 46.0000
[2019-03-22 23:20:29,698] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 50000, evaluation results [50000.0, 7523.088492180975, 2668495691.4594846, 68.0, 7124.754987767942, 2438729605.814016, 34.0, 7798.348511531635, 2410652606.9095383, 22.0, 6906.726251003709, 2495408102.175574, 47.0, 7480.027397713166, 2465856778.946759, 46.0]
[2019-03-22 23:20:30,244] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2956634e-27 3.5484307e-09 5.8845435e-34 1.0000000e+00 3.1366710e-22], sum to 1.0000
[2019-03-22 23:20:30,253] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5019
[2019-03-22 23:20:30,261] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.25, 89.5, 1.0, 2.0, 0.2159443136001509, 1.0, 2.0, 0.2159443136001509, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 525022.0943225225, 525022.094322523, 163014.6894513922], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1881000.0000, 
sim time next is 1881600.0000, 
raw observation next is [21.23333333333333, 89.66666666666667, 1.0, 2.0, 0.2153569133300619, 1.0, 2.0, 0.2153569133300619, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 523570.164489428, 523570.1644894284, 162887.4170799891], 
processed observation next is [1.0, 0.782608695652174, 0.34197530864197523, 0.8966666666666667, 1.0, 1.0, 0.06590108729769274, 1.0, 1.0, 0.06590108729769274, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18698934446051, 0.18698934446051013, 0.31324503284613286], 
reward next is 0.6868, 
noisyNet noise sample is [array([0.73292965], dtype=float32), 1.0452093]. 
=============================================
[2019-03-22 23:20:30,446] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8360785e-28 1.4914971e-07 1.1283581e-34 9.9999988e-01 1.4591938e-22], sum to 1.0000
[2019-03-22 23:20:30,452] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9190
[2019-03-22 23:20:30,459] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 91.0, 1.0, 2.0, 0.2142314060169483, 1.0, 2.0, 0.2142314060169483, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 521412.1813828414, 521412.1813828419, 162665.4565919137], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1890000.0000, 
sim time next is 1890600.0000, 
raw observation next is [20.98333333333333, 91.00000000000001, 1.0, 2.0, 0.2136171878791155, 1.0, 2.0, 0.2136171878791155, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 520020.187976591, 520020.1879765915, 162537.104803295], 
processed observation next is [1.0, 0.9130434782608695, 0.33271604938271593, 0.9100000000000001, 1.0, 1.0, 0.06382998557037559, 1.0, 1.0, 0.06382998557037559, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18572149570592536, 0.18572149570592555, 0.31257135539095193], 
reward next is 0.6874, 
noisyNet noise sample is [array([-0.00281779], dtype=float32), -1.0279388]. 
=============================================
[2019-03-22 23:20:30,744] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2907724e-23 8.3120985e-06 9.2890105e-29 9.9999166e-01 1.7031749e-20], sum to 1.0000
[2019-03-22 23:20:30,755] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8521
[2019-03-22 23:20:30,759] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.91666666666667, 91.0, 1.0, 2.0, 0.2101530686924334, 1.0, 2.0, 0.2101530686924334, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 512174.6824490359, 512174.6824490363, 161815.8747386547], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1893000.0000, 
sim time next is 1893600.0000, 
raw observation next is [20.9, 91.0, 1.0, 2.0, 0.2100657427224897, 1.0, 2.0, 0.2100657427224897, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 512096.7450176506, 512096.7450176506, 161801.8118731399], 
processed observation next is [1.0, 0.9565217391304348, 0.32962962962962955, 0.91, 1.0, 1.0, 0.0596020746696306, 1.0, 1.0, 0.0596020746696306, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18289169464916094, 0.18289169464916094, 0.31115733052526906], 
reward next is 0.6888, 
noisyNet noise sample is [array([0.8891461], dtype=float32), -0.7171309]. 
=============================================
[2019-03-22 23:20:31,775] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.9372685e-25 9.9321020e-12 2.0362143e-33 1.0000000e+00 1.9825550e-24], sum to 1.0000
[2019-03-22 23:20:31,784] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6759
[2019-03-22 23:20:31,790] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.83333333333334, 92.0, 1.0, 2.0, 0.1900364062897713, 1.0, 2.0, 0.1900364062897713, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 469865.1844885262, 469865.1844885266, 157807.6909078447], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1905600.0000, 
sim time next is 1906200.0000, 
raw observation next is [19.75, 92.0, 1.0, 2.0, 0.1881379694966745, 1.0, 2.0, 0.1881379694966745, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 465733.5999808246, 465733.5999808246, 157430.3458290898], 
processed observation next is [1.0, 0.043478260869565216, 0.28703703703703703, 0.92, 1.0, 1.0, 0.0334975827341363, 1.0, 1.0, 0.0334975827341363, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16633342856458022, 0.16633342856458022, 0.30275066505594195], 
reward next is 0.6972, 
noisyNet noise sample is [array([-0.9856221], dtype=float32), -0.16778976]. 
=============================================
[2019-03-22 23:20:32,660] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6639595e-28 7.9292029e-08 2.7039241e-32 9.9999988e-01 4.3898789e-22], sum to 1.0000
[2019-03-22 23:20:32,672] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4162
[2019-03-22 23:20:32,781] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.85, 89.5, 1.0, 2.0, 0.3514659191356853, 1.0, 2.0, 0.3514659191356853, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 856109.9264352283, 856109.9264352288, 195500.3424084815], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1931400.0000, 
sim time next is 1932000.0000, 
raw observation next is [20.96666666666667, 89.33333333333333, 1.0, 2.0, 0.3646473706686884, 1.0, 2.0, 0.3646473706686884, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 886016.5895010707, 886016.5895010711, 198935.8514717846], 
processed observation next is [1.0, 0.34782608695652173, 0.3320987654320988, 0.8933333333333333, 1.0, 1.0, 0.24362782222462906, 1.0, 1.0, 0.24362782222462906, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3164344962503824, 0.31643449625038256, 0.38256894513804734], 
reward next is 0.6174, 
noisyNet noise sample is [array([-0.60498345], dtype=float32), -0.1648729]. 
=============================================
[2019-03-22 23:20:32,793] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[66.48695 ]
 [66.500496]
 [66.57892 ]
 [66.58089 ]
 [66.57011 ]], R is [[66.44394684]
 [66.40354919]
 [66.38262939]
 [66.40390015]
 [66.42752075]].
[2019-03-22 23:20:34,016] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3958011e-19 5.2245524e-24 8.3683186e-33 1.0000000e+00 2.9999462e-23], sum to 1.0000
[2019-03-22 23:20:34,025] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4244
[2019-03-22 23:20:34,029] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.5, 61.5, 1.0, 2.0, 0.6316139326592664, 1.0, 2.0, 0.6316139326592664, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1464593.500375723, 1464593.500375723, 280269.3178731541], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1953000.0000, 
sim time next is 1953600.0000, 
raw observation next is [27.6, 61.33333333333333, 1.0, 2.0, 0.6422631200473412, 1.0, 2.0, 0.6422631200473412, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1486756.433753403, 1486756.433753403, 283971.7767276752], 
processed observation next is [1.0, 0.6086956521739131, 0.5777777777777778, 0.6133333333333333, 1.0, 1.0, 0.5741227619611204, 1.0, 1.0, 0.5741227619611204, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5309844406262153, 0.5309844406262153, 0.5460995706301447], 
reward next is 0.4539, 
noisyNet noise sample is [array([-1.9216058], dtype=float32), -0.26800555]. 
=============================================
[2019-03-22 23:20:42,015] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55821: loss 0.0172
[2019-03-22 23:20:42,018] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 55821: learning rate 0.0010
[2019-03-22 23:20:42,061] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 55842: loss 0.0045
[2019-03-22 23:20:42,063] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 55842: learning rate 0.0010
[2019-03-22 23:20:42,089] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8514617e-28 3.0746822e-11 1.7957409e-32 1.0000000e+00 3.2115539e-24], sum to 1.0000
[2019-03-22 23:20:42,099] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7664
[2019-03-22 23:20:42,107] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.33333333333334, 91.66666666666667, 1.0, 2.0, 0.2189668212492716, 1.0, 2.0, 0.2189668212492716, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 529610.2540899122, 529610.2540899125, 163569.1535350121], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2095800.0000, 
sim time next is 2096400.0000, 
raw observation next is [21.46666666666667, 91.33333333333334, 1.0, 2.0, 0.2209491103056517, 1.0, 2.0, 0.2209491103056517, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 533580.4494893445, 533580.449489345, 163967.9962461549], 
processed observation next is [0.0, 0.2608695652173913, 0.35061728395061736, 0.9133333333333334, 1.0, 1.0, 0.07255846464958536, 1.0, 1.0, 0.07255846464958536, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19056444624619445, 0.19056444624619462, 0.31532306970414403], 
reward next is 0.6847, 
noisyNet noise sample is [array([0.56517655], dtype=float32), -0.561756]. 
=============================================
[2019-03-22 23:20:42,113] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 55869: loss 0.0001
[2019-03-22 23:20:42,116] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 55869: learning rate 0.0010
[2019-03-22 23:20:42,131] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 55874: loss 0.0001
[2019-03-22 23:20:42,135] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 55874: learning rate 0.0010
[2019-03-22 23:20:42,165] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 55890: loss 0.0256
[2019-03-22 23:20:42,172] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 55893: learning rate 0.0010
[2019-03-22 23:20:42,222] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 55917: loss 0.0945
[2019-03-22 23:20:42,224] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 55917: learning rate 0.0010
[2019-03-22 23:20:42,261] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 55933: loss 0.0719
[2019-03-22 23:20:42,263] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 55934: learning rate 0.0010
[2019-03-22 23:20:42,320] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 55963: loss 0.0079
[2019-03-22 23:20:42,325] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 55964: learning rate 0.0010
[2019-03-22 23:20:42,358] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 55980: loss 0.0103
[2019-03-22 23:20:42,360] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 55980: learning rate 0.0010
[2019-03-22 23:20:42,400] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55999: loss 0.0016
[2019-03-22 23:20:42,402] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 56000: learning rate 0.0010
[2019-03-22 23:20:42,527] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 56059: loss 0.0707
[2019-03-22 23:20:42,531] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 56059: learning rate 0.0010
[2019-03-22 23:20:42,547] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 56068: loss 0.1014
[2019-03-22 23:20:42,550] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 56069: learning rate 0.0010
[2019-03-22 23:20:42,633] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 56109: loss 0.0171
[2019-03-22 23:20:42,635] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 56109: learning rate 0.0010
[2019-03-22 23:20:42,639] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 56111: loss 0.0137
[2019-03-22 23:20:42,641] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 56111: learning rate 0.0010
[2019-03-22 23:20:42,738] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 56157: loss 0.0015
[2019-03-22 23:20:42,739] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 56157: learning rate 0.0010
[2019-03-22 23:20:42,830] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 56199: loss 0.0722
[2019-03-22 23:20:42,832] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 56199: learning rate 0.0010
[2019-03-22 23:20:45,950] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3222462e-36 5.6299621e-13 5.1019476e-32 1.0000000e+00 3.1836574e-24], sum to 1.0000
[2019-03-22 23:20:45,961] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1217
[2019-03-22 23:20:45,966] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.53333333333333, 80.0, 1.0, 2.0, 0.2891310735618507, 1.0, 2.0, 0.2891310735618507, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 664968.2585509312, 664968.2585509316, 178170.4710156432], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2157600.0000, 
sim time next is 2158200.0000, 
raw observation next is [25.45, 80.5, 1.0, 2.0, 0.2886471067152093, 1.0, 2.0, 0.2886471067152093, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 663989.3012820509, 663989.3012820514, 178062.3624389384], 
processed observation next is [0.0, 1.0, 0.4981481481481481, 0.805, 1.0, 1.0, 0.15315131751810634, 1.0, 1.0, 0.15315131751810634, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23713903617216103, 0.2371390361721612, 0.34242762007488153], 
reward next is 0.6576, 
noisyNet noise sample is [array([0.4304077], dtype=float32), 1.2267289]. 
=============================================
[2019-03-22 23:20:47,250] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.2261886e-31 7.2544271e-10 6.8003539e-27 1.0000000e+00 1.0358840e-23], sum to 1.0000
[2019-03-22 23:20:47,256] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3263
[2019-03-22 23:20:47,258] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.5, 88.0, 1.0, 2.0, 0.3186119314571592, 1.0, 2.0, 0.3186119314571592, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 730225.2175244257, 730225.2175244262, 185184.2673394241], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2188800.0000, 
sim time next is 2189400.0000, 
raw observation next is [24.48333333333333, 88.33333333333334, 1.0, 2.0, 0.3486215119432878, 1.0, 2.0, 0.3486215119432878, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 798308.9286987892, 798308.9286987897, 192715.5933336182], 
processed observation next is [1.0, 0.34782608695652173, 0.4623456790123456, 0.8833333333333334, 1.0, 1.0, 0.2245494189801045, 1.0, 1.0, 0.2245494189801045, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.285110331678139, 0.28511033167813915, 0.3706069102569581], 
reward next is 0.6294, 
noisyNet noise sample is [array([1.6158437], dtype=float32), 0.107292034]. 
=============================================
[2019-03-22 23:20:48,905] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.9041310e-27 2.1159557e-10 4.9640612e-34 1.0000000e+00 5.6310239e-21], sum to 1.0000
[2019-03-22 23:20:48,908] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0610
[2019-03-22 23:20:48,913] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.26666666666667, 95.33333333333333, 1.0, 2.0, 0.2796617689256577, 1.0, 2.0, 0.2796617689256577, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 645632.2590537091, 645632.2590537091, 176060.8384324051], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2223600.0000, 
sim time next is 2224200.0000, 
raw observation next is [23.23333333333333, 95.16666666666667, 1.0, 2.0, 0.2793072302994542, 1.0, 2.0, 0.2793072302994542, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 645551.7981856023, 645551.7981856028, 176013.3007287131], 
processed observation next is [1.0, 0.7391304347826086, 0.4160493827160493, 0.9516666666666667, 1.0, 1.0, 0.14203241702315977, 1.0, 1.0, 0.14203241702315977, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2305542136377151, 0.23055421363771528, 0.33848711678598675], 
reward next is 0.6615, 
noisyNet noise sample is [array([-0.7163841], dtype=float32), 0.032560073]. 
=============================================
[2019-03-22 23:20:50,139] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.6880118e-33 2.7692835e-12 2.4466666e-36 1.0000000e+00 8.7279688e-26], sum to 1.0000
[2019-03-22 23:20:50,149] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5513
[2019-03-22 23:20:50,154] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.9, 98.0, 1.0, 2.0, 0.2818196103246597, 1.0, 2.0, 0.2818196103246597, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651388.7103881632, 651388.7103881632, 176603.6900115981], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2248200.0000, 
sim time next is 2248800.0000, 
raw observation next is [22.93333333333333, 98.0, 1.0, 2.0, 0.2825660166540974, 1.0, 2.0, 0.2825660166540974, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 652647.4863142942, 652647.4863142946, 176756.7966184336], 
processed observation next is [1.0, 0.0, 0.40493827160493817, 0.98, 1.0, 1.0, 0.1459119245882112, 1.0, 1.0, 0.1459119245882112, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23308838796939077, 0.23308838796939094, 0.33991691657391077], 
reward next is 0.6601, 
noisyNet noise sample is [array([0.5582692], dtype=float32), 0.26416454]. 
=============================================
[2019-03-22 23:20:51,372] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.3661078e-34 7.8982142e-12 5.0214703e-32 1.0000000e+00 5.2430753e-26], sum to 1.0000
[2019-03-22 23:20:51,381] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6276
[2019-03-22 23:20:51,478] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.85, 96.0, 1.0, 2.0, 0.2238060689650283, 1.0, 2.0, 0.2238060689650283, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 540182.4311331592, 540182.4311331596, 164577.6257431853], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2262600.0000, 
sim time next is 2263200.0000, 
raw observation next is [20.7, 95.66666666666666, 1.0, 2.0, 0.2201127467791671, 1.0, 2.0, 0.2201127467791671, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 532996.593774164, 532996.5937741643, 163839.326782073], 
processed observation next is [1.0, 0.17391304347826086, 0.3222222222222222, 0.9566666666666666, 1.0, 1.0, 0.07156279378472273, 1.0, 1.0, 0.07156279378472273, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1903559263479157, 0.19035592634791584, 0.3150756284270635], 
reward next is 0.6849, 
noisyNet noise sample is [array([-1.2535782], dtype=float32), 0.91943526]. 
=============================================
[2019-03-22 23:20:52,795] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8106512e-28 1.3774264e-08 6.8350872e-23 1.0000000e+00 4.1310066e-24], sum to 1.0000
[2019-03-22 23:20:52,801] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7102
[2019-03-22 23:20:52,806] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.73333333333333, 89.66666666666667, 1.0, 2.0, 0.5417898423245859, 1.0, 2.0, 0.5417898423245859, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1269823.531148937, 1269823.531148937, 250203.4550486878], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2283600.0000, 
sim time next is 2284200.0000, 
raw observation next is [22.9, 89.0, 1.0, 2.0, 0.5413828253049539, 1.0, 2.0, 0.5413828253049539, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1266816.36142212, 1266816.361422121, 249982.1303693714], 
processed observation next is [1.0, 0.43478260869565216, 0.4037037037037037, 0.89, 1.0, 1.0, 0.4540271729820879, 1.0, 1.0, 0.4540271729820879, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.45243441479361424, 0.4524344147936147, 0.48073486609494503], 
reward next is 0.5193, 
noisyNet noise sample is [array([-1.080435], dtype=float32), -0.27481267]. 
=============================================
[2019-03-22 23:20:53,345] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.4210646e-32 1.0977674e-12 2.4137513e-33 1.0000000e+00 1.0968111e-23], sum to 1.0000
[2019-03-22 23:20:53,356] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6860
[2019-03-22 23:20:53,361] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.40000000000001, 77.33333333333334, 1.0, 2.0, 0.5400960306956444, 1.0, 2.0, 0.5400960306956444, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1242982.720894617, 1242982.720894618, 248618.6024392357], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2298000.0000, 
sim time next is 2298600.0000, 
raw observation next is [25.45, 76.5, 1.0, 2.0, 0.5345984593583073, 1.0, 2.0, 0.5345984593583073, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1232592.503803483, 1232592.503803483, 246947.9378782424], 
processed observation next is [1.0, 0.6086956521739131, 0.4981481481481481, 0.765, 1.0, 1.0, 0.4459505468551277, 1.0, 1.0, 0.4459505468551277, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4402116085012439, 0.4402116085012439, 0.47489988053508153], 
reward next is 0.5251, 
noisyNet noise sample is [array([0.87765497], dtype=float32), -0.7131352]. 
=============================================
[2019-03-22 23:20:58,795] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63783: loss 1.6633
[2019-03-22 23:20:58,797] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63783: learning rate 0.0010
[2019-03-22 23:20:58,959] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 63863: loss 0.6370
[2019-03-22 23:20:58,961] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 63863: learning rate 0.0010
[2019-03-22 23:20:58,963] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 63864: loss 0.8878
[2019-03-22 23:20:58,965] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 63864: learning rate 0.0010
[2019-03-22 23:20:58,977] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 63870: loss 0.5402
[2019-03-22 23:20:58,980] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 63870: learning rate 0.0010
[2019-03-22 23:20:59,063] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 63905: loss 0.0690
[2019-03-22 23:20:59,068] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 63906: learning rate 0.0010
[2019-03-22 23:20:59,105] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 63929: loss 0.0125
[2019-03-22 23:20:59,110] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 63929: learning rate 0.0010
[2019-03-22 23:20:59,173] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63955: loss 0.0626
[2019-03-22 23:20:59,174] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63955: learning rate 0.0010
[2019-03-22 23:20:59,198] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 63964: loss 0.0051
[2019-03-22 23:20:59,198] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 63964: learning rate 0.0010
[2019-03-22 23:20:59,267] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 64000: loss 0.0026
[2019-03-22 23:20:59,270] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 64000: learning rate 0.0010
[2019-03-22 23:20:59,329] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 64029: loss 0.0192
[2019-03-22 23:20:59,331] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 64029: learning rate 0.0010
[2019-03-22 23:20:59,364] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 64041: loss 0.0218
[2019-03-22 23:20:59,367] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 64041: learning rate 0.0010
[2019-03-22 23:20:59,484] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 64098: loss 0.0138
[2019-03-22 23:20:59,488] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 64099: loss 0.0537
[2019-03-22 23:20:59,488] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 64099: learning rate 0.0010
[2019-03-22 23:20:59,491] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 64101: learning rate 0.0010
[2019-03-22 23:20:59,534] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 64117: loss 0.0100
[2019-03-22 23:20:59,537] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 64117: learning rate 0.0010
[2019-03-22 23:20:59,540] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 64118: loss 0.0135
[2019-03-22 23:20:59,544] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 64120: learning rate 0.0010
[2019-03-22 23:20:59,678] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 64185: loss 0.1138
[2019-03-22 23:20:59,680] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 64185: learning rate 0.0010
[2019-03-22 23:21:01,870] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3231444e-21 9.9999619e-01 7.0831134e-16 3.7899304e-06 1.2956551e-18], sum to 1.0000
[2019-03-22 23:21:01,875] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7282
[2019-03-22 23:21:01,883] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.06666666666667, 62.83333333333334, 1.0, 2.0, 0.3540646301795466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 450508.820090913, 450508.8200909126, 122511.2322278984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2441400.0000, 
sim time next is 2442000.0000, 
raw observation next is [22.63333333333333, 60.66666666666667, 1.0, 2.0, 0.3369418937705095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 427806.3755617127, 427806.3755617127, 120250.8238425775], 
processed observation next is [1.0, 0.2608695652173913, 0.393827160493827, 0.6066666666666667, 1.0, 1.0, 0.2106451116315589, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15278799127204026, 0.15278799127204026, 0.23125158431264906], 
reward next is 0.7687, 
noisyNet noise sample is [array([1.4387227], dtype=float32), 0.067203365]. 
=============================================
[2019-03-22 23:21:01,895] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[35.12767 ]
 [35.238693]
 [35.422527]
 [35.40788 ]
 [35.660316]], R is [[35.5121994 ]
 [35.92147827]
 [36.34067154]
 [36.75676727]
 [37.16965103]].
[2019-03-22 23:21:05,971] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2502900e-28 1.0000000e+00 3.2259533e-26 2.9964237e-08 1.4242137e-20], sum to 1.0000
[2019-03-22 23:21:05,983] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0889
[2019-03-22 23:21:06,081] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 60.0, 1.0, 2.0, 0.3952608031768006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 494844.4907891487, 494844.4907891483, 128054.6425994027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2523600.0000, 
sim time next is 2524200.0000, 
raw observation next is [24.26666666666667, 59.0, 1.0, 2.0, 0.4574593701732498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 572283.6923094315, 572283.6923094315, 137117.8420197973], 
processed observation next is [1.0, 0.21739130434782608, 0.4543209876543211, 0.59, 1.0, 1.0, 0.35411829782529736, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20438703296765412, 0.20438703296765412, 0.2636881577303794], 
reward next is 0.7363, 
noisyNet noise sample is [array([-1.2945286], dtype=float32), 1.3558978]. 
=============================================
[2019-03-22 23:21:09,585] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.4493835e-26 2.4219729e-30], sum to 1.0000
[2019-03-22 23:21:09,595] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0599
[2019-03-22 23:21:09,602] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.46666666666667, 37.33333333333334, 1.0, 2.0, 0.4623482747163827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 554797.2437477419, 554797.2437477419, 137224.1581697126], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2569200.0000, 
sim time next is 2569800.0000, 
raw observation next is [32.28333333333334, 38.16666666666666, 1.0, 2.0, 0.4670424540938731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 559969.2190117496, 559969.2190117496, 137917.6810689946], 
processed observation next is [1.0, 0.7391304347826086, 0.7512345679012348, 0.3816666666666666, 1.0, 1.0, 0.36552673106413464, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19998900678991058, 0.19998900678991058, 0.26522630974806655], 
reward next is 0.7348, 
noisyNet noise sample is [array([0.1764134], dtype=float32), -0.022497274]. 
=============================================
[2019-03-22 23:21:16,272] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71797: loss 0.0152
[2019-03-22 23:21:16,276] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71797: learning rate 0.0010
[2019-03-22 23:21:16,295] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 71806: loss 0.0010
[2019-03-22 23:21:16,297] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 71809: loss 0.0290
[2019-03-22 23:21:16,298] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 71809: learning rate 0.0010
[2019-03-22 23:21:16,299] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 71809: learning rate 0.0010
[2019-03-22 23:21:16,430] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 71872: loss 0.0067
[2019-03-22 23:21:16,433] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 71872: learning rate 0.0010
[2019-03-22 23:21:16,437] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 71874: loss 0.0092
[2019-03-22 23:21:16,438] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 71874: learning rate 0.0010
[2019-03-22 23:21:16,489] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 71896: loss 0.0033
[2019-03-22 23:21:16,490] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 71896: learning rate 0.0010
[2019-03-22 23:21:16,547] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71923: loss 0.0179
[2019-03-22 23:21:16,553] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71924: learning rate 0.0010
[2019-03-22 23:21:16,589] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 71940: loss 0.0001
[2019-03-22 23:21:16,594] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 71943: learning rate 0.0010
[2019-03-22 23:21:16,820] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 72049: loss 0.0171
[2019-03-22 23:21:16,823] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 72049: learning rate 0.0010
[2019-03-22 23:21:16,827] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 72051: loss 0.0181
[2019-03-22 23:21:16,829] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 72052: learning rate 0.0010
[2019-03-22 23:21:16,888] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 72074: loss 0.0096
[2019-03-22 23:21:16,889] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 72074: learning rate 0.0010
[2019-03-22 23:21:16,944] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 72102: loss 0.0123
[2019-03-22 23:21:16,945] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 72102: loss 0.0007
[2019-03-22 23:21:16,946] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 72102: learning rate 0.0010
[2019-03-22 23:21:16,949] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 72102: learning rate 0.0010
[2019-03-22 23:21:17,044] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 72146: loss 0.0858
[2019-03-22 23:21:17,047] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 72147: learning rate 0.0010
[2019-03-22 23:21:17,059] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 72154: loss 0.0613
[2019-03-22 23:21:17,061] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 72155: learning rate 0.0010
[2019-03-22 23:21:17,179] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 72209: loss 0.0527
[2019-03-22 23:21:17,181] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 72209: learning rate 0.0010
[2019-03-22 23:21:20,785] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0965888e-28 1.0000000e+00 2.1509779e-30 7.2261683e-11 7.0455800e-22], sum to 1.0000
[2019-03-22 23:21:20,792] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1554
[2019-03-22 23:21:20,802] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 94.0, 1.0, 2.0, 0.6597399492486619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 751894.4035702609, 751894.4035702604, 168659.7031069087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2766000.0000, 
sim time next is 2766600.0000, 
raw observation next is [24.5, 94.0, 1.0, 2.0, 0.6518766736000849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 743235.5905917881, 743235.5905917881, 167246.4320610408], 
processed observation next is [1.0, 0.0, 0.46296296296296297, 0.94, 1.0, 1.0, 0.5855674685715296, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26544128235421, 0.26544128235421, 0.32162775396354], 
reward next is 0.6784, 
noisyNet noise sample is [array([-1.4074733], dtype=float32), 0.35262993]. 
=============================================
[2019-03-22 23:21:22,943] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2788620e-32 1.0000000e+00 2.4755688e-32 7.2441143e-17 1.5468755e-23], sum to 1.0000
[2019-03-22 23:21:22,950] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2087
[2019-03-22 23:21:22,958] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1891981.380130078 W.
[2019-03-22 23:21:22,963] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.1, 61.66666666666666, 1.0, 2.0, 0.8294542128828987, 1.0, 2.0, 0.8294542128828987, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1891981.380130078, 1891981.380130078, 356076.9204305527], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2812200.0000, 
sim time next is 2812800.0000, 
raw observation next is [32.2, 60.33333333333334, 1.0, 2.0, 0.6067164340767549, 1.0, 2.0, 0.6067164340767549, 1.0, 1.0, 0.9659123224249779, 6.911200000000001, 6.9112, 121.94756008, 2076089.569864243, 2076089.569864243, 399047.1978698548], 
processed observation next is [1.0, 0.5652173913043478, 0.7481481481481482, 0.6033333333333334, 1.0, 1.0, 0.5318052786628035, 1.0, 1.0, 0.5318052786628035, 1.0, 0.5, 0.9573904030312225, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7414605606658011, 0.7414605606658011, 0.7673984574420285], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.998158], dtype=float32), 1.5859716]. 
=============================================
[2019-03-22 23:21:23,262] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-22 23:21:23,263] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:21:23,265] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:21:23,265] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:21:23,266] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:21:23,266] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:21:23,268] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:21:23,267] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:21:23,269] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:21:23,269] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:21:23,271] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:21:23,286] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run4
[2019-03-22 23:21:23,287] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run4
[2019-03-22 23:21:23,287] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run4
[2019-03-22 23:21:23,305] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run4
[2019-03-22 23:21:23,340] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run4
[2019-03-22 23:21:29,111] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2953578], dtype=float32), 0.24635983]
[2019-03-22 23:21:29,115] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.85, 47.5, 1.0, 2.0, 0.279735661406253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 360843.9467084795, 360843.946708479, 111348.2660617589]
[2019-03-22 23:21:29,116] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:21:29,119] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7595680e-28 1.0000000e+00 2.9657652e-23 2.8457358e-16 1.4970002e-19], sampled 0.2549331531640876
[2019-03-22 23:21:37,933] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.2953578], dtype=float32), 0.24635983]
[2019-03-22 23:21:37,934] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.16666666666667, 39.83333333333334, 1.0, 2.0, 0.2575020535482523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 332157.5897956548, 332157.5897956548, 92253.83362996402]
[2019-03-22 23:21:37,936] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:21:37,939] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.8004882e-28 1.0000000e+00 4.6505572e-23 3.6817288e-16 1.7245886e-19], sampled 0.8998997338135947
[2019-03-22 23:22:52,596] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2953578], dtype=float32), 0.24635983]
[2019-03-22 23:22:52,597] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.36666666666667, 92.0, 1.0, 2.0, 0.5382727373956105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 632621.7370476087, 632621.7370476082, 148667.2045645312]
[2019-03-22 23:22:52,598] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:22:52,601] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.4688323e-27 1.0000000e+00 6.9415064e-23 5.7727417e-15 5.9567028e-19], sampled 0.4494548521497771
[2019-03-22 23:23:15,290] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-22 23:23:15,702] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-22 23:23:15,998] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.6619 2445343923.2757 746.0000
[2019-03-22 23:23:16,081] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-22 23:23:16,139] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7013 2248693483.9672 553.0000
[2019-03-22 23:23:17,154] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 75000, evaluation results [75000.0, 8100.661928194693, 2445343923.2757144, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8583.701325530239, 2248693483.9671583, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-22 23:23:19,529] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5176815e-31 1.0000000e+00 3.5311358e-30 6.5765989e-16 1.4289446e-25], sum to 1.0000
[2019-03-22 23:23:19,541] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6346
[2019-03-22 23:23:19,548] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1378114.35210626 W.
[2019-03-22 23:23:19,556] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.41666666666667, 92.5, 1.0, 2.0, 0.977860647871295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.316422299488847, 6.9112, 122.6799032636202, 1378114.35210626, 1169321.295599735, 238300.2825366607], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2859000.0000, 
sim time next is 2859600.0000, 
raw observation next is [22.33333333333334, 94.0, 1.0, 2.0, 0.316675067179699, 1.0, 1.0, 0.316675067179699, 1.0, 1.0, 0.5052987793129403, 6.911200000000001, 6.9112, 121.94756008, 1103981.385077797, 1103981.385077796, 262526.5288932687], 
processed observation next is [1.0, 0.08695652173913043, 0.38271604938271625, 0.94, 1.0, 1.0, 0.1865179371186893, 1.0, 0.5, 0.1865179371186893, 1.0, 0.5, 0.38162347414117537, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.39427906609921326, 0.3942790660992128, 0.5048587094101321], 
reward next is 0.4951, 
noisyNet noise sample is [array([0.12536213], dtype=float32), 0.26682568]. 
=============================================
[2019-03-22 23:23:21,263] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3028879e-38 1.0000000e+00 2.0983838e-33 1.8531566e-14 6.2784849e-28], sum to 1.0000
[2019-03-22 23:23:21,272] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0119
[2019-03-22 23:23:21,278] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.86666666666667, 91.33333333333334, 1.0, 2.0, 0.7921997963038853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 942102.4082323333, 942102.4082323333, 196202.4261232324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2881200.0000, 
sim time next is 2881800.0000, 
raw observation next is [22.9, 92.0, 1.0, 2.0, 0.8770758864645823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1040466.006340586, 1040466.006340586, 214406.7266092963], 
processed observation next is [1.0, 0.34782608695652173, 0.4037037037037037, 0.92, 1.0, 1.0, 0.8536617696006933, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.371595002264495, 0.371595002264495, 0.4123206280948006], 
reward next is 0.5877, 
noisyNet noise sample is [array([0.34993082], dtype=float32), 0.22501135]. 
=============================================
[2019-03-22 23:23:23,694] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.2541039e-30 1.0000000e+00 2.4055433e-25 8.8670196e-15 1.7813636e-19], sum to 1.0000
[2019-03-22 23:23:23,700] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4439
[2019-03-22 23:23:23,706] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.6852007309650351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 780926.4050572189, 780926.4050572184, 173360.7346072997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2929200.0000, 
sim time next is 2929800.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.6850219263724854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 780722.5168627085, 780722.516862708, 173327.3514514834], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.89, 1.0, 1.0, 0.6250261028243873, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27882947030811017, 0.27882947030811, 0.33332182971439117], 
reward next is 0.6667, 
noisyNet noise sample is [array([-1.7769026], dtype=float32), 1.6400478]. 
=============================================
[2019-03-22 23:23:25,035] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6289356e-32 1.0000000e+00 8.5051901e-26 3.7535337e-13 6.6391386e-23], sum to 1.0000
[2019-03-22 23:23:25,044] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7071
[2019-03-22 23:23:25,048] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666666, 91.33333333333334, 1.0, 2.0, 0.8376127418975647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156303, 954739.2649005976, 954739.2649005976, 203828.6191891537], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2947200.0000, 
sim time next is 2947800.0000, 
raw observation next is [25.08333333333334, 92.66666666666667, 1.0, 2.0, 0.8251272356298684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 940499.1306660377, 940499.1306660377, 201181.6076131642], 
processed observation next is [1.0, 0.08695652173913043, 0.4845679012345681, 0.9266666666666667, 1.0, 1.0, 0.7918181376546053, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.335892546666442, 0.335892546666442, 0.3868877069483927], 
reward next is 0.6131, 
noisyNet noise sample is [array([-0.09619014], dtype=float32), -0.4284204]. 
=============================================
[2019-03-22 23:23:25,090] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8790203e-34 1.0000000e+00 9.5501822e-32 4.8343353e-17 2.5716796e-26], sum to 1.0000
[2019-03-22 23:23:25,102] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5854
[2019-03-22 23:23:25,106] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 90.0, 1.0, 2.0, 0.6936515931652869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 796742.8556693759, 796742.8556693759, 175254.352029655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2955600.0000, 
sim time next is 2956200.0000, 
raw observation next is [24.75, 90.66666666666667, 1.0, 2.0, 0.7462953603057716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 855976.7169773228, 855976.7169773228, 185367.3148086843], 
processed observation next is [1.0, 0.21739130434782608, 0.4722222222222222, 0.9066666666666667, 1.0, 1.0, 0.6979706670306804, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30570597034904384, 0.30570597034904384, 0.356475605401316], 
reward next is 0.6435, 
noisyNet noise sample is [array([0.62591535], dtype=float32), -0.46083024]. 
=============================================
[2019-03-22 23:23:27,277] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79798: loss 47.4905
[2019-03-22 23:23:27,279] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 79798: learning rate 0.0010
[2019-03-22 23:23:27,468] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 79855: loss 89.3082
[2019-03-22 23:23:27,473] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 79857: learning rate 0.0010
[2019-03-22 23:23:27,564] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 79868: loss 151.6893
[2019-03-22 23:23:27,567] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 79869: learning rate 0.0010
[2019-03-22 23:23:27,661] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 79880: loss 48.4031
[2019-03-22 23:23:27,664] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 79882: learning rate 0.0010
[2019-03-22 23:23:27,765] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 79894: loss 146.7032
[2019-03-22 23:23:27,766] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 79894: learning rate 0.0010
[2019-03-22 23:23:27,883] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 79919: loss 120.4352
[2019-03-22 23:23:27,883] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 79919: learning rate 0.0010
[2019-03-22 23:23:28,005] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 79952: loss 52.7405
[2019-03-22 23:23:28,009] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 79954: learning rate 0.0010
[2019-03-22 23:23:28,131] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 79981: loss 202.3189
[2019-03-22 23:23:28,132] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 79981: learning rate 0.0010
[2019-03-22 23:23:28,323] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 80047: loss 16.7112
[2019-03-22 23:23:28,325] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 80047: learning rate 0.0010
[2019-03-22 23:23:28,419] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 80058: loss 148.4104
[2019-03-22 23:23:28,421] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 80058: loss 176.3722
[2019-03-22 23:23:28,422] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 80058: learning rate 0.0010
[2019-03-22 23:23:28,425] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 80058: learning rate 0.0010
[2019-03-22 23:23:28,590] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 80070: loss 134.3864
[2019-03-22 23:23:28,592] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 80071: learning rate 0.0010
[2019-03-22 23:23:28,689] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 80082: loss -21.8572
[2019-03-22 23:23:28,691] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 80083: learning rate 0.0010
[2019-03-22 23:23:28,837] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 80128: loss -23.5643
[2019-03-22 23:23:28,840] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 80129: learning rate 0.0010
[2019-03-22 23:23:28,935] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 80146: loss -87.2153
[2019-03-22 23:23:28,937] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 80147: learning rate 0.0010
[2019-03-22 23:23:29,036] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 80163: loss -69.5105
[2019-03-22 23:23:29,038] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 80165: learning rate 0.0010
[2019-03-22 23:23:32,060] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3878025e-36 1.0000000e+00 9.7704495e-36 1.0336062e-31 3.5948521e-30], sum to 1.0000
[2019-03-22 23:23:32,070] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6425
[2019-03-22 23:23:32,075] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2198068.335213569 W.
[2019-03-22 23:23:32,079] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.66666666666667, 84.66666666666667, 1.0, 2.0, 0.9634793322659967, 1.0, 2.0, 0.9634793322659967, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2198068.335213569, 2198068.335213569, 415938.8968026016], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3061200.0000, 
sim time next is 3061800.0000, 
raw observation next is [29.0, 82.5, 1.0, 2.0, 1.007137629871771, 1.0, 2.0, 1.007137629871771, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2297797.94260373, 2297797.94260373, 436782.65107504], 
processed observation next is [1.0, 0.43478260869565216, 0.6296296296296297, 0.825, 1.0, 1.0, 1.0084971784187748, 1.0, 1.0, 1.0084971784187748, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.820642122358475, 0.820642122358475, 0.8399666366827692], 
reward next is 0.1600, 
noisyNet noise sample is [array([0.37355563], dtype=float32), -0.87110645]. 
=============================================
[2019-03-22 23:23:45,450] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 87792: loss 0.1170
[2019-03-22 23:23:45,454] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 87794: learning rate 0.0010
[2019-03-22 23:23:45,455] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87794: loss 0.0948
[2019-03-22 23:23:45,458] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 87796: learning rate 0.0010
[2019-03-22 23:23:45,577] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 87849: loss 0.0641
[2019-03-22 23:23:45,578] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 87849: learning rate 0.0010
[2019-03-22 23:23:45,586] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 87852: loss 0.0849
[2019-03-22 23:23:45,588] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 87852: learning rate 0.0010
[2019-03-22 23:23:45,588] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 87852: loss 0.0530
[2019-03-22 23:23:45,592] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 87855: learning rate 0.0010
[2019-03-22 23:23:45,748] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 87926: loss 0.0149
[2019-03-22 23:23:45,751] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 87926: learning rate 0.0010
[2019-03-22 23:23:45,794] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87949: loss 0.0148
[2019-03-22 23:23:45,800] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 87949: learning rate 0.0010
[2019-03-22 23:23:45,881] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 87987: loss 0.0120
[2019-03-22 23:23:45,883] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 87987: learning rate 0.0010
[2019-03-22 23:23:45,992] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 88036: loss 0.0846
[2019-03-22 23:23:46,000] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 88037: learning rate 0.0010
[2019-03-22 23:23:46,024] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 88051: loss 0.0738
[2019-03-22 23:23:46,027] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 88051: learning rate 0.0010
[2019-03-22 23:23:46,038] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 88057: loss 0.0500
[2019-03-22 23:23:46,041] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 88058: learning rate 0.0010
[2019-03-22 23:23:46,062] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 88071: loss 0.0239
[2019-03-22 23:23:46,069] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 88071: learning rate 0.0010
[2019-03-22 23:23:46,178] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 88120: loss 0.0223
[2019-03-22 23:23:46,182] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 88120: learning rate 0.0010
[2019-03-22 23:23:46,241] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.4351728e-24 7.0669670e-33], sum to 1.0000
[2019-03-22 23:23:46,245] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2134
[2019-03-22 23:23:46,250] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 88151: loss 0.0125
[2019-03-22 23:23:46,253] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.73333333333333, 93.33333333333334, 1.0, 2.0, 0.5307454941935716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 629505.7521772458, 629505.7521772454, 147674.923468966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3310800.0000, 
sim time next is 3311400.0000, 
raw observation next is [22.91666666666667, 91.66666666666666, 1.0, 2.0, 0.5283611796627021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626987.9529033051, 626987.9529033051, 147300.6103292744], 
processed observation next is [0.0, 0.30434782608695654, 0.4043209876543212, 0.9166666666666665, 1.0, 1.0, 0.4385252138841692, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22392426889403752, 0.22392426889403752, 0.28327040447937385], 
reward next is 0.7167, 
noisyNet noise sample is [array([0.00075202], dtype=float32), 0.65932065]. 
=============================================
[2019-03-22 23:23:46,256] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 88153: learning rate 0.0010
[2019-03-22 23:23:46,269] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 88162: loss 0.0192
[2019-03-22 23:23:46,270] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 88162: loss 0.0251
[2019-03-22 23:23:46,271] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 88162: learning rate 0.0010
[2019-03-22 23:23:46,275] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 88163: learning rate 0.0010
[2019-03-22 23:23:50,828] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0616658e-38 1.0000000e+00 1.4665217e-36 3.4548258e-24 1.2385970e-27], sum to 1.0000
[2019-03-22 23:23:50,834] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0593
[2019-03-22 23:23:50,846] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.86666666666667, 93.0, 1.0, 2.0, 0.8933475915443487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156311, 1036939.30861082, 1036939.30861082, 216971.0269692955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3379200.0000, 
sim time next is 3379800.0000, 
raw observation next is [23.93333333333333, 93.5, 1.0, 2.0, 0.8667908510444094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1003532.633747276, 1003532.633747276, 210945.6143824158], 
processed observation next is [1.0, 0.08695652173913043, 0.4419753086419752, 0.935, 1.0, 1.0, 0.8414176798147731, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3584045120525986, 0.3584045120525986, 0.40566464304310734], 
reward next is 0.5943, 
noisyNet noise sample is [array([0.31244287], dtype=float32), -0.41982925]. 
=============================================
[2019-03-22 23:23:53,330] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.4330061e-36 1.0000000e+00 2.0818904e-30 4.2369485e-31 1.3872356e-29], sum to 1.0000
[2019-03-22 23:23:53,337] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9675
[2019-03-22 23:23:53,357] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2199187.115998302 W.
[2019-03-22 23:23:53,363] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.53333333333333, 60.66666666666667, 1.0, 2.0, 0.9639691242469322, 1.0, 2.0, 0.9639691242469322, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2199187.115998302, 2199187.115998301, 416167.9337503476], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3424800.0000, 
sim time next is 3425400.0000, 
raw observation next is [31.3, 61.5, 1.0, 2.0, 0.6514413845781235, 1.0, 2.0, 0.6390853542654965, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2186986.617252394, 2186986.617252394, 416446.4330463811], 
processed observation next is [1.0, 0.6521739130434783, 0.7148148148148148, 0.615, 1.0, 1.0, 0.5850492673549089, 1.0, 1.0, 0.5703397074589244, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.7810666490187121, 0.7810666490187121, 0.8008585250891944], 
reward next is 0.1991, 
noisyNet noise sample is [array([1.9427768], dtype=float32), -0.63388103]. 
=============================================
[2019-03-22 23:24:03,002] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 95820: loss 19.5170
[2019-03-22 23:24:03,004] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 95820: loss -92.6419
[2019-03-22 23:24:03,007] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 95820: learning rate 0.0010
[2019-03-22 23:24:03,009] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 95821: learning rate 0.0010
[2019-03-22 23:24:03,028] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 95828: loss 68.6115
[2019-03-22 23:24:03,031] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 95831: learning rate 0.0010
[2019-03-22 23:24:03,096] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 95859: loss -10.1370
[2019-03-22 23:24:03,097] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 95859: learning rate 0.0010
[2019-03-22 23:24:03,149] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 95885: loss -0.3623
[2019-03-22 23:24:03,150] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 95886: learning rate 0.0010
[2019-03-22 23:24:03,190] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 95908: loss 6.6007
[2019-03-22 23:24:03,193] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 95908: learning rate 0.0010
[2019-03-22 23:24:03,360] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 95991: loss 115.9651
[2019-03-22 23:24:03,361] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 95991: learning rate 0.0010
[2019-03-22 23:24:03,375] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 95997: loss -41.7608
[2019-03-22 23:24:03,377] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 95997: learning rate 0.0010
[2019-03-22 23:24:03,490] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 96050: loss 80.1105
[2019-03-22 23:24:03,491] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 96050: learning rate 0.0010
[2019-03-22 23:24:03,531] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 96066: loss 147.2355
[2019-03-22 23:24:03,535] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 96066: learning rate 0.0010
[2019-03-22 23:24:03,547] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 96074: loss 64.8084
[2019-03-22 23:24:03,548] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 96074: learning rate 0.0010
[2019-03-22 23:24:03,571] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 96084: loss 120.4026
[2019-03-22 23:24:03,574] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 96085: learning rate 0.0010
[2019-03-22 23:24:03,611] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 96101: loss -36.2568
[2019-03-22 23:24:03,613] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 96101: learning rate 0.0010
[2019-03-22 23:24:03,667] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 96127: loss -8.6055
[2019-03-22 23:24:03,670] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 96128: learning rate 0.0010
[2019-03-22 23:24:03,679] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 96132: loss -42.9775
[2019-03-22 23:24:03,682] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 96132: learning rate 0.0010
[2019-03-22 23:24:03,750] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 96165: loss 156.9687
[2019-03-22 23:24:03,753] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 96166: learning rate 0.0010
[2019-03-22 23:24:07,022] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3250115e-31 1.0000000e+00 7.6193168e-35 3.0305198e-15 2.5645027e-23], sum to 1.0000
[2019-03-22 23:24:07,032] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2294
[2019-03-22 23:24:07,044] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1311664.375573918 W.
[2019-03-22 23:24:07,048] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.9948315633645611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.219274587714088, 6.9112, 121.9249149824906, 1311664.375573918, 1153904.110329632, 240577.6602930193], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3669600.0000, 
sim time next is 3670200.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.5326482978874154, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8482623639695739, 6.911199999999999, 6.9112, 121.9258570985808, 1220758.022756703, 1220758.022756703, 268484.0726393379], 
processed observation next is [1.0, 0.4782608695652174, 0.4074074074074074, 1.0, 1.0, 1.0, 0.4436289260564469, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.8103279549619674, -8.881784197001253e-17, 0.0, 0.8094608971796423, 0.43598500812739394, 0.43598500812739394, 0.516315524306419], 
reward next is 0.4837, 
noisyNet noise sample is [array([1.3221284], dtype=float32), 0.793413]. 
=============================================
[2019-03-22 23:24:08,340] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.4142232e-13 8.9041627e-09 3.0593546e-19 1.0000000e+00 1.9854214e-11], sum to 1.0000
[2019-03-22 23:24:08,348] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3944
[2019-03-22 23:24:08,359] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.8039179474945768, 1.0, 1.0, 0.8039179474945768, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1833673.480129336, 1833673.480129337, 345376.8729745445], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3684600.0000, 
sim time next is 3685200.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.8546378469197417, 1.0, 2.0, 0.8546378469197417, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1949487.832271864, 1949487.832271865, 366849.7001058497], 
processed observation next is [1.0, 0.6521739130434783, 0.5555555555555556, 0.89, 1.0, 1.0, 0.8269498177615972, 1.0, 1.0, 0.8269498177615972, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6962456543828085, 0.6962456543828089, 0.7054801925112495], 
reward next is 0.2945, 
noisyNet noise sample is [array([-1.5311478], dtype=float32), 0.789482]. 
=============================================
[2019-03-22 23:24:12,105] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-22 23:24:12,107] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:24:12,107] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:24:12,109] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:24:12,110] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:24:12,110] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:24:12,111] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:24:12,111] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:24:12,113] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:24:12,114] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:24:12,113] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:24:12,133] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run5
[2019-03-22 23:24:12,133] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run5
[2019-03-22 23:24:12,134] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run5
[2019-03-22 23:24:12,151] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run5
[2019-03-22 23:24:12,211] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run5
[2019-03-22 23:24:28,201] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.20983642], dtype=float32), 0.3561968]
[2019-03-22 23:24:28,202] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.23333333333333, 50.66666666666667, 1.0, 2.0, 0.3721291835902246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 473196.1783526849, 473196.1783526849, 124944.6493532887]
[2019-03-22 23:24:28,204] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:24:28,206] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.2631681e-31 1.0000000e+00 6.8295828e-32 4.4391764e-19 2.7166682e-20], sampled 0.4169529080677936
[2019-03-22 23:24:32,784] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.20983642], dtype=float32), 0.3561968]
[2019-03-22 23:24:32,785] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.33333333333334, 22.33333333333334, 1.0, 2.0, 0.3981631001268157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 495683.2157680407, 495683.2157680407, 128410.5841005782]
[2019-03-22 23:24:32,786] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:24:32,790] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.5847525e-32 1.0000000e+00 9.0950179e-35 2.4586487e-16 1.7464691e-19], sampled 0.8013490695120024
[2019-03-22 23:24:38,640] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.20983642], dtype=float32), 0.3561968]
[2019-03-22 23:24:38,641] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.98459237, 89.36364856, 1.0, 2.0, 0.6338466422373952, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260424450388, 1437299.276311414, 1437299.276311414, 305616.1435324101]
[2019-03-22 23:24:38,642] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:24:38,647] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3539618e-24 1.0000000e+00 1.7442372e-28 1.4119426e-12 2.5001897e-15], sampled 0.337356624383782
[2019-03-22 23:24:38,648] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1437299.276311414 W.
[2019-03-22 23:25:05,053] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.20983642], dtype=float32), 0.3561968]
[2019-03-22 23:25:05,053] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.1592706, 88.28113708333333, 1.0, 2.0, 0.6076168645238932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694363.8049346871, 694363.8049346871, 159486.7115068804]
[2019-03-22 23:25:05,054] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:25:05,056] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.1443515e-29 1.0000000e+00 3.2136257e-31 9.8455277e-16 2.9642232e-18], sampled 0.7780541105467639
[2019-03-22 23:25:48,240] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.20983642], dtype=float32), 0.3561968]
[2019-03-22 23:25:48,241] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.76666666666667, 56.33333333333334, 1.0, 2.0, 0.3381966808812994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 427442.6685877579, 427442.6685877574, 120396.0520851918]
[2019-03-22 23:25:48,242] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:25:48,244] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.4627545e-32 1.0000000e+00 1.0233541e-32 1.1235182e-18 2.5205038e-20], sampled 0.01854287709628366
[2019-03-22 23:25:54,107] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.20983642], dtype=float32), 0.3561968]
[2019-03-22 23:25:54,110] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.33333333333333, 96.0, 1.0, 2.0, 0.6762571856433026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 770728.2809810749, 770728.2809810744, 171699.0749998694]
[2019-03-22 23:25:54,111] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:25:54,113] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.94788976e-29 1.00000000e+00 2.52282717e-31 1.09418644e-16
 9.50611987e-19], sampled 0.025877230524747663
[2019-03-22 23:26:04,718] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2665 2170632327.5226 493.0000
[2019-03-22 23:26:04,985] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.2011 2445377682.4312 746.0000
[2019-03-22 23:26:05,024] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.8787 2248748925.1610 553.0000
[2019-03-22 23:26:05,038] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.1625 2120466133.0938 430.0000
[2019-03-22 23:26:05,125] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.6453 2195070843.7322 572.0000
[2019-03-22 23:26:06,140] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 100000, evaluation results [100000.0, 8099.201055540698, 2445377682.4311814, 746.0, 8770.266515857684, 2170632327.522563, 493.0, 8924.162528137549, 2120466133.0938108, 430.0, 8582.878745663738, 2248748925.160952, 553.0, 8701.6453272671, 2195070843.7322125, 572.0]
[2019-03-22 23:26:06,199] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3554253e-30 1.0000000e+00 2.3033881e-30 6.9751957e-14 2.3821769e-16], sum to 1.0000
[2019-03-22 23:26:06,200] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8742
[2019-03-22 23:26:06,202] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1712089.959484428 W.
[2019-03-22 23:26:06,207] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.5, 94.0, 1.0, 2.0, 0.750664413814802, 1.0, 2.0, 0.750664413814802, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1712089.959484428, 1712089.959484428, 323790.8816009572], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3749400.0000, 
sim time next is 3750000.0000, 
raw observation next is [26.66666666666667, 94.0, 1.0, 2.0, 0.8498855444136045, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1683880.016920213, 1683880.016920213, 346363.5034785351], 
processed observation next is [1.0, 0.391304347826087, 0.5432098765432101, 0.94, 1.0, 1.0, 0.8212923147781006, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.6013857203286475, 0.6013857203286475, 0.6660836605356444], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.28687304], dtype=float32), -0.29709423]. 
=============================================
[2019-03-22 23:26:06,223] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[54.964848]
 [54.64353 ]
 [54.35414 ]
 [54.092113]
 [54.714897]], R is [[54.11031342]
 [53.94653702]
 [53.40707397]
 [53.21678925]
 [52.97883606]].
[2019-03-22 23:26:07,749] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.071686e-23 1.000000e+00 1.554277e-28 1.913007e-18 5.968037e-13], sum to 1.0000
[2019-03-22 23:26:07,758] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8731
[2019-03-22 23:26:07,765] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.75, 67.0, 1.0, 2.0, 0.7802597750347094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 889328.4867677265, 889328.4867677265, 191904.0493726349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3785400.0000, 
sim time next is 3786000.0000, 
raw observation next is [31.33333333333334, 70.66666666666667, 1.0, 2.0, 0.8065515221866764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 919313.4027274995, 919313.4027274995, 197307.5699735106], 
processed observation next is [1.0, 0.8260869565217391, 0.7160493827160496, 0.7066666666666667, 1.0, 1.0, 0.7697041930793767, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32832621525982125, 0.32832621525982125, 0.37943763456444346], 
reward next is 0.6206, 
noisyNet noise sample is [array([-0.00316017], dtype=float32), -0.04765048]. 
=============================================
[2019-03-22 23:26:07,774] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[33.232986]
 [33.152534]
 [33.407555]
 [33.384212]
 [33.527138]], R is [[33.41815186]
 [33.71492386]
 [34.02328873]
 [34.33608627]
 [34.6462326 ]].
[2019-03-22 23:26:13,494] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 103677: loss 0.0621
[2019-03-22 23:26:13,496] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 103677: learning rate 0.0010
[2019-03-22 23:26:13,793] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 103817: loss 0.0567
[2019-03-22 23:26:13,800] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 103819: learning rate 0.0010
[2019-03-22 23:26:13,858] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 103847: loss 0.0077
[2019-03-22 23:26:13,860] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 103847: learning rate 0.0010
[2019-03-22 23:26:13,871] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 103854: loss 0.0020
[2019-03-22 23:26:13,872] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 103854: learning rate 0.0010
[2019-03-22 23:26:13,912] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 103876: loss 0.0316
[2019-03-22 23:26:13,917] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 103876: learning rate 0.0010
[2019-03-22 23:26:14,015] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 103917: loss 0.0487
[2019-03-22 23:26:14,021] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 103920: learning rate 0.0010
[2019-03-22 23:26:14,139] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 103978: loss 0.0020
[2019-03-22 23:26:14,144] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 103981: learning rate 0.0010
[2019-03-22 23:26:14,221] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 104016: loss 0.0129
[2019-03-22 23:26:14,228] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 104016: learning rate 0.0010
[2019-03-22 23:26:14,256] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 104034: loss 0.0004
[2019-03-22 23:26:14,259] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 104034: learning rate 0.0010
[2019-03-22 23:26:14,308] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 104056: loss 0.0091
[2019-03-22 23:26:14,310] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 104056: learning rate 0.0010
[2019-03-22 23:26:14,412] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 104104: loss 0.2029
[2019-03-22 23:26:14,417] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 104106: learning rate 0.0010
[2019-03-22 23:26:14,440] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 104117: loss 0.2857
[2019-03-22 23:26:14,444] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 104118: learning rate 0.0010
[2019-03-22 23:26:14,462] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 104129: loss 0.2516
[2019-03-22 23:26:14,465] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 104129: learning rate 0.0010
[2019-03-22 23:26:14,465] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 104130: loss 0.2030
[2019-03-22 23:26:14,473] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 104132: learning rate 0.0010
[2019-03-22 23:26:14,476] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 104133: loss 0.3178
[2019-03-22 23:26:14,478] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 104133: learning rate 0.0010
[2019-03-22 23:26:14,481] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 104133: loss 0.2653
[2019-03-22 23:26:14,487] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 104134: learning rate 0.0010
[2019-03-22 23:26:26,166] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.3359838e-37 1.0000000e+00 1.7770306e-37 4.7638650e-20 7.7053264e-23], sum to 1.0000
[2019-03-22 23:26:26,172] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2262
[2019-03-22 23:26:26,181] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2012962.126443526 W.
[2019-03-22 23:26:26,184] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 72.0, 1.0, 2.0, 0.8824330780252014, 1.0, 2.0, 0.8824330780252014, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2012962.126443526, 2012962.126443526, 378994.6794780657], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4116600.0000, 
sim time next is 4117200.0000, 
raw observation next is [29.0, 71.33333333333333, 1.0, 2.0, 0.5889082952381927, 1.0, 2.0, 0.5889082952381927, 1.0, 1.0, 0.9375611854233947, 6.9112, 6.9112, 121.94756008, 2015084.137690608, 2015084.137690608, 389365.3869254182], 
processed observation next is [1.0, 0.6521739130434783, 0.6296296296296297, 0.7133333333333333, 1.0, 1.0, 0.5106051133788008, 1.0, 1.0, 0.5106051133788008, 1.0, 0.5, 0.9219514817792435, 0.0, 0.0, 0.8096049824067558, 0.7196729063180742, 0.7196729063180742, 0.7487795902411889], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8526825], dtype=float32), -0.22807468]. 
=============================================
[2019-03-22 23:26:28,614] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:26:28,627] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0945
[2019-03-22 23:26:28,636] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 95.0, 1.0, 2.0, 0.4421820000544093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 539714.4385544419, 539714.4385544414, 134509.891473954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4152000.0000, 
sim time next is 4152600.0000, 
raw observation next is [20.85, 95.5, 1.0, 2.0, 0.4431452631645587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 540810.4722571144, 540810.4722571144, 134650.1315303274], 
processed observation next is [1.0, 0.043478260869565216, 0.32777777777777783, 0.955, 1.0, 1.0, 0.33707769424352224, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1931465972346837, 0.1931465972346837, 0.258942560635245], 
reward next is 0.7411, 
noisyNet noise sample is [array([-1.0908439], dtype=float32), 1.0487971]. 
=============================================
[2019-03-22 23:26:29,139] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 5.407064e-37 0.000000e+00], sum to 1.0000
[2019-03-22 23:26:29,149] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7338
[2019-03-22 23:26:29,160] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 98.0, 1.0, 2.0, 0.4988975135626824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 609378.9501984813, 609378.9501984813, 143194.7498903514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4155600.0000, 
sim time next is 4156200.0000, 
raw observation next is [20.35, 98.5, 1.0, 2.0, 0.4562237125813064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 557855.4149260485, 557855.4149260485, 136632.321306606], 
processed observation next is [1.0, 0.08695652173913043, 0.3092592592592593, 0.985, 1.0, 1.0, 0.35264727688250763, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19923407675930302, 0.19923407675930302, 0.26275446405116537], 
reward next is 0.7372, 
noisyNet noise sample is [array([-0.5533017], dtype=float32), -1.6906887]. 
=============================================
[2019-03-22 23:26:31,057] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111726: loss -58.8694
[2019-03-22 23:26:31,062] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111727: learning rate 0.0010
[2019-03-22 23:26:31,372] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 111868: loss -17.9499
[2019-03-22 23:26:31,373] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 111868: learning rate 0.0010
[2019-03-22 23:26:31,401] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 111884: loss -119.7946
[2019-03-22 23:26:31,406] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 111884: learning rate 0.0010
[2019-03-22 23:26:31,411] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 111887: loss -99.9090
[2019-03-22 23:26:31,414] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 111888: learning rate 0.0010
[2019-03-22 23:26:31,421] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 111889: loss -94.4943
[2019-03-22 23:26:31,425] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 111890: learning rate 0.0010
[2019-03-22 23:26:31,442] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 111895: loss 18.8863
[2019-03-22 23:26:31,444] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 111896: learning rate 0.0010
[2019-03-22 23:26:31,565] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 111955: loss -120.1738
[2019-03-22 23:26:31,568] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 111956: learning rate 0.0010
[2019-03-22 23:26:31,638] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 111982: loss 31.4201
[2019-03-22 23:26:31,638] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 111982: learning rate 0.0010
[2019-03-22 23:26:31,733] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 112032: loss -89.8413
[2019-03-22 23:26:31,736] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 112032: learning rate 0.0010
[2019-03-22 23:26:31,742] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 112035: loss 110.9618
[2019-03-22 23:26:31,746] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 112035: learning rate 0.0010
[2019-03-22 23:26:31,763] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 112046: loss 69.1022
[2019-03-22 23:26:31,768] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 112047: learning rate 0.0010
[2019-03-22 23:26:31,827] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 112066: loss 34.4969
[2019-03-22 23:26:31,829] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 112066: learning rate 0.0010
[2019-03-22 23:26:31,968] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 112133: loss 146.3122
[2019-03-22 23:26:31,969] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 112133: learning rate 0.0010
[2019-03-22 23:26:31,981] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 112138: loss 25.1825
[2019-03-22 23:26:31,982] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 112139: learning rate 0.0010
[2019-03-22 23:26:31,994] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 112142: loss 22.6372
[2019-03-22 23:26:31,994] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 112142: loss 39.3305
[2019-03-22 23:26:31,995] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 112142: learning rate 0.0010
[2019-03-22 23:26:31,996] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 112142: learning rate 0.0010
[2019-03-22 23:26:36,393] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 3.0748338e-34 6.6049721e-27 4.1889437e-24], sum to 1.0000
[2019-03-22 23:26:36,402] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9807
[2019-03-22 23:26:36,407] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 38.0, 1.0, 2.0, 0.5391900760319527, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8644582863089525, 6.9112, 6.9112, 121.9260426156618, 1274691.860547329, 1274691.860547329, 269934.505187616], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4279200.0000, 
sim time next is 4279800.0000, 
raw observation next is [32.0, 38.0, 1.0, 2.0, 1.002307347612966, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.478290225010666, 6.9112, 121.9236794928802, 1492360.700393945, 1201965.447675413, 244285.5975400177], 
processed observation next is [1.0, 0.5217391304347826, 0.7407407407407407, 0.38, 1.0, 1.0, 1.0027468423963881, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.056709022501066644, 0.0, 0.8094464401423406, 0.5329859644264089, 0.42927337416979033, 0.46977999526926484], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0973588], dtype=float32), 0.8116174]. 
=============================================
[2019-03-22 23:26:37,469] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0502631e-32 1.0000000e+00 2.5614835e-29 2.8328193e-20 6.5017446e-22], sum to 1.0000
[2019-03-22 23:26:37,479] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0269
[2019-03-22 23:26:37,486] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.75, 45.33333333333334, 1.0, 2.0, 0.3707210820006003, 1.0, 2.0, 0.3707210820006003, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 851977.1471706271, 851977.1471706271, 198630.2055818937], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4295400.0000, 
sim time next is 4296000.0000, 
raw observation next is [31.6, 46.66666666666667, 1.0, 2.0, 0.5154960977240161, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 601041.8667818238, 601041.8667818233, 144793.6344586168], 
processed observation next is [1.0, 0.7391304347826086, 0.725925925925926, 0.46666666666666673, 1.0, 1.0, 0.4232096401476381, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21465780956493707, 0.2146578095649369, 0.27844929703580157], 
reward next is 0.7216, 
noisyNet noise sample is [array([-1.6239917], dtype=float32), -1.7903284]. 
=============================================
[2019-03-22 23:26:37,506] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[29.973436]
 [27.407352]
 [26.764353]
 [26.641327]
 [26.305672]], R is [[32.40868759]
 [32.70262146]
 [32.70359802]
 [32.63497925]
 [32.55926132]].
[2019-03-22 23:26:39,722] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.1967993e-38 1.0000000e+00 0.0000000e+00 1.7566277e-31 7.8663812e-32], sum to 1.0000
[2019-03-22 23:26:39,736] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7267
[2019-03-22 23:26:39,742] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.534485915371232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 638014.7373969996, 638014.7373970001, 148437.7374722651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4341600.0000, 
sim time next is 4342200.0000, 
raw observation next is [23.16666666666667, 89.0, 1.0, 2.0, 0.6571767151382696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 781976.9507730954, 781976.9507730949, 169691.6682981087], 
processed observation next is [1.0, 0.2608695652173913, 0.4135802469135804, 0.89, 1.0, 1.0, 0.5918770418312733, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2792774824189626, 0.27927748241896244, 0.32633013134251676], 
reward next is 0.6737, 
noisyNet noise sample is [array([-0.2775938], dtype=float32), -1.7531117]. 
=============================================
[2019-03-22 23:26:40,002] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.3481092e-36 7.6888230e-31 2.4623224e-28], sum to 1.0000
[2019-03-22 23:26:40,009] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8692
[2019-03-22 23:26:40,013] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 89.33333333333333, 1.0, 2.0, 0.5185622600818428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622931.4718840994, 622931.4718840994, 146001.5364854894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4340400.0000, 
sim time next is 4341000.0000, 
raw observation next is [22.8, 89.16666666666667, 1.0, 2.0, 0.5258074800207587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 629659.7422717004, 629659.7422717004, 147100.7663897566], 
processed observation next is [1.0, 0.21739130434782608, 0.4, 0.8916666666666667, 1.0, 1.0, 0.435485095262808, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22487847938275016, 0.22487847938275016, 0.2828860892110704], 
reward next is 0.7171, 
noisyNet noise sample is [array([0.45310965], dtype=float32), 1.4237987]. 
=============================================
[2019-03-22 23:26:40,026] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[53.905163]
 [54.022354]
 [54.033947]
 [53.92321 ]
 [53.721756]], R is [[53.97765732]
 [54.15710831]
 [54.33666611]
 [54.51745224]
 [54.69156265]].
[2019-03-22 23:26:40,776] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.16912886e-35 1.00000000e+00 1.22586017e-32 1.02503038e-24
 1.68960004e-27], sum to 1.0000
[2019-03-22 23:26:40,785] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2866
[2019-03-22 23:26:40,792] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1849094.399867894 W.
[2019-03-22 23:26:40,797] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.2, 76.83333333333334, 1.0, 2.0, 0.8106717862248779, 1.0, 2.0, 0.8106717862248779, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425598578, 1849094.399867894, 1849094.399867894, 348184.1731887798], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4356600.0000, 
sim time next is 4357200.0000, 
raw observation next is [28.4, 74.66666666666667, 1.0, 2.0, 0.8393520195878353, 1.0, 2.0, 0.8393520195878353, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156448, 1914582.432231892, 1914582.432231892, 360283.7399870998], 
processed observation next is [1.0, 0.43478260869565216, 0.6074074074074074, 0.7466666666666667, 1.0, 1.0, 0.8087524042712325, 1.0, 1.0, 0.8087524042712325, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288200231, 0.6837794400828185, 0.6837794400828185, 0.692853346129038], 
reward next is 0.3071, 
noisyNet noise sample is [array([-0.75284165], dtype=float32), -0.9744347]. 
=============================================
[2019-03-22 23:26:46,443] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:26:46,458] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8291
[2019-03-22 23:26:46,464] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 74.16666666666667, 1.0, 2.0, 0.6265355143520305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716766.9639965609, 716766.9639965609, 162838.1674821817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4449000.0000, 
sim time next is 4449600.0000, 
raw observation next is [27.4, 74.0, 1.0, 2.0, 0.6305876495309908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 720288.1324666169, 720288.1324666169, 163500.4237305037], 
processed observation next is [0.0, 0.5217391304347826, 0.5703703703703703, 0.74, 1.0, 1.0, 0.5602233922987986, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25724576159522033, 0.25724576159522033, 0.3144238917894302], 
reward next is 0.6856, 
noisyNet noise sample is [array([0.48807865], dtype=float32), -0.14756721]. 
=============================================
[2019-03-22 23:26:48,373] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119610: loss 0.0074
[2019-03-22 23:26:48,377] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119611: learning rate 0.0010
[2019-03-22 23:26:48,910] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 119864: loss 0.0233
[2019-03-22 23:26:48,912] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 119864: learning rate 0.0010
[2019-03-22 23:26:48,919] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 119869: loss 0.0037
[2019-03-22 23:26:48,922] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 119870: learning rate 0.0010
[2019-03-22 23:26:48,931] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 119873: loss 0.0183
[2019-03-22 23:26:48,932] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 119873: learning rate 0.0010
[2019-03-22 23:26:48,967] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 119887: loss 0.0317
[2019-03-22 23:26:48,969] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 119887: learning rate 0.0010
[2019-03-22 23:26:48,983] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 119893: loss 0.0067
[2019-03-22 23:26:48,985] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 119895: learning rate 0.0010
[2019-03-22 23:26:49,050] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 119928: loss 0.0204
[2019-03-22 23:26:49,052] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 119928: learning rate 0.0010
[2019-03-22 23:26:49,145] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 119970: loss 0.0069
[2019-03-22 23:26:49,148] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 119970: learning rate 0.0010
[2019-03-22 23:26:49,261] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 120026: loss 0.0154
[2019-03-22 23:26:49,264] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 120026: learning rate 0.0010
[2019-03-22 23:26:49,351] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 120062: loss 0.0096
[2019-03-22 23:26:49,354] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 120062: learning rate 0.0010
[2019-03-22 23:26:49,364] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 120067: loss 0.0086
[2019-03-22 23:26:49,367] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 120069: learning rate 0.0010
[2019-03-22 23:26:49,431] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 120102: loss 0.0158
[2019-03-22 23:26:49,434] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 120102: learning rate 0.0010
[2019-03-22 23:26:49,467] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 120116: loss 0.0718
[2019-03-22 23:26:49,469] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 120116: learning rate 0.0010
[2019-03-22 23:26:49,487] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 120124: loss 0.1501
[2019-03-22 23:26:49,489] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 120124: learning rate 0.0010
[2019-03-22 23:26:49,632] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 120192: loss 0.1376
[2019-03-22 23:26:49,636] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 120192: learning rate 0.0010
[2019-03-22 23:26:49,658] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 120203: loss 0.0180
[2019-03-22 23:26:49,661] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 120203: learning rate 0.0010
[2019-03-22 23:26:50,866] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.6148051e-31 5.8699137e-38], sum to 1.0000
[2019-03-22 23:26:50,879] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2484
[2019-03-22 23:26:50,883] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 91.0, 1.0, 2.0, 0.5852850402488553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 678714.2085457573, 678714.2085457573, 156125.4731403083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4525200.0000, 
sim time next is 4525800.0000, 
raw observation next is [24.33333333333334, 90.66666666666667, 1.0, 2.0, 0.5903433234599739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683202.1034655073, 683202.1034655073, 156926.7957883757], 
processed observation next is [0.0, 0.391304347826087, 0.4567901234567903, 0.9066666666666667, 1.0, 1.0, 0.5123134803094926, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24400075123768117, 0.24400075123768117, 0.30178229959303016], 
reward next is 0.6982, 
noisyNet noise sample is [array([0.5038443], dtype=float32), -0.012400673]. 
=============================================
[2019-03-22 23:26:54,047] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.5901688e-38 5.0232620e-28 5.2232956e-32], sum to 1.0000
[2019-03-22 23:26:54,056] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7862
[2019-03-22 23:26:54,062] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 98.0, 1.0, 2.0, 0.4896455103047287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 587154.631144536, 587154.631144536, 141391.2481097938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4586400.0000, 
sim time next is 4587000.0000, 
raw observation next is [21.5, 98.33333333333334, 1.0, 2.0, 0.7865505204837915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 122.2837805496811, 943407.5784880484, 943407.5784880479, 195401.7936060465], 
processed observation next is [1.0, 0.08695652173913043, 0.35185185185185186, 0.9833333333333334, 1.0, 1.0, 0.7458934767664184, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8118371366807928, 0.33693127803144585, 0.3369312780314457, 0.3757726800116279], 
reward next is 0.6242, 
noisyNet noise sample is [array([0.4093947], dtype=float32), 1.0478418]. 
=============================================
[2019-03-22 23:26:54,072] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[69.52738]
 [69.50011]
 [69.74998]
 [70.09872]
 [70.3919 ]], R is [[68.87517548]
 [68.91452026]
 [68.95409393]
 [68.99397278]
 [69.0342865 ]].
[2019-03-22 23:26:55,903] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7086351e-36 1.0000000e+00 0.0000000e+00 1.3351052e-28 3.2323218e-26], sum to 1.0000
[2019-03-22 23:26:55,911] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4245
[2019-03-22 23:26:55,924] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1604343.574349336 W.
[2019-03-22 23:26:55,930] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.83333333333333, 72.33333333333334, 1.0, 2.0, 0.7802016399361745, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1604343.574349336, 1604343.574349336, 332328.7857843452], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4618200.0000, 
sim time next is 4618800.0000, 
raw observation next is [27.0, 71.0, 1.0, 2.0, 0.4437482460475615, 1.0, 1.0, 0.4437482460475615, 1.0, 2.0, 0.7064616595791541, 6.9112, 6.9112, 121.94756008, 1517954.87341424, 1517954.87341424, 316776.1887752704], 
processed observation next is [1.0, 0.4782608695652174, 0.5555555555555556, 0.71, 1.0, 1.0, 0.33779553100900184, 1.0, 0.5, 0.33779553100900184, 1.0, 1.0, 0.6330770744739425, 0.0, 0.0, 0.8096049824067558, 0.5421267405050857, 0.5421267405050857, 0.6091849784139816], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8014177], dtype=float32), 0.36953533]. 
=============================================
[2019-03-22 23:26:56,771] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2828461e-25 1.0000000e+00 2.2565415e-26 5.3391617e-21 8.5318064e-18], sum to 1.0000
[2019-03-22 23:26:56,782] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3205
[2019-03-22 23:26:56,790] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1781072.148811923 W.
[2019-03-22 23:26:56,795] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.1, 66.5, 1.0, 2.0, 0.5205864080978982, 1.0, 2.0, 0.5205864080978982, 1.0, 1.0, 0.8287905160075233, 6.911199999999999, 6.9112, 121.94756008, 1781072.148811923, 1781072.148811924, 353807.9887183802], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4627800.0000, 
sim time next is 4628400.0000, 
raw observation next is [29.23333333333333, 65.66666666666667, 1.0, 2.0, 0.5234136407151256, 1.0, 2.0, 0.5234136407151256, 1.0, 2.0, 0.8332915624106875, 6.911199999999999, 6.9112, 121.94756008, 1790754.598929828, 1790754.598929828, 355229.3396981574], 
processed observation next is [1.0, 0.5652173913043478, 0.6382716049382715, 0.6566666666666667, 1.0, 1.0, 0.4326352865656257, 1.0, 1.0, 0.4326352865656257, 1.0, 1.0, 0.7916144530133592, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.63955521390351, 0.63955521390351, 0.6831333455733796], 
reward next is 0.3169, 
noisyNet noise sample is [array([0.10630874], dtype=float32), -1.3516729]. 
=============================================
[2019-03-22 23:27:00,161] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-22 23:27:00,162] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:27:00,163] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:27:00,163] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:27:00,165] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:27:00,163] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:27:00,166] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:27:00,165] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:27:00,166] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:27:00,175] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:27:00,176] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:27:00,183] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run6
[2019-03-22 23:27:00,201] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run6
[2019-03-22 23:27:00,201] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run6
[2019-03-22 23:27:00,202] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run6
[2019-03-22 23:27:00,201] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run6
[2019-03-22 23:27:01,279] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.24256574], dtype=float32), 0.46140707]
[2019-03-22 23:27:01,279] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.83333333333334, 62.83333333333334, 1.0, 2.0, 0.3243747833042265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 418441.7347982461, 418441.7347982461, 112363.9637197247]
[2019-03-22 23:27:01,280] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:27:01,282] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.6160633e-24 1.0000000e+00 5.8884108e-25 9.4999574e-19 3.3313784e-19], sampled 0.18940671165039147
[2019-03-22 23:27:48,731] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.24256574], dtype=float32), 0.46140707]
[2019-03-22 23:27:48,732] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.75, 55.0, 1.0, 2.0, 0.7500682991957697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 854897.4991242032, 854897.4991242032, 185845.6424008517]
[2019-03-22 23:27:48,733] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:27:48,738] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.5988304e-38 1.0000000e+00 0.0000000e+00 5.4116435e-30 2.0488544e-31], sampled 0.538106571199655
[2019-03-22 23:28:02,471] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.24256574], dtype=float32), 0.46140707]
[2019-03-22 23:28:02,471] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.66191644, 51.79968998333334, 1.0, 2.0, 0.5810204302567005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 684184.2085965589, 684184.2085965589, 155851.9635816401]
[2019-03-22 23:28:02,473] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:28:02,476] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.0308900e-38 1.0000000e+00 0.0000000e+00 1.0772936e-29 7.3312987e-31], sampled 0.7005098223872611
[2019-03-22 23:28:03,146] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.24256574], dtype=float32), 0.46140707]
[2019-03-22 23:28:03,147] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.2, 66.0, 1.0, 2.0, 0.941580008885883, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1788549.86163724, 1788549.86163724, 366095.7262207177]
[2019-03-22 23:28:03,148] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:28:03,150] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.6720607e-33 1.0000000e+00 0.0000000e+00 2.3425505e-26 3.1158305e-26], sampled 0.3870704063452416
[2019-03-22 23:28:03,155] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1788549.86163724 W.
[2019-03-22 23:28:03,898] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.24256574], dtype=float32), 0.46140707]
[2019-03-22 23:28:03,898] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.99951432, 52.03189714, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.565936163720945, 6.9112, 121.9234542653759, 1498318.993487575, 1163042.675691638, 245585.5600118369]
[2019-03-22 23:28:03,899] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:28:03,904] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.8442751e-36 1.0000000e+00 0.0000000e+00 2.8693944e-28 1.3327384e-29], sampled 0.2411221247456966
[2019-03-22 23:28:03,906] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1498318.993487575 W.
[2019-03-22 23:28:06,126] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.24256574], dtype=float32), 0.46140707]
[2019-03-22 23:28:06,126] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.3, 80.0, 1.0, 2.0, 0.6079943875315943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696438.4746594977, 696438.4746594977, 159633.3958291828]
[2019-03-22 23:28:06,128] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:28:06,132] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.7824034e-32 1.2649607e-33], sampled 0.05258227943584792
[2019-03-22 23:28:24,773] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.24256574], dtype=float32), 0.46140707]
[2019-03-22 23:28:24,775] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.45, 43.5, 1.0, 2.0, 0.9953061074093141, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.520571921998561, 6.9112, 121.9235148168019, 1521857.29750962, 1209810.877954535, 243212.7369195896]
[2019-03-22 23:28:24,776] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:28:24,779] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.04342995e-33 1.00000000e+00 0.00000000e+00 4.99756252e-25
 4.16471873e-27], sampled 0.8918938475858864
[2019-03-22 23:28:24,780] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1521857.29750962 W.
[2019-03-22 23:28:30,435] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.24256574], dtype=float32), 0.46140707]
[2019-03-22 23:28:30,436] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.06666666666666, 86.33333333333333, 1.0, 2.0, 0.603041334747646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695524.3007758564, 695524.3007758564, 159004.2824974413]
[2019-03-22 23:28:30,437] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:28:30,442] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.9291751e-31 1.4957916e-32], sampled 0.7862881024408194
[2019-03-22 23:28:52,341] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0838 2170637693.1962 493.0000
[2019-03-22 23:28:52,420] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.9706 2445378853.1784 746.0000
[2019-03-22 23:28:52,506] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.6901 2195047582.3563 572.0000
[2019-03-22 23:28:52,524] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-22 23:28:52,650] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.1625 2120466133.0938 430.0000
[2019-03-22 23:28:53,665] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 125000, evaluation results [125000.0, 8099.970618414005, 2445378853.1783895, 746.0, 8771.08379319977, 2170637693.1962304, 493.0, 8924.162528137549, 2120466133.0938108, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.690060682284, 2195047582.3563175, 572.0]
[2019-03-22 23:28:59,446] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127661: loss -37.7727
[2019-03-22 23:28:59,452] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 127661: learning rate 0.0010
[2019-03-22 23:28:59,854] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 127847: loss -73.0627
[2019-03-22 23:28:59,858] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 127847: learning rate 0.0010
[2019-03-22 23:28:59,963] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 127896: loss -91.2668
[2019-03-22 23:28:59,967] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 127897: learning rate 0.0010
[2019-03-22 23:28:59,982] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 127903: loss -59.3192
[2019-03-22 23:28:59,987] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 127905: learning rate 0.0010
[2019-03-22 23:28:59,996] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 127908: loss -25.5794
[2019-03-22 23:28:59,998] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 127908: learning rate 0.0010
[2019-03-22 23:29:00,009] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 127913: loss -15.2889
[2019-03-22 23:29:00,012] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 127913: learning rate 0.0010
[2019-03-22 23:29:00,054] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 127934: loss -34.7955
[2019-03-22 23:29:00,056] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 127934: learning rate 0.0010
[2019-03-22 23:29:00,238] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 128019: loss 53.1220
[2019-03-22 23:29:00,240] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 128019: learning rate 0.0010
[2019-03-22 23:29:00,256] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 128025: loss -0.1123
[2019-03-22 23:29:00,259] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 128026: learning rate 0.0010
[2019-03-22 23:29:00,307] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 128049: loss -11.4078
[2019-03-22 23:29:00,308] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 128049: loss -13.0556
[2019-03-22 23:29:00,310] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 128049: learning rate 0.0010
[2019-03-22 23:29:00,312] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 128050: learning rate 0.0010
[2019-03-22 23:29:00,398] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 128088: loss -79.3689
[2019-03-22 23:29:00,401] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 128089: learning rate 0.0010
[2019-03-22 23:29:00,460] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 128116: loss -91.8945
[2019-03-22 23:29:00,464] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 128119: learning rate 0.0010
[2019-03-22 23:29:00,489] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 128130: loss -90.7930
[2019-03-22 23:29:00,492] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 128131: learning rate 0.0010
[2019-03-22 23:29:00,493] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 128131: loss 26.8310
[2019-03-22 23:29:00,495] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 128131: learning rate 0.0010
[2019-03-22 23:29:00,504] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 128137: loss -23.1016
[2019-03-22 23:29:00,507] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 128137: learning rate 0.0010
[2019-03-22 23:29:02,344] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.0646323e-30 1.0000000e+00 8.1810091e-35 1.1599327e-21 7.4054882e-20], sum to 1.0000
[2019-03-22 23:29:02,354] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4407
[2019-03-22 23:29:02,362] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.06666666666667, 92.33333333333333, 1.0, 2.0, 0.7102817568412787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 809526.4599810407, 809526.4599810407, 178100.9504440318], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4833600.0000, 
sim time next is 4834200.0000, 
raw observation next is [26.08333333333334, 92.16666666666667, 1.0, 2.0, 0.709582049442629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808728.5646687681, 808728.5646687681, 177967.2701681992], 
processed observation next is [1.0, 0.9565217391304348, 0.5216049382716051, 0.9216666666666667, 1.0, 1.0, 0.6542643445745584, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2888316302388457, 0.2888316302388457, 0.34224475032346], 
reward next is 0.6578, 
noisyNet noise sample is [array([-1.3158884], dtype=float32), 0.5093567]. 
=============================================
[2019-03-22 23:29:09,911] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0034736e-22 9.9999976e-01 1.3998171e-30 2.3058233e-07 3.5524162e-14], sum to 1.0000
[2019-03-22 23:29:09,919] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1503
[2019-03-22 23:29:09,930] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1405080.135948651 W.
[2019-03-22 23:29:09,935] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.6161721143090034, 1.0, 1.0, 0.6161721143090034, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9256910125804, 1405080.135948651, 1405080.135948652, 273648.6827051293], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4971600.0000, 
sim time next is 4972200.0000, 
raw observation next is [25.7, 90.0, 1.0, 2.0, 0.5885729783716014, 1.0, 2.0, 0.5885729783716014, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260425084473, 1342089.658093374, 1342089.658093373, 264134.2209460848], 
processed observation next is [1.0, 0.5652173913043478, 0.5074074074074074, 0.9, 1.0, 1.0, 0.5102059266328588, 1.0, 1.0, 0.5102059266328588, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621281083432, 0.47931773503334785, 0.4793177350333475, 0.5079504248963169], 
reward next is 0.4920, 
noisyNet noise sample is [array([0.6919358], dtype=float32), -1.2706343]. 
=============================================
[2019-03-22 23:29:11,188] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.2380370e-26 1.0000000e+00 2.1706761e-32 9.8059039e-17 1.8100345e-22], sum to 1.0000
[2019-03-22 23:29:11,196] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5837
[2019-03-22 23:29:11,202] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.6603334510250911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 752571.1394989771, 752571.1394989771, 168772.4737878468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4989600.0000, 
sim time next is 4990200.0000, 
raw observation next is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.6683032867126416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 761658.7424722443, 761658.7424722438, 170231.5408278625], 
processed observation next is [1.0, 0.782608695652174, 0.5493827160493825, 0.8483333333333333, 1.0, 1.0, 0.6051229603721924, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.272020979454373, 0.2720209794543728, 0.32736834774588947], 
reward next is 0.6726, 
noisyNet noise sample is [array([-0.8622337], dtype=float32), 0.7573254]. 
=============================================
[2019-03-22 23:29:16,907] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 135658: loss 1.2060
[2019-03-22 23:29:16,911] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 135660: learning rate 0.0010
[2019-03-22 23:29:17,310] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 135841: loss 2.5026
[2019-03-22 23:29:17,314] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 135842: learning rate 0.0010
[2019-03-22 23:29:17,363] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 135866: loss 2.1760
[2019-03-22 23:29:17,368] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 135867: learning rate 0.0010
[2019-03-22 23:29:17,388] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 135879: loss 2.0509
[2019-03-22 23:29:17,392] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 135880: learning rate 0.0010
[2019-03-22 23:29:17,444] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 135906: loss 1.8459
[2019-03-22 23:29:17,449] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 135907: learning rate 0.0010
[2019-03-22 23:29:17,453] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 135909: loss 1.4191
[2019-03-22 23:29:17,456] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 135909: learning rate 0.0010
[2019-03-22 23:29:17,509] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 135931: loss 1.4765
[2019-03-22 23:29:17,512] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 135933: learning rate 0.0010
[2019-03-22 23:29:17,604] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 135979: loss 1.6668
[2019-03-22 23:29:17,606] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 135980: learning rate 0.0010
[2019-03-22 23:29:17,780] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 136060: loss 2.1462
[2019-03-22 23:29:17,783] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 136060: learning rate 0.0010
[2019-03-22 23:29:17,787] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 136062: loss 1.6142
[2019-03-22 23:29:17,791] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 136063: learning rate 0.0010
[2019-03-22 23:29:17,797] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 136066: loss 2.0009
[2019-03-22 23:29:17,799] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 136066: learning rate 0.0010
[2019-03-22 23:29:17,866] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 136096: loss 2.0602
[2019-03-22 23:29:17,869] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 136097: learning rate 0.0010
[2019-03-22 23:29:17,894] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 136110: loss 2.4843
[2019-03-22 23:29:17,900] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 136111: learning rate 0.0010
[2019-03-22 23:29:17,913] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 136118: loss 2.4467
[2019-03-22 23:29:17,917] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 136119: learning rate 0.0010
[2019-03-22 23:29:17,935] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 136127: loss 2.3475
[2019-03-22 23:29:17,938] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 136130: learning rate 0.0010
[2019-03-22 23:29:17,985] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 136150: loss 1.7097
[2019-03-22 23:29:17,987] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 136150: learning rate 0.0010
[2019-03-22 23:29:24,527] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1561389e-24 1.0000000e+00 4.3914088e-27 1.6089122e-13 1.5528137e-20], sum to 1.0000
[2019-03-22 23:29:24,533] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8914
[2019-03-22 23:29:24,539] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1817729.675225894 W.
[2019-03-22 23:29:24,545] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5312900821113402, 1.0, 1.0, 0.5312900821113402, 1.0, 2.0, 0.845831113631249, 6.911200000000001, 6.9112, 121.94756008, 1817729.675225894, 1817729.675225894, 359211.9292433145], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5220000.0000, 
sim time next is 5220600.0000, 
raw observation next is [27.15, 82.16666666666667, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.433939010921118, 6.9112, 121.9242322253659, 2146043.1726005, 1878358.051845121, 382258.5665301372], 
processed observation next is [1.0, 0.43478260869565216, 0.561111111111111, 0.8216666666666668, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.05227390109211179, 0.0, 0.8094501097112443, 0.7664439902144642, 0.6708421613732575, 0.7351126279425716], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7016406], dtype=float32), -0.10188114]. 
=============================================
[2019-03-22 23:29:25,062] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6822739e-28 6.9635832e-20 3.0066187e-35 1.0000000e+00 1.6053435e-25], sum to 1.0000
[2019-03-22 23:29:25,074] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1673
[2019-03-22 23:29:25,084] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.75, 74.83333333333333, 1.0, 2.0, 0.8336693078042026, 1.0, 2.0, 0.8336693078042026, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1901606.228413956, 1901606.228413956, 357863.1494887609], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5223000.0000, 
sim time next is 5223600.0000, 
raw observation next is [27.9, 73.0, 1.0, 2.0, 0.8296982028494392, 1.0, 2.0, 0.8296982028494392, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1892538.509811252, 1892538.509811252, 356178.4962354809], 
processed observation next is [1.0, 0.4782608695652174, 0.5888888888888888, 0.73, 1.0, 1.0, 0.7972597652969514, 1.0, 1.0, 0.7972597652969514, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6759066106468756, 0.6759066106468756, 0.684958646606694], 
reward next is 0.3150, 
noisyNet noise sample is [array([0.8322839], dtype=float32), 0.20760836]. 
=============================================
[2019-03-22 23:29:29,404] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5406012e-37 1.0000000e+00 1.0550878e-36 1.7842157e-16 3.0497146e-29], sum to 1.0000
[2019-03-22 23:29:29,415] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1193
[2019-03-22 23:29:29,421] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.13333333333333, 92.33333333333334, 1.0, 2.0, 0.5333222047758803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640648.5271659299, 640648.5271659299, 148392.1895000489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5298000.0000, 
sim time next is 5298600.0000, 
raw observation next is [22.01666666666667, 92.66666666666666, 1.0, 2.0, 0.5058000232466445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 608460.7147585601, 608460.7147585601, 143994.0335407533], 
processed observation next is [1.0, 0.30434782608695654, 0.37098765432098774, 0.9266666666666665, 1.0, 1.0, 0.4116666943412435, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21730739812805716, 0.21730739812805716, 0.2769116029629871], 
reward next is 0.7231, 
noisyNet noise sample is [array([-1.3787941], dtype=float32), 0.26586702]. 
=============================================
[2019-03-22 23:29:32,559] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.7350712e-38 9.9980861e-01 1.3158878e-32 1.9143552e-04 9.1329683e-37], sum to 1.0000
[2019-03-22 23:29:32,571] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5679
[2019-03-22 23:29:32,578] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.48333333333333, 78.5, 1.0, 2.0, 0.6203204151498475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 711236.8510673959, 711236.8510673959, 161820.4223246805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5352600.0000, 
sim time next is 5353200.0000, 
raw observation next is [26.4, 79.0, 1.0, 2.0, 0.6190899250227945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 709921.6397188576, 709921.6397188576, 161608.8347323074], 
processed observation next is [1.0, 1.0, 0.5333333333333333, 0.79, 1.0, 1.0, 0.5465356250271363, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25354344275673485, 0.25354344275673485, 0.3107862206390527], 
reward next is 0.6892, 
noisyNet noise sample is [array([0.9699855], dtype=float32), 1.7580032]. 
=============================================
[2019-03-22 23:29:34,764] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 143813: loss -157.8498
[2019-03-22 23:29:34,765] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 143813: learning rate 0.0010
[2019-03-22 23:29:34,787] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 143821: loss -154.9092
[2019-03-22 23:29:34,790] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 143821: learning rate 0.0010
[2019-03-22 23:29:34,980] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 143906: loss 0.3865
[2019-03-22 23:29:34,983] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 143906: learning rate 0.0010
[2019-03-22 23:29:35,004] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 143915: loss -91.4211
[2019-03-22 23:29:35,006] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 143915: loss -67.8149
[2019-03-22 23:29:35,007] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 143915: learning rate 0.0010
[2019-03-22 23:29:35,008] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 143916: learning rate 0.0010
[2019-03-22 23:29:35,058] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 143938: loss -51.3743
[2019-03-22 23:29:35,061] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 143938: learning rate 0.0010
[2019-03-22 23:29:35,161] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 143986: loss -20.4313
[2019-03-22 23:29:35,164] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 143986: learning rate 0.0010
[2019-03-22 23:29:35,186] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 143996: loss -46.1104
[2019-03-22 23:29:35,188] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 143996: learning rate 0.0010
[2019-03-22 23:29:35,280] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 144040: loss 0.7121
[2019-03-22 23:29:35,284] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 144040: learning rate 0.0010
[2019-03-22 23:29:35,303] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 144049: loss -7.1948
[2019-03-22 23:29:35,306] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 144051: loss -18.0586
[2019-03-22 23:29:35,307] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 144051: learning rate 0.0010
[2019-03-22 23:29:35,308] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 144051: learning rate 0.0010
[2019-03-22 23:29:35,353] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 144071: loss -7.4242
[2019-03-22 23:29:35,354] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 144071: learning rate 0.0010
[2019-03-22 23:29:35,354] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 144071: loss -25.1194
[2019-03-22 23:29:35,357] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 144071: learning rate 0.0010
[2019-03-22 23:29:35,393] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 144088: loss 55.4624
[2019-03-22 23:29:35,395] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 144088: learning rate 0.0010
[2019-03-22 23:29:35,395] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 144088: loss 23.6484
[2019-03-22 23:29:35,399] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 144088: learning rate 0.0010
[2019-03-22 23:29:35,442] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 144108: loss 22.5107
[2019-03-22 23:29:35,444] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 144109: learning rate 0.0010
[2019-03-22 23:29:35,977] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.0555517e-35 1.0000000e+00 1.1720492e-35 2.0487893e-26 5.3601978e-30], sum to 1.0000
[2019-03-22 23:29:35,983] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9626
[2019-03-22 23:29:35,990] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.8, 73.5, 1.0, 2.0, 0.6828839023345173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.926042615639, 778284.5643275917, 778284.5643275912, 172935.9405586504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5419800.0000, 
sim time next is 5420400.0000, 
raw observation next is [29.73333333333333, 74.0, 1.0, 2.0, 0.6931546285121246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 789996.1699744429, 789996.1699744429, 174858.7836582968], 
processed observation next is [1.0, 0.7391304347826086, 0.65679012345679, 0.74, 1.0, 1.0, 0.6347078910858627, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2821414892765868, 0.2821414892765868, 0.3362668916505708], 
reward next is 0.6637, 
noisyNet noise sample is [array([-1.498666], dtype=float32), 0.75989884]. 
=============================================
[2019-03-22 23:29:38,916] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 1.3310563e-37 7.7439852e-31 1.4083079e-36], sum to 1.0000
[2019-03-22 23:29:38,923] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0502
[2019-03-22 23:29:38,928] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.15, 94.5, 1.0, 2.0, 0.8283836227333559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 944213.1227147543, 944213.1227147543, 201876.3314903781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5459400.0000, 
sim time next is 5460000.0000, 
raw observation next is [26.13333333333333, 94.66666666666666, 1.0, 2.0, 0.816759517126393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 930955.6181218252, 930955.6181218252, 199429.2742737081], 
processed observation next is [1.0, 0.17391304347826086, 0.5234567901234567, 0.9466666666666665, 1.0, 1.0, 0.7818565680076107, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33248414932922327, 0.33248414932922327, 0.38351783514174637], 
reward next is 0.6165, 
noisyNet noise sample is [array([0.44924334], dtype=float32), -0.74704707]. 
=============================================
[2019-03-22 23:29:38,938] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[53.72585 ]
 [53.58608 ]
 [53.261986]
 [53.555317]
 [53.75215 ]], R is [[53.73696136]
 [53.81136703]
 [53.88220978]
 [53.90912628]
 [53.93809891]].
[2019-03-22 23:29:39,195] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.3548567e-34 1.2048273e-38], sum to 1.0000
[2019-03-22 23:29:39,204] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3006
[2019-03-22 23:29:39,208] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333333, 92.16666666666667, 1.0, 2.0, 0.8877424738357537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1011916.552038062, 1011916.552038062, 214742.4420913097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5471400.0000, 
sim time next is 5472000.0000, 
raw observation next is [27.4, 92.0, 1.0, 2.0, 0.9115813774102135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1039108.376563733, 1039108.376563733, 220079.6289754228], 
processed observation next is [1.0, 0.34782608695652173, 0.5703703703703703, 0.92, 1.0, 1.0, 0.894739735012159, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3711101344870475, 0.3711101344870475, 0.4232300557219669], 
reward next is 0.5768, 
noisyNet noise sample is [array([0.3881118], dtype=float32), -0.6516819]. 
=============================================
[2019-03-22 23:29:39,222] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[55.356136]
 [55.279675]
 [55.28268 ]
 [55.43234 ]
 [55.570072]], R is [[55.3808403 ]
 [55.41406631]
 [55.44205856]
 [55.45506287]
 [55.48907471]].
[2019-03-22 23:29:40,395] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1341071e-34 1.0000000e+00 1.0951727e-37 3.2812751e-23 1.8794543e-30], sum to 1.0000
[2019-03-22 23:29:40,404] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0803
[2019-03-22 23:29:40,411] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2435520.467555193 W.
[2019-03-22 23:29:40,415] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.84999999999999, 66.0, 1.0, 2.0, 0.7964976083028803, 1.0, 2.0, 0.7116134661278748, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2435520.467555193, 2435520.467555193, 456177.1798718996], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5491800.0000, 
sim time next is 5492400.0000, 
raw observation next is [33.03333333333333, 65.0, 1.0, 2.0, 0.74073642192565, 1.0, 2.0, 0.6837328729392597, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2339973.173083852, 2339973.173083852, 440366.0204084307], 
processed observation next is [1.0, 0.5652173913043478, 0.7790123456790122, 0.65, 1.0, 1.0, 0.6913528832448215, 1.0, 1.0, 0.6234915154038805, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.8357047046728043, 0.8357047046728043, 0.8468577315546745], 
reward next is 0.1531, 
noisyNet noise sample is [array([-0.93929476], dtype=float32), 0.5110512]. 
=============================================
[2019-03-22 23:29:45,437] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.2028353e-31 1.0000000e+00 5.5064710e-32 2.3429051e-21 3.2923013e-20], sum to 1.0000
[2019-03-22 23:29:45,444] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6486
[2019-03-22 23:29:45,453] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1772286.820463446 W.
[2019-03-22 23:29:45,460] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.43333333333333, 77.33333333333334, 1.0, 2.0, 0.5180211045562495, 1.0, 2.0, 0.5180211045562495, 1.0, 2.0, 0.8247064692231149, 6.9112, 6.9112, 121.94756008, 1772286.820463446, 1772286.820463446, 352522.0645973017], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5574000.0000, 
sim time next is 5574600.0000, 
raw observation next is [28.65, 77.0, 1.0, 2.0, 0.8568698852905746, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1691852.25727054, 1691852.25727054, 347814.1377564979], 
processed observation next is [1.0, 0.5217391304347826, 0.6166666666666666, 0.77, 1.0, 1.0, 0.8296070062983031, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6042329490251929, 0.6042329490251929, 0.668873341839419], 
reward next is 0.3311, 
noisyNet noise sample is [array([0.12470724], dtype=float32), 0.91699183]. 
=============================================
[2019-03-22 23:29:45,701] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6386368e-25 1.0000000e+00 7.0460152e-28 9.5799002e-21 2.6698447e-17], sum to 1.0000
[2019-03-22 23:29:45,713] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4427
[2019-03-22 23:29:45,719] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2452486.974931376 W.
[2019-03-22 23:29:45,723] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.6, 76.5, 1.0, 2.0, 0.8063985999669381, 1.0, 2.0, 0.7165639619599038, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2452486.974931376, 2452486.974931376, 459054.8945294881], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5581800.0000, 
sim time next is 5582400.0000, 
raw observation next is [29.3, 77.33333333333333, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 7.677035782552629, 6.9112, 121.9230032847568, 2719859.827016256, 2327693.232762912, 443049.151955411], 
processed observation next is [1.0, 0.6086956521739131, 0.6407407407407407, 0.7733333333333333, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.25, 0.0765835782552629, 0.0, 0.8094419508236081, 0.9713785096486628, 0.83131901170104, 0.852017599914252], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3160534], dtype=float32), 0.6314377]. 
=============================================
[2019-03-22 23:29:48,110] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:29:48,119] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1610
[2019-03-22 23:29:48,125] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 97.33333333333333, 1.0, 2.0, 0.5982115962947225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690046.3545029548, 690046.3545029548, 158173.8431753124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5618400.0000, 
sim time next is 5619000.0000, 
raw observation next is [23.6, 97.16666666666667, 1.0, 2.0, 0.5974881480415504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 689523.9733779839, 689523.9733779839, 158063.8456803849], 
processed observation next is [0.0, 0.0, 0.4296296296296297, 0.9716666666666667, 1.0, 1.0, 0.5208192238589885, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24625856192070852, 0.24625856192070852, 0.3039689340007402], 
reward next is 0.6960, 
noisyNet noise sample is [array([-0.35767415], dtype=float32), 0.6832921]. 
=============================================
[2019-03-22 23:29:48,141] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.872  ]
 [73.74822]
 [73.6495 ]
 [73.73588]
 [74.19262]], R is [[73.97297668]
 [73.92906189]
 [73.88523865]
 [73.84136963]
 [73.79737854]].
[2019-03-22 23:29:48,375] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-22 23:29:48,377] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:29:48,379] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:29:48,380] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:29:48,381] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:29:48,382] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:29:48,383] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:29:48,384] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:29:48,384] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:29:48,382] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:29:48,388] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:29:48,400] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run7
[2019-03-22 23:29:48,417] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run7
[2019-03-22 23:29:48,433] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run7
[2019-03-22 23:29:48,451] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run7
[2019-03-22 23:29:48,472] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run7
[2019-03-22 23:29:53,421] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:29:53,423] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.6, 33.0, 1.0, 2.0, 0.2930715895212923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 378050.8289727205, 378050.8289727205, 101922.6246618581]
[2019-03-22 23:29:53,424] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:29:53,426] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.658862160006063
[2019-03-22 23:30:06,912] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:30:06,914] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.39478754666667, 91.19592807666666, 1.0, 2.0, 0.3122202638027583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396346.8772291243, 396346.8772291243, 117087.8479695335]
[2019-03-22 23:30:06,915] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:30:06,918] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4903688685527907
[2019-03-22 23:30:19,771] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:30:19,773] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.91666666666667, 45.5, 1.0, 2.0, 0.5471608350031429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639865.7078387914, 639865.7078387914, 149988.087055216]
[2019-03-22 23:30:19,773] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:30:19,775] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6714268405633366
[2019-03-22 23:30:22,076] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:30:22,079] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.39437055, 96.09727047, 1.0, 2.0, 0.4704181283130539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 566261.373452895, 566261.373452895, 138506.6665728815]
[2019-03-22 23:30:22,081] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:30:22,084] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.22686758361046744
[2019-03-22 23:30:22,801] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:30:22,802] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.73124498, 62.17211197, 1.0, 2.0, 0.5429697114093027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638800.9859060991, 638800.9859060991, 149461.5126203079]
[2019-03-22 23:30:22,802] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:30:22,804] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9975974674900285
[2019-03-22 23:30:29,463] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:30:29,466] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.26782735333333, 92.60434318666667, 1.0, 2.0, 0.6822088764280185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 785783.5183936988, 785783.5183936988, 173213.9295851691]
[2019-03-22 23:30:29,468] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:30:29,469] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8732076173526775
[2019-03-22 23:30:39,509] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:30:39,510] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.25, 72.0, 1.0, 2.0, 0.5647474334950642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652371.6480104356, 652371.6480104356, 152544.9555107396]
[2019-03-22 23:30:39,511] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:30:39,514] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.878980394452077
[2019-03-22 23:30:40,815] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:30:40,818] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.24782463666667, 78.66522575666667, 1.0, 2.0, 0.5056472667199053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602278.2067668727, 602278.2067668727, 143753.8587938268]
[2019-03-22 23:30:40,820] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:30:40,824] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6258279699133661
[2019-03-22 23:30:40,991] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:30:40,992] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.25, 52.33333333333333, 1.0, 2.0, 0.5274097096596009, 0.0, 2.0, 0.0, 1.0, 1.0, 0.839653434313172, 6.9112, 6.9112, 121.9257996526358, 1202513.048241215, 1202513.048241215, 266681.0362484108]
[2019-03-22 23:30:40,992] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:30:40,995] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0.0000000e+00 1.0000000e+00 2.3846974e-37 2.8208174e-35 3.0226727e-35], sampled 0.873211640587039
[2019-03-22 23:31:03,044] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:31:03,045] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.1, 86.33333333333334, 1.0, 2.0, 0.7289552072607337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 830820.6085206355, 830820.608520635, 181700.0192477321]
[2019-03-22 23:31:03,047] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:31:03,049] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7762560629839654
[2019-03-22 23:31:32,652] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.3847974], dtype=float32), 0.45371625]
[2019-03-22 23:31:32,652] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.12113276, 71.76201977, 1.0, 2.0, 0.5512420643115091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640594.9659184369, 640594.9659184369, 150483.9743594181]
[2019-03-22 23:31:32,653] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:31:32,658] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.48825416233761065
[2019-03-22 23:31:38,710] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2399 2120425912.2928 430.0000
[2019-03-22 23:31:39,136] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.6619 2445343923.2757 746.0000
[2019-03-22 23:31:39,284] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0845 2170631810.8436 493.0000
[2019-03-22 23:31:39,286] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7013 2248693483.9672 553.0000
[2019-03-22 23:31:39,362] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-22 23:31:40,378] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 150000, evaluation results [150000.0, 8100.661928194693, 2445343923.2757144, 746.0, 8771.084470098069, 2170631810.843588, 493.0, 8924.239875831723, 2120425912.2928398, 430.0, 8583.701325530239, 2248693483.9671583, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-22 23:31:41,146] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7529198e-38 0.0000000e+00], sum to 1.0000
[2019-03-22 23:31:41,156] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2704
[2019-03-22 23:31:41,164] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.26666666666667, 95.83333333333333, 1.0, 2.0, 0.6282126213237692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717219.674622882, 717219.674622882, 163061.7969178535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5641800.0000, 
sim time next is 5642400.0000, 
raw observation next is [24.33333333333334, 95.66666666666666, 1.0, 2.0, 0.6315028945720793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 720224.5809745941, 720224.5809745941, 163607.1322121412], 
processed observation next is [0.0, 0.30434782608695654, 0.4567901234567903, 0.9566666666666666, 1.0, 1.0, 0.5613129697286658, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2572230646337836, 0.2572230646337836, 0.3146291004079639], 
reward next is 0.6854, 
noisyNet noise sample is [array([-0.48784202], dtype=float32), -0.4308748]. 
=============================================
[2019-03-22 23:31:43,016] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4929367e-38 0.0000000e+00], sum to 1.0000
[2019-03-22 23:31:43,019] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2325
[2019-03-22 23:31:43,024] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.65, 66.0, 1.0, 2.0, 0.7188922886172006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819345.3507572464, 819345.3507572464, 179754.4587506498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5675400.0000, 
sim time next is 5676000.0000, 
raw observation next is [30.73333333333333, 65.66666666666666, 1.0, 2.0, 0.722934523462194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823954.896026817, 823954.896026817, 180534.3265788479], 
processed observation next is [0.0, 0.6956521739130435, 0.6938271604938271, 0.6566666666666666, 1.0, 1.0, 0.6701601469788023, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29426960572386324, 0.29426960572386324, 0.3471813972670152], 
reward next is 0.6528, 
noisyNet noise sample is [array([0.92258584], dtype=float32), 0.64409393]. 
=============================================
[2019-03-22 23:31:43,055] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[65.4192  ]
 [65.410515]
 [65.36268 ]
 [65.281906]
 [65.212296]], R is [[65.43283081]
 [65.43282318]
 [65.43678284]
 [65.44013214]
 [65.44015503]].
[2019-03-22 23:31:44,206] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 151752: loss 0.2335
[2019-03-22 23:31:44,208] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 151752: learning rate 0.0010
[2019-03-22 23:31:44,281] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 151786: loss 0.1079
[2019-03-22 23:31:44,283] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 151787: learning rate 0.0010
[2019-03-22 23:31:44,392] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 151836: loss 0.0011
[2019-03-22 23:31:44,393] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 151836: learning rate 0.0010
[2019-03-22 23:31:44,427] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 151853: loss 0.0013
[2019-03-22 23:31:44,429] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 151853: learning rate 0.0010
[2019-03-22 23:31:44,482] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 151876: loss 0.0538
[2019-03-22 23:31:44,485] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 151877: learning rate 0.0010
[2019-03-22 23:31:44,596] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 151928: loss 0.0612
[2019-03-22 23:31:44,599] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 151929: learning rate 0.0010
[2019-03-22 23:31:44,704] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 151975: loss 0.0070
[2019-03-22 23:31:44,710] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 151975: learning rate 0.0010
[2019-03-22 23:31:44,828] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 152034: loss 0.0012
[2019-03-22 23:31:44,833] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 152035: learning rate 0.0010
[2019-03-22 23:31:44,834] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 152035: loss 0.0041
[2019-03-22 23:31:44,838] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 152037: learning rate 0.0010
[2019-03-22 23:31:44,872] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 152052: loss 0.0170
[2019-03-22 23:31:44,874] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 152054: learning rate 0.0010
[2019-03-22 23:31:44,908] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 152070: loss 0.0112
[2019-03-22 23:31:44,913] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 152071: learning rate 0.0010
[2019-03-22 23:31:44,914] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 152072: loss 0.0079
[2019-03-22 23:31:44,919] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 152072: learning rate 0.0010
[2019-03-22 23:31:44,932] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 152081: loss 0.0082
[2019-03-22 23:31:44,935] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 152081: learning rate 0.0010
[2019-03-22 23:31:44,969] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 152096: loss 0.0018
[2019-03-22 23:31:44,971] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 152096: learning rate 0.0010
[2019-03-22 23:31:45,029] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 152123: loss 0.0056
[2019-03-22 23:31:45,031] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 152123: learning rate 0.0010
[2019-03-22 23:31:45,192] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 152195: loss 0.0525
[2019-03-22 23:31:45,196] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 152196: learning rate 0.0010
[2019-03-22 23:31:51,865] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 3.5201845e-32 0.0000000e+00], sum to 1.0000
[2019-03-22 23:31:51,872] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5241
[2019-03-22 23:31:51,880] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 51.66666666666667, 1.0, 2.0, 0.8038611481686216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1002318.159794572, 1002318.159794572, 200159.3302327861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5826000.0000, 
sim time next is 5826600.0000, 
raw observation next is [25.9, 50.0, 1.0, 2.0, 0.8053030910823387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1005886.322428261, 1005886.322428261, 200504.2384916426], 
processed observation next is [1.0, 0.43478260869565216, 0.5148148148148147, 0.5, 1.0, 1.0, 0.7682179655742127, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3592451151529504, 0.3592451151529504, 0.3855850740223896], 
reward next is 0.6144, 
noisyNet noise sample is [array([2.0361507], dtype=float32), -0.21695021]. 
=============================================
[2019-03-22 23:31:58,542] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.6045009e-28 9.9958140e-01 4.3427081e-32 4.1862583e-04 1.0737697e-30], sum to 1.0000
[2019-03-22 23:31:58,555] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7862
[2019-03-22 23:31:58,561] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.73333333333333, 56.33333333333334, 1.0, 2.0, 0.4740464296506099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 569902.0110335622, 569902.0110335627, 139036.682285836], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5941200.0000, 
sim time next is 5941800.0000, 
raw observation next is [27.6, 57.0, 1.0, 2.0, 0.4747518853705425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 570753.6246261043, 570753.6246261043, 139144.7125674069], 
processed observation next is [1.0, 0.782608695652174, 0.5777777777777778, 0.57, 1.0, 1.0, 0.3747046254411221, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20384058022360865, 0.20384058022360865, 0.26758598570655173], 
reward next is 0.7324, 
noisyNet noise sample is [array([-0.5502019], dtype=float32), 0.73380125]. 
=============================================
[2019-03-22 23:32:01,770] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 159774: loss -187.1606
[2019-03-22 23:32:01,772] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 159774: learning rate 0.0010
[2019-03-22 23:32:01,981] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 159871: loss -125.6740
[2019-03-22 23:32:01,983] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 159871: learning rate 0.0010
[2019-03-22 23:32:01,998] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 159876: loss -130.0235
[2019-03-22 23:32:01,999] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 159876: learning rate 0.0010
[2019-03-22 23:32:02,016] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 159884: loss -93.3094
[2019-03-22 23:32:02,017] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 159885: learning rate 0.0010
[2019-03-22 23:32:02,022] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 159885: loss -102.3933
[2019-03-22 23:32:02,024] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 159885: learning rate 0.0010
[2019-03-22 23:32:02,092] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 159913: loss 0.2254
[2019-03-22 23:32:02,094] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 159913: learning rate 0.0010
[2019-03-22 23:32:02,135] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 159935: loss 0.2084
[2019-03-22 23:32:02,136] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 159935: learning rate 0.0010
[2019-03-22 23:32:02,356] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 160037: loss 1.9106
[2019-03-22 23:32:02,358] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 160037: learning rate 0.0010
[2019-03-22 23:32:02,380] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 160043: loss -3.9681
[2019-03-22 23:32:02,383] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 160044: learning rate 0.0010
[2019-03-22 23:32:02,401] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 160050: loss -63.3220
[2019-03-22 23:32:02,404] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 160050: learning rate 0.0010
[2019-03-22 23:32:02,420] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 160056: loss -20.2292
[2019-03-22 23:32:02,423] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 160058: learning rate 0.0010
[2019-03-22 23:32:02,424] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 160059: loss 1.3411
[2019-03-22 23:32:02,427] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 160060: learning rate 0.0010
[2019-03-22 23:32:02,442] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 160063: loss 0.5983
[2019-03-22 23:32:02,445] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 160064: learning rate 0.0010
[2019-03-22 23:32:02,548] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 160116: loss 1.6884
[2019-03-22 23:32:02,548] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 160116: loss 1.3116
[2019-03-22 23:32:02,549] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 160117: learning rate 0.0010
[2019-03-22 23:32:02,551] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 160117: learning rate 0.0010
[2019-03-22 23:32:02,561] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 160120: loss -37.5306
[2019-03-22 23:32:02,564] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 160120: learning rate 0.0010
[2019-03-22 23:32:02,660] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7422441e-31 2.7649367e-05 4.5273415e-37 9.9997234e-01 1.2534838e-33], sum to 1.0000
[2019-03-22 23:32:02,667] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5439
[2019-03-22 23:32:02,674] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 59.5, 1.0, 2.0, 0.7231675266406471, 1.0, 2.0, 0.7231675266406471, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426154101, 1649318.098877519, 1649318.098877519, 313027.3471798752], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6011400.0000, 
sim time next is 6012000.0000, 
raw observation next is [29.0, 59.0, 1.0, 2.0, 0.7817021974125081, 1.0, 2.0, 0.7817021974125081, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156617, 1782950.531578745, 1782950.531578745, 336249.9283723101], 
processed observation next is [1.0, 0.6086956521739131, 0.6296296296296297, 0.59, 1.0, 1.0, 0.7401216635863191, 1.0, 1.0, 0.7401216635863191, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201352, 0.636768046992409, 0.636768046992409, 0.6466344776390579], 
reward next is 0.3534, 
noisyNet noise sample is [array([-0.92159027], dtype=float32), 1.7729465]. 
=============================================
[2019-03-22 23:32:02,694] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[64.87726 ]
 [63.439705]
 [63.011047]
 [65.115166]
 [68.48212 ]], R is [[64.93096924]
 [64.6796875 ]
 [64.03289032]
 [63.39256287]
 [62.75863647]].
[2019-03-22 23:32:05,162] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.782821e-38 1.000000e+00 0.000000e+00 1.980223e-13 0.000000e+00], sum to 1.0000
[2019-03-22 23:32:05,170] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9384
[2019-03-22 23:32:05,177] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 91.0, 1.0, 2.0, 0.4944364172215576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593097.8772030988, 593097.8772030988, 142145.2855194043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6055200.0000, 
sim time next is 6055800.0000, 
raw observation next is [22.45, 90.66666666666667, 1.0, 2.0, 0.7920870009217411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 122.280556667847, 950016.345366759, 950016.345366759, 196553.8461358111], 
processed observation next is [1.0, 0.08695652173913043, 0.387037037037037, 0.9066666666666667, 1.0, 1.0, 0.7524845249068346, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8118157334580152, 0.33929155191669963, 0.33929155191669963, 0.3779881656457906], 
reward next is 0.6220, 
noisyNet noise sample is [array([0.15863314], dtype=float32), -1.1520038]. 
=============================================
[2019-03-22 23:32:14,055] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5896019e-26 9.9999964e-01 8.0348818e-32 3.0655463e-07 5.2118056e-26], sum to 1.0000
[2019-03-22 23:32:14,065] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0955
[2019-03-22 23:32:14,070] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.41666666666667, 55.16666666666667, 1.0, 2.0, 0.5223675300161863, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 611975.0662026751, 611975.0662026746, 146013.4621743657], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6198600.0000, 
sim time next is 6199200.0000, 
raw observation next is [29.3, 56.0, 1.0, 2.0, 0.5301970273119437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622167.1396483212, 622167.1396483212, 147315.9970237608], 
processed observation next is [1.0, 0.782608695652174, 0.6407407407407407, 0.56, 1.0, 1.0, 0.440710746799933, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22220254987440044, 0.22220254987440044, 0.2832999942764631], 
reward next is 0.7167, 
noisyNet noise sample is [array([0.4364397], dtype=float32), 0.009818258]. 
=============================================
[2019-03-22 23:32:18,951] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0176290e-38 1.0000000e+00 1.0353799e-35 2.7660102e-16 1.9317422e-34], sum to 1.0000
[2019-03-22 23:32:18,961] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2507
[2019-03-22 23:32:18,967] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.18333333333333, 60.33333333333333, 1.0, 2.0, 0.6521165981723992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 743201.9880683129, 743201.9880683129, 167275.4296920089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6282600.0000, 
sim time next is 6283200.0000, 
raw observation next is [30.06666666666667, 60.66666666666667, 1.0, 2.0, 0.6413143619158926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 730885.0636366272, 730885.0636366272, 165330.2775783702], 
processed observation next is [0.0, 0.7391304347826086, 0.669135802469136, 0.6066666666666667, 1.0, 1.0, 0.5729932879951103, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.261030379870224, 0.261030379870224, 0.3179428414968658], 
reward next is 0.6821, 
noisyNet noise sample is [array([-0.30950978], dtype=float32), -0.73274976]. 
=============================================
[2019-03-22 23:32:19,461] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 167831: loss 0.1043
[2019-03-22 23:32:19,465] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 167832: learning rate 0.0010
[2019-03-22 23:32:19,492] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 167844: loss 0.1563
[2019-03-22 23:32:19,495] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 167845: learning rate 0.0010
[2019-03-22 23:32:19,519] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 167858: loss 0.1012
[2019-03-22 23:32:19,521] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 167858: learning rate 0.0010
[2019-03-22 23:32:19,569] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 167880: loss 0.0636
[2019-03-22 23:32:19,571] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 167880: learning rate 0.0010
[2019-03-22 23:32:19,651] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 167917: loss 0.0092
[2019-03-22 23:32:19,653] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 167917: learning rate 0.0010
[2019-03-22 23:32:19,700] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 167939: loss 0.0066
[2019-03-22 23:32:19,704] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 167941: learning rate 0.0010
[2019-03-22 23:32:19,715] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 167948: loss 0.0009
[2019-03-22 23:32:19,717] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 167949: learning rate 0.0010
[2019-03-22 23:32:19,738] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 167960: loss 0.0305
[2019-03-22 23:32:19,740] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 167960: learning rate 0.0010
[2019-03-22 23:32:19,840] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 168000: loss 0.0128
[2019-03-22 23:32:19,843] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 168000: learning rate 0.0010
[2019-03-22 23:32:19,913] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 168039: loss 0.0038
[2019-03-22 23:32:19,917] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 168039: learning rate 0.0010
[2019-03-22 23:32:19,937] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 168046: loss 0.0014
[2019-03-22 23:32:19,939] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 168047: learning rate 0.0010
[2019-03-22 23:32:19,946] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 168051: loss 0.0078
[2019-03-22 23:32:19,947] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 168051: learning rate 0.0010
[2019-03-22 23:32:19,973] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 168059: loss 0.0114
[2019-03-22 23:32:19,976] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 168060: learning rate 0.0010
[2019-03-22 23:32:20,097] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 168120: loss 0.0639
[2019-03-22 23:32:20,100] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 168121: learning rate 0.0010
[2019-03-22 23:32:20,126] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 168132: loss 0.0957
[2019-03-22 23:32:20,129] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 168132: learning rate 0.0010
[2019-03-22 23:32:20,278] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 168202: loss 0.0058
[2019-03-22 23:32:20,285] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 168202: learning rate 0.0010
[2019-03-22 23:32:25,648] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2507959e-33 1.0000000e+00 1.9556468e-34 1.9285163e-20 2.9646032e-36], sum to 1.0000
[2019-03-22 23:32:25,657] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3360
[2019-03-22 23:32:25,662] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.65, 82.5, 1.0, 2.0, 0.6825589677407253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777914.0476021738, 777914.0476021738, 172866.6964049963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6395400.0000, 
sim time next is 6396000.0000, 
raw observation next is [26.53333333333333, 83.0, 1.0, 2.0, 0.6792880249236382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774184.2638142337, 774184.2638142337, 172258.1782375922], 
processed observation next is [1.0, 0.0, 0.5382716049382715, 0.83, 1.0, 1.0, 0.6182000296709977, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2764943799336549, 0.2764943799336549, 0.331265727379985], 
reward next is 0.6687, 
noisyNet noise sample is [array([-0.59035283], dtype=float32), -0.024614295]. 
=============================================
[2019-03-22 23:32:25,676] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[53.07899 ]
 [53.52016 ]
 [54.15305 ]
 [54.982807]
 [56.150913]], R is [[52.88230515]
 [53.02104568]
 [53.158535  ]
 [53.29704285]
 [53.42892838]].
[2019-03-22 23:32:32,839] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2442220e-21 3.8757525e-23 1.9658594e-31 1.0000000e+00 2.2588342e-32], sum to 1.0000
[2019-03-22 23:32:32,850] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5817
[2019-03-22 23:32:32,856] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.2, 80.0, 1.0, 2.0, 0.8913299482844852, 1.0, 2.0, 0.8913299482844852, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2033280.326082734, 2033280.326082734, 382939.3162911995], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6523200.0000, 
sim time next is 6523800.0000, 
raw observation next is [28.1, 80.0, 1.0, 2.0, 0.9018274859205648, 1.0, 2.0, 0.9018274859205648, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2057254.639395896, 2057254.639395896, 387628.2970910157], 
processed observation next is [1.0, 0.5217391304347826, 0.5962962962962963, 0.8, 1.0, 1.0, 0.8831279594292438, 1.0, 1.0, 0.8831279594292438, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7347337997842486, 0.7347337997842486, 0.7454390328673378], 
reward next is 0.2546, 
noisyNet noise sample is [array([-0.81508136], dtype=float32), 0.35976067]. 
=============================================
[2019-03-22 23:32:33,539] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1618867e-15 3.2648233e-05 3.4652340e-23 9.9996734e-01 8.6079088e-22], sum to 1.0000
[2019-03-22 23:32:33,547] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3825
[2019-03-22 23:32:33,551] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.53333333333333, 79.33333333333334, 1.0, 2.0, 0.7645997379680646, 1.0, 2.0, 0.7645997379680646, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1743904.19833085, 1743904.19833085, 329343.6225649785], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6536400.0000, 
sim time next is 6537000.0000, 
raw observation next is [27.56666666666667, 79.16666666666667, 1.0, 2.0, 0.776935686102873, 1.0, 2.0, 0.776935686102873, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1772068.01940584, 1772068.019405842, 334316.0863518302], 
processed observation next is [1.0, 0.6521739130434783, 0.5765432098765433, 0.7916666666666667, 1.0, 1.0, 0.734447245360563, 1.0, 1.0, 0.734447245360563, 0.0, 1.0, -0.25, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.6328814355020858, 0.6328814355020864, 0.6429155506765966], 
reward next is 0.3571, 
noisyNet noise sample is [array([0.19622435], dtype=float32), -0.7348742]. 
=============================================
[2019-03-22 23:32:33,567] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[39.665665]
 [39.962055]
 [40.029682]
 [39.96048 ]
 [39.743088]], R is [[39.41401672]
 [39.3865242 ]
 [39.39054489]
 [39.39698792]
 [39.41317368]].
[2019-03-22 23:32:35,162] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-22 23:32:35,164] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:32:35,165] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:32:35,165] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:32:35,167] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:32:35,169] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:32:35,171] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:32:35,172] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:32:35,173] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:32:35,174] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:32:35,176] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:32:35,190] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run8
[2019-03-22 23:32:35,191] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run8
[2019-03-22 23:32:35,224] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run8
[2019-03-22 23:32:35,243] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run8
[2019-03-22 23:32:35,258] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run8
[2019-03-22 23:32:40,987] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:32:40,988] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.0, 56.0, 1.0, 2.0, 0.2348585627504608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 302943.4820554657, 302943.4820554657, 92494.09984015652]
[2019-03-22 23:32:40,989] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:32:40,995] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0070748e-37 1.0000000e+00 9.5206268e-36 2.7962602e-21 5.8616663e-35], sampled 0.7241366162474194
[2019-03-22 23:32:42,080] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:32:42,081] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 33.0, 1.0, 2.0, 0.2879252146292923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 371410.6001438839, 371410.6001438839, 103433.2498372609]
[2019-03-22 23:32:42,083] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:32:42,087] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.5295845e-37 1.0000000e+00 2.7919862e-36 2.9782522e-20 3.2617867e-35], sampled 0.5309729992547801
[2019-03-22 23:32:46,885] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:32:46,886] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.26482579666667, 27.37354179333333, 1.0, 2.0, 0.3648860816227769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 460949.2049862284, 460949.2049862284, 123935.4759661467]
[2019-03-22 23:32:46,887] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:32:46,890] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.3074640e-34 1.0000000e+00 1.3289528e-34 7.1395626e-17 5.1794628e-33], sampled 0.7342621699948233
[2019-03-22 23:33:02,462] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:33:02,463] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.4, 90.0, 1.0, 2.0, 0.3911658099881465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485332.5184709943, 485332.5184709943, 127396.2463377512]
[2019-03-22 23:33:02,464] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:33:02,471] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4243822e-35 1.0000000e+00 1.9276643e-34 3.5515020e-18 3.6722010e-33], sampled 0.13285906047530294
[2019-03-22 23:33:05,323] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:33:05,324] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.63333333333333, 61.66666666666667, 1.0, 2.0, 0.3468530352886198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434904.271987447, 434904.271987447, 121483.1534584577]
[2019-03-22 23:33:05,325] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:33:05,331] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.0599179e-36 1.0000000e+00 1.4632485e-34 1.0131765e-18 1.2201910e-33], sampled 0.39670228770876326
[2019-03-22 23:33:13,766] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:33:13,767] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.882610285, 81.255041615, 1.0, 2.0, 0.5417283917077141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 636248.1002022887, 636248.1002022887, 149213.7147122208]
[2019-03-22 23:33:13,768] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:33:13,770] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.8023727e-33 1.0000000e+00 8.1741548e-33 8.7006875e-16 8.6882457e-32], sampled 0.7412781135873105
[2019-03-22 23:33:56,251] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:33:56,251] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.35, 93.0, 1.0, 2.0, 0.5573871438875251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 653673.2517928953, 653673.2517928953, 151756.8184262488]
[2019-03-22 23:33:56,252] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:33:56,253] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.2466647e-32 1.0000000e+00 1.4488088e-32 1.6449881e-13 1.4664862e-31], sampled 0.7564521514456908
[2019-03-22 23:34:09,590] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:34:09,595] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.57869944, 55.0316562, 1.0, 2.0, 0.2693476590878491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 345029.9705561231, 345029.9705561226, 111872.910292115]
[2019-03-22 23:34:09,597] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:34:09,600] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.6942966e-36 1.0000000e+00 3.5917040e-35 1.1601779e-18 1.3865661e-33], sampled 0.9669331882385865
[2019-03-22 23:34:09,963] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:34:09,967] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.777166535, 59.43698244666666, 1.0, 2.0, 0.450779213251283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571716.6701028788, 571716.6701028788, 136213.5678339501]
[2019-03-22 23:34:09,968] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:34:09,970] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.2754093e-32 1.0000000e+00 6.4128630e-32 3.3287175e-15 2.3940302e-30], sampled 0.32979315051922875
[2019-03-22 23:34:11,711] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3416963], dtype=float32), 0.30302772]
[2019-03-22 23:34:11,712] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 66.0, 1.0, 2.0, 0.777830953485615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.926042615655, 886558.5508898029, 886558.5508898029, 191396.6258494803]
[2019-03-22 23:34:11,713] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:34:11,716] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.78153791e-24 9.99963164e-01 1.04106135e-26 3.67898792e-05
 7.79496732e-25], sampled 0.2218145823456794
[2019-03-22 23:34:26,967] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8199.7759 2429218637.5661 636.0000
[2019-03-22 23:34:27,527] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8671.5809 2234023102.0040 461.0000
[2019-03-22 23:34:27,530] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8947.3077 2116105785.6066 404.0000
[2019-03-22 23:34:27,545] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8834.8039 2162706030.2077 439.0000
[2019-03-22 23:34:27,644] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8769.5465 2186966330.4741 510.0000
[2019-03-22 23:34:28,662] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 175000, evaluation results [175000.0, 8199.775856189703, 2429218637.5661154, 636.0, 8834.803929050864, 2162706030.2077184, 439.0, 8947.307669801505, 2116105785.6066487, 404.0, 8671.580855784223, 2234023102.0039597, 461.0, 8769.546514818949, 2186966330.474065, 510.0]
[2019-03-22 23:34:29,864] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.2183758e-28 9.9999917e-01 1.4794727e-28 7.9434903e-07 2.3162175e-28], sum to 1.0000
[2019-03-22 23:34:29,873] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4023
[2019-03-22 23:34:29,876] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 46.66666666666666, 1.0, 2.0, 0.3438264218566243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434630.7926782126, 434630.7926782126, 121133.0787513559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6583200.0000, 
sim time next is 6583800.0000, 
raw observation next is [25.6, 46.33333333333334, 1.0, 2.0, 0.3412373286493937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 431649.5223090037, 431649.5223090037, 120796.8238314545], 
processed observation next is [1.0, 0.17391304347826086, 0.5037037037037038, 0.46333333333333343, 1.0, 1.0, 0.21575872458261156, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15416054368178703, 0.15416054368178703, 0.23230158429125866], 
reward next is 0.7677, 
noisyNet noise sample is [array([0.49389878], dtype=float32), 0.6696541]. 
=============================================
[2019-03-22 23:34:30,326] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 175766: loss 1.7074
[2019-03-22 23:34:30,330] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 175766: learning rate 0.0010
[2019-03-22 23:34:30,361] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 175782: loss 1.5215
[2019-03-22 23:34:30,364] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 175784: learning rate 0.0010
[2019-03-22 23:34:30,622] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 175898: loss 1.4788
[2019-03-22 23:34:30,628] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 175902: learning rate 0.0010
[2019-03-22 23:34:30,689] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 175931: loss 0.8096
[2019-03-22 23:34:30,692] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 175933: learning rate 0.0010
[2019-03-22 23:34:30,721] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 175946: loss 0.9633
[2019-03-22 23:34:30,723] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 175947: learning rate 0.0010
[2019-03-22 23:34:30,724] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 175947: loss 0.9054
[2019-03-22 23:34:30,728] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 175948: learning rate 0.0010
[2019-03-22 23:34:30,772] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 175964: loss 1.1822
[2019-03-22 23:34:30,773] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 175964: learning rate 0.0010
[2019-03-22 23:34:30,797] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 175975: loss 0.3828
[2019-03-22 23:34:30,798] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 175975: learning rate 0.0010
[2019-03-22 23:34:30,800] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 175977: loss 1.1437
[2019-03-22 23:34:30,805] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 175977: learning rate 0.0010
[2019-03-22 23:34:30,901] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 176027: loss 0.7459
[2019-03-22 23:34:30,905] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 176030: learning rate 0.0010
[2019-03-22 23:34:30,907] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 176030: loss 0.7157
[2019-03-22 23:34:30,911] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 176030: learning rate 0.0010
[2019-03-22 23:34:30,931] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 176037: loss 0.9721
[2019-03-22 23:34:30,932] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 176037: learning rate 0.0010
[2019-03-22 23:34:31,064] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 176101: loss 0.3732
[2019-03-22 23:34:31,066] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 176102: learning rate 0.0010
[2019-03-22 23:34:31,075] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 176107: loss 0.3877
[2019-03-22 23:34:31,078] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 176107: learning rate 0.0010
[2019-03-22 23:34:31,133] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 176129: loss 0.8782
[2019-03-22 23:34:31,136] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 176129: learning rate 0.0010
[2019-03-22 23:34:31,225] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 176175: loss 0.1593
[2019-03-22 23:34:31,231] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 176177: learning rate 0.0010
[2019-03-22 23:34:37,511] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.9293094e-29 3.9115221e-06 3.9940965e-33 9.9999607e-01 1.8341694e-27], sum to 1.0000
[2019-03-22 23:34:37,522] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8030
[2019-03-22 23:34:37,528] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.35, 27.5, 1.0, 2.0, 0.5245774768828138, 1.0, 2.0, 0.5245774768828138, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1302782.11592314, 1302782.11592314, 247075.2486123438], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6712200.0000, 
sim time next is 6712800.0000, 
raw observation next is [30.4, 27.33333333333334, 1.0, 2.0, 0.523074052000352, 1.0, 2.0, 0.523074052000352, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1298850.546559531, 1298850.546559531, 246580.8982433346], 
processed observation next is [1.0, 0.6956521739130435, 0.6814814814814815, 0.2733333333333334, 1.0, 1.0, 0.43223101428613325, 1.0, 1.0, 0.43223101428613325, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4638751951998325, 0.4638751951998325, 0.4741940350833358], 
reward next is 0.5258, 
noisyNet noise sample is [array([1.1155127], dtype=float32), 1.4834669]. 
=============================================
[2019-03-22 23:34:47,822] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 183772: loss 0.0109
[2019-03-22 23:34:47,825] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 183772: learning rate 0.0010
[2019-03-22 23:34:47,982] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 183843: loss 0.0040
[2019-03-22 23:34:47,987] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 183843: learning rate 0.0010
[2019-03-22 23:34:48,106] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 183900: loss -0.8097
[2019-03-22 23:34:48,109] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 183900: learning rate 0.0010
[2019-03-22 23:34:48,124] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 183907: loss -0.0002
[2019-03-22 23:34:48,127] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 183907: learning rate 0.0010
[2019-03-22 23:34:48,149] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 183918: loss 0.0062
[2019-03-22 23:34:48,151] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 183919: learning rate 0.0010
[2019-03-22 23:34:48,173] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 183930: loss 0.0020
[2019-03-22 23:34:48,175] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 183930: learning rate 0.0010
[2019-03-22 23:34:48,234] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 183955: loss 0.0748
[2019-03-22 23:34:48,236] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 183955: learning rate 0.0010
[2019-03-22 23:34:48,265] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 183966: loss 0.0282
[2019-03-22 23:34:48,270] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 183967: learning rate 0.0010
[2019-03-22 23:34:48,321] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3946671e-32 1.0000000e+00 0.0000000e+00 3.6264623e-15 0.0000000e+00], sum to 1.0000
[2019-03-22 23:34:48,327] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 183998: loss 0.0347
[2019-03-22 23:34:48,330] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 183999: learning rate 0.0010
[2019-03-22 23:34:48,331] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4130
[2019-03-22 23:34:48,335] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 60.66666666666666, 1.0, 2.0, 0.4356655855561231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 533030.0424065903, 533030.0424065898, 133585.822486131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6900000.0000, 
sim time next is 6900600.0000, 
raw observation next is [25.55, 61.33333333333334, 1.0, 2.0, 0.4349647507450312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 532394.605427117, 532394.605427117, 133489.1266679372], 
processed observation next is [0.0, 0.8695652173913043, 0.5018518518518519, 0.6133333333333334, 1.0, 1.0, 0.32733898898218006, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19014093050968464, 0.19014093050968464, 0.2567098589768023], 
reward next is 0.7433, 
noisyNet noise sample is [array([0.6750438], dtype=float32), -0.89413726]. 
=============================================
[2019-03-22 23:34:48,399] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 184028: loss 0.0199
[2019-03-22 23:34:48,401] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 184029: learning rate 0.0010
[2019-03-22 23:34:48,405] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 184029: loss 0.0805
[2019-03-22 23:34:48,408] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 184031: learning rate 0.0010
[2019-03-22 23:34:48,427] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 184039: loss 0.0014
[2019-03-22 23:34:48,433] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 184040: learning rate 0.0010
[2019-03-22 23:34:48,536] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 184091: loss 0.0088
[2019-03-22 23:34:48,541] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 184092: learning rate 0.0010
[2019-03-22 23:34:48,554] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 184097: loss 0.0723
[2019-03-22 23:34:48,558] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 184099: learning rate 0.0010
[2019-03-22 23:34:48,663] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 184151: loss 0.2237
[2019-03-22 23:34:48,665] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 184151: learning rate 0.0010
[2019-03-22 23:34:48,720] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 184173: loss 0.0268
[2019-03-22 23:34:48,722] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 184173: learning rate 0.0010
[2019-03-22 23:34:53,776] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.7608685e-31 1.0000000e+00 5.9960631e-38 4.3875330e-23 1.1655765e-33], sum to 1.0000
[2019-03-22 23:34:53,786] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5715
[2019-03-22 23:34:53,790] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 68.66666666666667, 1.0, 2.0, 0.4283219850047325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 526068.7254053593, 526068.7254053593, 132567.1146752201], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6993600.0000, 
sim time next is 6994200.0000, 
raw observation next is [23.93333333333334, 69.33333333333333, 1.0, 2.0, 0.4271844473079233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524869.5953252534, 524869.5953252534, 132406.7277104751], 
processed observation next is [0.0, 0.9565217391304348, 0.4419753086419756, 0.6933333333333332, 1.0, 1.0, 0.31807672298562306, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18745342690187622, 0.18745342690187622, 0.25462832252014445], 
reward next is 0.7454, 
noisyNet noise sample is [array([-0.27211702], dtype=float32), 0.024239583]. 
=============================================
[2019-03-22 23:35:01,310] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.64721730e-23 9.99999523e-01 1.16225094e-32 4.49264292e-07
 2.99644205e-25], sum to 1.0000
[2019-03-22 23:35:01,318] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0712
[2019-03-22 23:35:01,325] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 78.66666666666667, 1.0, 2.0, 0.655515490689397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813799.1866184906, 813799.1866184906, 170456.1721635896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7119600.0000, 
sim time next is 7120200.0000, 
raw observation next is [21.88333333333334, 78.33333333333333, 1.0, 2.0, 0.6671707762356495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 827468.4622224324, 827468.4622224324, 172621.8572284634], 
processed observation next is [1.0, 0.391304347826087, 0.36604938271604964, 0.7833333333333333, 1.0, 1.0, 0.6037747336138684, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29552445079372586, 0.29552445079372586, 0.33196511005473733], 
reward next is 0.6680, 
noisyNet noise sample is [array([0.00763657], dtype=float32), 0.074361965]. 
=============================================
[2019-03-22 23:35:02,552] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8396234e-21 1.9851430e-13 1.3107585e-32 1.0000000e+00 1.7188124e-30], sum to 1.0000
[2019-03-22 23:35:02,560] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9032
[2019-03-22 23:35:02,565] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.75, 61.66666666666667, 1.0, 2.0, 0.3852398803130151, 1.0, 2.0, 0.3852398803130151, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 949488.1165410358, 949488.1165410358, 204910.427057707], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7138200.0000, 
sim time next is 7138800.0000, 
raw observation next is [23.7, 62.0, 1.0, 2.0, 0.3837864463384478, 1.0, 2.0, 0.3837864463384478, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 945905.5276380169, 945905.5276380169, 204509.3971887501], 
processed observation next is [1.0, 0.6521739130434783, 0.4333333333333333, 0.62, 1.0, 1.0, 0.2664124361171997, 1.0, 1.0, 0.2664124361171997, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33782340272786315, 0.33782340272786315, 0.39328730228605785], 
reward next is 0.6067, 
noisyNet noise sample is [array([-0.22218764], dtype=float32), -0.12041196]. 
=============================================
[2019-03-22 23:35:05,271] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 191721: loss 0.1296
[2019-03-22 23:35:05,276] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 191723: learning rate 0.0010
[2019-03-22 23:35:05,568] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191856: loss 0.0106
[2019-03-22 23:35:05,570] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 191857: learning rate 0.0010
[2019-03-22 23:35:05,614] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 191876: loss 0.1194
[2019-03-22 23:35:05,616] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 191877: learning rate 0.0010
[2019-03-22 23:35:05,633] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 191883: loss 0.0313
[2019-03-22 23:35:05,637] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 191885: learning rate 0.0010
[2019-03-22 23:35:05,644] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 191890: loss 0.0764
[2019-03-22 23:35:05,648] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 191891: learning rate 0.0010
[2019-03-22 23:35:05,669] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 191901: loss 0.0158
[2019-03-22 23:35:05,670] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 191902: loss 0.0769
[2019-03-22 23:35:05,672] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 191902: learning rate 0.0010
[2019-03-22 23:35:05,672] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 191902: learning rate 0.0010
[2019-03-22 23:35:05,933] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 192022: loss 0.0161
[2019-03-22 23:35:05,941] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 192025: learning rate 0.0010
[2019-03-22 23:35:05,945] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 192026: loss 0.0365
[2019-03-22 23:35:05,947] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 192027: loss 0.0049
[2019-03-22 23:35:05,947] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 192026: learning rate 0.0010
[2019-03-22 23:35:05,951] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 192027: learning rate 0.0010
[2019-03-22 23:35:06,004] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 192051: loss 0.0510
[2019-03-22 23:35:06,005] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 192052: learning rate 0.0010
[2019-03-22 23:35:06,061] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 192076: loss 0.0503
[2019-03-22 23:35:06,066] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 192076: learning rate 0.0010
[2019-03-22 23:35:06,067] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 192077: loss 0.0437
[2019-03-22 23:35:06,068] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 192077: learning rate 0.0010
[2019-03-22 23:35:06,105] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 192095: loss 0.1585
[2019-03-22 23:35:06,108] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 192095: learning rate 0.0010
[2019-03-22 23:35:06,219] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 192147: loss 0.0883
[2019-03-22 23:35:06,223] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 192149: learning rate 0.0010
[2019-03-22 23:35:06,421] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 192237: loss 0.0561
[2019-03-22 23:35:06,428] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 192240: learning rate 0.0010
[2019-03-22 23:35:07,523] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4767609e-16 9.4072154e-04 1.8531119e-26 9.9905926e-01 4.3071787e-21], sum to 1.0000
[2019-03-22 23:35:07,532] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8130
[2019-03-22 23:35:07,539] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.83333333333334, 70.0, 1.0, 2.0, 0.3380731894096154, 1.0, 2.0, 0.3380731894096154, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818718.2775025856, 818718.2775025856, 191852.7827127107], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7231200.0000, 
sim time next is 7231800.0000, 
raw observation next is [23.81666666666667, 70.0, 1.0, 2.0, 0.3265483091533223, 1.0, 2.0, 0.3265483091533223, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 791788.0030559788, 791788.0030559788, 188931.2258657824], 
processed observation next is [1.0, 0.6956521739130435, 0.43765432098765444, 0.7, 1.0, 1.0, 0.19827179661109795, 1.0, 1.0, 0.19827179661109795, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2827814296628496, 0.2827814296628496, 0.36332928051112], 
reward next is 0.6367, 
noisyNet noise sample is [array([0.2720165], dtype=float32), 0.0024432319]. 
=============================================
[2019-03-22 23:35:10,308] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.0166183e-28 7.1810798e-17 1.0886047e-36 1.0000000e+00 7.1899371e-31], sum to 1.0000
[2019-03-22 23:35:10,317] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3693
[2019-03-22 23:35:10,321] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.6, 90.0, 1.0, 2.0, 0.1947034702642212, 1.0, 2.0, 0.1947034702642212, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478042.3981324756, 478042.3981324756, 158677.5049767168], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7280400.0000, 
sim time next is 7281000.0000, 
raw observation next is [20.65, 90.0, 1.0, 2.0, 0.1956324238504703, 1.0, 2.0, 0.1956324238504703, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 479969.4109619534, 479969.4109619539, 158860.0097287047], 
processed observation next is [1.0, 0.2608695652173913, 0.3203703703703703, 0.9, 1.0, 1.0, 0.04241955220294084, 1.0, 1.0, 0.04241955220294084, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1714176467721262, 0.1714176467721264, 0.30550001870904747], 
reward next is 0.6945, 
noisyNet noise sample is [array([0.69361377], dtype=float32), -1.3075519]. 
=============================================
[2019-03-22 23:35:10,331] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[64.09223]
 [64.09877]
 [64.08152]
 [64.05087]
 [64.02631]], R is [[64.17108917]
 [64.22423553]
 [64.27671051]
 [64.32853699]
 [64.3807373 ]].
[2019-03-22 23:35:21,074] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.9481541e-30 7.4854846e-08 1.8123812e-32 9.9999988e-01 2.2441176e-28], sum to 1.0000
[2019-03-22 23:35:21,081] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8527
[2019-03-22 23:35:21,087] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.8, 90.5, 1.0, 2.0, 0.2000548565859108, 1.0, 2.0, 0.2000548565859108, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 489341.5033948964, 489341.5033948969, 159738.5182914483], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7461000.0000, 
sim time next is 7461600.0000, 
raw observation next is [20.96666666666667, 90.0, 1.0, 2.0, 0.2021939559509602, 1.0, 2.0, 0.2021939559509602, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 493753.5928773807, 493753.5928773811, 160161.44097706], 
processed observation next is [0.0, 0.34782608695652173, 0.3320987654320988, 0.9, 1.0, 1.0, 0.05023089994161929, 1.0, 1.0, 0.05023089994161929, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17634056888477884, 0.17634056888477895, 0.3080027711097308], 
reward next is 0.6920, 
noisyNet noise sample is [array([0.8121675], dtype=float32), 0.2134747]. 
=============================================
[2019-03-22 23:35:22,804] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 199709: loss 0.0097
[2019-03-22 23:35:22,807] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 199711: learning rate 0.0010
[2019-03-22 23:35:23,053] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 199826: loss 0.7289
[2019-03-22 23:35:23,056] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 199826: learning rate 0.0010
[2019-03-22 23:35:23,084] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 199841: loss 0.0408
[2019-03-22 23:35:23,086] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 199841: learning rate 0.0010
[2019-03-22 23:35:23,094] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 199844: loss 0.0022
[2019-03-22 23:35:23,095] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 199844: learning rate 0.0010
[2019-03-22 23:35:23,221] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 199902: loss 0.1147
[2019-03-22 23:35:23,225] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 199904: learning rate 0.0010
[2019-03-22 23:35:23,233] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 199908: loss 0.0851
[2019-03-22 23:35:23,235] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 199908: learning rate 0.0010
[2019-03-22 23:35:23,292] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 199930: loss 0.0719
[2019-03-22 23:35:23,295] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 199932: learning rate 0.0010
[2019-03-22 23:35:23,355] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.2071258e-24 2.2667467e-05 5.2303151e-32 9.9997735e-01 1.4515735e-27], sum to 1.0000
[2019-03-22 23:35:23,363] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7074
[2019-03-22 23:35:23,366] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.65, 90.5, 1.0, 2.0, 0.2488910159884669, 1.0, 1.0, 0.2488910159884669, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589852.8944307165, 589852.8944307165, 169725.298152047], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7504200.0000, 
sim time next is 7504800.0000, 
raw observation next is [22.6, 90.66666666666667, 1.0, 2.0, 0.2481240130209718, 1.0, 2.0, 0.2481240130209718, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 587572.2678126878, 587572.2678126878, 169532.9329825081], 
processed observation next is [0.0, 0.8695652173913043, 0.39259259259259266, 0.9066666666666667, 1.0, 1.0, 0.10490953931068073, 1.0, 1.0, 0.10490953931068073, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20984723850453135, 0.20984723850453135, 0.3260248711202079], 
reward next is 0.6740, 
noisyNet noise sample is [array([-0.17614324], dtype=float32), -1.1377112]. 
=============================================
[2019-03-22 23:35:23,438] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-22 23:35:23,442] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:35:23,442] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:35:23,444] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:35:23,445] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:35:23,445] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:35:23,446] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:35:23,446] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:35:23,448] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:35:23,449] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:35:23,449] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:35:23,470] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run9
[2019-03-22 23:35:23,489] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run9
[2019-03-22 23:35:23,516] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run9
[2019-03-22 23:35:23,531] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run9
[2019-03-22 23:35:23,533] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run9
[2019-03-22 23:35:26,316] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37912035], dtype=float32), 0.25133058]
[2019-03-22 23:35:26,318] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.77189955, 34.64050563333333, 1.0, 2.0, 0.2712164242861643, 1.0, 2.0, 0.2712164242861643, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 663707.8955426173, 663707.8955426178, 175593.3984768034]
[2019-03-22 23:35:26,319] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:35:26,323] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.2677264e-27 8.9657527e-07 1.6206326e-32 9.9999905e-01 5.2637236e-29], sampled 0.807025663346013
[2019-03-22 23:35:42,392] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37912035], dtype=float32), 0.25133058]
[2019-03-22 23:35:42,393] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.98333333333333, 64.33333333333334, 1.0, 2.0, 0.3588078802395022, 1.0, 2.0, 0.3588078802395022, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 877144.3306534204, 877144.3306534209, 197537.6632466214]
[2019-03-22 23:35:42,394] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:35:42,399] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.6608320e-28 2.4145100e-07 1.2950371e-33 9.9999976e-01 2.3433507e-29], sampled 0.7645140867905948
[2019-03-22 23:35:43,010] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37912035], dtype=float32), 0.25133058]
[2019-03-22 23:35:43,012] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.6, 86.0, 1.0, 2.0, 0.1925619531817181, 1.0, 2.0, 0.1925619531817181, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 475872.3288495681, 475872.3288495686, 158324.936867255]
[2019-03-22 23:35:43,013] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:35:43,015] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.3913935e-29 1.0003049e-08 4.3645698e-35 1.0000000e+00 7.9681345e-31], sampled 0.2838726276925556
[2019-03-22 23:36:09,709] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37912035], dtype=float32), 0.25133058]
[2019-03-22 23:36:09,710] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [34.6, 32.0, 1.0, 2.0, 0.874309418427959, 1.0, 2.0, 0.874309418427959, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2019666.036309983, 2019666.036309984, 376777.5389295808]
[2019-03-22 23:36:09,712] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:36:09,716] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.6881085e-32 2.0900483e-21 0.0000000e+00 1.0000000e+00 2.4605190e-36], sampled 0.07893316782029958
[2019-03-22 23:36:15,289] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37912035], dtype=float32), 0.25133058]
[2019-03-22 23:36:15,290] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.85174759666667, 94.59866496333335, 1.0, 2.0, 0.3134622692064468, 1.0, 2.0, 0.3134622692064468, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732185.0053397705, 732185.0053397705, 184557.5408015142]
[2019-03-22 23:36:15,291] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:36:15,295] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.9785222e-28 5.5154726e-07 1.4603591e-34 9.9999940e-01 7.4475726e-30], sampled 0.668722995317512
[2019-03-22 23:36:16,905] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.37912035], dtype=float32), 0.25133058]
[2019-03-22 23:36:16,907] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.40791437666667, 89.62252359000001, 1.0, 2.0, 0.9152147724948227, 1.0, 2.0, 0.9152147724948227, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2087829.505337507, 2087829.505337507, 393666.0394335083]
[2019-03-22 23:36:16,908] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:36:16,911] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.0990420e-32 1.0978682e-19 0.0000000e+00 1.0000000e+00 2.3194208e-35], sampled 0.2114715700080293
[2019-03-22 23:36:25,355] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.37912035], dtype=float32), 0.25133058]
[2019-03-22 23:36:25,356] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.5, 78.0, 1.0, 2.0, 0.4732483873113156, 1.0, 2.0, 0.4732483873113156, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1078936.335637413, 1078936.335637413, 227235.5835232587]
[2019-03-22 23:36:25,357] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:36:25,359] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.6589103e-29 3.3351105e-07 2.0299295e-35 9.9999964e-01 1.0453634e-30], sampled 0.6983848768888318
[2019-03-22 23:36:30,924] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37912035], dtype=float32), 0.25133058]
[2019-03-22 23:36:30,926] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.87964342666667, 105.56371304, 1.0, 2.0, 0.4035227648774584, 1.0, 2.0, 0.4035227648774584, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 924617.442423335, 924617.4424233364, 207387.1975640283]
[2019-03-22 23:36:30,927] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:36:30,930] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.8341465e-28 5.7846275e-05 5.0384048e-34 9.9994218e-01 2.4228415e-29], sampled 0.2888395099462633
[2019-03-22 23:36:41,877] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37912035], dtype=float32), 0.25133058]
[2019-03-22 23:36:41,879] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.0, 67.0, 1.0, 2.0, 0.9008573461393398, 1.0, 2.0, 0.7637933350461047, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2614369.301218485, 2614369.301218485, 487574.8190363495]
[2019-03-22 23:36:41,880] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:36:41,883] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 0. 0. 1. 0.], sampled 0.5428383043221238
[2019-03-22 23:36:41,885] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 0, 0, 1, 0] has been changed to [0, 0, 0, 0, 1] for the demand 2614369.301218485 W.
[2019-03-22 23:37:15,393] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7977.0959 2357615712.4376 42.0000
[2019-03-22 23:37:15,728] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8139.3177 2379245529.6100 50.0000
[2019-03-22 23:37:15,788] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7944.6222 2596125571.8324 67.0000
[2019-03-22 23:37:15,877] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 7864.3492 2410900898.4854 49.0000
[2019-03-22 23:37:15,905] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8330.8701 2325103051.0089 36.0000
[2019-03-22 23:37:16,920] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 200000, evaluation results [200000.0, 7944.622184293238, 2596125571.8324018, 67.0, 7977.095860142422, 2357615712.4375677, 42.0, 8330.870074595641, 2325103051.0088673, 36.0, 7864.349238753188, 2410900898.4853897, 49.0, 8139.317676962071, 2379245529.610004, 50.0]
[2019-03-22 23:37:16,994] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 200039: loss -0.0936
[2019-03-22 23:37:17,000] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 200040: learning rate 0.0010
[2019-03-22 23:37:17,025] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 200055: loss 0.0634
[2019-03-22 23:37:17,030] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 200056: learning rate 0.0010
[2019-03-22 23:37:17,031] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 200058: loss -0.0722
[2019-03-22 23:37:17,036] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 200058: learning rate 0.0010
[2019-03-22 23:37:17,059] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 200068: loss -0.3574
[2019-03-22 23:37:17,063] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 200069: learning rate 0.0010
[2019-03-22 23:37:17,097] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 200088: loss 0.3246
[2019-03-22 23:37:17,099] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 200089: learning rate 0.0010
[2019-03-22 23:37:17,102] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 200089: loss 0.0101
[2019-03-22 23:37:17,105] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 200089: learning rate 0.0010
[2019-03-22 23:37:17,141] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 200106: loss 0.0386
[2019-03-22 23:37:17,144] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 200106: learning rate 0.0010
[2019-03-22 23:37:17,278] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 200169: loss 0.0699
[2019-03-22 23:37:17,280] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 200169: learning rate 0.0010
[2019-03-22 23:37:17,407] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 200232: loss 0.0628
[2019-03-22 23:37:17,409] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 200232: learning rate 0.0010
[2019-03-22 23:37:17,543] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0702323e-31 2.4143235e-17 1.0475937e-33 1.0000000e+00 1.6981954e-33], sum to 1.0000
[2019-03-22 23:37:17,553] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8293
[2019-03-22 23:37:17,559] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.8, 95.0, 1.0, 2.0, 0.2402550734095079, 1.0, 2.0, 0.2402550734095079, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571851.8609978136, 571851.8609978136, 167895.3997184242], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7513200.0000, 
sim time next is 7513800.0000, 
raw observation next is [21.75, 95.0, 1.0, 2.0, 0.2395838637183532, 1.0, 2.0, 0.2395838637183532, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 570676.8606803314, 570676.8606803318, 167763.3973516782], 
processed observation next is [0.0, 1.0, 0.3611111111111111, 0.95, 1.0, 1.0, 0.09474269490280142, 1.0, 1.0, 0.09474269490280142, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20381316452868978, 0.20381316452868994, 0.32262191798399653], 
reward next is 0.6774, 
noisyNet noise sample is [array([0.9266711], dtype=float32), 1.2890844]. 
=============================================
[2019-03-22 23:37:25,021] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.6123840e-30 2.2629800e-08 0.0000000e+00 1.0000000e+00 1.8573118e-28], sum to 1.0000
[2019-03-22 23:37:25,029] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2787
[2019-03-22 23:37:25,033] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.93333333333333, 74.66666666666667, 1.0, 2.0, 0.6116017746033401, 1.0, 2.0, 0.6116017746033401, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1401080.322035068, 1401080.322035069, 272374.5893533809], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7645200.0000, 
sim time next is 7645800.0000, 
raw observation next is [26.01666666666667, 73.83333333333333, 1.0, 2.0, 0.6115384312668918, 1.0, 2.0, 0.6115384312668918, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1402243.695427232, 1402243.695427233, 272417.0119261297], 
processed observation next is [1.0, 0.4782608695652174, 0.5191358024691359, 0.7383333333333333, 1.0, 1.0, 0.5375457515082045, 1.0, 1.0, 0.5375457515082045, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.50080131979544, 0.5008013197954403, 0.523878869088711], 
reward next is 0.4761, 
noisyNet noise sample is [array([-0.5179436], dtype=float32), 1.0870746]. 
=============================================
[2019-03-22 23:37:30,411] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.3689577e-24 1.0000000e+00 1.9742945e-28 4.0840494e-08 1.7989199e-27], sum to 1.0000
[2019-03-22 23:37:30,422] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3019
[2019-03-22 23:37:30,428] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 80.0, 1.0, 2.0, 0.7403058565986043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 917892.1952760911, 917892.1952760908, 186869.4456701014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7722000.0000, 
sim time next is 7722600.0000, 
raw observation next is [22.06666666666667, 78.5, 1.0, 2.0, 0.7258402753312223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 898031.7223312624, 898031.7223312624, 183927.2864294737], 
processed observation next is [1.0, 0.391304347826087, 0.3728395061728396, 0.785, 1.0, 1.0, 0.6736193753943123, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.320725615118308, 0.320725615118308, 0.3537063200566802], 
reward next is 0.6463, 
noisyNet noise sample is [array([-1.1657417], dtype=float32), 1.6679767]. 
=============================================
[2019-03-22 23:37:33,890] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 207766: loss 0.6129
[2019-03-22 23:37:33,893] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 207766: learning rate 0.0010
[2019-03-22 23:37:33,901] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 207772: loss 0.9090
[2019-03-22 23:37:33,902] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 207772: learning rate 0.0010
[2019-03-22 23:37:33,950] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 207798: loss 1.1577
[2019-03-22 23:37:33,952] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 207798: learning rate 0.0010
[2019-03-22 23:37:33,987] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 207811: loss 0.8304
[2019-03-22 23:37:33,995] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 207812: learning rate 0.0010
[2019-03-22 23:37:33,997] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207812: loss 0.7042
[2019-03-22 23:37:33,999] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207813: learning rate 0.0010
[2019-03-22 23:37:34,063] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9043400e-28 1.0000000e+00 1.0946832e-31 9.5686410e-12 1.7826248e-30], sum to 1.0000
[2019-03-22 23:37:34,070] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9951
[2019-03-22 23:37:34,076] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 63.16666666666667, 1.0, 2.0, 0.3347095296306536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426073.1871111949, 426073.1871111949, 119967.6076760421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7794600.0000, 
sim time next is 7795200.0000, 
raw observation next is [22.1, 62.33333333333334, 1.0, 2.0, 0.3206714923168763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407942.9510283774, 407942.9510283774, 118162.4584655707], 
processed observation next is [1.0, 0.21739130434782608, 0.3740740740740741, 0.6233333333333334, 1.0, 1.0, 0.1912755860915194, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14569391108156335, 0.14569391108156335, 0.22723549704917442], 
reward next is 0.7728, 
noisyNet noise sample is [array([0.17695282], dtype=float32), 0.26080686]. 
=============================================
[2019-03-22 23:37:34,148] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 207884: loss 0.1013
[2019-03-22 23:37:34,149] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 207884: learning rate 0.0010
[2019-03-22 23:37:34,329] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 207965: loss 0.2352
[2019-03-22 23:37:34,332] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 207966: learning rate 0.0010
[2019-03-22 23:37:34,427] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 208009: loss 0.1181
[2019-03-22 23:37:34,430] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 208010: learning rate 0.0010
[2019-03-22 23:37:34,498] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 208042: loss 0.0156
[2019-03-22 23:37:34,504] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 208042: learning rate 0.0010
[2019-03-22 23:37:34,530] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 208056: loss 0.1975
[2019-03-22 23:37:34,532] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 208056: learning rate 0.0010
[2019-03-22 23:37:34,561] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 208068: loss 0.0217
[2019-03-22 23:37:34,562] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 208068: learning rate 0.0010
[2019-03-22 23:37:34,573] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 208072: loss 0.0109
[2019-03-22 23:37:34,576] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 208072: learning rate 0.0010
[2019-03-22 23:37:34,647] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 208111: loss 0.0209
[2019-03-22 23:37:34,654] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 208112: learning rate 0.0010
[2019-03-22 23:37:34,668] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 208120: loss 0.0049
[2019-03-22 23:37:34,670] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 208121: learning rate 0.0010
[2019-03-22 23:37:34,892] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 208221: loss 0.1033
[2019-03-22 23:37:34,893] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 208221: learning rate 0.0010
[2019-03-22 23:37:35,002] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 208269: loss 0.2027
[2019-03-22 23:37:35,007] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 208271: learning rate 0.0010
[2019-03-22 23:37:43,625] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,625] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,627] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run2
[2019-03-22 23:37:43,661] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,662] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,664] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run2
[2019-03-22 23:37:43,681] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,682] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,685] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run2
[2019-03-22 23:37:43,706] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,707] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,708] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run2
[2019-03-22 23:37:43,718] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,719] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,722] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run2
[2019-03-22 23:37:43,766] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,767] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,768] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run2
[2019-03-22 23:37:43,867] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,867] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,868] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run2
[2019-03-22 23:37:43,939] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,939] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,940] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run2
[2019-03-22 23:37:43,957] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,958] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,959] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run2
[2019-03-22 23:37:43,976] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,976] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,978] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run2
[2019-03-22 23:37:43,995] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:43,996] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:43,998] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run2
[2019-03-22 23:37:44,014] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:44,014] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:44,016] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run2
[2019-03-22 23:37:44,038] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:44,038] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:44,040] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run2
[2019-03-22 23:37:44,061] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:44,061] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:44,063] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run2
[2019-03-22 23:37:44,079] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:44,097] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:44,098] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run2
[2019-03-22 23:37:44,097] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-22 23:37:44,148] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:37:44,150] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run2
[2019-03-22 23:37:49,668] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9414232e-34 3.9398315e-18 0.0000000e+00 1.0000000e+00 9.9956548e-38], sum to 1.0000
[2019-03-22 23:37:49,681] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8490
[2019-03-22 23:37:49,687] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.13333333333333, 51.33333333333333, 1.0, 2.0, 0.2086779387413868, 1.0, 2.0, 0.2086779387413868, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 508903.1912247504, 508903.1912247508, 161512.3723205253], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 74400.0000, 
sim time next is 75000.0000, 
raw observation next is [26.96666666666667, 52.16666666666667, 1.0, 2.0, 0.2089635235772831, 1.0, 2.0, 0.2089635235772831, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 509557.7743085566, 509557.7743085571, 161571.7910342314], 
processed observation next is [1.0, 0.8695652173913043, 0.554320987654321, 0.5216666666666667, 1.0, 1.0, 0.05828990902057511, 1.0, 1.0, 0.05828990902057511, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18198491939591308, 0.18198491939591324, 0.3107149827581373], 
reward next is 0.6893, 
noisyNet noise sample is [array([1.1464618], dtype=float32), -0.082458064]. 
=============================================
[2019-03-22 23:37:49,700] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[68.942764]
 [68.872955]
 [68.85746 ]
 [68.91852 ]
 [68.9911  ]], R is [[69.02679443]
 [69.02592468]
 [69.02494049]
 [69.02397156]
 [69.02323914]].
[2019-03-22 23:38:00,135] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0109819e-29 1.0000000e+00 9.4853086e-38 3.3165341e-13 1.9744296e-36], sum to 1.0000
[2019-03-22 23:38:00,144] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0923
[2019-03-22 23:38:00,153] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 45.33333333333333, 1.0, 2.0, 0.2846459512581628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 367179.4847521661, 367179.4847521666, 109864.4213241634], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 258000.0000, 
sim time next is 258600.0000, 
raw observation next is [22.95, 45.66666666666667, 1.0, 2.0, 0.2830227963042908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 365085.195363404, 365085.195363404, 108740.0173020564], 
processed observation next is [0.0, 1.0, 0.4055555555555555, 0.4566666666666667, 1.0, 1.0, 0.14645570988606046, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1303875697726443, 0.1303875697726443, 0.20911541788857], 
reward next is 0.7909, 
noisyNet noise sample is [array([0.21975625], dtype=float32), 0.7437123]. 
=============================================
[2019-03-22 23:38:07,061] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7866383e-29 3.5262908e-22 1.0075512e-37 1.0000000e+00 5.1225703e-36], sum to 1.0000
[2019-03-22 23:38:07,069] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2795
[2019-03-22 23:38:07,073] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.73333333333333, 28.33333333333334, 1.0, 2.0, 0.435940248201093, 1.0, 2.0, 0.435940248201093, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1098037.478615585, 1098037.478615585, 219844.9933212666], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 386400.0000, 
sim time next is 387000.0000, 
raw observation next is [28.85, 28.0, 1.0, 2.0, 0.446462010883909, 1.0, 2.0, 0.446462010883909, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1123959.558437327, 1123959.558437327, 222963.3769989102], 
processed observation next is [1.0, 0.4782608695652174, 0.6240740740740741, 0.28, 1.0, 1.0, 0.341026203433225, 1.0, 1.0, 0.341026203433225, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.40141412801333104, 0.40141412801333104, 0.42877572499790423], 
reward next is 0.5712, 
noisyNet noise sample is [array([0.03212444], dtype=float32), -0.80391467]. 
=============================================
[2019-03-22 23:38:07,087] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[66.48048 ]
 [66.373405]
 [66.1581  ]
 [65.91187 ]
 [65.66242 ]], R is [[66.5019989 ]
 [66.41420746]
 [66.33450317]
 [66.25866699]
 [66.17874146]].
[2019-03-22 23:38:12,257] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6399352e-07 5.2443698e-09 8.8586358e-22 9.9999988e-01 2.8971071e-23], sum to 1.0000
[2019-03-22 23:38:12,266] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5017
[2019-03-22 23:38:12,270] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [18.5, 75.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 331262.5588531869, 331262.5588531874, 140117.4548477911], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 451200.0000, 
sim time next is 451800.0000, 
raw observation next is [18.8, 73.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 332458.419523585, 332458.4195235855, 140333.7651408463], 
processed observation next is [1.0, 0.21739130434782608, 0.2518518518518519, 0.735, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11873514982985178, 0.11873514982985195, 0.2698726252708583], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.0922575], dtype=float32), -0.5561488]. 
=============================================
[2019-03-22 23:38:13,790] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-22 23:38:13,793] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:38:13,793] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:38:13,793] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:38:13,794] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:38:13,795] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:38:13,798] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:38:13,801] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:38:13,802] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:38:13,798] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:38:13,806] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:38:13,812] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run10
[2019-03-22 23:38:13,831] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run10
[2019-03-22 23:38:13,833] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run10
[2019-03-22 23:38:13,833] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run10
[2019-03-22 23:38:13,880] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run10
[2019-03-22 23:38:35,252] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.314468], dtype=float32), 0.22307123]
[2019-03-22 23:38:35,254] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.54807612166667, 19.959684965, 1.0, 2.0, 0.3201909623655795, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 413043.1746958577, 413043.1746958582, 105095.4599202419]
[2019-03-22 23:38:35,255] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:38:35,258] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.2987793e-26 9.9999654e-01 1.1612799e-27 3.4300328e-06 3.7017951e-25], sampled 0.2336475268265693
[2019-03-22 23:38:37,780] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.314468], dtype=float32), 0.22307123]
[2019-03-22 23:38:37,781] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.27869824333333, 34.89918486666667, 1.0, 2.0, 0.3222774051916507, 1.0, 2.0, 0.3222774051916507, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 811723.8380717163, 811723.8380717167, 188583.120610051]
[2019-03-22 23:38:37,783] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:38:37,786] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.0900056e-27 1.2009006e-10 3.8793608e-31 1.0000000e+00 9.2218341e-28], sampled 0.001901436715043725
[2019-03-22 23:38:39,725] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.314468], dtype=float32), 0.22307123]
[2019-03-22 23:38:39,727] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.12764981833333, 84.81397058333334, 1.0, 2.0, 0.3378690747534834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424901.9912757939, 424901.9912757939, 120326.7841207587]
[2019-03-22 23:38:39,728] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:38:39,732] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.1804624e-25 9.9982125e-01 3.5128864e-26 1.7876852e-04 4.7477633e-25], sampled 0.24583078366952504
[2019-03-22 23:39:07,277] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.314468], dtype=float32), 0.22307123]
[2019-03-22 23:39:07,277] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.7, 96.0, 1.0, 2.0, 0.3310011031800674, 1.0, 2.0, 0.3310011031800674, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 754473.9283978356, 754473.9283978356, 188066.7581191512]
[2019-03-22 23:39:07,278] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:39:07,282] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.0502629e-25 2.9434316e-06 8.2959691e-29 9.9999702e-01 1.5902414e-25], sampled 0.25476653460032805
[2019-03-22 23:40:05,515] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8006.0100 2408499879.1926 47.0000
[2019-03-22 23:40:05,741] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8163.6228 2361614811.2111 30.0000
[2019-03-22 23:40:05,829] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7880.1173 2621749025.3327 68.0000
[2019-03-22 23:40:05,863] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 7687.8632 2440997017.1794 47.0000
[2019-03-22 23:40:05,984] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7784.6650 2389304500.1812 34.0000
[2019-03-22 23:40:07,003] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 225000, evaluation results [225000.0, 7880.117262054836, 2621749025.3326664, 68.0, 7784.664988425718, 2389304500.1811624, 34.0, 8163.622793133269, 2361614811.211116, 30.0, 7687.863219370762, 2440997017.1793504, 47.0, 8006.0100367823725, 2408499879.192616, 47.0]
[2019-03-22 23:40:07,198] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3032953e-31 2.6616234e-28 1.2921924e-37 1.0000000e+00 7.6280997e-35], sum to 1.0000
[2019-03-22 23:40:07,209] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4265
[2019-03-22 23:40:07,214] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.35, 25.0, 1.0, 2.0, 0.562374388187307, 1.0, 2.0, 0.562374388187307, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1380303.018912247, 1380303.018912247, 259242.844336114], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 487800.0000, 
sim time next is 488400.0000, 
raw observation next is [32.4, 24.66666666666667, 1.0, 2.0, 0.5524421162751008, 1.0, 2.0, 0.5524421162751008, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1357102.465834039, 1357102.465834039, 255928.5393351554], 
processed observation next is [1.0, 0.6521739130434783, 0.7555555555555555, 0.2466666666666667, 1.0, 1.0, 0.4671929955655961, 1.0, 1.0, 0.4671929955655961, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.48467945208358537, 0.48467945208358537, 0.4921702679522219], 
reward next is 0.5078, 
noisyNet noise sample is [array([-1.030597], dtype=float32), 2.0381796]. 
=============================================
[2019-03-22 23:40:16,490] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.2011801e-26 4.1205257e-31 1.5914899e-33 1.0000000e+00 8.2041084e-34], sum to 1.0000
[2019-03-22 23:40:16,499] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3167
[2019-03-22 23:40:16,504] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.13333333333334, 34.0, 1.0, 2.0, 0.5941094851166918, 1.0, 2.0, 0.5941094851166918, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1413426.954903877, 1413426.954903877, 268654.3446761501], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 645600.0000, 
sim time next is 646200.0000, 
raw observation next is [32.35, 33.0, 1.0, 2.0, 0.5713920129562868, 1.0, 2.0, 0.5713920129562868, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1362794.976610473, 1362794.976610474, 260994.1475515534], 
processed observation next is [1.0, 0.4782608695652174, 0.7537037037037038, 0.33, 1.0, 1.0, 0.48975239637653195, 1.0, 1.0, 0.48975239637653195, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.48671249164659747, 0.48671249164659786, 0.5019118222145258], 
reward next is 0.4981, 
noisyNet noise sample is [array([-0.71568304], dtype=float32), -0.35145983]. 
=============================================
[2019-03-22 23:40:19,563] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.5591404e-24 3.4358671e-09 1.1032667e-35 1.0000000e+00 1.8358906e-28], sum to 1.0000
[2019-03-22 23:40:19,571] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7603
[2019-03-22 23:40:19,576] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.8, 35.5, 1.0, 2.0, 0.1668447185792858, 1.0, 2.0, 0.1668447185792858, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 420734.7684051606, 420734.7684051611, 153221.6373336068], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 689400.0000, 
sim time next is 690000.0000, 
raw observation next is [27.66666666666666, 35.66666666666667, 1.0, 2.0, 0.1659676312144248, 1.0, 2.0, 0.1659676312144248, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 418860.1419106681, 418860.1419106686, 153049.1007915319], 
processed observation next is [1.0, 1.0, 0.5802469135802467, 0.3566666666666667, 1.0, 1.0, 0.00710432287431522, 1.0, 1.0, 0.00710432287431522, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14959290782523862, 0.1495929078252388, 0.29432519382986905], 
reward next is 0.7057, 
noisyNet noise sample is [array([0.34702566], dtype=float32), 0.6060638]. 
=============================================
[2019-03-22 23:40:19,592] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[62.062977]
 [62.139374]
 [62.21951 ]
 [62.291737]
 [62.342968]], R is [[62.08026505]
 [62.16480255]
 [62.24814987]
 [62.33030319]
 [62.4112854 ]].
[2019-03-22 23:40:23,141] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.6265970e-24 2.9355890e-04 1.4601219e-25 9.9970645e-01 8.1285996e-26], sum to 1.0000
[2019-03-22 23:40:23,148] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5439
[2019-03-22 23:40:23,157] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.7, 29.0, 1.0, 2.0, 0.1734233060537873, 1.0, 2.0, 0.1734233060537873, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 437191.5270338318, 437191.5270338323, 154564.9986955184], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 763200.0000, 
sim time next is 763800.0000, 
raw observation next is [29.53333333333333, 29.5, 1.0, 2.0, 0.1726777930365685, 1.0, 2.0, 0.1726777930365685, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 435366.0811052372, 435366.0811052372, 154412.6304784254], 
processed observation next is [1.0, 0.8695652173913043, 0.6493827160493827, 0.295, 1.0, 1.0, 0.015092610757819633, 1.0, 1.0, 0.015092610757819633, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1554878861090133, 0.1554878861090133, 0.29694736630466423], 
reward next is 0.7031, 
noisyNet noise sample is [array([1.530871], dtype=float32), -0.6467724]. 
=============================================
[2019-03-22 23:40:38,908] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1733268e-25 1.0000000e+00 1.7909353e-28 1.0213326e-12 5.1025370e-30], sum to 1.0000
[2019-03-22 23:40:38,920] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9121
[2019-03-22 23:40:38,924] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 44.66666666666667, 1.0, 2.0, 0.2834315310021178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 364243.4703237468, 364243.4703237464, 113549.8643963362], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1023600.0000, 
sim time next is 1024200.0000, 
raw observation next is [24.0, 45.0, 1.0, 2.0, 0.2837306214167032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 364624.7804239031, 364624.7804239031, 113585.9628313754], 
processed observation next is [1.0, 0.8695652173913043, 0.4444444444444444, 0.45, 1.0, 1.0, 0.14729835882940856, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13022313586567968, 0.13022313586567968, 0.21843454390649114], 
reward next is 0.7816, 
noisyNet noise sample is [array([-0.6475543], dtype=float32), -0.7694178]. 
=============================================
[2019-03-22 23:40:44,387] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4245452e-35 1.0000000e+00 4.8326608e-38 8.9807767e-17 1.0132523e-36], sum to 1.0000
[2019-03-22 23:40:44,402] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2842
[2019-03-22 23:40:44,407] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.13333333333333, 74.0, 1.0, 2.0, 0.2752014886032156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 354000.678322728, 354000.678322728, 112561.2411828243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1129200.0000, 
sim time next is 1129800.0000, 
raw observation next is [19.11666666666667, 74.0, 1.0, 2.0, 0.2744336167775533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 353062.1117907489, 353062.1117907489, 112469.4740786382], 
processed observation next is [1.0, 0.043478260869565216, 0.2635802469135804, 0.74, 1.0, 1.0, 0.1362304961637539, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1260936113538389, 0.1260936113538389, 0.2162874501512273], 
reward next is 0.7837, 
noisyNet noise sample is [array([1.131397], dtype=float32), 0.28870407]. 
=============================================
[2019-03-22 23:40:44,605] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.2425387e-32 1.0000000e+00 2.0980317e-33 4.6305066e-13 1.9986813e-34], sum to 1.0000
[2019-03-22 23:40:44,615] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3887
[2019-03-22 23:40:44,619] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 74.0, 1.0, 2.0, 0.2755964242440173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 354409.694170025, 354409.694170025, 112608.9588846406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1128000.0000, 
sim time next is 1128600.0000, 
raw observation next is [19.15, 74.0, 1.0, 2.0, 0.2753715009133436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 354170.1565556722, 354170.1565556718, 112581.8279203153], 
processed observation next is [1.0, 0.043478260869565216, 0.2648148148148148, 0.74, 1.0, 1.0, 0.13734702489683764, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12648934162702577, 0.12648934162702566, 0.2165035152313756], 
reward next is 0.7835, 
noisyNet noise sample is [array([-0.11719304], dtype=float32), 0.57025695]. 
=============================================
[2019-03-22 23:40:47,639] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3622368e-37 1.0000000e+00 1.8940511e-37 7.8209335e-24 2.3184531e-38], sum to 1.0000
[2019-03-22 23:40:47,649] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0498
[2019-03-22 23:40:47,653] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.93333333333333, 83.66666666666667, 1.0, 2.0, 0.3451484799911345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 435069.7337082005, 435069.7337082, 121292.3125538586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1195800.0000, 
sim time next is 1196400.0000, 
raw observation next is [19.86666666666667, 84.33333333333334, 1.0, 2.0, 0.3453382961650551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 435226.7341702257, 435226.7341702253, 121316.216029151], 
processed observation next is [1.0, 0.8695652173913043, 0.2913580246913582, 0.8433333333333334, 1.0, 1.0, 0.22064082876792276, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15543811934650917, 0.15543811934650903, 0.23330041544067498], 
reward next is 0.7667, 
noisyNet noise sample is [array([-1.4970186], dtype=float32), -0.03739919]. 
=============================================
[2019-03-22 23:40:57,156] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.6348535e-31 1.3286000e-16 0.0000000e+00 1.0000000e+00 4.5940299e-37], sum to 1.0000
[2019-03-22 23:40:57,166] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1694
[2019-03-22 23:40:57,173] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.93333333333333, 29.33333333333334, 1.0, 2.0, 0.5192871062112996, 1.0, 2.0, 0.5192871062112996, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1275589.947736459, 1275589.947736459, 245005.8126965882], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1354800.0000, 
sim time next is 1355400.0000, 
raw observation next is [30.95, 29.0, 1.0, 2.0, 0.495717556349166, 1.0, 2.0, 0.495717556349166, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1220167.269304553, 1220167.269304553, 237545.4352926601], 
processed observation next is [1.0, 0.6956521739130435, 0.7018518518518518, 0.29, 1.0, 1.0, 0.39966375755853095, 1.0, 1.0, 0.39966375755853095, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4357740247516261, 0.4357740247516261, 0.45681814479357713], 
reward next is 0.5432, 
noisyNet noise sample is [array([-0.72232944], dtype=float32), -1.0008892]. 
=============================================
[2019-03-22 23:41:01,494] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-22 23:41:01,495] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:41:01,496] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:41:01,497] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:41:01,499] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:41:01,499] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:41:01,500] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:41:01,502] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:41:01,503] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:41:01,504] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:41:01,506] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:41:01,520] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run11
[2019-03-22 23:41:01,520] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run11
[2019-03-22 23:41:01,520] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run11
[2019-03-22 23:41:01,571] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run11
[2019-03-22 23:41:01,572] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run11
[2019-03-22 23:41:04,385] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37360176], dtype=float32), 0.11501284]
[2019-03-22 23:41:04,387] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [36.67072336666667, 20.12745002, 1.0, 2.0, 0.3270827787503067, 1.0, 1.0, 0.3270827787503067, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 795320.2950829077, 795320.2950829081, 189138.6627440353]
[2019-03-22 23:41:04,387] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:41:04,390] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.6488964e-35 1.0359392e-06 0.0000000e+00 9.9999893e-01 2.3892967e-34], sampled 0.5192165447649753
[2019-03-22 23:41:23,624] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.37360176], dtype=float32), 0.11501284]
[2019-03-22 23:41:23,624] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.0, 35.0, 1.0, 2.0, 0.3350743002252007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 421409.1797633227, 421409.1797633222, 119963.5560807275]
[2019-03-22 23:41:23,626] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:41:23,629] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.92783512e-37 9.99998569e-01 0.00000000e+00 1.47842763e-06
 1.16975176e-35], sampled 0.2557632342035615
[2019-03-22 23:41:28,367] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37360176], dtype=float32), 0.11501284]
[2019-03-22 23:41:28,368] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.25596505333333, 76.74068258, 1.0, 2.0, 0.3512892361079786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 440992.8869535611, 440992.8869535611, 122077.5763619248]
[2019-03-22 23:41:28,369] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:41:28,373] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.2518357e-35 1.0000000e+00 0.0000000e+00 9.0905206e-10 4.3227009e-34], sampled 0.8439103707133666
[2019-03-22 23:41:48,778] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37360176], dtype=float32), 0.11501284]
[2019-03-22 23:41:48,780] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.80137836, 90.65265356, 1.0, 2.0, 0.4232384239056237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 521555.732729984, 521555.732729984, 131873.4361228947]
[2019-03-22 23:41:48,781] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:41:48,786] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.8817552e-17 0.0000000e+00], sampled 0.8479260748258767
[2019-03-22 23:41:56,518] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37360176], dtype=float32), 0.11501284]
[2019-03-22 23:41:56,519] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.01666666666667, 52.66666666666667, 1.0, 2.0, 0.3498101940734654, 1.0, 2.0, 0.3498101940734654, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 797369.1023711537, 797369.1023711541, 192844.1895149994]
[2019-03-22 23:41:56,520] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:41:56,521] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.000000e+00 7.974901e-12 0.000000e+00 1.000000e+00 0.000000e+00], sampled 0.042409162365554476
[2019-03-22 23:42:11,184] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37360176], dtype=float32), 0.11501284]
[2019-03-22 23:42:11,186] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.09048795166667, 85.93670307333332, 1.0, 2.0, 0.5135569380187004, 1.0, 2.0, 0.5135569380187004, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1170904.093082704, 1170904.093082704, 239609.0855641287]
[2019-03-22 23:42:11,187] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:42:11,190] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.5229839e-33 1.3917808e-02 0.0000000e+00 9.8608220e-01 1.3667258e-33], sampled 0.22823109778923378
[2019-03-22 23:42:37,324] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37360176], dtype=float32), 0.11501284]
[2019-03-22 23:42:37,326] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.55, 63.0, 1.0, 2.0, 0.4833872037325196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580247.2279717482, 580247.2279717482, 140442.0014852065]
[2019-03-22 23:42:37,328] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:42:37,331] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.12927484e-35 1.00000000e+00 0.00000000e+00 2.06775708e-09
 1.32811591e-35], sampled 0.0005950928781625064
[2019-03-22 23:42:39,009] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.37360176], dtype=float32), 0.11501284]
[2019-03-22 23:42:39,011] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.7, 95.0, 1.0, 2.0, 0.2658592170861518, 1.0, 2.0, 0.2658592170861518, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 621587.7020541659, 621587.7020541664, 173231.7074044773]
[2019-03-22 23:42:39,013] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:42:39,016] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.6196976e-33 6.7897062e-03 0.0000000e+00 9.9321026e-01 1.7616668e-32], sampled 0.6981326964023971
[2019-03-22 23:42:53,615] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8382.5495 2463476086.6657 220.0000
[2019-03-22 23:42:53,815] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8843.3730 2233796470.7409 187.0000
[2019-03-22 23:42:53,830] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8880.6404 2210142003.6094 182.0000
[2019-03-22 23:42:53,893] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8953.4079 2177407849.3633 165.0000
[2019-03-22 23:42:53,977] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8774.6813 2269994657.2350 153.0000
[2019-03-22 23:42:54,993] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 250000, evaluation results [250000.0, 8382.54945126868, 2463476086.6656885, 220.0, 8880.640404943542, 2210142003.6093507, 182.0, 8953.40788786919, 2177407849.363342, 165.0, 8774.681255096357, 2269994657.235036, 153.0, 8843.373041429895, 2233796470.740854, 187.0]
[2019-03-22 23:43:00,647] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0497723e-36 1.0000000e+00 1.7369936e-35 5.8858528e-13 2.5810929e-35], sum to 1.0000
[2019-03-22 23:43:00,656] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3123
[2019-03-22 23:43:00,661] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.85, 24.5, 1.0, 2.0, 0.4105297618612624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 504312.722909889, 504312.722909889, 130006.3562935641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1515000.0000, 
sim time next is 1515600.0000, 
raw observation next is [35.0, 24.0, 1.0, 2.0, 0.4112055431347459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505403.7672326127, 505403.7672326127, 130109.4829956549], 
processed observation next is [0.0, 0.5652173913043478, 0.8518518518518519, 0.24, 1.0, 1.0, 0.2990542180175546, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1805013454402188, 0.1805013454402188, 0.25021054422241323], 
reward next is 0.7498, 
noisyNet noise sample is [array([0.7428105], dtype=float32), -1.4395666]. 
=============================================
[2019-03-22 23:43:00,855] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1892224e-30 1.0000000e+00 8.0407470e-38 2.0184921e-11 2.6156969e-34], sum to 1.0000
[2019-03-22 23:43:00,865] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1608
[2019-03-22 23:43:00,870] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.85, 24.5, 1.0, 2.0, 0.4105297618612624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 504312.722909889, 504312.722909889, 130006.3562935641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1515000.0000, 
sim time next is 1515600.0000, 
raw observation next is [35.0, 24.0, 1.0, 2.0, 0.4112055431347459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505403.7672326127, 505403.7672326127, 130109.4829956549], 
processed observation next is [0.0, 0.5652173913043478, 0.8518518518518519, 0.24, 1.0, 1.0, 0.2990542180175546, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1805013454402188, 0.1805013454402188, 0.25021054422241323], 
reward next is 0.7498, 
noisyNet noise sample is [array([-0.38788593], dtype=float32), 0.13710557]. 
=============================================
[2019-03-22 23:43:01,436] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4303280e-35 1.0000000e+00 0.0000000e+00 1.7075131e-15 3.4956357e-36], sum to 1.0000
[2019-03-22 23:43:01,441] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3586
[2019-03-22 23:43:01,448] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.2, 44.5, 1.0, 2.0, 0.569288338865246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 665300.2775014894, 665300.2775014889, 153648.2543167291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1530600.0000, 
sim time next is 1531200.0000, 
raw observation next is [31.7, 46.0, 1.0, 2.0, 0.550493483415627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 644487.091841032, 644487.091841032, 150567.7213753938], 
processed observation next is [0.0, 0.7391304347826086, 0.7296296296296296, 0.46, 1.0, 1.0, 0.46487319454241305, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23017396137179716, 0.23017396137179716, 0.28955331033729576], 
reward next is 0.7104, 
noisyNet noise sample is [array([0.2277176], dtype=float32), 1.164703]. 
=============================================
[2019-03-22 23:43:02,607] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1972091e-33 1.0000000e+00 2.8567044e-35 2.2137506e-17 5.3888254e-35], sum to 1.0000
[2019-03-22 23:43:02,624] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0399
[2019-03-22 23:43:02,629] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 66.0, 1.0, 2.0, 0.3924247107007521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489523.1114988203, 489523.1114988203, 127625.5113308267], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1552800.0000, 
sim time next is 1553400.0000, 
raw observation next is [23.2, 66.5, 1.0, 2.0, 0.3907700522048922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 487579.9581589521, 487579.9581589521, 127396.8807257692], 
processed observation next is [0.0, 1.0, 0.4148148148148148, 0.665, 1.0, 1.0, 0.27472625262487166, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1741356993424829, 0.1741356993424829, 0.24499400139570998], 
reward next is 0.7550, 
noisyNet noise sample is [array([1.9259369], dtype=float32), 0.026134131]. 
=============================================
[2019-03-22 23:43:25,859] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4864969e-32 1.3232173e-25 0.0000000e+00 1.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-22 23:43:25,869] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0968
[2019-03-22 23:43:25,873] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.3, 60.0, 1.0, 2.0, 0.6395768170715964, 1.0, 2.0, 0.6395768170715964, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1468630.788324469, 1468630.788324469, 282429.8087033341], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1958400.0000, 
sim time next is 1959000.0000, 
raw observation next is [28.4, 59.66666666666666, 1.0, 2.0, 0.6135721687978049, 1.0, 2.0, 0.6135721687978049, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1409300.582680891, 1409300.582680891, 273243.8880692305], 
processed observation next is [1.0, 0.6956521739130435, 0.6074074074074074, 0.5966666666666666, 1.0, 1.0, 0.5399668676164343, 1.0, 1.0, 0.5399668676164343, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5033216366717468, 0.5033216366717468, 0.5254690155177509], 
reward next is 0.4745, 
noisyNet noise sample is [array([-1.1356138], dtype=float32), -1.6032656]. 
=============================================
[2019-03-22 23:43:25,886] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[54.26981 ]
 [53.483387]
 [53.27365 ]
 [52.7561  ]
 [52.298954]], R is [[54.4503479 ]
 [54.36271286]
 [54.25285339]
 [54.14657974]
 [54.04108429]].
[2019-03-22 23:43:30,558] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.2506476e-22 0.0000000e+00], sum to 1.0000
[2019-03-22 23:43:30,565] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4281
[2019-03-22 23:43:30,571] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.65, 64.0, 1.0, 2.0, 0.5293240005611272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 622437.6532588879, 622437.6532588875, 147228.900813311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2035800.0000, 
sim time next is 2036400.0000, 
raw observation next is [27.8, 63.66666666666667, 1.0, 2.0, 0.533749635227806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 626644.3342059597, 626644.3342059592, 147904.0501298031], 
processed observation next is [0.0, 0.5652173913043478, 0.5851851851851853, 0.6366666666666667, 1.0, 1.0, 0.44494004193786435, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2238015479306999, 0.22380154793069973, 0.28443086563423675], 
reward next is 0.7156, 
noisyNet noise sample is [array([-0.97622615], dtype=float32), 0.24980383]. 
=============================================
[2019-03-22 23:43:31,732] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9496901e-36 1.0000000e+00 1.5716136e-37 1.6629684e-11 1.2140345e-33], sum to 1.0000
[2019-03-22 23:43:31,739] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4320
[2019-03-22 23:43:31,746] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 71.0, 1.0, 2.0, 0.6056599829213591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695836.7960836872, 695836.7960836872, 159329.164863532], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2055600.0000, 
sim time next is 2056200.0000, 
raw observation next is [27.48333333333333, 71.66666666666667, 1.0, 2.0, 0.6054629135036604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695725.1395598896, 695725.1395598896, 159300.5369897904], 
processed observation next is [0.0, 0.8260869565217391, 0.5734567901234567, 0.7166666666666667, 1.0, 1.0, 0.5303129922662624, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.248473264128532, 0.248473264128532, 0.30634718651882764], 
reward next is 0.6937, 
noisyNet noise sample is [array([-1.0208043], dtype=float32), -0.14225402]. 
=============================================
[2019-03-22 23:43:49,693] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-22 23:43:49,694] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:43:49,696] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:43:49,696] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:43:49,697] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:43:49,698] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:43:49,700] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:43:49,697] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:43:49,701] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:43:49,705] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:43:49,706] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:43:49,719] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run12
[2019-03-22 23:43:49,737] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run12
[2019-03-22 23:43:49,738] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run12
[2019-03-22 23:43:49,738] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run12
[2019-03-22 23:43:49,775] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run12
[2019-03-22 23:44:04,388] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.40835056], dtype=float32), 0.124407135]
[2019-03-22 23:44:04,389] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.4, 58.0, 1.0, 2.0, 0.5572226014139381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 704395.8673465628, 704395.8673465628, 153211.1970817576]
[2019-03-22 23:44:04,390] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:44:04,393] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7259180e-34 1.0000000e+00 1.1046864e-34 1.3601232e-15 1.6064144e-34], sampled 0.8260758849152385
[2019-03-22 23:44:12,052] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.40835056], dtype=float32), 0.124407135]
[2019-03-22 23:44:12,057] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.0, 43.0, 1.0, 2.0, 0.3212199562205705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 407801.9546615694, 407801.954661569, 118226.7206014312]
[2019-03-22 23:44:12,058] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:44:12,060] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 1.3072790e-38 3.2434003e-19 5.9739629e-38], sampled 0.41401178318821585
[2019-03-22 23:44:18,556] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.40835056], dtype=float32), 0.124407135]
[2019-03-22 23:44:18,557] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.58586645333333, 55.183952435, 1.0, 2.0, 0.6417203851027921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 786555.2677477662, 786555.2677477662, 167641.7495291572]
[2019-03-22 23:44:18,559] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:44:18,561] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.45387414e-32 1.00000000e+00 1.44911215e-33 7.74750120e-16
 3.79592817e-34], sampled 0.17011551446616646
[2019-03-22 23:44:24,689] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.40835056], dtype=float32), 0.124407135]
[2019-03-22 23:44:24,690] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.1, 63.33333333333334, 1.0, 2.0, 0.3573889652369676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 448982.3204113223, 448982.3204113219, 122893.9134373079]
[2019-03-22 23:44:24,691] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:44:24,694] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.0171714e-36 1.0000000e+00 5.5940884e-37 1.7842617e-18 4.7536219e-37], sampled 0.2422183217338053
[2019-03-22 23:44:30,062] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.40835056], dtype=float32), 0.124407135]
[2019-03-22 23:44:30,063] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.500083, 84.7656792, 1.0, 2.0, 0.3869505163851091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482066.0675867597, 482066.0675867597, 126850.4582009228]
[2019-03-22 23:44:30,064] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:44:30,066] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.7038368e-32 1.0000000e+00 1.2360068e-33 2.8774993e-10 3.0300180e-33], sampled 0.11978263507430476
[2019-03-22 23:44:35,628] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.40835056], dtype=float32), 0.124407135]
[2019-03-22 23:44:35,632] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.0, 88.5, 1.0, 2.0, 0.511391948822418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 610313.7406566628, 610313.7406566628, 144709.9300968849]
[2019-03-22 23:44:35,635] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:44:35,636] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.5883215e-34 1.0000000e+00 5.6556948e-36 1.0906251e-13 6.2671441e-35], sampled 0.5841380045397727
[2019-03-22 23:44:42,989] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.40835056], dtype=float32), 0.124407135]
[2019-03-22 23:44:42,991] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.57628691166667, 95.13406795, 1.0, 2.0, 0.7708127908207707, 1.0, 2.0, 0.7708127908207707, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260421465616, 1758088.915862387, 1758088.915862386, 331841.7312316707]
[2019-03-22 23:44:42,992] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:44:42,996] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0. 0. 0. 1. 0.], sampled 0.026100269448171787
[2019-03-22 23:44:43,543] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.40835056], dtype=float32), 0.124407135]
[2019-03-22 23:44:43,545] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.89246234, 92.54792849, 1.0, 2.0, 0.9062865163797462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 1033832.060277103, 1033832.060277102, 218915.6398788229]
[2019-03-22 23:44:43,546] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:44:43,550] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.9824039e-26 9.9983704e-01 1.8581846e-29 1.6290204e-04 2.7540449e-29], sampled 0.9381831587039089
[2019-03-22 23:44:54,267] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.40835056], dtype=float32), 0.124407135]
[2019-03-22 23:44:54,269] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.31666666666667, 81.0, 1.0, 2.0, 0.5552302971663778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 647182.398947488, 647182.398947488, 151227.8298933918]
[2019-03-22 23:44:54,272] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:44:54,277] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.7140605e-33 1.0000000e+00 9.6993402e-35 8.7994678e-13 1.9716167e-34], sampled 0.9082154405319687
[2019-03-22 23:45:41,088] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8912.4072 2162076824.9266 300.0000
[2019-03-22 23:45:41,594] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 9015.7110 2116045999.0616 299.0000
[2019-03-22 23:45:41,705] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8353.3410 2421817657.1878 414.0000
[2019-03-22 23:45:41,883] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8844.4152 2185036919.1411 359.0000
[2019-03-22 23:45:41,884] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8767.6955 2228215946.1035 311.0000
[2019-03-22 23:45:42,897] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 275000, evaluation results [275000.0, 8353.340979177075, 2421817657.1878424, 414.0, 8912.407168105345, 2162076824.926587, 300.0, 9015.711000136205, 2116045999.0616422, 299.0, 8767.69548610562, 2228215946.1034627, 311.0, 8844.415199310673, 2185036919.141122, 359.0]
[2019-03-22 23:45:43,435] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3114132e-32 1.6291978e-13 3.7221796e-35 1.0000000e+00 1.2447252e-36], sum to 1.0000
[2019-03-22 23:45:43,443] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9465
[2019-03-22 23:45:43,451] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 41.0, 1.0, 2.0, 0.3969196178916281, 1.0, 2.0, 0.3969196178916281, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 978447.7597401028, 978447.7597401019, 208164.6676227169], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2365200.0000, 
sim time next is 2365800.0000, 
raw observation next is [28.11666666666667, 40.83333333333334, 1.0, 2.0, 0.4278742181384738, 1.0, 2.0, 0.4278742181384738, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1052717.621565977, 1052717.621565977, 216959.5380148367], 
processed observation next is [1.0, 0.391304347826087, 0.5969135802469138, 0.40833333333333344, 1.0, 1.0, 0.31889787873627834, 1.0, 1.0, 0.31889787873627834, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3759705791307061, 0.3759705791307061, 0.41722988079776285], 
reward next is 0.5828, 
noisyNet noise sample is [array([-0.51057804], dtype=float32), -0.48213834]. 
=============================================
[2019-03-22 23:45:49,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.1832922e-38 0.0000000e+00], sum to 1.0000
[2019-03-22 23:45:49,915] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1723
[2019-03-22 23:45:49,922] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.31666666666667, 31.66666666666667, 1.0, 2.0, 0.3588368611479057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 449772.2523939685, 449772.2523939681, 123071.489465042], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2490600.0000, 
sim time next is 2491200.0000, 
raw observation next is [30.1, 32.0, 1.0, 2.0, 0.3560914504609924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446806.6616443675, 446806.6616443675, 122712.3802333334], 
processed observation next is [1.0, 0.8695652173913043, 0.6703703703703704, 0.32, 1.0, 1.0, 0.23344220292975285, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15957380773013125, 0.15957380773013125, 0.23598534660256423], 
reward next is 0.7640, 
noisyNet noise sample is [array([-0.31509396], dtype=float32), -1.0152501]. 
=============================================
[2019-03-22 23:45:54,754] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.6500868e-36 1.0000000e+00 1.4172557e-34 4.7926392e-38 3.4969043e-35], sum to 1.0000
[2019-03-22 23:45:54,763] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7752
[2019-03-22 23:45:54,774] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1760592.456073818 W.
[2019-03-22 23:45:54,781] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.7, 30.0, 1.0, 2.0, 0.8774883125055644, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9646175778080157, 6.9112, 6.9112, 121.9260426156618, 1760592.456073818, 1760592.456073818, 345461.7700661579], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2555400.0000, 
sim time next is 2556000.0000, 
raw observation next is [33.8, 30.0, 1.0, 2.0, 0.5067287699301963, 1.0, 1.0, 0.5067287699301963, 1.0, 2.0, 0.8090961047500829, 6.9112, 6.9112, 121.94756008, 1772827.747624072, 1772827.747624072, 347020.9779298937], 
processed observation next is [1.0, 0.6086956521739131, 0.8074074074074074, 0.3, 1.0, 1.0, 0.4127723451549956, 1.0, 0.5, 0.4127723451549956, 1.0, 1.0, 0.7613701309376036, 0.0, 0.0, 0.8096049824067558, 0.6331527670085971, 0.6331527670085971, 0.6673480344805648], 
reward next is 0.3327, 
noisyNet noise sample is [array([-0.24488418], dtype=float32), -0.75372434]. 
=============================================
[2019-03-22 23:45:54,792] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[40.112915]
 [39.853333]
 [40.34658 ]
 [40.32414 ]
 [40.925568]], R is [[39.70123672]
 [39.63987732]
 [39.58912659]
 [39.60177231]
 [39.20575333]].
[2019-03-22 23:45:59,465] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:45:59,476] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3294
[2019-03-22 23:45:59,480] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.55, 80.0, 1.0, 2.0, 0.5797547851444929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 674328.236541025, 674328.2365410255, 155276.5833222739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2662200.0000, 
sim time next is 2662800.0000, 
raw observation next is [25.4, 80.66666666666667, 1.0, 2.0, 0.576911804542468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 671703.699719032, 671703.6997190316, 154825.2118504687], 
processed observation next is [0.0, 0.8260869565217391, 0.49629629629629624, 0.8066666666666668, 1.0, 1.0, 0.4963235768362715, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23989417847108288, 0.23989417847108271, 0.29774079202013215], 
reward next is 0.7023, 
noisyNet noise sample is [array([-0.46754074], dtype=float32), -1.8415769]. 
=============================================
[2019-03-22 23:46:01,846] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:46:01,854] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5818
[2019-03-22 23:46:01,860] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 94.16666666666666, 1.0, 2.0, 0.4717347610908037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571850.9361365397, 571850.9361365397, 138838.6368055314], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2695800.0000, 
sim time next is 2696400.0000, 
raw observation next is [21.2, 93.0, 1.0, 2.0, 0.4591232413775544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 559069.157127115, 559069.157127115, 137001.5699384149], 
processed observation next is [0.0, 0.21739130434782608, 0.34074074074074073, 0.93, 1.0, 1.0, 0.356099096878041, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19966755611682677, 0.19966755611682677, 0.2634645575738748], 
reward next is 0.7365, 
noisyNet noise sample is [array([0.57089114], dtype=float32), -0.80989134]. 
=============================================
[2019-03-22 23:46:08,253] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:46:08,263] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2159
[2019-03-22 23:46:08,266] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.08333333333334, 79.83333333333334, 1.0, 2.0, 0.9510366203752069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1084115.085294425, 1084115.085294425, 229117.7701943414], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2794200.0000, 
sim time next is 2794800.0000, 
raw observation next is [27.26666666666667, 79.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 11.01698959055815, 6.9112, 121.9041889931103, 3266357.312675195, 1164202.921779141, 245584.7393572843], 
processed observation next is [1.0, 0.34782608695652173, 0.5654320987654322, 0.7966666666666667, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.41057895905581504, 0.0, 0.8093170434925596, 1.1665561830982838, 0.4157867577782647, 0.4722783449178544], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0501446], dtype=float32), 0.60973674]. 
=============================================
[2019-03-22 23:46:20,079] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:46:20,086] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5278
[2019-03-22 23:46:20,092] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1683123.450093 W.
[2019-03-22 23:46:20,097] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.6, 81.0, 1.0, 2.0, 0.7379760250560151, 1.0, 1.0, 0.7379760250560151, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1683123.450093, 1683123.450093, 318791.9912517056], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2989800.0000, 
sim time next is 2990400.0000, 
raw observation next is [26.73333333333333, 85.33333333333333, 1.0, 2.0, 0.8222318374957761, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1652315.532368609, 1652315.532368609, 340693.228278955], 
processed observation next is [1.0, 0.6086956521739131, 0.545679012345679, 0.8533333333333333, 1.0, 1.0, 0.7883712351140192, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.590112690131646, 0.590112690131646, 0.6551792851518365], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.33027175], dtype=float32), -0.33301213]. 
=============================================
[2019-03-22 23:46:23,427] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4740117e-25 1.0000000e+00 6.1449952e-33 3.4094051e-26 6.5647113e-33], sum to 1.0000
[2019-03-22 23:46:23,435] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5963
[2019-03-22 23:46:23,448] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2745667.077049398 W.
[2019-03-22 23:46:23,456] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 76.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.7273716944345, 6.9112, 121.922354758273, 2745667.077049398, 2327726.862584882, 443049.4788131016], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3063600.0000, 
sim time next is 3064200.0000, 
raw observation next is [30.16666666666666, 76.5, 1.0, 2.0, 0.6533107865882971, 1.0, 2.0, 0.6400200552705834, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2190189.140017142, 2190189.140017141, 416929.5259277736], 
processed observation next is [1.0, 0.4782608695652174, 0.6728395061728393, 0.765, 1.0, 1.0, 0.587274745938449, 1.0, 1.0, 0.5714524467506945, 1.0, 0.5, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7822104071489793, 0.7822104071489789, 0.8017875498611031], 
reward next is 0.1982, 
noisyNet noise sample is [array([-2.463908], dtype=float32), 0.6537991]. 
=============================================
[2019-03-22 23:46:27,378] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:46:27,387] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8302
[2019-03-22 23:46:27,391] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.93333333333334, 56.33333333333334, 1.0, 2.0, 0.7014058117158612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 841758.430332202, 841758.430332202, 178306.5183256296], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3136800.0000, 
sim time next is 3137400.0000, 
raw observation next is [28.4, 55.5, 1.0, 2.0, 0.7468515934358746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 892059.2560711806, 892059.2560711806, 187091.6585365566], 
processed observation next is [1.0, 0.30434782608695654, 0.6074074074074074, 0.555, 1.0, 1.0, 0.6986328493284222, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31859259145399305, 0.31859259145399305, 0.35979165103183963], 
reward next is 0.6402, 
noisyNet noise sample is [array([-1.1476232], dtype=float32), -1.2318714]. 
=============================================
[2019-03-22 23:46:34,020] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:46:34,030] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9934
[2019-03-22 23:46:34,034] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.53333333333333, 60.0, 1.0, 2.0, 0.4617443999327661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 559862.2019736118, 559862.2019736118, 137324.8504490312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3226800.0000, 
sim time next is 3227400.0000, 
raw observation next is [26.65, 60.5, 1.0, 2.0, 0.4686326684413961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 566450.8974415314, 566450.8974415314, 138313.6200174906], 
processed observation next is [0.0, 0.34782608695652173, 0.5425925925925925, 0.605, 1.0, 1.0, 0.36741984338261446, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2023038919434041, 0.2023038919434041, 0.2659877308028666], 
reward next is 0.7340, 
noisyNet noise sample is [array([0.3991158], dtype=float32), -0.9334344]. 
=============================================
[2019-03-22 23:46:37,523] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-22 23:46:37,525] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:46:37,526] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:46:37,526] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:46:37,527] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:46:37,528] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:46:37,529] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:46:37,529] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:46:37,530] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:46:37,529] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:46:37,532] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:46:37,548] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run13
[2019-03-22 23:46:37,565] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run13
[2019-03-22 23:46:37,566] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run13
[2019-03-22 23:46:37,567] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run13
[2019-03-22 23:46:37,623] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run13
[2019-03-22 23:46:48,233] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:46:48,237] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.16666666666667, 38.0, 1.0, 2.0, 0.3033982746942798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 388179.3216157662, 388179.3216157662, 115997.8619762557]
[2019-03-22 23:46:48,239] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:46:48,242] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.1537868177713303
[2019-03-22 23:46:52,576] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:46:52,581] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.33333333333334, 47.33333333333333, 1.0, 2.0, 0.2630392189351145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 339301.6817539089, 339301.6817539089, 103123.0365386632]
[2019-03-22 23:46:52,581] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:46:52,584] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5641135142450503
[2019-03-22 23:47:09,586] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:47:09,587] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.58333333333334, 32.83333333333334, 1.0, 2.0, 0.9566768104272126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.202153271477635, 6.9112, 121.9246511814457, 1299720.758489262, 1150728.378722215, 233397.6500237333]
[2019-03-22 23:47:09,589] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:47:09,591] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.361032369092285
[2019-03-22 23:47:09,594] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1299720.758489262 W.
[2019-03-22 23:47:12,739] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:47:12,739] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.544263595, 79.386728835, 1.0, 2.0, 0.2900254364218296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 369915.8833477332, 369915.8833477332, 114351.8282279932]
[2019-03-22 23:47:12,740] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:47:12,742] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5645021934227809
[2019-03-22 23:47:17,612] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:47:17,614] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.15549496666667, 93.49634345833334, 1.0, 2.0, 0.6716388925922891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 773560.246337154, 773560.246337154, 171245.46628991]
[2019-03-22 23:47:17,614] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:47:17,616] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.19469936434447332
[2019-03-22 23:47:32,192] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:47:32,193] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.66666666666667, 80.66666666666667, 1.0, 2.0, 0.8156234447714489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 929659.9191698672, 929659.9191698672, 199199.7209491604]
[2019-03-22 23:47:32,194] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:47:32,196] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.949615133152221
[2019-03-22 23:47:47,081] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:47:47,082] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.5, 66.66666666666666, 1.0, 2.0, 0.473218302407576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571636.4529930253, 571636.4529930253, 139001.3443079571]
[2019-03-22 23:47:47,083] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:47:47,086] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4092978419410358
[2019-03-22 23:47:48,483] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:47:48,483] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.08333333333334, 72.16666666666666, 1.0, 2.0, 0.4441126416193137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 540994.2899438395, 540994.28994384, 134764.2673243574]
[2019-03-22 23:47:48,483] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:47:48,487] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4310726220802762
[2019-03-22 23:47:51,694] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:47:51,695] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.91242125, 83.64071326999999, 1.0, 2.0, 0.555985020741818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 649433.4009135361, 649433.4009135365, 151413.0826524293]
[2019-03-22 23:47:51,695] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:47:51,697] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.04508034346529477
[2019-03-22 23:48:00,406] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:48:00,407] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.33333333333334, 91.33333333333334, 1.0, 2.0, 0.7161785470565237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 873590.1380051618, 873590.1380051618, 181661.4939122151]
[2019-03-22 23:48:00,407] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:48:00,409] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5004925104778009
[2019-03-22 23:48:13,270] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:48:13,271] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.33867629833334, 56.85377869166667, 1.0, 2.0, 0.3422889739065156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 430267.5960033878, 430267.5960033878, 120901.0006482615]
[2019-03-22 23:48:13,273] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:48:13,275] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8034166300803423
[2019-03-22 23:48:13,640] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:48:13,641] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.3, 76.0, 1.0, 2.0, 0.429349138884714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524915.4031054376, 524915.4031054376, 132651.3389074999]
[2019-03-22 23:48:13,643] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:48:13,646] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7649910098309334
[2019-03-22 23:48:17,922] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:48:17,922] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.08333333333334, 78.83333333333334, 1.0, 2.0, 0.3635720057266462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455387.9376790206, 455387.9376790206, 123701.958707535]
[2019-03-22 23:48:17,924] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:48:17,927] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.8888199911335581
[2019-03-22 23:48:25,132] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.30310234], dtype=float32), 0.14820911]
[2019-03-22 23:48:25,133] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.75, 59.0, 1.0, 2.0, 0.3558525021125046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 459059.9778118836, 459059.9778118836, 108334.583309957]
[2019-03-22 23:48:25,134] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:48:25,139] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.05743819137180195
[2019-03-22 23:48:28,451] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2619 2170662485.7283 493.0000
[2019-03-22 23:48:28,939] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.0583 2248755290.3993 553.0000
[2019-03-22 23:48:28,988] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.6001 2445376094.7952 746.0000
[2019-03-22 23:48:29,190] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.1818 2120456093.0328 430.0000
[2019-03-22 23:48:29,203] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.5254 2195133212.2000 572.0000
[2019-03-22 23:48:30,221] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 300000, evaluation results [300000.0, 8100.600059888084, 2445376094.795151, 746.0, 8770.261897406637, 2170662485.728274, 493.0, 8924.181835947267, 2120456093.0327566, 430.0, 8582.058316992165, 2248755290.399296, 553.0, 8701.52538790598, 2195133212.199995, 572.0]
[2019-03-22 23:48:35,290] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5910042e-33 0.0000000e+00], sum to 1.0000
[2019-03-22 23:48:35,298] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8282
[2019-03-22 23:48:35,302] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.18333333333333, 92.66666666666667, 1.0, 2.0, 0.6133088373476403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706990.7820918395, 706990.7820918395, 160774.188148523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3373800.0000, 
sim time next is 3374400.0000, 
raw observation next is [24.06666666666667, 92.33333333333334, 1.0, 2.0, 0.6018959295530594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696230.9142193808, 696230.9142193808, 158900.7036423538], 
processed observation next is [1.0, 0.043478260869565216, 0.4469135802469137, 0.9233333333333335, 1.0, 1.0, 0.5260665828012612, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24865389793549314, 0.24865389793549314, 0.30557827623529576], 
reward next is 0.6944, 
noisyNet noise sample is [array([0.21794878], dtype=float32), 0.428748]. 
=============================================
[2019-03-22 23:48:39,827] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.5076192e-35 1.0000000e+00 2.4232040e-36 7.2420414e-32 1.4804001e-35], sum to 1.0000
[2019-03-22 23:48:39,836] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8979
[2019-03-22 23:48:39,840] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 89.5, 1.0, 2.0, 0.6470360822556298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737409.0582130648, 737409.0582130648, 166357.5927797963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3454200.0000, 
sim time next is 3454800.0000, 
raw observation next is [25.16666666666666, 91.0, 1.0, 2.0, 0.6501290516280577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 740935.7331465431, 740935.7331465427, 166916.0643188509], 
processed observation next is [1.0, 1.0, 0.4876543209876541, 0.91, 1.0, 1.0, 0.5834869662238782, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.264619904695194, 0.2646199046951938, 0.3209924313824056], 
reward next is 0.6790, 
noisyNet noise sample is [array([0.00819715], dtype=float32), 0.5875608]. 
=============================================
[2019-03-22 23:48:42,707] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0203157e-28 1.0000000e+00 8.5075525e-35 2.1323480e-25 9.1727055e-30], sum to 1.0000
[2019-03-22 23:48:42,715] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9698
[2019-03-22 23:48:42,724] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1794903.953563946 W.
[2019-03-22 23:48:42,729] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.41666666666666, 80.66666666666667, 1.0, 2.0, 0.7869376974402963, 1.0, 2.0, 0.7869376974402963, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1794903.953563946, 1794903.953563946, 338387.4241440454], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3507000.0000, 
sim time next is 3507600.0000, 
raw observation next is [28.33333333333334, 82.33333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.562697304743433, 6.9112, 121.9239529074501, 2212046.535383204, 1878427.403231154, 381799.1864888588], 
processed observation next is [1.0, 0.6086956521739131, 0.6049382716049385, 0.8233333333333335, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.06514973047434332, 0.0, 0.8094482553307536, 0.7900166197797157, 0.6708669297254122, 0.7342292047862669], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6743243], dtype=float32), 0.30140564]. 
=============================================
[2019-03-22 23:48:46,335] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:48:46,346] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4165
[2019-03-22 23:48:46,351] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.45, 93.5, 1.0, 2.0, 0.5779806286761224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688138.9564953335, 688138.9564953335, 155635.2423156492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3569400.0000, 
sim time next is 3570000.0000, 
raw observation next is [22.26666666666667, 93.33333333333334, 1.0, 2.0, 0.5202340498488792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 621726.2726741177, 621726.2726741172, 146155.4038298317], 
processed observation next is [1.0, 0.30434782608695654, 0.38024691358024704, 0.9333333333333335, 1.0, 1.0, 0.4288500593439038, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22204509738361347, 0.2220450973836133, 0.28106808428813784], 
reward next is 0.7189, 
noisyNet noise sample is [array([0.8486159], dtype=float32), -0.6928985]. 
=============================================
[2019-03-22 23:48:46,373] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[62.829666]
 [62.683064]
 [62.58895 ]
 [62.69957 ]
 [62.644104]], R is [[63.32545471]
 [63.39290237]
 [63.45898819]
 [63.51467133]
 [63.58311844]].
[2019-03-22 23:48:48,424] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:48:48,432] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4233
[2019-03-22 23:48:48,438] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 88.0, 1.0, 2.0, 0.5457005767406324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641986.4578980857, 641986.4578980857, 149909.4450543516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3624000.0000, 
sim time next is 3624600.0000, 
raw observation next is [24.0, 85.0, 1.0, 2.0, 0.5352603653976642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 632176.4500010482, 632176.4500010482, 148302.9018014316], 
processed observation next is [1.0, 0.9565217391304348, 0.4444444444444444, 0.85, 1.0, 1.0, 0.4467385302353145, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22577730357180292, 0.22577730357180292, 0.28519788807967617], 
reward next is 0.7148, 
noisyNet noise sample is [array([0.71982443], dtype=float32), -2.3459032]. 
=============================================
[2019-03-22 23:48:54,091] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.18769885e-27
 0.00000000e+00], sum to 1.0000
[2019-03-22 23:48:54,100] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8487
[2019-03-22 23:48:54,105] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333333, 89.16666666666667, 1.0, 2.0, 0.7136999304661727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813424.3079552135, 813424.3079552135, 178757.4554525965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3694200.0000, 
sim time next is 3694800.0000, 
raw observation next is [26.86666666666667, 89.33333333333334, 1.0, 2.0, 0.7178856394877438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818197.4270262625, 818197.4270262625, 179560.9438940632], 
processed observation next is [1.0, 0.782608695652174, 0.5506172839506175, 0.8933333333333334, 1.0, 1.0, 0.6641495708187426, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29221336679509374, 0.29221336679509374, 0.3453095074885831], 
reward next is 0.6547, 
noisyNet noise sample is [array([-2.0626922], dtype=float32), -0.07461649]. 
=============================================
[2019-03-22 23:48:57,204] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.8966717e-36 1.0000000e+00 5.8013947e-38 2.8298715e-27 3.1506242e-33], sum to 1.0000
[2019-03-22 23:48:57,212] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3028
[2019-03-22 23:48:57,218] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1626292.498127237 W.
[2019-03-22 23:48:57,223] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.33333333333334, 94.0, 1.0, 2.0, 0.7994322712529766, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1626292.498127237, 1626292.498127237, 336122.9585953369], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3748800.0000, 
sim time next is 3749400.0000, 
raw observation next is [26.5, 94.0, 1.0, 2.0, 0.8746302202997778, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1712125.021768921, 1712125.021768921, 351545.9980795279], 
processed observation next is [1.0, 0.391304347826087, 0.5370370370370371, 0.94, 1.0, 1.0, 0.8507502622616402, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.611473222060329, 0.611473222060329, 0.6760499963067845], 
reward next is 0.3240, 
noisyNet noise sample is [array([-0.6326358], dtype=float32), -0.6373581]. 
=============================================
[2019-03-22 23:49:05,551] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 4.958676e-38 0.000000e+00], sum to 1.0000
[2019-03-22 23:49:05,561] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5190
[2019-03-22 23:49:05,569] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 94.66666666666666, 1.0, 2.0, 0.7161467662111348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816214.5217972418, 816214.5217972418, 179224.1990219064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3908400.0000, 
sim time next is 3909000.0000, 
raw observation next is [25.85, 94.33333333333334, 1.0, 2.0, 0.72122255099944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 822002.6521444863, 822002.6521444863, 180201.9914481305], 
processed observation next is [0.0, 0.21739130434782608, 0.5129629629629631, 0.9433333333333335, 1.0, 1.0, 0.6681220845231428, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29357237576588796, 0.29357237576588796, 0.3465422912464048], 
reward next is 0.6535, 
noisyNet noise sample is [array([-1.5199486], dtype=float32), -1.7620249]. 
=============================================
[2019-03-22 23:49:05,582] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[66.07444 ]
 [66.097496]
 [66.10339 ]
 [66.09768 ]
 [66.079056]], R is [[66.02039337]
 [66.01552582]
 [66.01232147]
 [66.01055145]
 [66.00994873]].
[2019-03-22 23:49:05,598] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:49:05,609] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0312
[2019-03-22 23:49:05,613] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.7523220758437918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 857467.6995142838, 857467.6995142838, 186289.07030845], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3898800.0000, 
sim time next is 3899400.0000, 
raw observation next is [26.83333333333333, 89.83333333333334, 1.0, 2.0, 0.7320571778248739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 834357.9779134631, 834357.9779134627, 182304.895869205], 
processed observation next is [0.0, 0.13043478260869565, 0.5493827160493825, 0.8983333333333334, 1.0, 1.0, 0.6810204497915165, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2979849921119511, 0.29798499211195095, 0.3505863382100096], 
reward next is 0.6494, 
noisyNet noise sample is [array([0.03974203], dtype=float32), 1.4233412]. 
=============================================
[2019-03-22 23:49:05,883] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.000000e+00 1.000000e+00 0.000000e+00 7.435057e-38 0.000000e+00], sum to 1.0000
[2019-03-22 23:49:05,889] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1844
[2019-03-22 23:49:05,900] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.98333333333333, 69.0, 1.0, 2.0, 0.7889111893861713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 899195.0249574006, 899195.0249574002, 193666.3760483042], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3946200.0000, 
sim time next is 3946800.0000, 
raw observation next is [30.96666666666667, 68.0, 1.0, 2.0, 0.7560300405303179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 861696.2705053339, 861696.2705053339, 187028.6312551579], 
processed observation next is [0.0, 0.6956521739130435, 0.7024691358024692, 0.68, 1.0, 1.0, 0.7095595720599022, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30774866803761924, 0.30774866803761924, 0.3596704447214575], 
reward next is 0.6403, 
noisyNet noise sample is [array([-1.6761496], dtype=float32), -3.2845023]. 
=============================================
[2019-03-22 23:49:06,178] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.00000e+00 1.00000e+00 0.00000e+00 8.08628e-36 0.00000e+00], sum to 1.0000
[2019-03-22 23:49:06,186] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4942
[2019-03-22 23:49:06,191] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.771609890515014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 879463.8202674534, 879463.8202674534, 190152.0553008922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3931800.0000, 
sim time next is 3932400.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.7640533583523271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 870846.159454618, 870846.159454618, 188632.9325222276], 
processed observation next is [0.0, 0.5217391304347826, 0.7037037037037037, 0.7, 1.0, 1.0, 0.7191111408956276, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31101648551950645, 0.31101648551950645, 0.36275563946582234], 
reward next is 0.6372, 
noisyNet noise sample is [array([-0.04745125], dtype=float32), 0.4276308]. 
=============================================
[2019-03-22 23:49:08,405] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:49:08,415] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8464
[2019-03-22 23:49:08,420] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 83.33333333333334, 1.0, 2.0, 0.670689513351238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 764379.6577056436, 764379.6577056436, 170666.5187426556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3972000.0000, 
sim time next is 3972600.0000, 
raw observation next is [26.15, 83.5, 1.0, 2.0, 0.6720911132061906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 765977.848371696, 765977.8483716955, 170924.7473890713], 
processed observation next is [0.0, 1.0, 0.524074074074074, 0.835, 1.0, 1.0, 0.6096322776264174, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2735635172756057, 0.2735635172756055, 0.32870143728667556], 
reward next is 0.6713, 
noisyNet noise sample is [array([-0.8422942], dtype=float32), 1.1634495]. 
=============================================
[2019-03-22 23:49:08,429] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:49:08,444] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5702
[2019-03-22 23:49:08,451] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.86666666666667, 69.0, 1.0, 2.0, 0.7825174332047576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 891903.2293104073, 891903.2293104068, 192360.5748182968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3940800.0000, 
sim time next is 3941400.0000, 
raw observation next is [30.93333333333333, 69.5, 1.0, 2.0, 0.7975348792874495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 909030.0711087177, 909030.0711087177, 195438.1921746335], 
processed observation next is [0.0, 0.6086956521739131, 0.7012345679012344, 0.695, 1.0, 1.0, 0.7589700943898208, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32465359682454203, 0.32465359682454203, 0.3758426772589106], 
reward next is 0.6242, 
noisyNet noise sample is [array([0.27481243], dtype=float32), 0.07556962]. 
=============================================
[2019-03-22 23:49:16,515] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5210820e-38 1.0000000e+00 7.5735236e-37 2.7375721e-32 3.0009322e-37], sum to 1.0000
[2019-03-22 23:49:16,525] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8297
[2019-03-22 23:49:16,537] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1566657.108176137 W.
[2019-03-22 23:49:16,543] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.18333333333333, 77.16666666666667, 1.0, 2.0, 0.6869563277456541, 1.0, 1.0, 0.6869563277456541, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1566657.108176137, 1566657.108176138, 299255.7398050202], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4097400.0000, 
sim time next is 4098000.0000, 
raw observation next is [26.36666666666667, 75.33333333333334, 1.0, 2.0, 0.4395710630757359, 1.0, 2.0, 0.4395710630757359, 1.0, 1.0, 0.6998114482466559, 6.9112, 6.9112, 121.94756008, 1503651.719465036, 1503651.719465036, 314850.0255269858], 
processed observation next is [1.0, 0.43478260869565216, 0.5320987654320989, 0.7533333333333334, 1.0, 1.0, 0.3328226941377808, 1.0, 1.0, 0.3328226941377808, 1.0, 0.5, 0.6247643103083198, 0.0, 0.0, 0.8096049824067558, 0.5370184712375128, 0.5370184712375128, 0.6054808183211265], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7944912], dtype=float32), 1.0318336]. 
=============================================
[2019-03-22 23:49:16,561] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[53.703026]
 [54.96821 ]
 [54.761963]
 [55.12027 ]
 [54.42335 ]], R is [[53.19065475]
 [53.08325577]
 [52.92108917]
 [52.80417633]
 [52.74340439]].
[2019-03-22 23:49:19,309] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:49:19,322] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2262
[2019-03-22 23:49:19,327] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.4371810224377863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 536156.916280609, 536156.916280609, 133843.2625761271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4158000.0000, 
sim time next is 4158600.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.5320810840414871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652639.5659251582, 652639.5659251582, 148610.7641838634], 
processed observation next is [1.0, 0.13043478260869565, 0.2962962962962963, 1.0, 1.0, 1.0, 0.44295367147796083, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23308555925898508, 0.23308555925898508, 0.2857899311228142], 
reward next is 0.7142, 
noisyNet noise sample is [array([0.24184194], dtype=float32), 0.7274714]. 
=============================================
[2019-03-22 23:49:21,549] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.43318e-38 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-22 23:49:21,556] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3410
[2019-03-22 23:49:21,563] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1552082.367846295 W.
[2019-03-22 23:49:21,571] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.66666666666667, 39.33333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.5946078580368, 6.9112, 121.923296466213, 1552082.367846295, 1202124.344538702, 247692.2941082155], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4192800.0000, 
sim time next is 4193400.0000, 
raw observation next is [32.83333333333333, 37.66666666666666, 1.0, 2.0, 0.5905961257414273, 1.0, 1.0, 0.5905961257414273, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9256310787604, 1377697.731610505, 1377697.731610505, 266291.3118349276], 
processed observation next is [1.0, 0.5217391304347826, 0.7716049382716048, 0.3766666666666666, 1.0, 1.0, 0.512614435406461, 1.0, 0.5, 0.512614435406461, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094593966430789, 0.4920349041466089, 0.4920349041466089, 0.51209867660563], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.34789422], dtype=float32), 1.3329719]. 
=============================================
[2019-03-22 23:49:24,672] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-22 23:49:24,674] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:49:24,674] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:49:24,674] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:49:24,676] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:49:24,678] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:49:24,680] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:49:24,681] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:49:24,681] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:49:24,683] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:49:24,684] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:49:24,697] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run14
[2019-03-22 23:49:24,713] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run14
[2019-03-22 23:49:24,732] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run14
[2019-03-22 23:49:24,749] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run14
[2019-03-22 23:49:24,771] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run14
[2019-03-22 23:49:26,918] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:49:26,920] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.91000622666667, 51.42661338666667, 1.0, 2.0, 0.4272701324373909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520681.6220780967, 520681.6220780967, 132300.4984586983]
[2019-03-22 23:49:26,922] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:49:26,925] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.11596197645068218
[2019-03-22 23:49:40,813] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:49:40,818] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.0, 64.0, 1.0, 2.0, 0.2158471413212797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 278416.2454673357, 278416.2454673357, 91109.72325395783]
[2019-03-22 23:49:40,819] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:49:40,823] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.9133335733710914
[2019-03-22 23:49:47,455] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:49:47,456] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.2, 72.66666666666667, 1.0, 2.0, 0.3849462546928865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 480692.9358286054, 480692.9358286054, 126595.0632859914]
[2019-03-22 23:49:47,458] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:49:47,462] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.26951612599002306
[2019-03-22 23:49:50,029] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:49:50,030] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.8, 89.0, 1.0, 2.0, 0.3603857028667307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 451356.6497012962, 451356.6497012962, 123273.1118447614]
[2019-03-22 23:49:50,032] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:49:50,034] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.038915118834457085
[2019-03-22 23:49:57,939] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:49:57,940] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.838693455, 90.604370975, 1.0, 2.0, 0.3684019966841644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 461751.1667734474, 461751.166773447, 124360.5974220193]
[2019-03-22 23:49:57,941] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:49:57,944] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.12459045792069245
[2019-03-22 23:50:11,992] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:50:11,994] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.79625225666667, 65.37085884333334, 1.0, 2.0, 0.5134986926318875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 609873.7382143426, 609873.7382143422, 144934.6475036736]
[2019-03-22 23:50:11,996] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:50:11,999] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.4528559080098311
[2019-03-22 23:50:37,978] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:50:37,979] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.15306951, 88.47168745, 1.0, 2.0, 0.7690232055993762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 876513.8883175642, 876513.8883175642, 189626.3131783268]
[2019-03-22 23:50:37,981] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:50:37,986] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7379689011108277
[2019-03-22 23:50:45,186] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:50:45,188] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.51666666666667, 85.00000000000001, 1.0, 2.0, 0.5057010167719389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 602931.3516543022, 602931.3516543019, 143785.2787860151]
[2019-03-22 23:50:45,191] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:50:45,195] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.30587082663968146
[2019-03-22 23:51:04,346] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:51:04,347] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 89.0, 1.0, 2.0, 0.9081432224687004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260371162602, 1035186.58861679, 1035186.588616789, 219299.1677427193]
[2019-03-22 23:51:04,349] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-22 23:51:04,351] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.2421188e-34 1.0000000e+00 0.0000000e+00 8.1500454e-28 1.0565906e-35], sampled 0.18925235343470914
[2019-03-22 23:51:05,205] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37814254], dtype=float32), 0.14722073]
[2019-03-22 23:51:05,207] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.27323550666667, 70.80952332333334, 1.0, 2.0, 0.2718714992297884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 350531.0210831255, 350531.0210831255, 112158.5279750311]
[2019-03-22 23:51:05,208] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:51:05,211] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.6227606766574072
[2019-03-22 23:51:15,817] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2619 2170662485.7283 493.0000
[2019-03-22 23:51:15,944] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.6001 2445376094.7952 746.0000
[2019-03-22 23:51:16,258] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.1199 2120488280.6681 430.0000
[2019-03-22 23:51:16,294] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.6068 2195090877.2100 572.0000
[2019-03-22 23:51:16,396] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.9180 2248703752.9508 553.0000
[2019-03-22 23:51:17,412] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 325000, evaluation results [325000.0, 8100.600059888084, 2445376094.795151, 746.0, 8770.261897406637, 2170662485.728274, 493.0, 8924.119936648443, 2120488280.668146, 430.0, 8582.91798649268, 2248703752.950837, 553.0, 8701.60680134833, 2195090877.2099733, 572.0]
[2019-03-22 23:51:19,284] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.8037296e-31 1.0000000e+00 1.9278809e-38 3.1156768e-33 2.2654466e-30], sum to 1.0000
[2019-03-22 23:51:19,291] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0237
[2019-03-22 23:51:19,311] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1725305.011650544 W.
[2019-03-22 23:51:19,317] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.4, 58.5, 1.0, 2.0, 0.4959624737517165, 1.0, 1.0, 0.4959624737517165, 1.0, 1.0, 0.7910006443540933, 6.911200000000001, 6.9112, 121.94756008, 1725305.011650544, 1725305.011650543, 341730.8337357916], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4264200.0000, 
sim time next is 4264800.0000, 
raw observation next is [27.26666666666667, 61.0, 1.0, 2.0, 0.478293924046866, 1.0, 2.0, 0.478293924046866, 1.0, 2.0, 0.7616783729357554, 6.911200000000001, 6.9112, 121.94756008, 1644109.265236971, 1644109.26523697, 333115.6241916368], 
processed observation next is [1.0, 0.34782608695652173, 0.5654320987654322, 0.61, 1.0, 1.0, 0.3789213381510309, 1.0, 1.0, 0.3789213381510309, 1.0, 1.0, 0.7020979661696941, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5871818804417753, 0.587181880441775, 0.6406069695993015], 
reward next is 0.3594, 
noisyNet noise sample is [array([0.8412293], dtype=float32), -1.5293285]. 
=============================================
[2019-03-22 23:51:23,010] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6027725e-38 1.0000000e+00 1.6757516e-38 0.0000000e+00 2.7000432e-36], sum to 1.0000
[2019-03-22 23:51:23,017] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6558
[2019-03-22 23:51:23,028] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 94.00000000000001, 1.0, 2.0, 0.9597197647220109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.984473841780147, 6.9112, 121.9257823224725, 1147859.752896813, 1110337.07686898, 232045.8052751591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4331400.0000, 
sim time next is 4332000.0000, 
raw observation next is [23.66666666666666, 94.0, 1.0, 2.0, 0.8555025522257342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9259984914974, 992974.2783576988, 992974.2783576988, 208606.1592582218], 
processed observation next is [1.0, 0.13043478260869565, 0.4320987654320985, 0.94, 1.0, 1.0, 0.8279792288401598, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094618358815702, 0.3546336708420353, 0.3546336708420353, 0.40116569088119575], 
reward next is 0.5988, 
noisyNet noise sample is [array([0.11616179], dtype=float32), 0.799371]. 
=============================================
[2019-03-22 23:51:23,039] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[50.64942 ]
 [51.757633]
 [52.207233]
 [52.19822 ]
 [52.0222  ]], R is [[50.66424942]
 [50.34499741]
 [50.45399857]
 [50.58709717]
 [50.71203613]].
[2019-03-22 23:51:24,755] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.2717299e-37 1.0000000e+00 5.5256977e-34 0.0000000e+00 4.5494240e-35], sum to 1.0000
[2019-03-22 23:51:24,763] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3058
[2019-03-22 23:51:24,770] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.46666666666667, 67.16666666666667, 1.0, 2.0, 0.7111352833115415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 810499.7604745197, 810499.7604745197, 178266.1745469242], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4389000.0000, 
sim time next is 4389600.0000, 
raw observation next is [29.93333333333333, 68.33333333333334, 1.0, 2.0, 0.7042118283258065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 802604.7836199184, 802604.7836199179, 176944.8273086768], 
processed observation next is [1.0, 0.8260869565217391, 0.6641975308641974, 0.6833333333333335, 1.0, 1.0, 0.6478712241973887, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2866445655785423, 0.2866445655785421, 0.3402785140551477], 
reward next is 0.6597, 
noisyNet noise sample is [array([-0.03602312], dtype=float32), -0.91303086]. 
=============================================
[2019-03-22 23:51:28,306] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:51:28,318] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9910
[2019-03-22 23:51:28,328] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4921303015996781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 590800.471093143, 590800.471093143, 141801.5276767784], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4420200.0000, 
sim time next is 4420800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.4917546613566779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 590350.1716416434, 590350.1716416434, 141742.9510794396], 
processed observation next is [0.0, 0.17391304347826086, 0.37037037037037035, 0.94, 1.0, 1.0, 0.39494602542461654, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21083934701487264, 0.21083934701487264, 0.27258259822969155], 
reward next is 0.7274, 
noisyNet noise sample is [array([0.12682989], dtype=float32), 0.3482277]. 
=============================================
[2019-03-22 23:51:49,851] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.5630571e-29 1.0000000e+00 5.1526055e-32 1.1437938e-21 1.1176056e-27], sum to 1.0000
[2019-03-22 23:51:49,857] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3427
[2019-03-22 23:51:49,867] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.95, 93.5, 1.0, 2.0, 0.7403494323221568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 856215.0477920956, 856215.0477920956, 184546.8872942495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4779000.0000, 
sim time next is 4779600.0000, 
raw observation next is [23.93333333333333, 93.33333333333334, 1.0, 2.0, 0.6723871681430491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 778241.8569937038, 778241.8569937033, 171567.5850664831], 
processed observation next is [1.0, 0.30434782608695654, 0.4419753086419752, 0.9333333333333335, 1.0, 1.0, 0.6099847239798204, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2779435203548942, 0.27794352035489406, 0.3299376635893906], 
reward next is 0.6701, 
noisyNet noise sample is [array([-0.38098404], dtype=float32), -1.9148338]. 
=============================================
[2019-03-22 23:51:51,682] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1467666e-17 4.3455303e-02 1.9127714e-24 9.5654470e-01 1.0218938e-16], sum to 1.0000
[2019-03-22 23:51:51,689] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1752
[2019-03-22 23:51:51,697] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.13333333333333, 94.33333333333334, 1.0, 2.0, 0.4620127694410426, 1.0, 2.0, 0.4620127694410426, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426155264, 1053303.181812323, 1053303.181812323, 223885.0971977349], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4848000.0000, 
sim time next is 4848600.0000, 
raw observation next is [25.06666666666667, 94.16666666666667, 1.0, 2.0, 0.4429468464461952, 1.0, 2.0, 0.4429468464461952, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1009807.781989348, 1009807.781989348, 218302.6417642855], 
processed observation next is [1.0, 0.08695652173913043, 0.4839506172839507, 0.9416666666666668, 1.0, 1.0, 0.33684148386451807, 1.0, 1.0, 0.33684148386451807, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.36064563642476716, 0.36064563642476716, 0.419812772623626], 
reward next is 0.5802, 
noisyNet noise sample is [array([-0.36010295], dtype=float32), 1.1746808]. 
=============================================
[2019-03-22 23:51:53,150] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1351204e-28 1.0000000e+00 1.3217435e-26 1.0728999e-09 8.3261803e-28], sum to 1.0000
[2019-03-22 23:51:53,157] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7375
[2019-03-22 23:51:53,163] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.26666666666667, 96.66666666666666, 1.0, 2.0, 0.6993869146389343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 797102.8703321803, 797102.8703321803, 176028.4099266914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4844400.0000, 
sim time next is 4845000.0000, 
raw observation next is [25.33333333333334, 95.83333333333334, 1.0, 2.0, 0.6979603191189947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 795476.1120403366, 795476.1120403371, 175758.5047773202], 
processed observation next is [1.0, 0.043478260869565216, 0.49382716049382736, 0.9583333333333335, 1.0, 1.0, 0.6404289513321365, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2840986114429774, 0.28409861144297754, 0.3379971245717696], 
reward next is 0.6620, 
noisyNet noise sample is [array([-1.3180957], dtype=float32), -0.19336201]. 
=============================================
[2019-03-22 23:51:53,176] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[50.246487]
 [50.39858 ]
 [50.561253]
 [50.71551 ]
 [50.931156]], R is [[50.33218384]
 [50.490345  ]
 [50.6462059 ]
 [50.79986572]
 [50.95142746]].
[2019-03-22 23:51:54,529] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7599576e-20 9.3737328e-01 2.1215513e-24 6.2626652e-02 1.6312104e-17], sum to 1.0000
[2019-03-22 23:51:54,536] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7168
[2019-03-22 23:51:54,546] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1982272.471613995 W.
[2019-03-22 23:51:54,556] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.65, 91.5, 1.0, 2.0, 0.8689944033313322, 1.0, 2.0, 0.8689944033313322, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1982272.471613995, 1982272.471613995, 373089.5949457923], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4872600.0000, 
sim time next is 4873200.0000, 
raw observation next is [26.86666666666667, 90.66666666666666, 1.0, 2.0, 0.5928327629675643, 1.0, 2.0, 0.5928327629675643, 1.0, 1.0, 0.9438090658595453, 6.911199999999999, 6.9112, 121.94756008, 2028527.848880925, 2028527.848880925, 391484.343671935], 
processed observation next is [1.0, 0.391304347826087, 0.5506172839506175, 0.9066666666666666, 1.0, 1.0, 0.5152770987709098, 1.0, 1.0, 0.5152770987709098, 1.0, 0.5, 0.9297613323244316, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7244742317431875, 0.7244742317431875, 0.7528545070614135], 
reward next is 0.2471, 
noisyNet noise sample is [array([-0.41184923], dtype=float32), -1.1771369]. 
=============================================
[2019-03-22 23:52:12,092] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-22 23:52:12,094] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:52:12,096] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:52:12,097] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:52:12,097] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:52:12,098] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:52:12,099] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:52:12,101] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:52:12,103] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:52:12,100] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:52:12,105] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:52:12,126] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run15
[2019-03-22 23:52:12,142] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run15
[2019-03-22 23:52:12,144] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run15
[2019-03-22 23:52:12,179] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run15
[2019-03-22 23:52:12,180] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run15
[2019-03-22 23:52:23,408] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.29774055], dtype=float32), 0.11320754]
[2019-03-22 23:52:23,410] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [37.93333333333334, 14.33333333333334, 1.0, 2.0, 0.5707503634775449, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9362067674051199, 6.911199999999999, 6.9112, 121.9260426156618, 1399904.960191221, 1399904.960191221, 279278.9226427369]
[2019-03-22 23:52:23,412] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:52:23,414] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.7763622e-29 0.0000000e+00], sampled 0.07029362950296647
[2019-03-22 23:52:23,415] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1399904.960191221 W.
[2019-03-22 23:52:32,098] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.29774055], dtype=float32), 0.11320754]
[2019-03-22 23:52:32,099] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.97882698, 39.01840554, 1.0, 2.0, 0.394145458799961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489473.1264798331, 489473.1264798331, 127821.2586146563]
[2019-03-22 23:52:32,100] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:52:32,101] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.07172201667978406
[2019-03-22 23:52:34,296] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.29774055], dtype=float32), 0.11320754]
[2019-03-22 23:52:34,299] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [34.86842642000001, 19.489125865, 1.0, 2.0, 0.3939484213853752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 493137.0012434031, 493137.0012434031, 127869.4221799428]
[2019-03-22 23:52:34,300] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:52:34,303] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5395723774654398
[2019-03-22 23:52:43,535] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.29774055], dtype=float32), 0.11320754]
[2019-03-22 23:52:43,537] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.84506479666667, 85.53559905333334, 1.0, 2.0, 0.4516843314359695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 546829.3324412127, 546829.3324412127, 135788.3723743958]
[2019-03-22 23:52:43,539] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:52:43,542] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5806268411757608
[2019-03-22 23:53:35,654] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.29774055], dtype=float32), 0.11320754]
[2019-03-22 23:53:35,657] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.62851149, 65.66917886, 1.0, 2.0, 0.6946395575353725, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426155949, 1506683.090403135, 1506683.090403134, 316265.1894482803]
[2019-03-22 23:53:35,658] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-22 23:53:35,660] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.7713068e-35 0.0000000e+00], sampled 0.9647639351658749
[2019-03-22 23:53:35,662] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1506683.090403135 W.
[2019-03-22 23:53:47,748] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.29774055], dtype=float32), 0.11320754]
[2019-03-22 23:53:47,750] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.3, 79.33333333333334, 1.0, 2.0, 0.4179620621306175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 514719.3723218975, 514719.3723218971, 131103.194473719]
[2019-03-22 23:53:47,752] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:53:47,755] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.374669733689026
[2019-03-22 23:54:02,235] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.5061 2195143254.2709 572.0000
[2019-03-22 23:54:02,271] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.5862 2248694038.7053 551.0000
[2019-03-22 23:54:02,360] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.1199 2120488280.6681 430.0000
[2019-03-22 23:54:02,411] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8101.0198 2445313766.5296 745.0000
[2019-03-22 23:54:02,480] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2619 2170662485.7283 493.0000
[2019-03-22 23:54:03,494] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 350000, evaluation results [350000.0, 8101.019752766, 2445313766.529631, 745.0, 8770.261897406637, 2170662485.728274, 493.0, 8924.119936648443, 2120488280.668146, 430.0, 8583.586166792616, 2248694038.705321, 551.0, 8701.506076231219, 2195143254.27087, 572.0]
[2019-03-22 23:54:04,024] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5945956e-35 1.0000000e+00 0.0000000e+00 1.9106065e-34 1.7982951e-35], sum to 1.0000
[2019-03-22 23:54:04,032] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6574
[2019-03-22 23:54:04,039] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 93.66666666666667, 1.0, 2.0, 0.9623863264738182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.978461711434527, 6.9112, 121.9254907807397, 1143666.421620131, 1109222.569475021, 232448.0796094096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5194200.0000, 
sim time next is 5194800.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.9135093414925953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.92600208384, 1053599.239415883, 1053599.239415883, 221175.2313743659], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.8970349303483278, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094618597309894, 0.3762854426485297, 0.3762854426485297, 0.4253369834122421], 
reward next is 0.5747, 
noisyNet noise sample is [array([-0.06157962], dtype=float32), -1.8234673]. 
=============================================
[2019-03-22 23:54:08,933] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:54:08,943] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5598
[2019-03-22 23:54:08,946] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 87.33333333333334, 1.0, 2.0, 0.7171056983264646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 817308.0289711765, 817308.0289711765, 179408.9724934152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5258400.0000, 
sim time next is 5259000.0000, 
raw observation next is [26.7, 87.66666666666667, 1.0, 2.0, 0.7154332503669486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 815400.8732488728, 815400.8732488728, 179087.401297078], 
processed observation next is [1.0, 0.8695652173913043, 0.5444444444444444, 0.8766666666666667, 1.0, 1.0, 0.6612300599606531, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29121459758888313, 0.29121459758888313, 0.34439884864822695], 
reward next is 0.6556, 
noisyNet noise sample is [array([-0.55901796], dtype=float32), 1.7806386]. 
=============================================
[2019-03-22 23:54:08,960] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[57.20597 ]
 [57.47936 ]
 [58.000736]
 [58.645924]
 [59.23003 ]], R is [[57.09360123]
 [57.17765045]
 [57.2598381 ]
 [57.33982086]
 [57.41699982]].
[2019-03-22 23:54:26,096] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0279821e-33 1.0000000e+00 0.0000000e+00 4.4866498e-30 2.5247501e-33], sum to 1.0000
[2019-03-22 23:54:26,100] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3307
[2019-03-22 23:54:26,106] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1581517.151966297 W.
[2019-03-22 23:54:26,111] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.6, 78.33333333333334, 1.0, 2.0, 0.693465518380481, 1.0, 2.0, 0.693465518380481, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1581517.151966297, 1581517.151966298, 301699.0796921269], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5571600.0000, 
sim time next is 5572200.0000, 
raw observation next is [27.8, 78.16666666666666, 1.0, 2.0, 0.690089454006023, 1.0, 2.0, 0.690089454006023, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1573809.788397176, 1573809.788397177, 300430.7858739935], 
processed observation next is [1.0, 0.4782608695652174, 0.5851851851851853, 0.7816666666666666, 1.0, 1.0, 0.631058873816694, 1.0, 1.0, 0.631058873816694, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5620749244275628, 0.5620749244275631, 0.5777515112961413], 
reward next is 0.4222, 
noisyNet noise sample is [array([-0.6626796], dtype=float32), -1.1849662]. 
=============================================
[2019-03-22 23:54:26,124] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:54:26,139] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4856
[2019-03-22 23:54:26,145] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.36666666666667, 93.0, 1.0, 2.0, 0.7687934814458343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 876251.9046503331, 876251.9046503326, 189573.8803037528], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5545200.0000, 
sim time next is 5545800.0000, 
raw observation next is [25.35, 93.0, 1.0, 2.0, 0.7548191582407742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 860315.3751440179, 860315.3751440179, 186779.0651612997], 
processed observation next is [1.0, 0.17391304347826086, 0.4944444444444445, 0.93, 1.0, 1.0, 0.7081180455247311, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30725549112286354, 0.30725549112286354, 0.35919050992557633], 
reward next is 0.6408, 
noisyNet noise sample is [array([1.2363955], dtype=float32), -1.7792274]. 
=============================================
[2019-03-22 23:54:28,089] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:54:28,097] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9516
[2019-03-22 23:54:28,101] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.15, 91.0, 1.0, 2.0, 0.602117982255403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686194.2345030855, 686194.2345030855, 158442.910105232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5592600.0000, 
sim time next is 5593200.0000, 
raw observation next is [25.2, 91.0, 1.0, 2.0, 0.6112221192546315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696574.3341255849, 696574.3341255849, 160019.1779613907], 
processed observation next is [1.0, 0.7391304347826086, 0.4888888888888889, 0.91, 1.0, 1.0, 0.5371691895888471, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2487765479019946, 0.2487765479019946, 0.3077291883872898], 
reward next is 0.6923, 
noisyNet noise sample is [array([0.08813997], dtype=float32), 1.9613875]. 
=============================================
[2019-03-22 23:54:31,730] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:54:31,740] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5507
[2019-03-22 23:54:31,743] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 88.0, 1.0, 2.0, 0.6648728857664028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 757747.2155204386, 757747.2155204382, 169600.2777525396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5650200.0000, 
sim time next is 5650800.0000, 
raw observation next is [26.16666666666666, 87.33333333333333, 1.0, 2.0, 0.6696131503582464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763152.3244464057, 763152.3244464057, 170470.9689689021], 
processed observation next is [0.0, 0.391304347826087, 0.5246913580246911, 0.8733333333333333, 1.0, 1.0, 0.6066823218550552, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27255440158800204, 0.27255440158800204, 0.3278287864786579], 
reward next is 0.6722, 
noisyNet noise sample is [array([1.0231936], dtype=float32), 1.3012017]. 
=============================================
[2019-03-22 23:54:32,439] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:54:32,449] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6261
[2019-03-22 23:54:32,456] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.98333333333333, 69.5, 1.0, 2.0, 0.7192870570345481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819795.5220172087, 819795.5220172087, 179830.4203672784], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5670600.0000, 
sim time next is 5671200.0000, 
raw observation next is [30.06666666666667, 69.0, 1.0, 2.0, 0.7192478798165262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819750.8465530908, 819750.8465530908, 179822.8324850003], 
processed observation next is [0.0, 0.6521739130434783, 0.669135802469136, 0.69, 1.0, 1.0, 0.6657712854958645, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29276815948324675, 0.29276815948324675, 0.34581313939423136], 
reward next is 0.6542, 
noisyNet noise sample is [array([-1.0796083], dtype=float32), 1.6902761]. 
=============================================
[2019-03-22 23:54:36,520] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:54:36,528] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2670
[2019-03-22 23:54:36,531] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.46666666666667, 87.5, 1.0, 2.0, 0.4278328193513551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524921.4351576674, 524921.4351576674, 132481.4344130966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5730600.0000, 
sim time next is 5731200.0000, 
raw observation next is [21.5, 87.0, 1.0, 2.0, 0.4261064130373477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 523040.1732337791, 523040.1732337791, 132236.7576461], 
processed observation next is [0.0, 0.34782608695652173, 0.35185185185185186, 0.87, 1.0, 1.0, 0.3167933488539854, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1868000618692068, 0.1868000618692068, 0.2543014570117308], 
reward next is 0.7457, 
noisyNet noise sample is [array([0.304961], dtype=float32), -1.9607122]. 
=============================================
[2019-03-22 23:54:39,002] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 4.1520843e-38 3.2278821e-36 0.0000000e+00], sum to 1.0000
[2019-03-22 23:54:39,012] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9905
[2019-03-22 23:54:39,016] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 56.83333333333334, 1.0, 2.0, 0.7863179035871862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 974632.6391731332, 974632.6391731336, 196316.1019288553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5824200.0000, 
sim time next is 5824800.0000, 
raw observation next is [25.4, 55.0, 1.0, 2.0, 0.778697062789079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 967391.6115246387, 967391.6115246387, 194777.6837357856], 
processed observation next is [1.0, 0.43478260869565216, 0.49629629629629624, 0.55, 1.0, 1.0, 0.7365441223679512, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3454970041159424, 0.3454970041159424, 0.3745724687226646], 
reward next is 0.6254, 
noisyNet noise sample is [array([0.6465717], dtype=float32), 0.12445821]. 
=============================================
[2019-03-22 23:54:39,622] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:54:39,632] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6774
[2019-03-22 23:54:39,642] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.76666666666667, 85.83333333333334, 1.0, 2.0, 0.474446681659799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 572085.8254121001, 572085.8254120996, 139155.3377407427], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5791800.0000, 
sim time next is 5792400.0000, 
raw observation next is [22.7, 86.0, 1.0, 2.0, 0.4723425346162108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 569976.4211514171, 569976.4211514171, 138847.7436294369], 
processed observation next is [1.0, 0.043478260869565216, 0.39629629629629626, 0.86, 1.0, 1.0, 0.37183635073358423, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20356300755407752, 0.20356300755407752, 0.26701489159507097], 
reward next is 0.7330, 
noisyNet noise sample is [array([-1.8739182], dtype=float32), 0.013952097]. 
=============================================
[2019-03-22 23:54:51,688] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9697287e-20 1.3441074e-16 3.5313784e-30 1.0000000e+00 1.7744006e-24], sum to 1.0000
[2019-03-22 23:54:51,690] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3555
[2019-03-22 23:54:51,696] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.36666666666667, 71.83333333333333, 1.0, 2.0, 0.5609588891694782, 1.0, 2.0, 0.5609588891694782, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1334005.725217789, 1334005.725217789, 257323.8361656522], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5994600.0000, 
sim time next is 5995200.0000, 
raw observation next is [24.53333333333333, 71.66666666666667, 1.0, 2.0, 0.5734454652597131, 1.0, 2.0, 0.5734454652597131, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1358990.437255907, 1358990.437255908, 261351.5718349575], 
processed observation next is [1.0, 0.391304347826087, 0.46419753086419746, 0.7166666666666667, 1.0, 1.0, 0.49219698245203936, 1.0, 1.0, 0.49219698245203936, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4853537275913954, 0.4853537275913957, 0.5025991766056874], 
reward next is 0.4974, 
noisyNet noise sample is [array([-1.1193373], dtype=float32), -0.22619513]. 
=============================================
[2019-03-22 23:54:56,312] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.3851854e-36 0.0000000e+00], sum to 1.0000
[2019-03-22 23:54:56,321] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2290
[2019-03-22 23:54:56,327] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.51666666666667, 75.16666666666667, 1.0, 2.0, 0.765114182874309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 904267.3072916633, 904267.3072916628, 190386.7198491396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6077400.0000, 
sim time next is 6078000.0000, 
raw observation next is [26.53333333333333, 70.33333333333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.497077956287765, 6.9112, 121.9239894088543, 1499979.059207733, 1199962.232711029, 247589.6578655135], 
processed observation next is [1.0, 0.34782608695652173, 0.5382716049382715, 0.7033333333333335, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.05858779562877654, 0.0, 0.8094484976621187, 0.5357068068599047, 0.42855794025393895, 0.4761339574336798], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.55533266], dtype=float32), 1.3564954]. 
=============================================
[2019-03-22 23:54:56,338] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[68.24914 ]
 [69.23869 ]
 [69.40856 ]
 [69.428276]
 [69.47674 ]], R is [[64.77428436]
 [64.76041412]
 [64.80487061]
 [64.85905457]
 [64.91371155]].
[2019-03-22 23:54:58,068] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-22 23:54:58,069] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:54:58,070] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:54:58,070] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:54:58,072] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:54:58,072] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:54:58,074] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:54:58,075] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:54:58,076] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:54:58,074] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:54:58,082] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:54:58,106] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run16
[2019-03-22 23:54:58,106] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run16
[2019-03-22 23:54:58,141] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run16
[2019-03-22 23:54:58,143] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run16
[2019-03-22 23:54:58,158] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run16
[2019-03-22 23:55:17,275] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3521504], dtype=float32), 0.08852717]
[2019-03-22 23:55:17,277] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.26666666666667, 63.33333333333334, 1.0, 2.0, 0.31315786207366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 397091.5086924711, 397091.5086924711, 117202.2562815193]
[2019-03-22 23:55:17,278] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:55:17,283] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0147054e-31 0.0000000e+00], sampled 0.6354172230949032
[2019-03-22 23:55:21,054] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3521504], dtype=float32), 0.08852717]
[2019-03-22 23:55:21,054] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 48.66666666666667, 1.0, 2.0, 0.9113406274732245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.937518459396486, 6.9112, 121.9258953717727, 1115102.166582407, 1101624.779330174, 223000.4958345299]
[2019-03-22 23:55:21,055] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-22 23:55:21,059] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1806879e-27 1.0000000e+00 6.6099711e-32 1.5275084e-14 7.3603933e-29], sampled 0.00045661731067658806
[2019-03-22 23:56:09,563] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3521504], dtype=float32), 0.08852717]
[2019-03-22 23:56:09,565] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.0, 94.0, 1.0, 2.0, 0.7941470671413676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 905166.363229948, 905166.363229948, 194740.476244479]
[2019-03-22 23:56:09,566] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-22 23:56:09,569] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0025393e-24 1.0000000e+00 9.1341168e-31 3.2500118e-09 7.8643871e-28], sampled 0.6401181697301581
[2019-03-22 23:56:20,030] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.3521504], dtype=float32), 0.08852717]
[2019-03-22 23:56:20,033] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.55418471, 66.27883852333335, 1.0, 2.0, 0.4840398797324084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 595068.2174134871, 595068.2174134871, 140973.1559814862]
[2019-03-22 23:56:20,037] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-22 23:56:20,039] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.5887169e-34 1.0000000e+00 1.1042677e-37 4.3248175e-24 6.4275239e-35], sampled 0.331473428290067
[2019-03-22 23:56:47,054] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8887.8219 2158652431.5132 361.0000
[2019-03-22 23:56:47,210] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8743.5960 2226891980.3075 377.0000
[2019-03-22 23:56:47,322] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8996.0235 2112297488.1121 342.0000
[2019-03-22 23:56:47,348] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8826.5245 2181326046.1543 419.0000
[2019-03-22 23:56:47,358] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8311.3449 2420420506.0261 495.0000
[2019-03-22 23:56:48,372] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 375000, evaluation results [375000.0, 8311.344867807718, 2420420506.02613, 495.0, 8887.82185406877, 2158652431.5132093, 361.0, 8996.023515037501, 2112297488.1120796, 342.0, 8743.595970819073, 2226891980.3075, 377.0, 8826.524485702983, 2181326046.15435, 419.0]
[2019-03-22 23:56:59,974] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:56:59,982] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7942
[2019-03-22 23:56:59,986] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 88.0, 1.0, 2.0, 0.5645186784039304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 661283.4324323619, 661283.4324323619, 152915.1870700168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6322800.0000, 
sim time next is 6323400.0000, 
raw observation next is [24.05, 88.0, 1.0, 2.0, 0.5628992067007859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 659604.4912601669, 659604.4912601664, 152653.4927059588], 
processed observation next is [0.0, 0.17391304347826086, 0.4462962962962963, 0.88, 1.0, 1.0, 0.4796419127390308, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23557303259291673, 0.23557303259291656, 0.29356440904992076], 
reward next is 0.7064, 
noisyNet noise sample is [array([1.0487374], dtype=float32), -0.90954447]. 
=============================================
[2019-03-22 23:57:00,728] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:57:00,734] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6759
[2019-03-22 23:57:00,737] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.06666666666667, 58.83333333333334, 1.0, 2.0, 0.6959674657849765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 793203.6512101679, 793203.6512101679, 175380.8629196532], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6354600.0000, 
sim time next is 6355200.0000, 
raw observation next is [31.13333333333333, 58.66666666666667, 1.0, 2.0, 0.6691222757995607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 762592.6006602708, 762592.6006602708, 170380.8899595532], 
processed observation next is [0.0, 0.5652173913043478, 0.7086419753086418, 0.5866666666666667, 1.0, 1.0, 0.6060979473804294, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.272354500235811, 0.272354500235811, 0.32765555761452536], 
reward next is 0.6723, 
noisyNet noise sample is [array([-0.09417789], dtype=float32), -0.78803915]. 
=============================================
[2019-03-22 23:57:07,075] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:57:07,081] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9071
[2019-03-22 23:57:07,085] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.13333333333333, 57.0, 1.0, 2.0, 0.6090587893400922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694107.7965572923, 694107.7965572923, 159644.2931438035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6457200.0000, 
sim time next is 6457800.0000, 
raw observation next is [31.06666666666667, 57.5, 1.0, 2.0, 0.6195895679794394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706114.621125785, 706114.621125785, 161481.4263387153], 
processed observation next is [1.0, 0.7391304347826086, 0.7061728395061729, 0.575, 1.0, 1.0, 0.5471304380707612, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2521837932592089, 0.2521837932592089, 0.3105412044975294], 
reward next is 0.6895, 
noisyNet noise sample is [array([-0.59146696], dtype=float32), 1.0556552]. 
=============================================
[2019-03-22 23:57:07,412] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.60536184e-31 1.00000000e+00 1.11681685e-35 3.34902244e-36
 0.00000000e+00], sum to 1.0000
[2019-03-22 23:57:07,423] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5837
[2019-03-22 23:57:07,428] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 55.5, 1.0, 2.0, 0.4334784570936808, 1.0, 2.0, 0.4334784570936808, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 988208.3090289363, 988208.3090289363, 215577.1170200618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6455400.0000, 
sim time next is 6456000.0000, 
raw observation next is [31.26666666666667, 56.0, 1.0, 2.0, 0.6054827917286754, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690030.612237212, 690030.612237212, 159024.5303081149], 
processed observation next is [1.0, 0.7391304347826086, 0.7135802469135804, 0.56, 1.0, 1.0, 0.5303366568198516, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24643950437043285, 0.24643950437043285, 0.30581640443868247], 
reward next is 0.6942, 
noisyNet noise sample is [array([-1.1575516], dtype=float32), -1.0840797]. 
=============================================
[2019-03-22 23:57:07,441] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[48.90672 ]
 [44.742805]
 [45.290085]
 [45.53575 ]
 [46.017624]], R is [[51.25430298]
 [51.3271904 ]
 [51.04101944]
 [50.76311493]
 [50.25548553]].
[2019-03-22 23:57:07,537] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:57:07,545] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6689
[2019-03-22 23:57:07,549] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.2, 64.0, 1.0, 2.0, 0.6890457452515938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 785310.8302891499, 785310.8302891499, 174080.4375662615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6465600.0000, 
sim time next is 6466200.0000, 
raw observation next is [30.08333333333334, 64.5, 1.0, 2.0, 0.6781439054198352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 772879.653919917, 772879.653919917, 172047.8202711437], 
processed observation next is [1.0, 0.8695652173913043, 0.6697530864197533, 0.645, 1.0, 1.0, 0.6168379826426609, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27602844782854175, 0.27602844782854175, 0.33086119282912246], 
reward next is 0.6691, 
noisyNet noise sample is [array([-0.27442083], dtype=float32), 0.8712677]. 
=============================================
[2019-03-22 23:57:07,862] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:57:07,869] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3722
[2019-03-22 23:57:07,873] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.26666666666667, 56.0, 1.0, 2.0, 0.605467257317639, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 690012.9006795381, 690012.9006795377, 159021.8469552816], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6456000.0000, 
sim time next is 6456600.0000, 
raw observation next is [31.2, 56.5, 1.0, 2.0, 0.5990299636640046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 682673.4559827371, 682673.4559827371, 157912.5861463695], 
processed observation next is [1.0, 0.7391304347826086, 0.7111111111111111, 0.565, 1.0, 1.0, 0.5226547186476246, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24381194856526325, 0.24381194856526325, 0.30367805028147976], 
reward next is 0.6963, 
noisyNet noise sample is [array([-0.5069241], dtype=float32), 0.6338648]. 
=============================================
[2019-03-22 23:57:11,508] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.51208692e-16 1.00000000e+00 9.59277317e-21 1.01490465e-20
 7.55376747e-20], sum to 1.0000
[2019-03-22 23:57:11,516] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4188
[2019-03-22 23:57:11,522] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1993823.971765656 W.
[2019-03-22 23:57:11,527] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.35, 80.5, 1.0, 2.0, 0.582701939355965, 1.0, 1.0, 0.582701939355965, 1.0, 2.0, 0.9276804647319885, 6.911200000000001, 6.9112, 121.94756008, 1993823.971765656, 1993823.971765655, 386031.3002838116], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6528600.0000, 
sim time next is 6529200.0000, 
raw observation next is [27.26666666666667, 80.66666666666667, 1.0, 2.0, 0.5674481032002626, 1.0, 2.0, 0.5674481032002626, 1.0, 2.0, 0.9033958607893489, 6.911200000000001, 6.9112, 121.94756008, 1941573.383965977, 1941573.383965977, 377925.1152748806], 
processed observation next is [1.0, 0.5652173913043478, 0.5654320987654322, 0.8066666666666668, 1.0, 1.0, 0.48505726571459834, 1.0, 1.0, 0.48505726571459834, 1.0, 1.0, 0.8792448259866861, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6934190657021346, 0.6934190657021346, 0.7267790678363089], 
reward next is 0.2732, 
noisyNet noise sample is [array([-0.36868912], dtype=float32), 0.7759733]. 
=============================================
[2019-03-22 23:57:13,775] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0. 1. 0. 0. 0.], sum to 1.0000
[2019-03-22 23:57:13,783] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7723
[2019-03-22 23:57:13,789] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.46666666666667, 41.16666666666666, 1.0, 2.0, 0.737784928338689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 934630.6456138123, 934630.6456138123, 186717.379517668], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6603000.0000, 
sim time next is 6603600.0000, 
raw observation next is [26.63333333333333, 40.33333333333334, 1.0, 2.0, 0.8054625884842693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1020327.648662016, 1020327.648662016, 200767.763243668], 
processed observation next is [1.0, 0.43478260869565216, 0.5419753086419752, 0.40333333333333343, 1.0, 1.0, 0.768407843433654, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3644027316650057, 0.3644027316650057, 0.38609185239166927], 
reward next is 0.6139, 
noisyNet noise sample is [array([-0.1834802], dtype=float32), -0.5613611]. 
=============================================
[2019-03-22 23:57:15,324] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3864741e-36], sum to 1.0000
[2019-03-22 23:57:15,336] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7164
[2019-03-22 23:57:15,345] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.96666666666667, 43.66666666666667, 1.0, 2.0, 0.5777301983110922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 731495.7052364501, 731495.7052364501, 156734.0499765849], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6601200.0000, 
sim time next is 6601800.0000, 
raw observation next is [26.13333333333333, 42.83333333333333, 1.0, 2.0, 0.5558606954304491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 704049.6869426618, 704049.6869426613, 152995.0829216214], 
processed observation next is [1.0, 0.391304347826087, 0.5234567901234567, 0.4283333333333333, 1.0, 1.0, 0.47126273265529656, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2514463167652363, 0.25144631676523616, 0.29422131331081036], 
reward next is 0.7058, 
noisyNet noise sample is [array([1.826129], dtype=float32), 0.1175554]. 
=============================================
[2019-03-22 23:57:16,890] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.8048516e-33 1.0000000e+00 5.6396602e-38 1.0830153e-32 1.5723345e-28], sum to 1.0000
[2019-03-22 23:57:16,899] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0078
[2019-03-22 23:57:16,905] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.43333333333333, 44.0, 1.0, 2.0, 0.3597413219394566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 449124.5917373403, 449124.5917373403, 123161.4285585821], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6632400.0000, 
sim time next is 6633000.0000, 
raw observation next is [27.15, 45.0, 1.0, 2.0, 0.3597305585898989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 449362.2901478652, 449362.2901478652, 123164.6250285196], 
processed observation next is [1.0, 0.782608695652174, 0.561111111111111, 0.45, 1.0, 1.0, 0.2377744745117844, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16048653219566614, 0.16048653219566614, 0.23685504813176847], 
reward next is 0.7631, 
noisyNet noise sample is [array([0.01112455], dtype=float32), -0.033782303]. 
=============================================
[2019-03-22 23:57:16,930] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[61.564106]
 [60.61723 ]
 [59.629356]
 [58.806026]
 [57.74893 ]], R is [[62.39551163]
 [62.53470612]
 [62.67276764]
 [62.81111526]
 [62.95149612]].
[2019-03-22 23:57:19,005] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.2704899e-38 1.0262391e-32], sum to 1.0000
[2019-03-22 23:57:19,012] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4227
[2019-03-22 23:57:19,016] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 44.50000000000001, 1.0, 2.0, 0.3192187026086005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 411788.6324863221, 411788.6324863221, 111290.2608871726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6671400.0000, 
sim time next is 6672000.0000, 
raw observation next is [22.9, 45.0, 1.0, 2.0, 0.2896552188353633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 373642.7715324259, 373642.7715324259, 108164.4186723898], 
processed observation next is [1.0, 0.21739130434782608, 0.4037037037037037, 0.45, 1.0, 1.0, 0.15435145099448014, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1334438469758664, 0.1334438469758664, 0.20800849744690347], 
reward next is 0.7920, 
noisyNet noise sample is [array([-1.6142558], dtype=float32), 0.095339976]. 
=============================================
[2019-03-22 23:57:19,031] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[75.87033]
 [75.96698]
 [75.92679]
 [75.87355]
 [75.86362]], R is [[75.99866486]
 [76.0246582 ]
 [76.06031799]
 [76.09425354]
 [76.12586212]].
[2019-03-22 23:57:25,441] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.7717595e-27 4.3453022e-26 0.0000000e+00 1.0000000e+00 4.6460250e-20], sum to 1.0000
[2019-03-22 23:57:25,454] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7594
[2019-03-22 23:57:25,458] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.25, 50.5, 1.0, 2.0, 0.447833210074338, 1.0, 2.0, 0.447833210074338, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1095821.410229771, 1095821.410229771, 222677.6862584314], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6780600.0000, 
sim time next is 6781200.0000, 
raw observation next is [26.36666666666667, 50.33333333333333, 1.0, 2.0, 0.4065879733255375, 1.0, 2.0, 0.4065879733255375, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 994643.3431781204, 994643.3431781204, 210685.1552623363], 
processed observation next is [1.0, 0.4782608695652174, 0.5320987654320989, 0.5033333333333333, 1.0, 1.0, 0.29355711110183036, 1.0, 1.0, 0.29355711110183036, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3552297654207573, 0.3552297654207573, 0.40516376011987754], 
reward next is 0.5948, 
noisyNet noise sample is [array([-1.2795873], dtype=float32), 1.2576845]. 
=============================================
[2019-03-22 23:57:25,651] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0206481e-21 5.6943641e-06 1.5893342e-24 9.9999428e-01 3.8153419e-13], sum to 1.0000
[2019-03-22 23:57:25,662] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4507
[2019-03-22 23:57:25,669] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.2, 49.0, 1.0, 2.0, 0.3700897112551894, 1.0, 2.0, 0.3700897112551894, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 900330.7852720452, 900330.7852720456, 200433.1014667407], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6786000.0000, 
sim time next is 6786600.0000, 
raw observation next is [27.31666666666667, 48.83333333333334, 1.0, 2.0, 0.4031155530313377, 1.0, 2.0, 0.4031155530313377, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 979964.4742924831, 979964.4742924835, 209519.6222801738], 
processed observation next is [1.0, 0.5652173913043478, 0.5672839506172841, 0.48833333333333345, 1.0, 1.0, 0.2894232774182592, 1.0, 1.0, 0.2894232774182592, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3499873122473154, 0.34998731224731555, 0.40292235053879577], 
reward next is 0.5971, 
noisyNet noise sample is [array([-0.02965715], dtype=float32), -1.6215478]. 
=============================================
[2019-03-22 23:57:27,337] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5064561e-13 9.9999976e-01 6.3023577e-21 2.8418185e-07 2.5156710e-13], sum to 1.0000
[2019-03-22 23:57:27,345] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6397
[2019-03-22 23:57:27,350] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 65.83333333333334, 1.0, 2.0, 0.4718105653884278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 568422.0054060986, 568422.0054060986, 138736.1647661685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6808200.0000, 
sim time next is 6808800.0000, 
raw observation next is [25.66666666666667, 66.66666666666667, 1.0, 2.0, 0.4718307700383521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 568668.5849233386, 568668.5849233386, 138746.6887793381], 
processed observation next is [1.0, 0.8260869565217391, 0.506172839506173, 0.6666666666666667, 1.0, 1.0, 0.3712271071885145, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20309592318690664, 0.20309592318690664, 0.2668205553448809], 
reward next is 0.7332, 
noisyNet noise sample is [array([1.0549898], dtype=float32), 1.0897607]. 
=============================================
[2019-03-22 23:57:28,877] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.6089979e-20 3.6099885e-07 3.0144100e-31 9.9999964e-01 8.0206092e-10], sum to 1.0000
[2019-03-22 23:57:28,882] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7129
[2019-03-22 23:57:28,887] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.7, 49.33333333333333, 1.0, 2.0, 0.2498694910960415, 1.0, 2.0, 0.2498694910960415, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 590381.864098681, 590381.8640986815, 169869.8217976366], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6871200.0000, 
sim time next is 6871800.0000, 
raw observation next is [29.85, 49.16666666666667, 1.0, 2.0, 0.2522280355037523, 1.0, 2.0, 0.2522280355037523, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 594869.1208354981, 594869.1208354981, 170355.7457806278], 
processed observation next is [0.0, 0.5217391304347826, 0.6611111111111112, 0.4916666666666667, 1.0, 1.0, 0.10979528036160986, 1.0, 1.0, 0.10979528036160986, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21245325744124932, 0.21245325744124932, 0.32760720342428423], 
reward next is 0.6724, 
noisyNet noise sample is [array([-0.4524014], dtype=float32), -0.86290246]. 
=============================================
[2019-03-22 23:57:31,411] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1217092e-25 1.0000000e+00 1.0870846e-31 6.2540728e-15 2.9687768e-15], sum to 1.0000
[2019-03-22 23:57:31,419] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8352
[2019-03-22 23:57:31,424] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 72.0, 1.0, 2.0, 0.4740147274291922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571511.0733360492, 571511.0733360492, 139087.5552182269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6944400.0000, 
sim time next is 6945000.0000, 
raw observation next is [25.06666666666667, 70.83333333333333, 1.0, 2.0, 0.4777515650307663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 575316.5880734181, 575316.5880734178, 139637.1830764656], 
processed observation next is [0.0, 0.391304347826087, 0.4839506172839507, 0.7083333333333333, 1.0, 1.0, 0.3782756726556742, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20547021002622076, 0.20547021002622062, 0.26853304437781844], 
reward next is 0.7315, 
noisyNet noise sample is [array([0.71286744], dtype=float32), -0.97568005]. 
=============================================
[2019-03-22 23:57:31,435] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[61.77311 ]
 [61.789127]
 [61.813377]
 [61.771465]
 [61.71872 ]], R is [[61.89765549]
 [62.01120377]
 [62.12443542]
 [62.23741913]
 [62.35020447]].
[2019-03-22 23:57:39,916] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-22 23:57:39,916] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-22 23:57:39,917] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:57:39,917] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-22 23:57:39,918] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-22 23:57:39,919] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-22 23:57:39,919] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:57:39,920] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-22 23:57:39,920] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:57:39,921] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:57:39,926] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-22 23:57:39,947] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run17
[2019-03-22 23:57:39,966] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run17
[2019-03-22 23:57:39,966] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run17
[2019-03-22 23:57:40,002] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run17
[2019-03-22 23:57:40,023] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/1/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run17
