Using TensorFlow backend.
[2019-03-24 01:22:45,778] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Bej-Train-v1', eval_act_func='part3_bej_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=5e-05, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[256, 8], model_type='nn', num_threads=16, output='./Part3-NA-Bej-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Bej-Test-v1', 'Part3-NA-Bej-Test-v2', 'Part3-NA-Bej-Test-v3', 'Part3-NA-Bej-Test-v4'], test_mode='Multiple', train_act_func='part3_bej_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=26)
[2019-03-24 01:22:45,778] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-24 01:22:45.879958: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-24 01:23:20,164] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-24 01:23:20,164] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Bej-Train-v1', 'Part3-NA-Bej-Test-v1', 'Part3-NA-Bej-Test-v2', 'Part3-NA-Bej-Test-v3', 'Part3-NA-Bej-Test-v4'] ...
[2019-03-24 01:23:20,176] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation worker starts!
[2019-03-24 01:23:20,178] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation worker starts!
[2019-03-24 01:23:20,181] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation worker starts!
[2019-03-24 01:23:20,185] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation worker starts!
[2019-03-24 01:23:20,190] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation worker starts!
[2019-03-24 01:23:20,190] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 01:23:20,191] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-24 01:23:20,274] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:20,275] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run1
[2019-03-24 01:23:21,192] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 01:23:21,196] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-24 01:23:21,298] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:21,298] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run1
[2019-03-24 01:23:21,748] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 01:23:21,749] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:23:21,749] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:23:21,749] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:21,749] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:23:21,750] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:23:21,750] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:23:21,750] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:21,751] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:21,751] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:21,749] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:21,754] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run1
[2019-03-24 01:23:21,755] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run1
[2019-03-24 01:23:21,755] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run1
[2019-03-24 01:23:21,755] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run1
[2019-03-24 01:23:21,780] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run1
[2019-03-24 01:23:22,197] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 01:23:22,198] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-24 01:23:22,309] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:22,310] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run1
[2019-03-24 01:23:23,199] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 01:23:23,202] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-24 01:23:23,477] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:23,480] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run1
[2019-03-24 01:23:24,200] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 01:23:24,207] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-24 01:23:24,334] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:24,364] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run1
[2019-03-24 01:23:25,207] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 01:23:25,211] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-24 01:23:25,334] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:25,365] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run1
[2019-03-24 01:23:26,211] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 01:23:26,218] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-24 01:23:26,323] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:26,349] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run1
[2019-03-24 01:23:27,216] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 01:23:27,220] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-24 01:23:27,342] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:27,343] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run1
[2019-03-24 01:23:28,219] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 01:23:28,223] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-24 01:23:28,342] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:28,353] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run1
[2019-03-24 01:23:29,223] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 01:23:29,226] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-24 01:23:29,347] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:29,370] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run1
[2019-03-24 01:23:30,226] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 01:23:30,229] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-24 01:23:30,351] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:30,362] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run1
[2019-03-24 01:23:31,229] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 01:23:31,234] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-24 01:23:31,347] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:31,373] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run1
[2019-03-24 01:23:32,234] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 01:23:32,238] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-24 01:23:32,355] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:32,387] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run1
[2019-03-24 01:23:33,237] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 01:23:33,241] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-24 01:23:33,371] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:33,400] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run1
[2019-03-24 01:23:34,241] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 01:23:34,245] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-24 01:23:34,364] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:34,391] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run1
[2019-03-24 01:23:35,244] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 01:23:35,246] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-24 01:23:35,370] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:23:35,396] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run1
[2019-03-24 01:23:44,048] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 01:23:44,051] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.23333333333333, 50.66666666666667, 1.0, 2.0, 0.3729196893407238, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 473187.6356991984, 473187.635699198, 125044.6710217211]
[2019-03-24 01:23:44,052] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:23:44,054] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0.20521137 0.1885079  0.20876545 0.20439932 0.193116  ], sampled 0.32972614405048206
[2019-03-24 01:23:54,108] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 01:23:54,109] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [17.55381574166667, 87.99441844333333, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2493684059495765, 6.911199999999999, 6.9112, 121.9260426156618, 362995.6188498162, 362995.6188498167, 150567.9658014765]
[2019-03-24 01:23:54,111] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:23:54,116] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.20699129 0.18824589 0.20886375 0.20074494 0.19515413], sampled 0.17718460960867255
[2019-03-24 01:23:56,792] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 01:23:56,793] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.22834130666667, 84.14653971, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.525510099328115, 6.9112, 6.9112, 121.9260426156618, 381164.9249787083, 381164.9249787083, 119185.539685687]
[2019-03-24 01:23:56,795] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:23:56,798] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0.20772982 0.19016765 0.20830524 0.20160198 0.19219525], sampled 0.7743443665688735
[2019-03-24 01:24:12,640] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 01:24:12,642] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [34.858197005, 33.24536747, 1.0, 2.0, 0.5256637889202905, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156448, 614267.4972749457, 614267.4972749457, 146473.3119574546]
[2019-03-24 01:24:12,643] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:24:12,645] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.20630194 0.18783692 0.21008773 0.20039114 0.1953823 ], sampled 0.4987313644440622
[2019-03-24 01:24:19,440] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 01:24:19,442] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.34767440333333, 101.3258961333333, 1.0, 2.0, 0.3400289631889437, 1.0, 1.0, 0.3400289631889437, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 803440.1726812831, 803440.1726812827, 191624.3142943428]
[2019-03-24 01:24:19,442] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:24:19,446] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.20672435 0.18786055 0.21251836 0.20136797 0.19152886], sampled 0.16786600624681647
[2019-03-24 01:24:19,447] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 803440.1726812831 W.
[2019-03-24 01:24:36,770] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 01:24:36,771] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.5, 85.5, 1.0, 2.0, 0.3011767013137168, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4804537428802407, 6.911199999999999, 6.9112, 121.9260426156618, 698914.672698702, 698914.6726987024, 195288.5473082428]
[2019-03-24 01:24:36,772] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:24:36,775] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0.20770594 0.18919006 0.20786473 0.20308799 0.19215132], sampled 0.02917455550037862
[2019-03-24 01:24:36,777] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 698914.672698702 W.
[2019-03-24 01:24:44,166] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 01:24:44,168] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.08649443333334, 80.80861729333334, 1.0, 2.0, 0.651352635573096, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742330.8962283568, 742330.8962283568, 167139.3654166664]
[2019-03-24 01:24:44,169] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:24:44,173] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0.20381755 0.18814065 0.2086847  0.20231873 0.19703843], sampled 0.5729799436806822
[2019-03-24 01:24:46,876] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 01:24:46,877] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.33321698, 83.56292595, 1.0, 2.0, 0.25145900609746, 1.0, 2.0, 0.25145900609746, 1.0, 2.0, 0.4003309271552498, 6.9112, 6.9112, 121.94756008, 859811.0723692206, 859811.0723692206, 238143.3906562255]
[2019-03-24 01:24:46,878] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:24:46,880] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.20676848 0.18853854 0.20937355 0.20315126 0.19216813], sampled 0.602955094972914
[2019-03-24 01:24:58,596] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 01:24:58,596] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.2, 70.0, 1.0, 2.0, 0.3029684636792837, 1.0, 1.0, 0.3029684636792837, 1.0, 1.0, 0.482335661171431, 6.911200000000001, 6.9112, 121.94756008, 1036055.843375477, 1036055.843375477, 257190.4724560701]
[2019-03-24 01:24:58,597] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:24:58,600] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0.20809972 0.18526904 0.20929778 0.20310289 0.19423054], sampled 0.3736837898282114
[2019-03-24 01:25:15,488] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 3810.4500 2538200855.9747 297.0000
[2019-03-24 01:25:15,609] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 3843.5947 2717999327.0342 413.0000
[2019-03-24 01:25:15,728] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4001.4658 2471316717.9839 227.0000
[2019-03-24 01:25:15,754] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 3816.0131 2500457630.3163 311.0000
[2019-03-24 01:25:15,898] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4052.8858 2434484825.9634 229.0000
[2019-03-24 01:25:16,912] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 3843.5947002972257, 2717999327.0342026, 413.0, 4001.465830130573, 2471316717.983903, 227.0, 4052.885844419524, 2434484825.9633594, 229.0, 3810.449950751472, 2538200855.9747458, 297.0, 3816.013067684819, 2500457630.3162675, 311.0]
[2019-03-24 01:25:27,226] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.12018093 0.12757865 0.33847436 0.1712494  0.2425166 ], sum to 1.0000
[2019-03-24 01:25:27,233] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3741
[2019-03-24 01:25:27,408] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [34.33333333333333, 27.33333333333334, 1.0, 2.0, 0.4952524693176967, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8001469821674161, 6.911199999999999, 6.9112, 121.9260426156618, 1190101.871105061, 1190101.871105061, 253566.7499903415], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 132000.0000, 
sim time next is 132600.0000, 
raw observation next is [34.71666666666667, 25.66666666666666, 1.0, 2.0, 0.498823262622116, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8075474440258098, 6.911199999999999, 6.9112, 121.9260426156618, 1202720.265088484, 1202720.265088485, 254606.2263876859], 
processed observation next is [1.0, 0.5217391304347826, 0.8413580246913581, 0.2566666666666666, 1.0, 1.0, 0.40336102693109055, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7594343050322622, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.42954295181731567, 0.4295429518173161, 0.4896273584378575], 
reward next is 0.5104, 
noisyNet noise sample is [array([-0.7993571], dtype=float32), -0.400797]. 
=============================================
[2019-03-24 01:25:27,783] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.05612646 0.0924062  0.31715864 0.15802233 0.37628642], sum to 1.0000
[2019-03-24 01:25:27,790] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8443
[2019-03-24 01:25:27,967] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [37.3, 9.0, 1.0, 2.0, 0.7213522063238756, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9617018484083302, 6.9112, 6.9112, 121.9260426156618, 1621215.488937182, 1621215.488937182, 303148.5414716046], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 144000.0000, 
sim time next is 144600.0000, 
raw observation next is [37.3, 8.5, 1.0, 2.0, 0.4570820536755574, 1.0, 1.0, 0.4570820536755574, 1.0, 2.0, 0.7592096259988921, 6.911200000000001, 6.9112, 121.94756008, 1701742.595247011, 1701742.59524701, 320836.9775131221], 
processed observation next is [1.0, 0.6956521739130435, 0.9370370370370369, 0.085, 1.0, 1.0, 0.3536691115185207, 1.0, 0.5, 0.3536691115185207, 1.0, 1.0, 0.6990120324986151, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6077652125882181, 0.6077652125882178, 0.6169941875252347], 
reward next is 0.3830, 
noisyNet noise sample is [array([-0.77004856], dtype=float32), -0.2508023]. 
=============================================
[2019-03-24 01:25:29,656] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3187350e-10 2.7044803e-10 9.9999797e-01 1.5878842e-07 1.9316037e-06], sum to 1.0000
[2019-03-24 01:25:29,666] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1300
[2019-03-24 01:25:29,833] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.65, 10.33333333333333, 1.0, 2.0, 0.1756841979948275, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3173942946080816, 6.9112, 6.9112, 121.9260426156618, 453273.6420878447, 453273.6420878447, 142414.5018783183], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 169800.0000, 
sim time next is 170400.0000, 
raw observation next is [30.4, 10.66666666666667, 1.0, 2.0, 0.1748450129541233, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3158782075206829, 6.911200000000001, 6.9112, 121.9260426156618, 451107.8676528303, 451107.8676528298, 141932.3177028153], 
processed observation next is [1.0, 1.0, 0.6814814814814815, 0.1066666666666667, 1.0, 1.0, 0.017672634469194405, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.14484775940085362, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16110995273315368, 0.1611099527331535, 0.2729467648131063], 
reward next is 0.7271, 
noisyNet noise sample is [array([-0.8772528], dtype=float32), 1.5998343]. 
=============================================
[2019-03-24 01:25:33,933] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.0460655e-03 1.7231151e-03 9.8718411e-01 6.9093570e-05 2.9776152e-03], sum to 1.0000
[2019-03-24 01:25:33,938] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6491
[2019-03-24 01:25:33,945] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.7, 44.0, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2614755109914088, 6.911200000000001, 6.9112, 121.9260426156618, 377022.3170129613, 377022.3170129608, 151309.5184703596], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 255600.0000, 
sim time next is 256200.0000, 
raw observation next is [23.55, 44.33333333333334, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2598393454805326, 6.911199999999999, 6.9112, 121.9260426156618, 374139.5886065581, 374139.5886065586, 150867.7895818474], 
processed observation next is [0.0, 1.0, 0.4277777777777778, 0.4433333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.07479918185066575, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13362128164519932, 0.1336212816451995, 0.2901303645804758], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.44783616], dtype=float32), 1.3414901]. 
=============================================
[2019-03-24 01:25:35,924] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7847: loss 0.6122
[2019-03-24 01:25:36,011] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7847: learning rate 0.0000
[2019-03-24 01:25:36,090] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 7886: loss 0.0053
[2019-03-24 01:25:36,093] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 7889: learning rate 0.0000
[2019-03-24 01:25:36,096] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7890: loss 0.0550
[2019-03-24 01:25:36,097] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7891: learning rate 0.0000
[2019-03-24 01:25:36,111] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7901: loss 0.1222
[2019-03-24 01:25:36,112] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7902: learning rate 0.0000
[2019-03-24 01:25:36,166] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7934: loss 0.2969
[2019-03-24 01:25:36,171] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7934: learning rate 0.0000
[2019-03-24 01:25:36,240] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7969: loss 0.6587
[2019-03-24 01:25:36,241] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 7969: learning rate 0.0000
[2019-03-24 01:25:36,298] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 8001: loss 0.3320
[2019-03-24 01:25:36,300] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 8001: learning rate 0.0000
[2019-03-24 01:25:36,306] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 8003: loss 0.7558
[2019-03-24 01:25:36,307] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 8004: learning rate 0.0000
[2019-03-24 01:25:36,318] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 8009: loss 0.4838
[2019-03-24 01:25:36,320] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 8010: learning rate 0.0000
[2019-03-24 01:25:36,336] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 8021: loss 0.2450
[2019-03-24 01:25:36,339] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 8021: learning rate 0.0000
[2019-03-24 01:25:36,357] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 8030: loss 0.0941
[2019-03-24 01:25:36,360] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 8031: learning rate 0.0000
[2019-03-24 01:25:36,363] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 8034: loss 0.2525
[2019-03-24 01:25:36,366] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 8034: learning rate 0.0000
[2019-03-24 01:25:36,373] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 8037: loss 0.1366
[2019-03-24 01:25:36,376] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 8037: learning rate 0.0000
[2019-03-24 01:25:36,401] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8048: loss 0.0107
[2019-03-24 01:25:36,404] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8048: learning rate 0.0000
[2019-03-24 01:25:36,427] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 8064: loss 0.0519
[2019-03-24 01:25:36,430] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 8066: learning rate 0.0000
[2019-03-24 01:25:36,498] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 8103: loss 0.6155
[2019-03-24 01:25:36,503] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 8105: learning rate 0.0000
[2019-03-24 01:25:37,773] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999988e-01 1.5641655e-09 1.6782505e-07 1.0610321e-15 5.9859402e-11], sum to 1.0000
[2019-03-24 01:25:37,782] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5299
[2019-03-24 01:25:37,957] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.8, 34.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5733565032546432, 6.911199999999999, 6.9112, 121.9260426156618, 413657.0765227927, 413657.0765227932, 122325.9028839723], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 327600.0000, 
sim time next is 328200.0000, 
raw observation next is [26.68333333333334, 34.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5721037785701798, 6.911200000000001, 6.9112, 121.9260426156618, 412609.0895792877, 412609.0895792873, 122169.8471929924], 
processed observation next is [0.0, 0.8260869565217391, 0.5438271604938274, 0.34333333333333343, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4651297232127247, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14736038913545987, 0.14736038913545974, 0.23494201383267768], 
reward next is 0.7651, 
noisyNet noise sample is [array([-0.09127472], dtype=float32), -1.4111754]. 
=============================================
[2019-03-24 01:25:46,433] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.3709041e-02 2.2073274e-11 9.2598724e-01 5.8830746e-11 3.0373535e-04], sum to 1.0000
[2019-03-24 01:25:46,440] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5297
[2019-03-24 01:25:46,613] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.76666666666667, 24.66666666666666, 1.0, 1.0, 0.1837274647406557, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3110644908252552, 6.911199999999999, 6.9112, 121.9260426156618, 461764.0699462772, 461764.0699462777, 162741.4183768205], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 495600.0000, 
sim time next is 496200.0000, 
raw observation next is [31.53333333333333, 25.33333333333334, 1.0, 2.0, 0.1840186385345456, 0.0, 2.0, 0.0, 1.0, 2.0, 0.311104813659601, 6.911199999999999, 6.9112, 121.9260426156618, 462091.6017912849, 462091.6017912854, 162883.1172262452], 
processed observation next is [1.0, 0.7391304347826086, 0.7234567901234568, 0.2533333333333334, 1.0, 1.0, 0.028593617303030457, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.13888101707450126, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1650327149254589, 0.16503271492545907, 0.3132367638966254], 
reward next is 0.6868, 
noisyNet noise sample is [array([0.56707853], dtype=float32), -0.4311495]. 
=============================================
[2019-03-24 01:25:50,888] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.2868718e-01 9.9597564e-08 4.6459872e-01 4.2580570e-09 6.7139659e-03], sum to 1.0000
[2019-03-24 01:25:50,896] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1777
[2019-03-24 01:25:50,903] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1488099.792622718 W.
[2019-03-24 01:25:51,075] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.8, 31.66666666666667, 1.0, 2.0, 0.6195478745771396, 1.0, 2.0, 0.6195478745771396, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1488099.792622718, 1488099.792622718, 278130.7967626821], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 576600.0000, 
sim time next is 577200.0000, 
raw observation next is [31.9, 31.33333333333334, 1.0, 2.0, 0.6801922587562251, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9580776864287837, 6.9112, 6.9112, 121.9260426156618, 1538319.849895207, 1538319.849895207, 303307.9078104319], 
processed observation next is [1.0, 0.6956521739130435, 0.7370370370370369, 0.3133333333333334, 1.0, 1.0, 0.6192764985193157, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9475971080359796, 0.0, 0.0, 0.8094621288201359, 0.5493999463911453, 0.5493999463911453, 0.5832844380969844], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.63986814], dtype=float32), -1.6843811]. 
=============================================
[2019-03-24 01:25:51,107] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9450278e-01 4.0976525e-10 5.3294096e-03 7.4306816e-10 1.6792375e-04], sum to 1.0000
[2019-03-24 01:25:51,114] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4554
[2019-03-24 01:25:51,283] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.15, 30.33333333333333, 1.0, 2.0, 0.27809532291239, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4531676909487793, 6.911199999999999, 6.9112, 121.9260426156618, 676557.8631981176, 676557.8631981179, 187472.8466429218], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 580200.0000, 
sim time next is 580800.0000, 
raw observation next is [32.0, 30.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6429951586702926, 6.9112, 6.9112, 121.9260426156618, 480445.5357540344, 480445.5357540344, 138246.5302966169], 
processed observation next is [1.0, 0.7391304347826086, 0.7407407407407407, 0.3066666666666667, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5537439483378657, 0.0, 0.0, 0.8094621288201359, 0.17158769134072657, 0.17158769134072657, 0.2658587121088786], 
reward next is 0.7341, 
noisyNet noise sample is [array([-2.1368575], dtype=float32), 0.14125265]. 
=============================================
[2019-03-24 01:25:51,905] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 15826: loss 7.5606
[2019-03-24 01:25:51,906] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 15827: learning rate 0.0000
[2019-03-24 01:25:51,926] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15833: loss 11.9004
[2019-03-24 01:25:51,928] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15833: learning rate 0.0000
[2019-03-24 01:25:52,029] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 15896: loss 0.9186
[2019-03-24 01:25:52,031] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 15896: learning rate 0.0000
[2019-03-24 01:25:52,041] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15898: loss 3.8083
[2019-03-24 01:25:52,045] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 15899: learning rate 0.0000
[2019-03-24 01:25:52,053] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 15902: loss 9.8365
[2019-03-24 01:25:52,056] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 15903: learning rate 0.0000
[2019-03-24 01:25:52,088] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15916: loss 4.9004
[2019-03-24 01:25:52,088] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15916: learning rate 0.0000
[2019-03-24 01:25:52,127] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 15936: loss 4.9982
[2019-03-24 01:25:52,127] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 15936: learning rate 0.0000
[2019-03-24 01:25:52,129] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 15936: loss 1.0347
[2019-03-24 01:25:52,131] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 15936: learning rate 0.0000
[2019-03-24 01:25:52,203] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 15981: loss 0.1377
[2019-03-24 01:25:52,205] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 15981: learning rate 0.0000
[2019-03-24 01:25:52,205] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 15981: loss 2.1455
[2019-03-24 01:25:52,211] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 15983: learning rate 0.0000
[2019-03-24 01:25:52,274] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 16014: loss 6.3233
[2019-03-24 01:25:52,278] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 16014: learning rate 0.0000
[2019-03-24 01:25:52,373] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 16067: loss 0.0167
[2019-03-24 01:25:52,375] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 16068: learning rate 0.0000
[2019-03-24 01:25:52,454] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 16106: loss 0.6800
[2019-03-24 01:25:52,456] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 16107: learning rate 0.0000
[2019-03-24 01:25:52,467] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 16111: loss 0.8404
[2019-03-24 01:25:52,468] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 16111: learning rate 0.0000
[2019-03-24 01:25:52,520] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 16143: loss 3.4241
[2019-03-24 01:25:52,522] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 16143: learning rate 0.0000
[2019-03-24 01:25:52,764] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 16268: loss 0.1667
[2019-03-24 01:25:52,765] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 16268: learning rate 0.0000
[2019-03-24 01:26:05,693] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.1087053e-27 1.7996631e-10 6.6678719e-30 1.4336756e-14], sum to 1.0000
[2019-03-24 01:26:05,703] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1328
[2019-03-24 01:26:05,713] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.61666666666667, 40.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6478270937154513, 6.911199999999999, 6.9112, 121.9260426156618, 483111.1005097752, 483111.1005097757, 136965.5101814226], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 849000.0000, 
sim time next is 849600.0000, 
raw observation next is [28.4, 41.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6420806618832106, 6.9112, 6.9112, 121.9260426156618, 478574.355408374, 478574.355408374, 136102.1810817076], 
processed observation next is [0.0, 0.8695652173913043, 0.6074074074074074, 0.41, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5526008273540132, 0.0, 0.0, 0.8094621288201359, 0.17091941264584784, 0.17091941264584784, 0.26173496361866844], 
reward next is 0.7383, 
noisyNet noise sample is [array([0.34847334], dtype=float32), 0.2568382]. 
=============================================
[2019-03-24 01:26:06,497] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.00000000e+00 5.45382013e-29 8.19114199e-09 4.45388132e-27
 1.33398965e-14], sum to 1.0000
[2019-03-24 01:26:06,507] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2260
[2019-03-24 01:26:06,520] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.93333333333334, 62.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.649245973704891, 6.911200000000001, 6.9112, 121.9260426156618, 483727.6433094683, 483727.6433094678, 136628.0734603229], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 866400.0000, 
sim time next is 867000.0000, 
raw observation next is [23.76666666666667, 63.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.646293760414891, 6.911199999999999, 6.9112, 121.9260426156618, 481392.2799525637, 481392.2799525642, 136197.5344515373], 
processed observation next is [0.0, 0.0, 0.43580246913580256, 0.6333333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5578672005186136, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17192581426877274, 0.17192581426877293, 0.26191833548372556], 
reward next is 0.7381, 
noisyNet noise sample is [array([-0.6799431], dtype=float32), -0.83345264]. 
=============================================
[2019-03-24 01:26:06,538] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[91.10108 ]
 [91.246376]
 [91.59927 ]
 [91.602905]
 [92.11156 ]], R is [[90.74217224]
 [90.57200623]
 [90.40268707]
 [90.23416138]
 [90.06648254]].
[2019-03-24 01:26:06,998] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.2252213e-22 5.7561930e-08 1.5044508e-23 1.6433811e-11], sum to 1.0000
[2019-03-24 01:26:07,007] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4913
[2019-03-24 01:26:07,011] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.1, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6040598253513685, 6.911200000000001, 6.9112, 121.9260426156618, 446337.0008756739, 446337.0008756734, 129493.113295219], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 874800.0000, 
sim time next is 875400.0000, 
raw observation next is [22.01666666666667, 66.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6001755620028982, 6.9112, 6.9112, 121.9260426156618, 442942.2229061592, 442942.2229061592, 128842.3733419716], 
processed observation next is [0.0, 0.13043478260869565, 0.37098765432098774, 0.6683333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5002194525036228, 0.0, 0.0, 0.8094621288201359, 0.158193651037914, 0.158193651037914, 0.24777379488840692], 
reward next is 0.7522, 
noisyNet noise sample is [array([0.68868023], dtype=float32), 0.21011516]. 
=============================================
[2019-03-24 01:26:07,686] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23781: loss 0.3441
[2019-03-24 01:26:07,690] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 23781: learning rate 0.0000
[2019-03-24 01:26:07,891] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23881: loss 0.0780
[2019-03-24 01:26:07,901] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23883: learning rate 0.0000
[2019-03-24 01:26:07,912] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 23888: loss 0.2935
[2019-03-24 01:26:07,913] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 23888: loss 0.2829
[2019-03-24 01:26:07,914] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 23888: learning rate 0.0000
[2019-03-24 01:26:07,914] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 23888: learning rate 0.0000
[2019-03-24 01:26:07,930] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 23893: loss 0.3828
[2019-03-24 01:26:07,934] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 23893: learning rate 0.0000
[2019-03-24 01:26:07,941] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23896: loss 0.4614
[2019-03-24 01:26:07,943] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23898: learning rate 0.0000
[2019-03-24 01:26:07,972] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23915: loss 0.5707
[2019-03-24 01:26:07,974] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 23915: learning rate 0.0000
[2019-03-24 01:26:08,037] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 23948: loss 0.4585
[2019-03-24 01:26:08,043] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 23948: learning rate 0.0000
[2019-03-24 01:26:08,109] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 23982: loss 0.0131
[2019-03-24 01:26:08,111] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 23982: learning rate 0.0000
[2019-03-24 01:26:08,179] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 24017: loss 0.0297
[2019-03-24 01:26:08,180] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 24017: learning rate 0.0000
[2019-03-24 01:26:08,192] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 24019: loss 0.0444
[2019-03-24 01:26:08,195] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 24019: learning rate 0.0000
[2019-03-24 01:26:08,318] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 24085: loss 1.0188
[2019-03-24 01:26:08,320] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 24085: learning rate 0.0000
[2019-03-24 01:26:08,341] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24094: loss 0.3185
[2019-03-24 01:26:08,345] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 24095: learning rate 0.0000
[2019-03-24 01:26:08,386] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 24118: loss 0.3454
[2019-03-24 01:26:08,387] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 24119: learning rate 0.0000
[2019-03-24 01:26:08,406] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 24129: loss 0.0906
[2019-03-24 01:26:08,407] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 24130: learning rate 0.0000
[2019-03-24 01:26:08,686] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 24265: loss 0.5968
[2019-03-24 01:26:08,690] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 24265: learning rate 0.0000
[2019-03-24 01:26:10,169] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 01:26:10,172] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:26:10,174] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:26:10,174] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:26:10,175] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:26:10,177] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:26:10,179] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:26:10,179] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:26:10,180] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:26:10,182] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:26:10,181] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:26:10,192] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run2
[2019-03-24 01:26:10,194] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run2
[2019-03-24 01:26:10,246] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run2
[2019-03-24 01:26:10,247] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run2
[2019-03-24 01:26:10,266] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run2
[2019-03-24 01:26:13,133] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.021732813]
[2019-03-24 01:26:13,134] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.20513772, 31.56197159, 1.0, 2.0, 0.6532652731833632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 803490.7483163013, 803490.7483163013, 169848.8419484042]
[2019-03-24 01:26:13,135] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:26:13,137] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9997711e-01 5.3341466e-16 2.2898030e-05 6.6041491e-17 5.3477276e-08], sampled 0.8708185030502315
[2019-03-24 01:26:13,138] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 803490.7483163013 W.
[2019-03-24 01:26:14,423] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.021732813]
[2019-03-24 01:26:14,425] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.0, 37.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4564286386336671, 6.9112, 6.9112, 121.9260426156618, 325887.8582089719, 325887.8582089719, 92130.29497355768]
[2019-03-24 01:26:14,426] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:26:14,430] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9999082e-01 2.5013184e-17 9.1203874e-06 2.5667857e-18 1.2578220e-08], sampled 0.7797303163604118
[2019-03-24 01:26:43,384] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.021732813]
[2019-03-24 01:26:43,387] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.83333333333334, 55.66666666666667, 1.0, 2.0, 0.6708484389998032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 765972.3488457205, 765972.3488457205, 170767.0202684741]
[2019-03-24 01:26:43,389] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:26:43,393] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9998748e-01 7.1689467e-17 1.2521288e-05 7.9624058e-18 2.0956804e-08], sampled 0.5922638891852837
[2019-03-24 01:26:43,394] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 765972.3488457205 W.
[2019-03-24 01:26:48,903] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.021732813]
[2019-03-24 01:26:48,904] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.4, 53.66666666666666, 1.0, 2.0, 0.6252470060378993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 712822.3822146391, 712822.3822146391, 162487.1054610476]
[2019-03-24 01:26:48,905] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:26:48,908] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9998271e-01 2.1283227e-16 1.7303420e-05 2.5012982e-17 3.4824751e-08], sampled 0.31631995449684647
[2019-03-24 01:26:48,909] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 712822.3822146391 W.
[2019-03-24 01:27:04,016] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.021732813]
[2019-03-24 01:27:04,018] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.3, 78.0, 1.0, 2.0, 0.6494440176514783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740154.640225956, 740154.640225956, 166793.5194572852]
[2019-03-24 01:27:04,020] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:27:04,025] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9998832e-01 5.9383984e-17 1.1715059e-05 6.4572655e-18 1.9076746e-08], sampled 0.8208734176352238
[2019-03-24 01:27:04,027] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 740154.640225956 W.
[2019-03-24 01:27:18,646] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.021732813]
[2019-03-24 01:27:18,647] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.4, 78.0, 1.0, 2.0, 0.9281665963645854, 1.0, 2.0, 0.7774479601587273, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2661177.055580489, 2661177.055580489, 496179.7593325124]
[2019-03-24 01:27:18,649] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:27:18,651] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9999881e-01 3.7441917e-20 1.2274015e-06 2.6109659e-21 5.8720845e-10], sampled 0.45621978423100973
[2019-03-24 01:27:18,652] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 2661177.055580489 W.
[2019-03-24 01:27:47,754] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.021732813]
[2019-03-24 01:27:47,755] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.80798015, 59.5157199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7719004559150356, 6.911200000000001, 6.9112, 121.9260426156618, 576238.944291356, 576238.9442913557, 151013.6039594966]
[2019-03-24 01:27:47,756] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:27:47,758] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9999678e-01 8.6149093e-19 3.2719345e-06 7.2461248e-20 2.5550506e-09], sampled 0.928447166945299
[2019-03-24 01:27:56,077] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8556.2651 2258352309.9227 536.0000
[2019-03-24 01:27:56,482] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8363.4371 2339475986.9735 616.0000
[2019-03-24 01:27:56,547] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8402.8788 2292956496.3333 697.0000
[2019-03-24 01:27:56,651] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8630.6983 2219252469.5742 543.0000
[2019-03-24 01:27:56,772] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7839.3582 2529785322.0825 831.0000
[2019-03-24 01:27:57,785] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 25000, evaluation results [25000.0, 7839.35819473556, 2529785322.0825343, 831.0, 8556.26510792546, 2258352309.9226737, 536.0, 8630.69825476134, 2219252469.574216, 543.0, 8363.437110714249, 2339475986.973477, 616.0, 8402.878782042042, 2292956496.3332763, 697.0]
[2019-03-24 01:27:58,194] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.2024462e-20 4.2741650e-08 7.7307682e-22 1.9265877e-11], sum to 1.0000
[2019-03-24 01:27:58,206] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3750
[2019-03-24 01:27:58,210] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.9, 50.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5424453741303391, 6.9112, 6.9112, 121.9260426156618, 395872.7629029266, 395872.7629029266, 121545.4409969326], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 944400.0000, 
sim time next is 945000.0000, 
raw observation next is [23.8, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.536861328003887, 6.9112, 6.9112, 121.9260426156618, 390908.8898194944, 390908.8898194944, 120709.0791252545], 
processed observation next is [0.0, 0.9565217391304348, 0.43703703703703706, 0.5, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.42107666000485866, 0.0, 0.0, 0.8094621288201359, 0.13961031779267657, 0.13961031779267657, 0.23213284447164328], 
reward next is 0.7679, 
noisyNet noise sample is [array([-0.17173645], dtype=float32), -2.3406541]. 
=============================================
[2019-03-24 01:27:58,228] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[71.100426]
 [71.13855 ]
 [71.1543  ]
 [71.195724]
 [71.20506 ]], R is [[71.11823273]
 [71.17330933]
 [71.22602844]
 [71.27648926]
 [71.32491302]].
[2019-03-24 01:27:58,302] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.3017658e-24 6.4630601e-10 4.6592440e-29 2.0047399e-12], sum to 1.0000
[2019-03-24 01:27:58,309] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4140
[2019-03-24 01:27:58,314] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.4, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4960929236285073, 6.911199999999999, 6.9112, 121.9260426156618, 356135.8522003017, 356135.8522003021, 115478.1398931841], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 952200.0000, 
sim time next is 952800.0000, 
raw observation next is [22.26666666666667, 53.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4940844123275477, 6.9112, 6.9112, 121.9260426156618, 354216.057343427, 354216.057343427, 115159.2178765103], 
processed observation next is [1.0, 0.0, 0.38024691358024704, 0.5333333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3676055154094346, 0.0, 0.0, 0.8094621288201359, 0.12650573476550964, 0.12650573476550964, 0.22146003437790443], 
reward next is 0.7785, 
noisyNet noise sample is [array([-0.25220275], dtype=float32), 1.0521796]. 
=============================================
[2019-03-24 01:28:00,079] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.3154343e-27 6.6239180e-13 2.1924316e-30 1.9151419e-15], sum to 1.0000
[2019-03-24 01:28:00,083] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2493
[2019-03-24 01:28:00,086] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 860596.5362277497 W.
[2019-03-24 01:28:00,270] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.66666666666667, 57.66666666666667, 1.0, 2.0, 0.6825853885528437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426117999, 860596.5362277497, 860596.5362277497, 175812.5235679174], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 984000.0000, 
sim time next is 984600.0000, 
raw observation next is [23.8, 57.5, 1.0, 2.0, 0.3499673555122405, 1.0, 1.0, 0.3499673555122405, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156606, 872267.1593728295, 872267.1593728295, 195614.696561275], 
processed observation next is [1.0, 0.391304347826087, 0.43703703703703706, 0.575, 1.0, 1.0, 0.22615161370504822, 1.0, 0.5, 0.22615161370504822, 0.0, 1.0, -0.25, 0.0, 0.0, 0.809462128820128, 0.31152398549029625, 0.31152398549029625, 0.3761821087716827], 
reward next is 0.6238, 
noisyNet noise sample is [array([-0.69524556], dtype=float32), -2.0527053]. 
=============================================
[2019-03-24 01:28:08,770] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999630e-01 6.6933743e-25 3.7177474e-06 5.6721292e-24 3.9565929e-08], sum to 1.0000
[2019-03-24 01:28:08,781] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8405
[2019-03-24 01:28:08,786] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.03333333333333, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4832877979821229, 6.911199999999999, 6.9112, 121.9260426156618, 346616.0097843832, 346616.0097843836, 114391.9073897776], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1143600.0000, 
sim time next is 1144200.0000, 
raw observation next is [19.11666666666667, 74.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4818463309963799, 6.911200000000001, 6.9112, 121.9260426156618, 345703.9545943809, 345703.9545943805, 114325.9121406562], 
processed observation next is [1.0, 0.21739130434782608, 0.2635802469135804, 0.745, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3523079137454749, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12346569806942176, 0.1234656980694216, 0.2198575233474158], 
reward next is 0.7801, 
noisyNet noise sample is [array([0.7671167], dtype=float32), -0.4571286]. 
=============================================
[2019-03-24 01:28:10,870] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 31697: loss 1.1085
[2019-03-24 01:28:10,873] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 31698: learning rate 0.0000
[2019-03-24 01:28:11,063] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 31793: loss 0.9583
[2019-03-24 01:28:11,066] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 31794: learning rate 0.0000
[2019-03-24 01:28:11,136] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31838: loss 1.2398
[2019-03-24 01:28:11,138] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31838: learning rate 0.0000
[2019-03-24 01:28:11,223] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 31877: loss 0.3438
[2019-03-24 01:28:11,224] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 31877: learning rate 0.0000
[2019-03-24 01:28:11,252] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 31893: loss 1.4014
[2019-03-24 01:28:11,257] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 31894: learning rate 0.0000
[2019-03-24 01:28:11,314] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31931: loss 0.7900
[2019-03-24 01:28:11,318] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31931: learning rate 0.0000
[2019-03-24 01:28:11,353] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 31948: loss 0.5152
[2019-03-24 01:28:11,356] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 31951: learning rate 0.0000
[2019-03-24 01:28:11,375] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 31957: loss 0.1297
[2019-03-24 01:28:11,377] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 31958: learning rate 0.0000
[2019-03-24 01:28:11,528] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 32040: loss 0.1627
[2019-03-24 01:28:11,533] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 32041: learning rate 0.0000
[2019-03-24 01:28:11,535] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32042: loss 0.1044
[2019-03-24 01:28:11,538] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 32042: learning rate 0.0000
[2019-03-24 01:28:11,559] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 32052: loss 0.2707
[2019-03-24 01:28:11,560] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 32052: learning rate 0.0000
[2019-03-24 01:28:11,571] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 32058: loss 0.0643
[2019-03-24 01:28:11,575] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 32058: learning rate 0.0000
[2019-03-24 01:28:11,661] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 32106: loss 0.2564
[2019-03-24 01:28:11,662] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 32106: learning rate 0.0000
[2019-03-24 01:28:11,729] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 32139: loss 0.0719
[2019-03-24 01:28:11,730] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 32139: learning rate 0.0000
[2019-03-24 01:28:11,742] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 32144: loss 0.1619
[2019-03-24 01:28:11,745] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 32145: learning rate 0.0000
[2019-03-24 01:28:11,941] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 32256: loss 1.2118
[2019-03-24 01:28:11,943] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 32257: learning rate 0.0000
[2019-03-24 01:28:12,103] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 6.1769631e-24 1.7063893e-12 2.0725388e-24 2.9579533e-11], sum to 1.0000
[2019-03-24 01:28:12,106] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9838
[2019-03-24 01:28:12,111] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.73333333333333, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5912205419890256, 6.9112, 6.9112, 121.9260426156618, 437452.3426364116, 437452.3426364116, 128662.0657567823], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1207200.0000, 
sim time next is 1207800.0000, 
raw observation next is [18.7, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5893310119143593, 6.911199999999999, 6.9112, 121.9260426156618, 435903.042919568, 435903.0429195684, 128398.0313361957], 
processed observation next is [1.0, 1.0, 0.24814814814814812, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4866637648929491, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15567965818556, 0.15567965818556015, 0.24691929103114557], 
reward next is 0.7531, 
noisyNet noise sample is [array([1.9098821], dtype=float32), -1.6979649]. 
=============================================
[2019-03-24 01:28:14,510] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.99999762e-01 6.18956197e-15 1.52439327e-07 1.08790316e-13
 6.20304519e-08], sum to 1.0000
[2019-03-24 01:28:14,524] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1624
[2019-03-24 01:28:14,528] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1187923.249745309 W.
[2019-03-24 01:28:14,705] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.13333333333333, 56.66666666666666, 1.0, 2.0, 0.490139014450133, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7962503636047593, 6.911199999999999, 6.9112, 121.9260426156618, 1187923.249745309, 1187923.24974531, 251291.7842758134], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1262400.0000, 
sim time next is 1263000.0000, 
raw observation next is [26.16666666666666, 56.33333333333334, 1.0, 2.0, 0.3383431841091231, 1.0, 1.0, 0.3383431841091231, 1.0, 2.0, 0.5453028375146844, 6.9112, 6.9112, 121.94756008, 1214138.395992509, 1214138.395992509, 270701.2602500582], 
processed observation next is [1.0, 0.6086956521739131, 0.5246913580246911, 0.5633333333333335, 1.0, 1.0, 0.21231331441562276, 1.0, 0.5, 0.21231331441562276, 1.0, 1.0, 0.4316285468933555, 0.0, 0.0, 0.8096049824067558, 0.4336208557116104, 0.4336208557116104, 0.5205793466347273], 
reward next is 0.4794, 
noisyNet noise sample is [array([1.5867643], dtype=float32), -1.4108324]. 
=============================================
[2019-03-24 01:28:14,734] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[37.073174]
 [36.977085]
 [36.056107]
 [36.09996 ]
 [36.359825]], R is [[37.48869324]
 [37.6305542 ]
 [37.79587173]
 [37.98711777]
 [38.12616348]].
[2019-03-24 01:28:18,562] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9992156e-01 2.9315092e-15 7.8386140e-05 4.6248273e-14 4.7763027e-08], sum to 1.0000
[2019-03-24 01:28:18,571] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8902
[2019-03-24 01:28:18,576] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 966441.9539519014 W.
[2019-03-24 01:28:18,753] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333333, 44.66666666666667, 1.0, 2.0, 0.3921894523458646, 1.0, 2.0, 0.3921894523458646, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 966441.9539519014, 966441.9539519014, 206833.749221327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1335000.0000, 
sim time next is 1335600.0000, 
raw observation next is [27.2, 43.0, 1.0, 2.0, 0.7677057363668055, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 958505.8223194628, 958505.8223194628, 192603.6131904378], 
processed observation next is [1.0, 0.4782608695652174, 0.5629629629629629, 0.43, 1.0, 1.0, 0.7234592099604827, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.34232350797123673, 0.34232350797123673, 0.370391563827765], 
reward next is 0.6296, 
noisyNet noise sample is [array([0.94743633], dtype=float32), 1.3190819]. 
=============================================
[2019-03-24 01:28:21,302] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9998772e-01 3.1610816e-19 1.2133956e-05 8.5942875e-18 1.2583526e-07], sum to 1.0000
[2019-03-24 01:28:21,313] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9603
[2019-03-24 01:28:21,319] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.6, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.55843805060471, 6.911199999999999, 6.9112, 121.9260426156618, 410118.4835385369, 410118.4835385374, 124048.0609094942], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1386000.0000, 
sim time next is 1386600.0000, 
raw observation next is [21.51666666666667, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5550502687804925, 6.911200000000001, 6.9112, 121.9260426156618, 407230.3023363766, 407230.3023363761, 123565.0433138931], 
processed observation next is [0.0, 0.043478260869565216, 0.35246913580246925, 0.67, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44381283597561555, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14543939369156308, 0.1454393936915629, 0.23762508329594825], 
reward next is 0.7624, 
noisyNet noise sample is [array([0.0303878], dtype=float32), -1.0952965]. 
=============================================
[2019-03-24 01:28:26,370] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39611: loss 0.0013
[2019-03-24 01:28:26,375] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 39611: learning rate 0.0000
[2019-03-24 01:28:26,628] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39749: loss 0.2797
[2019-03-24 01:28:26,631] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39749: learning rate 0.0000
[2019-03-24 01:28:26,791] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 39834: loss 0.0945
[2019-03-24 01:28:26,793] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 39834: learning rate 0.0000
[2019-03-24 01:28:26,890] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 39883: loss 0.0849
[2019-03-24 01:28:26,892] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 39883: learning rate 0.0000
[2019-03-24 01:28:27,006] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39942: loss 0.2429
[2019-03-24 01:28:27,007] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 39942: loss 0.2227
[2019-03-24 01:28:27,007] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39942: learning rate 0.0000
[2019-03-24 01:28:27,009] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 39942: learning rate 0.0000
[2019-03-24 01:28:27,057] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39967: loss 0.7373
[2019-03-24 01:28:27,060] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39968: learning rate 0.0000
[2019-03-24 01:28:27,083] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39986: loss 0.7279
[2019-03-24 01:28:27,085] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39986: learning rate 0.0000
[2019-03-24 01:28:27,087] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 39987: loss 0.7451
[2019-03-24 01:28:27,089] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 39987: learning rate 0.0000
[2019-03-24 01:28:27,128] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 40009: loss 0.9553
[2019-03-24 01:28:27,130] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 40009: learning rate 0.0000
[2019-03-24 01:28:27,158] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 40021: loss 0.3720
[2019-03-24 01:28:27,159] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 40021: learning rate 0.0000
[2019-03-24 01:28:27,189] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 40032: loss 0.4591
[2019-03-24 01:28:27,193] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 40033: learning rate 0.0000
[2019-03-24 01:28:27,388] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9997818e-01 1.4144525e-21 2.1760081e-05 8.5407052e-18 4.0234212e-08], sum to 1.0000
[2019-03-24 01:28:27,393] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0749
[2019-03-24 01:28:27,400] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.59999999999999, 33.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7184804917065639, 6.911200000000001, 6.9112, 121.9260426156618, 536615.5587882494, 536615.5587882489, 148052.2871801122], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1507200.0000, 
sim time next is 1507800.0000, 
raw observation next is [32.95, 32.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7185034160733721, 6.911200000000001, 6.9112, 121.9260426156618, 536600.2022084438, 536600.2022084434, 148115.6338066652], 
processed observation next is [0.0, 0.43478260869565216, 0.775925925925926, 0.32, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6481292700917152, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1916429293601585, 0.19164292936015836, 0.28483775732051], 
reward next is 0.7152, 
noisyNet noise sample is [array([-0.3709817], dtype=float32), -2.8727307]. 
=============================================
[2019-03-24 01:28:27,405] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 40151: loss 0.3231
[2019-03-24 01:28:27,409] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 40152: learning rate 0.0000
[2019-03-24 01:28:27,417] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 40154: loss 0.4052
[2019-03-24 01:28:27,421] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 40155: learning rate 0.0000
[2019-03-24 01:28:27,616] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 40261: loss 0.0521
[2019-03-24 01:28:27,617] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 40261: learning rate 0.0000
[2019-03-24 01:28:27,624] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 40265: loss 0.1594
[2019-03-24 01:28:27,629] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 40265: learning rate 0.0000
[2019-03-24 01:28:34,624] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9600548e-01 1.4895245e-20 3.9944933e-03 1.5410111e-19 2.8477631e-09], sum to 1.0000
[2019-03-24 01:28:34,630] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2249
[2019-03-24 01:28:34,634] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.2, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5537199363791644, 6.911200000000001, 6.9112, 121.9260426156618, 406421.2211283945, 406421.2211283941, 123528.9270884791], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1645200.0000, 
sim time next is 1645800.0000, 
raw observation next is [22.11666666666667, 63.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5549208640913539, 6.9112, 6.9112, 121.9260426156618, 407315.9104618744, 407315.9104618744, 123638.8173748584], 
processed observation next is [1.0, 0.043478260869565216, 0.3746913580246915, 0.635, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4436510801141923, 0.0, 0.0, 0.8094621288201359, 0.145469968022098, 0.145469968022098, 0.23776695649011229], 
reward next is 0.7622, 
noisyNet noise sample is [array([-1.1293364], dtype=float32), -1.3571044]. 
=============================================
[2019-03-24 01:28:41,069] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9959964e-01 6.0576508e-17 4.0040724e-04 4.6742319e-15 2.5746616e-09], sum to 1.0000
[2019-03-24 01:28:41,079] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4892
[2019-03-24 01:28:41,091] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 976937.599793056 W.
[2019-03-24 01:28:41,094] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.6, 71.33333333333334, 1.0, 2.0, 0.7987254699826515, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 976937.599793056, 976937.599793056, 198559.249129392], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1761600.0000, 
sim time next is 1762200.0000, 
raw observation next is [23.7, 71.0, 1.0, 2.0, 0.28290034844849, 1.0, 1.0, 0.28290034844849, 1.0, 1.0, 0.4618664497419533, 6.911199999999999, 6.9112, 121.94756008, 1035030.089541156, 1035030.089541157, 248384.2783914332], 
processed observation next is [1.0, 0.391304347826087, 0.4333333333333333, 0.71, 1.0, 1.0, 0.14630993862915476, 1.0, 0.5, 0.14630993862915476, 1.0, 0.5, 0.32733306217744157, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3696536034075557, 0.3696536034075561, 0.47766207382967923], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2705861], dtype=float32), -1.2757432]. 
=============================================
[2019-03-24 01:28:42,404] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 47678: loss 1.4961
[2019-03-24 01:28:42,409] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 47678: learning rate 0.0000
[2019-03-24 01:28:42,708] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 47829: loss 4.9497
[2019-03-24 01:28:42,711] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 47829: learning rate 0.0000
[2019-03-24 01:28:42,793] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47869: loss -7.2274
[2019-03-24 01:28:42,798] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 47870: learning rate 0.0000
[2019-03-24 01:28:42,812] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 47874: loss 3.6749
[2019-03-24 01:28:42,813] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 47874: learning rate 0.0000
[2019-03-24 01:28:42,851] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 47898: loss -2.8284
[2019-03-24 01:28:42,854] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 47898: learning rate 0.0000
[2019-03-24 01:28:42,915] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 47929: loss 6.3604
[2019-03-24 01:28:42,917] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 47929: learning rate 0.0000
[2019-03-24 01:28:42,985] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 47962: loss -2.5243
[2019-03-24 01:28:42,987] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 47963: learning rate 0.0000
[2019-03-24 01:28:43,029] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 47985: loss -1.4659
[2019-03-24 01:28:43,030] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 47985: learning rate 0.0000
[2019-03-24 01:28:43,050] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 47997: loss 1.4017
[2019-03-24 01:28:43,054] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 47997: learning rate 0.0000
[2019-03-24 01:28:43,066] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 48005: loss 3.8281
[2019-03-24 01:28:43,069] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 48006: learning rate 0.0000
[2019-03-24 01:28:43,088] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 48013: loss -1.9069
[2019-03-24 01:28:43,089] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 48013: learning rate 0.0000
[2019-03-24 01:28:43,165] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 48052: loss -1.8799
[2019-03-24 01:28:43,167] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 48052: learning rate 0.0000
[2019-03-24 01:28:43,257] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 48094: loss -2.0339
[2019-03-24 01:28:43,260] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 48095: learning rate 0.0000
[2019-03-24 01:28:43,261] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 48096: loss 1.3306
[2019-03-24 01:28:43,264] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 48098: learning rate 0.0000
[2019-03-24 01:28:43,574] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 48252: loss 0.0076
[2019-03-24 01:28:43,576] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 48253: learning rate 0.0000
[2019-03-24 01:28:43,765] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 48341: loss 0.4407
[2019-03-24 01:28:43,768] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 48342: learning rate 0.0000
[2019-03-24 01:28:47,125] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 01:28:47,127] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:28:47,128] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:28:47,128] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:28:47,129] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:28:47,129] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:28:47,130] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:28:47,131] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:28:47,130] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:28:47,131] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:28:47,133] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:28:47,149] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run3
[2019-03-24 01:28:47,150] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run3
[2019-03-24 01:28:47,204] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run3
[2019-03-24 01:28:47,204] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run3
[2019-03-24 01:28:47,224] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run3
[2019-03-24 01:29:02,173] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.03499224]
[2019-03-24 01:29:02,174] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.79219866666667, 63.73570321333334, 1.0, 1.0, 0.2101178540579479, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3434216781355151, 6.9112, 6.9112, 121.9260426156618, 512999.6614082333, 512999.6614082333, 170714.7725031153]
[2019-03-24 01:29:02,176] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:29:02,180] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.0880356e-01 2.8436383e-14 6.9106042e-01 1.5448700e-12 1.3610517e-04], sampled 0.634180402692361
[2019-03-24 01:29:28,250] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.03499224]
[2019-03-24 01:29:28,252] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.86027088, 82.77644356333334, 1.0, 2.0, 0.3495563428393633, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5565050820555764, 6.9112, 6.9112, 121.9260426156618, 796790.1645854957, 796790.1645854957, 209048.7122482704]
[2019-03-24 01:29:28,253] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:29:28,257] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.8507099e-01 4.4854937e-16 7.1488470e-01 4.1445319e-14 4.4326098e-05], sampled 0.3041108983888088
[2019-03-24 01:29:37,351] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.03499224]
[2019-03-24 01:29:37,352] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9131601409523564, 6.911200000000001, 6.9112, 121.9260426156618, 672755.6473083809, 672755.6473083805, 176640.9903697867]
[2019-03-24 01:29:37,354] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:29:37,356] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.0181277e-01 6.3605618e-15 6.9809651e-01 4.1946755e-13 9.0781461e-05], sampled 0.5434360357898428
[2019-03-24 01:29:47,967] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.03499224]
[2019-03-24 01:29:47,967] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.2552323714047012, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4106276505892365, 6.9112, 6.9112, 121.9260426156618, 608167.1048801392, 608167.1048801392, 182639.8566843194]
[2019-03-24 01:29:47,972] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:29:47,978] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.9022554e-01 8.9066171e-16 7.0972103e-01 7.5281219e-14 5.3509284e-05], sampled 0.14713972908715156
[2019-03-24 01:29:53,779] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.03499224]
[2019-03-24 01:29:53,780] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.03333333333333, 93.66666666666667, 1.0, 2.0, 0.3028982031444734, 0.0, 2.0, 0.0, 1.0, 1.0, 0.482372723404167, 6.911199999999999, 6.9112, 121.9260426156618, 693891.9050556262, 693891.9050556266, 195967.0549521557]
[2019-03-24 01:29:53,781] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:29:53,787] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.0501357e-01 1.6646095e-14 6.9486839e-01 9.6803381e-13 1.1805103e-04], sampled 0.2073872579193372
[2019-03-24 01:29:53,788] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 693891.9050556262 W.
[2019-03-24 01:30:32,822] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 5765.8515 2562409233.8867 304.0000
[2019-03-24 01:30:33,046] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 6036.2195 2523485227.8485 301.0000
[2019-03-24 01:30:33,120] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 6207.0429 2461430647.3282 208.0000
[2019-03-24 01:30:33,321] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 5877.9845 2495322623.1450 225.0000
[2019-03-24 01:30:33,443] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 5926.8885 2740066721.9083 422.0000
[2019-03-24 01:30:34,457] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 50000, evaluation results [50000.0, 5926.888494069648, 2740066721.9082522, 422.0, 5877.984485720814, 2495322623.1450067, 225.0, 6207.042895894911, 2461430647.328239, 208.0, 5765.8515433026005, 2562409233.886691, 304.0, 6036.219458066111, 2523485227.848455, 301.0]
[2019-03-24 01:30:35,510] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999321e-01 2.8022947e-22 6.8156833e-06 1.9748004e-21 3.0266150e-09], sum to 1.0000
[2019-03-24 01:30:35,516] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0379
[2019-03-24 01:30:35,524] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.16666666666667, 90.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6976847966942679, 6.911200000000001, 6.9112, 121.9260426156618, 521371.1963222628, 521371.1963222623, 144657.9846643029], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1883400.0000, 
sim time next is 1884000.0000, 
raw observation next is [21.13333333333333, 90.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6955559073562025, 6.911200000000001, 6.9112, 121.9260426156618, 519780.9215856874, 519780.9215856869, 144393.5087394848], 
processed observation next is [1.0, 0.8260869565217391, 0.33827160493827146, 0.9033333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6194448841952531, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18563604342345977, 0.1856360434234596, 0.27767982449900924], 
reward next is 0.7223, 
noisyNet noise sample is [array([0.73071986], dtype=float32), 0.31443623]. 
=============================================
[2019-03-24 01:30:35,539] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[70.19648 ]
 [70.0578  ]
 [70.4814  ]
 [70.070435]
 [70.54883 ]], R is [[69.87815857]
 [69.90118408]
 [69.92362976]
 [69.94580841]
 [69.96755219]].
[2019-03-24 01:30:35,899] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9995971e-01 1.2248286e-18 4.0112009e-05 2.4747988e-17 2.1654203e-07], sum to 1.0000
[2019-03-24 01:30:35,910] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7677
[2019-03-24 01:30:35,915] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.98333333333333, 91.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6958771789717023, 6.9112, 6.9112, 121.9260426156618, 520020.1879765915, 520020.1879765915, 144255.1000721408], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1890600.0000, 
sim time next is 1891200.0000, 
raw observation next is [20.96666666666667, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6921313129731681, 6.9112, 6.9112, 121.9260426156618, 517217.9631507876, 517217.9631507876, 143805.3116965152], 
processed observation next is [1.0, 0.9130434782608695, 0.3320987654320988, 0.91, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6151641412164601, 0.0, 0.0, 0.8094621288201359, 0.18472070112528127, 0.18472070112528127, 0.2765486763394523], 
reward next is 0.7235, 
noisyNet noise sample is [array([0.29686013], dtype=float32), -0.2840076]. 
=============================================
[2019-03-24 01:30:43,154] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9998140e-01 2.2281754e-21 1.8248998e-05 4.3147951e-19 3.1917367e-07], sum to 1.0000
[2019-03-24 01:30:43,161] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8273
[2019-03-24 01:30:43,165] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.1, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8665029899255945, 6.911199999999999, 6.9112, 121.9260426156618, 635295.9182062648, 635295.9182062653, 171301.6480557123], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2037600.0000, 
sim time next is 2038200.0000, 
raw observation next is [28.15, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8717357576356268, 6.9112, 6.9112, 121.9260426156618, 638598.2588006834, 638598.2588006834, 172096.1983314953], 
processed observation next is [0.0, 0.6086956521739131, 0.5981481481481481, 0.63, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8396696970445335, 0.0, 0.0, 0.8094621288201359, 0.22807080671452978, 0.22807080671452978, 0.3309542275605679], 
reward next is 0.6690, 
noisyNet noise sample is [array([-0.7025548], dtype=float32), -0.93323237]. 
=============================================
[2019-03-24 01:30:45,057] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999952e-01 5.5147661e-19 5.1230637e-07 8.0093505e-19 1.1949538e-08], sum to 1.0000
[2019-03-24 01:30:45,065] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6794
[2019-03-24 01:30:45,248] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.45, 76.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9426874694844638, 6.911199999999999, 6.9112, 121.9260426156618, 679786.3029153745, 679786.302915375, 183276.1612089674], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2061000.0000, 
sim time next is 2061600.0000, 
raw observation next is [26.3, 76.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9281629442432625, 6.911200000000001, 6.9112, 121.9260426156618, 674695.0185921664, 674695.0185921659, 180542.5567922404], 
processed observation next is [0.0, 0.8695652173913043, 0.5296296296296297, 0.7633333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.910203680304078, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24096250664005942, 0.24096250664005925, 0.34719722460046226], 
reward next is 0.6528, 
noisyNet noise sample is [array([0.19854447], dtype=float32), -1.1390284]. 
=============================================
[2019-03-24 01:30:45,798] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 55565: loss 0.0493
[2019-03-24 01:30:45,799] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 55565: learning rate 0.0000
[2019-03-24 01:30:46,355] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 55857: loss 0.4871
[2019-03-24 01:30:46,358] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 55857: learning rate 0.0000
[2019-03-24 01:30:46,439] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 55899: loss 0.0001
[2019-03-24 01:30:46,443] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 55900: learning rate 0.0000
[2019-03-24 01:30:46,490] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 55924: loss 0.0271
[2019-03-24 01:30:46,494] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 55926: learning rate 0.0000
[2019-03-24 01:30:46,511] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 55936: loss 0.0132
[2019-03-24 01:30:46,516] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 55938: learning rate 0.0000
[2019-03-24 01:30:46,544] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 55952: loss 0.1777
[2019-03-24 01:30:46,545] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 55953: learning rate 0.0000
[2019-03-24 01:30:46,575] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 55969: loss 0.2826
[2019-03-24 01:30:46,577] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 55969: learning rate 0.0000
[2019-03-24 01:30:46,591] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55975: loss 0.3131
[2019-03-24 01:30:46,593] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 55976: learning rate 0.0000
[2019-03-24 01:30:46,630] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 55994: loss 0.2154
[2019-03-24 01:30:46,631] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 55994: learning rate 0.0000
[2019-03-24 01:30:46,632] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 55995: loss 0.3180
[2019-03-24 01:30:46,637] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 55996: learning rate 0.0000
[2019-03-24 01:30:46,666] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 56008: loss 0.1025
[2019-03-24 01:30:46,668] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 56009: learning rate 0.0000
[2019-03-24 01:30:46,697] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 56032: loss 0.0896
[2019-03-24 01:30:46,703] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 56033: learning rate 0.0000
[2019-03-24 01:30:46,756] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 56060: loss 0.0011
[2019-03-24 01:30:46,759] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 56061: learning rate 0.0000
[2019-03-24 01:30:46,760] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 56063: loss 0.0002
[2019-03-24 01:30:46,765] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 56063: learning rate 0.0000
[2019-03-24 01:30:47,136] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 56256: loss 0.2082
[2019-03-24 01:30:47,139] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 56256: learning rate 0.0000
[2019-03-24 01:30:47,190] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 56288: loss 0.4479
[2019-03-24 01:30:47,193] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 56291: learning rate 0.0000
[2019-03-24 01:30:47,854] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.5095400e-21 8.2782332e-09 5.7679561e-18 1.9917035e-10], sum to 1.0000
[2019-03-24 01:30:47,860] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0359
[2019-03-24 01:30:48,047] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.58333333333334, 54.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9303231366145572, 6.911200000000001, 6.9112, 121.9260426156618, 674410.9560616381, 674410.9560616376, 181112.9785452639], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2124600.0000, 
sim time next is 2125200.0000, 
raw observation next is [30.66666666666667, 53.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.926709080291277, 6.9112, 6.9112, 121.9260426156618, 672437.709400504, 672437.709400504, 180525.6635725831], 
processed observation next is [0.0, 0.6086956521739131, 0.6913580246913582, 0.5366666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9083863503640962, 0.0, 0.0, 0.8094621288201359, 0.2401563247858943, 0.2401563247858943, 0.34716473763958283], 
reward next is 0.6528, 
noisyNet noise sample is [array([0.35297093], dtype=float32), 2.3387754]. 
=============================================
[2019-03-24 01:30:51,585] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9793470e-01 1.2343628e-10 2.0534866e-03 1.5231419e-10 1.1811124e-05], sum to 1.0000
[2019-03-24 01:30:51,592] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2538
[2019-03-24 01:30:51,599] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 780747.9770508376 W.
[2019-03-24 01:30:51,604] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.03333333333333, 89.0, 1.0, 2.0, 0.3380126193834732, 1.0, 1.0, 0.3380126193834732, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 780747.9770508376, 780747.9770508381, 190326.3624749339], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2182200.0000, 
sim time next is 2182800.0000, 
raw observation next is [24.06666666666667, 89.0, 1.0, 2.0, 0.2042549071169867, 1.0, 2.0, 0.2042549071169867, 1.0, 1.0, 0.3252913487042075, 6.9112, 6.9112, 121.94756008, 702153.1375040702, 702153.1375040702, 221999.5107230038], 
processed observation next is [1.0, 0.2608695652173913, 0.4469135802469137, 0.89, 1.0, 1.0, 0.05268441323450799, 1.0, 1.0, 0.05268441323450799, 1.0, 0.5, 0.15661418588025935, 0.0, 0.0, 0.8096049824067558, 0.25076897768002504, 0.25076897768002504, 0.42692213600577655], 
reward next is 0.5731, 
noisyNet noise sample is [array([0.4753852], dtype=float32), -0.9649872]. 
=============================================
[2019-03-24 01:30:51,628] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.8151052e-01 2.9899874e-11 1.8446714e-02 8.6736140e-10 4.2816046e-05], sum to 1.0000
[2019-03-24 01:30:51,633] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9951
[2019-03-24 01:30:51,636] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.36666666666667, 91.66666666666667, 1.0, 2.0, 0.6353755947054823, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1439044.214327425, 1439044.214327426, 305866.7337892126], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2197200.0000, 
sim time next is 2197800.0000, 
raw observation next is [24.35, 92.0, 1.0, 2.0, 0.6730544462381607, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1482046.977806814, 1482046.977806814, 312402.1908312035], 
processed observation next is [1.0, 0.43478260869565216, 0.4574074074074075, 0.92, 1.0, 1.0, 0.610779102664477, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5293024920738622, 0.5293024920738622, 0.6007734439061605], 
reward next is 0.3992, 
noisyNet noise sample is [array([0.93500847], dtype=float32), 0.2499167]. 
=============================================
[2019-03-24 01:30:57,326] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.8099112e-04 2.7368503e-17 9.9951899e-01 5.6434495e-14 2.4223363e-08], sum to 1.0000
[2019-03-24 01:30:57,333] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6961
[2019-03-24 01:30:57,336] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.2, 68.33333333333333, 1.0, 2.0, 0.4794696517470782, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7668236841569721, 6.911199999999999, 6.9112, 121.9260426156618, 1124953.245241911, 1124953.245241911, 249224.2717155599], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2306400.0000, 
sim time next is 2307000.0000, 
raw observation next is [26.25, 67.66666666666667, 1.0, 2.0, 0.4719910396909519, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7551836003035743, 6.9112, 6.9112, 121.9260426156618, 1108980.292274289, 1108980.292274289, 246646.280538075], 
processed observation next is [1.0, 0.6956521739130435, 0.5277777777777778, 0.6766666666666667, 1.0, 1.0, 0.37141790439399036, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.693979500379468, 0.0, 0.0, 0.8094621288201359, 0.3960643900979604, 0.3960643900979604, 0.47431977026552885], 
reward next is 0.5257, 
noisyNet noise sample is [array([-1.3081453], dtype=float32), -0.71821386]. 
=============================================
[2019-03-24 01:30:57,347] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[42.241013]
 [42.18747 ]
 [42.154232]
 [42.133167]
 [41.973583]], R is [[42.33550262]
 [42.43286896]
 [42.51105881]
 [42.59225082]
 [42.66576767]].
[2019-03-24 01:31:00,591] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1028125e-02 3.9388681e-21 9.6897179e-01 1.5873027e-17 5.0786891e-10], sum to 1.0000
[2019-03-24 01:31:00,600] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9975
[2019-03-24 01:31:00,605] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.35, 40.5, 1.0, 2.0, 0.4151253968027109, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6849849567848236, 6.911199999999999, 6.9112, 121.9260426156618, 1023994.292834498, 1023994.292834499, 225478.8953198621], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2367000.0000, 
sim time next is 2367600.0000, 
raw observation next is [28.46666666666667, 40.33333333333333, 1.0, 2.0, 0.4422546921048847, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7287778665878771, 6.911199999999999, 6.9112, 121.9260426156618, 1089583.936606934, 1089583.936606935, 234171.4080270512], 
processed observation next is [1.0, 0.391304347826087, 0.6098765432098766, 0.40333333333333327, 1.0, 1.0, 0.3360174906010533, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6609723332348463, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.38913712021676217, 0.3891371202167625, 0.45032963082125227], 
reward next is 0.5497, 
noisyNet noise sample is [array([1.744889], dtype=float32), 0.85167074]. 
=============================================
[2019-03-24 01:31:01,628] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 63714: loss 0.0708
[2019-03-24 01:31:01,630] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 63715: learning rate 0.0000
[2019-03-24 01:31:01,787] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63799: loss 0.7248
[2019-03-24 01:31:01,791] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63799: learning rate 0.0000
[2019-03-24 01:31:01,832] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 63822: loss 0.7821
[2019-03-24 01:31:01,832] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 63822: learning rate 0.0000
[2019-03-24 01:31:01,965] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63895: loss 0.2435
[2019-03-24 01:31:01,969] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63895: learning rate 0.0000
[2019-03-24 01:31:01,979] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 63900: loss 0.1329
[2019-03-24 01:31:01,981] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 63902: learning rate 0.0000
[2019-03-24 01:31:01,996] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 63905: loss 0.1069
[2019-03-24 01:31:01,998] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 63906: learning rate 0.0000
[2019-03-24 01:31:02,057] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 63935: loss 0.2149
[2019-03-24 01:31:02,059] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 63935: learning rate 0.0000
[2019-03-24 01:31:02,110] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 63967: loss 0.1409
[2019-03-24 01:31:02,113] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 63967: learning rate 0.0000
[2019-03-24 01:31:02,120] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 63970: loss 0.1377
[2019-03-24 01:31:02,123] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 63972: learning rate 0.0000
[2019-03-24 01:31:02,201] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 64009: loss 0.2592
[2019-03-24 01:31:02,205] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 64010: learning rate 0.0000
[2019-03-24 01:31:02,212] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 64014: loss 0.2700
[2019-03-24 01:31:02,216] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 64014: learning rate 0.0000
[2019-03-24 01:31:02,316] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 64070: loss 0.3938
[2019-03-24 01:31:02,320] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 64071: learning rate 0.0000
[2019-03-24 01:31:02,401] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 64114: loss 0.3163
[2019-03-24 01:31:02,403] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 64114: learning rate 0.0000
[2019-03-24 01:31:02,464] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 64148: loss 1.0815
[2019-03-24 01:31:02,471] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 64148: learning rate 0.0000
[2019-03-24 01:31:02,490] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 64157: loss 0.8656
[2019-03-24 01:31:02,491] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 64157: learning rate 0.0000
[2019-03-24 01:31:02,910] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 64377: loss 3.1096
[2019-03-24 01:31:02,912] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 64377: learning rate 0.0000
[2019-03-24 01:31:05,819] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.91782267e-03 1.10848786e-16 9.90082204e-01 7.07445263e-15
 3.03960341e-08], sum to 1.0000
[2019-03-24 01:31:05,825] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7212
[2019-03-24 01:31:05,832] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [34.41666666666666, 23.0, 1.0, 2.0, 0.4625481236221591, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7576204134841372, 6.9112, 6.9112, 121.9260426156618, 1132522.19777751, 1132522.19777751, 241288.0325864406], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2466600.0000, 
sim time next is 2467200.0000, 
raw observation next is [34.53333333333333, 23.0, 1.0, 2.0, 0.6180239360395523, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9562616717803939, 6.9112, 6.9112, 121.9260426156618, 1469075.135373869, 1469075.135373869, 290691.3422023818], 
processed observation next is [1.0, 0.5652173913043478, 0.8345679012345678, 0.23, 1.0, 1.0, 0.5452665905232765, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9453270897254923, 0.0, 0.0, 0.8094621288201359, 0.5246696912049532, 0.5246696912049532, 0.5590218119276573], 
reward next is 0.4410, 
noisyNet noise sample is [array([0.00485274], dtype=float32), 0.16500159]. 
=============================================
[2019-03-24 01:31:16,068] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.4197321e-05 1.6929104e-19 9.9996579e-01 2.6456532e-18 1.2716572e-10], sum to 1.0000
[2019-03-24 01:31:16,075] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7006
[2019-03-24 01:31:16,078] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.2857511604964488, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4558459752608857, 6.911199999999999, 6.9112, 121.9260426156618, 663101.7677438912, 663101.7677438917, 191193.6693215168], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2670000.0000, 
sim time next is 2670600.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.2860212814811059, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4562742820062876, 6.911200000000001, 6.9112, 121.9260426156618, 663708.6495365291, 663708.6495365286, 191265.1621604471], 
processed observation next is [0.0, 0.9130434782608695, 0.4444444444444444, 0.89, 1.0, 1.0, 0.15002533509655464, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3203428525078595, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23703880340590325, 0.23703880340590308, 0.36781761953932135], 
reward next is 0.6322, 
noisyNet noise sample is [array([0.28093886], dtype=float32), -0.5939594]. 
=============================================
[2019-03-24 01:31:17,362] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 71731: loss 0.0107
[2019-03-24 01:31:17,364] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 71731: learning rate 0.0000
[2019-03-24 01:31:17,434] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 71769: loss 0.0118
[2019-03-24 01:31:17,435] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 71769: learning rate 0.0000
[2019-03-24 01:31:17,456] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 71781: loss 0.0013
[2019-03-24 01:31:17,458] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 71782: learning rate 0.0000
[2019-03-24 01:31:17,649] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 71876: loss 0.3687
[2019-03-24 01:31:17,651] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 71876: learning rate 0.0000
[2019-03-24 01:31:17,658] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71876: loss 0.4135
[2019-03-24 01:31:17,661] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71878: learning rate 0.0000
[2019-03-24 01:31:17,681] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 71886: loss 0.3872
[2019-03-24 01:31:17,684] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 71887: learning rate 0.0000
[2019-03-24 01:31:17,819] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 71958: loss 0.0008
[2019-03-24 01:31:17,820] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 71958: learning rate 0.0000
[2019-03-24 01:31:17,824] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 71959: loss 0.0198
[2019-03-24 01:31:17,825] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 71959: learning rate 0.0000
[2019-03-24 01:31:17,841] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 71966: loss 0.0568
[2019-03-24 01:31:17,841] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 71966: learning rate 0.0000
[2019-03-24 01:31:17,984] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 72038: loss 0.3168
[2019-03-24 01:31:17,987] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 72038: learning rate 0.0000
[2019-03-24 01:31:18,048] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 72066: loss 0.0265
[2019-03-24 01:31:18,053] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 72067: learning rate 0.0000
[2019-03-24 01:31:18,061] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 72070: loss 0.0006
[2019-03-24 01:31:18,064] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 72072: learning rate 0.0000
[2019-03-24 01:31:18,215] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 72150: loss 0.6082
[2019-03-24 01:31:18,216] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 72150: learning rate 0.0000
[2019-03-24 01:31:18,219] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 72151: loss 0.5271
[2019-03-24 01:31:18,222] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 72153: learning rate 0.0000
[2019-03-24 01:31:18,264] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 72170: loss 0.8736
[2019-03-24 01:31:18,265] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 72170: learning rate 0.0000
[2019-03-24 01:31:18,671] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 72371: loss 0.0710
[2019-03-24 01:31:18,673] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 72372: learning rate 0.0000
[2019-03-24 01:31:18,748] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1239398e-08 1.4138903e-28 1.0000000e+00 3.6183324e-25 5.6174632e-14], sum to 1.0000
[2019-03-24 01:31:18,753] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9403
[2019-03-24 01:31:18,762] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.9, 72.5, 1.0, 2.0, 0.2678741914000881, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4283688184653809, 6.9112, 6.9112, 121.9260426156618, 628056.3840254659, 628056.3840254659, 186332.6951939297], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2709000.0000, 
sim time next is 2709600.0000, 
raw observation next is [26.26666666666667, 70.33333333333334, 1.0, 2.0, 0.2682371035023406, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4289129410210607, 6.911199999999999, 6.9112, 121.9260426156618, 628720.6490832512, 628720.6490832517, 186432.9192338641], 
processed observation next is [0.0, 0.34782608695652173, 0.5283950617283951, 0.7033333333333335, 1.0, 1.0, 0.12885369464564356, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.28614117627632585, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22454308895830402, 0.2245430889583042, 0.3585248446805079], 
reward next is 0.6415, 
noisyNet noise sample is [array([-1.3329561], dtype=float32), -2.5560439]. 
=============================================
[2019-03-24 01:31:22,580] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9667921e-06 2.2029482e-23 9.9999809e-01 7.2751182e-24 5.8378210e-13], sum to 1.0000
[2019-03-24 01:31:22,585] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5606
[2019-03-24 01:31:22,750] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.3903015241827978, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6214068522293886, 6.911199999999999, 6.9112, 121.9260426156618, 890773.5502877118, 890773.5502877122, 221109.5828251719], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2776800.0000, 
sim time next is 2777400.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.3852135542532697, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6133191464347235, 6.911199999999999, 6.9112, 121.9260426156618, 879509.8819577914, 879509.8819577919, 219559.558640462], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.26811137411103536, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5166489330434043, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31411067212778265, 0.3141106721277828, 0.4222299204624269], 
reward next is 0.5778, 
noisyNet noise sample is [array([1.0969961], dtype=float32), 0.663998]. 
=============================================
[2019-03-24 01:31:24,188] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 01:31:24,189] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:31:24,190] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:31:24,194] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:31:24,195] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:31:24,195] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:31:24,195] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:31:24,197] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:31:24,198] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:31:24,199] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:31:24,199] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:31:24,211] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run4
[2019-03-24 01:31:24,234] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run4
[2019-03-24 01:31:24,235] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run4
[2019-03-24 01:31:24,236] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run4
[2019-03-24 01:31:24,314] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run4
[2019-03-24 01:31:29,161] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.04680787]
[2019-03-24 01:31:29,165] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.33333333333333, 21.0, 1.0, 2.0, 0.1765388488004303, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3063873545570782, 6.9112, 6.9112, 121.9260426156618, 449264.4604418041, 449264.4604418041, 159915.2169186196]
[2019-03-24 01:31:29,166] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:31:29,169] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3995540e-04 3.7644710e-09 9.9985969e-01 1.0569865e-09 3.4697368e-07], sampled 0.3942825144499633
[2019-03-24 01:31:50,942] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.04680787]
[2019-03-24 01:31:50,944] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.15270849, 79.120503595, 1.0, 2.0, 0.2368158627589976, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4010721338663102, 6.911199999999999, 6.9112, 121.9260426156618, 595353.6580086582, 595353.6580086587, 174801.2405995503]
[2019-03-24 01:31:50,945] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:31:50,947] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.9181129e-05 1.4013022e-09 9.9991071e-01 3.6579353e-10 1.6330674e-07], sampled 0.3748773160968678
[2019-03-24 01:32:38,404] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.04680787]
[2019-03-24 01:32:38,405] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.15501072, 76.98483404, 1.0, 2.0, 0.3269004778562982, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5204362071525263, 6.911199999999999, 6.9112, 121.9260426156618, 745122.5438415003, 745122.5438415008, 202616.9449877995]
[2019-03-24 01:32:38,406] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:32:38,410] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.5929347e-05 1.6515072e-09 9.9990380e-01 4.3730045e-10 1.8446153e-07], sampled 0.8782938959760634
[2019-03-24 01:33:03,256] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.04680787]
[2019-03-24 01:33:03,256] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.16048577, 78.860076175, 1.0, 2.0, 0.228062313528638, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3698921628766129, 6.911199999999999, 6.9112, 121.9260426156618, 551211.048763079, 551211.0487630795, 175428.2638816677]
[2019-03-24 01:33:03,260] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:33:03,263] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.8766144e-05 1.3910980e-09 9.9991107e-01 3.6390363e-10 1.6236525e-07], sampled 0.4086698239952775
[2019-03-24 01:33:10,165] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7490.8812 2565823305.4782 47.0000
[2019-03-24 01:33:10,707] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6580.1326 2661617822.9794 110.0000
[2019-03-24 01:33:10,774] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6809.7004 2600682207.8493 61.0000
[2019-03-24 01:33:10,779] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7162.1619 2623841565.5436 97.0000
[2019-03-24 01:33:10,819] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7155.8681 2831382229.6543 210.0000
[2019-03-24 01:33:11,832] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 75000, evaluation results [75000.0, 7155.868076850539, 2831382229.654263, 210.0, 6809.700411667892, 2600682207.849264, 61.0, 7490.881244521181, 2565823305.4781704, 47.0, 6580.132611052069, 2661617822.9794006, 110.0, 7162.161864516047, 2623841565.5436435, 97.0]
[2019-03-24 01:33:13,074] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0865878e-09 9.6541106e-22 1.0000000e+00 2.2128562e-24 7.7557745e-14], sum to 1.0000
[2019-03-24 01:33:13,078] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1824
[2019-03-24 01:33:13,266] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.91666666666667, 73.5, 1.0, 2.0, 0.3329842244695202, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5301217298945704, 6.911199999999999, 6.9112, 121.9260426156618, 758996.4331781871, 758996.4331781876, 204321.2022648339], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2844600.0000, 
sim time next is 2845200.0000, 
raw observation next is [27.83333333333334, 73.0, 1.0, 2.0, 0.3291252971647263, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5239781919488501, 6.9112, 6.9112, 121.9260426156618, 750196.1804763081, 750196.1804763081, 203236.7538728048], 
processed observation next is [1.0, 0.9565217391304348, 0.58641975308642, 0.73, 1.0, 1.0, 0.20133963948181707, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4049727399360626, 0.0, 0.0, 0.8094621288201359, 0.26792720731296715, 0.26792720731296715, 0.3908399112938554], 
reward next is 0.6092, 
noisyNet noise sample is [array([0.776097], dtype=float32), 1.0349976]. 
=============================================
[2019-03-24 01:33:20,060] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.2522008e-11 1.3039570e-23 1.0000000e+00 9.5399753e-27 1.1091737e-14], sum to 1.0000
[2019-03-24 01:33:20,070] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3640
[2019-03-24 01:33:20,079] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 2140067.73778287 W.
[2019-03-24 01:33:20,082] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.2, 82.0, 1.0, 2.0, 0.6253910395790888, 1.0, 2.0, 0.6253910395790888, 1.0, 2.0, 0.9956429025741348, 6.911200000000001, 6.9112, 121.94756008, 2140067.73778287, 2140067.737782869, 409383.3959831466], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2975400.0000, 
sim time next is 2976000.0000, 
raw observation next is [28.26666666666667, 81.33333333333333, 1.0, 2.0, 0.8737203936869856, 1.0, 2.0, 0.8737203936869856, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156496, 1993065.00884669, 1993065.00884669, 375159.4399308849], 
processed observation next is [1.0, 0.43478260869565216, 0.6024691358024692, 0.8133333333333332, 1.0, 1.0, 0.8496671353416495, 1.0, 1.0, 0.8496671353416495, 0.0, 0.5, -0.25, 0.0, 0.0, 0.809462128820055, 0.7118089317309607, 0.7118089317309607, 0.721460461405548], 
reward next is 0.2785, 
noisyNet noise sample is [array([-1.0566688], dtype=float32), 1.609699]. 
=============================================
[2019-03-24 01:33:20,096] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[51.002052]
 [51.453438]
 [51.959213]
 [52.110077]
 [52.237423]], R is [[49.8881073 ]
 [49.60194778]
 [49.33712387]
 [48.84375381]
 [48.66415787]].
[2019-03-24 01:33:21,035] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 79696: loss 2.4751
[2019-03-24 01:33:21,037] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 79697: learning rate 0.0000
[2019-03-24 01:33:21,269] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 79748: loss 2.7796
[2019-03-24 01:33:21,270] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 79749: learning rate 0.0000
[2019-03-24 01:33:21,435] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 79771: loss 2.1710
[2019-03-24 01:33:21,436] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 79772: learning rate 0.0000
[2019-03-24 01:33:21,583] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 79785: loss 2.2792
[2019-03-24 01:33:21,584] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 79785: learning rate 0.0000
[2019-03-24 01:33:21,788] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 79813: loss 2.1163
[2019-03-24 01:33:21,790] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 79813: learning rate 0.0000
[2019-03-24 01:33:22,010] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 79872: loss 1.7831
[2019-03-24 01:33:22,018] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 79872: learning rate 0.0000
[2019-03-24 01:33:22,174] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 79886: loss 2.3397
[2019-03-24 01:33:22,176] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 79886: learning rate 0.0000
[2019-03-24 01:33:22,180] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 79889: loss 2.2197
[2019-03-24 01:33:22,310] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 79889: learning rate 0.0000
[2019-03-24 01:33:22,545] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 79946: loss 2.2600
[2019-03-24 01:33:22,546] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 79946: learning rate 0.0000
[2019-03-24 01:33:22,773] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 80000: loss 1.5222
[2019-03-24 01:33:22,775] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 80000: learning rate 0.0000
[2019-03-24 01:33:23,071] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 80086: loss 2.1331
[2019-03-24 01:33:23,074] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 80088: learning rate 0.0000
[2019-03-24 01:33:23,271] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 80118: loss 2.0068
[2019-03-24 01:33:23,274] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 80119: learning rate 0.0000
[2019-03-24 01:33:23,422] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 80137: loss 1.3604
[2019-03-24 01:33:23,423] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 80137: learning rate 0.0000
[2019-03-24 01:33:23,779] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 80250: loss 1.7584
[2019-03-24 01:33:23,780] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 80250: loss 1.0951
[2019-03-24 01:33:23,782] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 80250: learning rate 0.0000
[2019-03-24 01:33:23,783] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 80250: learning rate 0.0000
[2019-03-24 01:33:24,170] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 80322: loss 1.6766
[2019-03-24 01:33:24,172] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 80322: learning rate 0.0000
[2019-03-24 01:33:25,355] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.5439376e-10 1.4661111e-24 1.0000000e+00 2.2399612e-28 6.0402317e-16], sum to 1.0000
[2019-03-24 01:33:25,363] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2180
[2019-03-24 01:33:25,366] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.95, 98.0, 1.0, 2.0, 0.3203927958387913, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5100757654402482, 6.911199999999999, 6.9112, 121.9260426156618, 730282.1543846015, 730282.154384602, 200804.9334447534], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3018600.0000, 
sim time next is 3019200.0000, 
raw observation next is [23.93333333333333, 97.33333333333334, 1.0, 2.0, 0.3171643766501132, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5049360169496002, 6.911199999999999, 6.9112, 121.9260426156618, 722920.0392548885, 722920.039254889, 199913.6515669889], 
processed observation next is [1.0, 0.9565217391304348, 0.4419753086419752, 0.9733333333333334, 1.0, 1.0, 0.18710044839299192, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3811700211870002, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25818572830531733, 0.2581857283053175, 0.38444932993651715], 
reward next is 0.6156, 
noisyNet noise sample is [array([-1.6763811], dtype=float32), 0.0631053]. 
=============================================
[2019-03-24 01:33:25,847] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.9496147e-11 2.6420189e-28 1.0000000e+00 3.9150107e-31 2.6161971e-18], sum to 1.0000
[2019-03-24 01:33:25,853] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2605
[2019-03-24 01:33:25,858] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.33333333333333, 100.0, 1.0, 2.0, 0.2750611650858382, 0.0, 2.0, 0.0, 1.0, 2.0, 0.439534351180514, 6.911199999999999, 6.9112, 121.9260426156618, 643149.7612290588, 643149.7612290593, 188244.4620529446], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3048000.0000, 
sim time next is 3048600.0000, 
raw observation next is [22.66666666666667, 100.0, 1.0, 2.0, 0.2795579254350141, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4460362841809698, 6.911199999999999, 6.9112, 121.9260426156618, 649257.364330415, 649257.3643304154, 189560.1129424098], 
processed observation next is [1.0, 0.2608695652173913, 0.39506172839506193, 1.0, 1.0, 1.0, 0.14233086361311206, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.30754535522621224, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23187763011800536, 0.2318776301180055, 0.36453867873540347], 
reward next is 0.6355, 
noisyNet noise sample is [array([0.81417537], dtype=float32), 0.23096287]. 
=============================================
[2019-03-24 01:33:26,184] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.00594824e-10 4.21914130e-24 1.00000000e+00 1.75353634e-29
 6.30427511e-16], sum to 1.0000
[2019-03-24 01:33:26,192] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1738
[2019-03-24 01:33:26,196] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.6, 91.0, 1.0, 2.0, 0.3918732828187326, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6238750286692527, 6.911199999999997, 6.9112, 121.9260426156618, 893304.995006082, 893304.9950060834, 221603.7460193086], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3052800.0000, 
sim time next is 3053400.0000, 
raw observation next is [25.0, 90.66666666666667, 1.0, 2.0, 0.4202901457447006, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6691155999200087, 6.911199999999999, 6.9112, 121.9260426156618, 958123.8926106669, 958123.8926106674, 230443.3855708878], 
processed observation next is [1.0, 0.34782608695652173, 0.48148148148148145, 0.9066666666666667, 1.0, 1.0, 0.30986922112464355, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5863944999000108, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3421871045038096, 0.3421871045038098, 0.44316035686709193], 
reward next is 0.5568, 
noisyNet noise sample is [array([1.1373967], dtype=float32), -0.25107402]. 
=============================================
[2019-03-24 01:33:27,848] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4583278e-05 4.1597576e-12 9.9997544e-01 1.5967513e-13 3.2095294e-08], sum to 1.0000
[2019-03-24 01:33:27,857] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1825
[2019-03-24 01:33:27,862] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.83333333333333, 85.66666666666667, 1.0, 2.0, 0.891350671212249, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1731211.217551272, 1731211.217551272, 355108.6640525584], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3084600.0000, 
sim time next is 3085200.0000, 
raw observation next is [28.2, 86.0, 1.0, 2.0, 0.9137657522710574, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999998, 6.9112, 121.9260426156618, 1756798.405688888, 1756798.405688889, 359961.289395317], 
processed observation next is [1.0, 0.7391304347826086, 0.6, 0.86, 1.0, 1.0, 0.8973401812750683, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.6274280020317456, 0.6274280020317461, 0.6922332488371481], 
reward next is 0.3078, 
noisyNet noise sample is [array([1.2575111], dtype=float32), -1.6572952]. 
=============================================
[2019-03-24 01:33:27,990] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2651389e-05 4.5292960e-13 9.9998736e-01 2.8965742e-15 1.9947178e-08], sum to 1.0000
[2019-03-24 01:33:28,003] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9564
[2019-03-24 01:33:28,005] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.46666666666667, 85.33333333333333, 1.0, 2.0, 0.8273105724780504, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1658112.416688028, 1658112.416688028, 341726.1236244095], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3084000.0000, 
sim time next is 3084600.0000, 
raw observation next is [27.83333333333333, 85.66666666666667, 1.0, 2.0, 0.891350671212249, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1731211.217551272, 1731211.217551272, 355108.664052975], 
processed observation next is [1.0, 0.6956521739130435, 0.5864197530864196, 0.8566666666666667, 1.0, 1.0, 0.8706555609669631, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6182897205540256, 0.6182897205540256, 0.682901277024952], 
reward next is 0.3171, 
noisyNet noise sample is [array([1.8587159], dtype=float32), -0.47259158]. 
=============================================
[2019-03-24 01:33:28,748] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.4458426e-12 1.2183012e-28 1.0000000e+00 2.2312674e-31 3.5323123e-20], sum to 1.0000
[2019-03-24 01:33:28,756] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8848
[2019-03-24 01:33:28,761] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 83.0, 1.0, 2.0, 0.3508897521063808, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5586279130347764, 6.9112, 6.9112, 121.9260426156618, 799831.1671277479, 799831.1671277479, 209430.8658383353], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3096000.0000, 
sim time next is 3096600.0000, 
raw observation next is [27.33333333333333, 80.16666666666667, 1.0, 2.0, 0.3477978216861221, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5537054591085807, 6.911199999999999, 6.9112, 121.9260426156618, 792779.6609605873, 792779.6609605878, 208539.2870472076], 
processed observation next is [1.0, 0.8695652173913043, 0.5679012345679011, 0.8016666666666667, 1.0, 1.0, 0.22356883534062155, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44213182388572586, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28313559320020976, 0.2831355932002099, 0.4010370904753992], 
reward next is 0.5990, 
noisyNet noise sample is [array([0.6866939], dtype=float32), 0.14122847]. 
=============================================
[2019-03-24 01:33:30,064] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.6756470e-12 7.9969532e-28 1.0000000e+00 2.8324686e-31 4.0728848e-20], sum to 1.0000
[2019-03-24 01:33:30,073] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5550
[2019-03-24 01:33:30,077] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.06666666666667, 58.33333333333334, 1.0, 2.0, 0.2835717116896513, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4569654255378146, 6.911199999999999, 6.9112, 121.9260426156618, 677975.6455174594, 677975.6455174598, 189731.3823193464], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3126000.0000, 
sim time next is 3126600.0000, 
raw observation next is [27.1, 56.5, 1.0, 2.0, 0.2732141038934991, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4415543213366481, 6.9112, 6.9112, 121.9260426156618, 656668.9363478116, 656668.9363478116, 186830.9930825688], 
processed observation next is [1.0, 0.17391304347826086, 0.5592592592592593, 0.565, 1.0, 1.0, 0.13477869511130844, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3019429016708101, 0.0, 0.0, 0.8094621288201359, 0.23452462012421843, 0.23452462012421843, 0.3592903713126323], 
reward next is 0.6407, 
noisyNet noise sample is [array([0.85151035], dtype=float32), 0.021389103]. 
=============================================
[2019-03-24 01:33:33,005] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4117287e-10 2.4187144e-22 1.0000000e+00 1.3135569e-24 2.9614555e-17], sum to 1.0000
[2019-03-24 01:33:33,014] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9954
[2019-03-24 01:33:33,185] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.16666666666666, 76.16666666666667, 1.0, 2.0, 0.3130350027325569, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4983619191885308, 6.911199999999999, 6.9112, 121.9260426156618, 713503.4822012775, 713503.482201278, 198780.6762511596], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3192600.0000, 
sim time next is 3193200.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.3216778626318957, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5121216336265743, 6.911199999999999, 6.9112, 121.9260426156618, 733212.6515237777, 733212.6515237781, 201161.8051272096], 
processed observation next is [1.0, 1.0, 0.5555555555555556, 0.79, 1.0, 1.0, 0.192473645990352, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3901520420332178, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26186166125849203, 0.2618616612584922, 0.38684962524463384], 
reward next is 0.6132, 
noisyNet noise sample is [array([-1.84751], dtype=float32), -0.7714939]. 
=============================================
[2019-03-24 01:33:38,724] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 87702: loss 0.2059
[2019-03-24 01:33:38,725] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 87702: learning rate 0.0000
[2019-03-24 01:33:38,766] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 87722: loss 0.1816
[2019-03-24 01:33:38,770] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 87723: learning rate 0.0000
[2019-03-24 01:33:38,811] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.4978605e-15 8.1945463e-32 1.0000000e+00 8.0519198e-38 1.4854437e-23], sum to 1.0000
[2019-03-24 01:33:38,820] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9706
[2019-03-24 01:33:38,825] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.7, 93.0, 1.0, 2.0, 0.2405625986707818, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3885152762112188, 6.911199999999999, 6.9112, 121.9260426156618, 577467.5769175891, 577467.5769175894, 178737.1796446478], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3301200.0000, 
sim time next is 3301800.0000, 
raw observation next is [21.75, 94.16666666666666, 1.0, 2.0, 0.2428543679843508, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3917161876117355, 6.911199999999999, 6.9112, 121.9260426156618, 581624.7681032997, 581624.7681033, 179390.4456033226], 
processed observation next is [0.0, 0.21739130434782608, 0.3611111111111111, 0.9416666666666665, 1.0, 1.0, 0.0986361523623224, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.23964523451466935, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20772313146546417, 0.20772313146546428, 0.34498162616023575], 
reward next is 0.6550, 
noisyNet noise sample is [array([-1.3216773], dtype=float32), -1.9747959]. 
=============================================
[2019-03-24 01:33:38,902] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 87793: loss 0.0392
[2019-03-24 01:33:38,908] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 87793: learning rate 0.0000
[2019-03-24 01:33:38,926] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 87804: loss 0.0305
[2019-03-24 01:33:38,929] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 87804: learning rate 0.0000
[2019-03-24 01:33:39,072] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 87882: loss 0.1797
[2019-03-24 01:33:39,074] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 87883: learning rate 0.0000
[2019-03-24 01:33:39,126] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 87907: loss 0.1845
[2019-03-24 01:33:39,130] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 87907: learning rate 0.0000
[2019-03-24 01:33:39,207] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87951: loss 0.0087
[2019-03-24 01:33:39,210] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 87951: learning rate 0.0000
[2019-03-24 01:33:39,270] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 87980: loss 0.0166
[2019-03-24 01:33:39,271] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 87980: learning rate 0.0000
[2019-03-24 01:33:39,339] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 88018: loss 0.2264
[2019-03-24 01:33:39,345] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 88021: learning rate 0.0000
[2019-03-24 01:33:39,385] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 88042: loss 0.4402
[2019-03-24 01:33:39,386] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 88042: learning rate 0.0000
[2019-03-24 01:33:39,490] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 88099: loss 0.3558
[2019-03-24 01:33:39,491] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 88099: loss 0.2369
[2019-03-24 01:33:39,496] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 88101: learning rate 0.0000
[2019-03-24 01:33:39,498] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 88101: learning rate 0.0000
[2019-03-24 01:33:39,533] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 88120: loss 0.0094
[2019-03-24 01:33:39,534] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 88120: learning rate 0.0000
[2019-03-24 01:33:39,594] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 88149: loss 0.0144
[2019-03-24 01:33:39,595] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 88149: learning rate 0.0000
[2019-03-24 01:33:39,723] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 88218: loss 0.2003
[2019-03-24 01:33:39,725] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 88218: learning rate 0.0000
[2019-03-24 01:33:39,853] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 88283: loss 0.0193
[2019-03-24 01:33:39,855] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 88283: learning rate 0.0000
[2019-03-24 01:33:42,049] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.152852e-11 9.179534e-22 1.000000e+00 1.208724e-27 8.025817e-17], sum to 1.0000
[2019-03-24 01:33:42,055] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4837
[2019-03-24 01:33:42,228] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.83333333333334, 79.83333333333334, 1.0, 2.0, 0.3344432789480811, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5324445921425264, 6.911199999999999, 6.9112, 121.9260426156618, 762323.8215114798, 762323.8215114803, 204732.4410049864], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3354600.0000, 
sim time next is 3355200.0000, 
raw observation next is [26.8, 79.0, 1.0, 2.0, 0.3298072488149259, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5250638811855827, 6.911199999999999, 6.9112, 121.9260426156618, 751751.3583836444, 751751.3583836448, 203427.7041982799], 
processed observation next is [0.0, 0.8695652173913043, 0.5481481481481482, 0.79, 1.0, 1.0, 0.2021514866844356, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4063298514819783, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26848262799415873, 0.2684826279941589, 0.3912071234582306], 
reward next is 0.6088, 
noisyNet noise sample is [array([-0.5226458], dtype=float32), 0.38282433]. 
=============================================
[2019-03-24 01:33:42,510] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8687315e-14 7.9905818e-35 1.0000000e+00 0.0000000e+00 3.2726248e-23], sum to 1.0000
[2019-03-24 01:33:42,517] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1358
[2019-03-24 01:33:42,524] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.3465213826449864, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5516733265843753, 6.9112, 6.9112, 121.9260426156618, 789868.6125046582, 789868.6125046582, 208172.9522856677], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3360000.0000, 
sim time next is 3360600.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.3475461298828265, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5533047575607044, 6.911199999999999, 6.9112, 121.9260426156618, 792205.6514476116, 792205.6514476121, 208467.2519436022], 
processed observation next is [0.0, 0.9130434782608695, 0.5370370370370371, 0.865, 1.0, 1.0, 0.22326920224146013, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44163094695088045, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28293058980271846, 0.2829305898027186, 0.40089856143000424], 
reward next is 0.5991, 
noisyNet noise sample is [array([2.2193172], dtype=float32), 0.70685834]. 
=============================================
[2019-03-24 01:33:42,651] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0790668e-13 5.0625635e-28 1.0000000e+00 1.0584555e-33 5.0841606e-21], sum to 1.0000
[2019-03-24 01:33:42,659] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4634
[2019-03-24 01:33:42,663] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.93333333333334, 82.33333333333334, 1.0, 2.0, 0.341843662922623, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5442262444436771, 6.9112, 6.9112, 121.9260426156618, 779200.6936159167, 779200.6936159167, 206833.5677616027], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3357600.0000, 
sim time next is 3358200.0000, 
raw observation next is [26.96666666666667, 83.16666666666666, 1.0, 2.0, 0.3464277002404568, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5515241811453414, 6.911199999999999, 6.9112, 121.9260426156618, 789654.9607325121, 789654.9607325125, 208145.8207877244], 
processed observation next is [0.0, 0.8695652173913043, 0.554320987654321, 0.8316666666666666, 1.0, 1.0, 0.22193773838149622, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43940522643167673, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28201962883304005, 0.2820196288330402, 0.4002804245917777], 
reward next is 0.5997, 
noisyNet noise sample is [array([0.5752623], dtype=float32), -0.082014516]. 
=============================================
[2019-03-24 01:33:42,786] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.7351511e-12 6.1657036e-26 1.0000000e+00 2.6458892e-30 1.2525429e-19], sum to 1.0000
[2019-03-24 01:33:42,792] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2636
[2019-03-24 01:33:42,797] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.3451265512793383, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5494527096237773, 6.911199999999999, 6.9112, 121.9260426156618, 786687.5710085721, 786687.5710085726, 207772.2705305972], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3362400.0000, 
sim time next is 3363000.0000, 
raw observation next is [25.86666666666667, 88.16666666666667, 1.0, 2.0, 0.3345970706407348, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5326894335258768, 6.911199999999999, 6.9112, 121.9260426156618, 762674.5458464256, 762674.545846426, 204776.5314279155], 
processed observation next is [0.0, 0.9565217391304348, 0.5135802469135804, 0.8816666666666667, 1.0, 1.0, 0.2078536555246843, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.415861791907346, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2723837663737234, 0.2723837663737236, 0.3938010219767606], 
reward next is 0.6062, 
noisyNet noise sample is [array([0.9207443], dtype=float32), -0.78621906]. 
=============================================
[2019-03-24 01:33:42,810] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[55.39146 ]
 [55.36158 ]
 [55.34856 ]
 [55.338146]
 [55.332985]], R is [[55.49282837]
 [55.53833771]
 [55.58282089]
 [55.62638474]
 [55.66922379]].
[2019-03-24 01:33:44,714] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.2094671e-09 3.6946384e-19 1.0000000e+00 1.9249066e-21 9.4392037e-14], sum to 1.0000
[2019-03-24 01:33:44,724] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8622
[2019-03-24 01:33:44,733] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 2117589.629891815 W.
[2019-03-24 01:33:44,737] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.5, 61.66666666666666, 1.0, 2.0, 0.9282448821573245, 1.0, 2.0, 0.9282448821573245, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2117589.629891815, 2117589.629891816, 399596.7560495292], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3411600.0000, 
sim time next is 3412200.0000, 
raw observation next is [30.75, 60.33333333333334, 1.0, 2.0, 0.9439182564199673, 1.0, 2.0, 0.9439182564199673, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2153388.153930565, 2153388.153930566, 406812.3157878286], 
processed observation next is [1.0, 0.4782608695652174, 0.6944444444444444, 0.6033333333333334, 1.0, 1.0, 0.9332360195475801, 1.0, 1.0, 0.9332360195475801, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7690671978323446, 0.7690671978323449, 0.782331376515055], 
reward next is 0.2177, 
noisyNet noise sample is [array([0.9300891], dtype=float32), 0.11065233]. 
=============================================
[2019-03-24 01:33:46,623] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7719929e-09 9.4656236e-20 1.0000000e+00 1.0273959e-22 5.7573693e-15], sum to 1.0000
[2019-03-24 01:33:46,630] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2235
[2019-03-24 01:33:46,635] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.3445439240072851, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5485251480318232, 6.9112, 6.9112, 121.9260426156618, 785358.8397206649, 785358.8397206649, 207605.3705911011], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3447000.0000, 
sim time next is 3447600.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.3452685439489543, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5496787665781846, 6.911199999999999, 6.9112, 121.9260426156618, 787011.3977760593, 787011.3977760598, 207812.9552809816], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.89, 1.0, 1.0, 0.22055779041542178, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4370984582227307, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2810754992057355, 0.28107549920573566, 0.39964029861727235], 
reward next is 0.6004, 
noisyNet noise sample is [array([0.61027503], dtype=float32), 0.6784055]. 
=============================================
[2019-03-24 01:33:52,894] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7205144e-07 3.0007392e-20 9.9999952e-01 7.5470234e-20 3.7211981e-07], sum to 1.0000
[2019-03-24 01:33:52,903] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3251
[2019-03-24 01:33:52,905] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.2, 76.0, 1.0, 2.0, 0.2273603831910927, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3700256650788971, 6.911199999999999, 6.9112, 121.9260426156618, 552176.2378203196, 552176.2378203201, 175023.3446601448], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3560400.0000, 
sim time next is 3561000.0000, 
raw observation next is [23.16666666666666, 78.16666666666667, 1.0, 2.0, 0.2524877726088125, 0.0, 2.0, 0.0, 1.0, 2.0, 0.410109615842097, 6.911199999999999, 6.9112, 121.9260426156618, 611570.4708657942, 611570.4708657947, 181246.2584404522], 
processed observation next is [1.0, 0.21739130434782608, 0.41358024691358003, 0.7816666666666667, 1.0, 1.0, 0.11010449120096726, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.2626370198026212, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21841802530921223, 0.2184180253092124, 0.3485504970008696], 
reward next is 0.6514, 
noisyNet noise sample is [array([0.51268506], dtype=float32), -0.6857412]. 
=============================================
[2019-03-24 01:33:52,917] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[58.765083]
 [58.74404 ]
 [58.692608]
 [58.596558]
 [58.46579 ]], R is [[58.8209343 ]
 [58.89614487]
 [58.96854019]
 [59.03538895]
 [59.09698868]].
[2019-03-24 01:33:54,903] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 95715: loss 0.0458
[2019-03-24 01:33:54,908] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 95715: learning rate 0.0000
[2019-03-24 01:33:54,975] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 95747: loss 0.0164
[2019-03-24 01:33:54,977] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 95747: learning rate 0.0000
[2019-03-24 01:33:55,052] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 95789: loss 0.0027
[2019-03-24 01:33:55,054] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 95789: learning rate 0.0000
[2019-03-24 01:33:55,103] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 95806: loss 0.0080
[2019-03-24 01:33:55,106] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 95807: learning rate 0.0000
[2019-03-24 01:33:55,241] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 95875: loss 0.0072
[2019-03-24 01:33:55,242] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 95877: learning rate 0.0000
[2019-03-24 01:33:55,347] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 95927: loss 0.0734
[2019-03-24 01:33:55,352] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 95929: learning rate 0.0000
[2019-03-24 01:33:55,399] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 95953: loss 0.1859
[2019-03-24 01:33:55,401] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 95954: learning rate 0.0000
[2019-03-24 01:33:55,445] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 95971: loss 0.0587
[2019-03-24 01:33:55,448] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 95974: learning rate 0.0000
[2019-03-24 01:33:55,451] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 95976: loss 0.0559
[2019-03-24 01:33:55,453] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 95977: learning rate 0.0000
[2019-03-24 01:33:55,552] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 96027: loss 0.0345
[2019-03-24 01:33:55,564] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 96027: learning rate 0.0000
[2019-03-24 01:33:55,666] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 96084: loss 0.0415
[2019-03-24 01:33:55,668] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 96084: learning rate 0.0000
[2019-03-24 01:33:55,692] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1629315e-06 6.0874081e-17 9.9999857e-01 6.7980147e-18 2.8716443e-07], sum to 1.0000
[2019-03-24 01:33:55,700] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1662
[2019-03-24 01:33:55,704] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.75, 78.83333333333333, 1.0, 2.0, 0.2650764024573428, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4241816333573871, 6.911199999999999, 6.9112, 121.9260426156618, 622910.5811059331, 622910.5811059335, 185560.4064840777], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3613800.0000, 
sim time next is 3614400.0000, 
raw observation next is [24.7, 78.0, 1.0, 2.0, 0.2624118013203828, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4203548531954088, 6.911200000000001, 6.9112, 121.9260426156618, 618619.3433118764, 618619.343311876, 184795.2505890029], 
processed observation next is [1.0, 0.8695652173913043, 0.4703703703703703, 0.78, 1.0, 1.0, 0.12191881109569379, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.27544356649426094, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22093547975424158, 0.2209354797542414, 0.3553754819019287], 
reward next is 0.6446, 
noisyNet noise sample is [array([1.7232285], dtype=float32), 0.7725836]. 
=============================================
[2019-03-24 01:33:55,752] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 96124: loss 0.1319
[2019-03-24 01:33:55,754] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 96124: learning rate 0.0000
[2019-03-24 01:33:55,844] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 96170: loss 0.1754
[2019-03-24 01:33:55,845] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 96170: learning rate 0.0000
[2019-03-24 01:33:55,852] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 96172: loss 0.1876
[2019-03-24 01:33:55,854] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 96174: learning rate 0.0000
[2019-03-24 01:33:55,888] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 96190: loss 0.1945
[2019-03-24 01:33:55,889] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 96190: learning rate 0.0000
[2019-03-24 01:33:56,113] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 96297: loss 0.5518
[2019-03-24 01:33:56,115] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 96297: learning rate 0.0000
[2019-03-24 01:34:03,625] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 01:34:03,627] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:34:03,628] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:34:03,628] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:34:03,628] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:34:03,629] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:34:03,629] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:34:03,632] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:34:03,630] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:34:03,632] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:34:03,633] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:34:03,646] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run5
[2019-03-24 01:34:03,670] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run5
[2019-03-24 01:34:03,671] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run5
[2019-03-24 01:34:03,693] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run5
[2019-03-24 01:34:03,753] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run5
[2019-03-24 01:35:04,812] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.05642373]
[2019-03-24 01:35:04,813] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.88722978, 68.96441566, 1.0, 2.0, 0.8950744402620292, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1735461.911140452, 1735461.911140452, 355912.0985403204]
[2019-03-24 01:35:04,815] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:35:04,819] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1855684e-02 3.1111128e-11 9.4776851e-01 7.3914434e-12 4.0375732e-02], sampled 0.9469733398839307
[2019-03-24 01:35:30,458] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.05642373]
[2019-03-24 01:35:30,459] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.242595898749422, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3902443216696357, 6.9112, 6.9112, 121.9260426156618, 577876.5136624672, 577876.5136624672, 179533.1954559023]
[2019-03-24 01:35:30,460] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:35:30,463] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.4061036e-03 4.2109246e-12 9.5994359e-01 8.7638366e-13 3.1650282e-02], sampled 0.33337569297610026
[2019-03-24 01:35:31,065] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.05642373]
[2019-03-24 01:35:31,067] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.34081565666666, 77.83066343333333, 1.0, 2.0, 0.2896807072606971, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4614522682905633, 6.9112, 6.9112, 121.9260426156618, 665611.7477142547, 665611.7477142547, 192398.7541021025]
[2019-03-24 01:35:31,068] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:35:31,072] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.0950895e-03 6.6121583e-12 9.5741546e-01 1.4174177e-12 3.3489421e-02], sampled 0.0498285123511607
[2019-03-24 01:35:49,056] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6240.1541 2668725163.8492 116.0000
[2019-03-24 01:35:49,105] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 6770.5691 2630974878.9179 100.0000
[2019-03-24 01:35:49,191] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6450.0013 2607555722.9520 68.0000
[2019-03-24 01:35:49,194] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 6744.1552 2838503653.2092 219.0000
[2019-03-24 01:35:49,343] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7079.6689 2573234140.7380 58.0000
[2019-03-24 01:35:50,358] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 100000, evaluation results [100000.0, 6744.155205805775, 2838503653.209216, 219.0, 6450.001294179599, 2607555722.9520454, 68.0, 7079.66886951702, 2573234140.7380357, 58.0, 6240.154137570745, 2668725163.849227, 116.0, 6770.569106283754, 2630974878.9179125, 100.0]
[2019-03-24 01:35:53,402] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3214175e-03 2.1512423e-12 1.9047625e-03 3.1508238e-12 9.9277377e-01], sum to 1.0000
[2019-03-24 01:35:53,411] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4016
[2019-03-24 01:35:53,419] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.5, 79.0, 1.0, 2.0, 0.2098598733385951, 1.0, 2.0, 0.2098598733385951, 1.0, 2.0, 0.3341037530139657, 6.911199999999999, 6.9112, 121.94756008, 717505.0427589874, 717505.0427589879, 223842.4070421509], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3803400.0000, 
sim time next is 3804000.0000, 
raw observation next is [26.33333333333334, 80.66666666666667, 1.0, 2.0, 0.2109181734835759, 1.0, 2.0, 0.2109181734835759, 1.0, 2.0, 0.3357886013112046, 6.911199999999999, 6.9112, 121.94756008, 721125.0430012913, 721125.0430012918, 224194.232956607], 
processed observation next is [0.0, 0.0, 0.5308641975308644, 0.8066666666666668, 1.0, 1.0, 0.060616873194733197, 1.0, 1.0, 0.060616873194733197, 1.0, 1.0, 0.1697357516390057, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2575446582147469, 0.2575446582147471, 0.4311427556857827], 
reward next is 0.5689, 
noisyNet noise sample is [array([0.56181085], dtype=float32), 1.1543291]. 
=============================================
[2019-03-24 01:35:53,444] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[43.251263]
 [43.51622 ]
 [43.83989 ]
 [44.500034]
 [44.914227]], R is [[43.31908035]
 [43.45542526]
 [43.59069824]
 [43.72452164]
 [43.85615921]].
[2019-03-24 01:35:55,755] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4886167e-04 2.1513689e-16 7.2265640e-05 5.3773657e-19 9.9967885e-01], sum to 1.0000
[2019-03-24 01:35:55,762] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0277
[2019-03-24 01:35:55,769] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.06666666666667, 52.66666666666667, 1.0, 2.0, 0.2367919588264403, 1.0, 2.0, 0.2367919588264403, 1.0, 2.0, 0.3769805102274049, 6.9112, 6.9112, 121.94756008, 809633.7117668595, 809633.7117668595, 232990.7283384796], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3850800.0000, 
sim time next is 3851400.0000, 
raw observation next is [33.08333333333334, 51.83333333333333, 1.0, 2.0, 0.2344090119999045, 1.0, 2.0, 0.2344090119999045, 1.0, 2.0, 0.3731867812723998, 6.911199999999999, 6.9112, 121.94756008, 801481.7346775281, 801481.7346775286, 232164.9303283062], 
processed observation next is [0.0, 0.5652173913043478, 0.7808641975308646, 0.5183333333333333, 1.0, 1.0, 0.08858215714274344, 1.0, 1.0, 0.08858215714274344, 1.0, 1.0, 0.2164834765904997, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2862434766705458, 0.28624347667054595, 0.4464710198621273], 
reward next is 0.5535, 
noisyNet noise sample is [array([-0.8057865], dtype=float32), 0.7521093]. 
=============================================
[2019-03-24 01:35:57,599] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 103731: loss 0.0121
[2019-03-24 01:35:57,603] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 103731: learning rate 0.0000
[2019-03-24 01:35:57,683] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 103773: loss 0.0156
[2019-03-24 01:35:57,690] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 103774: learning rate 0.0000
[2019-03-24 01:35:57,704] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 103783: loss 0.0045
[2019-03-24 01:35:57,708] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 103783: learning rate 0.0000
[2019-03-24 01:35:57,821] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 103840: loss 0.0120
[2019-03-24 01:35:57,823] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 103840: learning rate 0.0000
[2019-03-24 01:35:57,920] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 103896: loss 0.0863
[2019-03-24 01:35:57,924] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 103896: learning rate 0.0000
[2019-03-24 01:35:57,942] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103905: loss 0.0588
[2019-03-24 01:35:57,942] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 103905: learning rate 0.0000
[2019-03-24 01:35:58,018] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 103944: loss 0.0355
[2019-03-24 01:35:58,020] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 103946: learning rate 0.0000
[2019-03-24 01:35:58,076] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 103976: loss 0.0026
[2019-03-24 01:35:58,079] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 103977: learning rate 0.0000
[2019-03-24 01:35:58,084] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 103981: loss 0.0031
[2019-03-24 01:35:58,085] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 103981: learning rate 0.0000
[2019-03-24 01:35:58,170] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 104025: loss 0.0138
[2019-03-24 01:35:58,171] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 104025: learning rate 0.0000
[2019-03-24 01:35:58,218] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 104050: loss 0.0754
[2019-03-24 01:35:58,219] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 104050: learning rate 0.0000
[2019-03-24 01:35:58,273] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 104075: loss 0.1246
[2019-03-24 01:35:58,274] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 104075: learning rate 0.0000
[2019-03-24 01:35:58,363] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 104126: loss 0.0356
[2019-03-24 01:35:58,366] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 104126: learning rate 0.0000
[2019-03-24 01:35:58,470] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 104176: loss 0.0181
[2019-03-24 01:35:58,472] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 104176: learning rate 0.0000
[2019-03-24 01:35:58,499] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 104194: loss 0.0383
[2019-03-24 01:35:58,502] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 104195: learning rate 0.0000
[2019-03-24 01:35:58,651] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3256726e-04 2.6598029e-17 3.6433647e-07 1.6569993e-17 9.9986708e-01], sum to 1.0000
[2019-03-24 01:35:58,663] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4236
[2019-03-24 01:35:58,667] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.245524939641822, 1.0, 2.0, 0.245524939641822, 1.0, 2.0, 0.3908837000988218, 6.911200000000001, 6.9112, 121.94756008, 839509.6722835446, 839509.6722835441, 236044.2241842669], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3902400.0000, 
sim time next is 3903000.0000, 
raw observation next is [25.85, 94.33333333333334, 1.0, 2.0, 0.2435558039976066, 1.0, 2.0, 0.2435558039976066, 1.0, 2.0, 0.3877487720229601, 6.911200000000001, 6.9112, 121.94756008, 832773.0599058905, 832773.05990589, 235351.9926375362], 
processed observation next is [0.0, 0.17391304347826086, 0.5129629629629631, 0.9433333333333335, 1.0, 1.0, 0.09947119523524595, 1.0, 1.0, 0.09947119523524595, 1.0, 1.0, 0.2346859650287001, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.29741894996638946, 0.2974189499663893, 0.45259998584141575], 
reward next is 0.5474, 
noisyNet noise sample is [array([-0.23398583], dtype=float32), -1.3800547]. 
=============================================
[2019-03-24 01:35:58,689] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[54.19819 ]
 [54.211468]
 [54.263298]
 [54.351036]
 [54.317284]], R is [[54.1270256 ]
 [54.13182449]
 [54.135746  ]
 [54.13885498]
 [54.1413269 ]].
[2019-03-24 01:35:58,914] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 104404: loss 0.0761
[2019-03-24 01:35:58,917] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 104404: learning rate 0.0000
[2019-03-24 01:36:02,538] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.8541524e-05 9.4262712e-14 2.0084307e-03 4.9128910e-14 9.9789304e-01], sum to 1.0000
[2019-03-24 01:36:02,548] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2138
[2019-03-24 01:36:02,554] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.7, 86.33333333333334, 1.0, 2.0, 0.2207090137125845, 1.0, 2.0, 0.2207090137125845, 1.0, 2.0, 0.3513759378211914, 6.9112, 6.9112, 121.94756008, 754616.205200631, 754616.205200631, 227478.8598804436], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3979200.0000, 
sim time next is 3979800.0000, 
raw observation next is [25.65, 86.5, 1.0, 2.0, 0.2202490472422888, 1.0, 2.0, 0.2202490472422888, 1.0, 2.0, 0.3506436562204185, 6.9112, 6.9112, 121.94756008, 753042.7822899865, 753042.7822899865, 227323.3499958954], 
processed observation next is [1.0, 0.043478260869565216, 0.5055555555555555, 0.865, 1.0, 1.0, 0.07172505624082, 1.0, 1.0, 0.07172505624082, 1.0, 1.0, 0.18830457027552308, 0.0, 0.0, 0.8096049824067558, 0.2689438508178523, 0.2689438508178523, 0.437160288453645], 
reward next is 0.5628, 
noisyNet noise sample is [array([0.5733256], dtype=float32), -0.82599646]. 
=============================================
[2019-03-24 01:36:05,518] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.2159041e-05 2.3536352e-17 3.5269746e-05 3.9722862e-16 9.9993253e-01], sum to 1.0000
[2019-03-24 01:36:05,527] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8007
[2019-03-24 01:36:05,531] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.53333333333333, 87.0, 1.0, 2.0, 0.2173633423501757, 1.0, 2.0, 0.2173633423501757, 1.0, 2.0, 0.3460495200513272, 6.9112, 6.9112, 121.94756008, 743171.6273370413, 743171.6273370413, 226350.4234757026], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4045200.0000, 
sim time next is 4045800.0000, 
raw observation next is [25.41666666666667, 86.5, 1.0, 2.0, 0.2143052583966325, 1.0, 2.0, 0.2143052583966325, 1.0, 2.0, 0.3411809508024453, 6.9112, 6.9112, 121.94756008, 732710.9525888235, 732710.9525888235, 225324.4630529651], 
processed observation next is [1.0, 0.8260869565217391, 0.49691358024691373, 0.865, 1.0, 1.0, 0.06464911713884822, 1.0, 1.0, 0.06464911713884822, 1.0, 1.0, 0.17647618850305663, 0.0, 0.0, 0.8096049824067558, 0.26168248306743697, 0.26168248306743697, 0.43331627510185594], 
reward next is 0.5667, 
noisyNet noise sample is [array([0.38428468], dtype=float32), -0.3493137]. 
=============================================
[2019-03-24 01:36:10,896] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [0.42876807 0.00127698 0.30845618 0.00126344 0.26023537], sum to 1.0000
[2019-03-24 01:36:10,905] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3238
[2019-03-24 01:36:10,912] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.2, 95.5, 1.0, 2.0, 0.16, 1.0, 1.0, 0.16, 1.0, 2.0, 0.2516906268777672, 6.911199999999999, 6.9112, 121.94756008, 560592.3512786715, 560592.351278672, 205488.572847347], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4141800.0000, 
sim time next is 4142400.0000, 
raw observation next is [21.26666666666667, 96.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.758027476059242, 6.911199999999999, 6.9112, 121.9260426156618, 564556.7435535252, 564556.7435535257, 154298.6777856018], 
processed observation next is [1.0, 0.9565217391304348, 0.34320987654320995, 0.96, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.6975343450740525, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20162740841197327, 0.20162740841197344, 0.2967282265107727], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.49389648], dtype=float32), 0.31185782]. 
=============================================
[2019-03-24 01:36:13,071] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 111733: loss -74.7427
[2019-03-24 01:36:13,074] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 111733: learning rate 0.0000
[2019-03-24 01:36:13,076] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 111733: loss -168.2874
[2019-03-24 01:36:13,078] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 111733: learning rate 0.0000
[2019-03-24 01:36:13,139] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 111767: loss -86.2361
[2019-03-24 01:36:13,141] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 111767: learning rate 0.0000
[2019-03-24 01:36:13,228] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 111812: loss -72.7983
[2019-03-24 01:36:13,231] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 111812: learning rate 0.0000
[2019-03-24 01:36:13,368] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 111883: loss -77.6879
[2019-03-24 01:36:13,377] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 111886: learning rate 0.0000
[2019-03-24 01:36:13,460] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 111932: loss 81.1223
[2019-03-24 01:36:13,461] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111933: loss -152.0827
[2019-03-24 01:36:13,463] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111933: learning rate 0.0000
[2019-03-24 01:36:13,464] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 111933: learning rate 0.0000
[2019-03-24 01:36:13,476] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 111941: loss -43.7088
[2019-03-24 01:36:13,478] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 111941: learning rate 0.0000
[2019-03-24 01:36:13,519] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 111962: loss -68.0394
[2019-03-24 01:36:13,520] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 111962: learning rate 0.0000
[2019-03-24 01:36:13,630] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 112020: loss -10.9559
[2019-03-24 01:36:13,633] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 112020: learning rate 0.0000
[2019-03-24 01:36:13,729] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 112069: loss -72.6837
[2019-03-24 01:36:13,730] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 112069: learning rate 0.0000
[2019-03-24 01:36:13,811] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 112106: loss -75.0640
[2019-03-24 01:36:13,814] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 112106: learning rate 0.0000
[2019-03-24 01:36:13,856] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 112133: loss 8.5025
[2019-03-24 01:36:13,859] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 112133: learning rate 0.0000
[2019-03-24 01:36:13,865] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 112135: loss 14.4312
[2019-03-24 01:36:13,867] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 112136: learning rate 0.0000
[2019-03-24 01:36:14,125] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 112271: loss -79.2540
[2019-03-24 01:36:14,126] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 112271: learning rate 0.0000
[2019-03-24 01:36:14,506] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 112470: loss -132.8873
[2019-03-24 01:36:14,506] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 112470: learning rate 0.0000
[2019-03-24 01:36:15,027] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.00000000e+00 1.29060405e-25 2.45331662e-17 1.31303885e-27
 1.95832798e-14], sum to 1.0000
[2019-03-24 01:36:15,035] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1895
[2019-03-24 01:36:15,040] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.0, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.917471923738955, 6.9112, 6.9112, 121.9260426156618, 667303.5507137891, 667303.5507137891, 179029.2178959782], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4222800.0000, 
sim time next is 4223400.0000, 
raw observation next is [28.5, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.925738539905074, 6.9112, 6.9112, 121.9260426156618, 672507.3514172513, 672507.3514172513, 180277.6609185326], 
processed observation next is [1.0, 0.9130434782608695, 0.6111111111111112, 0.64, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9071731748813424, 0.0, 0.0, 0.8094621288201359, 0.2401811969347326, 0.2401811969347326, 0.3466878094587166], 
reward next is 0.6533, 
noisyNet noise sample is [array([1.4266106], dtype=float32), 0.7089393]. 
=============================================
[2019-03-24 01:36:16,224] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.4805147e-24 3.9491461e-14 4.2632404e-26 5.4454185e-15], sum to 1.0000
[2019-03-24 01:36:16,230] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7867
[2019-03-24 01:36:16,236] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 832492.2256096195 W.
[2019-03-24 01:36:16,240] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.16666666666667, 54.83333333333333, 1.0, 2.0, 0.3461685514933475, 1.0, 1.0, 0.3461685514933475, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 832492.2256096195, 832492.2256096199, 193758.4221800895], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4261800.0000, 
sim time next is 4262400.0000, 
raw observation next is [27.8, 51.0, 1.0, 2.0, 0.3849035611375453, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6233013307745834, 6.9112, 6.9112, 121.9260426156618, 928302.934019581, 928302.934019581, 217746.0717316361], 
processed observation next is [1.0, 0.34782608695652173, 0.5851851851851853, 0.51, 1.0, 1.0, 0.26774233468755393, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.5291266634682292, 0.0, 0.0, 0.8094621288201359, 0.33153676214985034, 0.33153676214985034, 0.41874244563776175], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7952428], dtype=float32), 2.984305]. 
=============================================
[2019-03-24 01:36:20,726] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9999964e-01 5.9676300e-15 3.2298697e-10 1.5907824e-14 3.1823271e-07], sum to 1.0000
[2019-03-24 01:36:20,736] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9058
[2019-03-24 01:36:20,740] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.2, 89.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8131960331887604, 6.911200000000001, 6.9112, 121.9260426156618, 606344.2670350141, 606344.2670350136, 160474.7330760388], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4339200.0000, 
sim time next is 4339800.0000, 
raw observation next is [22.4, 89.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8281774189464981, 6.911200000000001, 6.9112, 121.9260426156618, 616934.2831047616, 616934.2831047612, 162769.4994689486], 
processed observation next is [1.0, 0.21739130434782608, 0.38518518518518513, 0.895, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7852217736831226, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22033367253741487, 0.2203336725374147, 0.31301826820951656], 
reward next is 0.6870, 
noisyNet noise sample is [array([-0.57148314], dtype=float32), 0.82761675]. 
=============================================
[2019-03-24 01:36:26,229] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.1855144e-24 3.5657983e-17 4.7524132e-27 4.6829412e-11], sum to 1.0000
[2019-03-24 01:36:26,235] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3414
[2019-03-24 01:36:26,239] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.3, 84.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9362476877670016, 6.911199999999999, 6.9112, 121.9260426156618, 679901.4671749301, 679901.4671749306, 181751.6179331464], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4437600.0000, 
sim time next is 4438200.0000, 
raw observation next is [25.65, 84.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9727637575410681, 6.911200000000001, 6.9112, 121.9259662999088, 702536.4228070145, 702536.4228070141, 187359.2415334378], 
processed observation next is [0.0, 0.34782608695652173, 0.5055555555555555, 0.8433333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9659546969263352, 8.881784197001253e-17, 0.0, 0.8094616221628987, 0.25090586528821945, 0.2509058652882193, 0.3603062337181496], 
reward next is 0.6397, 
noisyNet noise sample is [array([1.5010957], dtype=float32), 1.6597352]. 
=============================================
[2019-03-24 01:36:28,844] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 119599: loss 87.8367
[2019-03-24 01:36:28,846] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 119599: learning rate 0.0000
[2019-03-24 01:36:29,010] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9997127e-01 7.4508205e-10 6.7269825e-06 4.2533654e-10 2.2021259e-05], sum to 1.0000
[2019-03-24 01:36:29,016] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4040
[2019-03-24 01:36:29,021] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 806640.2849463621 W.
[2019-03-24 01:36:29,025] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.235916937605889, 1.0, 1.0, 0.235916937605889, 1.0, 1.0, 0.3755874479468355, 6.911200000000001, 6.9112, 121.94756008, 806640.2849463621, 806640.2849463617, 232687.1254585676], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4482000.0000, 
sim time next is 4482600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.347766090858724, 1.0, 2.0, 0.347766090858724, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 792707.2954623753, 792707.2954623757, 192318.9832517115], 
processed observation next is [0.0, 0.9130434782608695, 0.5555555555555556, 0.84, 1.0, 1.0, 0.2235310605461, 1.0, 1.0, 0.2235310605461, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28310974837941977, 0.28310974837941993, 0.36984419856098366], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1150242], dtype=float32), 0.44436306]. 
=============================================
[2019-03-24 01:36:29,118] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 119738: loss 75.5409
[2019-03-24 01:36:29,119] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 119738: learning rate 0.0000
[2019-03-24 01:36:29,163] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 119755: loss 54.5945
[2019-03-24 01:36:29,170] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 119755: learning rate 0.0000
[2019-03-24 01:36:29,342] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 119836: loss 115.0071
[2019-03-24 01:36:29,345] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 119837: learning rate 0.0000
[2019-03-24 01:36:29,460] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119898: loss 87.2973
[2019-03-24 01:36:29,461] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119899: learning rate 0.0000
[2019-03-24 01:36:29,524] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 119920: loss 144.0518
[2019-03-24 01:36:29,528] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 119921: learning rate 0.0000
[2019-03-24 01:36:29,554] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 119931: loss 129.3424
[2019-03-24 01:36:29,556] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 119931: learning rate 0.0000
[2019-03-24 01:36:29,666] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 119995: loss 58.5943
[2019-03-24 01:36:29,668] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 119995: learning rate 0.0000
[2019-03-24 01:36:29,705] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 120006: loss 191.2321
[2019-03-24 01:36:29,710] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 120006: learning rate 0.0000
[2019-03-24 01:36:29,795] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 120054: loss 48.9839
[2019-03-24 01:36:29,797] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 120054: learning rate 0.0000
[2019-03-24 01:36:29,833] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 120071: loss 121.4380
[2019-03-24 01:36:29,836] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 120073: learning rate 0.0000
[2019-03-24 01:36:29,866] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 120083: loss 188.4729
[2019-03-24 01:36:29,867] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 120083: learning rate 0.0000
[2019-03-24 01:36:30,040] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 120171: loss 230.5223
[2019-03-24 01:36:30,049] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 120173: learning rate 0.0000
[2019-03-24 01:36:30,059] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 120180: loss 76.0168
[2019-03-24 01:36:30,062] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 120180: learning rate 0.0000
[2019-03-24 01:36:30,394] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 120348: loss 92.2600
[2019-03-24 01:36:30,398] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 120349: learning rate 0.0000
[2019-03-24 01:36:30,572] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 120437: loss 237.9984
[2019-03-24 01:36:30,575] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 120437: learning rate 0.0000
[2019-03-24 01:36:32,448] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.3045711e-18 3.0548875e-08 2.9361189e-20 3.6368863e-08], sum to 1.0000
[2019-03-24 01:36:32,453] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8942
[2019-03-24 01:36:32,459] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 100.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9438775284929557, 6.911199999999999, 6.9112, 121.9260426156618, 683340.5256211737, 683340.5256211741, 183101.6077077004], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4548600.0000, 
sim time next is 4549200.0000, 
raw observation next is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9371577885293203, 6.911200000000001, 6.9112, 121.9260426156618, 682388.7019847847, 682388.7019847842, 181587.1510348218], 
processed observation next is [0.0, 0.6521739130434783, 0.4074074074074074, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9214472356616504, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24371025070885166, 0.2437102507088515, 0.34920605968234963], 
reward next is 0.6508, 
noisyNet noise sample is [array([-0.66240144], dtype=float32), 0.37136674]. 
=============================================
[2019-03-24 01:36:36,715] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9999881e-01 1.5140045e-10 5.5621502e-08 1.2512624e-10 1.1706800e-06], sum to 1.0000
[2019-03-24 01:36:36,725] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6435
[2019-03-24 01:36:36,733] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2191285.62244449 W.
[2019-03-24 01:36:36,738] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 69.33333333333333, 1.0, 2.0, 0.9605099095956156, 1.0, 2.0, 0.9605099095956156, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260424503252, 2191285.62244449, 2191285.62244449, 414544.1633013583], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4636200.0000, 
sim time next is 4636800.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.9729808394921566, 1.0, 2.0, 0.9729808394921566, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156114, 2219771.888289154, 2219771.888289153, 420418.0372800979], 
processed observation next is [1.0, 0.6956521739130435, 0.6666666666666666, 0.7, 1.0, 1.0, 0.9678343327287579, 1.0, 1.0, 0.9678343327287579, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288198013, 0.7927756743889836, 0.7927756743889832, 0.8084962255386497], 
reward next is 0.1915, 
noisyNet noise sample is [array([0.5523587], dtype=float32), 0.4182502]. 
=============================================
[2019-03-24 01:36:36,797] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9998224e-01 6.4460575e-09 2.0188493e-07 3.2600908e-10 1.7560053e-05], sum to 1.0000
[2019-03-24 01:36:36,807] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7564
[2019-03-24 01:36:36,813] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2008843.149236344 W.
[2019-03-24 01:36:36,820] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.66666666666667, 64.66666666666667, 1.0, 2.0, 0.5870864153018445, 1.0, 1.0, 0.5870864153018445, 1.0, 2.0, 0.9346606932302411, 6.9112, 6.9112, 121.94756008, 2008843.149236344, 2008843.149236344, 388384.5109935493], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4630800.0000, 
sim time next is 4631400.0000, 
raw observation next is [29.75, 65.0, 1.0, 2.0, 0.5859042050405672, 1.0, 2.0, 0.5859042050405672, 1.0, 2.0, 0.9327785759923876, 6.9112, 6.9112, 121.94756008, 2004793.421293053, 2004793.421293053, 387748.9816634763], 
processed observation next is [1.0, 0.6086956521739131, 0.6574074074074074, 0.65, 1.0, 1.0, 0.5070288155244848, 1.0, 1.0, 0.5070288155244848, 1.0, 1.0, 0.9159732199904843, 0.0, 0.0, 0.8096049824067558, 0.7159976504618046, 0.7159976504618046, 0.7456711185836083], 
reward next is 0.2543, 
noisyNet noise sample is [array([-2.2609491], dtype=float32), 0.22714317]. 
=============================================
[2019-03-24 01:36:37,302] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9999905e-01 8.0240849e-12 8.7605878e-10 1.0826782e-12 1.0026594e-06], sum to 1.0000
[2019-03-24 01:36:37,311] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7287
[2019-03-24 01:36:37,323] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2054900.881118478 W.
[2019-03-24 01:36:37,326] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.91666666666666, 65.66666666666666, 1.0, 2.0, 0.6005313668341844, 1.0, 2.0, 0.6005313668341844, 1.0, 1.0, 0.9560654939412283, 6.9112, 6.9112, 121.94756008, 2054900.881118478, 2054900.881118478, 395665.1869171277], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4632600.0000, 
sim time next is 4633200.0000, 
raw observation next is [30.0, 66.0, 1.0, 2.0, 0.6138838974076308, 1.0, 2.0, 0.6138838974076308, 1.0, 2.0, 0.9773231574757166, 6.9112, 6.9112, 121.94756008, 2100644.36174422, 2100644.36174422, 402992.1357713656], 
processed observation next is [1.0, 0.6521739130434783, 0.6666666666666666, 0.66, 1.0, 1.0, 0.5403379731043224, 1.0, 1.0, 0.5403379731043224, 1.0, 1.0, 0.9716539468446458, 0.0, 0.0, 0.8096049824067558, 0.7502301291943643, 0.7502301291943643, 0.7749848764833954], 
reward next is 0.2250, 
noisyNet noise sample is [array([-0.24093851], dtype=float32), -0.009054438]. 
=============================================
[2019-03-24 01:36:38,885] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.99964476e-01 1.07589345e-11 3.65055053e-09 5.74371540e-12
 3.55776247e-05], sum to 1.0000
[2019-03-24 01:36:38,891] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0726
[2019-03-24 01:36:38,903] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 781675.4874460106 W.
[2019-03-24 01:36:38,909] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.66666666666667, 89.83333333333333, 1.0, 2.0, 0.6858576561409813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 781675.4874460106, 781675.4874460106, 173482.3677530236], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4661400.0000, 
sim time next is 4662000.0000, 
raw observation next is [25.6, 89.0, 1.0, 2.0, 0.2247723139214451, 1.0, 1.0, 0.2247723139214451, 1.0, 1.0, 0.3578448440861467, 6.9112, 6.9112, 121.94756008, 768515.814347972, 768515.814347972, 228857.7594376183], 
processed observation next is [1.0, 1.0, 0.5037037037037038, 0.89, 1.0, 1.0, 0.07710989752552987, 1.0, 0.5, 0.07710989752552987, 1.0, 0.5, 0.19730605510768334, 0.0, 0.0, 0.8096049824067558, 0.2744699336957043, 0.2744699336957043, 0.44011107584157366], 
reward next is 0.5599, 
noisyNet noise sample is [array([0.399735], dtype=float32), -1.1844534]. 
=============================================
[2019-03-24 01:36:38,925] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[30.636724]
 [30.754614]
 [31.185028]
 [30.86258 ]
 [31.169138]], R is [[30.61585426]
 [30.97607613]
 [30.66631508]
 [30.35965157]
 [30.71271706]].
[2019-03-24 01:36:39,888] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 01:36:39,890] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:36:39,890] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:36:39,892] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:36:39,893] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:36:39,893] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:36:39,894] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:36:39,893] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:36:39,895] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:36:39,895] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:36:39,896] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:36:39,906] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run6
[2019-03-24 01:36:39,928] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run6
[2019-03-24 01:36:39,929] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run6
[2019-03-24 01:36:39,929] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run6
[2019-03-24 01:36:39,930] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run6
[2019-03-24 01:36:48,349] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.06122538]
[2019-03-24 01:36:48,350] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [17.65868481333333, 83.35363816333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.469923112278165, 6.911199999999999, 6.9112, 121.9260426156618, 335525.5700624171, 335525.5700624175, 111317.8192661294]
[2019-03-24 01:36:48,351] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:36:48,354] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9998701e-01 5.3621989e-13 1.9370030e-09 3.8078262e-13 1.2979397e-05], sampled 0.40014404314782126
[2019-03-24 01:37:12,956] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.06122538]
[2019-03-24 01:37:12,957] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.45671281833334, 105.2288430016667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7773647810551855, 6.911199999999999, 6.9112, 121.9260426156618, 580075.2929204039, 580075.2929204043, 151273.291802851]
[2019-03-24 01:37:12,959] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:37:12,962] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9997795e-01 1.9978591e-12 4.9649902e-09 1.4481949e-12 2.2043658e-05], sampled 0.31199840184568883
[2019-03-24 01:37:34,252] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.06122538]
[2019-03-24 01:37:34,254] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.0, 89.0, 1.0, 2.0, 0.6854875378224805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 781253.4467274375, 781253.4467274375, 173414.2922798655]
[2019-03-24 01:37:34,257] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:37:34,260] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.99949574e-01 1.59210735e-11 2.18687450e-08 1.18386715e-11
 5.04030395e-05], sampled 0.286784745340786
[2019-03-24 01:37:34,261] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 781253.4467274375 W.
[2019-03-24 01:37:52,437] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.06122538]
[2019-03-24 01:37:52,438] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.9, 73.16666666666667, 1.0, 2.0, 0.7751595971268589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 883512.0291126771, 883512.0291126771, 190866.2472711697]
[2019-03-24 01:37:52,439] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:37:52,443] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9992979e-01 3.6404078e-11 3.9465920e-08 2.7435561e-11 7.0180147e-05], sampled 0.5175742438533415
[2019-03-24 01:37:52,444] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 883512.0291126771 W.
[2019-03-24 01:38:06,493] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.06122538]
[2019-03-24 01:38:06,493] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.23333333333333, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.84180942211665, 6.9112, 6.9112, 121.9260426156618, 619756.35319077, 619756.35319077, 167508.1423759944]
[2019-03-24 01:38:06,494] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:38:06,496] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9998784e-01 4.4965545e-13 1.7058048e-09 3.1934159e-13 1.2130209e-05], sampled 0.47683271838286656
[2019-03-24 01:38:18,273] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.06122538]
[2019-03-24 01:38:18,274] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.0, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7373611548666227, 6.9112, 6.9112, 121.9260426156618, 526541.190267471, 526541.190267471, 129114.3145319662]
[2019-03-24 01:38:18,274] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:38:18,276] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9997139e-01 3.9316237e-12 8.0460669e-09 2.8869465e-12 2.8575900e-05], sampled 0.014762100354115182
[2019-03-24 01:38:23,755] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.06122538]
[2019-03-24 01:38:23,756] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.5, 52.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.956017541329595, 7.034025997540914, 6.9112, 121.9254863840486, 777182.1350138029, 714284.5331525191, 176577.9171119364]
[2019-03-24 01:38:23,756] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:38:23,757] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9997306e-01 3.3313387e-12 7.1076598e-09 2.4455017e-12 2.6903617e-05], sampled 0.4544990194271913
[2019-03-24 01:38:23,759] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 777182.1350138029 W.
[2019-03-24 01:38:24,575] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8632.3812 2219126056.5202 543.0000
[2019-03-24 01:38:24,667] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.2390 2292980111.6144 697.0000
[2019-03-24 01:38:24,735] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8361.8030 2339524911.9634 616.0000
[2019-03-24 01:38:24,827] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8559.5194 2258257419.8877 536.0000
[2019-03-24 01:38:24,961] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7839.9269 2529927107.4624 831.0000
[2019-03-24 01:38:25,977] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 125000, evaluation results [125000.0, 7839.926946175461, 2529927107.4623995, 831.0, 8559.519404238568, 2258257419.8877115, 536.0, 8632.381158635802, 2219126056.520221, 543.0, 8361.802956777869, 2339524911.9634447, 616.0, 8404.238967854026, 2292980111.6144123, 697.0]
[2019-03-24 01:38:27,713] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.8835224e-01 4.3137707e-10 1.3769770e-06 6.0725817e-08 1.1646262e-02], sum to 1.0000
[2019-03-24 01:38:27,718] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7630
[2019-03-24 01:38:27,724] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 796076.211998972 W.
[2019-03-24 01:38:27,730] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 84.33333333333334, 1.0, 2.0, 0.3492432903792833, 1.0, 1.0, 0.3492432903792833, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 796076.211998972, 796076.2119989725, 192698.147676799], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4736400.0000, 
sim time next is 4737000.0000, 
raw observation next is [26.75, 83.16666666666667, 1.0, 2.0, 0.6876479682134385, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783716.9584296992, 783716.9584296992, 173817.7389065658], 
processed observation next is [1.0, 0.8260869565217391, 0.5462962962962963, 0.8316666666666667, 1.0, 1.0, 0.6281523431112364, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27989891372489256, 0.27989891372489256, 0.33426488251262654], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.55264133], dtype=float32), -1.7235337]. 
=============================================
[2019-03-24 01:38:27,744] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[23.502228]
 [23.628313]
 [23.338243]
 [23.491196]
 [23.741745]], R is [[23.06691551]
 [22.83624649]
 [23.20349312]
 [23.6268425 ]
 [24.01357651]].
[2019-03-24 01:38:30,392] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.9308985e-01 2.1146420e-14 2.6588845e-10 3.4842914e-12 5.0691009e-01], sum to 1.0000
[2019-03-24 01:38:30,399] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3063
[2019-03-24 01:38:30,400] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 813993.641490987 W.
[2019-03-24 01:38:30,414] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 94.66666666666667, 1.0, 2.0, 0.2380664221624197, 1.0, 2.0, 0.2380664221624197, 1.0, 2.0, 0.3790094973646572, 6.9112, 6.9112, 121.94756008, 813993.641490987, 813993.641490987, 233433.6897384658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4767600.0000, 
sim time next is 4768200.0000, 
raw observation next is [23.75, 95.0, 1.0, 2.0, 0.691492283319129, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 795161.6964227278, 795161.6964227278, 174890.6054137184], 
processed observation next is [1.0, 0.17391304347826086, 0.4351851851851852, 0.95, 1.0, 1.0, 0.6327289087132488, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2839863201509742, 0.2839863201509742, 0.3363280873340739], 
reward next is 0.6637, 
noisyNet noise sample is [array([-1.6761988], dtype=float32), -0.5604634]. 
=============================================
[2019-03-24 01:38:31,070] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 127621: loss -3.6226
[2019-03-24 01:38:31,071] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 127622: learning rate 0.0000
[2019-03-24 01:38:31,200] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 127688: loss 25.8639
[2019-03-24 01:38:31,201] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 127688: learning rate 0.0000
[2019-03-24 01:38:31,327] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 127753: loss -1.1323
[2019-03-24 01:38:31,328] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 127753: learning rate 0.0000
[2019-03-24 01:38:31,437] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127815: loss -47.2834
[2019-03-24 01:38:31,440] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 127815: learning rate 0.0000
[2019-03-24 01:38:31,508] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 127845: loss -5.3670
[2019-03-24 01:38:31,510] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 127845: learning rate 0.0000
[2019-03-24 01:38:31,524] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8344133e-01 6.4099406e-11 1.0381356e-08 2.1873401e-09 7.1655869e-01], sum to 1.0000
[2019-03-24 01:38:31,527] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7836
[2019-03-24 01:38:31,532] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.577868623503433, 1.0, 2.0, 0.577868623503433, 1.0, 2.0, 0.9199856684846497, 6.911200000000001, 6.9112, 121.94756008, 1977267.569963928, 1977267.569963928, 383449.1998179711], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4808400.0000, 
sim time next is 4809000.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.5735780156249021, 1.0, 2.0, 0.5735780156249021, 1.0, 2.0, 0.9131548810066852, 6.9112, 6.9112, 121.94756008, 1962570.457797399, 1962570.457797399, 381167.5855463679], 
processed observation next is [1.0, 0.6521739130434783, 0.5555555555555556, 0.89, 1.0, 1.0, 0.49235478050583575, 1.0, 1.0, 0.49235478050583575, 1.0, 1.0, 0.8914436012583565, 0.0, 0.0, 0.8096049824067558, 0.7009180206419282, 0.7009180206419282, 0.733014587589169], 
reward next is 0.2670, 
noisyNet noise sample is [array([0.20579484], dtype=float32), -1.7901466]. 
=============================================
[2019-03-24 01:38:31,549] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 127870: loss -15.1437
[2019-03-24 01:38:31,553] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 127870: learning rate 0.0000
[2019-03-24 01:38:31,559] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[23.670206]
 [23.628384]
 [23.53926 ]
 [23.382412]
 [23.451355]], R is [[24.17301559]
 [24.1938839 ]
 [24.2089119 ]
 [23.96682358]
 [24.09062004]].
[2019-03-24 01:38:31,569] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 127880: loss -8.1635
[2019-03-24 01:38:31,569] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 127880: learning rate 0.0000
[2019-03-24 01:38:31,628] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 127906: loss -20.2418
[2019-03-24 01:38:31,630] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 127906: learning rate 0.0000
[2019-03-24 01:38:31,746] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 127970: loss 3.6472
[2019-03-24 01:38:31,748] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 127970: learning rate 0.0000
[2019-03-24 01:38:31,895] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 128047: loss 1.3413
[2019-03-24 01:38:31,898] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 128047: learning rate 0.0000
[2019-03-24 01:38:32,109] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 128151: loss -3.0344
[2019-03-24 01:38:32,110] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 128151: learning rate 0.0000
[2019-03-24 01:38:32,127] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 128158: loss 0.1465
[2019-03-24 01:38:32,128] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 128158: learning rate 0.0000
[2019-03-24 01:38:32,194] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 128197: loss 0.3068
[2019-03-24 01:38:32,196] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 128197: learning rate 0.0000
[2019-03-24 01:38:32,333] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 128269: loss 0.3948
[2019-03-24 01:38:32,334] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 128269: learning rate 0.0000
[2019-03-24 01:38:32,390] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 128296: loss 0.7058
[2019-03-24 01:38:32,392] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 128296: learning rate 0.0000
[2019-03-24 01:38:32,594] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 128399: loss 1.2384
[2019-03-24 01:38:32,595] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 128400: learning rate 0.0000
[2019-03-24 01:38:32,833] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.6267768e-04 4.6196932e-23 9.4727561e-20 1.9542704e-19 9.9943727e-01], sum to 1.0000
[2019-03-24 01:38:32,839] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5405
[2019-03-24 01:38:32,845] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.4, 92.66666666666667, 1.0, 2.0, 0.2474105430400047, 1.0, 2.0, 0.2474105430400047, 1.0, 2.0, 0.393885642118544, 6.911200000000001, 6.9112, 121.94756008, 845960.5678790599, 845960.5678790596, 236709.1211618848], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4826400.0000, 
sim time next is 4827000.0000, 
raw observation next is [26.2, 93.33333333333334, 1.0, 2.0, 0.2453147991086289, 1.0, 2.0, 0.2453147991086289, 1.0, 2.0, 0.390549149526179, 6.9112, 6.9112, 121.94756008, 838790.7574248558, 838790.7574248558, 235970.2479505785], 
processed observation next is [1.0, 0.8695652173913043, 0.5259259259259259, 0.9333333333333335, 1.0, 1.0, 0.10156523703408203, 1.0, 1.0, 0.10156523703408203, 1.0, 1.0, 0.2381864369077237, 0.0, 0.0, 0.8096049824067558, 0.29956812765173424, 0.29956812765173424, 0.4537889383664971], 
reward next is 0.5462, 
noisyNet noise sample is [array([0.58026165], dtype=float32), 1.6690599]. 
=============================================
[2019-03-24 01:38:32,875] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[52.372093]
 [52.22501 ]
 [52.13323 ]
 [52.00616 ]
 [51.96094 ]], R is [[52.50753784]
 [52.5272522 ]
 [52.54571533]
 [52.56270599]
 [52.57779312]].
[2019-03-24 01:38:33,323] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5021915e-02 6.1562735e-22 2.6407648e-18 8.7142717e-18 9.8497808e-01], sum to 1.0000
[2019-03-24 01:38:33,334] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4406
[2019-03-24 01:38:33,339] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 93.66666666666667, 1.0, 2.0, 0.2398946935093892, 1.0, 2.0, 0.2398946935093892, 1.0, 2.0, 0.3819201648916735, 6.9112, 6.9112, 121.94756008, 820248.1876591195, 820248.1876591195, 234070.7217066975], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4828800.0000, 
sim time next is 4829400.0000, 
raw observation next is [26.0, 93.5, 1.0, 2.0, 0.2392271774436499, 1.0, 2.0, 0.2392271774436499, 1.0, 2.0, 0.380857457575536, 6.911200000000001, 6.9112, 121.94756008, 817964.5983706284, 817964.598370628, 233837.9198781759], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.935, 1.0, 1.0, 0.09431806838529751, 1.0, 1.0, 0.09431806838529751, 1.0, 1.0, 0.22607182196942, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2921302137037959, 0.2921302137037957, 0.44968830745803057], 
reward next is 0.5503, 
noisyNet noise sample is [array([-1.6752703], dtype=float32), 0.23739102]. 
=============================================
[2019-03-24 01:38:33,598] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.3169355e-05 1.9747530e-22 2.8879901e-18 2.4897089e-17 9.9994683e-01], sum to 1.0000
[2019-03-24 01:38:33,604] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0922
[2019-03-24 01:38:33,608] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 100.0, 1.0, 2.0, 0.2356890200455897, 1.0, 2.0, 0.2356890200455897, 1.0, 2.0, 0.3752245957680823, 6.911199999999999, 6.9112, 121.94756008, 805860.5863026455, 805860.586302646, 232608.1159979695], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4840800.0000, 
sim time next is 4841400.0000, 
raw observation next is [25.0, 100.0, 1.0, 2.0, 0.2354611507463386, 1.0, 2.0, 0.2354611507463386, 1.0, 2.0, 0.3748618204224896, 6.911199999999999, 6.9112, 121.94756008, 805081.0535511822, 805081.0535511826, 232529.152293891], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 1.0, 1.0, 1.0, 0.08983470326945073, 1.0, 1.0, 0.08983470326945073, 1.0, 1.0, 0.218577275528112, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2875289476968508, 0.28752894769685095, 0.44717144671902115], 
reward next is 0.5528, 
noisyNet noise sample is [array([1.212497], dtype=float32), -1.4629399]. 
=============================================
[2019-03-24 01:38:33,869] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9778222e-03 2.6784794e-23 2.9214313e-19 2.6204157e-17 9.9002212e-01], sum to 1.0000
[2019-03-24 01:38:33,881] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3517
[2019-03-24 01:38:33,886] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.03333333333333, 92.66666666666667, 1.0, 2.0, 0.2378260722510376, 1.0, 2.0, 0.2378260722510376, 1.0, 2.0, 0.3786268524780868, 6.911199999999999, 6.9112, 121.94756008, 813171.4043099119, 813171.4043099124, 233350.0825829603], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4832400.0000, 
sim time next is 4833000.0000, 
raw observation next is [26.05, 92.5, 1.0, 2.0, 0.2374850910553553, 1.0, 2.0, 0.2374850910553553, 1.0, 2.0, 0.3780839993095784, 6.9112, 6.9112, 121.94756008, 812004.9089621166, 812004.9089621166, 233231.5256259883], 
processed observation next is [1.0, 0.9565217391304348, 0.5203703703703704, 0.925, 1.0, 1.0, 0.09224415601828014, 1.0, 1.0, 0.09224415601828014, 1.0, 1.0, 0.22260499913697301, 0.0, 0.0, 0.8096049824067558, 0.29000175320075594, 0.29000175320075594, 0.4485221646653621], 
reward next is 0.5515, 
noisyNet noise sample is [array([0.20391895], dtype=float32), -1.0755129]. 
=============================================
[2019-03-24 01:38:33,904] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[54.70873 ]
 [54.721607]
 [54.774525]
 [54.7933  ]
 [54.66352 ]], R is [[54.8490181 ]
 [54.85177994]
 [54.8547554 ]
 [54.85775375]
 [54.86026382]].
[2019-03-24 01:38:34,170] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.2805668e-01 3.6534831e-19 1.1540766e-16 1.0058815e-13 4.7194332e-01], sum to 1.0000
[2019-03-24 01:38:34,175] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5967
[2019-03-24 01:38:34,180] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 93.33333333333334, 1.0, 2.0, 0.2387052365170955, 1.0, 2.0, 0.2387052365170955, 1.0, 2.0, 0.3800265106220321, 6.9112, 6.9112, 121.94756008, 816179.0300421123, 816179.0300421123, 233656.0620777545], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4830000.0000, 
sim time next is 4830600.0000, 
raw observation next is [26.0, 93.16666666666666, 1.0, 2.0, 0.2380709663770223, 1.0, 2.0, 0.2380709663770223, 1.0, 2.0, 0.3790167319022992, 6.9112, 6.9112, 121.94756008, 814009.1872601752, 814009.1872601752, 233435.2707817011], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.9316666666666665, 1.0, 1.0, 0.09294162663931226, 1.0, 1.0, 0.09294162663931226, 1.0, 1.0, 0.22377091487787396, 0.0, 0.0, 0.8096049824067558, 0.29071756687863404, 0.29071756687863404, 0.4489139822725021], 
reward next is 0.5511, 
noisyNet noise sample is [array([0.3718936], dtype=float32), 1.2466925]. 
=============================================
[2019-03-24 01:38:34,551] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.0505631e-01 1.9740528e-14 1.1354247e-11 2.9609045e-12 2.9494366e-01], sum to 1.0000
[2019-03-24 01:38:34,558] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4930
[2019-03-24 01:38:34,571] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 803112.0409161287 W.
[2019-03-24 01:38:34,576] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.06666666666667, 99.16666666666667, 1.0, 2.0, 0.234885577323859, 1.0, 2.0, 0.234885577323859, 1.0, 2.0, 0.3739454887887844, 6.9112, 6.9112, 121.94756008, 803112.0409161287, 803112.0409161287, 232329.8276858026], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4842600.0000, 
sim time next is 4843200.0000, 
raw observation next is [25.13333333333333, 98.33333333333334, 1.0, 2.0, 0.3515508934900091, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5596804716493843, 6.911199999999999, 6.9112, 121.9260426156618, 801338.9852028806, 801338.985202881, 209622.6897498052], 
processed observation next is [1.0, 0.043478260869565216, 0.4864197530864196, 0.9833333333333334, 1.0, 1.0, 0.22803677796429658, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.4496005895617303, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2861924947153145, 0.28619249471531466, 0.40312055721116385], 
reward next is 0.5969, 
noisyNet noise sample is [array([-0.3740966], dtype=float32), 0.6430738]. 
=============================================
[2019-03-24 01:38:36,935] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3923767e-01 3.0284321e-12 2.1068931e-11 2.2719526e-09 8.6076236e-01], sum to 1.0000
[2019-03-24 01:38:36,941] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3876
[2019-03-24 01:38:36,946] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.4838512384653919, 1.0, 2.0, 0.4838512384653919, 1.0, 2.0, 0.7703069295716221, 6.9112, 6.9112, 121.94756008, 1655274.406439572, 1655274.406439572, 335733.755703203], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4885200.0000, 
sim time next is 4885800.0000, 
raw observation next is [29.46666666666667, 87.0, 1.0, 2.0, 0.5863689812612364, 1.0, 2.0, 0.5863689812612364, 1.0, 2.0, 0.9335185148723977, 6.911200000000001, 6.9112, 121.94756008, 2006385.536266489, 2006385.536266488, 387998.7449278596], 
processed observation next is [1.0, 0.5652173913043478, 0.6469135802469137, 0.87, 1.0, 1.0, 0.5075821205490909, 1.0, 1.0, 0.5075821205490909, 1.0, 1.0, 0.9168981435904971, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7165662629523175, 0.7165662629523172, 0.7461514325535761], 
reward next is 0.2538, 
noisyNet noise sample is [array([-1.9564235], dtype=float32), 0.87829953]. 
=============================================
[2019-03-24 01:38:39,018] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8762323e-01 1.0897930e-20 1.1463009e-20 1.6518168e-16 8.1237686e-01], sum to 1.0000
[2019-03-24 01:38:39,030] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9903
[2019-03-24 01:38:39,033] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.96666666666667, 77.66666666666667, 1.0, 2.0, 0.2163122270020231, 1.0, 1.0, 0.2163122270020231, 1.0, 1.0, 0.3443761101846314, 6.9112, 6.9112, 121.94756008, 739576.0998185752, 739576.0998185752, 225997.1933473143], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4929600.0000, 
sim time next is 4930200.0000, 
raw observation next is [26.95, 77.0, 1.0, 2.0, 0.2134825305157454, 1.0, 2.0, 0.2134825305157454, 1.0, 2.0, 0.3398711412216965, 6.9112, 6.9112, 121.94756008, 729896.7021002424, 729896.7021002424, 225049.3382430257], 
processed observation next is [1.0, 0.043478260869565216, 0.5537037037037037, 0.77, 1.0, 1.0, 0.06366967918541118, 1.0, 1.0, 0.06366967918541118, 1.0, 1.0, 0.17483892652712058, 0.0, 0.0, 0.8096049824067558, 0.2606773936072294, 0.2606773936072294, 0.43278718892889556], 
reward next is 0.5672, 
noisyNet noise sample is [array([0.64390796], dtype=float32), 0.7367443]. 
=============================================
[2019-03-24 01:38:40,114] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8518847e-01 7.8875741e-17 4.2748617e-16 2.1182607e-13 8.1481147e-01], sum to 1.0000
[2019-03-24 01:38:40,127] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5499
[2019-03-24 01:38:40,131] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 85.0, 1.0, 2.0, 0.1909063198765256, 1.0, 2.0, 0.1909063198765256, 1.0, 2.0, 0.3045135001470805, 6.9112, 6.9112, 121.94756008, 664151.4041260451, 664151.4041260451, 217617.2602263131], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4947600.0000, 
sim time next is 4948200.0000, 
raw observation next is [24.0, 86.0, 1.0, 2.0, 0.1987541130301991, 1.0, 2.0, 0.1987541130301991, 1.0, 2.0, 0.316919971121574, 6.9112, 6.9112, 121.94756008, 690067.7014524305, 690067.7014524305, 220172.7348036653], 
processed observation next is [1.0, 0.2608695652173913, 0.4444444444444444, 0.86, 1.0, 1.0, 0.04613584884547512, 1.0, 1.0, 0.04613584884547512, 1.0, 1.0, 0.14614996390196747, 0.0, 0.0, 0.8096049824067558, 0.24645275051872517, 0.24645275051872517, 0.42340910539166404], 
reward next is 0.5766, 
noisyNet noise sample is [array([-1.5967132], dtype=float32), 0.7754544]. 
=============================================
[2019-03-24 01:38:42,319] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.7506064e-01 2.1136923e-17 1.7544790e-14 9.0280287e-15 5.2493930e-01], sum to 1.0000
[2019-03-24 01:38:42,328] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6543
[2019-03-24 01:38:42,331] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.53333333333333, 94.0, 1.0, 2.0, 0.2134479215859807, 1.0, 2.0, 0.2134479215859807, 1.0, 2.0, 0.339816042678377, 6.911200000000001, 6.9112, 121.94756008, 729778.3178647206, 729778.3178647201, 225037.7731242311], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4998000.0000, 
sim time next is 4998600.0000, 
raw observation next is [24.4, 95.5, 1.0, 2.0, 0.2143575853930653, 1.0, 2.0, 0.2143575853930653, 1.0, 2.0, 0.3412642570849375, 6.911200000000001, 6.9112, 121.94756008, 732889.9444112272, 732889.9444112268, 225341.974303611], 
processed observation next is [1.0, 0.8695652173913043, 0.4592592592592592, 0.955, 1.0, 1.0, 0.06471141118222058, 1.0, 1.0, 0.06471141118222058, 1.0, 1.0, 0.17658032135617188, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.26174640871829546, 0.2617464087182953, 0.4333499505838673], 
reward next is 0.5667, 
noisyNet noise sample is [array([-0.52278835], dtype=float32), 0.4845871]. 
=============================================
[2019-03-24 01:38:43,165] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.3011686e-02 2.7853954e-28 3.1421469e-23 7.0836968e-22 9.4698828e-01], sum to 1.0000
[2019-03-24 01:38:43,171] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1485
[2019-03-24 01:38:43,177] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.6107786018575028, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 700725.5892840923, 700725.5892840923, 160169.8517053871], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5004000.0000, 
sim time next is 5004600.0000, 
raw observation next is [23.8, 94.16666666666667, 1.0, 2.0, 0.2026096557909724, 1.0, 1.0, 0.2026096557909724, 1.0, 1.0, 0.3225611705550495, 6.9112, 6.9112, 121.94756008, 692705.5537110289, 692705.5537110289, 221448.9705089], 
processed observation next is [1.0, 0.9565217391304348, 0.43703703703703706, 0.9416666666666668, 1.0, 1.0, 0.050725780703538566, 1.0, 0.5, 0.050725780703538566, 1.0, 0.5, 0.15320146319381187, 0.0, 0.0, 0.8096049824067558, 0.24739484061108175, 0.24739484061108175, 0.4258634048248077], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.30623338], dtype=float32), -0.05015054]. 
=============================================
[2019-03-24 01:38:43,818] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.5690126e-01 3.7163430e-23 1.1102715e-19 3.5771844e-19 2.4309874e-01], sum to 1.0000
[2019-03-24 01:38:43,823] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7547
[2019-03-24 01:38:43,827] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.9, 95.33333333333334, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8699630217076836, 6.911200000000001, 6.9112, 121.9260426156618, 636936.0060003954, 636936.0060003949, 171941.3812408143], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5031600.0000, 
sim time next is 5032200.0000, 
raw observation next is [22.95, 94.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8626498992626421, 6.9112, 6.9112, 121.9260426156618, 634725.2310152889, 634725.2310152889, 170264.7359639528], 
processed observation next is [0.0, 0.21739130434782608, 0.4055555555555555, 0.9466666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8283123740783027, 0.0, 0.0, 0.8094621288201359, 0.2266875825054603, 0.2266875825054603, 0.32743218454606304], 
reward next is 0.6726, 
noisyNet noise sample is [array([-0.06040734], dtype=float32), 0.23611596]. 
=============================================
[2019-03-24 01:38:46,507] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 135535: loss 0.1660
[2019-03-24 01:38:46,509] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 135536: learning rate 0.0000
[2019-03-24 01:38:46,701] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 135630: loss -154.2043
[2019-03-24 01:38:46,702] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 135630: learning rate 0.0000
[2019-03-24 01:38:46,972] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 135774: loss 35.8035
[2019-03-24 01:38:46,974] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 135775: learning rate 0.0000
[2019-03-24 01:38:47,092] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 135834: loss 25.9630
[2019-03-24 01:38:47,095] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 135834: learning rate 0.0000
[2019-03-24 01:38:47,219] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 135894: loss -27.0317
[2019-03-24 01:38:47,221] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 135895: learning rate 0.0000
[2019-03-24 01:38:47,292] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 135936: loss 32.7079
[2019-03-24 01:38:47,294] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 135936: learning rate 0.0000
[2019-03-24 01:38:47,351] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 135963: loss -140.6315
[2019-03-24 01:38:47,353] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 135965: learning rate 0.0000
[2019-03-24 01:38:47,432] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 136007: loss -52.0116
[2019-03-24 01:38:47,435] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 136007: learning rate 0.0000
[2019-03-24 01:38:47,470] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 136023: loss -9.0606
[2019-03-24 01:38:47,473] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 136023: learning rate 0.0000
[2019-03-24 01:38:47,492] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 136028: loss 37.3227
[2019-03-24 01:38:47,493] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 136029: learning rate 0.0000
[2019-03-24 01:38:47,520] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 136047: loss 15.7011
[2019-03-24 01:38:47,522] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 136048: learning rate 0.0000
[2019-03-24 01:38:47,645] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 136109: loss -1.9855
[2019-03-24 01:38:47,646] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 136109: learning rate 0.0000
[2019-03-24 01:38:47,713] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 136148: loss 76.8257
[2019-03-24 01:38:47,714] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 136148: learning rate 0.0000
[2019-03-24 01:38:47,728] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 136156: loss -121.2154
[2019-03-24 01:38:47,732] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 136158: learning rate 0.0000
[2019-03-24 01:38:48,003] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 136299: loss 0.3682
[2019-03-24 01:38:48,006] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 136301: learning rate 0.0000
[2019-03-24 01:38:48,236] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 136414: loss 0.7884
[2019-03-24 01:38:48,238] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 136414: learning rate 0.0000
[2019-03-24 01:38:49,070] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6523601e-03 3.9473575e-22 2.1045207e-20 4.0231629e-18 9.9634761e-01], sum to 1.0000
[2019-03-24 01:38:49,079] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2601
[2019-03-24 01:38:49,086] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.13333333333333, 95.33333333333334, 1.0, 2.0, 0.2455937746797727, 1.0, 2.0, 0.2455937746797727, 1.0, 2.0, 0.39099328772104, 6.9112, 6.9112, 121.94756008, 839745.1649875711, 839745.1649875711, 236068.4616983003], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5125200.0000, 
sim time next is 5125800.0000, 
raw observation next is [26.41666666666666, 94.16666666666666, 1.0, 2.0, 0.2490050541027429, 1.0, 2.0, 0.2490050541027429, 1.0, 2.0, 0.3964241556600232, 6.9112, 6.9112, 121.94756008, 851415.6409238946, 851415.6409238946, 237272.9238279634], 
processed observation next is [0.0, 0.30434782608695654, 0.5339506172839504, 0.9416666666666665, 1.0, 1.0, 0.1059583977413606, 1.0, 1.0, 0.1059583977413606, 1.0, 1.0, 0.24553019457502898, 0.0, 0.0, 0.8096049824067558, 0.30407701461567666, 0.30407701461567666, 0.456294084284545], 
reward next is 0.5437, 
noisyNet noise sample is [array([0.1608449], dtype=float32), 0.29775798]. 
=============================================
[2019-03-24 01:38:50,716] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.0518113e-01 1.0540622e-21 2.3751066e-18 1.1849814e-16 4.9481887e-01], sum to 1.0000
[2019-03-24 01:38:50,721] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5605
[2019-03-24 01:38:50,725] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.16666666666666, 85.16666666666667, 1.0, 2.0, 0.2384699436081775, 1.0, 1.0, 0.2384699436081775, 1.0, 2.0, 0.3796519166480796, 6.9112, 6.9112, 121.94756008, 815374.0905655271, 815374.0905655271, 233574.129693146], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5170200.0000, 
sim time next is 5170800.0000, 
raw observation next is [27.03333333333333, 85.33333333333334, 1.0, 2.0, 0.2395690938361848, 1.0, 2.0, 0.2395690938361848, 1.0, 2.0, 0.381401799607891, 6.9112, 6.9112, 121.94756008, 819134.302119148, 819134.302119148, 233957.1349810092], 
processed observation next is [0.0, 0.8695652173913043, 0.55679012345679, 0.8533333333333334, 1.0, 1.0, 0.0947251117097438, 1.0, 1.0, 0.0947251117097438, 1.0, 1.0, 0.22675224950986372, 0.0, 0.0, 0.8096049824067558, 0.29254796504255287, 0.29254796504255287, 0.44991756727117155], 
reward next is 0.5501, 
noisyNet noise sample is [array([0.84704375], dtype=float32), 0.8083154]. 
=============================================
[2019-03-24 01:38:52,971] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.2061149e-06 6.2588847e-28 3.1582015e-23 6.5918555e-23 9.9999380e-01], sum to 1.0000
[2019-03-24 01:38:52,981] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2562
[2019-03-24 01:38:52,985] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.86666666666667, 94.66666666666667, 1.0, 2.0, 0.2511103001981799, 1.0, 2.0, 0.2511103001981799, 1.0, 2.0, 0.3997757760070376, 6.9112, 6.9112, 121.94756008, 858618.0782798347, 858618.0782798347, 238019.4925400137], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5199600.0000, 
sim time next is 5200200.0000, 
raw observation next is [23.8, 95.0, 1.0, 2.0, 0.2463781387867324, 1.0, 2.0, 0.2463781387867324, 1.0, 2.0, 0.3922420209242753, 6.911200000000001, 6.9112, 121.94756008, 842428.5713116557, 842428.5713116552, 236344.8311846828], 
processed observation next is [1.0, 0.17391304347826086, 0.43703703703703706, 0.95, 1.0, 1.0, 0.10283111760325285, 1.0, 1.0, 0.10283111760325285, 1.0, 1.0, 0.2403025261553441, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3008673468970199, 0.3008673468970197, 0.4545092907397746], 
reward next is 0.5455, 
noisyNet noise sample is [array([-0.35291544], dtype=float32), 0.3371459]. 
=============================================
[2019-03-24 01:38:54,657] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.5622324e-02 3.6601742e-12 6.5033125e-11 2.4638835e-10 9.4437772e-01], sum to 1.0000
[2019-03-24 01:38:54,668] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0717
[2019-03-24 01:38:54,684] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5312795759962652, 1.0, 2.0, 0.5312795759962652, 1.0, 2.0, 0.8458143875538892, 6.9112, 6.9112, 121.94756008, 1817693.69355417, 1817693.69355417, 359206.5946399259], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5220000.0000, 
sim time next is 5220600.0000, 
raw observation next is [27.15, 82.16666666666667, 1.0, 2.0, 0.578462471790476, 1.0, 2.0, 0.578462471790476, 1.0, 2.0, 0.9209310942979105, 6.911199999999999, 6.9112, 121.94756008, 1979301.765787827, 1979301.765787828, 383765.7724029685], 
processed observation next is [1.0, 0.43478260869565216, 0.561111111111111, 0.8216666666666668, 1.0, 1.0, 0.49816960927437626, 1.0, 1.0, 0.49816960927437626, 1.0, 1.0, 0.9011638678723882, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7068934877813668, 0.7068934877813672, 0.7380111007749394], 
reward next is 0.2620, 
noisyNet noise sample is [array([-0.01962982], dtype=float32), -1.6739646]. 
=============================================
[2019-03-24 01:38:58,551] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.1660357e-01 2.1667533e-14 1.6372469e-13 4.0689253e-12 8.3396479e-02], sum to 1.0000
[2019-03-24 01:38:58,555] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9041
[2019-03-24 01:38:58,562] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.01666666666667, 92.66666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8197448976600381, 6.911199999999999, 6.9112, 121.9260426156618, 608447.428903809, 608447.4289038095, 163014.5671400285], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5298600.0000, 
sim time next is 5299200.0000, 
raw observation next is [21.9, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8118041291946181, 6.9112, 6.9112, 121.9260426156618, 604465.2512699974, 604465.2512699974, 160954.6089131368], 
processed observation next is [1.0, 0.34782608695652173, 0.36666666666666664, 0.93, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7647551614932726, 0.0, 0.0, 0.8094621288201359, 0.21588044688214195, 0.21588044688214195, 0.3095280940637246], 
reward next is 0.6905, 
noisyNet noise sample is [array([0.6976594], dtype=float32), -1.4614413]. 
=============================================
[2019-03-24 01:39:02,157] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 143371: loss 0.0987
[2019-03-24 01:39:02,161] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 143372: learning rate 0.0000
[2019-03-24 01:39:02,493] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 143542: loss 0.5436
[2019-03-24 01:39:02,497] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 143542: learning rate 0.0000
[2019-03-24 01:39:02,898] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 143733: loss 0.2251
[2019-03-24 01:39:02,900] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 143734: learning rate 0.0000
[2019-03-24 01:39:03,034] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 143804: loss 0.1463
[2019-03-24 01:39:03,037] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 143804: learning rate 0.0000
[2019-03-24 01:39:03,298] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 143933: loss 0.0039
[2019-03-24 01:39:03,301] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 143933: learning rate 0.0000
[2019-03-24 01:39:03,337] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 143956: loss 0.0035
[2019-03-24 01:39:03,338] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 143956: learning rate 0.0000
[2019-03-24 01:39:03,382] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 143977: loss 0.0259
[2019-03-24 01:39:03,387] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 143977: learning rate 0.0000
[2019-03-24 01:39:03,427] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 143995: loss 0.0378
[2019-03-24 01:39:03,429] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 143996: learning rate 0.0000
[2019-03-24 01:39:03,470] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 144019: loss 0.0573
[2019-03-24 01:39:03,472] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 144019: learning rate 0.0000
[2019-03-24 01:39:03,508] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 144040: loss 0.0518
[2019-03-24 01:39:03,515] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 144041: learning rate 0.0000
[2019-03-24 01:39:03,559] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 144062: loss 0.0465
[2019-03-24 01:39:03,561] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 144062: loss 0.0198
[2019-03-24 01:39:03,563] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 144062: learning rate 0.0000
[2019-03-24 01:39:03,563] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 144062: learning rate 0.0000
[2019-03-24 01:39:03,839] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 144204: loss 0.0052
[2019-03-24 01:39:03,840] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 144204: learning rate 0.0000
[2019-03-24 01:39:03,885] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 144225: loss 0.0147
[2019-03-24 01:39:03,890] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 144226: learning rate 0.0000
[2019-03-24 01:39:04,096] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 144327: loss 0.0354
[2019-03-24 01:39:04,099] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 144329: learning rate 0.0000
[2019-03-24 01:39:04,555] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 144553: loss 0.0517
[2019-03-24 01:39:04,559] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 144555: learning rate 0.0000
[2019-03-24 01:39:09,339] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.4350097e-05 1.9653145e-22 7.5529358e-20 1.6850893e-19 9.9993563e-01], sum to 1.0000
[2019-03-24 01:39:09,348] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7925
[2019-03-24 01:39:09,353] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.98333333333333, 81.0, 1.0, 2.0, 0.282166659306637, 1.0, 2.0, 0.282166659306637, 1.0, 2.0, 0.4492185111427054, 6.911200000000001, 6.9112, 121.94756008, 964875.5065431225, 964875.506543122, 249320.2699375196], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5505000.0000, 
sim time next is 5505600.0000, 
raw observation next is [26.96666666666667, 81.0, 1.0, 2.0, 0.2107720615324041, 1.0, 2.0, 0.2107720615324041, 1.0, 2.0, 0.335555986326405, 6.9112, 6.9112, 121.94756008, 720625.2543756946, 720625.2543756946, 224145.621569151], 
processed observation next is [1.0, 0.7391304347826086, 0.554320987654321, 0.81, 1.0, 1.0, 0.06044293039571917, 1.0, 1.0, 0.06044293039571917, 1.0, 1.0, 0.16944498290800622, 0.0, 0.0, 0.8096049824067558, 0.2573661622770338, 0.2573661622770338, 0.4310492722483673], 
reward next is 0.5690, 
noisyNet noise sample is [array([-0.03354885], dtype=float32), -0.84760433]. 
=============================================
[2019-03-24 01:39:10,126] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.4652781e-04 3.6106132e-24 2.9768988e-21 5.1494703e-21 9.9915349e-01], sum to 1.0000
[2019-03-24 01:39:10,134] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3403
[2019-03-24 01:39:10,138] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.2, 86.0, 1.0, 2.0, 0.2225758709982868, 1.0, 2.0, 0.2225758709982868, 1.0, 2.0, 0.3543480354193266, 6.9112, 6.9112, 121.94756008, 761002.2604064599, 761002.2604064599, 228111.2397729972], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5521200.0000, 
sim time next is 5521800.0000, 
raw observation next is [26.15, 86.5, 1.0, 2.0, 0.2232651220799208, 1.0, 2.0, 0.2232651220799208, 1.0, 2.0, 0.3554453455886286, 6.9112, 6.9112, 121.94756008, 763360.0306507377, 763360.0306507377, 228345.209624651], 
processed observation next is [1.0, 0.9130434782608695, 0.524074074074074, 0.865, 1.0, 1.0, 0.07531562152371524, 1.0, 1.0, 0.07531562152371524, 1.0, 1.0, 0.19430668198578574, 0.0, 0.0, 0.8096049824067558, 0.27262858237526344, 0.27262858237526344, 0.43912540312432885], 
reward next is 0.5609, 
noisyNet noise sample is [array([1.1743357], dtype=float32), -0.3473603]. 
=============================================
[2019-03-24 01:39:14,386] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.6275027e-03 6.4751879e-26 1.0101315e-23 5.0925356e-22 9.9437249e-01], sum to 1.0000
[2019-03-24 01:39:14,395] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0989
[2019-03-24 01:39:14,400] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.65, 92.5, 1.0, 2.0, 0.2288177215448736, 1.0, 2.0, 0.2288177215448736, 1.0, 2.0, 0.3642852647723732, 6.911199999999999, 6.9112, 121.94756008, 782354.4674517574, 782354.4674517579, 230239.7595129059], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5599800.0000, 
sim time next is 5600400.0000, 
raw observation next is [25.7, 92.66666666666667, 1.0, 2.0, 0.2301386266063552, 1.0, 2.0, 0.2301386266063552, 1.0, 2.0, 0.3663881886491264, 6.911200000000001, 6.9112, 121.94756008, 786873.1136517265, 786873.113651726, 230692.991462321], 
processed observation next is [1.0, 0.8260869565217391, 0.5074074074074074, 0.9266666666666667, 1.0, 1.0, 0.08349836500756572, 1.0, 1.0, 0.08349836500756572, 1.0, 1.0, 0.20798523581140801, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2810261120184738, 0.2810261120184736, 0.44364036819677116], 
reward next is 0.5564, 
noisyNet noise sample is [array([-0.82018715], dtype=float32), -0.5314385]. 
=============================================
[2019-03-24 01:39:15,638] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 01:39:15,641] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:39:15,643] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:39:15,643] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:39:15,646] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:39:15,646] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:39:15,647] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:39:15,648] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:39:15,648] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:39:15,649] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:39:15,651] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:39:15,661] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run7
[2019-03-24 01:39:15,684] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run7
[2019-03-24 01:39:15,684] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run7
[2019-03-24 01:39:15,704] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run7
[2019-03-24 01:39:15,725] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run7
[2019-03-24 01:39:22,966] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.06344529]
[2019-03-24 01:39:22,967] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.05, 40.5, 1.0, 2.0, 0.3259177216545214, 1.0, 2.0, 0.3259177216545214, 1.0, 2.0, 0.530971095778863, 6.9112, 6.9112, 121.94756008, 1189390.805070221, 1189390.805070221, 265098.5311002118]
[2019-03-24 01:39:22,968] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:39:22,971] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.5619876e-04 4.6584721e-25 5.3893144e-22 4.2141944e-21 9.9984384e-01], sampled 0.18893979268475214
[2019-03-24 01:39:45,922] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.06344529]
[2019-03-24 01:39:45,926] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.03333333333333, 39.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2388802032118726, 6.9112, 6.9112, 121.94756008, 531557.0603226229, 531557.0603226229, 201836.8869504157]
[2019-03-24 01:39:45,928] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:39:45,930] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.6347457e-05 2.0278998e-27 4.5982611e-24 4.3856018e-23 9.9993360e-01], sampled 0.5300259905245462
[2019-03-24 01:39:50,949] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.06344529]
[2019-03-24 01:39:50,951] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.869194335, 40.73809072166667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.911200000000001, 6.9112, 121.94756008, 387110.3932279485, 387110.393227948, 174219.1035891125]
[2019-03-24 01:39:50,952] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:39:50,955] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.5399261e-05 1.0029652e-26 1.8671599e-23 1.6800386e-22 9.9991465e-01], sampled 0.18411209490445957
[2019-03-24 01:40:03,862] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.06344529]
[2019-03-24 01:40:03,863] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [37.0, 25.0, 1.0, 2.0, 0.3454216133921042, 1.0, 2.0, 0.3454216133921042, 1.0, 2.0, 0.5507951420923752, 6.911200000000001, 6.9112, 121.94756008, 1199809.716683735, 1199809.716683734, 274047.9160111108]
[2019-03-24 01:40:03,864] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:40:03,868] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.0967715e-05 7.3478826e-27 1.4204990e-23 1.2931775e-22 9.9991906e-01], sampled 0.7264910502296872
[2019-03-24 01:40:08,480] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.06344529]
[2019-03-24 01:40:08,481] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.6, 70.0, 1.0, 2.0, 0.5420181698678113, 1.0, 2.0, 0.5420181698678113, 1.0, 2.0, 0.862910578728977, 6.9112, 6.9112, 121.94756008, 1854472.322257494, 1854472.322257494, 364690.4038557832]
[2019-03-24 01:40:08,484] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:40:08,487] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.63055868e-05 5.13078831e-27 1.03446636e-23 9.55864526e-23
 9.99923706e-01], sampled 0.5028563941617737
[2019-03-24 01:40:32,556] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.06344529]
[2019-03-24 01:40:32,557] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [34.66666666666666, 52.0, 1.0, 2.0, 0.2528680994160049, 1.0, 2.0, 0.2528680994160049, 1.0, 2.0, 0.4025742496093388, 6.911200000000001, 6.9112, 121.94756008, 864631.8872679494, 864631.887267949, 238644.7449720323]
[2019-03-24 01:40:32,558] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:40:32,563] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.2003689e-05 1.1543315e-28 3.7299451e-25 3.9571263e-24 9.9995804e-01], sampled 0.631806637626905
[2019-03-24 01:40:56,390] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.06344529]
[2019-03-24 01:40:56,392] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.0, 96.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.911200000000001, 6.9112, 121.94756008, 362155.5118667356, 362155.5118667352, 169697.4830770677]
[2019-03-24 01:40:56,392] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:40:56,394] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.1044528e-05 1.1582932e-27 2.8171663e-24 2.7428422e-23 9.9993896e-01], sampled 0.14013749106113393
[2019-03-24 01:40:59,765] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4393.8122 2875764154.0094 8.0000
[2019-03-24 01:41:00,290] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4489.4114 2940779206.0371 28.0000
[2019-03-24 01:41:00,312] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4275.9573 2920152679.8633 33.0000
[2019-03-24 01:41:00,364] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4609.9118 2894648914.3524 12.0000
[2019-03-24 01:41:00,446] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4511.2552 3107502958.5790 0.0000
[2019-03-24 01:41:01,460] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 150000, evaluation results [150000.0, 4511.25519736341, 3107502958.5789657, 0.0, 4609.911759045645, 2894648914.3524227, 12.0, 4393.812221699318, 2875764154.0093703, 8.0, 4489.411365254514, 2940779206.037067, 28.0, 4275.9572757857495, 2920152679.8633223, 33.0]
[2019-03-24 01:41:04,079] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 151370: loss 0.3750
[2019-03-24 01:41:04,081] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 151371: learning rate 0.0000
[2019-03-24 01:41:04,291] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 151476: loss 0.2417
[2019-03-24 01:41:04,292] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 151476: learning rate 0.0000
[2019-03-24 01:41:04,962] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 151830: loss 0.2361
[2019-03-24 01:41:04,964] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 151830: learning rate 0.0000
[2019-03-24 01:41:05,009] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 151855: loss 0.1035
[2019-03-24 01:41:05,012] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 151855: learning rate 0.0000
[2019-03-24 01:41:05,057] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 151876: loss 0.0692
[2019-03-24 01:41:05,062] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 151876: learning rate 0.0000
[2019-03-24 01:41:05,219] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 151963: loss 0.2485
[2019-03-24 01:41:05,220] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 151963: learning rate 0.0000
[2019-03-24 01:41:05,268] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 151989: loss 0.2365
[2019-03-24 01:41:05,272] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 151990: learning rate 0.0000
[2019-03-24 01:41:05,356] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 152033: loss 0.0027
[2019-03-24 01:41:05,362] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 152033: learning rate 0.0000
[2019-03-24 01:41:05,366] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 152038: loss 0.0130
[2019-03-24 01:41:05,367] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 152039: loss 0.0376
[2019-03-24 01:41:05,372] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 152042: learning rate 0.0000
[2019-03-24 01:41:05,372] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 152042: learning rate 0.0000
[2019-03-24 01:41:05,442] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 152074: loss 0.1086
[2019-03-24 01:41:05,446] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 152075: learning rate 0.0000
[2019-03-24 01:41:05,476] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 152093: loss 0.1793
[2019-03-24 01:41:05,477] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 152093: learning rate 0.0000
[2019-03-24 01:41:05,614] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 152165: loss 0.2940
[2019-03-24 01:41:05,619] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 152167: learning rate 0.0000
[2019-03-24 01:41:05,697] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 152208: loss 0.3023
[2019-03-24 01:41:05,698] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 152209: learning rate 0.0000
[2019-03-24 01:41:06,001] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 152366: loss 0.0002
[2019-03-24 01:41:06,004] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 152366: learning rate 0.0000
[2019-03-24 01:41:06,187] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 152459: loss 0.0576
[2019-03-24 01:41:06,189] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 152459: learning rate 0.0000
[2019-03-24 01:41:08,758] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.8048836e-04 5.9714123e-25 3.0258722e-20 7.9750615e-20 9.9921954e-01], sum to 1.0000
[2019-03-24 01:41:08,765] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1051
[2019-03-24 01:41:08,771] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.15, 70.66666666666667, 1.0, 2.0, 0.1972686855368101, 1.0, 2.0, 0.1972686855368101, 1.0, 2.0, 0.3140581719671655, 6.9112, 6.9112, 121.94756008, 674437.1896997218, 674437.1896997218, 219704.6365293951], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5767800.0000, 
sim time next is 5768400.0000, 
raw observation next is [27.0, 71.33333333333334, 1.0, 2.0, 0.1966343039003648, 1.0, 2.0, 0.1966343039003648, 1.0, 2.0, 0.313048215741577, 6.9112, 6.9112, 121.94756008, 672267.366681445, 672267.366681445, 219498.5119124062], 
processed observation next is [0.0, 0.782608695652174, 0.5555555555555556, 0.7133333333333334, 1.0, 1.0, 0.04361226654805332, 1.0, 1.0, 0.04361226654805332, 1.0, 1.0, 0.14131026967697122, 0.0, 0.0, 0.8096049824067558, 0.2400954881005161, 0.2400954881005161, 0.42211252290847345], 
reward next is 0.5779, 
noisyNet noise sample is [array([-0.7080693], dtype=float32), -0.2886883]. 
=============================================
[2019-03-24 01:41:09,662] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5629193e-01 2.9281250e-25 1.1880234e-22 7.6024356e-23 8.4370810e-01], sum to 1.0000
[2019-03-24 01:41:09,670] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7297
[2019-03-24 01:41:09,675] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.83333333333334, 85.66666666666666, 1.0, 1.0, 0.16, 1.0, 1.0, 0.16, 1.0, 2.0, 0.2576574903237559, 6.9112, 6.9112, 121.94756008, 574247.8783531073, 574247.8783531073, 207155.0545564145], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5791200.0000, 
sim time next is 5791800.0000, 
raw observation next is [22.76666666666667, 85.83333333333334, 1.0, 2.0, 0.1607810006140841, 1.0, 2.0, 0.1607810006140841, 1.0, 2.0, 0.258161634954667, 6.9112, 6.9112, 121.94756008, 572088.4115338062, 572088.4115338062, 207860.4816514272], 
processed observation next is [1.0, 0.0, 0.3987654320987655, 0.8583333333333334, 1.0, 1.0, 0.0009297626358143966, 1.0, 1.0, 0.0009297626358143966, 1.0, 1.0, 0.07270204369333372, 0.0, 0.0, 0.8096049824067558, 0.20431728983350222, 0.20431728983350222, 0.39973169548351384], 
reward next is 0.6003, 
noisyNet noise sample is [array([-0.54937416], dtype=float32), 1.1448642]. 
=============================================
[2019-03-24 01:41:18,210] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 3.9339728e-34 1.9982217e-36 1.0840374e-11], sum to 1.0000
[2019-03-24 01:41:18,216] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0676
[2019-03-24 01:41:18,218] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.11666666666667, 76.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7794908378683439, 6.9112, 6.9112, 121.9260426156618, 580407.807674649, 580407.807674649, 156974.7733922711], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5953800.0000, 
sim time next is 5954400.0000, 
raw observation next is [23.9, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7766339506758934, 6.9112, 6.9112, 121.9260426156618, 578429.2122029299, 578429.2122029299, 156524.8413844706], 
processed observation next is [1.0, 0.9565217391304348, 0.4407407407407407, 0.78, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7207924383448666, 0.0, 0.0, 0.8094621288201359, 0.20658186150104638, 0.20658186150104638, 0.30100931035475115], 
reward next is 0.6990, 
noisyNet noise sample is [array([-0.34659094], dtype=float32), 2.3941135]. 
=============================================
[2019-03-24 01:41:19,442] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 159327: loss 27.1905
[2019-03-24 01:41:19,444] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 159328: learning rate 0.0000
[2019-03-24 01:41:19,656] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 159434: loss -21.9563
[2019-03-24 01:41:19,662] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 159435: learning rate 0.0000
[2019-03-24 01:41:19,987] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.1763904e-38 9.8148704e-35 6.8636036e-35 7.9860129e-12], sum to 1.0000
[2019-03-24 01:41:19,997] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1328
[2019-03-24 01:41:20,001] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.58333333333334, 80.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7163130993766397, 6.911200000000001, 6.9112, 121.9260426156618, 535227.6402469504, 535227.64024695, 147198.6757892116], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5965800.0000, 
sim time next is 5966400.0000, 
raw observation next is [22.56666666666667, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7120471603511883, 6.911200000000001, 6.9112, 121.9260426156618, 532081.4392613106, 532081.4392613103, 146508.7166936651], 
processed observation next is [1.0, 0.043478260869565216, 0.39135802469135816, 0.8, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6400589504389853, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19002908545046807, 0.19002908545046795, 0.28174753210320214], 
reward next is 0.7183, 
noisyNet noise sample is [array([0.19642101], dtype=float32), 0.18206134]. 
=============================================
[2019-03-24 01:41:20,328] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 159787: loss -60.2090
[2019-03-24 01:41:20,329] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 159787: learning rate 0.0000
[2019-03-24 01:41:20,427] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 159837: loss -62.7974
[2019-03-24 01:41:20,428] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 159837: learning rate 0.0000
[2019-03-24 01:41:20,695] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 159970: loss -62.8660
[2019-03-24 01:41:20,698] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 159972: learning rate 0.0000
[2019-03-24 01:41:20,729] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 159992: loss -21.5308
[2019-03-24 01:41:20,731] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 159992: learning rate 0.0000
[2019-03-24 01:41:20,732] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 159992: loss -194.6644
[2019-03-24 01:41:20,734] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 159992: learning rate 0.0000
[2019-03-24 01:41:20,752] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 160004: loss -127.7511
[2019-03-24 01:41:20,757] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 160004: learning rate 0.0000
[2019-03-24 01:41:20,820] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 160030: loss -27.3763
[2019-03-24 01:41:20,821] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 160031: learning rate 0.0000
[2019-03-24 01:41:20,822] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 160032: loss -41.3567
[2019-03-24 01:41:20,824] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 160032: learning rate 0.0000
[2019-03-24 01:41:20,843] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 160042: loss -80.9426
[2019-03-24 01:41:20,851] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 160043: learning rate 0.0000
[2019-03-24 01:41:21,018] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 160133: loss -58.3001
[2019-03-24 01:41:21,020] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 160133: learning rate 0.0000
[2019-03-24 01:41:21,122] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 160181: loss -27.4105
[2019-03-24 01:41:21,126] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 160182: learning rate 0.0000
[2019-03-24 01:41:21,231] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 160239: loss 1.2329
[2019-03-24 01:41:21,234] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 160239: loss -53.3479
[2019-03-24 01:41:21,234] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 160239: learning rate 0.0000
[2019-03-24 01:41:21,237] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 160241: learning rate 0.0000
[2019-03-24 01:41:21,529] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9999487e-01 8.9705194e-19 4.6229900e-17 3.9115101e-17 5.1750494e-06], sum to 1.0000
[2019-03-24 01:41:21,533] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6153
[2019-03-24 01:41:21,540] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1567667.588828764 W.
[2019-03-24 01:41:21,545] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 58.16666666666666, 1.0, 2.0, 0.6873883479238809, 1.0, 1.0, 0.6873883479238809, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1567667.588828764, 1567667.588828764, 299418.2794357665], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6015000.0000, 
sim time next is 6015600.0000, 
raw observation next is [29.0, 58.0, 1.0, 2.0, 0.6894895927123651, 1.0, 2.0, 0.6894895927123651, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1572440.347188275, 1572440.347188275, 300204.0290535699], 
processed observation next is [1.0, 0.6521739130434783, 0.6296296296296297, 0.58, 1.0, 1.0, 0.6303447532290061, 1.0, 1.0, 0.6303447532290061, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5615858382815269, 0.5615858382815269, 0.5773154404876344], 
reward next is 0.4227, 
noisyNet noise sample is [array([0.6165665], dtype=float32), 0.32931027]. 
=============================================
[2019-03-24 01:41:21,667] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 160465: loss -6.1505
[2019-03-24 01:41:21,670] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 160466: learning rate 0.0000
[2019-03-24 01:41:31,482] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9993503e-01 6.9150083e-20 3.5931328e-18 1.1076534e-18 6.4964515e-05], sum to 1.0000
[2019-03-24 01:41:31,490] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6643
[2019-03-24 01:41:31,497] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1861540.651276383 W.
[2019-03-24 01:41:31,500] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 51.0, 1.0, 2.0, 0.8161227362925354, 1.0, 2.0, 0.8161227362925354, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260425891336, 1861540.651276383, 1861540.651276383, 350459.6511698364], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6195600.0000, 
sim time next is 6196200.0000, 
raw observation next is [29.88333333333333, 51.83333333333333, 1.0, 2.0, 0.369442174424065, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5891575646785743, 6.9112, 6.9112, 121.9260426156537, 855823.3191765787, 855823.3191765787, 214594.1489391724], 
processed observation next is [1.0, 0.7391304347826086, 0.6623456790123455, 0.5183333333333333, 1.0, 1.0, 0.24933592193341075, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4864469558482178, 0.0, 0.0, 0.8094621288200822, 0.30565118542020664, 0.30565118542020664, 0.4126810556522546], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.4427676], dtype=float32), 0.19345328]. 
=============================================
[2019-03-24 01:41:34,243] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9995351e-01 2.0706511e-29 1.3744697e-24 1.5878619e-26 4.6453304e-05], sum to 1.0000
[2019-03-24 01:41:34,250] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3000
[2019-03-24 01:41:34,258] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.15, 76.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9212724571467027, 6.9112, 6.9112, 121.9260426156618, 671784.3178477888, 671784.3178477888, 179257.0565953298], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6257400.0000, 
sim time next is 6258000.0000, 
raw observation next is [26.3, 76.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9288369020432984, 6.911200000000001, 6.9112, 121.9260426156618, 676259.5536858372, 676259.5536858367, 180461.6630344682], 
processed observation next is [0.0, 0.43478260869565216, 0.5296296296296297, 0.7633333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9110461275541228, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24152126917351327, 0.2415212691735131, 0.3470416596816696], 
reward next is 0.6530, 
noisyNet noise sample is [array([-0.43359575], dtype=float32), 0.65412235]. 
=============================================
[2019-03-24 01:41:34,277] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[67.28103 ]
 [67.20063 ]
 [67.12208 ]
 [67.055626]
 [66.99813 ]], R is [[67.31452179]
 [67.29665375]
 [67.28124237]
 [67.26768494]
 [67.25592804]].
[2019-03-24 01:41:35,551] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 167411: loss 5.1206
[2019-03-24 01:41:35,552] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 167411: learning rate 0.0000
[2019-03-24 01:41:35,590] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 167433: loss 4.5914
[2019-03-24 01:41:35,592] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 167433: learning rate 0.0000
[2019-03-24 01:41:36,430] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 167838: loss 3.5321
[2019-03-24 01:41:36,434] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 167841: learning rate 0.0000
[2019-03-24 01:41:36,439] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 167842: loss 2.9685
[2019-03-24 01:41:36,442] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 167842: learning rate 0.0000
[2019-03-24 01:41:36,611] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 167927: loss 1.2783
[2019-03-24 01:41:36,615] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 167929: learning rate 0.0000
[2019-03-24 01:41:36,632] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 167935: loss 2.5248
[2019-03-24 01:41:36,635] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 167937: learning rate 0.0000
[2019-03-24 01:41:36,750] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 167994: loss 1.2310
[2019-03-24 01:41:36,754] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 167995: learning rate 0.0000
[2019-03-24 01:41:36,827] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 168037: loss 2.0483
[2019-03-24 01:41:36,833] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 168037: learning rate 0.0000
[2019-03-24 01:41:36,876] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 168056: loss 1.1579
[2019-03-24 01:41:36,877] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 168056: learning rate 0.0000
[2019-03-24 01:41:36,925] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 168076: loss 1.1644
[2019-03-24 01:41:36,926] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 168076: learning rate 0.0000
[2019-03-24 01:41:37,005] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 168116: loss 0.7627
[2019-03-24 01:41:37,007] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 168117: learning rate 0.0000
[2019-03-24 01:41:37,029] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 168130: loss 2.0434
[2019-03-24 01:41:37,034] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 168131: learning rate 0.0000
[2019-03-24 01:41:37,160] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 168194: loss 1.5426
[2019-03-24 01:41:37,161] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 168194: learning rate 0.0000
[2019-03-24 01:41:37,223] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 168225: loss 0.4710
[2019-03-24 01:41:37,225] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 168225: learning rate 0.0000
[2019-03-24 01:41:37,350] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 168289: loss 1.3904
[2019-03-24 01:41:37,352] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 168289: learning rate 0.0000
[2019-03-24 01:41:37,928] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 168575: loss 1.4450
[2019-03-24 01:41:37,931] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 168576: learning rate 0.0000
[2019-03-24 01:41:38,390] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 4.5050256e-34 4.2649112e-28 2.3024568e-30 1.4178879e-12], sum to 1.0000
[2019-03-24 01:41:38,398] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2240
[2019-03-24 01:41:38,403] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.06666666666667, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9014404697424985, 6.9112, 6.9112, 121.9260426156618, 661283.4324323619, 661283.4324323619, 175801.5239667608], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6322800.0000, 
sim time next is 6323400.0000, 
raw observation next is [24.05, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8989428366563316, 6.911200000000001, 6.9112, 121.9260426156618, 659604.4912601677, 659604.4912601673, 175435.6913497594], 
processed observation next is [0.0, 0.17391304347826086, 0.4462962962962963, 0.88, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8736785458204144, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23557303259291704, 0.2355730325929169, 0.3373763295187681], 
reward next is 0.6626, 
noisyNet noise sample is [array([-0.09924769], dtype=float32), 0.7792995]. 
=============================================
[2019-03-24 01:41:46,371] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6295565e-04 5.8928838e-19 1.9530210e-15 7.3808696e-14 9.9983704e-01], sum to 1.0000
[2019-03-24 01:41:46,379] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6701
[2019-03-24 01:41:46,385] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.4, 85.0, 1.0, 2.0, 0.3337268012234183, 1.0, 2.0, 0.3337268012234183, 1.0, 2.0, 0.5313039362708127, 6.9112, 6.9112, 121.94756008, 1141317.907912139, 1141317.907912139, 269269.3251910455], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6496200.0000, 
sim time next is 6496800.0000, 
raw observation next is [26.36666666666667, 85.33333333333333, 1.0, 2.0, 0.3077825567306765, 1.0, 2.0, 0.3077825567306765, 1.0, 2.0, 0.4899998540933134, 6.9112, 6.9112, 121.94756008, 1052529.816273969, 1052529.816273969, 259046.2065244463], 
processed observation next is [1.0, 0.17391304347826086, 0.5320987654320989, 0.8533333333333333, 1.0, 1.0, 0.17593161515556727, 1.0, 1.0, 0.17593161515556727, 1.0, 1.0, 0.36249981761664174, 0.0, 0.0, 0.8096049824067558, 0.3759035058121318, 0.3759035058121318, 0.4981657817777813], 
reward next is 0.5018, 
noisyNet noise sample is [array([0.33271173], dtype=float32), 0.77478087]. 
=============================================
[2019-03-24 01:41:51,161] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 01:41:51,162] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:41:51,163] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:41:51,164] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:41:51,166] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:41:51,164] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:41:51,167] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:41:51,170] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:41:51,167] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:41:51,170] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:41:51,174] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:41:51,184] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run8
[2019-03-24 01:41:51,208] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run8
[2019-03-24 01:41:51,231] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run8
[2019-03-24 01:41:51,234] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run8
[2019-03-24 01:41:51,254] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run8
[2019-03-24 01:42:59,188] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.07089483]
[2019-03-24 01:42:59,190] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.16666666666667, 99.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2335109599594264, 6.911199999999999, 6.9112, 121.94756008, 521917.9375752214, 521917.9375752218, 199479.7653129989]
[2019-03-24 01:42:59,190] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:42:59,193] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.4059654e-04 8.3759721e-20 4.5987394e-17 2.2248244e-16 9.9975938e-01], sampled 0.007113387395251469
[2019-03-24 01:43:34,369] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.07089483]
[2019-03-24 01:43:34,372] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.83333333333334, 60.33333333333334, 1.0, 2.0, 0.1610791227461049, 1.0, 2.0, 0.1610791227461049, 1.0, 2.0, 0.2665198470549678, 6.9112, 6.9112, 121.94756008, 597319.3572448392, 597319.3572448392, 206351.8162786313]
[2019-03-24 01:43:34,372] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:43:34,375] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.7672958e-04 1.7906117e-19 8.8347475e-17 4.1538962e-16 9.9972326e-01], sampled 0.4569566643567916
[2019-03-24 01:43:35,057] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.07089483]
[2019-03-24 01:43:35,058] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.74762669, 67.04973172, 1.0, 2.0, 0.1640375592467234, 1.0, 2.0, 0.1640375592467234, 1.0, 2.0, 0.2771358665636509, 6.9112, 6.9112, 121.94756008, 617680.9466578715, 617680.9466578715, 206170.9572786716]
[2019-03-24 01:43:35,059] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:43:35,062] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.2621168e-04 6.8704336e-20 3.8847598e-17 1.8917799e-16 9.9977380e-01], sampled 0.008678309442470833
[2019-03-24 01:43:35,396] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4278.2134 2919986564.9304 33.0000
[2019-03-24 01:43:35,750] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4393.8977 2875710946.4137 8.0000
[2019-03-24 01:43:35,755] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4491.0539 2940674698.0736 28.0000
[2019-03-24 01:43:35,781] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4611.5170 2894543206.5945 12.0000
[2019-03-24 01:43:35,877] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4512.2102 3107360593.6163 1.0000
[2019-03-24 01:43:36,889] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 175000, evaluation results [175000.0, 4512.210155535908, 3107360593.6162505, 1.0, 4611.516974817517, 2894543206.5945463, 12.0, 4393.897706949222, 2875710946.413729, 8.0, 4491.053897292393, 2940674698.0735617, 28.0, 4278.213350961486, 2919986564.9304333, 33.0]
[2019-03-24 01:43:37,613] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 175377: loss 1.1587
[2019-03-24 01:43:37,616] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 175378: learning rate 0.0000
[2019-03-24 01:43:37,839] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 175494: loss 1.7982
[2019-03-24 01:43:37,840] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 175494: learning rate 0.0000
[2019-03-24 01:43:38,509] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 175842: loss 10.3970
[2019-03-24 01:43:38,512] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 175844: learning rate 0.0000
[2019-03-24 01:43:38,543] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 175856: loss 12.0860
[2019-03-24 01:43:38,545] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 175856: learning rate 0.0000
[2019-03-24 01:43:38,651] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 175915: loss 27.7399
[2019-03-24 01:43:38,652] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 175915: learning rate 0.0000
[2019-03-24 01:43:38,700] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 175935: loss 28.3505
[2019-03-24 01:43:38,701] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 175935: learning rate 0.0000
[2019-03-24 01:43:38,760] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 175970: loss 11.3236
[2019-03-24 01:43:38,761] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 175970: learning rate 0.0000
[2019-03-24 01:43:38,815] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 175998: loss -24.4786
[2019-03-24 01:43:38,816] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 175999: learning rate 0.0000
[2019-03-24 01:43:38,855] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 176018: loss -18.8145
[2019-03-24 01:43:38,857] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 176018: learning rate 0.0000
[2019-03-24 01:43:38,886] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 176031: loss 41.6042
[2019-03-24 01:43:38,888] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 176031: learning rate 0.0000
[2019-03-24 01:43:39,069] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 176127: loss -6.9910
[2019-03-24 01:43:39,070] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 176127: learning rate 0.0000
[2019-03-24 01:43:39,093] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 176137: loss -50.5445
[2019-03-24 01:43:39,095] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 176137: learning rate 0.0000
[2019-03-24 01:43:39,144] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 176166: loss -25.6625
[2019-03-24 01:43:39,146] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 176166: learning rate 0.0000
[2019-03-24 01:43:39,175] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 176179: loss -13.7339
[2019-03-24 01:43:39,178] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 176179: learning rate 0.0000
[2019-03-24 01:43:39,262] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 176224: loss 37.7907
[2019-03-24 01:43:39,263] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 176224: learning rate 0.0000
[2019-03-24 01:43:39,681] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 176435: loss 0.8878
[2019-03-24 01:43:39,683] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 176436: learning rate 0.0000
[2019-03-24 01:43:47,259] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.00000000e+00 3.26425712e-24 1.14078505e-17 2.01834137e-19
 6.89740209e-11], sum to 1.0000
[2019-03-24 01:43:47,267] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7514
[2019-03-24 01:43:47,271] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.5, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5112991365686871, 6.9112, 6.9112, 121.9260426156618, 370730.5295232001, 370730.5295232001, 117994.6882929235], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6760800.0000, 
sim time next is 6761400.0000, 
raw observation next is [19.76666666666667, 74.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5607275473029907, 6.9112, 6.9112, 121.9260426156618, 407020.2715480354, 407020.2715480354, 122203.1069581928], 
processed observation next is [1.0, 0.2608695652173913, 0.2876543209876544, 0.745, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4509094341287383, 0.0, 0.0, 0.8094621288201359, 0.14536438269572693, 0.14536438269572693, 0.23500597491960154], 
reward next is 0.7650, 
noisyNet noise sample is [array([0.5666239], dtype=float32), -2.4815147]. 
=============================================
[2019-03-24 01:43:47,789] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.8676277e-24 7.8097219e-17 1.8986619e-19 3.6165266e-09], sum to 1.0000
[2019-03-24 01:43:47,800] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1031
[2019-03-24 01:43:47,810] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.1, 62.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5708965417061681, 6.911200000000001, 6.9112, 121.9260426156618, 417867.5302177193, 417867.5302177188, 124492.1864236017], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6766800.0000, 
sim time next is 6767400.0000, 
raw observation next is [22.35, 61.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5716236238676268, 6.9112, 6.9112, 121.9260426156618, 418748.0746044568, 418748.0746044568, 124711.2161458923], 
processed observation next is [1.0, 0.30434782608695654, 0.38333333333333336, 0.6116666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.46452952983453344, 0.0, 0.0, 0.8094621288201359, 0.149552883787306, 0.149552883787306, 0.23982926181902364], 
reward next is 0.7602, 
noisyNet noise sample is [array([0.32972854], dtype=float32), -0.030226039]. 
=============================================
[2019-03-24 01:43:49,767] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.4899550e-31 4.8322527e-24 2.3013072e-22 2.2246898e-08], sum to 1.0000
[2019-03-24 01:43:49,778] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1562
[2019-03-24 01:43:49,785] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.43333333333334, 59.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7548637953101377, 6.9112, 6.9112, 121.9260426156618, 560584.57438338, 560584.57438338, 154856.3247731346], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6802800.0000, 
sim time next is 6803400.0000, 
raw observation next is [27.26666666666667, 60.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.761326541569191, 6.911200000000001, 6.9112, 121.9260426156618, 565535.0668571409, 565535.0668571404, 155561.2503665024], 
processed observation next is [1.0, 0.7391304347826086, 0.5654320987654322, 0.6016666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7016581769614888, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20197680959183603, 0.20197680959183587, 0.29915625070481233], 
reward next is 0.7008, 
noisyNet noise sample is [array([1.1987327], dtype=float32), 1.2100356]. 
=============================================
[2019-03-24 01:43:53,112] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 183360: loss 0.0562
[2019-03-24 01:43:53,114] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 183361: learning rate 0.0000
[2019-03-24 01:43:53,224] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 183415: loss 0.2143
[2019-03-24 01:43:53,225] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 183416: learning rate 0.0000
[2019-03-24 01:43:53,760] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 183699: loss 0.0974
[2019-03-24 01:43:53,762] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 183700: learning rate 0.0000
[2019-03-24 01:43:54,061] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 183855: loss 0.2266
[2019-03-24 01:43:54,065] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 183857: learning rate 0.0000
[2019-03-24 01:43:54,124] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 183887: loss 0.0322
[2019-03-24 01:43:54,127] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 183887: learning rate 0.0000
[2019-03-24 01:43:54,319] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 183988: loss 0.2897
[2019-03-24 01:43:54,320] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 183988: learning rate 0.0000
[2019-03-24 01:43:54,326] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 183990: loss 0.1853
[2019-03-24 01:43:54,327] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 183990: learning rate 0.0000
[2019-03-24 01:43:54,393] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 184025: loss 0.0513
[2019-03-24 01:43:54,394] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 184025: learning rate 0.0000
[2019-03-24 01:43:54,442] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 184052: loss 0.0003
[2019-03-24 01:43:54,444] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 184052: learning rate 0.0000
[2019-03-24 01:43:54,445] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 184054: loss 0.0510
[2019-03-24 01:43:54,451] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 184055: loss 0.0043
[2019-03-24 01:43:54,452] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 184055: learning rate 0.0000
[2019-03-24 01:43:54,454] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 184055: learning rate 0.0000
[2019-03-24 01:43:54,665] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 184167: loss 0.1500
[2019-03-24 01:43:54,668] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 184167: learning rate 0.0000
[2019-03-24 01:43:54,702] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 184185: loss 0.0840
[2019-03-24 01:43:54,704] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 184185: learning rate 0.0000
[2019-03-24 01:43:54,758] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 184210: loss 0.0545
[2019-03-24 01:43:54,760] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 184211: learning rate 0.0000
[2019-03-24 01:43:55,017] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 184347: loss 0.0071
[2019-03-24 01:43:55,018] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 184347: learning rate 0.0000
[2019-03-24 01:43:55,374] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 184528: loss 0.0664
[2019-03-24 01:43:55,376] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 184528: learning rate 0.0000
[2019-03-24 01:43:56,719] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 3.7594270e-26 1.1882424e-20 2.4673265e-19 5.4842697e-10], sum to 1.0000
[2019-03-24 01:43:56,734] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4872
[2019-03-24 01:43:56,738] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.06666666666667, 70.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7725567110176941, 6.9112, 6.9112, 121.9260426156618, 575316.5880734173, 575316.5880734173, 156085.1809238354], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6945000.0000, 
sim time next is 6945600.0000, 
raw observation next is [25.33333333333334, 69.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7782059058292708, 6.9112, 6.9112, 121.9260426156618, 579256.8421304319, 579256.8421304319, 156947.1539185903], 
processed observation next is [0.0, 0.391304347826087, 0.49382716049382736, 0.6966666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7227573822865885, 0.0, 0.0, 0.8094621288201359, 0.2068774436180114, 0.2068774436180114, 0.3018214498434429], 
reward next is 0.6982, 
noisyNet noise sample is [array([-0.29283574], dtype=float32), -0.5870894]. 
=============================================
[2019-03-24 01:43:57,838] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9999881e-01 1.3037181e-21 1.2204241e-15 2.1821798e-14 1.1709971e-06], sum to 1.0000
[2019-03-24 01:43:57,840] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4989
[2019-03-24 01:43:57,846] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.6, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7102986696189455, 6.911200000000001, 6.9112, 121.9260426156618, 530800.7187549787, 530800.7187549783, 146045.0566993737], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6991200.0000, 
sim time next is 6991800.0000, 
raw observation next is [24.46666666666667, 66.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7085691325254754, 6.911199999999999, 6.9112, 121.9260426156618, 529509.7766815688, 529509.7766815693, 145784.6471711759], 
processed observation next is [0.0, 0.9565217391304348, 0.46172839506172847, 0.6666666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6357114156568441, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1891106345291317, 0.18911063452913188, 0.28035509071379977], 
reward next is 0.7196, 
noisyNet noise sample is [array([-0.01600534], dtype=float32), -1.7904247]. 
=============================================
[2019-03-24 01:43:58,745] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 6.1684767e-27 5.5670103e-22 7.5033044e-21 7.9058182e-10], sum to 1.0000
[2019-03-24 01:43:58,751] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4204
[2019-03-24 01:43:58,756] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.56666666666667, 57.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7377334506771692, 6.911200000000001, 6.9112, 121.9260426156618, 551063.4179216876, 551063.4179216871, 150116.6065076141], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6983400.0000, 
sim time next is 6984000.0000, 
raw observation next is [26.3, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7325994612259126, 6.911200000000001, 6.9112, 121.9260426156618, 547326.2919595592, 547326.2919595587, 149285.2102671816], 
processed observation next is [0.0, 0.8695652173913043, 0.5296296296296297, 0.58, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6657493265323907, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19547367569984256, 0.1954736756998424, 0.28708694282150304], 
reward next is 0.7129, 
noisyNet noise sample is [array([0.51151526], dtype=float32), 1.3670663]. 
=============================================
[2019-03-24 01:43:58,774] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[73.55858 ]
 [73.58006 ]
 [73.59621 ]
 [73.61183 ]
 [73.644394]], R is [[73.52301025]
 [73.4990921 ]
 [73.47401428]
 [73.44793701]
 [73.42082977]].
[2019-03-24 01:44:05,533] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9999988e-01 1.0510403e-25 3.9887652e-19 1.3716247e-19 8.0630151e-08], sum to 1.0000
[2019-03-24 01:44:05,544] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5188
[2019-03-24 01:44:05,547] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.88333333333333, 84.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7011253442141187, 6.9112, 6.9112, 121.9260426156618, 522861.8092177322, 522861.8092177322, 142486.500246925], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7107000.0000, 
sim time next is 7107600.0000, 
raw observation next is [20.86666666666667, 84.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6899462489516905, 6.911199999999999, 6.9112, 121.9260426156618, 514432.6439959545, 514432.6439959549, 141201.181909327], 
processed observation next is [1.0, 0.2608695652173913, 0.3283950617283952, 0.8466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6124328111896131, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18372594428426944, 0.1837259442842696, 0.27154073444101345], 
reward next is 0.7285, 
noisyNet noise sample is [array([0.60006666], dtype=float32), -1.0840422]. 
=============================================
[2019-03-24 01:44:09,182] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 191329: loss 0.0316
[2019-03-24 01:44:09,184] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 191329: learning rate 0.0000
[2019-03-24 01:44:09,342] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 191408: loss 0.0325
[2019-03-24 01:44:09,343] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 191408: learning rate 0.0000
[2019-03-24 01:44:10,080] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 191766: loss 0.0273
[2019-03-24 01:44:10,082] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 191767: learning rate 0.0000
[2019-03-24 01:44:10,349] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 191898: loss 0.0141
[2019-03-24 01:44:10,351] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 191899: learning rate 0.0000
[2019-03-24 01:44:10,392] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 191920: loss 0.1042
[2019-03-24 01:44:10,395] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 191921: learning rate 0.0000
[2019-03-24 01:44:10,507] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191975: loss 0.1180
[2019-03-24 01:44:10,509] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 191975: learning rate 0.0000
[2019-03-24 01:44:10,527] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 191985: loss 0.0130
[2019-03-24 01:44:10,530] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 191987: learning rate 0.0000
[2019-03-24 01:44:10,552] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 191996: loss 0.0071
[2019-03-24 01:44:10,555] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 191998: learning rate 0.0000
[2019-03-24 01:44:10,587] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 192012: loss 0.0102
[2019-03-24 01:44:10,590] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 192012: learning rate 0.0000
[2019-03-24 01:44:10,594] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 192013: loss 0.0134
[2019-03-24 01:44:10,596] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 192013: learning rate 0.0000
[2019-03-24 01:44:10,660] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 192047: loss 0.0079
[2019-03-24 01:44:10,663] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 192049: learning rate 0.0000
[2019-03-24 01:44:10,747] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 192089: loss 0.1008
[2019-03-24 01:44:10,750] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 192090: learning rate 0.0000
[2019-03-24 01:44:10,795] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 192107: loss 0.0292
[2019-03-24 01:44:10,798] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 192107: learning rate 0.0000
[2019-03-24 01:44:10,834] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 192125: loss 0.0022
[2019-03-24 01:44:10,836] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 192125: learning rate 0.0000
[2019-03-24 01:44:11,219] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 192315: loss 1.0482
[2019-03-24 01:44:11,223] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 192317: learning rate 0.0000
[2019-03-24 01:44:11,686] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 192542: loss 0.0579
[2019-03-24 01:44:11,689] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 192545: learning rate 0.0000
[2019-03-24 01:44:13,036] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.1459681e-23 9.8052956e-19 3.0658051e-18 3.8205256e-10], sum to 1.0000
[2019-03-24 01:44:13,048] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1513
[2019-03-24 01:44:13,054] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.46666666666667, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.634199531768187, 6.9112, 6.9112, 121.9260426156618, 472419.8146216884, 472419.8146216884, 135027.8572282793], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7269600.0000, 
sim time next is 7270200.0000, 
raw observation next is [20.45, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6319455118000774, 6.9112, 6.9112, 121.9260426156618, 470804.9671626739, 470804.9671626739, 134868.1347346093], 
processed observation next is [1.0, 0.13043478260869565, 0.31296296296296294, 0.87, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5399318897500968, 0.0, 0.0, 0.8094621288201359, 0.16814463112952638, 0.16814463112952638, 0.25936179756655636], 
reward next is 0.7406, 
noisyNet noise sample is [array([-0.02060191], dtype=float32), 0.7898295]. 
=============================================
[2019-03-24 01:44:13,324] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 6.6978737e-31 3.4622818e-23 1.1428212e-21 5.0151918e-13], sum to 1.0000
[2019-03-24 01:44:13,333] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7052
[2019-03-24 01:44:13,341] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.25, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6514441320695387, 6.911200000000001, 6.9112, 121.9260426156618, 486138.9148172616, 486138.9148172612, 137760.2533920689], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7245000.0000, 
sim time next is 7245600.0000, 
raw observation next is [22.16666666666667, 76.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6479136343102264, 6.9112, 6.9112, 121.9260426156618, 483439.1701342592, 483439.1701342592, 137309.5272511528], 
processed observation next is [1.0, 0.8695652173913043, 0.3765432098765434, 0.7633333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5598920428877829, 0.0, 0.0, 0.8094621288201359, 0.17265684647652116, 0.17265684647652116, 0.2640567831752938], 
reward next is 0.7359, 
noisyNet noise sample is [array([-0.878378], dtype=float32), 0.80030143]. 
=============================================
[2019-03-24 01:44:20,321] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.5034746e-21 8.9982322e-17 6.3835080e-15 1.9763671e-09], sum to 1.0000
[2019-03-24 01:44:20,328] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5406
[2019-03-24 01:44:20,333] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6256951699958047, 6.911200000000001, 6.9112, 121.9260426156618, 464637.1863132103, 464637.1863132098, 132984.3353158335], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7372800.0000, 
sim time next is 7373400.0000, 
raw observation next is [19.03333333333333, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6576157142557126, 6.9112, 6.9112, 121.9260426156618, 488358.8678266543, 488358.8678266543, 136125.8520809152], 
processed observation next is [1.0, 0.34782608695652173, 0.26049382716049374, 0.95, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5720196428196408, 0.0, 0.0, 0.8094621288201359, 0.17441388136666225, 0.17441388136666225, 0.2617804847709908], 
reward next is 0.7382, 
noisyNet noise sample is [array([1.2230458], dtype=float32), 0.45925766]. 
=============================================
[2019-03-24 01:44:25,602] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 199345: loss 0.0697
[2019-03-24 01:44:25,607] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 199345: learning rate 0.0000
[2019-03-24 01:44:25,654] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 199370: loss 0.0060
[2019-03-24 01:44:25,655] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 199370: learning rate 0.0000
[2019-03-24 01:44:26,460] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 199771: loss 0.1842
[2019-03-24 01:44:26,463] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 199772: learning rate 0.0000
[2019-03-24 01:44:26,655] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 199868: loss 0.1821
[2019-03-24 01:44:26,657] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 199868: learning rate 0.0000
[2019-03-24 01:44:26,804] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 199931: loss 0.2824
[2019-03-24 01:44:26,806] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 199931: learning rate 0.0000
[2019-03-24 01:44:26,865] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 199971: loss 0.0133
[2019-03-24 01:44:26,867] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 199971: learning rate 0.0000
[2019-03-24 01:44:26,908] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 199990: loss 0.0017
[2019-03-24 01:44:26,911] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 199990: learning rate 0.0000
[2019-03-24 01:44:26,916] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 199992: loss 0.0001
[2019-03-24 01:44:26,921] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 199992: learning rate 0.0000
[2019-03-24 01:44:26,940] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 01:44:26,942] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:44:26,944] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:44:26,946] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:44:26,946] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:44:26,946] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:44:26,948] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:44:26,947] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:44:26,949] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:44:26,948] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:44:26,951] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:44:26,964] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run9
[2019-03-24 01:44:26,987] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run9
[2019-03-24 01:44:26,987] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run9
[2019-03-24 01:44:27,034] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run9
[2019-03-24 01:44:27,034] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run9
[2019-03-24 01:44:46,624] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.0822418]
[2019-03-24 01:44:46,626] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [38.16666666666666, 15.83333333333333, 1.0, 2.0, 0.848492844744527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9259627970734, 1047913.667547949, 1047913.667547948, 209588.5461664112]
[2019-03-24 01:44:46,627] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:44:46,631] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.8014678e-23 3.6517497e-18 9.2672311e-18 3.7422266e-12], sampled 0.8747043027425364
[2019-03-24 01:44:46,632] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1047913.667547949 W.
[2019-03-24 01:45:42,000] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.0822418]
[2019-03-24 01:45:42,000] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.1, 88.33333333333334, 1.0, 2.0, 0.7219916418355605, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 822879.6825052495, 822879.68250525, 180347.5285648306]
[2019-03-24 01:45:42,002] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:45:42,004] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.8911664e-26 1.2940040e-20 3.6592622e-20 9.2001669e-14], sampled 0.9690700908699545
[2019-03-24 01:45:42,004] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 822879.6825052495 W.
[2019-03-24 01:45:45,674] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.0822418]
[2019-03-24 01:45:45,675] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.16666666666667, 99.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8541455679824882, 6.911200000000001, 6.9112, 121.9260426156618, 630629.5627432216, 630629.5627432212, 168557.5631371965]
[2019-03-24 01:45:45,675] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:45:45,677] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.3527485e-24 3.5381805e-19 9.2123477e-19 7.9080682e-13], sampled 0.021806615846567845
[2019-03-24 01:45:53,174] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.0822418]
[2019-03-24 01:45:53,176] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.80553974, 61.39600659, 1.0, 2.0, 0.7676127628705046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 874905.3825151637, 874905.3825151637, 189342.7474124334]
[2019-03-24 01:45:53,177] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:45:53,179] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 6.9860780e-24 1.2494176e-18 3.2268527e-18 1.8402387e-12], sampled 0.8495711120728001
[2019-03-24 01:45:53,182] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 874905.3825151637 W.
[2019-03-24 01:45:58,001] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.0822418]
[2019-03-24 01:45:58,002] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.5, 67.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7639964241919602, 6.911200000000001, 6.9112, 121.9260426156618, 569151.8501968605, 569151.85019686, 154904.3650964799]
[2019-03-24 01:45:58,004] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:45:58,006] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.4416536e-26 1.5848120e-20 4.4042417e-20 1.0331327e-13], sampled 0.021821181109957122
[2019-03-24 01:46:00,085] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.0822418]
[2019-03-24 01:46:00,086] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.71666666666667, 70.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7005021770170161, 6.9112, 6.9112, 121.9260426156618, 523460.2485054039, 523460.2485054039, 144548.8683873218]
[2019-03-24 01:46:00,086] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:46:00,089] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 3.2574017e-25 1.1796482e-19 3.1195879e-19 3.8150510e-13], sampled 0.9719278980726758
[2019-03-24 01:46:10,517] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 01:46:10,728] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 01:46:10,775] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 01:46:10,783] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 01:46:10,841] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 01:46:11,856] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 200000, evaluation results [200000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 01:46:11,900] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 200032: loss 0.1208
[2019-03-24 01:46:11,901] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 200032: learning rate 0.0000
[2019-03-24 01:46:11,982] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 200073: loss 0.1131
[2019-03-24 01:46:11,987] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 200074: loss 0.1962
[2019-03-24 01:46:11,991] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 200074: learning rate 0.0000
[2019-03-24 01:46:11,994] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 200074: learning rate 0.0000
[2019-03-24 01:46:12,095] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 200126: loss 0.0588
[2019-03-24 01:46:12,099] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 200126: learning rate 0.0000
[2019-03-24 01:46:12,145] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 200153: loss 0.0146
[2019-03-24 01:46:12,149] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 200154: learning rate 0.0000
[2019-03-24 01:46:12,300] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 200233: loss 0.3959
[2019-03-24 01:46:12,306] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 200233: learning rate 0.0000
[2019-03-24 01:46:12,774] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 200480: loss 0.0016
[2019-03-24 01:46:12,777] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 200480: learning rate 0.0000
[2019-03-24 01:46:12,816] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 200495: loss 0.0835
[2019-03-24 01:46:12,817] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 200496: learning rate 0.0000
[2019-03-24 01:46:14,497] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.2692478e-34 7.8874991e-26 1.9417981e-26 4.9985008e-16], sum to 1.0000
[2019-03-24 01:46:14,503] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3184
[2019-03-24 01:46:14,511] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.73333333333333, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7318053490066775, 6.911200000000001, 6.9112, 121.9260426156618, 545891.5759862314, 545891.575986231, 150479.1317494694], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7548000.0000, 
sim time next is 7548600.0000, 
raw observation next is [21.91666666666667, 91.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7367334444758764, 6.911199999999999, 6.9112, 121.9260426156618, 549310.7809309096, 549310.78093091, 151295.5811448738], 
processed observation next is [0.0, 0.34782608695652173, 0.36728395061728414, 0.9166666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6709168055948456, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19618242176103912, 0.19618242176103928, 0.29095304066321886], 
reward next is 0.7090, 
noisyNet noise sample is [array([1.2541823], dtype=float32), -0.9289573]. 
=============================================
[2019-03-24 01:46:15,308] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.3238252e-25 2.0111226e-21 9.3064346e-21 1.7459549e-13], sum to 1.0000
[2019-03-24 01:46:15,319] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5100
[2019-03-24 01:46:15,326] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.5, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8628785788432882, 6.911200000000001, 6.9112, 121.9260426156618, 633328.8675052646, 633328.8675052641, 170677.2274688228], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7569000.0000, 
sim time next is 7569600.0000, 
raw observation next is [27.66666666666666, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8750607866716414, 6.911200000000001, 6.9112, 121.9260426156618, 640866.6289445808, 640866.6289445803, 172564.9047060434], 
processed observation next is [0.0, 0.6086956521739131, 0.5802469135802467, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8438259833395517, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22888093890877886, 0.2288809389087787, 0.3318555859731604], 
reward next is 0.6681, 
noisyNet noise sample is [array([1.4003215], dtype=float32), -0.2103868]. 
=============================================
[2019-03-24 01:46:16,527] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.2686973e-29 4.6511981e-22 6.6189910e-21 4.1855604e-15], sum to 1.0000
[2019-03-24 01:46:16,533] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5158
[2019-03-24 01:46:16,539] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.73333333333333, 87.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7807761718123482, 6.911200000000001, 6.9112, 121.9260426156618, 580955.5179806432, 580955.5179806427, 157394.3047690548], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7602000.0000, 
sim time next is 7602600.0000, 
raw observation next is [22.61666666666667, 87.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7724491888093227, 6.9112, 6.9112, 121.9260426156618, 575262.859258572, 575262.859258572, 156053.820487755], 
processed observation next is [0.0, 1.0, 0.39320987654321005, 0.8716666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7155614860116533, 0.0, 0.0, 0.8094621288201359, 0.2054510211637757, 0.2054510211637757, 0.3001035009379904], 
reward next is 0.6999, 
noisyNet noise sample is [array([1.111844], dtype=float32), -0.3434669]. 
=============================================
[2019-03-24 01:46:21,995] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.000000e+00 4.826295e-27 9.005194e-19 9.610982e-20 1.710885e-10], sum to 1.0000
[2019-03-24 01:46:22,002] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5635
[2019-03-24 01:46:22,006] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.93333333333333, 76.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5397267850311163, 6.911199999999999, 6.9112, 121.9260426156618, 394503.4325814692, 394503.4325814696, 121582.1805181828], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7677600.0000, 
sim time next is 7678200.0000, 
raw observation next is [19.91666666666666, 77.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.544518707132612, 6.911200000000001, 6.9112, 121.9260426156618, 398424.6568671672, 398424.6568671668, 122169.2836427285], 
processed observation next is [1.0, 0.8695652173913043, 0.2932098765432097, 0.7733333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43064838391576493, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14229452030970258, 0.14229452030970244, 0.23494093008217018], 
reward next is 0.7651, 
noisyNet noise sample is [array([0.6951341], dtype=float32), -0.23026039]. 
=============================================
[2019-03-24 01:46:22,543] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 3.3843575e-26 2.4357432e-21 1.7675760e-18 3.0492074e-11], sum to 1.0000
[2019-03-24 01:46:22,550] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5818
[2019-03-24 01:46:22,555] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.7, 67.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4819216178358805, 6.911200000000001, 6.9112, 121.9260426156618, 344300.8392206779, 344300.8392206775, 112043.6595026664], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7693800.0000, 
sim time next is 7694400.0000, 
raw observation next is [19.7, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4691331103139398, 6.911200000000001, 6.9112, 121.9260426156618, 334976.5147017079, 334976.5147017075, 108560.8104443203], 
processed observation next is [1.0, 0.043478260869565216, 0.28518518518518515, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3364163878924247, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11963446953632426, 0.11963446953632412, 0.2087707893160006], 
reward next is 0.7912, 
noisyNet noise sample is [array([0.44496092], dtype=float32), 1.8788197]. 
=============================================
[2019-03-24 01:46:26,037] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 207312: loss 0.0280
[2019-03-24 01:46:26,041] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 207313: learning rate 0.0000
[2019-03-24 01:46:26,207] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 207399: loss 0.1255
[2019-03-24 01:46:26,208] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 207399: learning rate 0.0000
[2019-03-24 01:46:26,604] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 207604: loss 0.0056
[2019-03-24 01:46:26,608] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 207604: learning rate 0.0000
[2019-03-24 01:46:27,103] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 207866: loss 0.1152
[2019-03-24 01:46:27,104] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 207866: learning rate 0.0000
[2019-03-24 01:46:27,160] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 207896: loss 0.0119
[2019-03-24 01:46:27,161] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 207896: learning rate 0.0000
[2019-03-24 01:46:27,165] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 207896: loss 0.0135
[2019-03-24 01:46:27,167] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 207897: learning rate 0.0000
[2019-03-24 01:46:27,214] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 207925: loss 0.0092
[2019-03-24 01:46:27,216] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 207925: learning rate 0.0000
[2019-03-24 01:46:27,282] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 207958: loss 0.0146
[2019-03-24 01:46:27,283] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 207958: learning rate 0.0000
[2019-03-24 01:46:27,334] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207982: loss 0.0383
[2019-03-24 01:46:27,335] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207984: learning rate 0.0000
[2019-03-24 01:46:27,387] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 208010: loss 0.0105
[2019-03-24 01:46:27,388] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 208010: learning rate 0.0000
[2019-03-24 01:46:27,590] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 208113: loss 0.1675
[2019-03-24 01:46:27,592] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 208114: learning rate 0.0000
[2019-03-24 01:46:27,614] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 208126: loss 0.3224
[2019-03-24 01:46:27,614] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 208126: learning rate 0.0000
[2019-03-24 01:46:27,645] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 208141: loss 0.1468
[2019-03-24 01:46:27,646] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 208141: learning rate 0.0000
[2019-03-24 01:46:28,140] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 208397: loss 0.4053
[2019-03-24 01:46:28,143] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 208398: learning rate 0.0000
[2019-03-24 01:46:28,220] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 208436: loss 0.3248
[2019-03-24 01:46:28,221] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 208436: learning rate 0.0000
[2019-03-24 01:46:28,364] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 208511: loss 0.2144
[2019-03-24 01:46:28,365] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 208511: learning rate 0.0000
[2019-03-24 01:46:34,789] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:46:34,789] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:34,820] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run2
[2019-03-24 01:46:35,045] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:46:35,045] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:35,046] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run2
[2019-03-24 01:46:35,242] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:46:35,243] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:35,244] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run2
[2019-03-24 01:46:35,615] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:46:35,616] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:35,617] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run2
[2019-03-24 01:46:35,683] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:46:35,684] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:35,685] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run2
[2019-03-24 01:46:35,806] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:46:35,806] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:35,807] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run2
[2019-03-24 01:46:35,883] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:46:35,883] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:35,884] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run2
[2019-03-24 01:46:35,909] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:46:35,910] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:35,911] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run2
[2019-03-24 01:46:35,966] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:46:35,967] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:35,968] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run2
[2019-03-24 01:46:35,995] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:46:35,996] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:35,997] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run2
[2019-03-24 01:46:36,022] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:46:36,023] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:36,025] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run2
[2019-03-24 01:46:36,055] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:46:36,056] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:36,058] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run2
[2019-03-24 01:46:36,087] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:46:36,088] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:36,089] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run2
[2019-03-24 01:46:36,181] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:46:36,181] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:36,182] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run2
[2019-03-24 01:46:36,278] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:46:36,279] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:36,280] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run2
[2019-03-24 01:46:36,334] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:46:36,334] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:46:36,336] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run2
[2019-03-24 01:46:41,370] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.7775501e-01 1.1423909e-17 5.2995493e-13 3.1534823e-11 2.2244973e-02], sum to 1.0000
[2019-03-24 01:46:41,377] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7248
[2019-03-24 01:46:41,381] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.13333333333333, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6935995330052935, 6.911200000000001, 6.9112, 121.9260426156618, 518315.7892717841, 518315.7892717836, 143969.896134311], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 78000.0000, 
sim time next is 78600.0000, 
raw observation next is [25.96666666666667, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6924077427508172, 6.9112, 6.9112, 121.9260426156618, 517427.2314256969, 517427.2314256969, 143893.1180019691], 
processed observation next is [1.0, 0.9130434782608695, 0.517283950617284, 0.58, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6155096784385214, 0.0, 0.0, 0.8094621288201359, 0.18479543979489177, 0.18479543979489177, 0.2767175346191713], 
reward next is 0.7233, 
noisyNet noise sample is [array([0.027336], dtype=float32), 0.7246159]. 
=============================================
[2019-03-24 01:46:44,419] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9825984e-01 3.9399903e-17 1.3698646e-12 4.7947698e-11 1.7401568e-03], sum to 1.0000
[2019-03-24 01:46:44,425] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1232
[2019-03-24 01:46:44,429] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [34.75, 10.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6945826633162406, 6.911200000000001, 6.9112, 121.9260426156618, 495983.6781783903, 495983.6781783898, 128353.0448484857], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 153000.0000, 
sim time next is 153600.0000, 
raw observation next is [34.46666666666667, 10.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6902870498037129, 6.911200000000001, 6.9112, 121.9260426156618, 492915.3041479621, 492915.3041479616, 128430.1873185339], 
processed observation next is [1.0, 0.782608695652174, 0.8320987654320988, 0.1066666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6128588122546411, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1760411800528436, 0.17604118005284344, 0.24698112945871906], 
reward next is 0.7530, 
noisyNet noise sample is [array([0.04037922], dtype=float32), 0.47428545]. 
=============================================
[2019-03-24 01:46:44,787] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9902701e-01 5.1323870e-13 1.6638024e-10 7.0760846e-09 9.7294751e-04], sum to 1.0000
[2019-03-24 01:46:44,794] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8623
[2019-03-24 01:46:44,800] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1714681.710113776 W.
[2019-03-24 01:46:44,811] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.4, 14.5, 1.0, 2.0, 0.4740124341721952, 1.0, 2.0, 0.4740124341721952, 1.0, 1.0, 0.7673201550150147, 6.9112, 6.9112, 121.94756008, 1714681.710113776, 1714681.710113776, 330452.0990201616], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 137400.0000, 
sim time next is 138000.0000, 
raw observation next is [37.4, 14.0, 1.0, 2.0, 0.6448222223306295, 1.0, 2.0, 0.6448222223306295, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1572527.430969118, 1572527.430969118, 288071.5146909049], 
processed observation next is [1.0, 0.6086956521739131, 0.9407407407407407, 0.14, 1.0, 1.0, 0.5771693122983684, 1.0, 1.0, 0.5771693122983684, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5616169396318278, 0.5616169396318278, 0.553983682097894], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1456772], dtype=float32), 0.14476544]. 
=============================================
[2019-03-24 01:46:44,829] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[38.543724]
 [38.416317]
 [39.191303]
 [39.298687]
 [38.934856]], R is [[38.75629044]
 [38.36872864]
 [37.98504257]
 [37.60519409]
 [37.22914124]].
[2019-03-24 01:46:46,281] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.99985933e-01 3.48647637e-29 1.01221192e-18 1.58933100e-19
 1.40733955e-05], sum to 1.0000
[2019-03-24 01:46:46,286] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0964
[2019-03-24 01:46:46,290] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.1, 11.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6400116278971829, 6.911200000000001, 6.9112, 121.9260426156618, 457004.2876534775, 457004.287653477, 112358.3459987184], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 167400.0000, 
sim time next is 168000.0000, 
raw observation next is [31.03333333333333, 10.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6391725979170271, 6.9112, 6.9112, 121.9260426156618, 456404.9947787616, 456404.9947787616, 111703.5115915652], 
processed observation next is [1.0, 0.9565217391304348, 0.7049382716049382, 0.1066666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5489657473962838, 0.0, 0.0, 0.8094621288201359, 0.1630017838495577, 0.1630017838495577, 0.2148144453683946], 
reward next is 0.7852, 
noisyNet noise sample is [array([-1.2320335], dtype=float32), 1.3033175]. 
=============================================
[2019-03-24 01:46:46,318] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[88.53003 ]
 [88.68445 ]
 [88.846344]
 [88.96863 ]
 [89.094666]], R is [[88.2769928 ]
 [88.17815399]
 [88.07901764]
 [87.97944641]
 [87.87934113]].
[2019-03-24 01:46:51,191] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.8284916e-26 1.3052692e-18 2.7822422e-17 3.9759666e-08], sum to 1.0000
[2019-03-24 01:46:51,203] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8862
[2019-03-24 01:46:51,210] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.15, 41.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4816535263456072, 6.9112, 6.9112, 121.9260426156618, 343902.345012694, 343902.345012694, 97745.46628834751], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 283800.0000, 
sim time next is 284400.0000, 
raw observation next is [22.4, 40.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4859556665188058, 6.911200000000001, 6.9112, 121.9260426156618, 346974.7833803201, 346974.7833803197, 98337.23574886553], 
processed observation next is [0.0, 0.30434782608695654, 0.38518518518518513, 0.4, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3574445831485072, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12391956549297148, 0.12391956549297133, 0.18911006874781833], 
reward next is 0.8109, 
noisyNet noise sample is [array([-0.31052768], dtype=float32), -1.2600849]. 
=============================================
[2019-03-24 01:46:53,071] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9999344e-01 5.5233829e-20 2.8639706e-15 4.8523754e-16 6.6070720e-06], sum to 1.0000
[2019-03-24 01:46:53,084] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1212
[2019-03-24 01:46:53,089] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.4, 40.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4859556665188058, 6.911200000000001, 6.9112, 121.9260426156618, 346974.7833803201, 346974.7833803197, 98337.23574886553], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 284400.0000, 
sim time next is 285000.0000, 
raw observation next is [22.63333333333333, 39.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4902785509137633, 6.911200000000001, 6.9112, 121.9260426156618, 350062.0489449988, 350062.0489449984, 98996.31674545755], 
processed observation next is [0.0, 0.30434782608695654, 0.393827160493827, 0.3916666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.36284818864220414, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12502216033749958, 0.12502216033749944, 0.19037753220280298], 
reward next is 0.8096, 
noisyNet noise sample is [array([0.11468941], dtype=float32), -0.8642893]. 
=============================================
[2019-03-24 01:46:53,115] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[61.882202]
 [61.937344]
 [62.003857]
 [62.082027]
 [62.16263 ]], R is [[62.01232529]
 [62.20309448]
 [62.39308929]
 [62.58231735]
 [62.77088928]].
[2019-03-24 01:46:56,057] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999988e-01 1.2056489e-25 1.3118238e-17 1.1787367e-16 1.0815962e-07], sum to 1.0000
[2019-03-24 01:46:56,070] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7579
[2019-03-24 01:46:56,078] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.15, 46.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.51179219828238, 6.9112, 6.9112, 121.9260426156618, 365426.5926981748, 365426.5926981748, 113941.2482906801], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 343800.0000, 
sim time next is 344400.0000, 
raw observation next is [23.0, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5084691766863215, 6.9112, 6.9112, 121.9260426156618, 363053.3474563877, 363053.3474563877, 113165.401252142], 
processed observation next is [0.0, 1.0, 0.4074074074074074, 0.47, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3855864708579019, 0.0, 0.0, 0.8094621288201359, 0.12966190980585277, 0.12966190980585277, 0.21762577163873462], 
reward next is 0.7824, 
noisyNet noise sample is [array([-0.56098574], dtype=float32), 1.0919825]. 
=============================================
[2019-03-24 01:47:03,868] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 01:47:03,869] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:47:03,870] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:47:03,871] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:47:03,871] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:47:03,872] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:47:03,872] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:47:03,873] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:47:03,874] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:47:03,875] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:47:03,877] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:47:03,892] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run10
[2019-03-24 01:47:03,915] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run10
[2019-03-24 01:47:03,916] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run10
[2019-03-24 01:47:03,916] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run10
[2019-03-24 01:47:03,974] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run10
[2019-03-24 01:47:08,131] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.09710114]
[2019-03-24 01:47:08,132] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.0, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3783852875836295, 6.911200000000001, 6.9112, 121.9260426156618, 270155.4663358607, 270155.4663358603, 81337.556109086]
[2019-03-24 01:47:08,132] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:47:08,137] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9911851e-01 3.4276965e-20 4.2891191e-10 5.5284098e-13 8.8154193e-04], sampled 0.43546220902383603
[2019-03-24 01:47:23,409] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.09710114]
[2019-03-24 01:47:23,410] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.96493675, 39.60393415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5282001280929204, 6.9112, 6.9112, 121.9260426156618, 377158.07664146, 377158.07664146, 104209.0486172534]
[2019-03-24 01:47:23,410] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:47:23,414] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9911565e-01 3.0509743e-20 4.0907197e-10 5.1760213e-13 8.8434841e-04], sampled 0.12361861195270873
[2019-03-24 01:47:26,670] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.09710114]
[2019-03-24 01:47:26,673] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [35.81666666666666, 22.16666666666667, 1.0, 2.0, 0.5878435866639317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156534, 721789.9309515668, 721789.9309515668, 158052.2455844844]
[2019-03-24 01:47:26,674] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:47:26,676] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9739194e-01 1.0610530e-17 7.2556596e-09 2.2246730e-11 2.6080294e-03], sampled 0.5298732926385317
[2019-03-24 01:47:26,678] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 721789.9309515668 W.
[2019-03-24 01:47:32,329] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.09710114]
[2019-03-24 01:47:32,329] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.16666666666667, 93.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5849665128121738, 6.911199999999999, 6.9112, 121.9260426156618, 433991.367354947, 433991.3673549474, 128835.8264860718]
[2019-03-24 01:47:32,331] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:47:32,333] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9934727e-01 4.7345290e-21 1.6556763e-10 1.5857962e-13 6.5274280e-04], sampled 0.96251751612082
[2019-03-24 01:47:32,397] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.09710114]
[2019-03-24 01:47:32,399] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.5, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6112802553837623, 6.911199999999999, 6.9112, 121.9260426156618, 453992.9751785075, 453992.975178508, 131644.2810457318]
[2019-03-24 01:47:32,399] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:47:32,402] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.99414325e-01 2.13567735e-21 1.13278144e-10 9.64262714e-14
 5.85691188e-04], sampled 0.7230533845847649
[2019-03-24 01:48:02,862] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.09710114]
[2019-03-24 01:48:02,865] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.70832601666667, 82.77135931000001, 1.0, 1.0, 0.6018490295162955, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 720803.5571099052, 720803.5571099052, 159921.0093935106]
[2019-03-24 01:48:02,866] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:48:02,868] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9886060e-01 1.2912391e-19 8.2817869e-10 1.3024339e-12 1.1394206e-03], sampled 0.2840668015551101
[2019-03-24 01:48:02,868] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 720803.5571099052 W.
[2019-03-24 01:48:19,986] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.09710114]
[2019-03-24 01:48:19,987] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 100.0, 1.0, 2.0, 0.8362522437998235, 1.0, 2.0, 0.8362522437998235, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426154891, 1907504.217330153, 1907504.217330153, 358962.4955755668]
[2019-03-24 01:48:19,988] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:48:19,993] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9725914e-01 7.1443399e-18 6.1723817e-09 1.7984201e-11 2.7408088e-03], sampled 0.6480632492698335
[2019-03-24 01:48:19,994] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1907504.217330153 W.
[2019-03-24 01:48:21,327] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.09710114]
[2019-03-24 01:48:21,329] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.83333333333333, 52.33333333333334, 1.0, 2.0, 0.6471356547035256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737522.5927593148, 737522.5927593148, 166379.8717839999]
[2019-03-24 01:48:21,330] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:48:21,331] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9801195e-01 2.4619153e-18 3.5305450e-09 8.6811730e-12 1.9880200e-03], sampled 0.6475396349498044
[2019-03-24 01:48:21,333] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 737522.5927593148 W.
[2019-03-24 01:48:29,625] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.09710114]
[2019-03-24 01:48:29,626] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [34.11363784, 39.97970478833333, 1.0, 2.0, 0.6437340053655279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737281.0890949622, 737281.0890949622, 165944.0229882984]
[2019-03-24 01:48:29,626] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:48:29,628] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9800473e-01 2.0653898e-18 3.2721041e-09 7.8555591e-12 1.9953165e-03], sampled 0.6632994066576866
[2019-03-24 01:48:29,629] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 737281.0890949622 W.
[2019-03-24 01:48:39,420] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.09710114]
[2019-03-24 01:48:39,421] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.27387646, 80.64530807, 1.0, 2.0, 0.894096133709251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426028248, 1019163.75430156, 1019163.75430156, 216145.6732969996]
[2019-03-24 01:48:39,422] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:48:39,425] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9802005e-01 3.4748931e-18 4.1116683e-09 1.0585136e-11 1.9799231e-03], sampled 0.8133481654081363
[2019-03-24 01:48:39,427] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1019163.75430156 W.
[2019-03-24 01:48:47,094] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7829.9364 2530391514.7852 831.0000
[2019-03-24 01:48:47,202] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8386.5590 2294023402.7485 695.0000
[2019-03-24 01:48:47,231] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8340.1410 2340561731.2418 616.0000
[2019-03-24 01:48:47,312] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8541.9532 2259110179.9092 535.0000
[2019-03-24 01:48:47,349] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8616.2997 2219995629.6074 541.0000
[2019-03-24 01:48:48,362] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 225000, evaluation results [225000.0, 7829.936365688605, 2530391514.785223, 831.0, 8541.953236714027, 2259110179.9091864, 535.0, 8616.299662242236, 2219995629.6073833, 541.0, 8340.140971519355, 2340561731.241773, 616.0, 8386.559023356804, 2294023402.7485433, 695.0]
[2019-03-24 01:48:50,056] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9998164e-01 2.7530167e-20 1.1434426e-11 2.5699466e-14 1.8312130e-05], sum to 1.0000
[2019-03-24 01:48:50,064] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3081
[2019-03-24 01:48:50,067] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.26666666666667, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5454893695357524, 6.9112, 6.9112, 121.9260426156618, 398967.7801920812, 398967.7801920812, 122177.6064999972], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 516000.0000, 
sim time next is 516600.0000, 
raw observation next is [23.1, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5454186809100052, 6.911200000000001, 6.9112, 121.9260426156618, 398976.6811603931, 398976.6811603926, 122198.3379933648], 
processed observation next is [1.0, 1.0, 0.41111111111111115, 0.56, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4317733511375065, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14249167184299755, 0.14249167184299735, 0.23499680383339383], 
reward next is 0.7650, 
noisyNet noise sample is [array([-0.74162745], dtype=float32), 0.52136314]. 
=============================================
[2019-03-24 01:48:59,184] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9982917e-01 5.6769802e-17 8.7435718e-11 2.0618936e-10 1.7073905e-04], sum to 1.0000
[2019-03-24 01:48:59,191] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9861
[2019-03-24 01:48:59,196] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.95, 37.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5608382097411738, 6.911200000000001, 6.9112, 121.9260426156618, 409638.4931463773, 409638.4931463768, 123244.8166578075], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 693000.0000, 
sim time next is 693600.0000, 
raw observation next is [26.8, 37.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5590646756187225, 6.911200000000001, 6.9112, 121.9260426156618, 408010.9690253361, 408010.9690253356, 122952.3181862347], 
processed observation next is [1.0, 0.0, 0.5481481481481482, 0.3733333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4488308445234031, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1457182032233343, 0.14571820322333415, 0.23644676574275902], 
reward next is 0.7636, 
noisyNet noise sample is [array([-0.9567545], dtype=float32), 1.0650766]. 
=============================================
[2019-03-24 01:48:59,973] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999869e-01 4.6679799e-26 1.6102132e-15 9.2786191e-16 1.2902186e-06], sum to 1.0000
[2019-03-24 01:48:59,986] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8681
[2019-03-24 01:48:59,992] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.1, 53.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6302393367424101, 6.911199999999999, 6.9112, 121.9260426156618, 457978.5643456761, 457978.5643456766, 128415.3536855409], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 711600.0000, 
sim time next is 712200.0000, 
raw observation next is [23.2, 53.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6250151485093238, 6.9112, 6.9112, 121.9260426156618, 455046.8842745315, 455046.8842745315, 128290.1797842046], 
processed observation next is [1.0, 0.21739130434782608, 0.4148148148148148, 0.5383333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5312689356366548, 0.0, 0.0, 0.8094621288201359, 0.16251674438376126, 0.16251674438376126, 0.24671188420039347], 
reward next is 0.7533, 
noisyNet noise sample is [array([-0.23151436], dtype=float32), -0.16668208]. 
=============================================
[2019-03-24 01:49:00,737] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9997246e-01 2.9103520e-16 6.2298317e-10 1.5019880e-10 2.7594839e-05], sum to 1.0000
[2019-03-24 01:49:00,744] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3527
[2019-03-24 01:49:00,750] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1343767.644881027 W.
[2019-03-24 01:49:00,754] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.3, 53.0, 1.0, 2.0, 0.9322516601152602, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.265292195972908, 6.9112, 121.9247114032224, 1343767.644881027, 1162442.771903681, 228958.4440787319], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 723600.0000, 
sim time next is 724200.0000, 
raw observation next is [25.43333333333334, 53.0, 1.0, 2.0, 0.3083204178847292, 1.0, 1.0, 0.3083204178847292, 1.0, 1.0, 0.5038124794009794, 6.911200000000001, 6.9112, 121.94756008, 1129293.200545738, 1129293.200545737, 258010.1875717352], 
processed observation next is [1.0, 0.391304347826087, 0.4975308641975311, 0.53, 1.0, 1.0, 0.17657192605324903, 1.0, 0.5, 0.17657192605324903, 1.0, 0.5, 0.3797655992512242, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4033190001949064, 0.4033190001949061, 0.4961734376379523], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.113123], dtype=float32), -0.76224375]. 
=============================================
[2019-03-24 01:49:08,259] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9999201e-01 1.7102729e-19 2.1443670e-10 5.6205214e-12 7.9963156e-06], sum to 1.0000
[2019-03-24 01:49:08,268] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5066
[2019-03-24 01:49:08,277] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.1, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6523691251717417, 6.9112, 6.9112, 121.9260426156618, 486182.2216009459, 486182.2216009459, 137073.7608314156], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 865800.0000, 
sim time next is 866400.0000, 
raw observation next is [23.93333333333334, 62.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.649245973704891, 6.911200000000001, 6.9112, 121.9260426156618, 483727.6433094683, 483727.6433094678, 136628.0734603229], 
processed observation next is [0.0, 0.0, 0.4419753086419756, 0.6266666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5615574671311138, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1727598726105244, 0.17275987261052422, 0.26274629511600556], 
reward next is 0.7373, 
noisyNet noise sample is [array([0.6338437], dtype=float32), 0.02302602]. 
=============================================
[2019-03-24 01:49:11,016] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9998438e-01 2.4125078e-18 7.7649682e-09 2.0878100e-12 1.5619562e-05], sum to 1.0000
[2019-03-24 01:49:11,023] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8435
[2019-03-24 01:49:11,030] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.3, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6489347299803542, 6.911200000000001, 6.9112, 121.9260426156618, 483954.9489428666, 483954.9489428662, 137098.8890525808], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 901800.0000, 
sim time next is 902400.0000, 
raw observation next is [24.43333333333333, 61.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6517077639315533, 6.9112, 6.9112, 121.9260426156618, 486170.7539669792, 486170.7539669792, 137563.5976112195], 
processed observation next is [0.0, 0.43478260869565216, 0.4604938271604937, 0.6166666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5646347049144416, 0.0, 0.0, 0.8094621288201359, 0.173632412131064, 0.173632412131064, 0.26454538002157596], 
reward next is 0.7355, 
noisyNet noise sample is [array([0.12896696], dtype=float32), 1.0674645]. 
=============================================
[2019-03-24 01:49:14,259] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 9.0505254e-24 1.0225400e-14 1.3308122e-15 1.0896303e-11], sum to 1.0000
[2019-03-24 01:49:14,263] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9068
[2019-03-24 01:49:14,271] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.13333333333333, 58.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6023976158299926, 6.9112, 6.9112, 121.9260426156618, 437275.2466354957, 437275.2466354957, 125767.974628687], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 976800.0000, 
sim time next is 977400.0000, 
raw observation next is [22.25, 58.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6037477096269892, 6.911199999999999, 6.9112, 121.9260426156618, 438858.9259908839, 438858.9259908843, 126120.4519255296], 
processed observation next is [1.0, 0.30434782608695654, 0.37962962962962965, 0.585, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5046846370337364, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15673533071102996, 0.1567353307110301, 0.24253933062601846], 
reward next is 0.7575, 
noisyNet noise sample is [array([-2.159359], dtype=float32), 0.4698673]. 
=============================================
[2019-03-24 01:49:17,676] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 6.8001721e-27 9.9235141e-14 4.7375198e-18 3.5508324e-10], sum to 1.0000
[2019-03-24 01:49:17,683] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6787
[2019-03-24 01:49:17,690] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.1, 66.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5589943875474842, 6.9112, 6.9112, 121.9260426156618, 407242.8929824411, 407242.8929824411, 122648.362131136], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1045800.0000, 
sim time next is 1046400.0000, 
raw observation next is [21.03333333333333, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5350589315918213, 6.9112, 6.9112, 121.9260426156618, 389829.385167547, 389829.385167547, 120655.8339030919], 
processed observation next is [1.0, 0.08695652173913043, 0.3345679012345678, 0.67, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.41882366448977654, 0.0, 0.0, 0.8094621288201359, 0.13922478041698105, 0.13922478041698105, 0.23203044981363827], 
reward next is 0.7680, 
noisyNet noise sample is [array([0.7994786], dtype=float32), -1.2107667]. 
=============================================
[2019-03-24 01:49:17,871] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999988e-01 8.2371833e-21 1.4869445e-10 1.5345701e-13 1.0196922e-07], sum to 1.0000
[2019-03-24 01:49:17,885] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2652
[2019-03-24 01:49:17,895] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.46666666666667, 70.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5880352766117085, 6.9112, 6.9112, 121.9260426156618, 428296.3629871624, 428296.3629871624, 125097.1342698011], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1052400.0000, 
sim time next is 1053000.0000, 
raw observation next is [20.4, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5857056968445293, 6.9112, 6.9112, 121.9260426156618, 426468.4853504596, 426468.4853504596, 124841.8811547666], 
processed observation next is [1.0, 0.17391304347826086, 0.31111111111111106, 0.71, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4821321210556616, 0.0, 0.0, 0.8094621288201359, 0.15231017333944985, 0.15231017333944985, 0.24008054068224347], 
reward next is 0.7599, 
noisyNet noise sample is [array([-2.0520036], dtype=float32), 0.65454006]. 
=============================================
[2019-03-24 01:49:17,908] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[65.84705]
 [65.82435]
 [66.11437]
 [66.15715]
 [66.37365]], R is [[65.89707947]
 [65.99753571]
 [66.09157562]
 [66.19451904]
 [66.29675293]].
[2019-03-24 01:49:21,762] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9999559e-01 1.1569239e-19 4.3474956e-06 3.2966108e-12 6.0957248e-08], sum to 1.0000
[2019-03-24 01:49:21,771] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2552
[2019-03-24 01:49:21,776] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.68333333333334, 70.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5899079563394357, 6.9112, 6.9112, 121.9260426156618, 423519.5024312892, 423519.5024312892, 122992.1105604645], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1149000.0000, 
sim time next is 1149600.0000, 
raw observation next is [19.76666666666667, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5205687698724641, 6.9112, 6.9112, 121.9260426156618, 373825.8434021463, 373825.8434021463, 117412.0138132721], 
processed observation next is [1.0, 0.30434782608695654, 0.2876543209876544, 0.7, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4007109623405801, 0.0, 0.0, 0.8094621288201359, 0.13350922978648083, 0.13350922978648083, 0.2257923342562925], 
reward next is 0.7742, 
noisyNet noise sample is [array([-1.5530301], dtype=float32), -0.65683186]. 
=============================================
[2019-03-24 01:49:26,208] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.1201617e-28 8.1097394e-14 1.4554284e-17 1.0175948e-13], sum to 1.0000
[2019-03-24 01:49:26,215] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6627
[2019-03-24 01:49:26,219] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.8, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5958813591457205, 6.9112, 6.9112, 121.9260426156618, 440689.1698869915, 440689.1698869915, 128966.4934142334], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1188000.0000, 
sim time next is 1188600.0000, 
raw observation next is [20.73333333333333, 77.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6004935805108287, 6.9112, 6.9112, 121.9260426156618, 444106.9010177482, 444106.9010177482, 129397.0865110749], 
processed observation next is [1.0, 0.782608695652174, 0.3234567901234567, 0.775, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5006169756385358, 0.0, 0.0, 0.8094621288201359, 0.15860960750633865, 0.15860960750633865, 0.24884055098283633], 
reward next is 0.7512, 
noisyNet noise sample is [array([0.91320443], dtype=float32), -0.23012787]. 
=============================================
[2019-03-24 01:49:27,557] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.4247883e-25 1.1326824e-10 3.9661383e-14 9.8342778e-10], sum to 1.0000
[2019-03-24 01:49:27,567] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5182
[2019-03-24 01:49:27,570] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.01666666666667, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5537356064160053, 6.9112, 6.9112, 121.9260426156618, 405412.9230549557, 405412.9230549557, 123061.3342332381], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1219800.0000, 
sim time next is 1220400.0000, 
raw observation next is [18.0, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.550002826663212, 6.9112, 6.9112, 121.9260426156618, 402578.0262655262, 402578.0262655262, 122697.0431022659], 
processed observation next is [1.0, 0.13043478260869565, 0.2222222222222222, 0.93, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4375035333290149, 0.0, 0.0, 0.8094621288201359, 0.14377786652340221, 0.14377786652340221, 0.23595585211974213], 
reward next is 0.7640, 
noisyNet noise sample is [array([2.257073], dtype=float32), -0.3376682]. 
=============================================
[2019-03-24 01:49:27,901] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999928e-01 1.6332994e-18 2.8189757e-07 3.8852459e-12 4.5902078e-07], sum to 1.0000
[2019-03-24 01:49:27,910] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2301
[2019-03-24 01:49:27,920] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.83333333333334, 88.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.57512654872659, 6.9112, 6.9112, 121.9260426156618, 422818.9020351854, 422818.9020351854, 125722.6004366717], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1236000.0000, 
sim time next is 1236600.0000, 
raw observation next is [18.9, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.598809478599064, 6.9112, 6.9112, 121.9260426156618, 440508.1418916085, 440508.1418916085, 127978.1868199074], 
processed observation next is [1.0, 0.30434782608695654, 0.2555555555555555, 0.885, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.49851184824882994, 0.0, 0.0, 0.8094621288201359, 0.15732433638986018, 0.15732433638986018, 0.24611189773059114], 
reward next is 0.7539, 
noisyNet noise sample is [array([0.4052243], dtype=float32), -0.19329152]. 
=============================================
[2019-03-24 01:49:29,176] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999905e-01 1.6735257e-17 8.9124632e-07 3.4232620e-11 1.2639958e-07], sum to 1.0000
[2019-03-24 01:49:29,186] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9404
[2019-03-24 01:49:29,192] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 892783.6669881386 W.
[2019-03-24 01:49:29,197] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.5, 79.83333333333333, 1.0, 2.0, 0.3592436381842759, 1.0, 2.0, 0.3592436381842759, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 892783.6669881386, 892783.666988139, 198026.1119925861], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1242600.0000, 
sim time next is 1243200.0000, 
raw observation next is [20.7, 78.66666666666667, 1.0, 2.0, 0.3172063004996029, 1.0, 2.0, 0.3172063004996029, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 788290.6186166427, 788290.6186166431, 187099.371226014], 
processed observation next is [1.0, 0.391304347826087, 0.3222222222222222, 0.7866666666666667, 1.0, 1.0, 0.1871503577376225, 1.0, 1.0, 0.1871503577376225, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2815323637916581, 0.28153236379165825, 0.35980648312694996], 
reward next is 0.6402, 
noisyNet noise sample is [array([-0.6528124], dtype=float32), 2.2866795]. 
=============================================
[2019-03-24 01:49:29,521] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9998379e-01 6.2115520e-16 1.0665678e-05 9.1537922e-10 5.6095200e-06], sum to 1.0000
[2019-03-24 01:49:29,529] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8780
[2019-03-24 01:49:29,542] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 842044.5653288089 W.
[2019-03-24 01:49:29,547] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.3, 75.16666666666667, 1.0, 2.0, 0.3388072645281343, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5640731981346482, 6.911199999999999, 6.9112, 121.9260426156618, 842044.5653288089, 842044.5653288093, 202280.2899593734], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1245000.0000, 
sim time next is 1245600.0000, 
raw observation next is [21.5, 74.0, 1.0, 2.0, 0.3499664148217101, 1.0, 1.0, 0.3499664148217101, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 868073.2889099976, 868073.288909998, 195523.8591951545], 
processed observation next is [1.0, 0.43478260869565216, 0.35185185185185186, 0.74, 1.0, 1.0, 0.22615049383536917, 1.0, 0.5, 0.22615049383536917, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3100261746107134, 0.3100261746107136, 0.3760074215291433], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2119272], dtype=float32), 1.2900845]. 
=============================================
[2019-03-24 01:49:30,567] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.000000e+00 3.986923e-20 8.782936e-09 7.428617e-13 1.284439e-08], sum to 1.0000
[2019-03-24 01:49:30,575] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7684
[2019-03-24 01:49:30,579] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.83333333333333, 89.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5611072703179892, 6.911200000000001, 6.9112, 121.9260426156618, 413072.8966014844, 413072.896601484, 124769.7505850357], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1309200.0000, 
sim time next is 1309800.0000, 
raw observation next is [18.76666666666667, 89.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5582411563446891, 6.9112, 6.9112, 121.9260426156618, 410818.2176039992, 410818.2176039992, 124445.2413476227], 
processed observation next is [1.0, 0.13043478260869565, 0.2506172839506174, 0.8966666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4478014454308613, 0.0, 0.0, 0.8094621288201359, 0.1467207920014283, 0.1467207920014283, 0.23931777182235134], 
reward next is 0.7607, 
noisyNet noise sample is [array([0.7397286], dtype=float32), 1.1112278]. 
=============================================
[2019-03-24 01:49:38,701] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 01:49:38,707] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:49:38,708] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:49:38,710] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:49:38,712] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:49:38,712] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:49:38,713] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:49:38,716] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:49:38,715] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:49:38,717] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:49:38,718] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:49:38,726] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run11
[2019-03-24 01:49:38,751] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run11
[2019-03-24 01:49:38,785] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run11
[2019-03-24 01:49:38,788] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run11
[2019-03-24 01:49:38,839] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run11
[2019-03-24 01:50:29,803] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.10737446]
[2019-03-24 01:50:29,804] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.33333333333334, 73.66666666666667, 1.0, 2.0, 0.947156902278997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1079689.362543379, 1079689.362543379, 228232.961636761]
[2019-03-24 01:50:29,806] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:50:29,809] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.3739068e-26 7.3441578e-13 9.9462812e-16 8.9824835e-11], sampled 0.07853453058073101
[2019-03-24 01:50:29,810] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1079689.362543379 W.
[2019-03-24 01:50:44,756] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.10737446]
[2019-03-24 01:50:44,760] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.385470445, 65.39441471166666, 1.0, 2.0, 0.858242163568201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 978268.3847369036, 978268.3847369036, 208267.2290781465]
[2019-03-24 01:50:44,760] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:50:44,763] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.9656939e-24 4.5594500e-12 9.5282126e-15 4.0469642e-10], sampled 0.5238572218239491
[2019-03-24 01:50:44,764] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 978268.3847369036 W.
[2019-03-24 01:50:56,792] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.10737446]
[2019-03-24 01:50:56,793] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.3, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7748133417999713, 6.9112, 6.9112, 121.9260426156618, 576668.5148492754, 576668.5148492754, 156575.6302419748]
[2019-03-24 01:50:56,794] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:50:56,798] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 3.1773662e-28 6.7575882e-14 5.2712554e-17 1.2275040e-11], sampled 0.9273708085311045
[2019-03-24 01:51:00,476] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.10737446]
[2019-03-24 01:51:00,477] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.16666666666666, 83.16666666666667, 1.0, 2.0, 0.6961532331147346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 793415.4823598762, 793415.4823598762, 175417.6637903582]
[2019-03-24 01:51:00,477] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:51:00,479] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 6.9868940e-27 3.0470646e-13 3.3633444e-16 4.3571372e-11], sampled 0.3278132770301141
[2019-03-24 01:51:00,480] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 793415.4823598762 W.
[2019-03-24 01:51:11,065] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.10737446]
[2019-03-24 01:51:11,065] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.66507776333333, 62.65383652, 1.0, 2.0, 0.8267580351519783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 958214.8754682888, 958214.8754682888, 202352.3056869359]
[2019-03-24 01:51:11,066] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:51:11,068] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 9.9293281e-25 3.3309011e-12 6.4227849e-15 3.1637526e-10], sampled 0.5951125524250767
[2019-03-24 01:51:11,069] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 958214.8754682888 W.
[2019-03-24 01:51:18,697] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.10737446]
[2019-03-24 01:51:18,698] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.72129425333333, 93.89092203333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6326380833177904, 6.9112, 6.9112, 121.9260426156618, 472011.8936396559, 472011.8936396559, 135727.9396683334]
[2019-03-24 01:51:18,699] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:51:18,701] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.00000000e+00 2.42230805e-28 5.93397063e-14 4.48981262e-17
 1.10306556e-11], sampled 0.20284307865162576
[2019-03-24 01:51:21,032] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 01:51:21,040] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 01:51:21,181] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 01:51:21,190] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 01:51:21,310] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7839.2980 2529817172.9303 831.0000
[2019-03-24 01:51:22,324] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 250000, evaluation results [250000.0, 7839.298043065237, 2529817172.930288, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 01:51:24,941] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.1235044e-27 1.8115349e-13 5.9199856e-18 2.9809367e-11], sum to 1.0000
[2019-03-24 01:51:24,953] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9484
[2019-03-24 01:51:24,959] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.88333333333333, 66.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6183044125378251, 6.9112, 6.9112, 121.9260426156618, 459275.9645618869, 459275.9645618869, 132365.6907920498], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1489800.0000, 
sim time next is 1490400.0000, 
raw observation next is [23.2, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6213169720575595, 6.9112, 6.9112, 121.9260426156618, 461774.0944889897, 461774.0944889897, 132852.5474487836], 
processed observation next is [0.0, 0.2608695652173913, 0.4148148148148148, 0.65, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5266462150719494, 0.0, 0.0, 0.8094621288201359, 0.16491931946035346, 0.16491931946035346, 0.25548566817073765], 
reward next is 0.7445, 
noisyNet noise sample is [array([-1.8938205], dtype=float32), -1.8485278]. 
=============================================
[2019-03-24 01:51:26,396] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.9948590e-25 2.9876861e-12 1.7889678e-14 5.2964919e-13], sum to 1.0000
[2019-03-24 01:51:26,403] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0535
[2019-03-24 01:51:26,406] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.2, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8803839326207036, 6.9112, 6.9112, 121.9260426156618, 650148.1797353628, 650148.1797353628, 171876.0710259272], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1534200.0000, 
sim time next is 1534800.0000, 
raw observation next is [28.7, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8495791300954212, 6.911200000000001, 6.9112, 121.9260426156618, 627863.196986527, 627863.1969865265, 167782.4343310413], 
processed observation next is [0.0, 0.782608695652174, 0.6185185185185185, 0.56, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8119739126192765, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22423685606661678, 0.2242368560666166, 0.3226585275596948], 
reward next is 0.6773, 
noisyNet noise sample is [array([1.0777477], dtype=float32), 0.30151817]. 
=============================================
[2019-03-24 01:51:29,514] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.6755209e-19 4.5517758e-09 1.1974292e-09 2.6738574e-08], sum to 1.0000
[2019-03-24 01:51:29,521] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4348
[2019-03-24 01:51:29,525] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 75.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6453531860948983, 6.911200000000001, 6.9112, 121.9260426156618, 480284.6345435274, 480284.6345435269, 135730.0789385446], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1561800.0000, 
sim time next is 1562400.0000, 
raw observation next is [21.7, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6445907837227756, 6.9112, 6.9112, 121.9260426156618, 479699.6430867161, 479699.6430867161, 135638.9006255336], 
processed observation next is [1.0, 0.08695652173913043, 0.3592592592592592, 0.76, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5557384796534695, 0.0, 0.0, 0.8094621288201359, 0.17132130110239863, 0.17132130110239863, 0.2608440396644877], 
reward next is 0.7392, 
noisyNet noise sample is [array([0.36418203], dtype=float32), -1.0734323]. 
=============================================
[2019-03-24 01:51:30,572] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9999988e-01 1.0250887e-17 1.9051285e-09 2.2325627e-11 9.6025921e-08], sum to 1.0000
[2019-03-24 01:51:30,578] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5466
[2019-03-24 01:51:30,584] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1288629.841839002 W.
[2019-03-24 01:51:30,590] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.53333333333333, 56.66666666666667, 1.0, 2.0, 0.9201554554568386, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.186255791453883, 6.9112, 121.9248770668167, 1288629.841839002, 1147778.038888973, 226129.9338215011], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1588800.0000, 
sim time next is 1589400.0000, 
raw observation next is [24.65, 56.5, 1.0, 2.0, 0.9402499679651882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.334390312530598, 6.9112, 121.9240484883917, 1391973.056127948, 1175265.336151795, 230913.8906664632], 
processed observation next is [1.0, 0.391304347826087, 0.46851851851851845, 0.565, 1.0, 1.0, 0.928869009482367, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.04231903125305978, 0.0, 0.8094488898888087, 0.49713323433141, 0.4197376200542125, 0.4440651743585831], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8768363], dtype=float32), -0.48972493]. 
=============================================
[2019-03-24 01:51:37,732] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.4301247e-22 1.4588446e-09 1.3125231e-12 1.9414657e-10], sum to 1.0000
[2019-03-24 01:51:37,742] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8489
[2019-03-24 01:51:37,745] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.76666666666667, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6630888161894452, 6.911200000000001, 6.9112, 121.9260426156618, 494748.7775904469, 494748.7775904465, 138843.2964147798], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1723200.0000, 
sim time next is 1723800.0000, 
raw observation next is [21.68333333333334, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6569776095755387, 6.911200000000001, 6.9112, 121.9260426156618, 490021.4429502197, 490021.4429502193, 137999.2916880847], 
processed observation next is [1.0, 0.9565217391304348, 0.3586419753086422, 0.79, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5712220119694233, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17500765819650702, 0.1750076581965069, 0.26538325324631673], 
reward next is 0.7346, 
noisyNet noise sample is [array([-0.17818606], dtype=float32), -0.28610182]. 
=============================================
[2019-03-24 01:51:43,634] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9998212e-01 8.5445798e-19 3.7438560e-06 2.9761557e-08 1.4235229e-05], sum to 1.0000
[2019-03-24 01:51:43,639] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4777
[2019-03-24 01:51:43,648] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 805038.5498855319 W.
[2019-03-24 01:51:43,652] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 80.66666666666667, 1.0, 2.0, 0.3301584999393697, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5389500007088268, 6.911200000000001, 6.9112, 121.9260426156618, 805038.5498855319, 805038.5498855314, 201274.7673170638], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1858800.0000, 
sim time next is 1859400.0000, 
raw observation next is [21.9, 81.0, 1.0, 2.0, 0.5825346549832329, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717117.1386504472, 717117.1386504472, 157180.1893380852], 
processed observation next is [1.0, 0.5217391304347826, 0.36666666666666664, 0.81, 1.0, 1.0, 0.5030174464086106, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2561132638037312, 0.2561132638037312, 0.3022695948809331], 
reward next is 0.6977, 
noisyNet noise sample is [array([0.77488375], dtype=float32), -0.74175847]. 
=============================================
[2019-03-24 01:51:49,106] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.2533254e-21 1.3198310e-08 8.9724745e-13 4.4487919e-10], sum to 1.0000
[2019-03-24 01:51:49,117] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6677
[2019-03-24 01:51:49,125] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.1, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.627936341212489, 6.9112, 6.9112, 121.9260426156618, 468295.8093931106, 468295.8093931106, 134993.1781394396], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1924200.0000, 
sim time next is 1924800.0000, 
raw observation next is [20.13333333333333, 91.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6638387478769683, 6.911200000000001, 6.9112, 121.9260426156618, 495110.7442863549, 495110.7442863545, 138667.1660523165], 
processed observation next is [1.0, 0.2608695652173913, 0.30123456790123443, 0.9133333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5797984348462103, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17682526581655533, 0.1768252658165552, 0.26666762702368557], 
reward next is 0.7333, 
noisyNet noise sample is [array([0.14191511], dtype=float32), 0.7480139]. 
=============================================
[2019-03-24 01:51:54,614] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9999976e-01 1.8333263e-23 2.0858155e-07 2.6750881e-14 2.1266462e-09], sum to 1.0000
[2019-03-24 01:51:54,622] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4393
[2019-03-24 01:51:54,625] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.65, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8461780905073077, 6.9112, 6.9112, 121.9260426156618, 622437.6532588879, 622437.6532588879, 168202.185297433], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2035800.0000, 
sim time next is 2036400.0000, 
raw observation next is [27.8, 63.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8528068337900093, 6.911200000000001, 6.9112, 121.9260426156618, 626644.3342059605, 626644.3342059602, 169214.1711339329], 
processed observation next is [0.0, 0.5652173913043478, 0.5851851851851853, 0.6366666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8160085422375115, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22380154793070017, 0.22380154793070006, 0.3254118675652556], 
reward next is 0.6746, 
noisyNet noise sample is [array([0.5021547], dtype=float32), -1.8562689]. 
=============================================
[2019-03-24 01:51:58,994] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999940e-01 2.7281366e-24 3.2242602e-07 5.2701750e-14 2.7232991e-07], sum to 1.0000
[2019-03-24 01:51:59,000] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0890
[2019-03-24 01:51:59,004] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.08333333333334, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7010728193285627, 6.911200000000001, 6.9112, 121.9260426156618, 523842.4251697067, 523842.4251697062, 145477.9160594924], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2094600.0000, 
sim time next is 2095200.0000, 
raw observation next is [21.2, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7041791682828537, 6.911199999999999, 6.9112, 121.9260426156618, 526126.4833966142, 526126.4833966147, 145964.3796153402], 
processed observation next is [0.0, 0.2608695652173913, 0.34074074074074073, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.630223960353567, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1879023154987908, 0.18790231549879094, 0.2807007300295004], 
reward next is 0.7193, 
noisyNet noise sample is [array([0.46776095], dtype=float32), -0.6530802]. 
=============================================
[2019-03-24 01:52:04,929] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9999976e-01 1.0074656e-16 7.7677798e-10 2.2639378e-08 2.6866437e-07], sum to 1.0000
[2019-03-24 01:52:04,938] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5368
[2019-03-24 01:52:04,947] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.73333333333333, 94.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8550239094077066, 6.911200000000001, 6.9112, 121.9260426156618, 631417.9702842914, 631417.970284291, 168624.9567316326], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2231400.0000, 
sim time next is 2232000.0000, 
raw observation next is [22.7, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8484695160862537, 6.9112, 6.9112, 121.9260426156618, 626957.7531994256, 626957.7531994256, 167670.5721695838], 
processed observation next is [1.0, 0.8695652173913043, 0.39629629629629626, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8105868951078171, 0.0, 0.0, 0.8094621288201359, 0.22391348328550917, 0.22391348328550917, 0.32244340801843036], 
reward next is 0.6776, 
noisyNet noise sample is [array([-0.02538304], dtype=float32), -0.39910007]. 
=============================================
[2019-03-24 01:52:04,964] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[49.46704 ]
 [49.41693 ]
 [49.254803]
 [49.211422]
 [49.548946]], R is [[49.55151367]
 [49.73171997]
 [49.90855408]
 [50.08304214]
 [50.25503922]].
[2019-03-24 01:52:07,449] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.0394421e-24 1.5083136e-14 2.6261013e-14 1.4010283e-10], sum to 1.0000
[2019-03-24 01:52:07,455] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3888
[2019-03-24 01:52:07,459] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.4, 95.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6779616655506695, 6.9112, 6.9112, 121.9260426156618, 506610.2435691761, 506610.2435691761, 142105.8807981062], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2265600.0000, 
sim time next is 2266200.0000, 
raw observation next is [20.4, 95.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6775388133674536, 6.911200000000001, 6.9112, 121.9260426156618, 506299.8214316124, 506299.821431612, 142109.5647297219], 
processed observation next is [1.0, 0.21739130434782608, 0.31111111111111106, 0.955, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.596923516709317, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18082136479700445, 0.18082136479700428, 0.2732876244802344], 
reward next is 0.7267, 
noisyNet noise sample is [array([-0.46798256], dtype=float32), 0.017170578]. 
=============================================
[2019-03-24 01:52:12,666] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 01:52:12,667] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:52:12,669] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:52:12,671] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:52:12,672] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:52:12,673] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:52:12,673] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:52:12,673] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:52:12,674] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:52:12,674] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:52:12,675] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:52:12,694] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run12
[2019-03-24 01:52:12,694] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run12
[2019-03-24 01:52:12,695] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run12
[2019-03-24 01:52:12,717] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run12
[2019-03-24 01:52:12,771] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run12
[2019-03-24 01:52:35,347] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.114120826]
[2019-03-24 01:52:35,348] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7490592403497155, 6.911199999999999, 6.9112, 121.9260426156618, 557707.4438963968, 557707.4438963972, 153349.9742032316]
[2019-03-24 01:52:35,349] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:52:35,353] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 8.1001765e-20 8.0362999e-12 1.5241988e-11 1.1174964e-09], sampled 0.9688972113690744
[2019-03-24 01:52:45,408] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.114120826]
[2019-03-24 01:52:45,409] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.35, 38.5, 1.0, 2.0, 0.7903330563118852, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1615907.021728872, 1615907.021728872, 334316.1549885481]
[2019-03-24 01:52:45,411] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:52:45,415] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.00000000e+00 1.02966926e-19 9.66215476e-12 1.84944820e-11
 1.33781508e-09], sampled 0.7537387061481033
[2019-03-24 01:52:45,416] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1615907.021728872 W.
[2019-03-24 01:53:14,750] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.114120826]
[2019-03-24 01:53:14,752] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.02575163666667, 60.84301938, 1.0, 2.0, 0.6975931048856161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 795057.3752690579, 795057.3752690579, 175689.2887865271]
[2019-03-24 01:53:14,753] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:53:14,757] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 4.3718372e-19 2.1682496e-11 4.0232651e-11 2.4858797e-09], sampled 0.8731318728570724
[2019-03-24 01:53:14,758] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 795057.3752690579 W.
[2019-03-24 01:53:15,737] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.114120826]
[2019-03-24 01:53:15,739] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8736694466645615, 6.9112, 6.9112, 121.9260426156618, 640364.3534857937, 640364.3534857937, 172273.2469528323]
[2019-03-24 01:53:15,739] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:53:15,746] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.1381207e-21 1.2048203e-12 2.3952899e-12 2.4314167e-10], sampled 0.3847618176676091
[2019-03-24 01:53:46,579] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.114120826]
[2019-03-24 01:53:46,580] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.7, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9181123007467595, 6.911199999999999, 6.9112, 121.9260426156618, 665485.4744714273, 665485.4744714277, 179457.6445912556]
[2019-03-24 01:53:46,580] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:53:46,583] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 7.6456957e-20 7.8592029e-12 1.4903937e-11 1.1021749e-09], sampled 0.9078860704553373
[2019-03-24 01:53:54,398] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.114120826]
[2019-03-24 01:53:54,399] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.93333333333333, 36.16666666666666, 1.0, 2.0, 0.5909155962096662, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9572543690439375, 6.9112, 6.9112, 121.9260425122274, 1426421.810728508, 1426421.810728508, 288122.5685567735]
[2019-03-24 01:53:54,401] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:53:54,404] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.9268628e-19 1.3585547e-11 2.5565723e-11 1.7118881e-09], sampled 0.1122947527463849
[2019-03-24 01:53:54,406] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1426421.810728508 W.
[2019-03-24 01:53:54,970] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8363.4371 2339475986.9735 616.0000
[2019-03-24 01:53:55,002] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 01:53:55,056] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8403.4437 2293032039.0419 697.0000
[2019-03-24 01:53:55,186] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8559.5151 2258223744.7508 536.0000
[2019-03-24 01:53:55,274] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 01:53:56,291] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 275000, evaluation results [275000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8559.515058168116, 2258223744.7507515, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8363.437110714249, 2339475986.973477, 616.0, 8403.44368145064, 2293032039.0418916, 697.0]
[2019-03-24 01:53:56,761] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.5852809e-01 2.0082348e-10 1.2394268e-02 1.2711182e-04 3.2895058e-01], sum to 1.0000
[2019-03-24 01:53:56,769] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4749
[2019-03-24 01:53:56,776] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1359934.143720018 W.
[2019-03-24 01:53:56,779] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.9, 38.0, 1.0, 2.0, 0.9488004053353625, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.288465345364638, 6.9112, 121.9244825427353, 1359934.143720018, 1166743.03925748, 232438.3480578453], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2376000.0000, 
sim time next is 2376600.0000, 
raw observation next is [30.0, 37.83333333333334, 1.0, 2.0, 0.3905854004162589, 1.0, 1.0, 0.3905854004162589, 1.0, 1.0, 0.6307486980783458, 6.911199999999999, 6.9112, 121.94756008, 1406927.597470116, 1406927.597470116, 292507.2676236368], 
processed observation next is [1.0, 0.5217391304347826, 0.6666666666666666, 0.3783333333333334, 1.0, 1.0, 0.27450642906697487, 1.0, 0.5, 0.27450642906697487, 1.0, 0.5, 0.5384358725979321, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5024741419536128, 0.5024741419536128, 0.5625139761993015], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6266587], dtype=float32), -1.4834156]. 
=============================================
[2019-03-24 01:53:57,900] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.4006817e-20 9.4116848e-13 1.4133855e-10 1.1569243e-08], sum to 1.0000
[2019-03-24 01:53:57,908] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1749
[2019-03-24 01:53:57,918] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1367016.029650889 W.
[2019-03-24 01:53:57,922] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.01666666666667, 37.0, 1.0, 2.0, 0.5692888476478705, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9193186259669454, 6.911199999999999, 6.9112, 121.9260426156618, 1367016.029650889, 1367016.029650889, 280255.416423231], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2386200.0000, 
sim time next is 2386800.0000, 
raw observation next is [31.0, 37.0, 1.0, 2.0, 0.5851688751218787, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9465468042079487, 6.911200000000001, 6.9112, 121.9260426156618, 1409204.982817064, 1409204.982817064, 286080.4765278442], 
processed observation next is [1.0, 0.6521739130434783, 0.7037037037037037, 0.37, 1.0, 1.0, 0.5061534227641412, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9331835052599358, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5032874938632371, 0.5032874938632371, 0.5501547625535466], 
reward next is 0.4498, 
noisyNet noise sample is [array([1.3212035], dtype=float32), 0.07369946]. 
=============================================
[2019-03-24 01:53:58,615] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.5593714e-22 1.3152433e-14 7.4746988e-12 1.1729353e-08], sum to 1.0000
[2019-03-24 01:53:58,622] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6279
[2019-03-24 01:53:58,626] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.35, 60.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6370910589841682, 6.9112, 6.9112, 121.9260426156618, 474672.5271166008, 474672.5271166008, 135412.9918662141], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2413800.0000, 
sim time next is 2414400.0000, 
raw observation next is [24.13333333333333, 61.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.637442635528513, 6.911199999999999, 6.9112, 121.9260426156618, 474904.7333167108, 474904.7333167113, 135418.1245644508], 
processed observation next is [1.0, 0.9565217391304348, 0.44938271604938257, 0.6166666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5468032944106412, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1696088333273967, 0.1696088333273969, 0.2604194703162515], 
reward next is 0.7396, 
noisyNet noise sample is [array([0.9670054], dtype=float32), 0.43613604]. 
=============================================
[2019-03-24 01:54:01,499] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.3094944e-04 2.2112089e-24 1.8047455e-10 1.3068534e-09 9.9946910e-01], sum to 1.0000
[2019-03-24 01:54:01,506] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2563
[2019-03-24 01:54:01,509] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.25, 25.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2165880264892412, 6.9112, 6.9112, 121.94756008, 485524.4902335461, 485524.4902335461, 193132.9889128937], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2482200.0000, 
sim time next is 2482800.0000, 
raw observation next is [33.03333333333333, 26.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2155374914524429, 6.911200000000001, 6.9112, 121.94756008, 483189.344221135, 483189.3442211345, 192703.0520907592], 
processed observation next is [1.0, 0.7391304347826086, 0.7790123456790122, 0.26, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.019421864315553594, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.17256762293611966, 0.17256762293611946, 0.37058279248222925], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.20824619], dtype=float32), -0.103740394]. 
=============================================
[2019-03-24 01:54:05,838] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999988e-01 8.9675370e-15 1.2064777e-09 3.2979632e-09 1.2698411e-07], sum to 1.0000
[2019-03-24 01:54:05,843] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9044
[2019-03-24 01:54:05,848] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1502459.778890599 W.
[2019-03-24 01:54:05,855] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.1, 30.0, 1.0, 2.0, 0.6217845120723232, 1.0, 2.0, 0.6217845120723232, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1502459.778890599, 1502459.7788906, 279248.2019744962], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2545800.0000, 
sim time next is 2546400.0000, 
raw observation next is [32.2, 30.0, 1.0, 2.0, 0.6228168374956381, 1.0, 2.0, 0.6228168374956381, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1503130.011233475, 1503130.011233475, 279555.240325696], 
processed observation next is [1.0, 0.4782608695652174, 0.7481481481481482, 0.3, 1.0, 1.0, 0.5509724255900453, 1.0, 1.0, 0.5509724255900453, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5368321468690982, 0.5368321468690982, 0.5376062313955693], 
reward next is 0.4624, 
noisyNet noise sample is [array([0.5512193], dtype=float32), -0.67645603]. 
=============================================
[2019-03-24 01:54:08,357] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.1532109e-25 3.7070111e-16 1.7464117e-16 3.4560332e-12], sum to 1.0000
[2019-03-24 01:54:08,365] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8025
[2019-03-24 01:54:08,368] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.53333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7487683087860355, 6.911199999999999, 6.9112, 121.9260426156618, 558964.459920045, 558964.4599200455, 151967.5547108368], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2600400.0000, 
sim time next is 2601000.0000, 
raw observation next is [21.45, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7469358679975173, 6.9112, 6.9112, 121.9260426156618, 557636.4679539811, 557636.4679539811, 151697.9270061144], 
processed observation next is [0.0, 0.08695652173913043, 0.35, 0.925, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6836698349968967, 0.0, 0.0, 0.8094621288201359, 0.1991558814121361, 0.1991558814121361, 0.29172678270406616], 
reward next is 0.7083, 
noisyNet noise sample is [array([1.2177255], dtype=float32), 1.2493274]. 
=============================================
[2019-03-24 01:54:08,388] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[63.177723]
 [63.15358 ]
 [63.146725]
 [63.02194 ]
 [63.06947 ]], R is [[63.18320084]
 [63.25912476]
 [63.33376694]
 [63.40697861]
 [63.47848129]].
[2019-03-24 01:54:09,873] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.5513128e-29 1.1195980e-20 2.6588869e-18 1.9549102e-17], sum to 1.0000
[2019-03-24 01:54:09,884] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2708
[2019-03-24 01:54:09,888] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.6, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7265967900468963, 6.911200000000001, 6.9112, 121.9260426156618, 542857.3420342486, 542857.3420342482, 148553.1899915311], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2610000.0000, 
sim time next is 2610600.0000, 
raw observation next is [20.55, 97.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7255737830374184, 6.911200000000001, 6.9112, 121.9260426156618, 542098.077456882, 542098.0774568815, 148421.1766970241], 
processed observation next is [0.0, 0.21739130434782608, 0.3166666666666667, 0.975, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6569672287967728, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1936064562346007, 0.19360645623460054, 0.2854253398019694], 
reward next is 0.7146, 
noisyNet noise sample is [array([-1.2113671], dtype=float32), -1.755036]. 
=============================================
[2019-03-24 01:54:23,867] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.5267731e-23 2.2501515e-14 9.9546700e-16 7.8344364e-15], sum to 1.0000
[2019-03-24 01:54:23,877] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4523
[2019-03-24 01:54:23,886] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1434677.131588184 W.
[2019-03-24 01:54:23,893] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.76666666666667, 87.33333333333333, 1.0, 2.0, 0.62913918983343, 1.0, 1.0, 0.62913918983343, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1434677.131588184, 1434677.131588184, 278208.8389096661], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2893200.0000, 
sim time next is 2893800.0000, 
raw observation next is [24.88333333333333, 88.16666666666667, 1.0, 2.0, 0.4179858884925497, 1.0, 2.0, 0.4179858884925497, 1.0, 1.0, 0.6654471473301647, 6.9112, 6.9112, 121.94756008, 1429745.860027582, 1429745.860027582, 305050.5596637702], 
processed observation next is [1.0, 0.4782608695652174, 0.47716049382716036, 0.8816666666666667, 1.0, 1.0, 0.3071260577292258, 1.0, 1.0, 0.3071260577292258, 1.0, 0.5, 0.5818089341627058, 0.0, 0.0, 0.8096049824067558, 0.5106235214384222, 0.5106235214384222, 0.5866356916610965], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2753864], dtype=float32), 1.8613659]. 
=============================================
[2019-03-24 01:54:26,081] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 6.9841885e-16 3.5550154e-09 6.5541503e-11 5.5460359e-11], sum to 1.0000
[2019-03-24 01:54:26,092] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2725
[2019-03-24 01:54:26,099] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 954487.7226052842 W.
[2019-03-24 01:54:26,102] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 89.0, 1.0, 2.0, 0.837025519453867, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 954487.7226052842, 954487.7226052837, 203724.0571232473], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2897400.0000, 
sim time next is 2898000.0000, 
raw observation next is [25.0, 89.0, 1.0, 2.0, 0.4997829567923049, 1.0, 1.0, 0.4997829567923049, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1139476.215059996, 1139476.215059996, 235315.1522822606], 
processed observation next is [1.0, 0.5652173913043478, 0.48148148148148145, 0.89, 1.0, 1.0, 0.4045035199908391, 1.0, 0.5, 0.4045035199908391, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4069557910928557, 0.4069557910928557, 0.45252913900434727], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.24679865], dtype=float32), 1.2761375]. 
=============================================
[2019-03-24 01:54:26,120] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[34.546387]
 [34.538677]
 [34.463673]
 [35.103146]
 [34.867886]], R is [[34.14142227]
 [34.40822983]
 [34.65396881]
 [34.87766647]
 [34.5288887 ]].
[2019-03-24 01:54:32,694] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9460948e-01 1.3661498e-12 1.1588522e-05 1.8679600e-09 5.3789075e-03], sum to 1.0000
[2019-03-24 01:54:32,703] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0126
[2019-03-24 01:54:32,709] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1688072.461234775 W.
[2019-03-24 01:54:32,714] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.4934293500352051, 1.0, 2.0, 0.4934293500352051, 1.0, 1.0, 0.7855555951280809, 6.9112, 6.9112, 121.94756008, 1688072.461234775, 1688072.461234775, 340375.7828934382], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3056400.0000, 
sim time next is 3057000.0000, 
raw observation next is [27.16666666666666, 89.0, 1.0, 2.0, 0.512421179863842, 1.0, 2.0, 0.512421179863842, 1.0, 2.0, 0.8157912067359872, 6.911199999999999, 6.9112, 121.94756008, 1753109.204073332, 1753109.204073332, 349727.3432181798], 
processed observation next is [1.0, 0.391304347826087, 0.5617283950617282, 0.89, 1.0, 1.0, 0.41954902364743085, 1.0, 1.0, 0.41954902364743085, 1.0, 1.0, 0.769739008419984, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.62611043002619, 0.62611043002619, 0.6725525831118843], 
reward next is 0.3274, 
noisyNet noise sample is [array([0.21715432], dtype=float32), -0.37997478]. 
=============================================
[2019-03-24 01:54:32,730] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[36.457542]
 [35.964634]
 [35.351635]
 [34.79913 ]
 [35.657703]], R is [[37.40463638]
 [37.03059006]
 [37.02906036]
 [37.01915359]
 [36.64896393]].
[2019-03-24 01:54:39,192] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9999976e-01 3.7795534e-13 9.7079607e-09 9.3574391e-11 2.6247056e-07], sum to 1.0000
[2019-03-24 01:54:39,197] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5429
[2019-03-24 01:54:39,210] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1959026.616168398 W.
[2019-03-24 01:54:39,213] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.0, 32.0, 1.0, 2.0, 0.8550865651792174, 1.0, 2.0, 0.8550865651792174, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1959026.616168398, 1959026.616168398, 367505.7786380576], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3168000.0000, 
sim time next is 3168600.0000, 
raw observation next is [34.95, 32.0, 1.0, 2.0, 0.55566834573056, 1.0, 2.0, 0.55566834573056, 1.0, 1.0, 0.8846421032576648, 6.911200000000001, 6.9112, 121.94756008, 1901225.018925302, 1901225.018925301, 371751.0484650285], 
processed observation next is [1.0, 0.6956521739130435, 0.8500000000000001, 0.32, 1.0, 1.0, 0.47103374491733335, 1.0, 1.0, 0.47103374491733335, 1.0, 0.5, 0.855802629072081, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.679008935330465, 0.6790089353304647, 0.7149058624327471], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4608703], dtype=float32), 0.5270513]. 
=============================================
[2019-03-24 01:54:42,583] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.9570024e-29 3.3547124e-21 3.9747491e-25 6.9383967e-19], sum to 1.0000
[2019-03-24 01:54:42,591] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6770
[2019-03-24 01:54:42,602] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 692522.6611511658 W.
[2019-03-24 01:54:42,608] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.33333333333334, 75.66666666666666, 1.0, 2.0, 0.3013793853597146, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4800892116443103, 6.9112, 6.9112, 121.9260426156618, 692522.6611511658, 692522.6611511658, 195515.5639113736], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3195600.0000, 
sim time next is 3196200.0000, 
raw observation next is [26.16666666666667, 74.83333333333334, 1.0, 2.0, 0.2931901146094001, 1.0, 1.0, 0.2931901146094001, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 675639.7203330141, 675639.7203330146, 179199.7243179648], 
processed observation next is [1.0, 1.0, 0.5246913580246916, 0.7483333333333334, 1.0, 1.0, 0.15855966024928583, 1.0, 0.5, 0.15855966024928583, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24129990011893362, 0.2412999001189338, 0.34461485445762463], 
reward next is 0.6554, 
noisyNet noise sample is [array([0.43689692], dtype=float32), 2.397907]. 
=============================================
[2019-03-24 01:54:44,103] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 9.3253759e-36 1.4983854e-23 6.0866101e-30 6.9558044e-20], sum to 1.0000
[2019-03-24 01:54:44,110] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3821
[2019-03-24 01:54:44,113] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.7, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8159391002427872, 6.911199999999999, 6.9112, 121.9260426156618, 605172.1519035476, 605172.151903548, 162732.7099801988], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3234000.0000, 
sim time next is 3234600.0000, 
raw observation next is [29.05, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8116679170440895, 6.9112, 6.9112, 121.9260426156618, 602331.4786813528, 602331.4786813528, 162048.5927993107], 
processed observation next is [0.0, 0.43478260869565216, 0.6314814814814815, 0.52, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7645848963051118, 0.0, 0.0, 0.8094621288201359, 0.2151183852433403, 0.2151183852433403, 0.3116319092294436], 
reward next is 0.6884, 
noisyNet noise sample is [array([0.1905282], dtype=float32), 0.46186024]. 
=============================================
[2019-03-24 01:54:45,332] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.6735681e-29 7.1741142e-20 1.0627692e-24 1.5676411e-18], sum to 1.0000
[2019-03-24 01:54:45,340] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6614
[2019-03-24 01:54:45,348] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 92.66666666666667, 1.0, 2.0, 0.197725723555451, 1.0, 2.0, 0.197725723555451, 1.0, 2.0, 0.3148341838169179, 6.911200000000001, 6.9112, 121.94756008, 677969.6859718349, 677969.6859718345, 219860.0382866653], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3277200.0000, 
sim time next is 3277800.0000, 
raw observation next is [23.4, 92.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9115824294110297, 6.911200000000001, 6.9112, 121.9260426156618, 665451.7724154331, 665451.7724154326, 177817.414528576], 
processed observation next is [0.0, 0.9565217391304348, 0.42222222222222217, 0.92, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8894780367637872, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2376613472912261, 0.23766134729122593, 0.34195656640110766], 
reward next is 0.6580, 
noisyNet noise sample is [array([-1.2668916], dtype=float32), 1.5432005]. 
=============================================
[2019-03-24 01:54:46,706] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 01:54:46,711] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:54:46,712] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:54:46,713] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:54:46,714] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:54:46,713] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:54:46,714] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:54:46,717] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:54:46,715] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:54:46,718] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:54:46,719] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:54:46,736] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run13
[2019-03-24 01:54:46,760] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run13
[2019-03-24 01:54:46,761] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run13
[2019-03-24 01:54:46,762] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run13
[2019-03-24 01:54:46,827] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run13
[2019-03-24 01:54:59,968] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.11765843]
[2019-03-24 01:54:59,969] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.96317972, 64.55901945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5481836360779068, 6.911199999999999, 6.9112, 121.9260426156618, 402027.8849491721, 402027.8849491726, 122898.0533318555]
[2019-03-24 01:54:59,970] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:54:59,973] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 5.3552813e-34 9.0897618e-24 1.6202295e-28 1.6908764e-20], sampled 0.5232050978317861
[2019-03-24 01:55:53,682] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.11765843]
[2019-03-24 01:55:53,683] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.22298677333333, 94.83688091500001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8371524086482004, 6.9112, 6.9112, 121.9260426156618, 620135.0031500271, 620135.0031500271, 165692.0988244394]
[2019-03-24 01:55:53,684] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:55:53,687] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.000000e+00 1.576888e-35 7.806086e-25 8.433740e-30 2.081352e-21], sampled 0.9890032674957286
[2019-03-24 01:56:05,273] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.11765843]
[2019-03-24 01:56:05,274] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.26674660666667, 88.24064261000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7377466574802564, 6.9112, 6.9112, 121.9260426156618, 551039.3540706702, 551039.3540706702, 150189.0446889758]
[2019-03-24 01:56:05,274] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:56:05,278] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.4171629e-35 7.2876834e-25 7.7178897e-30 1.9529013e-21], sampled 0.4415937538981448
[2019-03-24 01:56:28,339] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 01:56:28,692] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 01:56:28,770] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 01:56:28,865] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 01:56:29,083] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 01:56:30,099] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 300000, evaluation results [300000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 01:56:31,639] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.1377096e-22 1.1036225e-16 1.4974750e-18 1.5434124e-12], sum to 1.0000
[2019-03-24 01:56:31,645] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8110
[2019-03-24 01:56:31,652] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 718942.6095334764 W.
[2019-03-24 01:56:31,658] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.65, 79.66666666666667, 1.0, 2.0, 0.2102801438328945, 1.0, 2.0, 0.2102801438328945, 1.0, 2.0, 0.3347728373281447, 6.9112, 6.9112, 121.94756008, 718942.6095334764, 718942.6095334764, 223982.0485677967], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3325800.0000, 
sim time next is 3326400.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.322028552205634, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5126799428491275, 6.911199999999999, 6.9112, 121.9260426156618, 734012.3743853564, 734012.3743853569, 201259.0392003492], 
processed observation next is [0.0, 0.5217391304347826, 0.5555555555555556, 0.79, 1.0, 1.0, 0.1928911335781357, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.3908499285614094, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26214727656619874, 0.2621472765661989, 0.38703661384682536], 
reward next is 0.6130, 
noisyNet noise sample is [array([0.08398544], dtype=float32), -0.15696803]. 
=============================================
[2019-03-24 01:56:32,811] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.4175252e-20 8.8979896e-15 1.9572533e-17 4.4555321e-11], sum to 1.0000
[2019-03-24 01:56:32,819] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3903
[2019-03-24 01:56:32,825] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 795472.3003719143 W.
[2019-03-24 01:56:32,828] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.3489784882248848, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5555851186899158, 6.9112, 6.9112, 121.9260426156618, 795472.3003719143, 795472.3003719143, 208879.8864608904], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3358800.0000, 
sim time next is 3359400.0000, 
raw observation next is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.2283460855392141, 1.0, 1.0, 0.2283460855392141, 1.0, 2.0, 0.3635344048912509, 6.9112, 6.9112, 121.94756008, 780741.067833817, 780741.067833817, 230078.1670453087], 
processed observation next is [0.0, 0.9130434782608695, 0.5493827160493825, 0.8483333333333333, 1.0, 1.0, 0.08136438754668344, 1.0, 0.5, 0.08136438754668344, 1.0, 1.0, 0.20441800611406358, 0.0, 0.0, 0.8096049824067558, 0.2788360956549346, 0.2788360956549346, 0.4424580135486706], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3253687], dtype=float32), -1.3912569]. 
=============================================
[2019-03-24 01:56:34,158] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.0318710e-12 3.1620424e-08 6.4383873e-11 4.6577743e-08], sum to 1.0000
[2019-03-24 01:56:34,166] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0511
[2019-03-24 01:56:34,173] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 729036.1236619884 W.
[2019-03-24 01:56:34,177] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.96666666666667, 98.0, 1.0, 2.0, 0.6261201755602137, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 729036.1236619884, 729036.1236619884, 163368.0193516133], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3390000.0000, 
sim time next is 3390600.0000, 
raw observation next is [22.98333333333333, 99.0, 1.0, 2.0, 0.2123027355899407, 1.0, 1.0, 0.2123027355899407, 1.0, 1.0, 0.3380591629291071, 6.9112, 6.9112, 121.94756008, 728441.9738106597, 728441.9738106597, 224664.5291404333], 
processed observation next is [1.0, 0.21739130434782608, 0.40679012345679005, 0.99, 1.0, 1.0, 0.06226516141659607, 1.0, 0.5, 0.06226516141659607, 1.0, 0.5, 0.17257395366138384, 0.0, 0.0, 0.8096049824067558, 0.26015784778952133, 0.26015784778952133, 0.4320471714239102], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9410663], dtype=float32), 0.8022672]. 
=============================================
[2019-03-24 01:56:40,497] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.7998960e-04 1.6191561e-10 5.2615488e-04 1.0092033e-06 9.9899286e-01], sum to 1.0000
[2019-03-24 01:56:40,503] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5619
[2019-03-24 01:56:40,510] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.08333333333333, 80.83333333333333, 1.0, 2.0, 0.5068993366581186, 1.0, 2.0, 0.5068993366581186, 1.0, 2.0, 0.8070002525185972, 6.9112, 6.9112, 121.94756008, 1734199.390207666, 1734199.390207666, 346988.2284155755], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3514200.0000, 
sim time next is 3514800.0000, 
raw observation next is [27.16666666666667, 77.66666666666667, 1.0, 2.0, 0.4511453555580756, 1.0, 2.0, 0.4511453555580756, 1.0, 2.0, 0.7182380988269307, 6.9112, 6.9112, 121.94756008, 1543284.08075367, 1543284.08075367, 320210.7721888776], 
processed observation next is [1.0, 0.6956521739130435, 0.5617283950617286, 0.7766666666666667, 1.0, 1.0, 0.34660161375961385, 1.0, 1.0, 0.34660161375961385, 1.0, 1.0, 0.6477976235336632, 0.0, 0.0, 0.8096049824067558, 0.5511728859834536, 0.5511728859834536, 0.6157899465170724], 
reward next is 0.3842, 
noisyNet noise sample is [array([-1.325597], dtype=float32), -1.259222]. 
=============================================
[2019-03-24 01:56:41,274] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.5081779e-05 1.2469767e-12 3.1453706e-05 6.2335758e-08 9.9993336e-01], sum to 1.0000
[2019-03-24 01:56:41,281] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2964
[2019-03-24 01:56:41,285] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.23333333333333, 77.33333333333333, 1.0, 2.0, 0.198813798578296, 1.0, 2.0, 0.198813798578296, 1.0, 2.0, 0.3165180422500296, 6.9112, 6.9112, 121.94756008, 679722.0812363338, 679722.0812363338, 220207.6207489689], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3530400.0000, 
sim time next is 3531000.0000, 
raw observation next is [26.61666666666667, 75.66666666666667, 1.0, 2.0, 0.2003651064852555, 1.0, 2.0, 0.2003651064852555, 1.0, 2.0, 0.3189877749604806, 6.911199999999999, 6.9112, 121.94756008, 685028.1982851764, 685028.1982851769, 220713.9663852486], 
processed observation next is [1.0, 0.8695652173913043, 0.5413580246913582, 0.7566666666666667, 1.0, 1.0, 0.048053698196732726, 1.0, 1.0, 0.048053698196732726, 1.0, 1.0, 0.1487347187006007, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.24465292795899157, 0.24465292795899174, 0.4244499353562473], 
reward next is 0.5756, 
noisyNet noise sample is [array([0.23868097], dtype=float32), -0.14419417]. 
=============================================
[2019-03-24 01:56:41,296] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[45.87717 ]
 [45.828884]
 [45.725063]
 [45.56911 ]
 [45.38872 ]], R is [[46.0213089 ]
 [46.13761902]
 [46.25385666]
 [46.36999512]
 [46.48591995]].
[2019-03-24 01:56:44,715] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.3927176e-07 6.8074988e-15 7.6671165e-07 3.5452027e-11 9.9999881e-01], sum to 1.0000
[2019-03-24 01:56:44,720] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4571
[2019-03-24 01:56:44,723] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 88.0, 1.0, 2.0, 0.3017364086632877, 1.0, 2.0, 0.3017364086632877, 1.0, 2.0, 0.4803921627315505, 6.911199999999997, 6.9112, 121.94756008, 1032696.636608906, 1032696.636608907, 256722.6724056933], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3588600.0000, 
sim time next is 3589200.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.3490877078903833, 1.0, 2.0, 0.3490877078903833, 1.0, 2.0, 0.5557589999544256, 6.911200000000001, 6.9112, 121.94756008, 1193891.857268984, 1193891.857268984, 275498.6489709343], 
processed observation next is [1.0, 0.5652173913043478, 0.4444444444444444, 0.89, 1.0, 1.0, 0.2251044141552182, 1.0, 1.0, 0.2251044141552182, 1.0, 1.0, 0.44469874994303193, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4263899490246371, 0.4263899490246371, 0.5298050941748736], 
reward next is 0.4702, 
noisyNet noise sample is [array([0.15907314], dtype=float32), 0.3529016]. 
=============================================
[2019-03-24 01:56:52,119] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.7259011e-03 1.7780420e-09 1.6798925e-02 4.9059972e-06 9.7747028e-01], sum to 1.0000
[2019-03-24 01:56:52,129] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7904
[2019-03-24 01:56:52,135] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.9, 94.66666666666667, 1.0, 2.0, 0.2425494983314653, 1.0, 2.0, 0.2425494983314653, 1.0, 2.0, 0.3861467006293756, 6.911199999999999, 6.9112, 121.94756008, 829330.409209257, 829330.4092092575, 234999.0716071688], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3730200.0000, 
sim time next is 3730800.0000, 
raw observation next is [24.8, 95.33333333333334, 1.0, 2.0, 0.2181756047190835, 1.0, 2.0, 0.2181756047190835, 1.0, 2.0, 0.3473426681961669, 6.911199999999999, 6.9112, 121.94756008, 745950.1271897913, 745950.1271897918, 226623.8097918682], 
processed observation next is [1.0, 0.17391304347826086, 0.4740740740740741, 0.9533333333333335, 1.0, 1.0, 0.06925667228462322, 1.0, 1.0, 0.06925667228462322, 1.0, 1.0, 0.18417833524520857, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.26641075971063977, 0.26641075971063993, 0.43581501883051577], 
reward next is 0.5642, 
noisyNet noise sample is [array([-0.45269078], dtype=float32), 0.63286895]. 
=============================================
[2019-03-24 01:56:59,187] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6372722e-06 2.4258268e-14 5.7422176e-07 4.6464946e-10 9.9999678e-01], sum to 1.0000
[2019-03-24 01:56:59,193] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1902
[2019-03-24 01:56:59,199] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.03333333333333, 52.33333333333333, 1.0, 2.0, 0.2310433678221845, 1.0, 2.0, 0.2310433678221845, 1.0, 2.0, 0.367828566130091, 6.9112, 6.9112, 121.94756008, 789968.1322695431, 789968.1322695431, 231003.9912432834], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3854400.0000, 
sim time next is 3855000.0000, 
raw observation next is [33.01666666666667, 52.66666666666667, 1.0, 2.0, 0.233207749694071, 1.0, 2.0, 0.233207749694071, 1.0, 2.0, 0.3712743325591308, 6.9112, 6.9112, 121.94756008, 797372.2915404413, 797372.2915404413, 231749.8423929991], 
processed observation next is [0.0, 0.6086956521739131, 0.7783950617283953, 0.5266666666666667, 1.0, 1.0, 0.08715208296913213, 1.0, 1.0, 0.08715208296913213, 1.0, 1.0, 0.21409291569891345, 0.0, 0.0, 0.8096049824067558, 0.2847758184073005, 0.2847758184073005, 0.44567277383269055], 
reward next is 0.5543, 
noisyNet noise sample is [array([-0.45022514], dtype=float32), -0.4141792]. 
=============================================
[2019-03-24 01:56:59,213] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[53.67351 ]
 [53.662563]
 [53.62438 ]
 [53.555225]
 [53.50941 ]], R is [[53.69679642]
 [53.71559143]
 [53.73749161]
 [53.75907135]
 [53.77677155]].
[2019-03-24 01:57:05,777] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.3044251e-07 1.7488139e-12 2.4076658e-07 1.2187844e-08 9.9999917e-01], sum to 1.0000
[2019-03-24 01:57:05,786] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3353
[2019-03-24 01:57:05,791] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.253445445734714, 1.0, 2.0, 0.253445445734714, 1.0, 2.0, 0.4034934037515806, 6.9112, 6.9112, 121.94756008, 866607.1234260512, 866607.1234260512, 238850.4846078328], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3967200.0000, 
sim time next is 3967800.0000, 
raw observation next is [26.88333333333333, 88.0, 1.0, 2.0, 0.2495855856024254, 1.0, 2.0, 0.2495855856024254, 1.0, 2.0, 0.3973483807141087, 6.9112, 6.9112, 121.94756008, 853401.7400988635, 853401.7400988635, 237478.5464486676], 
processed observation next is [0.0, 0.9565217391304348, 0.5512345679012344, 0.88, 1.0, 1.0, 0.10664950666955407, 1.0, 1.0, 0.10664950666955407, 1.0, 1.0, 0.24668547589263587, 0.0, 0.0, 0.8096049824067558, 0.30478633574959413, 0.30478633574959413, 0.4566895124012838], 
reward next is 0.5433, 
noisyNet noise sample is [array([0.40558407], dtype=float32), 0.8220996]. 
=============================================
[2019-03-24 01:57:05,803] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.26433064e-07 1.72674592e-12 2.39008216e-07 1.20815615e-08
 9.99999166e-01], sum to 1.0000
[2019-03-24 01:57:05,811] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0561
[2019-03-24 01:57:05,820] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.88333333333333, 88.0, 1.0, 2.0, 0.2495855856024254, 1.0, 2.0, 0.2495855856024254, 1.0, 2.0, 0.3973483807141087, 6.9112, 6.9112, 121.94756008, 853401.7400988635, 853401.7400988635, 237478.5464486676], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3967800.0000, 
sim time next is 3968400.0000, 
raw observation next is [26.76666666666667, 87.0, 1.0, 2.0, 0.2448082351082577, 1.0, 2.0, 0.2448082351082577, 1.0, 2.0, 0.3897426831399503, 6.9112, 6.9112, 121.94756008, 837057.7466687036, 837057.7466687036, 235792.0225319469], 
processed observation next is [0.0, 0.9565217391304348, 0.5469135802469137, 0.87, 1.0, 1.0, 0.10096218465268773, 1.0, 1.0, 0.10096218465268773, 1.0, 1.0, 0.23717835392493786, 0.0, 0.0, 0.8096049824067558, 0.29894919523882274, 0.29894919523882274, 0.45344619717682094], 
reward next is 0.5466, 
noisyNet noise sample is [array([0.40558407], dtype=float32), 0.8220996]. 
=============================================
[2019-03-24 01:57:05,853] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5693926e-06 6.5809093e-13 8.1153195e-07 1.9201394e-09 9.9999762e-01], sum to 1.0000
[2019-03-24 01:57:05,866] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1250
[2019-03-24 01:57:05,870] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.23333333333333, 68.66666666666666, 1.0, 2.0, 0.2482381623394417, 1.0, 2.0, 0.2482381623394417, 1.0, 2.0, 0.3952032389969265, 6.9112, 6.9112, 121.94756008, 848791.9787806025, 848791.9787806025, 237001.5815344923], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3951600.0000, 
sim time next is 3952200.0000, 
raw observation next is [30.06666666666667, 69.83333333333334, 1.0, 2.0, 0.2503981702600999, 1.0, 2.0, 0.2503981702600999, 1.0, 2.0, 0.3986420419531612, 6.911200000000001, 6.9112, 121.94756008, 856181.7421077644, 856181.7421077639, 237766.6778059827], 
processed observation next is [0.0, 0.7391304347826086, 0.669135802469136, 0.6983333333333335, 1.0, 1.0, 0.10761686935726181, 1.0, 1.0, 0.10761686935726181, 1.0, 1.0, 0.2483025524414515, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.30577919360991584, 0.3057791936099157, 0.45724361116535134], 
reward next is 0.5428, 
noisyNet noise sample is [array([1.3680745], dtype=float32), -0.8582485]. 
=============================================
[2019-03-24 01:57:06,238] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0885841e-07 4.7054274e-16 1.1064578e-07 5.2812730e-11 9.9999964e-01], sum to 1.0000
[2019-03-24 01:57:06,246] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5340
[2019-03-24 01:57:06,251] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.2, 89.0, 1.0, 2.0, 0.3671690509775564, 1.0, 2.0, 0.3671690509775564, 1.0, 2.0, 0.5845450870174383, 6.9112, 6.9112, 121.94756008, 1255781.343579615, 1255781.343579615, 282999.2102487204], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3985200.0000, 
sim time next is 3985800.0000, 
raw observation next is [25.16666666666666, 89.33333333333334, 1.0, 2.0, 0.3542644407381036, 1.0, 2.0, 0.3542644407381036, 1.0, 2.0, 0.564000527242415, 6.911199999999999, 6.9112, 121.94756008, 1211610.458166853, 1211610.458166854, 277627.5228560329], 
processed observation next is [1.0, 0.13043478260869565, 0.4876543209876541, 0.8933333333333334, 1.0, 1.0, 0.23126719135488524, 1.0, 1.0, 0.23126719135488524, 1.0, 1.0, 0.45500065905301873, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4327180207738761, 0.43271802077387644, 0.5338990824154478], 
reward next is 0.4661, 
noisyNet noise sample is [array([-0.44916984], dtype=float32), 0.48375615]. 
=============================================
[2019-03-24 01:57:10,455] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9256642e-05 1.7253539e-13 1.5540161e-06 2.1982378e-09 9.9997914e-01], sum to 1.0000
[2019-03-24 01:57:10,469] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6893
[2019-03-24 01:57:10,476] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.33333333333334, 98.0, 1.0, 2.0, 0.2219006036222334, 1.0, 2.0, 0.2219006036222334, 1.0, 2.0, 0.3532729877647265, 6.9112, 6.9112, 121.94756008, 758692.3322512965, 758692.3322512965, 227882.2744371076], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4052400.0000, 
sim time next is 4053000.0000, 
raw observation next is [24.16666666666666, 99.0, 1.0, 2.0, 0.2219960222312749, 1.0, 2.0, 0.2219960222312749, 1.0, 2.0, 0.3534248972978877, 6.9112, 6.9112, 121.94756008, 759018.7360644236, 759018.7360644236, 227914.6128948467], 
processed observation next is [1.0, 0.9130434782608695, 0.45061728395061706, 0.99, 1.0, 1.0, 0.07380478837056537, 1.0, 1.0, 0.07380478837056537, 1.0, 1.0, 0.19178112162235958, 0.0, 0.0, 0.8096049824067558, 0.2710781200230084, 0.2710781200230084, 0.43829733249008984], 
reward next is 0.5617, 
noisyNet noise sample is [array([-0.38261324], dtype=float32), 1.7411662]. 
=============================================
[2019-03-24 01:57:10,491] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[48.61945 ]
 [48.584297]
 [48.543774]
 [48.44698 ]
 [48.39394 ]], R is [[48.72883987]
 [48.80331421]
 [48.8768158 ]
 [48.94945526]
 [49.02143478]].
[2019-03-24 01:57:20,326] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 01:57:20,328] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:57:20,328] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:57:20,330] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:57:20,333] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:57:20,333] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:57:20,334] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:57:20,335] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:57:20,336] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:57:20,336] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:57:20,338] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:57:20,355] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run14
[2019-03-24 01:57:20,378] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run14
[2019-03-24 01:57:20,379] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run14
[2019-03-24 01:57:20,426] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run14
[2019-03-24 01:57:20,426] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run14
[2019-03-24 01:57:40,686] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.12796289]
[2019-03-24 01:57:40,688] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.20426424, 54.70966376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5497255851063578, 6.911199999999999, 6.9112, 121.9260426156618, 401518.5397680831, 401518.5397680836, 122298.8901528477]
[2019-03-24 01:57:40,692] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:57:40,695] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 7.9109772e-25 1.0333623e-15 3.0711746e-20 8.9950584e-13], sampled 0.8129536197541772
[2019-03-24 01:57:42,113] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.12796289]
[2019-03-24 01:57:42,114] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.82971238, 68.728193665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6809297575106223, 6.911199999999999, 6.9112, 121.9260426156618, 508766.5619047121, 508766.5619047125, 142095.410822537]
[2019-03-24 01:57:42,115] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:57:42,118] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.0311864e-25 5.6996762e-16 1.4129256e-20 5.5945943e-13], sampled 0.8823522402830534
[2019-03-24 01:58:23,956] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.12796289]
[2019-03-24 01:58:23,958] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.86666666666667, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9484529519561558, 6.9112, 6.9112, 121.9260426156618, 684577.5412989556, 684577.5412989556, 184001.5236033431]
[2019-03-24 01:58:23,960] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:58:23,962] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.1261366e-23 8.1944297e-15 4.4846729e-19 4.7542352e-12], sampled 0.594509658938154
[2019-03-24 01:58:38,840] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.12796289]
[2019-03-24 01:58:38,840] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.45324400666667, 80.13945023333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6656347397590217, 6.911199999999999, 6.9112, 121.9260426156618, 496786.6077030989, 496786.6077030993, 139301.1979267801]
[2019-03-24 01:58:38,841] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:58:38,844] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 5.6430332e-25 8.4301971e-16 2.3438895e-20 7.6553683e-13], sampled 0.5382149061149862
[2019-03-24 01:58:51,325] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.12796289]
[2019-03-24 01:58:51,325] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.97977425333334, 59.00590971333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6404612385314062, 6.911200000000001, 6.9112, 121.9260426156618, 477283.3051036214, 477283.305103621, 135851.2402461141]
[2019-03-24 01:58:51,326] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:58:51,328] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 7.2729361e-25 9.8307787e-16 2.8717278e-20 8.6499021e-13], sampled 0.8657666476434382
[2019-03-24 01:58:53,172] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.12796289]
[2019-03-24 01:58:53,173] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.58333333333334, 81.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.783072933244133, 6.9112, 6.9112, 121.9260426156618, 582516.091046717, 582516.091046717, 157763.6871321563]
[2019-03-24 01:58:53,174] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:58:53,176] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.000000e+00 8.969853e-25 1.121302e-15 3.405659e-20 9.607038e-13], sampled 0.3054056647747725
[2019-03-24 01:58:57,013] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([1.3815873e-06], dtype=float32), 0.12796289]
[2019-03-24 01:58:57,014] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.0, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5854180450054802, 6.911199999999999, 6.9112, 121.9260426156618, 433374.9056975752, 433374.9056975757, 128260.2529624052]
[2019-03-24 01:58:57,015] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:58:57,017] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.9891228e-24 1.8417459e-15 6.5001391e-20 1.4303693e-12], sampled 0.8091086341955467
[2019-03-24 01:59:00,909] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.2958 2292950550.9323 697.0000
[2019-03-24 01:59:01,779] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 01:59:01,979] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 01:59:02,275] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5295 2529767993.6091 831.0000
[2019-03-24 01:59:02,295] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.7982 2219159744.7191 543.0000
[2019-03-24 01:59:03,310] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 325000, evaluation results [325000.0, 7841.529523729852, 2529767993.609111, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.798202931406, 2219159744.719052, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.29581531956, 2292950550.9323354, 697.0]
[2019-03-24 01:59:06,112] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9994802e-01 1.4108344e-10 7.1458686e-07 1.3662966e-09 5.1308871e-05], sum to 1.0000
[2019-03-24 01:59:06,122] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8113
[2019-03-24 01:59:06,131] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1816177.521953531 W.
[2019-03-24 01:59:06,135] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.8, 34.0, 1.0, 2.0, 0.9422438106855144, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9768560022021638, 6.911199999999999, 6.9112, 121.9260426156618, 1816177.521953531, 1816177.521953532, 362786.9063737127], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4285800.0000, 
sim time next is 4286400.0000, 
raw observation next is [33.86666666666667, 34.0, 1.0, 2.0, 0.7864681648134503, 1.0, 1.0, 0.7864681648134503, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1824725.050394643, 1824725.050394643, 339784.0946865383], 
processed observation next is [1.0, 0.6086956521739131, 0.8098765432098766, 0.34, 1.0, 1.0, 0.7457954343017265, 1.0, 0.5, 0.7457954343017265, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6516875179980868, 0.6516875179980868, 0.653430951320266], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2640276], dtype=float32), -1.2140433]. 
=============================================
[2019-03-24 01:59:15,145] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.999995e-01 9.752760e-13 3.216178e-07 7.496240e-12 7.966765e-08], sum to 1.0000
[2019-03-24 01:59:15,148] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5376
[2019-03-24 01:59:15,152] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 839591.7662301066 W.
[2019-03-24 01:59:15,156] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.7366467365047404, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 839591.7662301066, 839591.7662301066, 183200.9397564787], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4464000.0000, 
sim time next is 4464600.0000, 
raw observation next is [29.91666666666666, 69.33333333333334, 1.0, 2.0, 0.3618151789856413, 1.0, 1.0, 0.3618151789856413, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 824748.3907390658, 824748.3907390663, 195957.3786472135], 
processed observation next is [0.0, 0.6956521739130435, 0.66358024691358, 0.6933333333333335, 1.0, 1.0, 0.2402561654590968, 1.0, 0.5, 0.2402561654590968, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2945529966925235, 0.29455299669252366, 0.3768411127831029], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9674079], dtype=float32), -0.28039107]. 
=============================================
[2019-03-24 01:59:16,901] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9998116e-01 5.4381985e-14 1.8387231e-05 4.4606280e-14 4.6461011e-07], sum to 1.0000
[2019-03-24 01:59:16,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4301
[2019-03-24 01:59:16,920] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 805280.4751057366 W.
[2019-03-24 01:59:16,922] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.13333333333334, 82.66666666666667, 1.0, 2.0, 0.3532791343617677, 1.0, 1.0, 0.3532791343617677, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 805280.4751057366, 805280.4751057371, 193738.3211796792], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4479600.0000, 
sim time next is 4480200.0000, 
raw observation next is [27.1, 83.0, 1.0, 2.0, 0.3531879223829636, 1.0, 2.0, 0.3531879223829636, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 805072.4531945934, 805072.4531945939, 193714.7597467853], 
processed observation next is [0.0, 0.8695652173913043, 0.5592592592592593, 0.83, 1.0, 1.0, 0.22998562188448046, 1.0, 1.0, 0.22998562188448046, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28752587614092623, 0.2875258761409264, 0.37252838412843325], 
reward next is 0.6275, 
noisyNet noise sample is [array([0.31453946], dtype=float32), -0.061724998]. 
=============================================
[2019-03-24 01:59:31,850] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5242841e-03 7.7345377e-14 1.8072264e-05 1.5164441e-10 9.9645764e-01], sum to 1.0000
[2019-03-24 01:59:31,856] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1757
[2019-03-24 01:59:31,862] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.3, 89.0, 1.0, 2.0, 0.2148636952271175, 1.0, 2.0, 0.2148636952271175, 1.0, 2.0, 0.3420700004235952, 6.9112, 6.9112, 121.94756008, 734621.1661621903, 734621.1661621903, 225511.4232332299], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4748400.0000, 
sim time next is 4749000.0000, 
raw observation next is [25.25, 89.83333333333334, 1.0, 2.0, 0.2147875424914677, 1.0, 2.0, 0.2147875424914677, 1.0, 2.0, 0.3419487627883193, 6.911200000000001, 6.9112, 121.94756008, 734360.6744864029, 734360.6744864024, 225485.917632351], 
processed observation next is [1.0, 1.0, 0.49074074074074076, 0.8983333333333334, 1.0, 1.0, 0.06522326487079488, 1.0, 1.0, 0.06522326487079488, 1.0, 1.0, 0.17743595348539912, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2622716694594296, 0.2622716694594294, 0.43362676467759803], 
reward next is 0.5664, 
noisyNet noise sample is [array([-1.5230446], dtype=float32), -0.711559]. 
=============================================
[2019-03-24 01:59:31,882] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[51.94657 ]
 [51.936474]
 [51.93679 ]
 [51.932934]
 [51.922264]], R is [[52.00444412]
 [52.05072403]
 [52.09540176]
 [52.13826752]
 [52.17920685]].
[2019-03-24 01:59:32,495] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7014288e-03 1.8250382e-11 6.5018452e-05 1.9311519e-09 9.9823356e-01], sum to 1.0000
[2019-03-24 01:59:32,507] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5194
[2019-03-24 01:59:32,513] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.25, 88.33333333333334, 1.0, 2.0, 0.4156378887726386, 1.0, 2.0, 0.4156378887726386, 1.0, 2.0, 0.661709055307054, 6.911199999999999, 6.9112, 121.94756008, 1421706.93245269, 1421706.93245269, 304000.1395751612], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4799400.0000, 
sim time next is 4800000.0000, 
raw observation next is [26.5, 87.66666666666667, 1.0, 2.0, 0.5120622837701333, 1.0, 2.0, 0.5120622837701333, 1.0, 2.0, 0.8152198324663732, 6.911199999999999, 6.9112, 121.94756008, 1751880.135222731, 1751880.135222732, 349548.8104126156], 
processed observation next is [1.0, 0.5652173913043478, 0.5370370370370371, 0.8766666666666667, 1.0, 1.0, 0.4191217663930158, 1.0, 1.0, 0.4191217663930158, 1.0, 1.0, 0.7690247905829664, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.625671476865261, 0.6256714768652615, 0.6722092507934915], 
reward next is 0.3278, 
noisyNet noise sample is [array([1.6294825], dtype=float32), 2.0213947]. 
=============================================
[2019-03-24 01:59:32,527] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[39.128883]
 [39.158386]
 [39.246834]
 [39.146122]
 [39.04893 ]], R is [[38.64250565]
 [38.67146683]
 [38.71215057]
 [38.77201843]
 [38.83016205]].
[2019-03-24 01:59:33,650] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.8655886e-05 5.8811406e-12 1.8357016e-05 9.1468699e-10 9.9993300e-01], sum to 1.0000
[2019-03-24 01:59:33,664] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3164
[2019-03-24 01:59:33,673] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 86.33333333333334, 1.0, 2.0, 0.5629833309710398, 1.0, 2.0, 0.5629833309710398, 1.0, 2.0, 0.896287797992946, 6.9112, 6.9112, 121.94756008, 1926280.302873106, 1926280.302873106, 375576.199348394], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4801200.0000, 
sim time next is 4801800.0000, 
raw observation next is [27.25, 85.66666666666667, 1.0, 2.0, 0.5757876770114407, 1.0, 2.0, 0.5757876770114407, 1.0, 2.0, 0.916672733897702, 6.911199999999999, 6.9112, 121.94756008, 1970139.434638216, 1970139.434638217, 382341.3759568021], 
processed observation next is [1.0, 0.5652173913043478, 0.5648148148148148, 0.8566666666666667, 1.0, 1.0, 0.4949853297755247, 1.0, 1.0, 0.4949853297755247, 1.0, 1.0, 0.8958409173721273, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7036212266565057, 0.7036212266565061, 0.7352718768400041], 
reward next is 0.2647, 
noisyNet noise sample is [array([-1.1058341], dtype=float32), -0.7123067]. 
=============================================
[2019-03-24 01:59:39,824] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1439937e-05 2.3620723e-17 9.7299484e-08 2.8155113e-12 9.9997842e-01], sum to 1.0000
[2019-03-24 01:59:39,836] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8943
[2019-03-24 01:59:39,842] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.93333333333333, 76.33333333333334, 1.0, 2.0, 0.2108379952534101, 1.0, 2.0, 0.2108379952534101, 1.0, 2.0, 0.335660954957558, 6.9112, 6.9112, 121.94756008, 720850.7863574657, 720850.7863574657, 224167.5562124696], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4930800.0000, 
sim time next is 4931400.0000, 
raw observation next is [26.91666666666667, 75.66666666666666, 1.0, 2.0, 0.2083232418151849, 1.0, 2.0, 0.2083232418151849, 1.0, 2.0, 0.3316573855841017, 6.9112, 6.9112, 121.94756008, 712248.9022263711, 712248.9022263711, 223332.6783252563], 
processed observation next is [1.0, 0.043478260869565216, 0.5524691358024693, 0.7566666666666666, 1.0, 1.0, 0.05752766882760108, 1.0, 1.0, 0.05752766882760108, 1.0, 1.0, 0.1645717319801271, 0.0, 0.0, 0.8096049824067558, 0.25437460793798966, 0.25437460793798966, 0.4294859198562621], 
reward next is 0.5705, 
noisyNet noise sample is [array([-0.3001397], dtype=float32), -0.00048121862]. 
=============================================
[2019-03-24 01:59:46,964] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.5687928e-05 7.4398014e-17 2.4181634e-08 5.8039870e-14 9.9994433e-01], sum to 1.0000
[2019-03-24 01:59:46,972] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7459
[2019-03-24 01:59:46,978] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.75, 67.5, 1.0, 2.0, 0.2553015177466057, 1.0, 2.0, 0.2553015177466057, 1.0, 2.0, 0.4064483308425575, 6.911199999999999, 6.9112, 121.94756008, 872957.2123415641, 872957.2123415646, 239513.1643624183], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5061000.0000, 
sim time next is 5061600.0000, 
raw observation next is [30.9, 66.0, 1.0, 2.0, 0.2518016326733848, 1.0, 2.0, 0.2518016326733848, 1.0, 2.0, 0.4008763998226906, 6.911200000000002, 6.9112, 121.94756008, 860983.2696603687, 860983.2696603679, 238265.1948872474], 
processed observation next is [0.0, 0.6086956521739131, 0.7, 0.66, 1.0, 1.0, 0.1092876579445057, 1.0, 1.0, 0.1092876579445057, 1.0, 1.0, 0.2510954997783632, 1.7763568394002506e-16, 0.0, 0.8096049824067558, 0.3074940248787031, 0.3074940248787028, 0.45820229786009115], 
reward next is 0.5418, 
noisyNet noise sample is [array([-0.51274234], dtype=float32), 0.3203189]. 
=============================================
[2019-03-24 01:59:47,372] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6447450e-05 2.1211725e-19 6.3104855e-09 1.2404627e-13 9.9998355e-01], sum to 1.0000
[2019-03-24 01:59:47,381] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2448
[2019-03-24 01:59:47,387] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.75, 89.5, 1.0, 2.0, 0.2018194033693493, 1.0, 2.0, 0.2018194033693493, 1.0, 2.0, 0.3213030629631008, 6.9112, 6.9112, 121.94756008, 690002.530711117, 690002.530711117, 221189.8713337743], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5038200.0000, 
sim time next is 5038800.0000, 
raw observation next is [25.0, 88.0, 1.0, 2.0, 0.2026526813940337, 1.0, 2.0, 0.2026526813940337, 1.0, 2.0, 0.3226296687163691, 6.911199999999999, 6.9112, 121.94756008, 692852.7211320217, 692852.7211320222, 221463.0873006854], 
processed observation next is [0.0, 0.30434782608695654, 0.48148148148148145, 0.88, 1.0, 1.0, 0.05077700165956392, 1.0, 1.0, 0.05077700165956392, 1.0, 1.0, 0.15328708589546136, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.24744740040429347, 0.24744740040429364, 0.4258905525013181], 
reward next is 0.5741, 
noisyNet noise sample is [array([0.06762534], dtype=float32), -1.9289099]. 
=============================================
[2019-03-24 01:59:50,059] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.9425190e-06 1.6981953e-17 2.6037551e-07 4.7469698e-14 9.9999177e-01], sum to 1.0000
[2019-03-24 01:59:50,069] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2975
[2019-03-24 01:59:50,073] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 95.0, 1.0, 2.0, 0.2450939011065934, 1.0, 2.0, 0.2450939011065934, 1.0, 2.0, 0.3901974727127928, 6.9112, 6.9112, 121.94756008, 838035.0407586817, 838035.0407586817, 235892.5113397599], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5100600.0000, 
sim time next is 5101200.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.2456318651697407, 1.0, 2.0, 0.2456318651697407, 1.0, 2.0, 0.3910539290215897, 6.911200000000001, 6.9112, 121.94756008, 839875.477033406, 839875.4770334056, 236081.8748833299], 
processed observation next is [0.0, 0.043478260869565216, 0.5185185185185185, 0.94, 1.0, 1.0, 0.10194269663064369, 1.0, 1.0, 0.10194269663064369, 1.0, 1.0, 0.2388174112769871, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2999555275119307, 0.29995552751193055, 0.4540036055448652], 
reward next is 0.5460, 
noisyNet noise sample is [array([0.8322079], dtype=float32), 1.4743814]. 
=============================================
[2019-03-24 01:59:53,411] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.0016995e-03 2.0270664e-12 2.2096171e-04 2.6124664e-10 9.9677736e-01], sum to 1.0000
[2019-03-24 01:59:53,419] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5271
[2019-03-24 01:59:53,428] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.3, 71.5, 1.0, 2.0, 0.2581286279413199, 1.0, 2.0, 0.2581286279413199, 1.0, 2.0, 0.4109491823450935, 6.9112, 6.9112, 121.94756008, 882629.5680580424, 882629.5680580424, 240526.2338882475], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5160600.0000, 
sim time next is 5161200.0000, 
raw observation next is [30.1, 72.33333333333333, 1.0, 2.0, 0.2590068962555824, 1.0, 2.0, 0.2590068962555824, 1.0, 2.0, 0.4123474141046017, 6.911200000000001, 6.9112, 121.94756008, 885634.4009832657, 885634.4009832653, 240841.8619932248], 
processed observation next is [0.0, 0.7391304347826086, 0.6703703703703704, 0.7233333333333333, 1.0, 1.0, 0.11786535268521711, 1.0, 1.0, 0.11786535268521711, 1.0, 1.0, 0.26543426763075206, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.31629800035116634, 0.3162980003511662, 0.4631574269100477], 
reward next is 0.5368, 
noisyNet noise sample is [array([-2.430778], dtype=float32), 0.7969974]. 
=============================================
[2019-03-24 01:59:53,746] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 01:59:53,747] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:59:53,748] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:59:53,750] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:59:53,751] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:59:53,751] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:59:53,752] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:59:53,753] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:59:53,753] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:59:53,757] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:59:53,757] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:59:53,771] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run15
[2019-03-24 01:59:53,772] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run15
[2019-03-24 01:59:53,824] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run15
[2019-03-24 01:59:53,825] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run15
[2019-03-24 01:59:53,881] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run15
[2019-03-24 01:59:55,857] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00074292], dtype=float32), 0.1344746]
[2019-03-24 01:59:55,858] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.2, 43.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 324409.2134314035, 324409.2134314035, 144879.6873805051]
[2019-03-24 01:59:55,859] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:59:55,863] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.6642820e-06 7.9691689e-18 2.7619492e-08 7.9672656e-15 9.9999726e-01], sampled 0.2101887246524624
[2019-03-24 02:00:00,504] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00074292], dtype=float32), 0.1344746]
[2019-03-24 02:00:00,505] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.69351740666667, 24.51231975333333, 1.0, 2.0, 0.3009433443976038, 1.0, 2.0, 0.3009433443976038, 1.0, 2.0, 0.496520590827753, 6.911199999999999, 6.9112, 121.94756008, 1113457.139123719, 1113457.13912372, 254601.2831316717]
[2019-03-24 02:00:00,506] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:00:00,510] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.6472849e-06 4.1612982e-17 5.5627890e-08 3.4451937e-14 9.9999726e-01], sampled 0.05554948448702279
[2019-03-24 02:00:02,496] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00074292], dtype=float32), 0.1344746]
[2019-03-24 02:00:02,497] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.66666666666667, 45.83333333333333, 1.0, 2.0, 0.4061534262284079, 1.0, 2.0, 0.4061534262284079, 1.0, 2.0, 0.6509900196489732, 6.911200000000001, 6.9112, 121.94756008, 1439356.444921043, 1439356.444921043, 299715.784913847]
[2019-03-24 02:00:02,500] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:00:02,502] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.3563844e-06 6.2939240e-17 6.5908374e-08 5.0764436e-14 9.9999762e-01], sampled 0.7537171158772131
[2019-03-24 02:00:12,928] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00074292], dtype=float32), 0.1344746]
[2019-03-24 02:00:12,929] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.85568854333333, 82.45861065666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 409043.7931239739, 409043.7931239739, 179395.3216868572]
[2019-03-24 02:00:12,929] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:00:12,931] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.7064318e-06 9.7343318e-18 3.1476038e-08 8.6010571e-15 9.9999523e-01], sampled 0.16749145796743892
[2019-03-24 02:00:32,221] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00074292], dtype=float32), 0.1344746]
[2019-03-24 02:00:32,222] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.840594025, 50.31138751166667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2307905804293827, 6.9112, 6.9112, 121.94756008, 516705.637052397, 516705.637052397, 198161.0978954613]
[2019-03-24 02:00:32,223] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:00:32,227] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.0601653e-06 1.1426271e-17 3.3371581e-08 1.0191674e-14 9.9999595e-01], sampled 0.6916013595207752
[2019-03-24 02:00:54,860] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00074292], dtype=float32), 0.1344746]
[2019-03-24 02:00:54,861] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.90298914333334, 83.21602870999999, 1.0, 2.0, 0.2483106800463343, 1.0, 2.0, 0.2483106800463343, 1.0, 2.0, 0.3953186895480365, 6.911199999999998, 6.9112, 121.94756008, 849040.0733313437, 849040.0733313445, 237027.2257467689]
[2019-03-24 02:00:54,862] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:00:54,863] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.8109498e-06 1.3783465e-17 3.5137106e-08 1.2817859e-14 9.9999714e-01], sampled 0.5109644459950703
[2019-03-24 02:01:01,663] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00074292], dtype=float32), 0.1344746]
[2019-03-24 02:01:01,665] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.95, 77.0, 1.0, 2.0, 0.2134825290193069, 1.0, 2.0, 0.2134825290193069, 1.0, 2.0, 0.3398711388393176, 6.9112, 6.9112, 121.94756008, 729896.6969814841, 729896.6969814841, 225049.3377429527]
[2019-03-24 02:01:01,667] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:01:01,671] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3225850e-06 1.5065777e-18 1.3041742e-08 2.0608223e-15 9.9999869e-01], sampled 0.7782400212863777
[2019-03-24 02:01:29,818] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00074292], dtype=float32), 0.1344746]
[2019-03-24 02:01:29,820] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.08333333333333, 53.83333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 376017.7522077535, 376017.7522077535, 173368.1299188895]
[2019-03-24 02:01:29,820] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:01:29,823] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.6964111e-06 2.2182176e-18 1.5601772e-08 2.7807126e-15 9.9999833e-01], sampled 0.009061370871204844
[2019-03-24 02:01:35,322] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4489.4114 2940741243.8540 28.0000
[2019-03-24 02:01:35,465] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4392.9187 2875863645.9409 8.0000
[2019-03-24 02:01:35,589] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4276.0130 2920123490.3933 33.0000
[2019-03-24 02:01:35,663] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4512.3260 3107461961.2423 0.0000
[2019-03-24 02:01:35,674] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4609.9101 2894648459.8238 12.0000
[2019-03-24 02:01:36,688] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 350000, evaluation results [350000.0, 4512.32602290767, 3107461961.242318, 0.0, 4609.910050545777, 2894648459.823759, 12.0, 4392.918701142564, 2875863645.9409337, 8.0, 4489.411365254514, 2940741243.8539834, 28.0, 4276.012977927667, 2920123490.3932676, 33.0]
[2019-03-24 02:01:39,506] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2030843e-04 6.4847482e-11 1.6272182e-04 5.8238387e-09 9.9951696e-01], sum to 1.0000
[2019-03-24 02:01:39,514] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2618
[2019-03-24 02:01:39,518] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.53333333333334, 70.0, 1.0, 2.0, 0.2187771306107689, 1.0, 2.0, 0.2187771306107689, 1.0, 2.0, 0.3483003170060607, 6.9112, 6.9112, 121.94756008, 748007.7688298072, 748007.7688298072, 226826.5055828285], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5246400.0000, 
sim time next is 5247000.0000, 
raw observation next is [29.4, 71.0, 1.0, 2.0, 0.2161048265359718, 1.0, 2.0, 0.2161048265359718, 1.0, 2.0, 0.3440459218881161, 6.9112, 6.9112, 121.94756008, 738866.6515256716, 738866.6515256716, 225927.5688792056], 
processed observation next is [1.0, 0.7391304347826086, 0.6444444444444444, 0.71, 1.0, 1.0, 0.06679146016187118, 1.0, 1.0, 0.06679146016187118, 1.0, 1.0, 0.1800574023601451, 0.0, 0.0, 0.8096049824067558, 0.26388094697345416, 0.26388094697345416, 0.43447609399847226], 
reward next is 0.5655, 
noisyNet noise sample is [array([-0.03521481], dtype=float32), -1.3575017]. 
=============================================
[2019-03-24 02:01:39,536] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[31.650467]
 [30.288736]
 [28.417479]
 [28.491552]
 [28.62599 ]], R is [[32.67781067]
 [32.91482925]
 [33.08816147]
 [32.95281219]
 [32.82036972]].
[2019-03-24 02:01:41,503] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3747740e-04 8.1451648e-13 1.0375816e-06 1.3100700e-11 9.9976152e-01], sum to 1.0000
[2019-03-24 02:01:41,512] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8029
[2019-03-24 02:01:41,516] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.68333333333333, 88.66666666666667, 1.0, 2.0, 0.2219950188488223, 1.0, 2.0, 0.2219950188488223, 1.0, 2.0, 0.3534232998803453, 6.911199999999999, 6.9112, 121.94756008, 759015.3037368007, 759015.3037368011, 227914.2728105662], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5271000.0000, 
sim time next is 5271600.0000, 
raw observation next is [25.66666666666667, 88.33333333333334, 1.0, 2.0, 0.2207589886934141, 1.0, 2.0, 0.2207589886934141, 1.0, 2.0, 0.3514554996182436, 6.9112, 6.9112, 121.94756008, 754787.1565075837, 754787.1565075837, 227495.7630296047], 
processed observation next is [1.0, 0.0, 0.506172839506173, 0.8833333333333334, 1.0, 1.0, 0.07233212939692153, 1.0, 1.0, 0.07233212939692153, 1.0, 1.0, 0.1893193745228045, 0.0, 0.0, 0.8096049824067558, 0.26956684160985134, 0.26956684160985134, 0.43749185198000906], 
reward next is 0.5625, 
noisyNet noise sample is [array([-0.09955825], dtype=float32), -0.7846873]. 
=============================================
[2019-03-24 02:01:42,116] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.6268053e-09 1.0680013e-21 7.8713730e-11 8.8625372e-19 1.0000000e+00], sum to 1.0000
[2019-03-24 02:01:42,121] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8630
[2019-03-24 02:01:42,126] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.63333333333333, 77.33333333333334, 1.0, 2.0, 0.2316865867725099, 1.0, 2.0, 0.2316865867725099, 1.0, 2.0, 0.3688525916471879, 6.911200000000001, 6.9112, 121.94756008, 792168.5200349506, 792168.5200349501, 231225.3725259341], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5250000.0000, 
sim time next is 5250600.0000, 
raw observation next is [28.45, 79.0, 1.0, 2.0, 0.2376443861811527, 1.0, 2.0, 0.2376443861811527, 1.0, 2.0, 0.3783376023377277, 6.9112, 6.9112, 121.94756008, 812549.8567486613, 812549.8567486613, 233286.9034234512], 
processed observation next is [1.0, 0.782608695652174, 0.6092592592592593, 0.79, 1.0, 1.0, 0.09243379307280082, 1.0, 1.0, 0.09243379307280082, 1.0, 1.0, 0.22292200292215958, 0.0, 0.0, 0.8096049824067558, 0.2901963774102362, 0.2901963774102362, 0.4486286604297139], 
reward next is 0.5514, 
noisyNet noise sample is [array([-0.5021401], dtype=float32), -1.6723281]. 
=============================================
[2019-03-24 02:01:44,505] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.93956213e-05 1.04001424e-14 4.13093119e-07 1.52625516e-11
 9.99950171e-01], sum to 1.0000
[2019-03-24 02:01:44,513] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2351
[2019-03-24 02:01:44,516] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.6, 66.0, 1.0, 2.0, 0.4823150350945394, 1.0, 2.0, 0.4823150350945394, 1.0, 2.0, 0.7678612437745738, 6.9112, 6.9112, 121.94756008, 1650014.140994699, 1650014.140994699, 334993.8701438276], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5319000.0000, 
sim time next is 5319600.0000, 
raw observation next is [27.8, 65.0, 1.0, 2.0, 0.4521274184825251, 1.0, 2.0, 0.4521274184825251, 1.0, 2.0, 0.7198015749862108, 6.911199999999999, 6.9112, 121.94756008, 1546646.926923083, 1546646.926923084, 320669.0317351634], 
processed observation next is [1.0, 0.5652173913043478, 0.5851851851851853, 0.65, 1.0, 1.0, 0.34777073628872035, 1.0, 1.0, 0.34777073628872035, 1.0, 1.0, 0.6497519687327635, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5523739024725296, 0.55237390247253, 0.6166712148753143], 
reward next is 0.3833, 
noisyNet noise sample is [array([-1.8152943], dtype=float32), 1.2253298]. 
=============================================
[2019-03-24 02:01:45,010] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0186211e-07 8.3136496e-19 2.7838458e-09 2.0055205e-15 9.9999988e-01], sum to 1.0000
[2019-03-24 02:01:45,018] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4079
[2019-03-24 02:01:45,023] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.73333333333333, 72.66666666666667, 1.0, 2.0, 0.2132285269183508, 1.0, 2.0, 0.2132285269183508, 1.0, 2.0, 0.3394667592223247, 6.911199999999999, 6.9112, 121.94756008, 729027.850992022, 729027.8509920224, 224964.4745325251], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5343600.0000, 
sim time next is 5344200.0000, 
raw observation next is [27.65, 73.0, 1.0, 2.0, 0.2135791713215262, 1.0, 2.0, 0.2135791713215262, 1.0, 2.0, 0.3400249965318709, 6.911200000000001, 6.9112, 121.94756008, 730227.2743352149, 730227.2743352144, 225081.6358384989], 
processed observation next is [1.0, 0.8695652173913043, 0.5796296296296296, 0.73, 1.0, 1.0, 0.06378472776372167, 1.0, 1.0, 0.06378472776372167, 1.0, 1.0, 0.1750312456648386, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2607954551197196, 0.2607954551197194, 0.432849299689421], 
reward next is 0.5672, 
noisyNet noise sample is [array([-0.60512036], dtype=float32), -1.3426836]. 
=============================================
[2019-03-24 02:01:45,548] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6197002e-05 2.2318357e-16 5.9273997e-08 7.7767274e-14 9.9998379e-01], sum to 1.0000
[2019-03-24 02:01:45,555] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8388
[2019-03-24 02:01:45,559] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.5, 91.0, 1.0, 2.0, 0.2434184640316078, 1.0, 2.0, 0.2434184640316078, 1.0, 2.0, 0.3875301223242395, 6.9112, 6.9112, 121.94756008, 832303.208187557, 832303.208187557, 235303.7928548655], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5380200.0000, 
sim time next is 5380800.0000, 
raw observation next is [24.53333333333333, 91.0, 1.0, 2.0, 0.250174391183777, 1.0, 2.0, 0.250174391183777, 1.0, 2.0, 0.3982857783756795, 6.9112, 6.9112, 121.94756008, 855416.1516018923, 855416.1516018923, 237687.2920204246], 
processed observation next is [1.0, 0.2608695652173913, 0.46419753086419746, 0.91, 1.0, 1.0, 0.10735046569497261, 1.0, 1.0, 0.10735046569497261, 1.0, 1.0, 0.2478572229695994, 0.0, 0.0, 0.8096049824067558, 0.30550576842924726, 0.30550576842924726, 0.45709094619312424], 
reward next is 0.5429, 
noisyNet noise sample is [array([-1.3785454], dtype=float32), -0.66591215]. 
=============================================
[2019-03-24 02:01:50,011] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3962596e-04 7.1970832e-11 7.3285504e-05 9.9390247e-09 9.9958712e-01], sum to 1.0000
[2019-03-24 02:01:50,023] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4885
[2019-03-24 02:01:50,026] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 72.0, 1.0, 2.0, 0.7317457704983464, 1.0, 2.0, 0.6792375472256079, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2324568.568185078, 2324568.568185078, 437879.6381357064], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5418000.0000, 
sim time next is 5418600.0000, 
raw observation next is [29.93333333333333, 72.5, 1.0, 2.0, 0.3242179750964932, 1.0, 2.0, 0.3242179750964932, 1.0, 2.0, 0.5161655753959009, 6.9112, 6.9112, 121.94756008, 1108774.986485481, 1108774.986485481, 265478.9604899402], 
processed observation next is [1.0, 0.7391304347826086, 0.6641975308641974, 0.725, 1.0, 1.0, 0.19549758940058715, 1.0, 1.0, 0.19549758940058715, 1.0, 1.0, 0.3952069692448761, 0.0, 0.0, 0.8096049824067558, 0.3959910666019575, 0.3959910666019575, 0.5105364624806542], 
reward next is 0.4895, 
noisyNet noise sample is [array([-1.6248957], dtype=float32), -0.79386455]. 
=============================================
[2019-03-24 02:01:50,454] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.7363744e-06 5.9074731e-17 4.5141981e-08 1.5679812e-13 9.9999321e-01], sum to 1.0000
[2019-03-24 02:01:50,464] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9149
[2019-03-24 02:01:50,468] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.13333333333333, 89.66666666666667, 1.0, 2.0, 0.2525388409648455, 1.0, 2.0, 0.2525388409648455, 1.0, 2.0, 0.4020500594318939, 6.911200000000001, 6.9112, 121.94756008, 863505.4197367148, 863505.4197367143, 238527.4957819776], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5442000.0000, 
sim time next is 5442600.0000, 
raw observation next is [27.06666666666667, 89.83333333333333, 1.0, 2.0, 0.2512993773689923, 1.0, 2.0, 0.2512993773689923, 1.0, 2.0, 0.4000767930207845, 6.9112, 6.9112, 121.94756008, 859264.9496615094, 859264.9496615094, 238086.6648079067], 
processed observation next is [1.0, 1.0, 0.5580246913580248, 0.8983333333333333, 1.0, 1.0, 0.10868973496308611, 1.0, 1.0, 0.10868973496308611, 1.0, 1.0, 0.25009599127598064, 0.0, 0.0, 0.8096049824067558, 0.30688033916482477, 0.30688033916482477, 0.45785897078443594], 
reward next is 0.5421, 
noisyNet noise sample is [array([1.1169775], dtype=float32), -0.26171753]. 
=============================================
[2019-03-24 02:01:53,397] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.8806577e-06 1.6551196e-15 1.4691042e-07 1.1779049e-12 9.9998999e-01], sum to 1.0000
[2019-03-24 02:01:53,407] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3793
[2019-03-24 02:01:53,417] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.2, 72.0, 1.0, 2.0, 0.696548077601018, 1.0, 2.0, 0.6616387007769438, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2264263.308943421, 2264263.308943421, 428313.7712703343], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5499000.0000, 
sim time next is 5499600.0000, 
raw observation next is [29.83333333333334, 73.0, 1.0, 2.0, 0.5988539611411816, 1.0, 2.0, 0.5988539611411816, 1.0, 2.0, 0.9533950094486784, 6.911199999999999, 6.9112, 121.94756008, 2049154.542429057, 2049154.542429057, 394751.5269392354], 
processed observation next is [1.0, 0.6521739130434783, 0.6604938271604941, 0.73, 1.0, 1.0, 0.52244519183474, 1.0, 1.0, 0.52244519183474, 1.0, 1.0, 0.9417437618108478, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7318409080103775, 0.7318409080103775, 0.7591375518062219], 
reward next is 0.2409, 
noisyNet noise sample is [array([0.09608254], dtype=float32), -0.5742434]. 
=============================================
[2019-03-24 02:02:01,717] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.6611258e-07 4.6323458e-18 2.0167311e-08 1.6343114e-15 9.9999917e-01], sum to 1.0000
[2019-03-24 02:02:01,722] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7697
[2019-03-24 02:02:01,726] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.81666666666667, 97.66666666666667, 1.0, 2.0, 0.2091473479054715, 1.0, 2.0, 0.2091473479054715, 1.0, 2.0, 0.3329693893190996, 6.911200000000001, 6.9112, 121.94756008, 715067.8021861333, 715067.8021861329, 223605.8850403274], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5611800.0000, 
sim time next is 5612400.0000, 
raw observation next is [23.7, 98.0, 1.0, 2.0, 0.2076361430766112, 1.0, 2.0, 0.2076361430766112, 1.0, 2.0, 0.3305635020150487, 6.9112, 6.9112, 121.94756008, 709898.651330114, 709898.651330114, 223105.182699285], 
processed observation next is [1.0, 1.0, 0.4333333333333333, 0.98, 1.0, 1.0, 0.05670969413882287, 1.0, 1.0, 0.05670969413882287, 1.0, 1.0, 0.16320437751881084, 0.0, 0.0, 0.8096049824067558, 0.25353523261789784, 0.25353523261789784, 0.4290484282678558], 
reward next is 0.5710, 
noisyNet noise sample is [array([-0.60160303], dtype=float32), 0.048550356]. 
=============================================
[2019-03-24 02:02:02,643] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.6619977e-07 6.2264206e-19 6.5717298e-09 1.4453873e-15 9.9999964e-01], sum to 1.0000
[2019-03-24 02:02:02,648] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5507
[2019-03-24 02:02:02,655] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.33333333333334, 95.66666666666666, 1.0, 2.0, 0.2106558404527783, 1.0, 2.0, 0.2106558404527783, 1.0, 2.0, 0.3353709585825845, 6.9112, 6.9112, 121.94756008, 720227.7103062739, 720227.7103062739, 224106.9633935284], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5642400.0000, 
sim time next is 5643000.0000, 
raw observation next is [24.4, 95.5, 1.0, 2.0, 0.2112877267146462, 1.0, 2.0, 0.2112877267146462, 1.0, 2.0, 0.336376942090577, 6.9112, 6.9112, 121.94756008, 722389.1333951436, 722389.1333951436, 224317.2364888916], 
processed observation next is [0.0, 0.30434782608695654, 0.4592592592592592, 0.955, 1.0, 1.0, 0.06105681751743597, 1.0, 1.0, 0.06105681751743597, 1.0, 1.0, 0.17047117761322123, 0.0, 0.0, 0.8096049824067558, 0.2579961190696941, 0.2579961190696941, 0.4313793009401761], 
reward next is 0.5686, 
noisyNet noise sample is [array([1.1434695], dtype=float32), -0.16419137]. 
=============================================
[2019-03-24 02:02:02,671] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[55.111893]
 [55.14376 ]
 [55.159023]
 [55.16231 ]
 [55.168255]], R is [[55.11102295]
 [55.12894058]
 [55.14723969]
 [55.165905  ]
 [55.185009  ]].
[2019-03-24 02:02:09,591] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 6.6366556e-16 1.2743692e-10 8.4670350e-16 1.6582137e-08], sum to 1.0000
[2019-03-24 02:02:09,602] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4089
[2019-03-24 02:02:09,609] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 961577.3543238153 W.
[2019-03-24 02:02:09,615] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.56666666666667, 53.33333333333334, 1.0, 2.0, 0.263392715930326, 1.0, 2.0, 0.263392715930326, 1.0, 2.0, 0.4292847314550833, 6.911200000000001, 6.9112, 121.94756008, 961577.3543238153, 961577.3543238149, 241302.1077406324], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5825400.0000, 
sim time next is 5826000.0000, 
raw observation next is [25.73333333333333, 51.66666666666667, 1.0, 2.0, 0.2741842346929028, 1.0, 2.0, 0.2741842346929028, 1.0, 2.0, 0.447344770612796, 6.911200000000001, 6.9112, 121.94756008, 1002322.249900035, 1002322.249900035, 245187.2952585382], 
processed observation next is [1.0, 0.43478260869565216, 0.5086419753086419, 0.5166666666666667, 1.0, 1.0, 0.1359336127296462, 1.0, 1.0, 0.1359336127296462, 1.0, 1.0, 0.3091809632659949, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.35797223210715534, 0.35797223210715534, 0.4715140293433427], 
reward next is 0.5285, 
noisyNet noise sample is [array([0.1301314], dtype=float32), 0.054075476]. 
=============================================
[2019-03-24 02:02:09,624] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[45.188904]
 [44.47972 ]
 [44.33213 ]
 [43.56746 ]
 [43.979813]], R is [[44.91209412]
 [44.99893188]
 [45.08384323]
 [45.20902634]
 [45.32939911]].
[2019-03-24 02:02:12,633] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.4390778e-22 1.6141846e-12 7.7769146e-21 9.6872328e-12], sum to 1.0000
[2019-03-24 02:02:12,641] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8024
[2019-03-24 02:02:12,651] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.96666666666667, 81.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7958040123765022, 6.911199999999999, 6.9112, 121.9260426156618, 594019.734441463, 594019.7344414635, 157647.5823570682], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5815200.0000, 
sim time next is 5815800.0000, 
raw observation next is [23.1, 80.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7683796279139473, 6.911199999999999, 6.9112, 121.9260426156618, 573508.3692667872, 573508.3692667877, 154403.8050559776], 
processed observation next is [1.0, 0.30434782608695654, 0.41111111111111115, 0.805, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7104745348924341, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20482441759528114, 0.2048244175952813, 0.29693039433841845], 
reward next is 0.7031, 
noisyNet noise sample is [array([-0.24199456], dtype=float32), -1.3221133]. 
=============================================
[2019-03-24 02:02:15,442] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9999988e-01 7.0921521e-21 7.0283175e-11 1.2477464e-17 6.3570184e-08], sum to 1.0000
[2019-03-24 02:02:15,447] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5064
[2019-03-24 02:02:15,452] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.45, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.65575770502222, 6.9112, 6.9112, 121.9260426156618, 483465.3454825889, 483465.3454825889, 133814.6711245278], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5887800.0000, 
sim time next is 5888400.0000, 
raw observation next is [19.4, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6207892622021809, 6.9112, 6.9112, 121.9260426156618, 457395.6620533384, 457395.6620533384, 130352.7869381724], 
processed observation next is [1.0, 0.13043478260869565, 0.274074074074074, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5259865777527261, 0.0, 0.0, 0.8094621288201359, 0.16335559359047802, 0.16335559359047802, 0.25067843641956233], 
reward next is 0.7493, 
noisyNet noise sample is [array([0.8948196], dtype=float32), -1.108857]. 
=============================================
[2019-03-24 02:02:20,387] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.0008714e-09 5.0490064e-20 1.1863988e-09 5.1778853e-17 1.0000000e+00], sum to 1.0000
[2019-03-24 02:02:20,395] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9309
[2019-03-24 02:02:20,398] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.3, 70.0, 1.0, 2.0, 0.3788783853784281, 1.0, 2.0, 0.3788783853784281, 1.0, 2.0, 0.6031867287300244, 6.9112, 6.9112, 121.94756008, 1295863.151361088, 1295863.151361088, 287953.3606417642], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6001200.0000, 
sim time next is 6001800.0000, 
raw observation next is [26.58333333333334, 69.33333333333334, 1.0, 2.0, 0.4002331440886164, 1.0, 2.0, 0.4002331440886164, 1.0, 2.0, 0.6371842000725817, 6.911199999999999, 6.9112, 121.94756008, 1368967.269444128, 1368967.269444128, 297184.2790831794], 
processed observation next is [1.0, 0.4782608695652174, 0.5401234567901236, 0.6933333333333335, 1.0, 1.0, 0.2859918382007338, 1.0, 1.0, 0.2859918382007338, 1.0, 1.0, 0.5464802500907271, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4889168819443314, 0.4889168819443314, 0.5715082290061143], 
reward next is 0.4285, 
noisyNet noise sample is [array([-0.5387468], dtype=float32), 1.2050842]. 
=============================================
[2019-03-24 02:02:20,933] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 6.4005083e-21 6.0853861e-13 1.9726173e-19 1.6542428e-08], sum to 1.0000
[2019-03-24 02:02:20,941] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7637
[2019-03-24 02:02:20,946] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6507067851312982, 6.911200000000001, 6.9112, 121.9260426156618, 485742.528785623, 485742.5287856225, 137918.1776022677], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5979600.0000, 
sim time next is 5980200.0000, 
raw observation next is [21.11666666666667, 85.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7756808811026021, 6.9112, 6.9112, 121.9260426156618, 579070.6168296319, 579070.6168296319, 151457.6170669824], 
processed observation next is [1.0, 0.21739130434782608, 0.33765432098765447, 0.8516666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7196011013782527, 0.0, 0.0, 0.8094621288201359, 0.20681093458201139, 0.20681093458201139, 0.2912646482057354], 
reward next is 0.7087, 
noisyNet noise sample is [array([-0.29613915], dtype=float32), 0.95516163]. 
=============================================
[2019-03-24 02:02:27,097] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 02:02:27,098] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:02:27,098] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:02:27,098] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:02:27,100] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:02:27,101] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:02:27,101] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:02:27,102] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:02:27,102] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:02:27,103] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:02:27,101] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:02:27,118] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run16
[2019-03-24 02:02:27,144] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run16
[2019-03-24 02:02:27,144] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run16
[2019-03-24 02:02:27,145] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run16
[2019-03-24 02:02:27,146] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run16
[2019-03-24 02:02:37,718] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00044958], dtype=float32), 0.14158456]
[2019-03-24 02:02:37,720] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.25, 36.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5650666245482774, 6.9112, 6.9112, 121.9260426156618, 413371.3020473935, 413371.3020473935, 123886.0464055914]
[2019-03-24 02:02:37,722] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:02:37,727] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.5861115e-21 3.6008772e-15 5.2041375e-19 2.1369244e-10], sampled 0.3772725262396295
[2019-03-24 02:02:45,328] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00044958], dtype=float32), 0.14158456]
[2019-03-24 02:02:45,331] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.96666666666667, 25.66666666666667, 1.0, 2.0, 0.9177718392571371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.153053713600943, 6.9112, 121.9247949136861, 1265467.561266139, 1141618.110660524, 225499.5032717484]
[2019-03-24 02:02:45,333] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:02:45,336] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9922717e-01 4.8328868e-16 8.8526220e-10 3.6610252e-13 7.7284308e-04], sampled 0.3458076094359239
[2019-03-24 02:02:45,340] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1265467.561266139 W.
[2019-03-24 02:03:12,063] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00044958], dtype=float32), 0.14158456]
[2019-03-24 02:03:12,064] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.43285679, 28.99082571, 1.0, 1.0, 0.472491488233196, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9259296494952, 582763.5077758975, 582763.507775898, 139235.0020437555]
[2019-03-24 02:03:12,065] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:03:12,067] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.5709484e-22 1.4452665e-15 1.5022059e-19 1.3827739e-10], sampled 0.2366157463170665
[2019-03-24 02:03:17,227] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00044958], dtype=float32), 0.14158456]
[2019-03-24 02:03:17,229] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.1, 82.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7582584615583364, 6.911200000000001, 6.9112, 121.9260426156618, 565568.7048263152, 565568.7048263147, 153632.1707529369]
[2019-03-24 02:03:17,230] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:03:17,233] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 4.0924479e-19 1.7183881e-13 6.9550987e-17 2.8125651e-09], sampled 0.04419118305287717
[2019-03-24 02:04:08,047] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8553.7851 2258733396.8042 533.0000
[2019-03-24 02:04:08,050] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8356.8227 2339779721.4687 617.0000
[2019-03-24 02:04:08,183] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8631.4209 2219286721.7921 542.0000
[2019-03-24 02:04:08,203] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8397.0355 2293357082.6195 695.0000
[2019-03-24 02:04:08,352] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7829.6713 2530131953.3817 820.0000
[2019-03-24 02:04:09,366] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 375000, evaluation results [375000.0, 7829.671257028277, 2530131953.381723, 820.0, 8553.785077105536, 2258733396.8042417, 533.0, 8631.42089649293, 2219286721.7920732, 542.0, 8356.822710296598, 2339779721.468676, 617.0, 8397.035533532575, 2293357082.6194773, 695.0]
[2019-03-24 02:04:13,567] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.3471564e-16 3.5158118e-12 1.2720111e-14 4.1358259e-08], sum to 1.0000
[2019-03-24 02:04:13,573] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9677
[2019-03-24 02:04:13,580] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1605153.552151779 W.
[2019-03-24 02:04:13,587] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.33333333333333, 62.33333333333333, 1.0, 2.0, 0.7809113134002149, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1605153.552151779, 1605153.55215178, 332466.8886879105], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6178200.0000, 
sim time next is 6178800.0000, 
raw observation next is [28.46666666666667, 61.66666666666667, 1.0, 2.0, 0.5376235711545748, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8562908249487499, 6.911199999999999, 6.9112, 121.9260426156618, 1233918.615955609, 1233918.61595561, 270262.2558167764], 
processed observation next is [1.0, 0.5217391304347826, 0.6098765432098766, 0.6166666666666667, 1.0, 1.0, 0.44955187042211286, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8203635311859372, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.44068521998414606, 0.44068521998414645, 0.5197351073399546], 
reward next is 0.4803, 
noisyNet noise sample is [array([0.55684286], dtype=float32), 1.5419033]. 
=============================================
[2019-03-24 02:04:16,719] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 9.9785816e-24 1.8391744e-17 3.5968145e-22 7.9189509e-13], sum to 1.0000
[2019-03-24 02:04:16,731] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1896
[2019-03-24 02:04:16,735] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.3, 81.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7726952630302593, 6.911200000000001, 6.9112, 121.9260426156618, 575789.6235662407, 575789.6235662402, 155829.8978220792], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6232200.0000, 
sim time next is 6232800.0000, 
raw observation next is [23.2, 82.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7705667328881818, 6.911200000000001, 6.9112, 121.9260426156618, 574227.635243447, 574227.6352434466, 155554.8181527866], 
processed observation next is [0.0, 0.13043478260869565, 0.4148148148148148, 0.8233333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7132084161102272, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2050812983012311, 0.20508129830123092, 0.2991438810630512], 
reward next is 0.7009, 
noisyNet noise sample is [array([-1.1384256], dtype=float32), -1.7678615]. 
=============================================
[2019-03-24 02:04:16,979] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.0344768e-18 1.3578584e-14 9.9444553e-17 7.1023587e-10], sum to 1.0000
[2019-03-24 02:04:16,986] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3660
[2019-03-24 02:04:16,991] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 732157.6906573457 W.
[2019-03-24 02:04:16,995] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.26666666666667, 64.5, 1.0, 2.0, 0.2141435160971725, 1.0, 2.0, 0.2141435160971725, 1.0, 1.0, 0.3409234517941259, 6.911200000000001, 6.9112, 121.94756008, 732157.6906573457, 732157.6906573452, 225270.3456130655], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6270600.0000, 
sim time next is 6271200.0000, 
raw observation next is [29.4, 64.0, 1.0, 2.0, 0.3227146144365867, 1.0, 2.0, 0.3227146144365867, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 735576.8933723962, 735576.8933723967, 186001.0624625659], 
processed observation next is [0.0, 0.6086956521739131, 0.6444444444444444, 0.64, 1.0, 1.0, 0.19370787432926992, 1.0, 1.0, 0.19370787432926992, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2627060333472844, 0.26270603334728454, 0.3576943508895498], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0027641], dtype=float32), 0.6525518]. 
=============================================
[2019-03-24 02:04:19,243] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.1417411e-20 8.4019493e-15 1.7472154e-19 2.3604011e-11], sum to 1.0000
[2019-03-24 02:04:19,249] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0040
[2019-03-24 02:04:19,258] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 735611.1991978976 W.
[2019-03-24 02:04:19,263] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.4, 64.0, 1.0, 2.0, 0.2151531235258833, 1.0, 2.0, 0.2151531235258833, 1.0, 1.0, 0.342530779701252, 6.9112, 6.9112, 121.94756008, 735611.1991978976, 735611.1991978976, 225608.3901609993], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6271200.0000, 
sim time next is 6271800.0000, 
raw observation next is [29.45, 63.83333333333334, 1.0, 2.0, 0.2135914775729683, 1.0, 2.0, 0.2135914775729683, 1.0, 2.0, 0.3400445884849533, 6.9112, 6.9112, 121.94756008, 730269.3694522742, 730269.3694522742, 225085.7489931557], 
processed observation next is [0.0, 0.6086956521739131, 0.6462962962962963, 0.6383333333333334, 1.0, 1.0, 0.06379937806305752, 1.0, 1.0, 0.06379937806305752, 1.0, 1.0, 0.1750557356061916, 0.0, 0.0, 0.8096049824067558, 0.2608104890900979, 0.2608104890900979, 0.43285720960222246], 
reward next is 0.5671, 
noisyNet noise sample is [array([0.49859375], dtype=float32), -1.0298488]. 
=============================================
[2019-03-24 02:04:19,900] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 7.8451625e-25 1.0890882e-18 2.4445944e-22 4.4097399e-12], sum to 1.0000
[2019-03-24 02:04:19,910] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9395
[2019-03-24 02:04:19,914] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.66666666666666, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.928054712210071, 6.911199999999999, 6.9112, 121.9260426156618, 676356.1104079626, 676356.110407963, 180242.5423486725], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6331200.0000, 
sim time next is 6331800.0000, 
raw observation next is [24.73333333333333, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9339782695011618, 6.9112, 6.9112, 121.9260426156618, 679923.454435276, 679923.454435276, 181176.7816811645], 
processed observation next is [0.0, 0.2608695652173913, 0.4716049382716048, 0.87, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9174728368764523, 0.0, 0.0, 0.8094621288201359, 0.2428298051554557, 0.2428298051554557, 0.34841688784839325], 
reward next is 0.6516, 
noisyNet noise sample is [array([0.12606087], dtype=float32), 0.033294745]. 
=============================================
[2019-03-24 02:04:20,198] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.4952828e-17 2.5407224e-13 1.7162311e-15 1.4915392e-08], sum to 1.0000
[2019-03-24 02:04:20,207] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1928
[2019-03-24 02:04:20,222] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 701520.9455781069 W.
[2019-03-24 02:04:20,227] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.2, 86.0, 1.0, 2.0, 0.3077803152118121, 1.0, 2.0, 0.3077803152118121, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 701520.9455781069, 701520.9455781074, 182338.1197731951], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6336000.0000, 
sim time next is 6336600.0000, 
raw observation next is [25.43333333333333, 85.0, 1.0, 2.0, 0.2064518377666553, 1.0, 2.0, 0.2064518377666553, 1.0, 1.0, 0.3286780493914677, 6.911200000000001, 6.9112, 121.94756008, 705847.7008035043, 705847.7008035039, 222713.6842108649], 
processed observation next is [0.0, 0.34782608695652173, 0.49753086419753073, 0.85, 1.0, 1.0, 0.055299806865065824, 1.0, 1.0, 0.055299806865065824, 1.0, 0.5, 0.16084756173933462, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.25208846457268014, 0.25208846457267997, 0.4282955465593556], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3608691], dtype=float32), -1.3274693]. 
=============================================
[2019-03-24 02:04:20,847] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.7625355e-15 1.9258482e-12 4.4716499e-14 4.7867829e-08], sum to 1.0000
[2019-03-24 02:04:20,853] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0368
[2019-03-24 02:04:20,859] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 710307.7686844514 W.
[2019-03-24 02:04:20,868] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.66666666666667, 84.0, 1.0, 2.0, 0.6224339136285363, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 710307.7686844514, 710307.7686844514, 162025.3892129671], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6337200.0000, 
sim time next is 6337800.0000, 
raw observation next is [25.9, 83.0, 1.0, 2.0, 0.2091592552630579, 1.0, 1.0, 0.2091592552630579, 1.0, 1.0, 0.3329883462201726, 6.9112, 6.9112, 121.94756008, 715108.5320300375, 715108.5320300375, 223609.8353396174], 
processed observation next is [0.0, 0.34782608695652173, 0.5148148148148147, 0.83, 1.0, 1.0, 0.05852292293221178, 1.0, 0.5, 0.05852292293221178, 1.0, 0.5, 0.1662354327752157, 0.0, 0.0, 0.8096049824067558, 0.25539590429644193, 0.25539590429644193, 0.4300189141146488], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.04982722], dtype=float32), -0.50852907]. 
=============================================
[2019-03-24 02:04:23,499] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9997532e-01 3.0646498e-13 8.6471946e-10 7.0405786e-12 2.4704901e-05], sum to 1.0000
[2019-03-24 02:04:23,504] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6055
[2019-03-24 02:04:23,510] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 760445.0027732142 W.
[2019-03-24 02:04:23,516] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.8, 86.5, 1.0, 2.0, 0.6672388414112647, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 760445.0027732142, 760445.0027732142, 170032.2074776603], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6400200.0000, 
sim time next is 6400800.0000, 
raw observation next is [25.7, 87.0, 1.0, 2.0, 0.2218375438606119, 1.0, 1.0, 0.2218375438606119, 1.0, 1.0, 0.353172594570512, 6.911200000000001, 6.9112, 121.94756008, 758476.6202473424, 758476.6202473419, 227860.9055575996], 
processed observation next is [1.0, 0.08695652173913043, 0.5074074074074074, 0.87, 1.0, 1.0, 0.07361612364358561, 1.0, 0.5, 0.07361612364358561, 1.0, 0.5, 0.19146574321313994, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2708845072311937, 0.27088450723119356, 0.43819404914923], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.17667627], dtype=float32), -0.32682407]. 
=============================================
[2019-03-24 02:04:26,965] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9588937e-01 6.2623442e-13 3.1157487e-08 5.4776225e-11 4.1106516e-03], sum to 1.0000
[2019-03-24 02:04:26,965] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4820
[2019-03-24 02:04:26,965] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 985236.2348358001 W.
[2019-03-24 02:04:26,967] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.75, 91.83333333333333, 1.0, 2.0, 0.2881170937634635, 1.0, 2.0, 0.2881170937634635, 1.0, 2.0, 0.4586917965900942, 6.911200000000001, 6.9112, 121.94756008, 985236.2348358001, 985236.2348357997, 251546.9402893119], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6411000.0000, 
sim time next is 6411600.0000, 
raw observation next is [24.7, 92.0, 1.0, 2.0, 0.4195594252713556, 0.0, 1.0, 0.0, 1.0, 2.0, 0.667952269128539, 6.9112, 6.9112, 121.9260426156618, 956457.0496765636, 956457.0496765636, 230211.8044684344], 
processed observation next is [1.0, 0.21739130434782608, 0.4703703703703703, 0.92, 1.0, 1.0, 0.30899931579923284, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.5849403364106737, 0.0, 0.0, 0.8094621288201359, 0.34159180345591555, 0.34159180345591555, 0.44271500859314306], 
reward next is 0.5573, 
noisyNet noise sample is [array([0.26531637], dtype=float32), -1.1490002]. 
=============================================
[2019-03-24 02:04:42,073] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.7153864e-19 3.8183109e-10 1.5388246e-15 3.2753977e-08], sum to 1.0000
[2019-03-24 02:04:42,081] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9163
[2019-03-24 02:04:42,088] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1270041.823068582 W.
[2019-03-24 02:04:42,092] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.16666666666667, 28.0, 1.0, 2.0, 0.5120956031685467, 1.0, 2.0, 0.5120956031685467, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260425282026, 1270041.823068582, 1270041.823068582, 242992.6997953304], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6709800.0000, 
sim time next is 6710400.0000, 
raw observation next is [30.2, 28.0, 1.0, 2.0, 0.329676333812403, 1.0, 2.0, 0.329676333812403, 1.0, 1.0, 0.5438888058220162, 6.911200000000001, 6.9112, 121.94756008, 1219771.192542161, 1219771.192542161, 265854.8671505732], 
processed observation next is [1.0, 0.6956521739130435, 0.674074074074074, 0.28, 1.0, 1.0, 0.20199563549095598, 1.0, 1.0, 0.20199563549095598, 1.0, 0.5, 0.42986100727752014, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4356325687650575, 0.4356325687650575, 0.5112593599049484], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.49006602], dtype=float32), 1.2247933]. 
=============================================
[2019-03-24 02:04:44,791] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.7924832e-06 1.8282104e-18 1.0213458e-07 1.6688464e-13 9.9999511e-01], sum to 1.0000
[2019-03-24 02:04:44,797] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4960
[2019-03-24 02:04:44,803] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.9, 48.0, 1.0, 2.0, 0.4098529408124752, 1.0, 2.0, 0.4098529408124752, 1.0, 2.0, 0.6575872363441201, 6.911199999999999, 6.9112, 121.94756008, 1456409.072695726, 1456409.072695726, 301311.0491610609], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6789600.0000, 
sim time next is 6790200.0000, 
raw observation next is [27.91666666666666, 48.5, 1.0, 2.0, 0.3528562504003343, 1.0, 2.0, 0.3528562504003343, 1.0, 2.0, 0.5663362293893227, 6.911200000000001, 6.9112, 121.94756008, 1254807.586778173, 1254807.586778173, 276852.9841089999], 
processed observation next is [1.0, 0.6086956521739131, 0.5895061728395059, 0.485, 1.0, 1.0, 0.22959077428611227, 1.0, 1.0, 0.22959077428611227, 1.0, 1.0, 0.45792028673665336, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.44814556670649036, 0.44814556670649036, 0.5324095848249998], 
reward next is 0.4676, 
noisyNet noise sample is [array([1.0777496], dtype=float32), -0.26659197]. 
=============================================
[2019-03-24 02:04:49,208] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.8777224e-35 6.7491168e-24 1.9883779e-33 2.9954896e-21], sum to 1.0000
[2019-03-24 02:04:49,217] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6932
[2019-03-24 02:04:49,220] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.06666666666667, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7287838521620836, 6.9112, 6.9112, 121.9260426156618, 544338.124545585, 544338.124545585, 149173.3698149614], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6826800.0000, 
sim time next is 6827400.0000, 
raw observation next is [23.0, 78.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7219102108017817, 6.911199999999999, 6.9112, 121.9260426156618, 539301.0913668656, 539301.091366866, 148171.4325393511], 
processed observation next is [0.0, 0.0, 0.4074074074074074, 0.785, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.652387763502227, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19260753263102343, 0.1926075326310236, 0.2849450625756752], 
reward next is 0.7151, 
noisyNet noise sample is [array([0.9334674], dtype=float32), 1.0795857]. 
=============================================
[2019-03-24 02:04:50,008] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 6.4481872e-32 7.0399580e-24 2.3763265e-28 6.4264484e-19], sum to 1.0000
[2019-03-24 02:04:50,019] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7074
[2019-03-24 02:04:50,027] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.03333333333333, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6337752641066028, 6.911199999999999, 6.9112, 121.9260426156618, 472434.5554954884, 472434.5554954889, 135327.7579300583], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6846000.0000, 
sim time next is 6846600.0000, 
raw observation next is [22.11666666666667, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6372293364190301, 6.911199999999999, 6.9112, 121.9260426156618, 475194.1488940172, 475194.1488940176, 135882.4233330502], 
processed observation next is [0.0, 0.21739130434782608, 0.3746913580246915, 0.76, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5465366705237876, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16971219603357757, 0.16971219603357773, 0.26131235256355806], 
reward next is 0.7387, 
noisyNet noise sample is [array([-2.4122655], dtype=float32), -0.36833796]. 
=============================================
[2019-03-24 02:04:51,596] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.2543849e-31 1.3022924e-22 7.7096252e-29 5.8112824e-20], sum to 1.0000
[2019-03-24 02:04:51,605] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7850
[2019-03-24 02:04:51,611] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.4, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7118995152564724, 6.9112, 6.9112, 121.9260426156618, 531971.3705828723, 531971.3705828723, 146490.3563729688], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6901200.0000, 
sim time next is 6901800.0000, 
raw observation next is [25.25, 62.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7096876053874992, 6.9112, 6.9112, 121.9260426156618, 530333.20189525, 530333.20189525, 146125.0715145734], 
processed observation next is [0.0, 0.9130434782608695, 0.49074074074074076, 0.625, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.637109506734374, 0.0, 0.0, 0.8094621288201359, 0.1894047149625893, 0.1894047149625893, 0.2810097529126412], 
reward next is 0.7190, 
noisyNet noise sample is [array([-1.1625348], dtype=float32), -0.29313198]. 
=============================================
[2019-03-24 02:04:52,894] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 4.1267676e-25 1.0910932e-17 1.5943972e-22 6.0196445e-16], sum to 1.0000
[2019-03-24 02:04:52,900] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8855
[2019-03-24 02:04:52,908] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7001138895094694, 6.911200000000001, 6.9112, 121.9260426156618, 523189.1246388203, 523189.1246388198, 144786.3375180908], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6933600.0000, 
sim time next is 6934200.0000, 
raw observation next is [21.91666666666667, 84.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7034933166747898, 6.9112, 6.9112, 121.9260426156618, 525712.7112073946, 525712.7112073946, 145308.8780876052], 
processed observation next is [0.0, 0.2608695652173913, 0.36728395061728414, 0.8450000000000002, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6293666458434871, 0.0, 0.0, 0.8094621288201359, 0.18775453971692666, 0.18775453971692666, 0.27944015016847157], 
reward next is 0.7206, 
noisyNet noise sample is [array([0.16835786], dtype=float32), -0.35242704]. 
=============================================
[2019-03-24 02:04:53,465] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.000000e+00 8.288483e-25 7.685681e-17 4.105386e-23 1.987760e-14], sum to 1.0000
[2019-03-24 02:04:53,474] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5584
[2019-03-24 02:04:53,478] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.5, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7166058194427757, 6.911200000000001, 6.9112, 121.9260426156618, 535399.3223902785, 535399.322390278, 147399.1699449328], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6937200.0000, 
sim time next is 6937800.0000, 
raw observation next is [22.61666666666667, 81.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7193782461080007, 6.911200000000001, 6.9112, 121.9260426156618, 537415.8328206602, 537415.8328206597, 147868.1882213189], 
processed observation next is [0.0, 0.30434782608695654, 0.39320987654321005, 0.8166666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.649222807635001, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19193422600737864, 0.19193422600737847, 0.28436190042561327], 
reward next is 0.7156, 
noisyNet noise sample is [array([1.6991258], dtype=float32), 1.1125982]. 
=============================================
[2019-03-24 02:04:55,404] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.3159485e-25 1.4345166e-16 2.1985522e-24 1.0835086e-14], sum to 1.0000
[2019-03-24 02:04:55,413] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9970
[2019-03-24 02:04:55,416] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.03333333333333, 48.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8985698654017482, 6.9112, 6.9112, 121.9260426156618, 659537.6177843225, 659537.6177843225, 175338.7760863302], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6970200.0000, 
sim time next is 6970800.0000, 
raw observation next is [31.06666666666667, 47.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8733941257135333, 6.911199999999999, 6.9112, 121.9260426156618, 642261.8790597726, 642261.879059773, 171746.0820773536], 
processed observation next is [0.0, 0.6956521739130435, 0.7061728395061729, 0.47333333333333344, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8417426571419164, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22937924252134737, 0.22937924252134753, 0.3302809270718339], 
reward next is 0.6697, 
noisyNet noise sample is [array([0.00192502], dtype=float32), -1.58777]. 
=============================================
[2019-03-24 02:04:58,241] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 7.2104421e-27 2.2780510e-19 7.9767352e-25 5.2561637e-14], sum to 1.0000
[2019-03-24 02:04:58,248] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9110
[2019-03-24 02:04:58,258] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.01666666666667, 84.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7566201034564705, 6.9112, 6.9112, 121.9260426156618, 565406.1846525936, 565406.1846525936, 151524.98588722], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7026600.0000, 
sim time next is 7027200.0000, 
raw observation next is [22.1, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7660997742724064, 6.911200000000001, 6.9112, 121.9260426156618, 572475.7249897019, 572475.7249897014, 152729.3055861519], 
processed observation next is [1.0, 0.34782608695652173, 0.3740740740740741, 0.84, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7076247178405078, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20445561606775067, 0.2044556160677505, 0.2937102030502921], 
reward next is 0.7063, 
noisyNet noise sample is [array([-0.37405932], dtype=float32), 1.1540993]. 
=============================================
[2019-03-24 02:04:59,905] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 02:04:59,909] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:04:59,910] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:04:59,910] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:04:59,912] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:04:59,913] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:04:59,912] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:04:59,918] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:04:59,918] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:04:59,913] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:04:59,920] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:04:59,931] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run17
[2019-03-24 02:04:59,954] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run17
[2019-03-24 02:04:59,974] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run17
[2019-03-24 02:04:59,976] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run17
[2019-03-24 02:04:59,977] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run17
[2019-03-24 02:05:10,273] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.14602697]
[2019-03-24 02:05:10,274] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [34.46374549666667, 37.589077455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7696303893394061, 6.9112, 6.9112, 121.9260426156618, 565155.2529037724, 565155.2529037724, 158720.5767909864]
[2019-03-24 02:05:10,274] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:05:10,278] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.6361849e-29 2.8653934e-19 3.8116144e-26 2.7330776e-15], sampled 0.1342347157838738
[2019-03-24 02:05:12,830] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.14602697]
[2019-03-24 02:05:12,830] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.3293928, 50.76395911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6563536755675793, 6.9112, 6.9112, 121.9260426156618, 489599.2509513373, 489599.2509513373, 137989.5852203724]
[2019-03-24 02:05:12,831] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:05:12,834] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.7733886e-28 1.0659231e-18 4.2853192e-25 3.8620870e-15], sampled 0.19327847571272583
[2019-03-24 02:05:23,902] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.14602697]
[2019-03-24 02:05:23,904] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.16666666666667, 83.33333333333334, 1.0, 2.0, 0.5715255798920003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260425961897, 726212.6233472523, 726212.6233472518, 155686.4342701886]
[2019-03-24 02:05:23,906] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:05:23,909] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 5.9655626e-22 2.6415087e-14 2.0512599e-19 2.5704144e-11], sampled 0.06933526906496523
[2019-03-24 02:05:23,910] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 726212.6233472523 W.
[2019-03-24 02:05:35,514] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.14602697]
[2019-03-24 02:05:35,515] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.87002791, 34.052644455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5540401471755078, 6.9112, 6.9112, 121.9260426156618, 400884.07079003, 400884.07079003, 121156.0698440988]
[2019-03-24 02:05:35,516] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:05:35,518] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.4271513e-27 5.3646691e-18 3.8367682e-24 1.4027502e-14], sampled 0.4304014964459132
[2019-03-24 02:05:55,631] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.14602697]
[2019-03-24 02:05:55,632] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.13403908166666, 78.76720495666666, 1.0, 2.0, 0.5726221530399132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 671835.393758886, 671835.393758886, 154322.4687159929]
[2019-03-24 02:05:55,632] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:05:55,633] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9999988e-01 3.1485148e-22 9.1122043e-13 1.0162034e-18 1.2347576e-07], sampled 0.18233781492327372
[2019-03-24 02:06:07,671] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.14602697]
[2019-03-24 02:06:07,672] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.93333333333333, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7676534396738508, 6.9112, 6.9112, 121.9260426156618, 571549.8641436843, 571549.8641436843, 155572.7829667506]
[2019-03-24 02:06:07,673] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:06:07,677] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.7400837e-28 6.4108752e-19 2.1463113e-25 2.5598998e-15], sampled 0.15569902240123323
[2019-03-24 02:06:16,272] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.14602697]
[2019-03-24 02:06:16,274] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.9, 76.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7484491301585646, 6.9112, 6.9112, 121.9260426156618, 559319.0004687477, 559319.0004687477, 150076.9436068859]
[2019-03-24 02:06:16,276] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:06:16,277] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.8475681e-27 3.0894968e-18 1.7822494e-24 9.2140532e-15], sampled 0.6349325248992077
[2019-03-24 02:06:23,191] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.14602697]
[2019-03-24 02:06:23,192] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.66666666666666, 84.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8472374615876108, 6.911200000000001, 6.9112, 121.9260426156618, 621234.7273526853, 621234.7273526848, 168807.7161160587]
[2019-03-24 02:06:23,194] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:06:23,196] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 4.0746245e-28 1.1243714e-18 4.5880333e-25 4.0263660e-15], sampled 0.44747237909390136
[2019-03-24 02:06:33,503] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.14602697]
[2019-03-24 02:06:33,504] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.5, 64.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.484750931615599, 6.911199999999999, 6.9112, 121.9260426156618, 353259.7958441141, 353259.7958441146, 116629.6218724406]
[2019-03-24 02:06:33,504] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:06:33,507] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.5375185e-27 4.6005106e-18 3.1291744e-24 1.2308289e-14], sampled 0.5595833414532522
[2019-03-24 02:06:35,825] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.14602697]
[2019-03-24 02:06:35,826] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.03333333333333, 93.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4931189619349924, 6.9112, 6.9112, 121.9260426156618, 355074.4207386335, 355074.4207386335, 115631.7062383854]
[2019-03-24 02:06:35,826] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:06:35,828] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.2793246e-26 1.0544903e-17 9.7363169e-24 2.3500114e-14], sampled 0.029403552682895406
[2019-03-24 02:06:40,202] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8357.0511 2340036357.5137 606.0000
[2019-03-24 02:06:40,274] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8630.5875 2219516490.0595 539.0000
[2019-03-24 02:06:40,305] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8561.4166 2258376784.8915 532.0000
[2019-03-24 02:06:40,530] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8398.9713 2293554841.3595 688.0000
[2019-03-24 02:06:40,645] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7827.2462 2530622093.2991 802.0000
[2019-03-24 02:06:41,660] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 400000, evaluation results [400000.0, 7827.246153926185, 2530622093.2990727, 802.0, 8561.416628169432, 2258376784.89148, 532.0, 8630.587524620338, 2219516490.0595264, 539.0, 8357.051122096062, 2340036357.5136676, 606.0, 8398.971329305612, 2293554841.3595004, 688.0]
[2019-03-24 02:06:45,249] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.000000e+00 2.993199e-25 8.505387e-18 1.189743e-21 6.484380e-15], sum to 1.0000
[2019-03-24 02:06:45,257] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3159
[2019-03-24 02:06:45,262] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.86666666666667, 84.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6899462489516905, 6.911199999999999, 6.9112, 121.9260426156618, 514432.6439959545, 514432.6439959549, 141201.181909327], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7107600.0000, 
sim time next is 7108200.0000, 
raw observation next is [20.85, 84.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6870483404605401, 6.911199999999999, 6.9112, 121.9260426156618, 512177.3611633233, 512177.3611633237, 140792.1676111344], 
processed observation next is [1.0, 0.2608695652173913, 0.32777777777777783, 0.845, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6088104255756751, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1829204861297583, 0.18292048612975845, 0.2707541684829508], 
reward next is 0.7292, 
noisyNet noise sample is [array([-0.53417754], dtype=float32), -0.66875356]. 
=============================================
[2019-03-24 02:06:45,635] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.6647329e-26 7.1059442e-19 2.4784136e-24 5.6107759e-16], sum to 1.0000
[2019-03-24 02:06:45,640] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8890
[2019-03-24 02:06:45,647] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 985188.6370351118 W.
[2019-03-24 02:06:45,650] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.83333333333334, 61.66666666666667, 1.0, 2.0, 0.2686254392111365, 1.0, 2.0, 0.2686254392111365, 1.0, 1.0, 0.4394789058518467, 6.911200000000001, 6.9112, 121.94756008, 985188.6370351118, 985188.6370351113, 242989.2400630513], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7134000.0000, 
sim time next is 7134600.0000, 
raw observation next is [23.91666666666666, 60.83333333333333, 1.0, 2.0, 0.3971485617193417, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6555605778724504, 6.9112, 6.9112, 121.9260426156618, 979954.3219917046, 979954.3219917046, 219923.4066261146], 
processed observation next is [1.0, 0.5652173913043478, 0.4413580246913578, 0.6083333333333333, 1.0, 1.0, 0.28231971633254965, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.5694507223405629, 0.0, 0.0, 0.8094621288201359, 0.3499836864256088, 0.3499836864256088, 0.42292962812714346], 
reward next is 0.5771, 
noisyNet noise sample is [array([-0.63435787], dtype=float32), -0.2970611]. 
=============================================
[2019-03-24 02:06:46,231] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.8565496e-25 1.4620463e-15 3.3417066e-23 5.3509808e-16], sum to 1.0000
[2019-03-24 02:06:46,237] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0385
[2019-03-24 02:06:46,243] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 884801.3375077196 W.
[2019-03-24 02:06:46,248] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.1, 65.33333333333334, 1.0, 2.0, 0.240156351069554, 1.0, 1.0, 0.240156351069554, 1.0, 2.0, 0.3945835728333364, 6.911200000000001, 6.9112, 121.94756008, 884801.3375077196, 884801.3375077192, 232572.5568943052], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7144800.0000, 
sim time next is 7145400.0000, 
raw observation next is [23.05, 65.66666666666666, 1.0, 2.0, 0.3521994542383681, 1.0, 2.0, 0.3521994542383681, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 868512.1526959063, 868512.1526959068, 195991.0470488489], 
processed observation next is [1.0, 0.6956521739130435, 0.40925925925925927, 0.6566666666666666, 1.0, 1.0, 0.2288088740932954, 1.0, 1.0, 0.2288088740932954, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31018291167710943, 0.3101829116771096, 0.37690585970932483], 
reward next is 0.6231, 
noisyNet noise sample is [array([0.8307379], dtype=float32), 2.1452696]. 
=============================================
[2019-03-24 02:06:49,957] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.6890706e-23 7.9754632e-16 5.2547593e-22 1.8327689e-14], sum to 1.0000
[2019-03-24 02:06:49,962] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5785
[2019-03-24 02:06:49,967] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 986767.8494391622 W.
[2019-03-24 02:06:49,972] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 69.0, 1.0, 2.0, 0.4058398269721346, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6609321426739292, 6.911199999999999, 6.9112, 121.9260426156618, 986767.8494391622, 986767.8494391626, 223647.2891839557], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7221600.0000, 
sim time next is 7222200.0000, 
raw observation next is [24.0, 69.83333333333333, 1.0, 2.0, 0.3131464078646057, 1.0, 1.0, 0.3131464078646057, 1.0, 2.0, 0.5050627608716307, 6.9112, 6.9112, 121.94756008, 1125221.003177878, 1125221.003177878, 260637.6991797787], 
processed observation next is [1.0, 0.6086956521739131, 0.4444444444444444, 0.6983333333333333, 1.0, 1.0, 0.18231715221976866, 1.0, 0.5, 0.18231715221976866, 1.0, 1.0, 0.38132845108953833, 0.0, 0.0, 0.8096049824067558, 0.40186464399209926, 0.40186464399209926, 0.5012263445764975], 
reward next is 0.4988, 
noisyNet noise sample is [array([0.3815673], dtype=float32), 0.0039628902]. 
=============================================
[2019-03-24 02:06:54,385] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.4887571e-30 1.4626673e-20 6.3711350e-27 2.3305551e-17], sum to 1.0000
[2019-03-24 02:06:54,391] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0903
[2019-03-24 02:06:54,400] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1298429.993107518 W.
[2019-03-24 02:06:54,407] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.9, 61.0, 1.0, 2.0, 0.5523803956431271, 1.0, 1.0, 0.5523803956431271, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1298429.993107518, 1298429.993107519, 253846.6138136392], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7317000.0000, 
sim time next is 7317600.0000, 
raw observation next is [26.9, 61.0, 1.0, 2.0, 0.5510580960769587, 1.0, 2.0, 0.5510580960769587, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1294907.267461202, 1294907.267461203, 253391.7468376099], 
processed observation next is [1.0, 0.6956521739130435, 0.5518518518518518, 0.61, 1.0, 1.0, 0.46554535247256984, 1.0, 1.0, 0.46554535247256984, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4624668812361436, 0.46246688123614393, 0.48729182084155753], 
reward next is 0.5127, 
noisyNet noise sample is [array([-1.004529], dtype=float32), -1.9377946]. 
=============================================
[2019-03-24 02:07:00,917] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.7276362e-29 2.1488564e-20 4.6110838e-27 3.0363966e-16], sum to 1.0000
[2019-03-24 02:07:00,925] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4041
[2019-03-24 02:07:00,932] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.21666666666667, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6407205510433324, 6.911199999999999, 6.9112, 121.9260426156618, 477690.1770784192, 477690.1770784197, 136108.5502486559], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7423800.0000, 
sim time next is 7424400.0000, 
raw observation next is [20.23333333333333, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6442118059437248, 6.9112, 6.9112, 121.9260426156618, 480331.8068519392, 480331.8068519392, 136503.3146110308], 
processed observation next is [1.0, 0.9565217391304348, 0.3049382716049382, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.555264757429656, 0.0, 0.0, 0.8094621288201359, 0.17154707387569257, 0.17154707387569257, 0.2625063742519823], 
reward next is 0.7375, 
noisyNet noise sample is [array([-0.92486554], dtype=float32), -0.58314764]. 
=============================================
[2019-03-24 02:07:02,609] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.7256007e-28 1.1952896e-19 5.3095176e-25 5.0600266e-16], sum to 1.0000
[2019-03-24 02:07:02,614] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9887
[2019-03-24 02:07:02,621] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.8, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6263000557926075, 6.9112, 6.9112, 121.9260426156618, 467033.3135124873, 467033.3135124873, 134780.3479887031], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7455600.0000, 
sim time next is 7456200.0000, 
raw observation next is [19.88333333333333, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6285229781358403, 6.911200000000001, 6.9112, 121.9260426156618, 468789.9574950198, 468789.9574950194, 135120.6621468524], 
processed observation next is [0.0, 0.30434782608695654, 0.2919753086419752, 0.9366666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5356537226698004, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16742498481964993, 0.1674249848196498, 0.2598474272054854], 
reward next is 0.7402, 
noisyNet noise sample is [array([-0.1716531], dtype=float32), -0.66092426]. 
=============================================
[2019-03-24 02:07:05,500] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.1885514e-34 6.7846874e-24 3.4119760e-29 7.3259199e-19], sum to 1.0000
[2019-03-24 02:07:05,511] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5295
[2019-03-24 02:07:05,514] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.91666666666666, 89.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8029670991418815, 6.911200000000001, 6.9112, 121.9260426156618, 595606.1442749839, 595606.1442749834, 161073.7304010178], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7501800.0000, 
sim time next is 7502400.0000, 
raw observation next is [22.8, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8027103797014364, 6.911200000000001, 6.9112, 121.9260426156618, 595573.9374663914, 595573.9374663909, 160972.3275998288], 
processed observation next is [0.0, 0.8695652173913043, 0.4, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7533879746267954, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21270497766656835, 0.21270497766656818, 0.3095621684612092], 
reward next is 0.6904, 
noisyNet noise sample is [array([-0.28988865], dtype=float32), -1.3689749]. 
=============================================
[2019-03-24 02:07:08,046] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 5.5366280e-34 1.6659106e-23 2.0668241e-30 1.0324195e-17], sum to 1.0000
[2019-03-24 02:07:08,054] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3233
[2019-03-24 02:07:08,059] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.46666666666667, 76.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8534148086268817, 6.9112, 6.9112, 121.9260426156618, 628185.7329483355, 628185.7329483355, 169013.9716161751], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7558800.0000, 
sim time next is 7559400.0000, 
raw observation next is [25.73333333333333, 75.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8570783109860945, 6.9112, 6.9112, 121.9260426156618, 630402.6490595455, 630402.6490595455, 169607.1758235095], 
processed observation next is [0.0, 0.4782608695652174, 0.5086419753086419, 0.7533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8213478887326181, 0.0, 0.0, 0.8094621288201359, 0.22514380323555197, 0.22514380323555197, 0.3261676458144413], 
reward next is 0.6738, 
noisyNet noise sample is [array([-0.8296109], dtype=float32), -1.154084]. 
=============================================
[2019-03-24 02:07:09,591] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 7.8930673e-26 1.9378766e-18 1.0676174e-23 9.6619193e-15], sum to 1.0000
[2019-03-24 02:07:09,598] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2797
[2019-03-24 02:07:09,602] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.3, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8266781762475071, 6.911199999999999, 6.9112, 121.9260426156618, 611111.5139920479, 611111.5139920483, 164852.6164157286], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7581600.0000, 
sim time next is 7582200.0000, 
raw observation next is [26.13333333333333, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8267624914245801, 6.911200000000001, 6.9112, 121.9260426156618, 611102.6098314914, 611102.6098314909, 164887.1781415451], 
processed observation next is [0.0, 0.782608695652174, 0.5234567901234567, 0.7, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7834531142807252, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2182509320826755, 0.21825093208267532, 0.31709072719527903], 
reward next is 0.6829, 
noisyNet noise sample is [array([0.48357004], dtype=float32), 0.37434694]. 
=============================================
[2019-03-24 02:07:09,689] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.5436667e-33 8.1230932e-23 1.6923067e-30 3.6466652e-20], sum to 1.0000
[2019-03-24 02:07:09,697] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5893
[2019-03-24 02:07:09,704] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.3, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8159998955025508, 6.9112, 6.9112, 121.9260426156618, 604229.4878441992, 604229.4878441992, 163136.4181643959], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7578000.0000, 
sim time next is 7578600.0000, 
raw observation next is [27.13333333333333, 63.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8145747101356187, 6.911199999999999, 6.9112, 121.9260426156618, 603236.615391143, 603236.6153911435, 162931.696875512], 
processed observation next is [0.0, 0.7391304347826086, 0.5604938271604937, 0.6316666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7682183876695233, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21544164835397964, 0.2154416483539798, 0.3133301862990615], 
reward next is 0.6867, 
noisyNet noise sample is [array([-1.0859178], dtype=float32), -0.8864703]. 
=============================================
[2019-03-24 02:07:14,489] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 6.8249835e-29 1.1107253e-18 3.0237951e-25 3.9757530e-16], sum to 1.0000
[2019-03-24 02:07:14,496] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5726
[2019-03-24 02:07:14,500] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.65, 67.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6457779472124067, 6.911200000000001, 6.9112, 121.9260426156618, 482165.9172607036, 482165.9172607032, 137589.8842582598], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7666200.0000, 
sim time next is 7666800.0000, 
raw observation next is [23.4, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6429487469690739, 6.9112, 6.9112, 121.9260426156618, 479789.714425238, 479789.714425238, 136883.1266766379], 
processed observation next is [1.0, 0.7391304347826086, 0.42222222222222217, 0.68, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5536859337113423, 0.0, 0.0, 0.8094621288201359, 0.171353469437585, 0.171353469437585, 0.26323678207045753], 
reward next is 0.7368, 
noisyNet noise sample is [array([0.48399746], dtype=float32), -0.8710676]. 
=============================================
[2019-03-24 02:07:20,325] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.5632100e-33 1.1154819e-24 1.7086608e-29 1.7441712e-20], sum to 1.0000
[2019-03-24 02:07:20,332] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4272
[2019-03-24 02:07:20,335] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.670469500102278, 6.911199999999999, 6.9112, 121.9260426156618, 500729.4896970252, 500729.4896970257, 140383.0492987827], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7761600.0000, 
sim time next is 7762200.0000, 
raw observation next is [23.86666666666667, 66.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6676879149630595, 6.911200000000001, 6.9112, 121.9260426156618, 498545.5111330266, 498545.5111330262, 139884.1674932623], 
processed observation next is [1.0, 0.8695652173913043, 0.4395061728395063, 0.665, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5846098937038243, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17805196826179523, 0.1780519682617951, 0.2690080144101198], 
reward next is 0.7310, 
noisyNet noise sample is [array([-0.7852986], dtype=float32), -1.387743]. 
=============================================
[2019-03-24 02:07:29,562] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:07:29,563] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:29,575] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run3
[2019-03-24 02:07:29,633] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.3841049e-31 1.8925785e-21 4.5717109e-27 1.2297739e-20], sum to 1.0000
[2019-03-24 02:07:29,635] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3365
[2019-03-24 02:07:29,638] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.45, 55.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8063079225526917, 6.911199999999999, 6.9112, 121.9260426156618, 597734.3183553825, 597734.318355383, 161640.6290588141], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7929000.0000, 
sim time next is 7929600.0000, 
raw observation next is [28.23333333333333, 56.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8039168268056831, 6.9112, 6.9112, 121.9260426156618, 596180.8265209994, 596180.8265209994, 161248.4183858368], 
processed observation next is [1.0, 0.782608695652174, 0.6012345679012344, 0.5633333333333332, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7548960335071039, 0.0, 0.0, 0.8094621288201359, 0.2129217237574998, 0.2129217237574998, 0.3100931122804554], 
reward next is 0.6899, 
noisyNet noise sample is [array([-0.8305347], dtype=float32), 1.0568243]. 
=============================================
[2019-03-24 02:07:29,956] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:07:29,956] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:29,958] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run3
[2019-03-24 02:07:30,050] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:07:30,050] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:30,052] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run3
[2019-03-24 02:07:30,164] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:07:30,165] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:30,166] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run3
[2019-03-24 02:07:30,292] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:07:30,292] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:30,294] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run3
[2019-03-24 02:07:30,315] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:07:30,315] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:07:30,316] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:30,318] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run3
[2019-03-24 02:07:30,316] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:30,337] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:07:30,338] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:30,341] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run3
[2019-03-24 02:07:30,363] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:07:30,364] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:30,366] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run3
[2019-03-24 02:07:30,392] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run3
[2019-03-24 02:07:30,419] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:07:30,420] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:30,422] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run3
[2019-03-24 02:07:30,529] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:07:30,529] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:30,530] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run3
[2019-03-24 02:07:30,652] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:07:30,653] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:30,654] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run3
[2019-03-24 02:07:30,735] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:07:30,736] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:30,737] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run3
[2019-03-24 02:07:30,797] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:07:30,797] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:30,798] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run3
[2019-03-24 02:07:30,961] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:07:30,962] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:30,964] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run3
[2019-03-24 02:07:31,123] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:07:31,124] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:31,125] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run3
[2019-03-24 02:07:33,965] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 02:07:33,967] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:07:33,969] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:07:33,971] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:33,972] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:33,974] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:07:33,974] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:07:33,975] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:07:33,977] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:33,976] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:33,979] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:07:33,995] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run18
[2019-03-24 02:07:33,995] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run18
[2019-03-24 02:07:34,017] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run18
[2019-03-24 02:07:34,017] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run18
[2019-03-24 02:07:34,037] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run18
[2019-03-24 02:07:35,687] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.15779728]
[2019-03-24 02:07:35,689] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.43554294166667, 47.60089894166666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8796049072065368, 6.9112, 6.9112, 121.9260426156618, 654013.6394023916, 654013.6394023916, 160715.7160754316]
[2019-03-24 02:07:35,690] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:07:35,691] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 6.9102306e-29 1.1674169e-21 4.5876286e-26 1.5780268e-18], sampled 0.43415717313795377
[2019-03-24 02:07:35,700] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.15779728]
[2019-03-24 02:07:35,703] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.63792468, 46.74522337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8240007394570026, 6.9112, 6.9112, 121.9260426156618, 612722.0432919057, 612722.0432919057, 154468.4456823581]
[2019-03-24 02:07:35,704] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:07:35,706] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.6040126e-29 7.1871454e-22 2.5501097e-26 1.0448239e-18], sampled 0.5409046678911632
[2019-03-24 02:07:38,498] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.15779728]
[2019-03-24 02:07:38,501] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.23333333333333, 51.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3784893093942535, 6.9112, 6.9112, 121.9260426156618, 270229.7477947038, 270229.7477947038, 81639.94804139329]
[2019-03-24 02:07:38,501] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:07:38,506] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.0563959e-30 8.4701384e-23 1.9231834e-27 1.6865547e-19], sampled 0.3495324458632446
[2019-03-24 02:08:50,610] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.15779728]
[2019-03-24 02:08:50,610] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.35962810333334, 91.00698519500001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7694251987244612, 6.911200000000001, 6.9112, 121.9260426156618, 572344.9925725262, 572344.9925725257, 156114.5016060094]
[2019-03-24 02:08:50,611] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:08:50,612] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.6425265e-31 2.8020128e-23 5.0325257e-28 6.6381102e-20], sampled 0.3588597771664196
[2019-03-24 02:09:13,263] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.15779728]
[2019-03-24 02:09:13,265] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.90395520333334, 62.72363357333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6954456638590131, 6.9112, 6.9112, 121.9260426156618, 519665.6829860123, 519665.6829860123, 143895.0564899294]
[2019-03-24 02:09:13,266] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:09:13,268] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.5174073e-31 1.2135314e-23 1.8309738e-28 3.2396768e-20], sampled 0.9845884053017792
[2019-03-24 02:09:14,000] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 02:09:14,073] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 02:09:14,170] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 02:09:14,388] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 02:09:14,762] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 02:09:15,778] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 425000, evaluation results [425000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 02:09:32,900] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 5.3102386e-28 2.0487231e-22 1.9450814e-27 4.8204819e-19], sum to 1.0000
[2019-03-24 02:09:32,905] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4513
[2019-03-24 02:09:32,909] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 52.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4790274935076211, 6.9112, 6.9112, 121.9260426156618, 342026.9300575697, 342026.9300575697, 105663.0207075554], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 350400.0000, 
sim time next is 351000.0000, 
raw observation next is [21.35, 52.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4759382299265255, 6.9112, 6.9112, 121.9260426156618, 339820.6988103485, 339820.6988103485, 104910.8122018104], 
processed observation next is [1.0, 0.043478260869565216, 0.3462962962962963, 0.525, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.34492278740815685, 0.0, 0.0, 0.8094621288201359, 0.12136453528941019, 0.12136453528941019, 0.20175156192655846], 
reward next is 0.7982, 
noisyNet noise sample is [array([-0.9548808], dtype=float32), -0.55075425]. 
=============================================
[2019-03-24 02:09:32,932] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[61.8444  ]
 [62.03667 ]
 [62.244633]
 [62.0456  ]
 [62.252293]], R is [[62.04202271]
 [62.21840668]
 [62.39167786]
 [62.56185913]
 [62.72889709]].
[2019-03-24 02:09:38,334] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 6.4686557e-26 7.7400414e-20 1.5321065e-22 5.6655503e-18], sum to 1.0000
[2019-03-24 02:09:38,343] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9018
[2019-03-24 02:09:38,349] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.8, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4656291731659757, 6.911200000000001, 6.9112, 121.9260426156618, 332458.419523585, 332458.4195235845, 109900.0407596844], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 451800.0000, 
sim time next is 452400.0000, 
raw observation next is [19.1, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4683543106024143, 6.911200000000001, 6.9112, 121.9260426156618, 334404.5871047127, 334404.5871047123, 111326.6574379937], 
processed observation next is [1.0, 0.21739130434782608, 0.262962962962963, 0.72, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3354428882530178, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11943020968025453, 0.1194302096802544, 0.21408972584229558], 
reward next is 0.7859, 
noisyNet noise sample is [array([1.535407], dtype=float32), -0.32361045]. 
=============================================
[2019-03-24 02:09:43,829] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.1452258e-22 2.3501975e-16 1.6225193e-19 1.3010215e-14], sum to 1.0000
[2019-03-24 02:09:43,835] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2641
[2019-03-24 02:09:43,841] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1148665.349318942 W.
[2019-03-24 02:09:43,844] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 40.0, 1.0, 2.0, 0.4724943401230746, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7693341183103969, 6.9112, 6.9112, 121.9259924973456, 1148665.349318942, 1148665.349318942, 245110.1821057676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 564600.0000, 
sim time next is 565200.0000, 
raw observation next is [29.8, 39.0, 1.0, 2.0, 0.8512430328471776, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426003795, 1044220.209114005, 1044220.209114005, 209988.0439127465], 
processed observation next is [1.0, 0.5652173913043478, 0.6592592592592593, 0.39, 1.0, 1.0, 0.8229083724371162, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621287186774, 0.3729357889692875, 0.3729357889692875, 0.4038231613706664], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3092818], dtype=float32), 0.5788673]. 
=============================================
[2019-03-24 02:09:46,309] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.3885394e-27 2.0645898e-19 3.2080031e-24 4.5496568e-17], sum to 1.0000
[2019-03-24 02:09:46,315] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8026
[2019-03-24 02:09:46,318] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.2, 40.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6198790188814112, 6.911200000000001, 6.9112, 121.9260426156618, 461282.6686672783, 461282.6686672778, 133185.1180102854], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 594600.0000, 
sim time next is 595200.0000, 
raw observation next is [28.0, 41.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6186133193386587, 6.9112, 6.9112, 121.9260426156618, 460152.2128305487, 460152.2128305487, 132901.9603576824], 
processed observation next is [1.0, 0.9130434782608695, 0.5925925925925926, 0.41, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5232666491733233, 0.0, 0.0, 0.8094621288201359, 0.16434007601091025, 0.16434007601091025, 0.2555806929955431], 
reward next is 0.7444, 
noisyNet noise sample is [array([0.36783546], dtype=float32), -0.44977313]. 
=============================================
[2019-03-24 02:09:52,976] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.9423449e-18 1.0967456e-13 5.5158686e-17 1.3108775e-11], sum to 1.0000
[2019-03-24 02:09:52,989] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8934
[2019-03-24 02:09:52,995] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1307594.690251643 W.
[2019-03-24 02:09:53,000] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.63333333333333, 52.33333333333333, 1.0, 2.0, 0.5377893404873688, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8756794122915215, 6.911199999999999, 6.9112, 121.9260426156618, 1307594.690251643, 1307594.690251643, 267843.3896343713], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 729600.0000, 
sim time next is 730200.0000, 
raw observation next is [26.76666666666667, 52.16666666666667, 1.0, 2.0, 0.3702011006220075, 1.0, 1.0, 0.3702011006220075, 1.0, 2.0, 0.5968824933187794, 6.9112, 6.9112, 121.94756008, 1329563.701098999, 1329563.701098999, 283862.067288741], 
processed observation next is [1.0, 0.43478260869565216, 0.5469135802469137, 0.5216666666666667, 1.0, 1.0, 0.2502394055023899, 1.0, 0.5, 0.2502394055023899, 1.0, 1.0, 0.49610311664847423, 0.0, 0.0, 0.8096049824067558, 0.4748441789639282, 0.4748441789639282, 0.5458885909398865], 
reward next is 0.4541, 
noisyNet noise sample is [array([-1.099151], dtype=float32), 1.1355066]. 
=============================================
[2019-03-24 02:09:54,555] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.00000000e+00 1.67355880e-25 1.13651961e-17 1.01084277e-22
 4.42797008e-16], sum to 1.0000
[2019-03-24 02:09:54,564] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0136
[2019-03-24 02:09:54,575] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1258020.291111987 W.
[2019-03-24 02:09:54,583] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.06666666666667, 23.33333333333334, 1.0, 2.0, 0.5080522820996313, 1.0, 2.0, 0.5080522820996313, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156288, 1258020.291111987, 1258020.291111988, 241648.7975430845], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 746400.0000, 
sim time next is 747000.0000, 
raw observation next is [32.05, 23.5, 1.0, 2.0, 0.3423696899795401, 1.0, 2.0, 0.3423696899795401, 1.0, 1.0, 0.5633135489806365, 6.9112, 6.9112, 121.94756008, 1263487.509055195, 1263487.509055195, 271132.9022634174], 
processed observation next is [1.0, 0.6521739130434783, 0.7425925925925925, 0.235, 1.0, 1.0, 0.21710677378516677, 1.0, 1.0, 0.21710677378516677, 1.0, 0.5, 0.4541419362257955, 0.0, 0.0, 0.8096049824067558, 0.4512455389482839, 0.4512455389482839, 0.5214094274296488], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7883826], dtype=float32), 0.19475004]. 
=============================================
[2019-03-24 02:09:54,597] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[63.250805]
 [63.0656  ]
 [62.317905]
 [62.30083 ]
 [62.25078 ]], R is [[63.70048523]
 [63.59877014]
 [63.44789886]
 [62.81341934]
 [62.18528748]].
[2019-03-24 02:09:54,703] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.00000000e+00 1.22717676e-29 1.42166720e-21 4.16040360e-25
 2.13818893e-17], sum to 1.0000
[2019-03-24 02:09:54,709] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1789
[2019-03-24 02:09:54,712] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.66666666666667, 24.33333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6207036333964354, 6.9112, 6.9112, 121.9260426156618, 459561.2884511715, 459561.2884511715, 131592.3759022361], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 753600.0000, 
sim time next is 754200.0000, 
raw observation next is [31.55, 24.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6089915532731921, 6.9112, 6.9112, 121.9260426156618, 448808.3910108642, 448808.3910108642, 129315.6498349564], 
processed observation next is [1.0, 0.7391304347826086, 0.7240740740740741, 0.245, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.51123944159149, 0.0, 0.0, 0.8094621288201359, 0.16028871107530862, 0.16028871107530862, 0.24868394199030078], 
reward next is 0.7513, 
noisyNet noise sample is [array([-0.9476813], dtype=float32), -0.66198254]. 
=============================================
[2019-03-24 02:10:06,249] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 02:10:06,252] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:10:06,255] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:10:06,256] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:10:06,257] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:10:06,257] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:10:06,257] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:10:06,258] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:10:06,258] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:10:06,258] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:10:06,259] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:10:06,273] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run19
[2019-03-24 02:10:06,296] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run19
[2019-03-24 02:10:06,323] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run19
[2019-03-24 02:10:06,343] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run19
[2019-03-24 02:10:06,363] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run19
[2019-03-24 02:10:27,904] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.16693133]
[2019-03-24 02:10:27,905] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.33333333333333, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5752301351486322, 6.9112, 6.9112, 121.9260426156618, 424056.5147389828, 424056.5147389828, 126320.9619742155]
[2019-03-24 02:10:27,906] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:10:27,908] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 8.5840941e-28 6.1906135e-19 7.4234582e-25 3.4119969e-17], sampled 0.7727573670599462
[2019-03-24 02:10:33,137] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.16693133]
[2019-03-24 02:10:33,139] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.03500065, 94.85661306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7795509142467156, 6.9112, 6.9112, 121.9260426156618, 579524.8097044457, 579524.8097044457, 157543.4499910974]
[2019-03-24 02:10:33,140] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:10:33,143] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 9.0470944e-27 3.0371814e-18 6.0873718e-24 1.4360770e-16], sampled 0.3760064036122206
[2019-03-24 02:10:53,489] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.16693133]
[2019-03-24 02:10:53,491] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.49461505333333, 80.66739470666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.840223550989654, 6.9112, 6.9112, 121.9260426156618, 621004.4975656864, 621004.4975656864, 166585.1161285899]
[2019-03-24 02:10:53,492] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:10:53,497] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.3757046e-28 3.9287238e-19 4.0591321e-25 2.2618521e-17], sampled 0.16461989765195362
[2019-03-24 02:10:56,395] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.16693133]
[2019-03-24 02:10:56,398] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.42257849166667, 95.01192181333333, 1.0, 1.0, 0.6450337998744863, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260116743592, 735126.0184552135, 735126.0184552135, 166001.7933850461]
[2019-03-24 02:10:56,398] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:10:56,402] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 7.8064433e-25 6.1849075e-17 3.2886579e-22 2.1980173e-15], sampled 0.23720145716997454
[2019-03-24 02:10:56,405] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 735126.0184552135 W.
[2019-03-24 02:10:57,496] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.16693133]
[2019-03-24 02:10:57,499] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.66666666666666, 66.33333333333333, 1.0, 2.0, 0.9289814655725658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1058956.381145899, 1058956.381145899, 224047.9794096779]
[2019-03-24 02:10:57,501] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:10:57,504] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.1109237e-27 7.7764480e-19 9.6140372e-25 4.5670627e-17], sampled 0.38128293768007016
[2019-03-24 02:10:57,505] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1058956.381145899 W.
[2019-03-24 02:11:17,657] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.16693133]
[2019-03-24 02:11:17,658] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.5, 95.0, 1.0, 2.0, 0.7144998894175615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 814336.5284871071, 814336.5284871071, 178907.2748901765]
[2019-03-24 02:11:17,658] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:11:17,661] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.5583573e-26 4.6436021e-18 1.0216464e-23 2.2999274e-16], sampled 0.5578027466927185
[2019-03-24 02:11:17,662] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 814336.5284871071 W.
[2019-03-24 02:11:20,445] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.16693133]
[2019-03-24 02:11:20,447] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.83333333333333, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8489815590650321, 6.9112, 6.9112, 121.9260426156618, 626151.6663148389, 626151.6663148389, 168105.0133717054]
[2019-03-24 02:11:20,447] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:11:20,451] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 6.8818195e-29 1.1261393e-19 7.7694818e-26 7.2999235e-18], sampled 0.8816140090307371
[2019-03-24 02:11:45,522] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8559.5091 2258259887.1738 536.0000
[2019-03-24 02:11:45,996] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 02:11:46,063] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 02:11:46,191] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 02:11:46,302] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 02:11:47,319] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 450000, evaluation results [450000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8559.509129880978, 2258259887.1737776, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 02:11:49,658] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.1941313e-29 1.4871874e-19 9.1655491e-27 6.2258559e-18], sum to 1.0000
[2019-03-24 02:11:49,664] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7111
[2019-03-24 02:11:49,670] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.3, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5232388268212232, 6.9112, 6.9112, 121.9260426156618, 380953.050154114, 380953.050154114, 119574.5291648363], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1044000.0000, 
sim time next is 1044600.0000, 
raw observation next is [21.23333333333333, 65.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8137767500359171, 6.9112, 6.9112, 121.9260426156618, 592773.0574587536, 592773.0574587536, 146780.7677328203], 
processed observation next is [1.0, 0.08695652173913043, 0.34197530864197523, 0.655, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7672209375448963, 0.0, 0.0, 0.8094621288201359, 0.21170466337812627, 0.21170466337812627, 0.28227070717850056], 
reward next is 0.7177, 
noisyNet noise sample is [array([0.25109667], dtype=float32), 1.6007701]. 
=============================================
[2019-03-24 02:11:51,385] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 9.0227574e-28 1.6666404e-17 7.7622948e-23 1.2187787e-15], sum to 1.0000
[2019-03-24 02:11:51,395] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9577
[2019-03-24 02:11:51,398] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.7, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5889131857244206, 6.9112, 6.9112, 121.9260426156618, 431469.4925148584, 431469.4925148584, 126255.0752644626], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1065600.0000, 
sim time next is 1066200.0000, 
raw observation next is [22.78333333333333, 58.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5856216038717675, 6.9112, 6.9112, 121.9260426156618, 429090.1035940216, 429090.1035940216, 125978.4752892014], 
processed observation next is [1.0, 0.34782608695652173, 0.39938271604938264, 0.585, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4820270048397094, 0.0, 0.0, 0.8094621288201359, 0.15324646556929342, 0.15324646556929342, 0.2422662986330796], 
reward next is 0.7577, 
noisyNet noise sample is [array([-1.3226031], dtype=float32), 0.22079036]. 
=============================================
[2019-03-24 02:11:52,058] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 8.9321543e-18 2.2314095e-11 3.0875223e-15 1.6907366e-10], sum to 1.0000
[2019-03-24 02:11:52,064] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3505
[2019-03-24 02:11:52,070] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 814522.8135530518 W.
[2019-03-24 02:11:52,075] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.8, 54.0, 1.0, 2.0, 0.6451275290160522, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 814522.8135530518, 814522.8135530518, 168772.959853414], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1072800.0000, 
sim time next is 1073400.0000, 
raw observation next is [23.88333333333334, 53.5, 1.0, 2.0, 0.4139384900846098, 1.0, 1.0, 0.4139384900846098, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1036889.659301772, 1036889.659301772, 213343.6528672699], 
processed observation next is [1.0, 0.43478260869565216, 0.4401234567901237, 0.535, 1.0, 1.0, 0.3023077262912021, 1.0, 0.5, 0.3023077262912021, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3703177354649186, 0.3703177354649186, 0.4102762555139806], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.60296077], dtype=float32), 0.50441134]. 
=============================================
[2019-03-24 02:11:53,079] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.00000000e+00 1.00022305e-19 3.33351337e-12 2.07123395e-17
 7.31494726e-11], sum to 1.0000
[2019-03-24 02:11:53,086] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4646
[2019-03-24 02:11:53,094] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 818695.0228334551 W.
[2019-03-24 02:11:53,104] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 48.33333333333334, 1.0, 2.0, 0.3259349242166022, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5510808836424941, 6.911199999999999, 6.9112, 121.9260426156618, 818695.0228334551, 818695.0228334556, 197706.59077313], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1078800.0000, 
sim time next is 1079400.0000, 
raw observation next is [25.05, 47.66666666666667, 1.0, 2.0, 0.6459206098430902, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816570.7232191359, 816570.7232191359, 168932.8910253621], 
processed observation next is [1.0, 0.4782608695652174, 0.48333333333333334, 0.47666666666666674, 1.0, 1.0, 0.5784769164798692, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2916324011496914, 0.2916324011496914, 0.3248709442795425], 
reward next is 0.6751, 
noisyNet noise sample is [array([1.318861], dtype=float32), -1.5922896]. 
=============================================
[2019-03-24 02:11:55,993] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 7.1024303e-24 1.2810459e-15 7.3004142e-21 5.2711430e-14], sum to 1.0000
[2019-03-24 02:11:56,002] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7168
[2019-03-24 02:11:56,010] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.4, 72.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5090089601822156, 6.9112, 6.9112, 121.9260426156618, 365379.4659833665, 365379.4659833665, 116461.3202733516], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1146600.0000, 
sim time next is 1147200.0000, 
raw observation next is [19.46666666666667, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5166161876229902, 6.9112, 6.9112, 121.9260426156618, 370835.3130206997, 370835.3130206997, 117050.358070373], 
processed observation next is [1.0, 0.2608695652173913, 0.2765432098765433, 0.72, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3957702345287377, 0.0, 0.0, 0.8094621288201359, 0.13244118322167847, 0.13244118322167847, 0.225096842443025], 
reward next is 0.7749, 
noisyNet noise sample is [array([-0.53587437], dtype=float32), 0.9503685]. 
=============================================
[2019-03-24 02:11:56,472] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.3678578e-26 1.1873340e-16 5.6335078e-24 3.5219342e-15], sum to 1.0000
[2019-03-24 02:11:56,483] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9068
[2019-03-24 02:11:56,490] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.01666666666667, 68.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5461901580742362, 6.9112, 6.9112, 121.9260426156618, 392517.6437145423, 392517.6437145423, 119544.7360597775], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1151400.0000, 
sim time next is 1152000.0000, 
raw observation next is [20.1, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5400828572285145, 6.9112, 6.9112, 121.9260426156618, 388218.5580073925, 388218.5580073925, 119086.1861654661], 
processed observation next is [1.0, 0.34782608695652173, 0.30000000000000004, 0.68, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.42510357153564304, 0.0, 0.0, 0.8094621288201359, 0.13864948500264018, 0.13864948500264018, 0.2290118964720502], 
reward next is 0.7710, 
noisyNet noise sample is [array([0.4602325], dtype=float32), -0.9620657]. 
=============================================
[2019-03-24 02:11:56,505] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[66.37563]
 [66.40599]
 [66.45312]
 [66.48573]
 [66.47239]], R is [[66.45619965]
 [66.56174469]
 [66.66760254]
 [66.77601624]
 [66.88246155]].
[2019-03-24 02:12:02,323] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.7073537e-26 3.4486086e-14 2.5370933e-22 4.4796184e-16], sum to 1.0000
[2019-03-24 02:12:02,340] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4283
[2019-03-24 02:12:02,351] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1104789.98381332 W.
[2019-03-24 02:12:02,355] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.63333333333333, 59.0, 1.0, 2.0, 0.3071383543796098, 1.0, 2.0, 0.3071383543796098, 1.0, 2.0, 0.4956576735498243, 6.9112, 6.9112, 121.94756008, 1104789.98381332, 1104789.98381332, 258268.4096128089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1258800.0000, 
sim time next is 1259400.0000, 
raw observation next is [25.81666666666667, 58.5, 1.0, 2.0, 0.9291581736432799, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.109316285819938, 6.9112, 121.9252009344839, 1234954.3845438, 1133501.839124443, 227503.5482125646], 
processed observation next is [1.0, 0.5652173913043478, 0.5117283950617285, 0.585, 1.0, 1.0, 0.915664492432476, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.019811628581993812, 0.0, 0.8094565409324014, 0.4410551373370714, 0.40482208540158676, 0.4375068234857012], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.3394248], dtype=float32), 1.2800473]. 
=============================================
[2019-03-24 02:12:04,296] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 5.5981518e-27 4.1388944e-16 5.6922274e-22 1.0446940e-15], sum to 1.0000
[2019-03-24 02:12:04,303] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3616
[2019-03-24 02:12:04,309] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.76666666666667, 89.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5582411563446891, 6.9112, 6.9112, 121.9260426156618, 410818.2176039992, 410818.2176039992, 124445.2413476227], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1309800.0000, 
sim time next is 1310400.0000, 
raw observation next is [18.7, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5566357585707368, 6.9112, 6.9112, 121.9260426156618, 409490.358684371, 409490.358684371, 124231.543184707], 
processed observation next is [1.0, 0.17391304347826086, 0.24814814814814812, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44579469821342094, 0.0, 0.0, 0.8094621288201359, 0.14624655667298964, 0.14624655667298964, 0.23890681381674422], 
reward next is 0.7611, 
noisyNet noise sample is [array([-1.0280801], dtype=float32), 0.5751455]. 
=============================================
[2019-03-24 02:12:07,429] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.7031775e-26 3.6930679e-15 1.2622051e-23 5.1344194e-16], sum to 1.0000
[2019-03-24 02:12:07,436] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4790
[2019-03-24 02:12:07,441] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.75, 33.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5978028942736497, 6.911199999999999, 6.9112, 121.9260426156618, 443389.2796941163, 443389.2796941168, 129947.3577652453], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1360200.0000, 
sim time next is 1360800.0000, 
raw observation next is [29.5, 34.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5969596225089957, 6.9112, 6.9112, 121.9260426156618, 442883.4246774931, 442883.4246774931, 129949.8199204922], 
processed observation next is [1.0, 0.782608695652174, 0.6481481481481481, 0.34, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.49619952813624457, 0.0, 0.0, 0.8094621288201359, 0.15817265167053327, 0.15817265167053327, 0.2499034998471004], 
reward next is 0.7501, 
noisyNet noise sample is [array([-0.3733787], dtype=float32), 0.2773914]. 
=============================================
[2019-03-24 02:12:09,878] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.6729787e-28 6.7784482e-18 2.8251609e-25 5.5841701e-16], sum to 1.0000
[2019-03-24 02:12:09,884] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0687
[2019-03-24 02:12:09,888] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.8, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5051826558162543, 6.9112, 6.9112, 121.9260426156618, 363959.7611884105, 363959.7611884105, 116634.9898811867], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1395000.0000, 
sim time next is 1395600.0000, 
raw observation next is [20.76666666666667, 63.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5008517681877197, 6.9112, 6.9112, 121.9260426156618, 360282.7635492733, 360282.7635492733, 116099.3375622786], 
processed observation next is [0.0, 0.13043478260869565, 0.32469135802469146, 0.6366666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3760647102346496, 0.0, 0.0, 0.8094621288201359, 0.1286724155533119, 0.1286724155533119, 0.22326795685053577], 
reward next is 0.7767, 
noisyNet noise sample is [array([1.4611919], dtype=float32), 2.4966958]. 
=============================================
[2019-03-24 02:12:11,635] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.1229012e-32 8.6522518e-19 4.7674428e-29 3.0739322e-18], sum to 1.0000
[2019-03-24 02:12:11,643] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6258
[2019-03-24 02:12:11,646] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.6, 22.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6541321068079433, 6.9112, 6.9112, 121.9260426156618, 485543.6507286868, 485543.6507286868, 135617.2176192739], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1431600.0000, 
sim time next is 1432200.0000, 
raw observation next is [33.75, 21.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.656544477163326, 6.9112, 6.9112, 121.9260426156618, 487186.3921748362, 487186.3921748362, 135753.1127820835], 
processed observation next is [0.0, 0.5652173913043478, 0.8055555555555556, 0.215, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5706805964541575, 0.0, 0.0, 0.8094621288201359, 0.1739951400624415, 0.1739951400624415, 0.26106367842708367], 
reward next is 0.7389, 
noisyNet noise sample is [array([0.964847], dtype=float32), -1.03545]. 
=============================================
[2019-03-24 02:12:27,419] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 6.9059492e-25 3.5550320e-11 1.3397367e-22 2.0739224e-13], sum to 1.0000
[2019-03-24 02:12:27,434] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8142
[2019-03-24 02:12:27,442] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.7, 70.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6673351762184977, 6.911199999999999, 6.9112, 121.9260426156618, 498661.6125180126, 498661.612518013, 140933.1974858324], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1705200.0000, 
sim time next is 1705800.0000, 
raw observation next is [23.65, 71.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.673410271872012, 6.911200000000001, 6.9112, 121.9260426156618, 503216.7171282184, 503216.7171282179, 141698.4132505542], 
processed observation next is [1.0, 0.7391304347826086, 0.4314814814814814, 0.7133333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5917628398400149, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17972025611722084, 0.17972025611722067, 0.2724969485587581], 
reward next is 0.7275, 
noisyNet noise sample is [array([-0.14658572], dtype=float32), 0.74811226]. 
=============================================
[2019-03-24 02:12:30,030] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9999976e-01 7.7802815e-17 1.8962537e-07 6.9054785e-16 2.9501591e-08], sum to 1.0000
[2019-03-24 02:12:30,036] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8955
[2019-03-24 02:12:30,042] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1115083.756712416 W.
[2019-03-24 02:12:30,048] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.11666666666667, 69.66666666666667, 1.0, 2.0, 0.4626568396507881, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7488414687357913, 6.911199999999998, 6.9112, 121.9260426156618, 1115083.756712416, 1115083.756712417, 242367.0698304716], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1764600.0000, 
sim time next is 1765200.0000, 
raw observation next is [24.23333333333333, 69.33333333333334, 1.0, 2.0, 0.4261424303205537, 1.0, 1.0, 0.4261424303205537, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1025208.060688138, 1025208.060688138, 215745.9517830069], 
processed observation next is [1.0, 0.43478260869565216, 0.45308641975308633, 0.6933333333333335, 1.0, 1.0, 0.31683622657208776, 1.0, 0.5, 0.31683622657208776, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3661457359600493, 0.3661457359600493, 0.4148960611211671], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5210945], dtype=float32), -0.77904004]. 
=============================================
[2019-03-24 02:12:30,575] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 6.9727274e-20 3.8460460e-08 2.8970928e-18 1.2074924e-10], sum to 1.0000
[2019-03-24 02:12:30,585] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8268
[2019-03-24 02:12:30,590] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.9, 74.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6325606271076676, 6.911200000000001, 6.9112, 121.9260426156618, 471069.5523858909, 471069.5523858904, 134741.0936708681], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1795200.0000, 
sim time next is 1795800.0000, 
raw observation next is [21.45, 75.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6189541976691132, 6.911200000000001, 6.9112, 121.9260426156618, 460102.5978409006, 460102.5978409002, 132690.155053795], 
processed observation next is [1.0, 0.782608695652174, 0.35, 0.7583333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5236927470863915, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16432235637175022, 0.16432235637175008, 0.2551733751034519], 
reward next is 0.7448, 
noisyNet noise sample is [array([-0.2639952], dtype=float32), -0.30276224]. 
=============================================
[2019-03-24 02:12:37,956] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 02:12:37,958] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:12:37,959] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:12:37,965] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:12:37,966] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:12:37,966] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:12:37,966] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:12:37,966] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:12:37,967] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:12:37,968] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:12:37,970] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:12:37,987] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run20
[2019-03-24 02:12:38,011] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run20
[2019-03-24 02:12:38,037] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run20
[2019-03-24 02:12:38,059] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run20
[2019-03-24 02:12:38,084] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run20
[2019-03-24 02:12:52,498] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.17193648]
[2019-03-24 02:12:52,499] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.6, 26.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5766829655891301, 6.9112, 6.9112, 121.9260426156618, 411771.9211094152, 411771.9211094152, 110362.0091612617]
[2019-03-24 02:12:52,501] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:12:52,505] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 8.4513302e-21 5.8051297e-10 1.6214497e-18 5.7577185e-12], sampled 0.8562426387815515
[2019-03-24 02:13:25,976] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.17193648]
[2019-03-24 02:13:25,977] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.72043617333333, 55.36742733, 1.0, 2.0, 0.98951675927174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.314538486131332, 6.9112, 121.9242607219687, 1378123.680358006, 1171581.344040427, 240487.4131210901]
[2019-03-24 02:13:25,978] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:13:25,982] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 8.9294014e-24 2.6105290e-11 3.7977635e-21 1.4968106e-13], sampled 0.23183214952072262
[2019-03-24 02:13:25,985] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1378123.680358006 W.
[2019-03-24 02:13:34,290] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.17193648]
[2019-03-24 02:13:34,291] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.09605543333333, 95.34662686666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6207027342251972, 6.911200000000001, 6.9112, 121.9260426156618, 461964.6370227578, 461964.6370227574, 133325.4913182034]
[2019-03-24 02:13:34,292] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:13:34,296] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.2101303e-21 2.3678604e-10 2.8846409e-19 1.9420750e-12], sampled 0.5118739910202144
[2019-03-24 02:13:42,356] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.17193648]
[2019-03-24 02:13:42,357] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.41666666666667, 96.66666666666666, 1.0, 2.0, 0.6015323530118108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 697899.7788070549, 697899.7788070549, 158934.2712014076]
[2019-03-24 02:13:42,358] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:13:42,362] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.4233617e-19 2.2054738e-09 2.0240028e-17 3.0349917e-11], sampled 0.6281862863181317
[2019-03-24 02:13:42,363] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 697899.7788070549 W.
[2019-03-24 02:14:17,511] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 02:14:17,728] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 02:14:17,760] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 02:14:18,005] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8559.5091 2258259887.1738 536.0000
[2019-03-24 02:14:18,153] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7840.8532 2529795142.6922 831.0000
[2019-03-24 02:14:19,168] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 475000, evaluation results [475000.0, 7840.853177063691, 2529795142.6922317, 831.0, 8559.509129880978, 2258259887.1737776, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 02:14:19,596] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.00000000e+00 5.71977220e-26 4.69367861e-12 1.28327096e-23
 4.34081414e-14], sum to 1.0000
[2019-03-24 02:14:19,603] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2042
[2019-03-24 02:14:19,607] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.7, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6326355633832683, 6.911199999999999, 6.9112, 121.9260426156618, 470915.3487308797, 470915.3487308802, 134555.7479927663], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1918800.0000, 
sim time next is 1919400.0000, 
raw observation next is [19.75, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.618574326923206, 6.9112, 6.9112, 121.9260426156618, 460554.7943707338, 460554.7943707338, 133275.3241273398], 
processed observation next is [1.0, 0.21739130434782608, 0.28703703703703703, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5232179086540075, 0.0, 0.0, 0.8094621288201359, 0.16448385513240493, 0.16448385513240493, 0.2562987002448842], 
reward next is 0.7437, 
noisyNet noise sample is [array([0.9597778], dtype=float32), 1.0710263]. 
=============================================
[2019-03-24 02:14:23,452] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.2027514e-31 1.2306189e-12 4.0505280e-27 2.7495016e-18], sum to 1.0000
[2019-03-24 02:14:23,460] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1746
[2019-03-24 02:14:23,467] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.5, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6102993808339285, 6.9112, 6.9112, 121.9260426156618, 453264.1210875884, 453264.1210875884, 131550.4224020631], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1990800.0000, 
sim time next is 1991400.0000, 
raw observation next is [19.48333333333333, 90.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6103739038253655, 6.9112, 6.9112, 121.9260426156618, 453234.6618031468, 453234.6618031468, 131495.7055898573], 
processed observation next is [0.0, 0.043478260869565216, 0.2771604938271604, 0.9083333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5129673797817068, 0.0, 0.0, 0.8094621288201359, 0.16186952207255242, 0.16186952207255242, 0.25287635690357174], 
reward next is 0.7471, 
noisyNet noise sample is [array([1.2915318], dtype=float32), -0.2506468]. 
=============================================
[2019-03-24 02:14:28,911] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.2811540e-29 1.0177487e-12 5.6301508e-26 1.5791304e-16], sum to 1.0000
[2019-03-24 02:14:28,920] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2670
[2019-03-24 02:14:28,925] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.46666666666667, 88.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7569626513981861, 6.911200000000001, 6.9112, 121.9260426156618, 563854.2577225622, 563854.2577225617, 154106.9054012732], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2101200.0000, 
sim time next is 2101800.0000, 
raw observation next is [22.58333333333334, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7625323748962953, 6.9112, 6.9112, 121.9260426156618, 567753.6552885142, 567753.6552885142, 154946.3775215261], 
processed observation next is [0.0, 0.30434782608695654, 0.39197530864197555, 0.8833333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7031654686203692, 0.0, 0.0, 0.8094621288201359, 0.2027691626030408, 0.2027691626030408, 0.2979738029260117], 
reward next is 0.7020, 
noisyNet noise sample is [array([1.8673244], dtype=float32), -0.39232868]. 
=============================================
[2019-03-24 02:14:29,894] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999988e-01 8.5757126e-21 6.3179627e-08 2.4499121e-17 8.3473489e-12], sum to 1.0000
[2019-03-24 02:14:29,902] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4122
[2019-03-24 02:14:29,906] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.83333333333333, 52.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9173005925717893, 6.911199999999999, 6.9112, 121.9260426156618, 666944.4972653025, 666944.4972653029, 179043.0603411371], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2126400.0000, 
sim time next is 2127000.0000, 
raw observation next is [30.91666666666667, 51.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9122302531767811, 6.911200000000001, 6.9112, 121.9260426156618, 663924.7592124519, 663924.7592124514, 178250.7826747206], 
processed observation next is [0.0, 0.6086956521739131, 0.7006172839506175, 0.5166666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8902878164709762, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23711598543301854, 0.23711598543301837, 0.342789966682155], 
reward next is 0.6572, 
noisyNet noise sample is [array([0.35669744], dtype=float32), -0.20129155]. 
=============================================
[2019-03-24 02:14:29,938] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[55.891384]
 [55.84923 ]
 [55.812496]
 [55.77886 ]
 [55.758663]], R is [[56.04652023]
 [56.14174271]
 [56.23450851]
 [56.32500076]
 [56.41345978]].
[2019-03-24 02:14:35,924] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.2731200e-20 1.7786741e-12 4.0567605e-19 3.8452295e-13], sum to 1.0000
[2019-03-24 02:14:35,930] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0929
[2019-03-24 02:14:35,935] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.7, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8482181313076331, 6.911199999999999, 6.9112, 121.9260426156618, 626096.1465590566, 626096.146559057, 167854.9158013305], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2235600.0000, 
sim time next is 2236200.0000, 
raw observation next is [22.7, 95.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8518227748610667, 6.911200000000001, 6.9112, 121.9260426156618, 628605.945992335, 628605.9459923345, 168358.1969638034], 
processed observation next is [1.0, 0.9130434782608695, 0.39629629629629626, 0.9516666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8147784685763334, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22450212356869106, 0.2245021235686909, 0.32376576339192964], 
reward next is 0.6762, 
noisyNet noise sample is [array([-1.1133016], dtype=float32), -0.050352473]. 
=============================================
[2019-03-24 02:14:40,399] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.00000000e+00 1.10524736e-26 1.35150650e-15 3.32447679e-24
 1.31696832e-17], sum to 1.0000
[2019-03-24 02:14:40,409] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4348
[2019-03-24 02:14:40,413] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.06666666666667, 68.0, 1.0, 2.0, 0.2481487388320099, 1.0, 2.0, 0.2481487388320099, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 584813.752424533, 584813.7524245335, 169417.0443182886], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2308800.0000, 
sim time next is 2309400.0000, 
raw observation next is [25.95, 68.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7817174887789553, 6.911200000000001, 6.9112, 121.9260426156618, 578763.7060475468, 578763.7060475464, 158863.6045372363], 
processed observation next is [1.0, 0.7391304347826086, 0.5166666666666666, 0.685, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.7271468609736942, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2067013235884096, 0.20670132358840942, 0.3055069318023775], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.37512153], dtype=float32), -0.32971126]. 
=============================================
[2019-03-24 02:14:40,963] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 7.9820314e-25 8.6377466e-14 4.3564812e-22 2.3419268e-17], sum to 1.0000
[2019-03-24 02:14:40,970] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4743
[2019-03-24 02:14:40,975] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.91666666666667, 92.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7603837334457035, 6.911200000000001, 6.9112, 121.9260426156618, 566711.1110827335, 566711.111082733, 154278.3725534416], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2333400.0000, 
sim time next is 2334000.0000, 
raw observation next is [21.93333333333333, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7627663111569172, 6.9112, 6.9112, 121.9260426156618, 568371.08323437, 568371.08323437, 154654.2951145762], 
processed observation next is [1.0, 0.0, 0.36790123456790114, 0.9233333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7034578889461465, 0.0, 0.0, 0.8094621288201359, 0.20298967258370357, 0.20298967258370357, 0.29741210598956963], 
reward next is 0.7026, 
noisyNet noise sample is [array([-1.4477504], dtype=float32), 0.61150795]. 
=============================================
[2019-03-24 02:14:40,994] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[67.40861]
 [67.66874]
 [67.9861 ]
 [67.97692]
 [67.9642 ]], R is [[67.21643829]
 [67.24758148]
 [67.27912903]
 [67.31101227]
 [67.34304047]].
[2019-03-24 02:14:45,552] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.5677550e-25 1.2869321e-13 7.0148964e-23 2.1725980e-17], sum to 1.0000
[2019-03-24 02:14:45,562] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5986
[2019-03-24 02:14:45,567] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.7, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6580792073058487, 6.911199999999999, 6.9112, 121.9260426156618, 491541.2408701496, 491541.2408701501, 139241.3087175668], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2401200.0000, 
sim time next is 2401800.0000, 
raw observation next is [28.53333333333333, 43.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6572210255038134, 6.9112, 6.9112, 121.9260426156618, 490834.4865633972, 490834.4865633972, 139004.911878349], 
processed observation next is [1.0, 0.8260869565217391, 0.6123456790123456, 0.4333333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5715262818797667, 0.0, 0.0, 0.8094621288201359, 0.175298030915499, 0.175298030915499, 0.26731713822759423], 
reward next is 0.7327, 
noisyNet noise sample is [array([0.68945676], dtype=float32), -1.6218829]. 
=============================================
[2019-03-24 02:14:53,361] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9996686e-01 1.0803886e-16 3.3156663e-05 3.0183776e-13 5.2181255e-09], sum to 1.0000
[2019-03-24 02:14:53,368] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6315
[2019-03-24 02:14:53,376] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1400385.075935371 W.
[2019-03-24 02:14:53,383] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.06666666666667, 38.16666666666666, 1.0, 2.0, 0.5793537962776427, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9393573878669674, 6.911199999999999, 6.9112, 121.9260426156618, 1400385.075935371, 1400385.075935371, 283629.4057189142], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2538600.0000, 
sim time next is 2539200.0000, 
raw observation next is [30.23333333333333, 37.33333333333334, 1.0, 2.0, 0.5868750403864534, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9536143675206291, 6.911199999999999, 6.9112, 121.9260426156618, 1423039.224272141, 1423039.224272142, 286268.5759980715], 
processed observation next is [1.0, 0.391304347826087, 0.6753086419753086, 0.3733333333333334, 1.0, 1.0, 0.5081845718886351, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9420179594007863, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5082282943829075, 0.5082282943829078, 0.5505164923039837], 
reward next is 0.4495, 
noisyNet noise sample is [array([1.2607126], dtype=float32), 0.9963638]. 
=============================================
[2019-03-24 02:15:09,641] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 02:15:09,643] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:15:09,644] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:15:09,644] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:15:09,644] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:15:09,645] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:15:09,646] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:15:09,647] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:15:09,647] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:15:09,644] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:15:09,650] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:15:09,656] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run21
[2019-03-24 02:15:09,657] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run21
[2019-03-24 02:15:09,657] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run21
[2019-03-24 02:15:09,730] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run21
[2019-03-24 02:15:09,730] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run21
[2019-03-24 02:15:37,454] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.17484254]
[2019-03-24 02:15:37,455] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.12250000333334, 45.66051785000001, 1.0, 1.0, 0.6083859985875022, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 743822.7366467408, 743822.7366467408, 161573.543938506]
[2019-03-24 02:15:37,456] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:15:37,459] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.2019821e-14 4.0310908e-08 2.3940314e-14 5.2272357e-12], sampled 0.8615874619256847
[2019-03-24 02:15:37,460] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 743822.7366467408 W.
[2019-03-24 02:15:42,762] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.17484254]
[2019-03-24 02:15:42,762] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.55556604666667, 95.75303212666667, 1.0, 2.0, 0.6011075312351418, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9569827664319172, 6.911199999999999, 6.9112, 121.9260426156618, 1370697.064779292, 1370697.064779292, 294291.8000321147]
[2019-03-24 02:15:42,764] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:15:42,766] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 4.3515805e-15 2.3704386e-08 8.8081576e-15 2.3233000e-12], sampled 0.9806281285164858
[2019-03-24 02:15:42,767] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1370697.064779292 W.
[2019-03-24 02:15:43,458] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.17484254]
[2019-03-24 02:15:43,461] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.40398677333333, 83.40342388666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 8.462525917753567, 6.9112, 121.9198127960077, 1957727.511150684, 1163350.576142623, 245587.2505041414]
[2019-03-24 02:15:43,462] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:15:43,464] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9999988e-01 7.4090141e-14 1.0926772e-07 1.4329981e-13 2.3748423e-11], sampled 0.2604620860919481
[2019-03-24 02:15:43,465] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1957727.511150684 W.
[2019-03-24 02:15:59,240] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.17484254]
[2019-03-24 02:15:59,242] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.66666666666667, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7499777859604949, 6.9112, 6.9112, 121.9260426156618, 559859.1330428227, 559859.1330428227, 152120.1354862558]
[2019-03-24 02:15:59,243] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:15:59,246] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 6.9316048e-17 2.5451072e-09 1.5047776e-16 7.9082303e-14], sampled 0.08953141440786683
[2019-03-24 02:16:50,802] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 02:16:51,122] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.7982 2219159744.7191 543.0000
[2019-03-24 02:16:51,350] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 02:16:51,356] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.2390 2292980111.6144 697.0000
[2019-03-24 02:16:51,452] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 02:16:52,466] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 500000, evaluation results [500000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.798202931406, 2219159744.719052, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.238967854026, 2292980111.6144123, 697.0]
[2019-03-24 02:16:53,545] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9999940e-01 1.6879812e-13 5.9551911e-07 5.6328345e-14 2.7004470e-11], sum to 1.0000
[2019-03-24 02:16:53,552] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8071
[2019-03-24 02:16:53,561] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1281040.084176433 W.
[2019-03-24 02:16:53,564] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3745481069069262, 1.0, 2.0, 0.3745481069069262, 1.0, 1.0, 0.5962927843760693, 6.9112, 6.9112, 121.94756008, 1281040.084176433, 1281040.084176433, 286112.378150413], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2887200.0000, 
sim time next is 2887800.0000, 
raw observation next is [23.21666666666667, 92.33333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.491862736209124, 6.9112, 121.9236321042562, 1488257.246358313, 1190911.905088222, 247127.3725442941], 
processed observation next is [1.0, 0.43478260869565216, 0.4154320987654322, 0.9233333333333335, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.05806627362091241, 0.0, 0.8094461255311579, 0.5315204451279689, 0.42532568038865065, 0.4752449472005656], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04536487], dtype=float32), 1.3292496]. 
=============================================
[2019-03-24 02:16:54,439] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9999964e-01 1.4531057e-14 3.9772146e-07 6.5727785e-14 4.1694144e-12], sum to 1.0000
[2019-03-24 02:16:54,447] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5266
[2019-03-24 02:16:54,453] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1923259.256666055 W.
[2019-03-24 02:16:54,458] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5621013359433422, 1.0, 1.0, 0.5621013359433422, 1.0, 2.0, 0.8948836331842789, 6.911199999999999, 6.9112, 121.94756008, 1923259.256666055, 1923259.256666055, 375113.4547676766], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2907600.0000, 
sim time next is 2908200.0000, 
raw observation next is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.8573736778313481, 1.0, 2.0, 0.8573736778313481, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1955735.284277447, 1955735.284277448, 368032.6200403413], 
processed observation next is [1.0, 0.6521739130434783, 0.5493827160493825, 0.8483333333333333, 1.0, 1.0, 0.8302067593230334, 1.0, 1.0, 0.8302067593230334, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6984768872419453, 0.6984768872419457, 0.7077550385391178], 
reward next is 0.2922, 
noisyNet noise sample is [array([2.8071454], dtype=float32), -1.4250098]. 
=============================================
[2019-03-24 02:16:57,338] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9999654e-01 1.1790387e-12 3.4504399e-06 4.0476797e-12 1.1354825e-09], sum to 1.0000
[2019-03-24 02:16:57,343] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1787
[2019-03-24 02:16:57,355] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 746106.4785629848 W.
[2019-03-24 02:16:57,362] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 91.33333333333334, 1.0, 2.0, 0.6546638802631262, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 746106.4785629848, 746106.4785629848, 167737.2396842747], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2942400.0000, 
sim time next is 2943000.0000, 
raw observation next is [25.25, 90.0, 1.0, 2.0, 0.6495369820736203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740260.6405449307, 740260.6405449307, 166808.910226758], 
processed observation next is [1.0, 0.043478260869565216, 0.49074074074074076, 0.9, 1.0, 1.0, 0.5827821215162147, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2643788001946181, 0.2643788001946181, 0.3207863658206884], 
reward next is 0.6792, 
noisyNet noise sample is [array([0.1992044], dtype=float32), 0.69961387]. 
=============================================
[2019-03-24 02:16:57,377] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[29.357353]
 [29.803162]
 [29.59056 ]
 [30.559132]
 [30.072247]], R is [[29.27178001]
 [28.97906303]
 [28.68927193]
 [28.40237999]
 [28.72772026]].
[2019-03-24 02:17:04,120] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9999940e-01 6.7184641e-10 5.9919870e-07 6.9834466e-10 3.2278504e-09], sum to 1.0000
[2019-03-24 02:17:04,132] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2326
[2019-03-24 02:17:04,140] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1916390.978363134 W.
[2019-03-24 02:17:04,149] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.51666666666667, 82.5, 1.0, 2.0, 0.5600961296572213, 1.0, 2.0, 0.5600961296572213, 1.0, 2.0, 0.8916912794717649, 6.911200000000001, 6.9112, 121.94756008, 1916390.978363134, 1916390.978363134, 374062.9728185037], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3081000.0000, 
sim time next is 3081600.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.5389932501627313, 1.0, 2.0, 0.5389932501627313, 1.0, 2.0, 0.8580948080437325, 6.911200000000001, 6.9112, 121.94756008, 1844112.116345715, 1844112.116345714, 363139.3771261002], 
processed observation next is [1.0, 0.6956521739130435, 0.5185185185185185, 0.84, 1.0, 1.0, 0.45118244066991814, 1.0, 1.0, 0.45118244066991814, 1.0, 1.0, 0.8226185100546657, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6586114701234697, 0.6586114701234693, 0.6983449560117311], 
reward next is 0.3017, 
noisyNet noise sample is [array([-0.61072916], dtype=float32), 1.7087017]. 
=============================================
[2019-03-24 02:17:05,804] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9999988e-01 4.1797246e-13 5.9732784e-08 4.3376153e-12 7.6156637e-10], sum to 1.0000
[2019-03-24 02:17:05,811] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4320
[2019-03-24 02:17:05,820] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.26666666666667, 49.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.73769288406018, 6.911200000000001, 6.9112, 121.9260426156618, 550812.763009029, 550812.7630090285, 150510.264980767], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3116400.0000, 
sim time next is 3117000.0000, 
raw observation next is [28.33333333333334, 47.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7159518227381116, 6.9112, 6.9112, 121.9260426156618, 534959.9507497996, 534959.9507497996, 147148.5105647655], 
processed observation next is [1.0, 0.043478260869565216, 0.6049382716049385, 0.47166666666666657, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6449397784226396, 0.0, 0.0, 0.8094621288201359, 0.19105712526778557, 0.19105712526778557, 0.28297790493224134], 
reward next is 0.7170, 
noisyNet noise sample is [array([-0.74264777], dtype=float32), -0.86913884]. 
=============================================
[2019-03-24 02:17:05,841] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[35.35052 ]
 [35.28401 ]
 [35.324432]
 [35.458763]
 [35.601807]], R is [[35.85190582]
 [36.20394135]
 [36.54582596]
 [36.87787628]
 [37.200737  ]].
[2019-03-24 02:17:06,416] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.1875868e-22 6.3594160e-13 6.9027465e-22 8.7723358e-17], sum to 1.0000
[2019-03-24 02:17:06,420] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5744
[2019-03-24 02:17:06,423] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.33333333333334, 61.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8954529161835807, 6.9112, 6.9112, 121.9260426156618, 656200.9401330438, 656200.9401330438, 175160.9668394154], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3108000.0000, 
sim time next is 3108600.0000, 
raw observation next is [28.25, 60.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8807507157312262, 6.911199999999999, 6.9112, 121.9260426156618, 647385.7520805422, 647385.7520805426, 172773.9584571607], 
processed observation next is [1.0, 1.0, 0.6018518518518519, 0.605, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8509383946640328, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2312091971716222, 0.23120919717162236, 0.33225761241761675], 
reward next is 0.6677, 
noisyNet noise sample is [array([-0.6659809], dtype=float32), -0.40904006]. 
=============================================
[2019-03-24 02:17:13,334] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.0984810e-17 6.0253749e-09 1.6621126e-18 3.1459105e-14], sum to 1.0000
[2019-03-24 02:17:13,335] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3157
[2019-03-24 02:17:13,343] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.7, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8159391002427872, 6.911199999999999, 6.9112, 121.9260426156618, 605172.1519035476, 605172.151903548, 162732.7099801988], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3234000.0000, 
sim time next is 3234600.0000, 
raw observation next is [29.05, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8116679170440895, 6.9112, 6.9112, 121.9260426156618, 602331.4786813528, 602331.4786813528, 162048.5927993107], 
processed observation next is [0.0, 0.43478260869565216, 0.6314814814814815, 0.52, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7645848963051118, 0.0, 0.0, 0.8094621288201359, 0.2151183852433403, 0.2151183852433403, 0.3116319092294436], 
reward next is 0.6884, 
noisyNet noise sample is [array([-0.58670914], dtype=float32), 0.8178348]. 
=============================================
[2019-03-24 02:17:18,178] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 7.9520120e-23 2.3941070e-12 1.8480239e-22 1.0016597e-17], sum to 1.0000
[2019-03-24 02:17:18,186] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4620
[2019-03-24 02:17:18,189] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.45, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9084383521568862, 6.911200000000001, 6.9112, 121.9260426156618, 665497.0109084606, 665497.0109084601, 176933.6103404386], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3321000.0000, 
sim time next is 3321600.0000, 
raw observation next is [24.6, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9074270561167324, 6.911200000000001, 6.9112, 121.9260426156618, 664642.7378919611, 664642.7378919607, 176822.6285252337], 
processed observation next is [0.0, 0.43478260869565216, 0.46666666666666673, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8842838201459154, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2373724063899861, 0.23737240638998594, 0.3400435163946802], 
reward next is 0.6600, 
noisyNet noise sample is [array([0.33162883], dtype=float32), -1.5412909]. 
=============================================
[2019-03-24 02:17:18,513] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 3.5602086e-19 6.9416549e-11 1.2191993e-19 3.4518645e-15], sum to 1.0000
[2019-03-24 02:17:18,520] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6762
[2019-03-24 02:17:18,524] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.85, 89.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8807291247445095, 6.9112, 6.9112, 121.9260426156618, 647148.6617742798, 647148.6617742798, 172825.4853744056], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3315000.0000, 
sim time next is 3315600.0000, 
raw observation next is [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8890100065613629, 6.911199999999999, 6.9112, 121.9260426156618, 652083.9069517417, 652083.9069517421, 174177.7231347848], 
processed observation next is [0.0, 0.391304347826087, 0.4444444444444444, 0.89, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8612625082017036, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23288710962562204, 0.2328871096256222, 0.3349571598745862], 
reward next is 0.6650, 
noisyNet noise sample is [array([1.1699611], dtype=float32), -1.4700301]. 
=============================================
[2019-03-24 02:17:26,772] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9469429e-01 3.5522086e-07 5.2970047e-03 8.7502826e-08 8.1781409e-06], sum to 1.0000
[2019-03-24 02:17:26,780] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3114
[2019-03-24 02:17:26,788] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 833752.1912537538 W.
[2019-03-24 02:17:26,791] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.5, 86.0, 1.0, 2.0, 0.7315259557261513, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 833752.1912537538, 833752.1912537548, 182191.9184459379], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3484800.0000, 
sim time next is 3485400.0000, 
raw observation next is [25.75, 86.5, 1.0, 2.0, 0.3806621546343985, 1.0, 1.0, 0.3806621546343985, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 867733.9065236093, 867733.9065236093, 200943.7774932142], 
processed observation next is [1.0, 0.34782608695652173, 0.5092592592592593, 0.865, 1.0, 1.0, 0.2626930412314268, 1.0, 0.5, 0.2626930412314268, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30990496661557476, 0.30990496661557476, 0.3864303413331042], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.08027444], dtype=float32), 0.65292925]. 
=============================================
[2019-03-24 02:17:27,044] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9555796e-01 1.0823350e-07 4.4400943e-03 6.7277576e-08 1.8501019e-06], sum to 1.0000
[2019-03-24 02:17:27,052] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6314
[2019-03-24 02:17:27,058] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1438906.823541603 W.
[2019-03-24 02:17:27,062] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.16666666666667, 77.5, 1.0, 2.0, 0.6309922670018688, 1.0, 2.0, 0.6309922670018688, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1438906.823541603, 1438906.823541603, 278867.0308304182], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3502200.0000, 
sim time next is 3502800.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.4589403033926077, 1.0, 2.0, 0.4589403033926077, 1.0, 1.0, 0.7306479096432335, 6.9112, 6.9112, 121.94756008, 1569976.473946353, 1569976.473946353, 323862.7943078146], 
processed observation next is [1.0, 0.5652173913043478, 0.5925925925925926, 0.79, 1.0, 1.0, 0.3558813135626282, 1.0, 1.0, 0.3558813135626282, 1.0, 0.5, 0.6633098870540418, 0.0, 0.0, 0.8096049824067558, 0.5607058835522689, 0.5607058835522689, 0.6228130659765666], 
reward next is 0.3772, 
noisyNet noise sample is [array([0.45381334], dtype=float32), 2.434096]. 
=============================================
[2019-03-24 02:17:34,727] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9998093e-01 6.4976138e-19 1.9060193e-05 3.0791079e-18 2.6392964e-15], sum to 1.0000
[2019-03-24 02:17:34,735] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0502
[2019-03-24 02:17:34,740] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9177846866620718, 6.9112, 6.9112, 121.9260426156618, 668579.4998041625, 668579.4998041625, 178899.3962849035], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3631200.0000, 
sim time next is 3631800.0000, 
raw observation next is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9176143052351808, 6.911200000000001, 6.9112, 121.9260426156618, 668455.3379705658, 668455.3379705653, 178876.3657156228], 
processed observation next is [1.0, 0.0, 0.4074074074074074, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8970178815439761, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23873404927520206, 0.2387340492752019, 0.3439930109915823], 
reward next is 0.6560, 
noisyNet noise sample is [array([-0.59958994], dtype=float32), 2.1980903]. 
=============================================
[2019-03-24 02:17:36,230] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9995887e-01 9.3649611e-12 4.1067273e-05 4.1215989e-12 1.0075357e-09], sum to 1.0000
[2019-03-24 02:17:36,238] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5942
[2019-03-24 02:17:36,251] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 697756.004680973 W.
[2019-03-24 02:17:36,253] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 94.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9477547575004933, 6.911199999999999, 6.9112, 121.9260426156618, 697756.004680973, 697756.0046809735, 181424.7277276366], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3643800.0000, 
sim time next is 3644400.0000, 
raw observation next is [23.0, 94.66666666666667, 1.0, 1.0, 0.2873373795521824, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4589658737999596, 6.911199999999999, 6.9112, 121.9260426156618, 670785.1757428871, 670785.1757428874, 191479.4589009296], 
processed observation next is [1.0, 0.17391304347826086, 0.4074074074074074, 0.9466666666666668, 1.0, 0.5, 0.15159211851450288, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3237073422499495, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23956613419388825, 0.23956613419388836, 0.36822972865563386], 
reward next is 0.6318, 
noisyNet noise sample is [array([1.3641441], dtype=float32), -0.5303922]. 
=============================================
[2019-03-24 02:17:36,613] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9990046e-01 6.3514922e-11 9.9488192e-05 3.2114821e-11 2.6760694e-09], sum to 1.0000
[2019-03-24 02:17:36,618] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8087
[2019-03-24 02:17:36,622] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.1, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8374969345810611, 6.9112, 6.9112, 121.9260426156618, 619724.8761716713, 619724.8761716713, 165986.4556346868], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3657600.0000, 
sim time next is 3658200.0000, 
raw observation next is [22.08333333333334, 98.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8726303409471377, 6.9112, 6.9112, 121.9260426156618, 645640.4188598316, 645640.4188598316, 170463.0301576678], 
processed observation next is [1.0, 0.34782608695652173, 0.373456790123457, 0.9833333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8407879261839221, 0.0, 0.0, 0.8094621288201359, 0.2305858638785113, 0.2305858638785113, 0.3278135195339765], 
reward next is 0.6722, 
noisyNet noise sample is [array([-1.1816052], dtype=float32), 0.69825196]. 
=============================================
[2019-03-24 02:17:43,429] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 02:17:43,432] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:17:43,433] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:17:43,434] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:17:43,435] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:17:43,438] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:17:43,438] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:17:43,440] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:17:43,441] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:17:43,441] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:17:43,442] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:17:43,453] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run22
[2019-03-24 02:17:43,478] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run22
[2019-03-24 02:17:43,478] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run22
[2019-03-24 02:17:43,523] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run22
[2019-03-24 02:17:43,555] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run22
[2019-03-24 02:17:52,465] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.1786391]
[2019-03-24 02:17:52,466] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.5, 36.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6644265572967415, 6.911199999999999, 6.9112, 121.9260426156618, 491437.9812202942, 491437.9812202946, 135525.1362457962]
[2019-03-24 02:17:52,467] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:17:52,470] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9999356e-01 2.2229736e-09 6.3863763e-06 3.7731560e-09 2.0128422e-08], sampled 0.8703947110609431
[2019-03-24 02:18:04,654] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.1786391]
[2019-03-24 02:18:04,655] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.0, 35.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5932741185805187, 6.9112, 6.9112, 121.9260426156618, 439541.4368777158, 439541.4368777158, 129203.3978902978]
[2019-03-24 02:18:04,655] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:18:04,658] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9999917e-01 9.3043795e-11 8.9032045e-07 1.6467001e-10 1.1022855e-09], sampled 0.8246108968507108
[2019-03-24 02:18:04,697] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.1786391]
[2019-03-24 02:18:04,698] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 43.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5863874405370805, 6.911200000000001, 6.9112, 121.9260426156618, 434621.5490785664, 434621.549078566, 128683.822449028]
[2019-03-24 02:18:04,699] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:18:04,704] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9999702e-01 6.6587558e-10 3.0001495e-06 1.1458061e-09 6.6071930e-09], sampled 0.45302749436860446
[2019-03-24 02:18:26,470] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.1786391]
[2019-03-24 02:18:26,471] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.18142643666667, 80.96529340166667, 1.0, 2.0, 0.7048398663166011, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1518325.463000318, 1518325.463000318, 318112.7306216672]
[2019-03-24 02:18:26,472] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:18:26,476] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9999917e-01 8.9604019e-11 8.5645780e-07 1.5810929e-10 1.0214014e-09], sampled 0.785997686448227
[2019-03-24 02:18:26,477] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1518325.463000318 W.
[2019-03-24 02:18:31,816] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.1786391]
[2019-03-24 02:18:31,818] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.70605634, 66.1616507, 1.0, 1.0, 0.6316522671794201, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719868.318897736, 719868.318897736, 163610.8152539984]
[2019-03-24 02:18:31,819] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:18:31,823] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9999857e-01 2.0484475e-10 1.3983648e-06 3.5199368e-10 2.1391979e-09], sampled 0.7570684462870976
[2019-03-24 02:18:31,827] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 719868.318897736 W.
[2019-03-24 02:18:44,961] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.1786391]
[2019-03-24 02:18:44,962] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.46666666666667, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9148435773939104, 6.911200000000001, 6.9112, 121.9260426156618, 668836.9571944213, 668836.957194421, 178066.1420734912]
[2019-03-24 02:18:44,963] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:18:44,967] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9999857e-01 2.0488890e-10 1.4113673e-06 3.5439596e-10 2.1583624e-09], sampled 0.5720016079841947
[2019-03-24 02:19:01,941] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.1786391]
[2019-03-24 02:19:01,942] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.06666666666667, 62.0, 1.0, 2.0, 0.5785043253717969, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9209977265624492, 6.911200000000001, 6.9112, 121.9260426156618, 1319110.908495382, 1319110.908495381, 285593.8119990547]
[2019-03-24 02:19:01,943] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:19:01,947] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9999928e-01 6.2826321e-11 6.9907725e-07 1.1314573e-10 7.6171702e-10], sampled 0.04267597915192589
[2019-03-24 02:19:01,949] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1319110.908495382 W.
[2019-03-24 02:19:12,404] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.1786391]
[2019-03-24 02:19:12,406] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.10047975333334, 75.15320330666668, 1.0, 2.0, 0.7973401922417401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 908808.0352852517, 908808.0352852512, 195388.5875329904]
[2019-03-24 02:19:12,408] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:19:12,411] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9999702e-01 6.3752803e-10 2.9489331e-06 1.1169646e-09 6.4501626e-09], sampled 0.21145868353247232
[2019-03-24 02:19:12,412] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 908808.0352852517 W.
[2019-03-24 02:19:17,943] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.1786391]
[2019-03-24 02:19:17,945] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.3496984, 72.65879298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7171689668602038, 6.9112, 6.9112, 121.9260426156618, 535487.4029250002, 535487.4029250002, 148159.1258299254]
[2019-03-24 02:19:17,946] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:19:17,948] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9999797e-01 3.5753248e-10 2.0104858e-06 6.1498856e-10 3.6445713e-09], sampled 0.5629112107197927
[2019-03-24 02:19:22,062] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.2958 2292950550.9323 697.0000
[2019-03-24 02:19:22,266] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8557.8724 2258287852.8061 536.0000
[2019-03-24 02:19:22,356] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 02:19:22,374] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 02:19:22,615] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 02:19:23,632] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 525000, evaluation results [525000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8557.872443712158, 2258287852.806074, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.29581531956, 2292950550.9323354, 697.0]
[2019-03-24 02:19:27,419] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 6.1792238e-17 6.2170787e-13 6.9161272e-17 5.6745538e-16], sum to 1.0000
[2019-03-24 02:19:27,426] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0960
[2019-03-24 02:19:27,430] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 801498.9796255504 W.
[2019-03-24 02:19:27,433] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.08333333333334, 51.83333333333333, 1.0, 2.0, 0.2344140529871083, 1.0, 2.0, 0.2344140529871083, 1.0, 1.0, 0.3731948066882017, 6.911200000000001, 6.9112, 121.94756008, 801498.9796255504, 801498.97962555, 232166.67390642], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3851400.0000, 
sim time next is 3852000.0000, 
raw observation next is [33.1, 51.0, 1.0, 2.0, 0.2318759547993418, 1.0, 2.0, 0.2318759547993418, 1.0, 2.0, 0.3691540717131901, 6.911200000000002, 6.9112, 121.94756008, 792816.3303384755, 792816.3303384746, 231290.5927514333], 
processed observation next is [0.0, 0.6086956521739131, 0.7814814814814816, 0.51, 1.0, 1.0, 0.0855666128563593, 1.0, 1.0, 0.0855666128563593, 1.0, 1.0, 0.2114425896414876, 1.7763568394002506e-16, 0.0, 0.8096049824067558, 0.2831486894065984, 0.2831486894065981, 0.444789601445064], 
reward next is 0.5552, 
noisyNet noise sample is [array([-0.34534281], dtype=float32), -0.26988763]. 
=============================================
[2019-03-24 02:19:27,449] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[43.98784 ]
 [44.41542 ]
 [44.09252 ]
 [43.86959 ]
 [44.035614]], R is [[44.6227684 ]
 [44.73006439]
 [44.90924072]
 [44.46014786]
 [44.01554871]].
[2019-03-24 02:19:35,530] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.46260449e-01 1.66797992e-10 7.53739536e-01 6.48913978e-10
 1.28066775e-08], sum to 1.0000
[2019-03-24 02:19:35,535] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4780
[2019-03-24 02:19:35,539] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.6, 94.0, 1.0, 2.0, 0.6841985091038215, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1494766.127018572, 1494766.127018572, 314383.5297378145], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4006800.0000, 
sim time next is 4007400.0000, 
raw observation next is [24.66666666666667, 94.00000000000001, 1.0, 2.0, 0.7291365359868798, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1546057.775800568, 1546057.775800568, 322586.1209737715], 
processed observation next is [1.0, 0.391304347826087, 0.469135802469136, 0.9400000000000002, 1.0, 1.0, 0.6775434952224759, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.5521634913573458, 0.5521634913573458, 0.6203579249495605], 
reward next is 0.3796, 
noisyNet noise sample is [array([0.07753151], dtype=float32), -0.37853745]. 
=============================================
[2019-03-24 02:19:39,937] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7431207e-02 3.8661858e-13 9.6256882e-01 5.6317190e-13 1.1153299e-09], sum to 1.0000
[2019-03-24 02:19:39,943] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9833
[2019-03-24 02:19:39,947] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.73333333333333, 71.66666666666666, 1.0, 2.0, 0.7304201620449633, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9935615660051942, 6.911199999999999, 6.9112, 121.9260426156618, 1551278.861464706, 1551278.861464706, 322129.8583432374], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4099200.0000, 
sim time next is 4099800.0000, 
raw observation next is [26.91666666666667, 69.83333333333334, 1.0, 2.0, 0.743792383882379, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9917365573933943, 6.911199999999998, 6.9112, 121.9260426156618, 1568324.254531219, 1568324.25453122, 324336.3312031971], 
processed observation next is [1.0, 0.43478260869565216, 0.5524691358024693, 0.6983333333333335, 1.0, 1.0, 0.6949909331933083, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9896706967417429, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.560115805189721, 0.5601158051897215, 0.6237237138523022], 
reward next is 0.3763, 
noisyNet noise sample is [array([0.35284263], dtype=float32), -2.7177403]. 
=============================================
[2019-03-24 02:19:51,206] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.2044230e-16 1.6533626e-08 1.1470075e-17 2.0443041e-15], sum to 1.0000
[2019-03-24 02:19:51,213] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3458
[2019-03-24 02:19:51,219] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2045268.408635952 W.
[2019-03-24 02:19:51,227] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.45, 44.0, 1.0, 2.0, 0.8965791577502811, 1.0, 2.0, 0.8965791577502811, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2045268.408635952, 2045268.408635953, 385277.017738844], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4293000.0000, 
sim time next is 4293600.0000, 
raw observation next is [32.26666666666667, 44.0, 1.0, 2.0, 0.5894859564914776, 1.0, 2.0, 0.5894859564914776, 1.0, 1.0, 0.9384808409517379, 6.911200000000001, 6.9112, 121.94756008, 2017062.969406957, 2017062.969406957, 389676.7655253186], 
processed observation next is [1.0, 0.6956521739130435, 0.7506172839506176, 0.44, 1.0, 1.0, 0.5112928053469972, 1.0, 1.0, 0.5112928053469972, 1.0, 0.5, 0.9231010511896722, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.720379631931056, 0.720379631931056, 0.7493783952409974], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.1687756], dtype=float32), 1.1857284]. 
=============================================
[2019-03-24 02:19:57,659] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 6.5080822e-34 1.5936537e-24 3.0528913e-37 5.2587576e-34], sum to 1.0000
[2019-03-24 02:19:57,666] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6554
[2019-03-24 02:19:57,674] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.16666666666667, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7960385081201147, 6.911200000000001, 6.9112, 121.9260426156618, 592070.1774641605, 592070.17746416, 159410.8905056182], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4416000.0000, 
sim time next is 4416600.0000, 
raw observation next is [22.08333333333334, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.794791270026195, 6.911199999999999, 6.9112, 121.9260426156618, 591144.5452017398, 591144.5452017402, 159255.5569799242], 
processed observation next is [0.0, 0.08695652173913043, 0.373456790123457, 0.9333333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7434890875327438, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2111230518577642, 0.21112305185776437, 0.3062606864998542], 
reward next is 0.6937, 
noisyNet noise sample is [array([0.10953619], dtype=float32), -0.44057235]. 
=============================================
[2019-03-24 02:19:57,981] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.0352463e-23 1.9049829e-17 4.3663859e-27 2.1871591e-24], sum to 1.0000
[2019-03-24 02:19:57,992] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1565
[2019-03-24 02:19:57,996] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.13333333333333, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7936471127787171, 6.9112, 6.9112, 121.9260426156618, 590265.8153994323, 590265.8153994323, 159130.2460391815], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4422000.0000, 
sim time next is 4422600.0000, 
raw observation next is [22.2, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7935595730957271, 6.9112, 6.9112, 121.9260426156618, 590180.9990871004, 590180.9990871004, 159130.7315694924], 
processed observation next is [0.0, 0.17391304347826086, 0.37777777777777777, 0.925, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7419494663696587, 0.0, 0.0, 0.8094621288201359, 0.210778928245393, 0.210778928245393, 0.30602063763363924], 
reward next is 0.6940, 
noisyNet noise sample is [array([0.120754], dtype=float32), -1.906919]. 
=============================================
[2019-03-24 02:19:58,700] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.8653115e-23 1.1522312e-16 3.3294009e-24 7.1914714e-24], sum to 1.0000
[2019-03-24 02:19:58,712] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7359
[2019-03-24 02:19:58,717] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.33333333333334, 91.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7929054445404793, 6.9112, 6.9112, 121.9260426156618, 589647.4828861657, 589647.4828861657, 159076.746517584], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4425000.0000, 
sim time next is 4425600.0000, 
raw observation next is [22.26666666666667, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7922318983918605, 6.911200000000001, 6.9112, 121.9260426156618, 589161.1846985806, 589161.1846985802, 158985.3698583283], 
processed observation next is [0.0, 0.21739130434782608, 0.38024691358024704, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7402898729898255, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21041470882092167, 0.2104147088209215, 0.3057410958814006], 
reward next is 0.6943, 
noisyNet noise sample is [array([1.2137661], dtype=float32), -0.4915093]. 
=============================================
[2019-03-24 02:20:05,144] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.5634568e-25 5.5348566e-18 1.0354518e-26 4.6804523e-25], sum to 1.0000
[2019-03-24 02:20:05,150] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6429
[2019-03-24 02:20:05,154] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.73333333333333, 94.0, 1.0, 2.0, 0.5909750655596192, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 682068.6194631652, 682068.6194631652, 156946.7606551363], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4562400.0000, 
sim time next is 4563000.0000, 
raw observation next is [23.6, 94.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9266833940420834, 6.911200000000001, 6.9112, 121.9260426156618, 675712.8822241809, 675712.8822241804, 179993.9994286932], 
processed observation next is [0.0, 0.8260869565217391, 0.4296296296296297, 0.94, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.9083542425526042, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24132602936577888, 0.2413260293657787, 0.34614230659364076], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7556841], dtype=float32), 0.73413473]. 
=============================================
[2019-03-24 02:20:05,170] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[53.562534]
 [53.793938]
 [53.456726]
 [54.501724]
 [53.241257]], R is [[54.43611145]
 [53.89175034]
 [53.35283279]
 [53.47054291]
 [53.55896759]].
[2019-03-24 02:20:12,049] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.3186853e-13 9.5126385e-10 1.6593918e-14 4.1788881e-13], sum to 1.0000
[2019-03-24 02:20:12,058] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5976
[2019-03-24 02:20:12,063] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 723728.3268474304 W.
[2019-03-24 02:20:12,068] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.23333333333333, 94.33333333333334, 1.0, 2.0, 0.6173137330795992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 723728.3268474304, 723728.3268474304, 162027.18797685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4681200.0000, 
sim time next is 4681800.0000, 
raw observation next is [23.35, 94.5, 1.0, 2.0, 0.6127299403638127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716472.0278331479, 716472.0278331479, 161136.9831523453], 
processed observation next is [1.0, 0.17391304347826086, 0.42037037037037045, 0.945, 1.0, 1.0, 0.5389642147188246, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25588286708326713, 0.25588286708326713, 0.30987881375451015], 
reward next is 0.6901, 
noisyNet noise sample is [array([0.29054248], dtype=float32), 0.6949109]. 
=============================================
[2019-03-24 02:20:15,000] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 02:20:15,001] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:20:15,002] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:20:15,004] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:20:15,005] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:20:15,005] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:20:15,007] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:20:15,007] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:20:15,008] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:20:15,010] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:20:15,010] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:20:15,030] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run23
[2019-03-24 02:20:15,030] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run23
[2019-03-24 02:20:15,031] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run23
[2019-03-24 02:20:15,099] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run23
[2019-03-24 02:20:15,120] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run23
[2019-03-24 02:20:18,882] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.18035348]
[2019-03-24 02:20:18,885] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.41666666666667, 49.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3858438715720686, 6.911199999999999, 6.9112, 121.9260426156618, 275481.6223895224, 275481.6223895228, 84524.11479938649]
[2019-03-24 02:20:18,886] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:20:18,890] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.00000000e+00 3.62688548e-18 5.77317708e-13 5.01191525e-19
 1.20633944e-17], sampled 0.23876620213258004
[2019-03-24 02:20:38,472] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.18035348]
[2019-03-24 02:20:38,474] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.43281663, 54.3931903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5332830640613502, 6.9112, 6.9112, 121.9260426156618, 386923.2002629743, 386923.2002629743, 119863.2993731337]
[2019-03-24 02:20:38,476] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:20:38,479] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.1408411e-18 2.4163969e-13 1.4814346e-19 3.8164898e-18], sampled 0.5487405006581473
[2019-03-24 02:20:49,150] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.18035348]
[2019-03-24 02:20:49,152] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.09115156166667, 66.85595793166667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9582718352459968, 10.33606447087992, 6.9112, 124.8534144821008, 2510952.660556389, 715007.3625796646, 163174.7894957147]
[2019-03-24 02:20:49,152] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:20:49,154] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.4850956e-18 5.6454147e-13 4.8190664e-19 1.1617196e-17], sampled 0.9267679203179644
[2019-03-24 02:20:49,154] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2510952.660556389 W.
[2019-03-24 02:21:42,043] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.18035348]
[2019-03-24 02:21:42,043] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.04529877, 65.33473968, 1.0, 2.0, 0.5824262378989699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 675488.204697963, 675488.204697963, 155642.3905869287]
[2019-03-24 02:21:42,044] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:21:42,046] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.0796851e-17 2.3972918e-12 4.8260041e-18 9.0564637e-17], sampled 0.27953449019604004
[2019-03-24 02:21:49,054] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.18035348]
[2019-03-24 02:21:49,056] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.04129368666667, 58.73239646, 1.0, 2.0, 0.5765203797449013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 669219.8868620705, 669219.8868620705, 154666.7691322695]
[2019-03-24 02:21:49,056] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:21:49,058] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.5024501e-17 2.6237359e-12 5.5258275e-18 1.0258521e-16], sampled 0.39061764325181436
[2019-03-24 02:21:53,138] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 02:21:53,424] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 02:21:53,582] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 02:21:53,597] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 02:21:53,605] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 02:21:54,620] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 550000, evaluation results [550000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 02:21:56,445] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.6955426e-16 6.4206911e-11 1.8866282e-17 3.9567950e-16], sum to 1.0000
[2019-03-24 02:21:56,452] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5538
[2019-03-24 02:21:56,463] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 762668.8130555728 W.
[2019-03-24 02:21:56,467] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.46666666666667, 84.33333333333334, 1.0, 2.0, 0.3345945568276838, 1.0, 2.0, 0.3345945568276838, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 762668.8130555728, 762668.8130555733, 188970.0054692754], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4738800.0000, 
sim time next is 4739400.0000, 
raw observation next is [26.35, 85.5, 1.0, 2.0, 0.3350814419007093, 1.0, 2.0, 0.3350814419007093, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763779.1630488366, 763779.1630488366, 189092.7568088016], 
processed observation next is [1.0, 0.8695652173913043, 0.5314814814814816, 0.855, 1.0, 1.0, 0.20843028797703492, 1.0, 1.0, 0.20843028797703492, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27277827251744163, 0.27277827251744163, 0.3636399169400031], 
reward next is 0.6364, 
noisyNet noise sample is [array([0.46643707], dtype=float32), 0.15809554]. 
=============================================
[2019-03-24 02:22:02,428] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.4451673e-15 1.2763950e-11 6.9048516e-15 3.0045641e-14], sum to 1.0000
[2019-03-24 02:22:02,435] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4147
[2019-03-24 02:22:02,441] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2056703.234254111 W.
[2019-03-24 02:22:02,449] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.4, 85.66666666666667, 1.0, 2.0, 0.9015860475011118, 1.0, 2.0, 0.9015860475011118, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2056703.234254111, 2056703.234254111, 387521.0466126865], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4879200.0000, 
sim time next is 4879800.0000, 
raw observation next is [28.3, 86.5, 1.0, 2.0, 0.6047853328437265, 1.0, 2.0, 0.6047853328437265, 1.0, 1.0, 0.9628379463704202, 6.911200000000001, 6.9112, 121.94756008, 2069473.985071332, 2069473.985071332, 397989.0558712119], 
processed observation next is [1.0, 0.4782608695652174, 0.6037037037037037, 0.865, 1.0, 1.0, 0.5295063486234839, 1.0, 1.0, 0.5295063486234839, 1.0, 0.5, 0.9535474329630252, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.73909785181119, 0.73909785181119, 0.7653635689830999], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.24395129], dtype=float32), -2.020783]. 
=============================================
[2019-03-24 02:22:10,234] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.4048700e-18 7.6834508e-14 2.2531756e-21 3.8759191e-21], sum to 1.0000
[2019-03-24 02:22:10,244] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0883
[2019-03-24 02:22:10,250] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.73333333333333, 98.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8956172103981956, 6.911200000000001, 6.9112, 121.9260426156618, 656454.2053431747, 656454.2053431743, 175153.9812831234], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5017200.0000, 
sim time next is 5017800.0000, 
raw observation next is [22.66666666666667, 98.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8867287365971901, 6.9112, 6.9112, 121.9260426156618, 650945.8463722671, 650945.8463722671, 173755.4848937234], 
processed observation next is [0.0, 0.043478260869565216, 0.39506172839506193, 0.9833333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8584109207464876, 0.0, 0.0, 0.8094621288201359, 0.23248065941866683, 0.23248065941866683, 0.33414516325716037], 
reward next is 0.6659, 
noisyNet noise sample is [array([-0.49060497], dtype=float32), 0.5292578]. 
=============================================
[2019-03-24 02:22:11,228] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.5781554e-18 3.3202224e-14 2.5977284e-19 2.4005089e-19], sum to 1.0000
[2019-03-24 02:22:11,238] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7283
[2019-03-24 02:22:11,240] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.93288167867769, 6.9112, 6.9112, 121.9260426156618, 677304.6612336868, 677304.6612336868, 181312.8108551606], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5036400.0000, 
sim time next is 5037000.0000, 
raw observation next is [24.25, 92.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9424901924086654, 6.9112, 6.9112, 121.9260426156618, 683084.6467424227, 683084.6467424227, 182806.8956211357], 
processed observation next is [0.0, 0.30434782608695654, 0.4537037037037037, 0.9250000000000002, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9281127405108316, 0.0, 0.0, 0.8094621288201359, 0.2439588024080081, 0.2439588024080081, 0.3515517223483379], 
reward next is 0.6484, 
noisyNet noise sample is [array([-1.2953719], dtype=float32), 1.6597389]. 
=============================================
[2019-03-24 02:22:11,253] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[47.639618]
 [47.685207]
 [47.720592]
 [47.762173]
 [47.806896]], R is [[47.74948883]
 [47.92331696]
 [48.1001358 ]
 [48.27947617]
 [48.46075058]].
[2019-03-24 02:22:12,590] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.9465203e-13 2.0249175e-10 1.9295074e-15 3.2736479e-16], sum to 1.0000
[2019-03-24 02:22:12,601] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1900
[2019-03-24 02:22:12,609] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 880197.508339269 W.
[2019-03-24 02:22:12,614] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.7, 77.0, 1.0, 2.0, 0.3861266162891711, 1.0, 2.0, 0.3861266162891711, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 880197.508339269, 880197.5083392694, 202415.1289627964], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5053200.0000, 
sim time next is 5053800.0000, 
raw observation next is [29.85, 78.0, 1.0, 2.0, 0.2650102647135366, 1.0, 2.0, 0.2650102647135366, 1.0, 1.0, 0.4219049722057257, 6.911199999999999, 6.9112, 121.94756008, 906174.1334986325, 906174.1334986329, 243010.8575186529], 
processed observation next is [0.0, 0.4782608695652174, 0.6611111111111112, 0.78, 1.0, 1.0, 0.1250122198970674, 1.0, 1.0, 0.1250122198970674, 1.0, 0.5, 0.2773812152571571, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.32363361910665445, 0.3236336191066546, 0.46732857215125556], 
reward next is 0.5327, 
noisyNet noise sample is [array([-0.85350126], dtype=float32), -1.3979142]. 
=============================================
[2019-03-24 02:22:14,051] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 6.3967932e-15 7.8528642e-12 9.5340573e-17 5.7518977e-17], sum to 1.0000
[2019-03-24 02:22:14,059] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2050
[2019-03-24 02:22:14,064] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 864042.1034315546 W.
[2019-03-24 02:22:14,074] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.53333333333333, 92.66666666666666, 1.0, 2.0, 0.7580870542028166, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 864042.1034315546, 864042.1034315546, 187435.66872909], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5092800.0000, 
sim time next is 5093400.0000, 
raw observation next is [26.41666666666667, 92.33333333333333, 1.0, 2.0, 0.2503808169061003, 1.0, 1.0, 0.2503808169061003, 1.0, 1.0, 0.3986144148484346, 6.911199999999999, 6.9112, 121.94756008, 856122.3729772569, 856122.3729772574, 237760.5206909493], 
processed observation next is [0.0, 0.9565217391304348, 0.5339506172839508, 0.9233333333333333, 1.0, 1.0, 0.10759621060250037, 1.0, 0.5, 0.10759621060250037, 1.0, 0.5, 0.2482680185605432, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3057579903490203, 0.30575799034902046, 0.4572317705595179], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.57125986], dtype=float32), -0.9311954]. 
=============================================
[2019-03-24 02:22:18,083] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.8993415e-01 1.6092444e-06 1.0063252e-02 2.5818429e-07 6.5985654e-07], sum to 1.0000
[2019-03-24 02:22:18,088] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6032
[2019-03-24 02:22:18,093] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 893656.91187991 W.
[2019-03-24 02:22:18,096] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.7, 69.83333333333333, 1.0, 2.0, 0.2613517409159089, 1.0, 1.0, 0.2613517409159089, 1.0, 2.0, 0.4160804831701007, 6.911200000000001, 6.9112, 121.94756008, 893656.91187991, 893656.9118799097, 241686.6514610686], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5159400.0000, 
sim time next is 5160000.0000, 
raw observation next is [30.5, 70.66666666666667, 1.0, 2.0, 0.2537106133296669, 1.0, 2.0, 0.2537106133296669, 1.0, 2.0, 0.4039155591986514, 6.9112, 6.9112, 121.94756008, 867514.3252030353, 867514.3252030353, 238945.0405093263], 
processed observation next is [0.0, 0.7391304347826086, 0.6851851851851852, 0.7066666666666667, 1.0, 1.0, 0.11156025396388915, 1.0, 1.0, 0.11156025396388915, 1.0, 1.0, 0.2548944489983142, 0.0, 0.0, 0.8096049824067558, 0.30982654471536974, 0.30982654471536974, 0.45950969328716595], 
reward next is 0.5405, 
noisyNet noise sample is [array([1.663585], dtype=float32), 0.08841476]. 
=============================================
[2019-03-24 02:22:18,121] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[32.673847]
 [32.59547 ]
 [32.15366 ]
 [31.907598]
 [32.123318]], R is [[32.84165955]
 [33.04846191]
 [32.71797943]
 [32.39080048]
 [32.60009003]].
[2019-03-24 02:22:27,292] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2203710e-01 6.6010872e-09 6.7796284e-01 5.4225423e-11 2.0733335e-08], sum to 1.0000
[2019-03-24 02:22:27,304] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3675
[2019-03-24 02:22:27,312] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.23333333333333, 63.33333333333334, 1.0, 2.0, 0.7638534294764195, 1.0, 1.0, 0.7638534294764195, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1742200.353016016, 1742200.353016016, 329042.9425962248], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5322000.0000, 
sim time next is 5322600.0000, 
raw observation next is [28.25, 63.5, 1.0, 2.0, 0.9051476568047249, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1746960.61953742, 1746960.619537421, 358076.0765992909], 
processed observation next is [1.0, 0.6086956521739131, 0.6018518518518519, 0.635, 1.0, 1.0, 0.8870805438151487, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.62391450697765, 0.6239145069776504, 0.688607839614021], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3032137], dtype=float32), -0.63890004]. 
=============================================
[2019-03-24 02:22:27,672] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.5446553e-01 1.7335530e-10 4.4553450e-01 1.3586643e-13 5.9808323e-09], sum to 1.0000
[2019-03-24 02:22:27,682] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9087
[2019-03-24 02:22:27,690] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.65, 77.5, 1.0, 2.0, 0.3122172761735062, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4970600718750274, 6.9112, 6.9112, 121.9260426156618, 711638.7655902317, 711638.7655902317, 198556.2730375989], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5351400.0000, 
sim time next is 5352000.0000, 
raw observation next is [26.56666666666666, 78.0, 1.0, 2.0, 0.3123472817755086, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4972670450274021, 6.9112, 6.9112, 121.9260426156618, 711935.2257637734, 711935.2257637734, 198591.812641454], 
processed observation next is [1.0, 0.9565217391304348, 0.5395061728395059, 0.78, 1.0, 1.0, 0.18136581163751023, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3715838062842526, 0.0, 0.0, 0.8094621288201359, 0.2542625806299191, 0.2542625806299191, 0.38190733200279614], 
reward next is 0.6181, 
noisyNet noise sample is [array([-0.69593674], dtype=float32), -2.38149]. 
=============================================
[2019-03-24 02:22:27,719] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[46.61744 ]
 [46.575207]
 [47.02194 ]
 [47.332832]
 [47.159683]], R is [[46.90148163]
 [46.43246841]
 [46.61545944]
 [46.83759689]
 [46.98735046]].
[2019-03-24 02:22:29,028] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9578689e-03 5.4922450e-14 9.9704212e-01 3.6114155e-18 7.4172532e-15], sum to 1.0000
[2019-03-24 02:22:29,032] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7079
[2019-03-24 02:22:29,038] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.98333333333333, 80.66666666666666, 1.0, 2.0, 0.3074092422125705, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4894197507852429, 6.911199999999999, 6.9112, 121.9260426156618, 701133.2967915379, 701133.2967915384, 197239.3098916611], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5356200.0000, 
sim time next is 5356800.0000, 
raw observation next is [25.9, 81.0, 1.0, 2.0, 0.305985297130366, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4871724296556985, 6.911199999999999, 6.9112, 121.9260426156618, 698450.5235016224, 698450.5235016228, 196844.3813458154], 
processed observation next is [1.0, 0.0, 0.5148148148148147, 0.81, 1.0, 1.0, 0.17379202039329283, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3589655370696231, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24944661553629371, 0.24944661553629388, 0.37854688720349117], 
reward next is 0.6215, 
noisyNet noise sample is [array([-1.0998974], dtype=float32), -0.80880857]. 
=============================================
[2019-03-24 02:22:29,421] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.6468548e-01 2.4585076e-09 1.3531452e-01 1.2054703e-13 6.7216954e-11], sum to 1.0000
[2019-03-24 02:22:29,426] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5149
[2019-03-24 02:22:29,435] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 691173.5184044582 W.
[2019-03-24 02:22:29,440] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.08333333333334, 86.5, 1.0, 2.0, 0.3032426042014265, 1.0, 2.0, 0.3032426042014265, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 691173.5184044582, 691173.5184044577, 181240.5695973034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5363400.0000, 
sim time next is 5364000.0000, 
raw observation next is [25.0, 87.0, 1.0, 2.0, 0.6015966365715839, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 691138.8307084751, 691138.8307084746, 158623.6710994706], 
processed observation next is [1.0, 0.08695652173913043, 0.48148148148148145, 0.87, 1.0, 1.0, 0.525710281632838, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24683529668159823, 0.24683529668159807, 0.3050455213451358], 
reward next is 0.6950, 
noisyNet noise sample is [array([0.31679663], dtype=float32), 0.37399688]. 
=============================================
[2019-03-24 02:22:29,463] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[44.850872]
 [45.20368 ]
 [45.746723]
 [46.62957 ]
 [47.355675]], R is [[44.77983093]
 [44.98348999]
 [44.53365707]
 [44.08832169]
 [44.34189606]].
[2019-03-24 02:22:30,694] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1651898e-02 9.1803898e-09 9.7834808e-01 2.8377181e-11 1.1129899e-09], sum to 1.0000
[2019-03-24 02:22:30,707] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1585
[2019-03-24 02:22:30,710] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5053741410884168, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8045720914994801, 6.9112, 6.9112, 121.9260426156542, 1152233.377570225, 1152233.377570225, 258851.4676110432], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5401800.0000, 
sim time next is 5402400.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5018305935874474, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7989306484726515, 6.911199999999999, 6.9112, 121.9260426156618, 1144148.194400839, 1144148.19440084, 257610.3326020582], 
processed observation next is [1.0, 0.5217391304347826, 0.5555555555555556, 0.84, 1.0, 1.0, 0.40694118284219927, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7486633105908144, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4086243551431568, 0.40862435514315715, 0.4954044857731888], 
reward next is 0.5046, 
noisyNet noise sample is [array([1.9509624], dtype=float32), -1.0276709]. 
=============================================
[2019-03-24 02:22:31,633] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.5202763e-01 1.1036229e-05 2.4795845e-01 1.6000247e-07 2.7009589e-06], sum to 1.0000
[2019-03-24 02:22:31,643] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9408
[2019-03-24 02:22:31,649] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.6, 81.33333333333334, 1.0, 2.0, 0.96457047637054, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156507, 1814795.557307683, 1814795.557307683, 371275.3308910638], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5404800.0000, 
sim time next is 5405400.0000, 
raw observation next is [27.9, 80.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.199473956549381, 6.9112, 121.9249391421207, 2025852.470327609, 1878231.774971734, 383101.2191652498], 
processed observation next is [1.0, 0.5652173913043478, 0.5888888888888888, 0.8, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.028827395654938127, 0.0, 0.8094548029033547, 0.7235187394027175, 0.670797062489905, 0.7367331137793265], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7301763], dtype=float32), -0.48869]. 
=============================================
[2019-03-24 02:22:39,738] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0446376e-01 2.7725215e-13 8.9553624e-01 5.0048651e-19 1.0980510e-14], sum to 1.0000
[2019-03-24 02:22:39,747] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6354
[2019-03-24 02:22:39,752] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.55, 92.5, 1.0, 2.0, 0.3412538387503946, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5432872251522572, 6.9112, 6.9112, 121.9260426156618, 777855.562335317, 777855.562335317, 206665.5813582277], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5535000.0000, 
sim time next is 5535600.0000, 
raw observation next is [25.53333333333333, 92.66666666666667, 1.0, 2.0, 0.341275725539887, 0.0, 2.0, 0.0, 1.0, 2.0, 0.543322069633932, 6.911199999999999, 6.9112, 121.9260426156618, 777905.4764990462, 777905.4764990467, 206671.8369671257], 
processed observation next is [1.0, 0.043478260869565216, 0.5012345679012346, 0.9266666666666667, 1.0, 1.0, 0.21580443516653214, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.429152587042415, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27782338446394506, 0.2778233844639452, 0.39744584032139557], 
reward next is 0.6026, 
noisyNet noise sample is [array([-0.03892057], dtype=float32), 0.30982822]. 
=============================================
[2019-03-24 02:22:40,590] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7674817e-01 9.0819945e-08 8.2325172e-01 5.2084584e-13 7.1490375e-10], sum to 1.0000
[2019-03-24 02:22:40,595] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8896
[2019-03-24 02:22:40,598] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.96666666666667, 82.66666666666667, 1.0, 2.0, 0.772577143019352, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1595641.487128913, 1595641.487128913, 330846.8615709755], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5562600.0000, 
sim time next is 5563200.0000, 
raw observation next is [26.03333333333333, 82.33333333333334, 1.0, 2.0, 0.7365095172049818, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1554473.523737634, 1554473.523737634, 323964.6974273592], 
processed observation next is [1.0, 0.391304347826087, 0.519753086419753, 0.8233333333333335, 1.0, 1.0, 0.6863208538154545, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.5551691156205836, 0.5551691156205836, 0.6230090335141523], 
reward next is 0.3770, 
noisyNet noise sample is [array([-0.69067264], dtype=float32), 0.34105283]. 
=============================================
[2019-03-24 02:22:43,189] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999189e-01 5.5980689e-14 8.0650962e-06 6.1564126e-20 4.1242508e-16], sum to 1.0000
[2019-03-24 02:22:43,194] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8772
[2019-03-24 02:22:43,201] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 741108.5163858557 W.
[2019-03-24 02:22:43,205] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 96.0, 1.0, 2.0, 0.3251402929300455, 1.0, 1.0, 0.3251402929300455, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 741108.5163858557, 741108.5163858557, 186603.2097793446], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5608800.0000, 
sim time next is 5609400.0000, 
raw observation next is [24.28333333333333, 96.33333333333333, 1.0, 2.0, 0.6455336158280346, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 735695.9172341208, 735695.9172341203, 166086.84237053], 
processed observation next is [1.0, 0.9565217391304348, 0.4549382716049382, 0.9633333333333333, 1.0, 1.0, 0.5780162093190888, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26274854186932883, 0.26274854186932867, 0.3193977737894808], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9111845], dtype=float32), -0.48002487]. 
=============================================
[2019-03-24 02:22:44,272] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999964e-01 1.2807370e-16 3.7499478e-07 5.3883684e-21 3.8304007e-19], sum to 1.0000
[2019-03-24 02:22:44,278] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3937
[2019-03-24 02:22:44,281] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.5, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9310696405933325, 6.911200000000001, 6.9112, 121.9260426156618, 676671.8164635063, 676671.8164635058, 180960.7527422002], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5632800.0000, 
sim time next is 5633400.0000, 
raw observation next is [23.5, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9325266010432789, 6.9112, 6.9112, 121.9260426156618, 677731.2016692339, 677731.2016692339, 181159.988212416], 
processed observation next is [0.0, 0.17391304347826086, 0.42592592592592593, 0.97, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9156582513040986, 0.0, 0.0, 0.8094621288201359, 0.24204685773901208, 0.24204685773901208, 0.3483845927161846], 
reward next is 0.6516, 
noisyNet noise sample is [array([1.12778], dtype=float32), 1.7508264]. 
=============================================
[2019-03-24 02:22:45,868] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 02:22:45,868] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:22:45,868] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:22:45,869] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:22:45,870] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:22:45,871] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:22:45,871] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:22:45,870] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:22:45,872] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:22:45,872] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:22:45,875] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:22:45,895] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run24
[2019-03-24 02:22:45,895] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run24
[2019-03-24 02:22:45,955] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run24
[2019-03-24 02:22:45,984] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run24
[2019-03-24 02:22:46,009] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run24
[2019-03-24 02:22:48,664] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.18269205]
[2019-03-24 02:22:48,664] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.8589793, 74.98914671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9663817176761549, 6.9112, 6.9112, 121.9260426156618, 713879.0985349314, 713879.0985349314, 183259.502755802]
[2019-03-24 02:22:48,665] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:22:48,670] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9855071e-01 8.3446011e-13 1.4492244e-03 3.3125989e-17 5.2282533e-14], sampled 0.22854248354012818
[2019-03-24 02:22:48,671] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 713879.0985349314 W.
[2019-03-24 02:23:37,596] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.18269205]
[2019-03-24 02:23:37,596] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.0, 59.0, 1.0, 2.0, 0.6314531342314018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 722533.7688282294, 722533.7688282294, 163716.3560948353]
[2019-03-24 02:23:37,598] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:23:37,600] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9954116e-01 1.2078318e-14 4.5887291e-04 9.4853117e-20 4.4543091e-16], sampled 0.9384659254702339
[2019-03-24 02:23:37,601] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 722533.7688282294 W.
[2019-03-24 02:23:58,141] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.18269205]
[2019-03-24 02:23:58,142] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.33333333333334, 57.0, 1.0, 2.0, 0.7396273834494341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 842990.8213680394, 842990.8213680389, 183788.4892195319]
[2019-03-24 02:23:58,144] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:23:58,146] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9921405e-01 1.0788030e-13 7.8590889e-04 1.9618786e-18 5.0877436e-15], sampled 0.4434941346688115
[2019-03-24 02:23:58,149] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 842990.8213680394 W.
[2019-03-24 02:24:23,710] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8548.3512 2258721699.6498 536.0000
[2019-03-24 02:24:23,789] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8618.1811 2219609264.6265 543.0000
[2019-03-24 02:24:24,161] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8390.2490 2293350217.2924 697.0000
[2019-03-24 02:24:24,206] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8343.4620 2340067840.0842 616.0000
[2019-03-24 02:24:24,328] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7822.4022 2530348213.8182 830.0000
[2019-03-24 02:24:25,343] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 575000, evaluation results [575000.0, 7822.402199236487, 2530348213.818158, 830.0, 8548.351187378164, 2258721699.649805, 536.0, 8618.181125199215, 2219609264.6264997, 543.0, 8343.461962371874, 2340067840.084232, 616.0, 8390.249047606607, 2293350217.2924194, 697.0]
[2019-03-24 02:24:32,673] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.4299919e-25 7.4634873e-12 2.5352449e-30 3.8068444e-28], sum to 1.0000
[2019-03-24 02:24:32,678] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2724
[2019-03-24 02:24:32,682] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.7, 90.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7669539271542254, 6.9112, 6.9112, 121.9260426156618, 572586.5997612883, 572586.5997612883, 154044.3660581018], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5801400.0000, 
sim time next is 5802000.0000, 
raw observation next is [21.63333333333333, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7547642602726564, 6.9112, 6.9112, 121.9260426156618, 563491.4813876618, 563491.4813876618, 152598.7801357257], 
processed observation next is [1.0, 0.13043478260869565, 0.35679012345678995, 0.91, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6934553253408204, 0.0, 0.0, 0.8094621288201359, 0.20124695763845063, 0.20124695763845063, 0.2934591925687033], 
reward next is 0.7065, 
noisyNet noise sample is [array([0.74585927], dtype=float32), -0.6839036]. 
=============================================
[2019-03-24 02:24:32,716] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[74.297035]
 [74.63863 ]
 [74.47762 ]
 [74.51583 ]
 [73.89718 ]], R is [[74.51108551]
 [74.46973419]
 [74.42474365]
 [74.36185455]
 [74.3006897 ]].
[2019-03-24 02:24:34,963] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 7.0658112e-17 1.5135133e-09 8.3620430e-23 5.5698808e-21], sum to 1.0000
[2019-03-24 02:24:34,969] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3699
[2019-03-24 02:24:34,975] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1002177.096272006 W.
[2019-03-24 02:24:34,987] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.8, 62.33333333333334, 1.0, 2.0, 0.4127107832287045, 1.0, 1.0, 0.4127107832287045, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1002177.096272006, 1002177.096272006, 212203.2145354887], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5822400.0000, 
sim time next is 5823000.0000, 
raw observation next is [24.95, 60.5, 1.0, 2.0, 0.4167457430443028, 1.0, 2.0, 0.4167457430443028, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1012469.535479411, 1012469.535479411, 213370.9429234845], 
processed observation next is [1.0, 0.391304347826087, 0.47962962962962963, 0.605, 1.0, 1.0, 0.3056496941003604, 1.0, 1.0, 0.3056496941003604, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3615962626712182, 0.3615962626712182, 0.41032873639131634], 
reward next is 0.5897, 
noisyNet noise sample is [array([0.65831804], dtype=float32), 1.4073905]. 
=============================================
[2019-03-24 02:24:35,008] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[48.162113]
 [47.966526]
 [48.042534]
 [47.997517]
 [48.106796]], R is [[48.66802979]
 [48.18135071]
 [48.30181885]
 [48.38627243]
 [48.46338272]].
[2019-03-24 02:24:39,649] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.5877279e-20 4.1397772e-13 2.2636025e-26 2.5872798e-23], sum to 1.0000
[2019-03-24 02:24:39,656] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5284
[2019-03-24 02:24:39,662] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1317535.869362165 W.
[2019-03-24 02:24:39,664] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.93333333333334, 45.33333333333334, 1.0, 2.0, 0.5517972691414682, 1.0, 2.0, 0.5517972691414682, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1317535.869362165, 1317535.869362165, 254469.7593015985], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5923200.0000, 
sim time next is 5923800.0000, 
raw observation next is [29.1, 44.5, 1.0, 2.0, 0.5633800639024633, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9101592786901471, 6.911199999999999, 6.9112, 121.9260426156618, 1353811.580796868, 1353811.580796869, 278004.9326824243], 
processed observation next is [1.0, 0.5652173913043478, 0.6333333333333334, 0.445, 1.0, 1.0, 0.4802143617886468, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.8876990983626839, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4835041359988815, 0.4835041359988818, 0.5346248705431237], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7341679], dtype=float32), -0.7705296]. 
=============================================
[2019-03-24 02:24:44,908] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.000000e+00 8.021338e-27 5.814132e-16 9.973540e-35 7.374751e-30], sum to 1.0000
[2019-03-24 02:24:44,916] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6957
[2019-03-24 02:24:44,929] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.5, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8412495998967384, 6.9112, 6.9112, 121.9260426156618, 622110.8385706975, 622110.8385706975, 166595.1384040684], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6040200.0000, 
sim time next is 6040800.0000, 
raw observation next is [25.4, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.839241679941598, 6.9112, 6.9112, 121.9260426156618, 620756.4979903961, 620756.4979903961, 166297.5730581726], 
processed observation next is [1.0, 0.9565217391304348, 0.49629629629629624, 0.74, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7990520999269975, 0.0, 0.0, 0.8094621288201359, 0.22169874928228434, 0.22169874928228434, 0.31980302511187036], 
reward next is 0.6802, 
noisyNet noise sample is [array([-0.365608], dtype=float32), -0.92020804]. 
=============================================
[2019-03-24 02:24:45,298] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.4476269e-22 1.6947349e-16 2.3504060e-29 4.1594337e-26], sum to 1.0000
[2019-03-24 02:24:45,306] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9955
[2019-03-24 02:24:45,317] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1295894.328177461 W.
[2019-03-24 02:24:45,319] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.3, 70.0, 1.0, 2.0, 0.3778848936398418, 1.0, 1.0, 0.3778848936398418, 1.0, 2.0, 0.6016877936296126, 6.9112, 6.9112, 121.94756008, 1295894.328177461, 1295894.328177461, 287552.3380087094], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6001200.0000, 
sim time next is 6001800.0000, 
raw observation next is [26.58333333333334, 69.33333333333334, 1.0, 2.0, 0.5921187618712722, 0.0, 1.0, 0.0, 1.0, 2.0, 0.94391134748866, 6.911199999999999, 6.9112, 121.9260426156618, 1368934.47841446, 1368934.478414461, 290516.1366685758], 
processed observation next is [1.0, 0.4782608695652174, 0.5401234567901236, 0.6933333333333335, 1.0, 1.0, 0.5144270974658003, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.929889184360825, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.48890517086230717, 0.4889051708623075, 0.5586848782087996], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14764023], dtype=float32), 0.16931011]. 
=============================================
[2019-03-24 02:24:49,580] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.0622372e-20 2.4578074e-14 5.7483016e-24 2.6907674e-22], sum to 1.0000
[2019-03-24 02:24:49,587] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3271
[2019-03-24 02:24:49,594] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.53333333333333, 65.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8831906278172225, 6.911200000000001, 6.9112, 121.9260426156618, 648267.3397922558, 648267.3397922553, 173310.7156442229], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6119400.0000, 
sim time next is 6120000.0000, 
raw observation next is [27.4, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8842832273311084, 6.9112, 6.9112, 121.9260426156618, 649183.6720128149, 649183.6720128149, 173427.2093635456], 
processed observation next is [1.0, 0.8695652173913043, 0.5703703703703703, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8553540341638854, 0.0, 0.0, 0.8094621288201359, 0.2318513114331482, 0.2318513114331482, 0.33351386416066464], 
reward next is 0.6665, 
noisyNet noise sample is [array([0.2129243], dtype=float32), -0.45563912]. 
=============================================
[2019-03-24 02:24:49,609] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[44.77865 ]
 [44.7555  ]
 [44.515846]
 [44.48466 ]
 [44.27575 ]], R is [[45.04310608]
 [45.25938416]
 [45.4741745 ]
 [45.68772888]
 [45.8997612 ]].
[2019-03-24 02:24:50,112] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 4.9824155e-23 7.5604710e-16 4.7214723e-29 4.5712051e-27], sum to 1.0000
[2019-03-24 02:24:50,120] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4103
[2019-03-24 02:24:50,123] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.35, 61.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8730807147495672, 6.9112, 6.9112, 121.9260426156618, 639820.8303352107, 639820.8303352107, 172220.7418655571], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6115800.0000, 
sim time next is 6116400.0000, 
raw observation next is [28.2, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8729085561195985, 6.911199999999999, 6.9112, 121.9260426156618, 640149.1109863515, 640149.1109863519, 172098.9766176943], 
processed observation next is [1.0, 0.8260869565217391, 0.6, 0.62, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.841135695149498, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22862468249512555, 0.22862468249512566, 0.3309595704186429], 
reward next is 0.6690, 
noisyNet noise sample is [array([1.1518123], dtype=float32), -1.0623064]. 
=============================================
[2019-03-24 02:24:52,037] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.6828597e-19 1.0838694e-12 2.9800560e-22 4.7625905e-21], sum to 1.0000
[2019-03-24 02:24:52,044] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8163
[2019-03-24 02:24:52,048] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.4, 91.0, 1.0, 2.0, 0.5725235771255488, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683388.4864419341, 683388.4864419341, 154770.9425306843], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6152400.0000, 
sim time next is 6153000.0000, 
raw observation next is [22.5, 90.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8518104812818428, 6.9112, 6.9112, 121.9260426156618, 633031.1833635162, 633031.1833635162, 166604.4962834708], 
processed observation next is [1.0, 0.21739130434782608, 0.3888888888888889, 0.9066666666666667, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.8147631016023035, 0.0, 0.0, 0.8094621288201359, 0.2260825654869701, 0.2260825654869701, 0.3203932620835977], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.02104544], dtype=float32), -2.6407974]. 
=============================================
[2019-03-24 02:24:52,069] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[45.141155]
 [44.9139  ]
 [44.325203]
 [44.0538  ]
 [44.365345]], R is [[45.77748108]
 [46.02206802]
 [46.1398201 ]
 [46.25297546]
 [45.79044724]].
[2019-03-24 02:24:53,143] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 8.1786854e-16 1.9233760e-10 3.4345702e-20 2.0422676e-17], sum to 1.0000
[2019-03-24 02:24:53,151] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9664
[2019-03-24 02:24:53,153] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1770923.475039935 W.
[2019-03-24 02:24:53,159] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.9, 53.5, 1.0, 2.0, 0.9202054088303726, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9918028722933864, 6.911199999999999, 6.9112, 121.9260426156618, 1770923.475039935, 1770923.475039936, 360476.2696372073], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6190200.0000, 
sim time next is 6190800.0000, 
raw observation next is [29.9, 53.33333333333333, 1.0, 2.0, 0.8217404481234651, 1.0, 1.0, 0.8217404481234651, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1874367.85427138, 1874367.85427138, 352818.0875107583], 
processed observation next is [1.0, 0.6521739130434783, 0.6629629629629629, 0.5333333333333333, 1.0, 1.0, 0.7877862477660299, 1.0, 0.5, 0.7877862477660299, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6694170908112071, 0.6694170908112071, 0.6784963221360737], 
reward next is 0.3215, 
noisyNet noise sample is [array([-0.01852221], dtype=float32), -0.3002482]. 
=============================================
[2019-03-24 02:24:59,170] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 3.2740019e-21 1.0083435e-14 4.8455964e-25 5.5622103e-23], sum to 1.0000
[2019-03-24 02:24:59,177] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3915
[2019-03-24 02:24:59,183] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 744204.7131416472 W.
[2019-03-24 02:24:59,190] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.2, 60.66666666666667, 1.0, 2.0, 0.3264980021588069, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5197954527344018, 6.911199999999999, 6.9112, 121.9260426156618, 744204.7131416472, 744204.7131416476, 202502.380544722], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6280800.0000, 
sim time next is 6281400.0000, 
raw observation next is [30.25, 60.33333333333333, 1.0, 2.0, 0.2182118981241047, 1.0, 1.0, 0.2182118981241047, 1.0, 2.0, 0.3474004484789544, 6.9112, 6.9112, 121.94756008, 746074.2760058175, 746074.2760058175, 226636.0338191552], 
processed observation next is [0.0, 0.6956521739130435, 0.6759259259259259, 0.6033333333333333, 1.0, 1.0, 0.06929987871917224, 1.0, 0.5, 0.06929987871917224, 1.0, 1.0, 0.184250560598693, 0.0, 0.0, 0.8096049824067558, 0.26645509857350624, 0.26645509857350624, 0.4358385265752984], 
reward next is 0.5642, 
noisyNet noise sample is [array([-1.1427158], dtype=float32), 0.19705538]. 
=============================================
[2019-03-24 02:24:59,912] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.9064187e-23 2.1080195e-18 1.2993494e-30 8.6803414e-29], sum to 1.0000
[2019-03-24 02:24:59,920] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1911
[2019-03-24 02:24:59,923] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.66666666666667, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9393597049590806, 6.9112, 6.9112, 121.9260426156618, 685319.5204760162, 685319.5204760162, 181659.4289914585], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6297600.0000, 
sim time next is 6298200.0000, 
raw observation next is [26.5, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.93762290514367, 6.9112, 6.9112, 121.9260426156618, 684091.9976131736, 684091.9976131736, 181414.5456702373], 
processed observation next is [0.0, 0.9130434782608695, 0.5370370370370371, 0.74, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9220286314295875, 0.0, 0.0, 0.8094621288201359, 0.2443185705761334, 0.2443185705761334, 0.3488741262889179], 
reward next is 0.6511, 
noisyNet noise sample is [array([-1.7034044], dtype=float32), 0.28241056]. 
=============================================
[2019-03-24 02:25:02,803] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 5.9685898e-22 8.4826128e-17 2.8942738e-27 1.8266522e-24], sum to 1.0000
[2019-03-24 02:25:02,810] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3324
[2019-03-24 02:25:02,816] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 782014.2920650645 W.
[2019-03-24 02:25:02,820] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.65, 57.16666666666666, 1.0, 2.0, 0.3430773892497199, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5461903769360767, 6.911199999999999, 6.9112, 121.9260426156618, 782014.2920650645, 782014.292065065, 207186.369619444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6360600.0000, 
sim time next is 6361200.0000, 
raw observation next is [31.7, 57.0, 1.0, 2.0, 0.6859660741915264, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 781799.1150698224, 781799.1150698224, 173504.4548595018], 
processed observation next is [0.0, 0.6521739130434783, 0.7296296296296296, 0.57, 1.0, 1.0, 0.6261500883232457, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2792139696677937, 0.2792139696677937, 0.3336624131913496], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9391344], dtype=float32), -1.4674264]. 
=============================================
[2019-03-24 02:25:07,247] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.7798110e-12 3.2147960e-09 1.7036094e-15 3.6786137e-15], sum to 1.0000
[2019-03-24 02:25:07,252] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3455
[2019-03-24 02:25:07,262] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2147879.71895974 W.
[2019-03-24 02:25:07,264] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.66666666666667, 64.66666666666667, 1.0, 2.0, 0.941506582438473, 1.0, 2.0, 0.941506582438473, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9258302925613, 2147879.71895974, 2147879.71895974, 405697.1233126516], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6438000.0000, 
sim time next is 6438600.0000, 
raw observation next is [30.85, 63.5, 1.0, 2.0, 0.9103179506366162, 1.0, 2.0, 0.9103179506366162, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260425509185, 2076645.663365539, 2076645.66336554, 391448.6633319984], 
processed observation next is [1.0, 0.5217391304347826, 0.6981481481481482, 0.635, 1.0, 1.0, 0.8932356555197812, 1.0, 1.0, 0.8932356555197812, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621283903077, 0.7416591654876925, 0.7416591654876928, 0.7527858910230738], 
reward next is 0.2472, 
noisyNet noise sample is [array([-0.46742445], dtype=float32), 0.2660559]. 
=============================================
[2019-03-24 02:25:09,068] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 9.4245280e-17 1.6657906e-11 9.5452145e-20 4.4329341e-18], sum to 1.0000
[2019-03-24 02:25:09,074] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5316
[2019-03-24 02:25:09,084] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 763010.7949310116 W.
[2019-03-24 02:25:09,089] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.6, 61.0, 1.0, 2.0, 0.2231630295275044, 1.0, 2.0, 0.2231630295275044, 1.0, 1.0, 0.3552828109202593, 6.9112, 6.9112, 121.94756008, 763010.7949310116, 763010.7949310116, 228310.5370154441], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6462000.0000, 
sim time next is 6462600.0000, 
raw observation next is [30.53333333333334, 61.5, 1.0, 2.0, 0.3316492137373575, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5279963493307033, 6.9112, 6.9112, 121.9260426156618, 755951.9405034317, 755951.9405034317, 203946.5142095791], 
processed observation next is [1.0, 0.8260869565217391, 0.6864197530864199, 0.615, 1.0, 1.0, 0.20434430206828275, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.40999543666337906, 0.0, 0.0, 0.8094621288201359, 0.26998283589408273, 0.26998283589408273, 0.39220483501842135], 
reward next is 0.6078, 
noisyNet noise sample is [array([-0.13909636], dtype=float32), -0.02731866]. 
=============================================
[2019-03-24 02:25:09,912] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 7.8534783e-12 1.4641864e-08 8.5638402e-15 2.2906674e-13], sum to 1.0000
[2019-03-24 02:25:09,918] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7410
[2019-03-24 02:25:09,923] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1004357.234193338 W.
[2019-03-24 02:25:09,927] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.56666666666666, 83.66666666666667, 1.0, 2.0, 0.2937050728008813, 1.0, 1.0, 0.2937050728008813, 1.0, 1.0, 0.4675880412054353, 6.9112, 6.9112, 121.94756008, 1004357.234193338, 1004357.234193338, 253655.9521545721], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6493200.0000, 
sim time next is 6493800.0000, 
raw observation next is [26.53333333333333, 83.83333333333333, 1.0, 2.0, 0.4325515083165088, 0.0, 1.0, 0.0, 1.0, 2.0, 0.688636088459028, 6.911199999999999, 6.9112, 121.9260426156618, 986093.7682655642, 986093.7682655647, 234358.892364098], 
processed observation next is [1.0, 0.13043478260869565, 0.5382716049382715, 0.8383333333333333, 1.0, 1.0, 0.3244660813291771, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.610795110573785, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3521763458091301, 0.35217634580913026, 0.45069017762326535], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8965622], dtype=float32), 1.0825545]. 
=============================================
[2019-03-24 02:25:12,282] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.0777252e-14 1.0594121e-12 1.3565509e-18 2.1307225e-17], sum to 1.0000
[2019-03-24 02:25:12,291] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1641
[2019-03-24 02:25:12,301] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2025698.686217585 W.
[2019-03-24 02:25:12,306] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.61666666666667, 79.16666666666667, 1.0, 2.0, 0.8880101470026864, 1.0, 2.0, 0.8880101470026864, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2025698.686217585, 2025698.686217586, 381464.6256447175], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6520200.0000, 
sim time next is 6520800.0000, 
raw observation next is [28.53333333333333, 79.33333333333334, 1.0, 2.0, 0.9175298834727706, 1.0, 2.0, 0.9175298834727706, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2093117.031590623, 2093117.031590624, 394713.8437975068], 
processed observation next is [1.0, 0.4782608695652174, 0.6123456790123456, 0.7933333333333334, 1.0, 1.0, 0.9018212898485365, 1.0, 1.0, 0.9018212898485365, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7475417969966511, 0.7475417969966515, 0.7590650842259746], 
reward next is 0.2409, 
noisyNet noise sample is [array([0.46936005], dtype=float32), 0.020661866]. 
=============================================
[2019-03-24 02:25:15,457] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 9.3094311e-33 1.2737136e-28 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 02:25:15,463] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0118
[2019-03-24 02:25:15,466] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.7, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5977893222245791, 6.911200000000001, 6.9112, 121.9260426156618, 439855.6686070439, 439855.6686070435, 127934.3604682912], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6591600.0000, 
sim time next is 6592200.0000, 
raw observation next is [24.63333333333333, 50.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6229531084736578, 6.911200000000001, 6.9112, 121.9260426156618, 458345.2692086044, 458345.2692086039, 130228.7925516921], 
processed observation next is [1.0, 0.30434782608695654, 0.46790123456790106, 0.5033333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5286913855920722, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.163694739003073, 0.16369473900307283, 0.25043998567633097], 
reward next is 0.7496, 
noisyNet noise sample is [array([0.8720422], dtype=float32), 0.17517458]. 
=============================================
[2019-03-24 02:25:16,520] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 02:25:16,522] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:25:16,522] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:25:16,523] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:25:16,523] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:25:16,523] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:25:16,524] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:25:16,524] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:25:16,524] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:25:16,525] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:25:16,526] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:25:16,541] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run25
[2019-03-24 02:25:16,542] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run25
[2019-03-24 02:25:16,588] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run25
[2019-03-24 02:25:16,623] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run25
[2019-03-24 02:25:16,624] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run25
[2019-03-24 02:25:46,142] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.18540157]
[2019-03-24 02:25:46,143] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.59959641, 66.35254344166667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5605692428602784, 6.911200000000001, 6.9112, 121.9260426156618, 409832.9389862248, 409832.9389862243, 123390.5235022404]
[2019-03-24 02:25:46,144] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:25:46,146] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.8112307e-28 1.0150425e-23 5.9858112e-35 8.4665091e-33], sampled 0.40306798597253257
[2019-03-24 02:25:51,945] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.18540157]
[2019-03-24 02:25:51,947] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.75, 58.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.872093084598076, 6.911200000000001, 6.9112, 121.9260426156618, 640527.854151877, 640527.8541518765, 171768.1890302254]
[2019-03-24 02:25:51,948] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:25:51,952] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.7910546e-28 2.1122724e-23 1.9830215e-34 2.5068913e-32], sampled 0.3030031737749751
[2019-03-24 02:26:33,932] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.18540157]
[2019-03-24 02:26:33,933] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.56666666666667, 51.33333333333333, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9953227907816927, 7.210125914826163, 6.9112, 121.9248107784237, 2034336.810782927, 1881261.571254749, 382732.6464031473]
[2019-03-24 02:26:33,934] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:26:33,935] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.2215904e-22 4.1636237e-19 8.8536434e-28 3.3364918e-26], sampled 0.20647868130463287
[2019-03-24 02:26:33,936] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2034336.810782927 W.
[2019-03-24 02:26:54,493] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 02:26:55,084] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 02:26:55,093] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 02:26:55,133] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 02:26:55,165] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 02:26:56,180] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 600000, evaluation results [600000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 02:27:02,610] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 9.4999674e-32 6.8529382e-25 0.0000000e+00 1.1991115e-35], sum to 1.0000
[2019-03-24 02:27:02,614] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6908
[2019-03-24 02:27:02,618] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.3, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5722094429541205, 6.911200000000001, 6.9112, 121.9260426156618, 421795.8533348636, 421795.8533348631, 126033.4202435027], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6728400.0000, 
sim time next is 6729000.0000, 
raw observation next is [24.03333333333333, 54.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5758230259914953, 6.911200000000001, 6.9112, 121.9260426156618, 424588.0373353301, 424588.0373353297, 126423.9710608486], 
processed observation next is [1.0, 0.9130434782608695, 0.4456790123456789, 0.5466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.46977878248936905, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15163858476261788, 0.15163858476261774, 0.24312302127086272], 
reward next is 0.7569, 
noisyNet noise sample is [array([0.44653526], dtype=float32), -1.0771704]. 
=============================================
[2019-03-24 02:27:02,636] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.93618 ]
 [68.95725 ]
 [69.25388 ]
 [69.321365]
 [69.669136]], R is [[68.96422577]
 [69.0322113 ]
 [69.09988403]
 [69.16725159]
 [69.23422241]].
[2019-03-24 02:27:07,722] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 5.3053942e-30 3.9479720e-25 5.6611286e-38 9.5485598e-36], sum to 1.0000
[2019-03-24 02:27:07,728] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4342
[2019-03-24 02:27:07,736] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1321439.434182709 W.
[2019-03-24 02:27:07,741] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 53.0, 1.0, 2.0, 0.558264259965884, 1.0, 2.0, 0.558264259965884, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1321439.434182709, 1321439.434182709, 256178.2261166857], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6795600.0000, 
sim time next is 6796200.0000, 
raw observation next is [28.0, 53.5, 1.0, 2.0, 0.4031682436276944, 1.0, 2.0, 0.4031682436276944, 1.0, 1.0, 0.6440271461497916, 6.9112, 6.9112, 121.94756008, 1412863.327536026, 1412863.327536026, 298523.0160600648], 
processed observation next is [1.0, 0.6521739130434783, 0.5925925925925926, 0.535, 1.0, 1.0, 0.28948600431868377, 1.0, 1.0, 0.28948600431868377, 1.0, 0.5, 0.5550339326872394, 0.0, 0.0, 0.8096049824067558, 0.5045940455485807, 0.5045940455485807, 0.5740827231924323], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.28404856], dtype=float32), 0.6074386]. 
=============================================
[2019-03-24 02:27:10,332] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.00000000e+00 3.71209981e-34 1.17898274e-26 0.00000000e+00
 0.00000000e+00], sum to 1.0000
[2019-03-24 02:27:10,341] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2759
[2019-03-24 02:27:10,346] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.13333333333333, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6896038645625567, 6.9112, 6.9112, 121.9260426156618, 515324.5426450467, 515324.5426450467, 143869.4107719073], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6853200.0000, 
sim time next is 6853800.0000, 
raw observation next is [23.21666666666667, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6956923052316633, 6.9112, 6.9112, 121.9260426156618, 519850.5378490128, 519850.5378490128, 144736.3672609034], 
processed observation next is [0.0, 0.30434782608695654, 0.4154320987654322, 0.76, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6196153815395791, 0.0, 0.0, 0.8094621288201359, 0.18566090637464744, 0.18566090637464744, 0.27833916780942963], 
reward next is 0.7217, 
noisyNet noise sample is [array([-1.3217672], dtype=float32), 0.22619604]. 
=============================================
[2019-03-24 02:27:11,489] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.6043991e-28 3.4063832e-22 3.4815744e-33 3.7553612e-31], sum to 1.0000
[2019-03-24 02:27:11,500] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0904
[2019-03-24 02:27:11,506] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.6, 48.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8460204460248467, 6.911199999999999, 6.9112, 121.9260426156618, 623533.1086701693, 623533.1086701697, 167855.5637208887], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6877800.0000, 
sim time next is 6878400.0000, 
raw observation next is [30.46666666666667, 48.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8418120073941867, 6.911200000000001, 6.9112, 121.9260426156618, 621018.083184703, 621018.0831847026, 167152.046389151], 
processed observation next is [0.0, 0.6086956521739131, 0.6839506172839507, 0.4866666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8022650092427333, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22179217256596537, 0.2217921725659652, 0.32144624305605957], 
reward next is 0.6786, 
noisyNet noise sample is [array([-0.74980104], dtype=float32), 0.055972017]. 
=============================================
[2019-03-24 02:27:11,910] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 3.3593020e-33 8.3177679e-28 0.0000000e+00 4.0680804e-38], sum to 1.0000
[2019-03-24 02:27:11,924] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8718
[2019-03-24 02:27:11,933] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.55, 61.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7124820758212475, 6.911199999999999, 6.9112, 121.9260426156618, 532394.6054271165, 532394.605427117, 146627.9892694213], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6900600.0000, 
sim time next is 6901200.0000, 
raw observation next is [25.4, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7118995152564724, 6.9112, 6.9112, 121.9260426156618, 531971.3705828723, 531971.3705828723, 146490.3563729688], 
processed observation next is [0.0, 0.9130434782608695, 0.49629629629629624, 0.62, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6398743940705905, 0.0, 0.0, 0.8094621288201359, 0.18998977520816868, 0.18998977520816868, 0.28171222379417077], 
reward next is 0.7183, 
noisyNet noise sample is [array([0.3288404], dtype=float32), -0.6228538]. 
=============================================
[2019-03-24 02:27:13,973] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 6.8389909e-33 5.4692873e-26 0.0000000e+00 4.4697876e-38], sum to 1.0000
[2019-03-24 02:27:13,981] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1220
[2019-03-24 02:27:13,987] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.11666666666667, 80.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6873476775532341, 6.911200000000001, 6.9112, 121.9260426156618, 513558.8855140111, 513558.8855140107, 142765.5618578029], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6923400.0000, 
sim time next is 6924000.0000, 
raw observation next is [22.03333333333333, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6869723720106041, 6.9112, 6.9112, 121.9260426156618, 513268.1903908714, 513268.1903908714, 142687.0557374282], 
processed observation next is [0.0, 0.13043478260869565, 0.37160493827160485, 0.81, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6087154650132551, 0.0, 0.0, 0.8094621288201359, 0.18331006799673977, 0.18331006799673977, 0.2743981841104388], 
reward next is 0.7256, 
noisyNet noise sample is [array([-0.4500811], dtype=float32), 0.22488979]. 
=============================================
[2019-03-24 02:27:14,004] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[77.67393]
 [77.73911]
 [77.81868]
 [77.92197]
 [77.97827]], R is [[77.48374176]
 [77.43435669]
 [77.38527679]
 [77.33646393]
 [77.28800201]].
[2019-03-24 02:27:22,123] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 9.8933137e-29 1.9366070e-24 2.8075887e-37 1.1185965e-32], sum to 1.0000
[2019-03-24 02:27:22,133] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8767
[2019-03-24 02:27:22,142] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.93333333333333, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6649414680372538, 6.9112, 6.9112, 121.9260426156618, 496111.1239663675, 496111.1239663675, 139007.2554047664], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7105200.0000, 
sim time next is 7105800.0000, 
raw observation next is [20.91666666666667, 85.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6565123099160861, 6.911199999999999, 6.9112, 121.9260426156618, 489743.1032359574, 489743.1032359579, 138038.2857268002], 
processed observation next is [1.0, 0.21739130434782608, 0.3302469135802471, 0.8516666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5706403873951076, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17490825115569908, 0.17490825115569925, 0.2654582417823081], 
reward next is 0.7345, 
noisyNet noise sample is [array([1.2453071], dtype=float32), -0.6978805]. 
=============================================
[2019-03-24 02:27:30,467] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.6835258e-28 2.8126176e-21 4.4854086e-34 6.1075630e-31], sum to 1.0000
[2019-03-24 02:27:30,485] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9667
[2019-03-24 02:27:30,493] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1218085.022861916 W.
[2019-03-24 02:27:30,498] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.98333333333333, 73.33333333333334, 1.0, 2.0, 0.5116971849546609, 1.0, 2.0, 0.5116971849546609, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156508, 1218085.022861916, 1218085.022861916, 241280.9500651713], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7225800.0000, 
sim time next is 7226400.0000, 
raw observation next is [23.96666666666667, 72.66666666666667, 1.0, 2.0, 0.4990456966099745, 1.0, 2.0, 0.4990456966099745, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1191877.242989517, 1191877.242989517, 237431.9574030136], 
processed observation next is [1.0, 0.6521739130434783, 0.4432098765432099, 0.7266666666666667, 1.0, 1.0, 0.4036258292975887, 1.0, 1.0, 0.4036258292975887, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4256704439248275, 0.4256704439248275, 0.45659991808271844], 
reward next is 0.5434, 
noisyNet noise sample is [array([0.71104604], dtype=float32), -1.3547335]. 
=============================================
[2019-03-24 02:27:31,739] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.9416759e-30 1.4303797e-24 1.0619685e-36 7.2331202e-33], sum to 1.0000
[2019-03-24 02:27:31,749] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0428
[2019-03-24 02:27:31,754] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.65, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6427511669547732, 6.911200000000001, 6.9112, 121.9260426156618, 479969.4109619543, 479969.4109619539, 137400.0636029207], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7281000.0000, 
sim time next is 7281600.0000, 
raw observation next is [20.7, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.646858005786912, 6.911200000000001, 6.9112, 121.9260426156618, 483099.5897598541, 483099.5897598536, 137948.6204491528], 
processed observation next is [1.0, 0.2608695652173913, 0.3222222222222222, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5585725072336399, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17253556777137646, 0.1725355677713763, 0.2652858085560631], 
reward next is 0.7347, 
noisyNet noise sample is [array([0.32245243], dtype=float32), -0.67311734]. 
=============================================
[2019-03-24 02:27:35,653] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.1610045e-31 9.1793753e-26 2.3532595e-36 4.3769892e-36], sum to 1.0000
[2019-03-24 02:27:35,659] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8300
[2019-03-24 02:27:35,664] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.43333333333334, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7145445922177373, 6.911199999999999, 6.9112, 121.9260426156618, 533964.8015422927, 533964.8015422932, 146656.3591386538], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7335600.0000, 
sim time next is 7336200.0000, 
raw observation next is [22.26666666666667, 81.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7079494171995265, 6.911200000000001, 6.9112, 121.9260426156618, 529046.1721444415, 529046.172144441, 145734.5155631217], 
processed observation next is [1.0, 0.9130434782608695, 0.38024691358024704, 0.8133333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6349367714994081, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1889450614801577, 0.18894506148015752, 0.28025868377523405], 
reward next is 0.7197, 
noisyNet noise sample is [array([0.2701511], dtype=float32), 1.2043921]. 
=============================================
[2019-03-24 02:27:35,998] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.5236600e-31 3.4420097e-26 4.4762033e-38 2.7186973e-37], sum to 1.0000
[2019-03-24 02:27:36,005] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6720
[2019-03-24 02:27:36,012] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.1, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6732522464219808, 6.911200000000001, 6.9112, 121.9260426156618, 502825.8711200712, 502825.8711200707, 140712.9692599761], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7342200.0000, 
sim time next is 7342800.0000, 
raw observation next is [21.06666666666667, 86.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6713368159608132, 6.911200000000001, 6.9112, 121.9260426156618, 501325.623466861, 501325.6234668606, 140369.1811886601], 
processed observation next is [1.0, 1.0, 0.3358024691358026, 0.8633333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5891710199510164, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17904486552387894, 0.1790448655238788, 0.26994073305511557], 
reward next is 0.7301, 
noisyNet noise sample is [array([0.829476], dtype=float32), -0.8040962]. 
=============================================
[2019-03-24 02:27:36,320] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.9732578e-30 2.7000509e-23 3.5846567e-34 8.6858133e-35], sum to 1.0000
[2019-03-24 02:27:36,332] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7310
[2019-03-24 02:27:36,336] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.55, 75.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.727527473404245, 6.9112, 6.9112, 121.9260426156618, 543408.8420226715, 543408.8420226715, 149011.173834173], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7331400.0000, 
sim time next is 7332000.0000, 
raw observation next is [23.4, 76.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7281567747339183, 6.911200000000001, 6.9112, 121.9260426156618, 543909.8304822808, 543909.8304822803, 149017.8070812856], 
processed observation next is [1.0, 0.8695652173913043, 0.42222222222222217, 0.7633333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6601959684173977, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19425351088652887, 0.1942535108865287, 0.28657270592554923], 
reward next is 0.7134, 
noisyNet noise sample is [array([0.8723336], dtype=float32), 1.177174]. 
=============================================
[2019-03-24 02:27:36,358] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[68.689896]
 [68.618996]
 [68.73972 ]
 [68.985214]
 [68.86126 ]], R is [[68.64690399]
 [68.6738739 ]
 [68.70069122]
 [68.72728729]
 [68.75328064]].
[2019-03-24 02:27:42,050] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 5.5602301e-33 1.1995608e-26 0.0000000e+00 2.3923772e-38], sum to 1.0000
[2019-03-24 02:27:42,056] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5467
[2019-03-24 02:27:42,061] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.98333333333333, 96.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.60331854086073, 6.911200000000001, 6.9112, 121.9260426156618, 448484.7091140824, 448484.709114082, 131194.68171301], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7449000.0000, 
sim time next is 7449600.0000, 
raw observation next is [19.06666666666667, 96.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6045480826553152, 6.9112, 6.9112, 121.9260426156618, 449545.1044042325, 449545.1044042325, 131428.691907833], 
processed observation next is [0.0, 0.21739130434782608, 0.2617283950617285, 0.9633333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.505685103319144, 0.0, 0.0, 0.8094621288201359, 0.1605518230015116, 0.1605518230015116, 0.2527474844381404], 
reward next is 0.7473, 
noisyNet noise sample is [array([-0.37781203], dtype=float32), 0.16093208]. 
=============================================
[2019-03-24 02:27:43,105] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.8798525e-26 7.3710436e-21 5.3325140e-33 5.9245329e-31], sum to 1.0000
[2019-03-24 02:27:43,111] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0678
[2019-03-24 02:27:43,116] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.1, 96.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6115757494744706, 6.9112, 6.9112, 121.9260426156618, 454979.6374893068, 454979.6374893068, 132274.4002328724], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7446000.0000, 
sim time next is 7446600.0000, 
raw observation next is [19.05, 96.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6094884404593325, 6.911200000000001, 6.9112, 121.9260426156618, 453326.4991697329, 453326.4991697324, 131989.6469420881], 
processed observation next is [0.0, 0.17391304347826086, 0.2611111111111111, 0.965, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5118605505741656, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16190232113204747, 0.16190232113204728, 0.2538262441194002], 
reward next is 0.7462, 
noisyNet noise sample is [array([-1.291299], dtype=float32), -1.0639867]. 
=============================================
[2019-03-24 02:27:44,118] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.6348935e-35 1.0638263e-27 0.0000000e+00 5.0764447e-37], sum to 1.0000
[2019-03-24 02:27:44,123] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5762
[2019-03-24 02:27:44,127] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.16666666666667, 92.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7760676258186133, 6.911199999999999, 6.9112, 121.9260426156618, 577167.7908125118, 577167.7908125123, 156988.7627471227], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7509000.0000, 
sim time next is 7509600.0000, 
raw observation next is [22.1, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.774544539162665, 6.911200000000001, 6.9112, 121.9260426156618, 576138.363140538, 576138.3631405375, 156743.7901639503], 
processed observation next is [0.0, 0.9565217391304348, 0.3740740740740741, 0.93, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7181806739533311, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2057637011216207, 0.20576370112162054, 0.3014303656999044], 
reward next is 0.6986, 
noisyNet noise sample is [array([0.18123941], dtype=float32), 0.06873817]. 
=============================================
[2019-03-24 02:27:47,266] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 02:27:47,268] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:27:47,268] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:27:47,269] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:27:47,270] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:27:47,270] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:27:47,271] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:27:47,271] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:27:47,271] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:27:47,272] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:27:47,273] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:27:47,288] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run26
[2019-03-24 02:27:47,288] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run26
[2019-03-24 02:27:47,288] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run26
[2019-03-24 02:27:47,288] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run26
[2019-03-24 02:27:47,388] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run26
[2019-03-24 02:27:52,298] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.19514799]
[2019-03-24 02:27:52,299] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.83333333333334, 31.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5880262866468067, 6.911200000000001, 6.9112, 121.9260426156618, 425478.4019685152, 425478.4019685148, 124007.9457184774]
[2019-03-24 02:27:52,300] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:27:52,302] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.1817288e-27 1.4358589e-22 5.0571048e-34 2.2967798e-31], sampled 0.7014091676357607
[2019-03-24 02:28:02,859] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.19514799]
[2019-03-24 02:28:02,859] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.01921745, 72.664193445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6032237344832548, 6.9112, 6.9112, 121.9260426156618, 448555.156302749, 448555.156302749, 131298.1003787663]
[2019-03-24 02:28:02,862] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:28:02,865] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 4.1788799e-28 6.2083372e-23 1.3936022e-34 7.0851905e-32], sampled 0.9524924084229242
[2019-03-24 02:28:05,760] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.19514799]
[2019-03-24 02:28:05,761] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.14949667, 42.2814183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5946385405607669, 6.911199999999999, 6.9112, 121.9260426156618, 433075.0246255366, 433075.024625537, 125659.9114590199]
[2019-03-24 02:28:05,762] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:28:05,766] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 7.1085720e-27 6.1650815e-22 4.6704808e-33 1.7655974e-30], sampled 0.13435963514184934
[2019-03-24 02:28:10,529] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.19514799]
[2019-03-24 02:28:10,530] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.77837469666667, 42.89519819, 1.0, 2.0, 0.8064211375359405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1003033.599278364, 1003033.599278364, 200648.8084291549]
[2019-03-24 02:28:10,533] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:28:10,535] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.5715565e-26 2.3226957e-21 4.7964945e-32 1.2446109e-29], sampled 0.8531733519078784
[2019-03-24 02:28:10,537] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1003033.599278364 W.
[2019-03-24 02:28:25,647] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.19514799]
[2019-03-24 02:28:25,648] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.629446025, 102.61463325, 1.0, 2.0, 0.5776839180427212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 674860.8494052463, 674860.8494052463, 155055.227941419]
[2019-03-24 02:28:25,650] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:28:25,652] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.2894139e-24 4.2751906e-20 2.9280398e-30 6.6538020e-28], sampled 0.9813704964339492
[2019-03-24 02:28:29,807] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.19514799]
[2019-03-24 02:28:29,808] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.17261996333334, 66.28355370833333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.914940994369229, 6.9112, 6.9112, 121.9260426156618, 665888.6847584856, 665888.6847584856, 178618.1651578562]
[2019-03-24 02:28:29,808] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:28:29,809] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.9908116e-28 3.3861185e-23 5.5675258e-35 3.0282515e-32], sampled 0.6571962060462462
[2019-03-24 02:29:12,159] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.19514799]
[2019-03-24 02:29:12,162] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.3, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8722733626870011, 6.911199999999999, 6.9112, 121.9260426156618, 641131.950622645, 641131.9506226454, 171677.2154721009]
[2019-03-24 02:29:12,164] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:29:12,168] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.7143679e-28 3.0000380e-23 4.6234299e-35 2.5601021e-32], sampled 0.2707942177056155
[2019-03-24 02:29:21,517] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.19514799]
[2019-03-24 02:29:21,518] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.5756461, 90.17526223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5772665627921252, 6.9112, 6.9112, 121.9260426156618, 428534.6885549639, 428534.6885549639, 128304.3676265742]
[2019-03-24 02:29:21,520] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:29:21,523] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.1670579e-27 3.1696401e-22 1.7164706e-33 6.9769718e-31], sampled 0.6548291242381428
[2019-03-24 02:29:25,195] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 02:29:25,355] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 02:29:25,452] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 02:29:25,555] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 02:29:25,746] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 02:29:26,760] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 625000, evaluation results [625000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 02:29:29,114] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.3328806e-36 8.1757036e-28 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 02:29:29,119] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9467
[2019-03-24 02:29:29,122] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.13333333333333, 63.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8145747101356187, 6.911199999999999, 6.9112, 121.9260426156618, 603236.615391143, 603236.6153911435, 162931.696875512], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7578600.0000, 
sim time next is 7579200.0000, 
raw observation next is [26.96666666666667, 64.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8160673554186533, 6.911200000000001, 6.9112, 121.9260426156618, 604120.487263188, 604120.4872631875, 163204.1034168853], 
processed observation next is [0.0, 0.7391304347826086, 0.554320987654321, 0.6433333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7700841942733166, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21575731687971, 0.21575731687970984, 0.3138540450324717], 
reward next is 0.6861, 
noisyNet noise sample is [array([1.0738736], dtype=float32), -1.6026344]. 
=============================================
[2019-03-24 02:29:29,506] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.00000000e+00 4.81637957e-28 1.07560506e-23 1.63307461e-35
 5.36342396e-32], sum to 1.0000
[2019-03-24 02:29:29,514] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4470
[2019-03-24 02:29:29,518] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.96666666666667, 77.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8277063287896634, 6.9112, 6.9112, 121.9260426156618, 611864.2530964919, 611864.2530964919, 164982.9432526759], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7586400.0000, 
sim time next is 7587000.0000, 
raw observation next is [24.8, 78.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8278606236295073, 6.911199999999999, 6.9112, 121.9260426156618, 611921.5841124976, 611921.5841124981, 165021.3189536419], 
processed observation next is [0.0, 0.8260869565217391, 0.4740740740740741, 0.785, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.784825779536884, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2185434228973206, 0.21854342289732076, 0.3173486902954652], 
reward next is 0.6827, 
noisyNet noise sample is [array([-1.033764], dtype=float32), 0.023308152]. 
=============================================
[2019-03-24 02:29:29,547] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[63.988377]
 [63.98357 ]
 [63.97052 ]
 [63.93719 ]
 [63.894253]], R is [[64.04897308]
 [64.09120941]
 [64.13312531]
 [64.17476654]
 [64.21603394]].
[2019-03-24 02:29:30,469] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 9.3575274e-34 9.8916205e-28 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 02:29:30,477] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0828
[2019-03-24 02:29:30,483] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.6, 87.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6949647930979467, 6.9112, 6.9112, 121.9260426156618, 518377.9952963831, 518377.9952963831, 141969.7537546807], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7614600.0000, 
sim time next is 7615200.0000, 
raw observation next is [20.5, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6572152992256485, 6.9112, 6.9112, 121.9260426156618, 490128.5602775866, 490128.5602775866, 137938.2540066995], 
processed observation next is [1.0, 0.13043478260869565, 0.3148148148148148, 0.88, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5715191240320605, 0.0, 0.0, 0.8094621288201359, 0.17504591438485237, 0.17504591438485237, 0.26526587308980676], 
reward next is 0.7347, 
noisyNet noise sample is [array([0.02557536], dtype=float32), -0.31523767]. 
=============================================
[2019-03-24 02:29:37,540] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.5232269e-35 4.7111320e-27 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 02:29:37,546] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6281
[2019-03-24 02:29:37,552] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.670469500102278, 6.911199999999999, 6.9112, 121.9260426156618, 500729.4896970252, 500729.4896970257, 140383.0492987827], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7761600.0000, 
sim time next is 7762200.0000, 
raw observation next is [23.86666666666667, 66.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6676879149630595, 6.911200000000001, 6.9112, 121.9260426156618, 498545.5111330266, 498545.5111330262, 139884.1674932623], 
processed observation next is [1.0, 0.8695652173913043, 0.4395061728395063, 0.665, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5846098937038243, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17805196826179523, 0.1780519682617951, 0.2690080144101198], 
reward next is 0.7310, 
noisyNet noise sample is [array([1.3748801], dtype=float32), 0.40339592]. 
=============================================
[2019-03-24 02:29:39,400] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 5.6119057e-25 2.7587759e-20 6.4455248e-34 1.3108798e-30], sum to 1.0000
[2019-03-24 02:29:39,406] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7295
[2019-03-24 02:29:39,410] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.66666666666666, 70.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6342729936669065, 6.911200000000001, 6.9112, 121.9260426156618, 472471.0058132405, 472471.0058132401, 135031.6727708299], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7767600.0000, 
sim time next is 7768200.0000, 
raw observation next is [22.53333333333333, 70.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6299678716677308, 6.911199999999999, 6.9112, 121.9260426156618, 469047.4860167534, 469047.4860167538, 134400.1672197467], 
processed observation next is [1.0, 0.9130434782608695, 0.3901234567901234, 0.7066666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5374598395846635, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16751695929169766, 0.1675169592916978, 0.25846186003797444], 
reward next is 0.7415, 
noisyNet noise sample is [array([0.31930956], dtype=float32), 0.21677224]. 
=============================================
[2019-03-24 02:29:43,020] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 4.4820229e-26 7.7870633e-22 1.0511484e-33 2.9125107e-30], sum to 1.0000
[2019-03-24 02:29:43,026] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4233
[2019-03-24 02:29:43,031] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.76666666666667, 56.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7134764327689593, 6.911200000000001, 6.9112, 121.9260426156618, 532945.2151819244, 532945.2151819239, 147347.6375228316], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7845600.0000, 
sim time next is 7846200.0000, 
raw observation next is [26.45, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7145024773373281, 6.911200000000001, 6.9112, 121.9260426156618, 533705.5357258641, 533705.5357258637, 147476.8686265252], 
processed observation next is [1.0, 0.8260869565217391, 0.5351851851851852, 0.58, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6431280966716602, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19060911990209434, 0.19060911990209417, 0.28360936274331766], 
reward next is 0.7164, 
noisyNet noise sample is [array([1.206], dtype=float32), 1.5911853]. 
=============================================
[2019-03-24 02:29:47,112] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.6607436e-18 1.0914023e-15 2.5607990e-22 1.3607729e-21], sum to 1.0000
[2019-03-24 02:29:47,119] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4260
[2019-03-24 02:29:47,128] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1756553.728911272 W.
[2019-03-24 02:29:47,132] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.65, 47.5, 1.0, 2.0, 0.5064993991539248, 1.0, 1.0, 0.5064993991539248, 1.0, 1.0, 0.8073995498385694, 6.911200000000001, 6.9112, 121.94756008, 1756553.728911272, 1756553.728911272, 346907.9375028646], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7911000.0000, 
sim time next is 7911600.0000, 
raw observation next is [29.8, 47.0, 1.0, 2.0, 0.7698555459732916, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9738349938008277, 6.9112, 6.9112, 121.926042325212, 1618317.610873605, 1618317.610873605, 325797.6152541186], 
processed observation next is [1.0, 0.5652173913043478, 0.6592592592592593, 0.47, 1.0, 1.0, 0.7260185071110614, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9672937422510347, 0.0, 0.0, 0.8094621268918513, 0.5779705753120018, 0.5779705753120018, 0.6265338754886896], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1090205], dtype=float32), 0.29399097]. 
=============================================
[2019-03-24 02:29:47,791] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 6.1610106e-23 1.9367292e-20 9.5124924e-29 2.0684621e-25], sum to 1.0000
[2019-03-24 02:29:47,798] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9713
[2019-03-24 02:29:47,802] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1659477.232477088 W.
[2019-03-24 02:29:47,806] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.1, 47.83333333333333, 1.0, 2.0, 0.4845631579702345, 1.0, 2.0, 0.4845631579702345, 1.0, 2.0, 0.7714780353979402, 6.9112, 6.9112, 121.94756008, 1659477.232477088, 1659477.232477088, 336090.3172360541], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7919400.0000, 
sim time next is 7920000.0000, 
raw observation next is [30.1, 48.0, 1.0, 2.0, 0.7983208505166501, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9795522744602809, 6.911199999999999, 6.9112, 121.9260426156618, 1644436.130179965, 1644436.130179966, 332690.1314290069], 
processed observation next is [1.0, 0.6956521739130435, 0.6703703703703704, 0.48, 1.0, 1.0, 0.7599057744245835, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9744403430753512, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.587298617921416, 0.5872986179214165, 0.6397887142865518], 
reward next is 0.3602, 
noisyNet noise sample is [array([2.9987228], dtype=float32), 1.5401767]. 
=============================================
[2019-03-24 02:29:47,828] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[53.967495]
 [53.570583]
 [52.935722]
 [52.63491 ]
 [52.340656]], R is [[54.36299896]
 [54.1730423 ]
 [53.98757553]
 [53.79951096]
 [53.62693405]].
[2019-03-24 02:29:48,509] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:29:48,510] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:48,533] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run4
[2019-03-24 02:29:48,892] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:29:48,893] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:48,896] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run4
[2019-03-24 02:29:49,092] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:29:49,092] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:49,095] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run4
[2019-03-24 02:29:49,151] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:29:49,151] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:49,153] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run4
[2019-03-24 02:29:49,207] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:29:49,207] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:49,208] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run4
[2019-03-24 02:29:49,340] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:29:49,341] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:49,342] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run4
[2019-03-24 02:29:49,397] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:29:49,397] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:49,398] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run4
[2019-03-24 02:29:49,421] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:29:49,421] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:49,423] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run4
[2019-03-24 02:29:49,644] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:29:49,645] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:49,646] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run4
[2019-03-24 02:29:49,727] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:29:49,727] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:49,728] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run4
[2019-03-24 02:29:49,755] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:29:49,755] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:49,759] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run4
[2019-03-24 02:29:49,785] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:29:49,785] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:49,786] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:29:49,788] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:49,794] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run4
[2019-03-24 02:29:49,829] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run4
[2019-03-24 02:29:49,885] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:29:49,885] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:49,887] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run4
[2019-03-24 02:29:49,957] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:29:49,957] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:49,959] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run4
[2019-03-24 02:29:50,138] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:29:50,138] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:29:50,140] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run4
[2019-03-24 02:29:54,509] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.7414065e-25 1.2112848e-21 2.7324926e-31 3.3457127e-30], sum to 1.0000
[2019-03-24 02:29:54,517] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1858
[2019-03-24 02:29:54,525] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1340326.753478245 W.
[2019-03-24 02:29:54,529] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.83333333333333, 38.33333333333334, 1.0, 2.0, 0.3731811595240818, 1.0, 2.0, 0.3731811595240818, 1.0, 1.0, 0.6016993168374242, 6.911200000000001, 6.9112, 121.94756008, 1340326.753478245, 1340326.753478244, 285123.1259123533], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 58800.0000, 
sim time next is 59400.0000, 
raw observation next is [29.8, 38.5, 1.0, 2.0, 0.5541872403252885, 1.0, 2.0, 0.5541872403252885, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1336670.124941705, 1336670.124941705, 255748.2287835513], 
processed observation next is [1.0, 0.6956521739130435, 0.6592592592592593, 0.385, 1.0, 1.0, 0.46927052419677207, 1.0, 1.0, 0.46927052419677207, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4773821874791804, 0.4773821874791804, 0.4918235168914448], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.21444751], dtype=float32), -1.0560083]. 
=============================================
[2019-03-24 02:29:58,760] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 5.4482054e-29 3.0926561e-26 2.3277249e-36 5.1732454e-32], sum to 1.0000
[2019-03-24 02:29:58,768] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0089
[2019-03-24 02:29:58,775] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1586910.017632645 W.
[2019-03-24 02:29:58,779] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [37.4, 13.5, 1.0, 2.0, 0.4361700505049756, 1.0, 2.0, 0.4361700505049756, 1.0, 1.0, 0.7088365175645136, 6.911200000000001, 6.9112, 121.94756008, 1586910.017632645, 1586910.017632645, 312513.8871729159], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 138600.0000, 
sim time next is 139200.0000, 
raw observation next is [37.4, 13.0, 1.0, 2.0, 0.4710175184794534, 1.0, 2.0, 0.4710175184794534, 1.0, 2.0, 0.7646827052812246, 6.911199999999999, 6.9112, 121.94756008, 1711329.627241103, 1711329.627241103, 328850.454516569], 
processed observation next is [1.0, 0.6086956521739131, 0.9407407407407407, 0.13, 1.0, 1.0, 0.37025895057077785, 1.0, 1.0, 0.37025895057077785, 1.0, 1.0, 0.7058533816015308, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6111891525861082, 0.6111891525861082, 0.6324047202241712], 
reward next is 0.3676, 
noisyNet noise sample is [array([0.4025319], dtype=float32), -0.14836772]. 
=============================================
[2019-03-24 02:30:02,175] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.0180773e-26 1.7176283e-20 5.8662416e-31 1.8949259e-29], sum to 1.0000
[2019-03-24 02:30:02,186] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2124
[2019-03-24 02:30:02,190] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.08333333333333, 64.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.542981732296773, 6.911199999999999, 6.9112, 121.9260426156618, 398701.8434196074, 398701.8434196078, 122684.7408286031], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 198600.0000, 
sim time next is 199200.0000, 
raw observation next is [22.26666666666667, 65.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5577699437539203, 6.9112, 6.9112, 121.9260426156618, 410959.4815183475, 410959.4815183475, 124654.070675244], 
processed observation next is [0.0, 0.30434782608695654, 0.38024691358024704, 0.6533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4472124296924003, 0.0, 0.0, 0.8094621288201359, 0.14677124339940983, 0.14677124339940983, 0.23971936668316154], 
reward next is 0.7603, 
noisyNet noise sample is [array([0.53114873], dtype=float32), -0.77151924]. 
=============================================
[2019-03-24 02:30:09,067] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 7.0682463e-37 5.2861673e-28 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 02:30:09,071] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3402
[2019-03-24 02:30:09,076] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.4, 32.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5845247803146731, 6.9112, 6.9112, 121.9260426156618, 422117.0136226642, 422117.0136226642, 123406.8684349549], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 324000.0000, 
sim time next is 324600.0000, 
raw observation next is [27.3, 32.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5835687223191702, 6.911200000000001, 6.9112, 121.9260426156618, 421341.1647495357, 421341.1647495353, 123295.2498597159], 
processed observation next is [0.0, 0.782608695652174, 0.5666666666666667, 0.3233333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.47946090289896276, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15047898741054846, 0.15047898741054833, 0.23710624973022287], 
reward next is 0.7629, 
noisyNet noise sample is [array([-0.35545573], dtype=float32), -0.94318014]. 
=============================================
[2019-03-24 02:30:11,236] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.5113050e-26 2.3741513e-21 7.5989809e-32 2.0147763e-30], sum to 1.0000
[2019-03-24 02:30:11,246] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8117
[2019-03-24 02:30:11,250] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.6, 54.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6005922793605889, 6.9112, 6.9112, 121.9260426156618, 428848.7857002051, 428848.7857002051, 112669.1783758799], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 367800.0000, 
sim time next is 368400.0000, 
raw observation next is [21.0, 52.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5621302915844634, 6.9112, 6.9112, 121.9260426156618, 401378.0806720078, 401378.0806720078, 110643.9945895118], 
processed observation next is [1.0, 0.2608695652173913, 0.3333333333333333, 0.5266666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4526628644805792, 0.0, 0.0, 0.8094621288201359, 0.1433493145257171, 0.1433493145257171, 0.21277691267213808], 
reward next is 0.7872, 
noisyNet noise sample is [array([0.4104092], dtype=float32), -0.24261609]. 
=============================================
[2019-03-24 02:30:15,282] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 4.1056367e-23 1.1521993e-18 3.9660668e-27 5.1008762e-25], sum to 1.0000
[2019-03-24 02:30:15,292] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4722
[2019-03-24 02:30:15,298] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.35, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5098320742085148, 6.911200000000001, 6.9112, 121.9260426156618, 364026.7041998394, 364026.704199839, 112131.6911179622], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 448200.0000, 
sim time next is 448800.0000, 
raw observation next is [18.2, 76.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5057979336088597, 6.9112, 6.9112, 121.9260426156618, 361145.59734834, 361145.59734834, 111111.1038635922], 
processed observation next is [1.0, 0.17391304347826086, 0.2296296296296296, 0.7666666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3822474170110746, 0.0, 0.0, 0.8094621288201359, 0.12898057048154998, 0.12898057048154998, 0.21367519973767732], 
reward next is 0.7863, 
noisyNet noise sample is [array([1.846428], dtype=float32), -0.03439378]. 
=============================================
[2019-03-24 02:30:15,381] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.1206973e-25 8.5103726e-21 9.0572978e-31 1.0728900e-27], sum to 1.0000
[2019-03-24 02:30:15,389] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0225
[2019-03-24 02:30:15,394] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.45, 65.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8446434041949201, 6.911200000000001, 6.9112, 121.9260426156618, 607661.9530161567, 607661.9530161562, 147217.3523962665], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 439800.0000, 
sim time next is 440400.0000, 
raw observation next is [20.3, 66.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6771201101691172, 6.9112, 6.9112, 121.9260426156618, 486698.5514011913, 486698.5514011913, 130763.5688362177], 
processed observation next is [1.0, 0.08695652173913043, 0.3074074074074074, 0.6633333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5964001377113964, 0.0, 0.0, 0.8094621288201359, 0.17382091121471116, 0.17382091121471116, 0.25146840160811096], 
reward next is 0.7485, 
noisyNet noise sample is [array([0.23939441], dtype=float32), -1.0951806]. 
=============================================
[2019-03-24 02:30:19,697] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 02:30:19,699] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:30:19,700] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:30:19,700] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:30:19,701] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:30:19,701] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:30:19,702] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:30:19,703] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:30:19,704] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:30:19,704] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:30:19,707] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:30:19,721] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run27
[2019-03-24 02:30:19,743] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run27
[2019-03-24 02:30:19,745] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run27
[2019-03-24 02:30:19,789] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run27
[2019-03-24 02:30:19,813] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run27
[2019-03-24 02:30:55,160] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.20384872]
[2019-03-24 02:30:55,161] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.3, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9101138804469266, 6.911200000000001, 6.9112, 121.9260426156618, 661938.7249147543, 661938.7249147538, 178037.4655048712]
[2019-03-24 02:30:55,164] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:30:55,167] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.00000000e+00 7.76552889e-29 1.11595064e-23 6.80780149e-35
 6.88367317e-32], sampled 0.2614572432462007
[2019-03-24 02:30:57,408] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.20384872]
[2019-03-24 02:30:57,409] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.345930855, 68.07671782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8751111440347338, 6.911200000000001, 6.9112, 121.9260426156618, 642017.4412084884, 642017.4412084881, 172329.20288653]
[2019-03-24 02:30:57,410] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:30:57,414] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.8179988e-28 3.2458569e-23 3.2807437e-34 2.9177023e-31], sampled 0.6111001497740377
[2019-03-24 02:31:22,397] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.20384872]
[2019-03-24 02:31:22,398] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.01380478, 100.2171181, 1.0, 2.0, 0.948437705907031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1081150.414776827, 1081150.414776827, 228534.5478289949]
[2019-03-24 02:31:22,399] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:31:22,401] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 5.5878822e-22 4.6490611e-18 1.5583038e-26 2.8398898e-24], sampled 0.4464299348159544
[2019-03-24 02:31:22,403] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1081150.414776827 W.
[2019-03-24 02:31:26,236] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.20384872]
[2019-03-24 02:31:26,237] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.0, 94.0, 1.0, 2.0, 0.905024736505644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9259774753312, 1043965.276391734, 1043965.276391734, 219261.4383322211]
[2019-03-24 02:31:26,238] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:31:26,243] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.9364634e-22 2.5919787e-18 6.9881197e-27 1.2850584e-24], sampled 0.9982091266527371
[2019-03-24 02:31:26,244] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1043965.276391734 W.
[2019-03-24 02:31:32,465] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.20384872]
[2019-03-24 02:31:32,467] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [34.11666666666667, 38.33333333333334, 1.0, 2.0, 0.687073794241378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 800304.1338193013, 800304.1338193013, 174548.7736142355]
[2019-03-24 02:31:32,469] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:31:32,470] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.3923704e-24 8.1918455e-20 4.1526892e-29 1.1926891e-26], sampled 0.04512347721076304
[2019-03-24 02:31:32,470] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 800304.1338193013 W.
[2019-03-24 02:31:40,475] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.20384872]
[2019-03-24 02:31:40,475] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.41666666666667, 56.16666666666666, 1.0, 2.0, 0.6137730146918045, 0.0, 2.0, 0.0, 1.0, 2.0, 0.977146628580923, 6.9112, 6.9112, 121.9260424215003, 1399604.377592408, 1399604.377592408, 299255.7759741069]
[2019-03-24 02:31:40,476] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:31:40,479] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 6.8775592e-24 1.2000776e-19 7.2078494e-29 1.9843160e-26], sampled 0.7310887770436628
[2019-03-24 02:31:40,479] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1399604.377592408 W.
[2019-03-24 02:31:55,587] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.20384872]
[2019-03-24 02:31:55,594] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.08333333333334, 72.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4678172464858477, 6.9112, 6.9112, 121.9260426156618, 334021.0402701686, 334021.0402701686, 111674.9782454193]
[2019-03-24 02:31:55,594] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:31:55,598] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.8599995e-26 1.4093828e-21 9.0941644e-32 4.8468434e-29], sampled 0.1728443634062291
[2019-03-24 02:31:57,575] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 02:31:58,392] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 02:31:58,472] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 02:31:58,508] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 02:31:58,526] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 02:31:59,539] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 650000, evaluation results [650000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 02:32:11,556] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 5.1337522e-24 3.3489732e-20 1.1021979e-28 4.3989392e-26], sum to 1.0000
[2019-03-24 02:32:11,563] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9651
[2019-03-24 02:32:11,573] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1280990.221682139 W.
[2019-03-24 02:32:11,582] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.96666666666667, 24.0, 1.0, 2.0, 0.51601716327749, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8575551405879348, 6.9112, 6.9112, 121.9260426156414, 1280990.221682139, 1280990.221682139, 258316.5038617085], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 750000.0000, 
sim time next is 750600.0000, 
raw observation next is [31.95, 24.0, 1.0, 2.0, 0.5145088607873802, 1.0, 1.0, 0.5145088607873802, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1274926.434877983, 1274926.434877984, 243744.5025070659], 
processed observation next is [1.0, 0.6956521739130435, 0.7388888888888888, 0.24, 1.0, 1.0, 0.42203435808021456, 1.0, 0.5, 0.42203435808021456, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.45533086959927965, 0.45533086959928, 0.4687394278982036], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6646441], dtype=float32), 1.1535892]. 
=============================================
[2019-03-24 02:32:11,849] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.9996130e-24 4.8132081e-18 2.1391712e-29 7.5221385e-27], sum to 1.0000
[2019-03-24 02:32:11,857] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7273
[2019-03-24 02:32:11,865] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1275039.561720707 W.
[2019-03-24 02:32:11,878] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.18333333333334, 23.0, 1.0, 2.0, 0.3454479353639301, 1.0, 2.0, 0.3454479353639301, 1.0, 1.0, 0.5684601912798327, 6.9112, 6.9112, 121.94756008, 1275039.561720707, 1275039.561720707, 272379.3200631127], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 742200.0000, 
sim time next is 742800.0000, 
raw observation next is [32.16666666666667, 23.0, 1.0, 2.0, 0.5037930879557074, 1.0, 2.0, 0.5037930879557074, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1247432.142894355, 1247432.142894355, 240287.7573059832], 
processed observation next is [1.0, 0.6086956521739131, 0.7469135802469138, 0.23, 1.0, 1.0, 0.4092774856615564, 1.0, 1.0, 0.4092774856615564, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4455114796051268, 0.4455114796051268, 0.4620918409730446], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.18087754], dtype=float32), -1.9157691]. 
=============================================
[2019-03-24 02:32:15,071] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.0801095e-34 3.2835099e-27 0.0000000e+00 1.5837483e-35], sum to 1.0000
[2019-03-24 02:32:15,079] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3470
[2019-03-24 02:32:15,083] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.73333333333333, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5923803960601757, 6.9112, 6.9112, 121.9260426156618, 438676.9477939233, 438676.9477939233, 128993.0030111595], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 805800.0000, 
sim time next is 806400.0000, 
raw observation next is [23.8, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.595836555166231, 6.9112, 6.9112, 121.9260426156618, 441489.2453051695, 441489.2453051695, 129473.0126240474], 
processed observation next is [0.0, 0.34782608695652173, 0.43703703703703706, 0.59, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4947956939577887, 0.0, 0.0, 0.8094621288201359, 0.15767473046613195, 0.15767473046613195, 0.2489865627385527], 
reward next is 0.7510, 
noisyNet noise sample is [array([-2.0934496], dtype=float32), -1.1738325]. 
=============================================
[2019-03-24 02:32:16,663] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.1482415e-33 2.2331358e-28 2.0127641e-37 2.0550095e-36], sum to 1.0000
[2019-03-24 02:32:16,672] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6727
[2019-03-24 02:32:16,682] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.4, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6516960204270491, 6.9112, 6.9112, 121.9260426156618, 485984.3245050904, 485984.3245050904, 137343.2382926488], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 853200.0000, 
sim time next is 853800.0000, 
raw observation next is [27.25, 46.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6545550049978994, 6.9112, 6.9112, 121.9260426156618, 488175.4217870397, 488175.4217870397, 137704.3910159404], 
processed observation next is [0.0, 0.9130434782608695, 0.5648148148148148, 0.46833333333333343, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5681937562473742, 0.0, 0.0, 0.8094621288201359, 0.17434836492394276, 0.17434836492394276, 0.2648161365691162], 
reward next is 0.7352, 
noisyNet noise sample is [array([-0.681623], dtype=float32), 1.2266868]. 
=============================================
[2019-03-24 02:32:17,418] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.3403831e-26 3.0267441e-21 7.0862414e-33 9.3515515e-30], sum to 1.0000
[2019-03-24 02:32:17,424] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0100
[2019-03-24 02:32:17,431] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.93333333333334, 62.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.649245973704891, 6.911200000000001, 6.9112, 121.9260426156618, 483727.6433094683, 483727.6433094678, 136628.0734603229], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 866400.0000, 
sim time next is 867000.0000, 
raw observation next is [23.76666666666667, 63.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.646293760414891, 6.911199999999999, 6.9112, 121.9260426156618, 481392.2799525637, 481392.2799525642, 136197.5344515373], 
processed observation next is [0.0, 0.0, 0.43580246913580256, 0.6333333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5578672005186136, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17192581426877274, 0.17192581426877293, 0.26191833548372556], 
reward next is 0.7381, 
noisyNet noise sample is [array([-2.4304674], dtype=float32), -0.15399732]. 
=============================================
[2019-03-24 02:32:17,451] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[59.30713 ]
 [59.128456]
 [58.960827]
 [58.773777]
 [58.674175]], R is [[59.61951828]
 [59.76057816]
 [59.89936829]
 [60.03587341]
 [60.17018127]].
[2019-03-24 02:32:22,271] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.8112577e-30 7.9218139e-26 4.6623186e-37 9.4271791e-34], sum to 1.0000
[2019-03-24 02:32:22,278] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8577
[2019-03-24 02:32:22,284] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.26666666666667, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5110471859146893, 6.9112, 6.9112, 121.9260426156618, 368755.2394148224, 368755.2394148224, 117299.5451179575], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 948000.0000, 
sim time next is 948600.0000, 
raw observation next is [23.15, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5079817779571804, 6.9112, 6.9112, 121.9260426156618, 366404.236453061, 366404.236453061, 117008.1317727833], 
processed observation next is [0.0, 1.0, 0.4129629629629629, 0.505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3849772224464754, 0.0, 0.0, 0.8094621288201359, 0.13085865587609322, 0.13085865587609322, 0.22501563802458327], 
reward next is 0.7750, 
noisyNet noise sample is [array([1.1718249], dtype=float32), -0.3225888]. 
=============================================
[2019-03-24 02:32:27,704] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 6.1541099e-29 4.1804350e-24 3.5406630e-35 1.8680892e-30], sum to 1.0000
[2019-03-24 02:32:27,713] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3310
[2019-03-24 02:32:27,717] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.5, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4937541502388819, 6.9112, 6.9112, 121.9260426156618, 355915.0330477285, 355915.0330477285, 115819.2178766023], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1036800.0000, 
sim time next is 1037400.0000, 
raw observation next is [22.4, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4978416277645797, 6.9112, 6.9112, 121.9260426156618, 359264.1537263697, 359264.1537263697, 116282.1332536731], 
processed observation next is [1.0, 0.0, 0.38518518518518513, 0.55, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3723020347057246, 0.0, 0.0, 0.8094621288201359, 0.12830862633084633, 0.12830862633084633, 0.22361948702629444], 
reward next is 0.7764, 
noisyNet noise sample is [array([-0.34789157], dtype=float32), -0.0056712506]. 
=============================================
[2019-03-24 02:32:35,728] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.00000000e+00 1.04371544e-35 6.24328084e-28 0.00000000e+00
 0.00000000e+00], sum to 1.0000
[2019-03-24 02:32:35,735] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3245
[2019-03-24 02:32:35,742] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.8, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5909196301984995, 6.911199999999999, 6.9112, 121.9260426156618, 437154.4758556151, 437154.4758556156, 128589.3625632822], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1197000.0000, 
sim time next is 1197600.0000, 
raw observation next is [19.73333333333333, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5943556065242911, 6.9112, 6.9112, 121.9260426156618, 439767.5672368614, 439767.5672368614, 128948.5620197579], 
processed observation next is [1.0, 0.8695652173913043, 0.28641975308641965, 0.8566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.49294450815536384, 0.0, 0.0, 0.8094621288201359, 0.1570598454417362, 0.1570598454417362, 0.2479780038841498], 
reward next is 0.7520, 
noisyNet noise sample is [array([0.2074663], dtype=float32), -1.8463794]. 
=============================================
[2019-03-24 02:32:38,391] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.1148937e-26 6.6331136e-23 8.0837243e-35 3.3702415e-31], sum to 1.0000
[2019-03-24 02:32:38,397] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7526
[2019-03-24 02:32:38,403] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.85, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5324898786306256, 6.9112, 6.9112, 121.9260426156618, 388848.9943779763, 388848.9943779763, 120818.8897971844], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1225800.0000, 
sim time next is 1226400.0000, 
raw observation next is [17.83333333333334, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5305875858659511, 6.9112, 6.9112, 121.9260426156618, 387355.9842235419, 387355.9842235419, 120616.4175673662], 
processed observation next is [1.0, 0.17391304347826086, 0.2160493827160496, 0.93, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.41323448233243887, 0.0, 0.0, 0.8094621288201359, 0.13834142293697926, 0.13834142293697926, 0.23195464916801192], 
reward next is 0.7680, 
noisyNet noise sample is [array([-0.99637246], dtype=float32), -0.566887]. 
=============================================
[2019-03-24 02:32:39,232] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 9.4207150e-25 3.1343162e-21 8.1180776e-30 3.2064322e-27], sum to 1.0000
[2019-03-24 02:32:39,237] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0948
[2019-03-24 02:32:39,243] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.63333333333333, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5863275498420011, 6.911199999999999, 6.9112, 121.9260426156618, 433693.5042375665, 433693.504237567, 128129.7785118048], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1302000.0000, 
sim time next is 1302600.0000, 
raw observation next is [19.56666666666667, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.583383173974521, 6.9112, 6.9112, 121.9260426156618, 431215.9328493635, 431215.9328493635, 127685.2208459874], 
processed observation next is [1.0, 0.043478260869565216, 0.28024691358024706, 0.86, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4792289674681512, 0.0, 0.0, 0.8094621288201359, 0.1540056903033441, 0.1540056903033441, 0.24554850162689884], 
reward next is 0.7545, 
noisyNet noise sample is [array([0.19102104], dtype=float32), 0.93948627]. 
=============================================
[2019-03-24 02:32:40,540] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.000000e+00 7.479775e-31 6.725388e-26 0.000000e+00 6.133072e-34], sum to 1.0000
[2019-03-24 02:32:40,546] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7039
[2019-03-24 02:32:40,551] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.3, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6794465758636089, 6.9112, 6.9112, 121.9260426156618, 507627.6089707423, 507627.6089707423, 141826.0140953615], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1284600.0000, 
sim time next is 1285200.0000, 
raw observation next is [23.1, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.676159279896425, 6.911199999999999, 6.9112, 121.9260426156618, 505133.4675446501, 505133.4675446505, 141358.3537802082], 
processed observation next is [1.0, 0.9130434782608695, 0.41111111111111115, 0.73, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5951990998705312, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18040480983737503, 0.18040480983737517, 0.271842988038862], 
reward next is 0.7282, 
noisyNet noise sample is [array([-0.09618608], dtype=float32), 0.4508756]. 
=============================================
[2019-03-24 02:32:46,293] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.2063305e-33 6.8572240e-26 0.0000000e+00 1.3786264e-36], sum to 1.0000
[2019-03-24 02:32:46,301] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9982
[2019-03-24 02:32:46,311] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.71666666666667, 65.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6018025849407413, 6.911200000000001, 6.9112, 121.9260426156618, 446213.079922707, 446213.0799227065, 130227.2117803501], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1378200.0000, 
sim time next is 1378800.0000, 
raw observation next is [22.5, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5997726724689316, 6.9112, 6.9112, 121.9260426156618, 444588.2323553088, 444588.2323553088, 129958.0039199905], 
processed observation next is [1.0, 1.0, 0.3888888888888889, 0.67, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4997158405861645, 0.0, 0.0, 0.8094621288201359, 0.1587815115554674, 0.1587815115554674, 0.24991923830767404], 
reward next is 0.7501, 
noisyNet noise sample is [array([1.7734903], dtype=float32), 0.590623]. 
=============================================
[2019-03-24 02:32:50,535] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 02:32:50,536] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:32:50,537] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:32:50,537] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:32:50,541] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:32:50,538] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:32:50,540] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:32:50,540] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:32:50,542] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:32:50,543] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:32:50,543] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:32:50,550] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run28
[2019-03-24 02:32:50,592] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run28
[2019-03-24 02:32:50,593] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run28
[2019-03-24 02:32:50,614] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run28
[2019-03-24 02:32:50,635] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run28
[2019-03-24 02:33:23,066] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.20986815]
[2019-03-24 02:33:23,067] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.00924003333333, 93.65619041333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6687776455926492, 6.9112, 6.9112, 121.9260426156618, 499763.8161247736, 499763.8161247736, 141481.8804032187]
[2019-03-24 02:33:23,068] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:33:23,072] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.2942945e-30 7.5516447e-25 1.3937283e-36 2.1332506e-33], sampled 0.727854292137974
[2019-03-24 02:33:23,547] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.20986815]
[2019-03-24 02:33:23,548] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.83333333333334, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8233216398516381, 6.9112, 6.9112, 121.9260426156618, 611981.4234870921, 611981.4234870921, 163018.1439708571]
[2019-03-24 02:33:23,549] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:33:23,551] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.000000e+00 7.226815e-30 1.445271e-24 3.633860e-36 5.116270e-33], sampled 0.5875512264485151
[2019-03-24 02:33:23,731] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.20986815]
[2019-03-24 02:33:23,732] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.73003502666667, 98.66414239666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8387100607322747, 6.911200000000001, 6.9112, 121.9260426156618, 621210.725883421, 621210.7258834206, 165916.941643381]
[2019-03-24 02:33:23,733] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:33:23,737] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.8193658e-27 1.9299421e-22 5.2435563e-33 3.8202825e-30], sampled 0.03857184274146008
[2019-03-24 02:33:32,597] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.20986815]
[2019-03-24 02:33:32,597] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.23771715, 100.1883356033333, 1.0, 2.0, 0.5990099769543885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 690457.1250451786, 690457.1250451781, 158287.1119377085]
[2019-03-24 02:33:32,598] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:33:32,599] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.6573012e-24 7.0429272e-20 3.2931028e-29 1.0992430e-26], sampled 0.2742838264107639
[2019-03-24 02:33:32,601] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 690457.1250451786 W.
[2019-03-24 02:33:43,170] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.20986815]
[2019-03-24 02:33:43,172] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.46672587, 98.98271575333334, 1.0, 2.0, 0.9540924061134409, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260408899666, 1802833.797867865, 1802833.797867865, 368902.592333321]
[2019-03-24 02:33:43,173] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:33:43,174] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.8187466e-24 3.8091260e-20 1.4096298e-29 4.8614027e-27], sampled 0.5415939056787926
[2019-03-24 02:33:43,175] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1802833.797867865 W.
[2019-03-24 02:34:19,777] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.20986815]
[2019-03-24 02:34:19,780] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.0, 65.0, 1.0, 2.0, 0.9394245566755396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1091769.287096721, 1091769.287096721, 227559.1350715222]
[2019-03-24 02:34:19,781] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:34:19,783] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.4775825e-23 2.1480707e-19 1.8139205e-28 5.0197235e-26], sampled 0.28009692083962234
[2019-03-24 02:34:19,784] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1091769.287096721 W.
[2019-03-24 02:34:29,247] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 02:34:29,269] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 02:34:29,270] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 02:34:29,355] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 02:34:29,390] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 02:34:30,404] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 675000, evaluation results [675000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 02:34:31,069] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.6156401e-25 7.6314132e-21 1.9605039e-32 4.8623462e-28], sum to 1.0000
[2019-03-24 02:34:31,077] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7637
[2019-03-24 02:34:31,081] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.73333333333333, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5880350318487954, 6.911200000000001, 6.9112, 121.9260426156618, 434446.66292571, 434446.6629257095, 127990.9867348824], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1470000.0000, 
sim time next is 1470600.0000, 
raw observation next is [25.45, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5874259180609007, 6.9112, 6.9112, 121.9260426156618, 433708.5133276218, 433708.5133276218, 127774.1870287386], 
processed observation next is [0.0, 0.0, 0.4981481481481481, 0.48, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.48428239757612584, 0.0, 0.0, 0.8094621288201359, 0.15489589761700778, 0.15489589761700778, 0.24571959043988192], 
reward next is 0.7543, 
noisyNet noise sample is [array([-0.7508255], dtype=float32), -0.16874304]. 
=============================================
[2019-03-24 02:34:32,878] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.2484220e-33 1.3246604e-27 2.9460888e-38 1.0714449e-37], sum to 1.0000
[2019-03-24 02:34:32,885] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6316
[2019-03-24 02:34:32,890] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [34.85, 24.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.674870088001989, 6.9112, 6.9112, 121.9260426156618, 504312.7229098885, 504312.7229098885, 141912.8103619872], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1515000.0000, 
sim time next is 1515600.0000, 
raw observation next is [35.0, 24.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.676339914948356, 6.911199999999999, 6.9112, 121.9260426156618, 505403.7672326127, 505403.7672326132, 141982.4840743811], 
processed observation next is [0.0, 0.5652173913043478, 0.8518518518518519, 0.24, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5954248936854449, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1805013454402188, 0.18050134544021898, 0.273043238604579], 
reward next is 0.7270, 
noisyNet noise sample is [array([1.2175486], dtype=float32), 1.0662862]. 
=============================================
[2019-03-24 02:34:33,249] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.7623470e-34 3.0823960e-27 0.0000000e+00 2.2151737e-36], sum to 1.0000
[2019-03-24 02:34:33,256] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6849
[2019-03-24 02:34:33,262] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [35.8, 20.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6899540220589477, 6.911200000000001, 6.9112, 121.9260426156618, 514950.3441350584, 514950.3441350579, 141862.1647863052], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1519200.0000, 
sim time next is 1519800.0000, 
raw observation next is [35.63333333333333, 21.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7127000949041425, 6.9112, 6.9112, 121.9260426156618, 532126.7258112546, 532126.7258112546, 144608.1207590796], 
processed observation next is [0.0, 0.6086956521739131, 0.8753086419753087, 0.21166666666666673, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6408751186301781, 0.0, 0.0, 0.8094621288201359, 0.1900452592183052, 0.1900452592183052, 0.27809253992130695], 
reward next is 0.7219, 
noisyNet noise sample is [array([0.42785394], dtype=float32), 1.0884321]. 
=============================================
[2019-03-24 02:34:33,812] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.0448125e-32 2.0515579e-26 0.0000000e+00 1.2742971e-35], sum to 1.0000
[2019-03-24 02:34:33,820] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0036
[2019-03-24 02:34:33,824] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.53333333333334, 36.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8030067889156888, 6.911200000000001, 6.9112, 121.9260426156618, 594454.5911940134, 594454.5911940129, 161549.0452945043], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1527000.0000, 
sim time next is 1527600.0000, 
raw observation next is [33.36666666666667, 37.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8136429970947743, 6.911199999999999, 6.9112, 121.9260426156618, 601149.6201116801, 601149.6201116806, 163300.0244894749], 
processed observation next is [0.0, 0.6956521739130435, 0.7913580246913581, 0.3766666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7670537463684679, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21469629289702863, 0.2146962928970288, 0.31403850863360555], 
reward next is 0.6860, 
noisyNet noise sample is [array([0.2546944], dtype=float32), -0.17019686]. 
=============================================
[2019-03-24 02:34:40,995] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 2.2013748e-29 1.7083848e-24 3.0328728e-34 4.1005939e-32], sum to 1.0000
[2019-03-24 02:34:41,004] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9723
[2019-03-24 02:34:41,009] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.15, 88.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5596594184399089, 6.911199999999999, 6.9112, 121.9260426156618, 407448.5366169081, 407448.5366169085, 122591.0048395988], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1663800.0000, 
sim time next is 1664400.0000, 
raw observation next is [18.2, 88.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5428093631382933, 6.9112, 6.9112, 121.9260426156618, 395375.6128228477, 395375.6128228477, 121258.0578925442], 
processed observation next is [1.0, 0.2608695652173913, 0.2296296296296296, 0.8866666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4285117039228666, 0.0, 0.0, 0.8094621288201359, 0.1412055760081599, 0.1412055760081599, 0.2331885728702773], 
reward next is 0.7668, 
noisyNet noise sample is [array([0.09362759], dtype=float32), -1.0790596]. 
=============================================
[2019-03-24 02:34:49,441] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.7587218e-36 5.2085943e-31 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 02:34:49,453] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5281
[2019-03-24 02:34:49,460] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.8, 72.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6673968649868729, 6.911200000000001, 6.9112, 121.9260426156618, 498226.4236044976, 498226.4236044972, 139677.9090272048], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1794000.0000, 
sim time next is 1794600.0000, 
raw observation next is [22.35, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6505595314824687, 6.911199999999999, 6.9112, 121.9260426156618, 485157.6145745868, 485157.6145745873, 137252.6576549523], 
processed observation next is [1.0, 0.782608695652174, 0.38333333333333336, 0.735, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5631994143530858, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.173270576633781, 0.17327057663378118, 0.26394741856721593], 
reward next is 0.7361, 
noisyNet noise sample is [array([-0.02993597], dtype=float32), 0.20228252]. 
=============================================
[2019-03-24 02:34:51,193] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.2925263e-24 1.3207598e-20 4.3160857e-30 3.9945813e-27], sum to 1.0000
[2019-03-24 02:34:51,199] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7155
[2019-03-24 02:34:51,205] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 871478.3485273985 W.
[2019-03-24 02:34:51,209] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.7, 77.0, 1.0, 2.0, 0.3542951577658796, 1.0, 2.0, 0.3542951577658796, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 871478.3485273985, 871478.3485273985, 196488.8754283306], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1848600.0000, 
sim time next is 1849200.0000, 
raw observation next is [21.73333333333333, 77.0, 1.0, 2.0, 0.3559365445809951, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5871293331436538, 6.911199999999999, 6.9112, 121.9260426156618, 877642.5560647104, 877642.5560647108, 207790.5314780384], 
processed observation next is [1.0, 0.391304347826087, 0.3604938271604937, 0.77, 1.0, 1.0, 0.23325779116785134, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4839116664295672, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31344377002311086, 0.313443770023111, 0.3995971759193046], 
reward next is 0.6004, 
noisyNet noise sample is [array([-0.37649378], dtype=float32), -0.47289267]. 
=============================================
[2019-03-24 02:35:01,029] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.1734319e-27 1.3101910e-21 4.6066549e-34 1.1364991e-30], sum to 1.0000
[2019-03-24 02:35:01,037] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3841
[2019-03-24 02:35:01,043] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.25, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7714713724951292, 6.911200000000001, 6.9112, 121.9260426156618, 573243.596312825, 573243.5963128245, 156704.102655904], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2029800.0000, 
sim time next is 2030400.0000, 
raw observation next is [26.4, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.780696329988872, 6.9112, 6.9112, 121.9260426156618, 579452.9529284044, 579452.9529284044, 158143.1660933926], 
processed observation next is [0.0, 0.5217391304347826, 0.5333333333333333, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7258704124860899, 0.0, 0.0, 0.8094621288201359, 0.20694748318871586, 0.20694748318871586, 0.3041214732565242], 
reward next is 0.6959, 
noisyNet noise sample is [array([-0.6063891], dtype=float32), 2.5045083]. 
=============================================
[2019-03-24 02:35:02,300] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.6241574e-30 3.0548905e-25 1.7913466e-34 5.8894647e-33], sum to 1.0000
[2019-03-24 02:35:02,310] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4396
[2019-03-24 02:35:02,313] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.53333333333333, 65.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7886011914243943, 6.9112, 6.9112, 121.9260426156618, 584752.217192639, 584752.217192639, 159367.015281823], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2031000.0000, 
sim time next is 2031600.0000, 
raw observation next is [26.66666666666667, 65.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7960386876900275, 6.9112, 6.9112, 121.9260426156618, 589735.301661165, 589735.301661165, 160507.3744330475], 
processed observation next is [0.0, 0.5217391304347826, 0.5432098765432101, 0.6566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7450483596125342, 0.0, 0.0, 0.8094621288201359, 0.2106197505932732, 0.2106197505932732, 0.30866802775586055], 
reward next is 0.6913, 
noisyNet noise sample is [array([-0.0686248], dtype=float32), 1.2432401]. 
=============================================
[2019-03-24 02:35:02,462] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.3409576e-31 2.7929394e-25 0.0000000e+00 1.9450161e-33], sum to 1.0000
[2019-03-24 02:35:02,467] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6697
[2019-03-24 02:35:02,471] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.53333333333333, 65.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7886011914243943, 6.9112, 6.9112, 121.9260426156618, 584752.217192639, 584752.217192639, 159367.015281823], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2031000.0000, 
sim time next is 2031600.0000, 
raw observation next is [26.66666666666667, 65.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7960386876900275, 6.9112, 6.9112, 121.9260426156618, 589735.301661165, 589735.301661165, 160507.3744330475], 
processed observation next is [0.0, 0.5217391304347826, 0.5432098765432101, 0.6566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7450483596125342, 0.0, 0.0, 0.8094621288201359, 0.2106197505932732, 0.2106197505932732, 0.30866802775586055], 
reward next is 0.6913, 
noisyNet noise sample is [array([-0.45726734], dtype=float32), 0.43555176]. 
=============================================
[2019-03-24 02:35:08,020] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.4801785e-27 5.1012315e-23 9.2302917e-33 4.6350992e-29], sum to 1.0000
[2019-03-24 02:35:08,031] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5957
[2019-03-24 02:35:08,035] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.912595444990587, 6.9112, 6.9112, 121.9260426156618, 665898.4107619887, 665898.4107619887, 178007.0347148896], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2161800.0000, 
sim time next is 2162400.0000, 
raw observation next is [24.93333333333333, 84.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9141599814711769, 6.9112, 6.9112, 121.9260426156618, 666742.0555607487, 666742.0555607487, 178270.8694322786], 
processed observation next is [1.0, 0.0, 0.47901234567901224, 0.8466666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8926999768389712, 0.0, 0.0, 0.8094621288201359, 0.23812216270026737, 0.23812216270026737, 0.3428285950620742], 
reward next is 0.6572, 
noisyNet noise sample is [array([-0.58904237], dtype=float32), -0.0065038777]. 
=============================================
[2019-03-24 02:35:15,468] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.000000e+00 5.055778e-25 4.866202e-22 3.696350e-31 2.269920e-29], sum to 1.0000
[2019-03-24 02:35:15,478] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5805
[2019-03-24 02:35:15,488] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1285971.770923768 W.
[2019-03-24 02:35:15,491] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.45, 76.5, 1.0, 2.0, 0.5534513531718135, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8830453885640782, 6.911200000000001, 6.9112, 121.9257528290737, 1285971.770923768, 1285971.770923767, 275775.8166133206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2298600.0000, 
sim time next is 2299200.0000, 
raw observation next is [25.5, 75.66666666666666, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.674263290251758, 6.9112, 121.9230173490965, 1588352.870045949, 1197605.959187489, 247467.0828733807], 
processed observation next is [1.0, 0.6086956521739131, 0.5, 0.7566666666666666, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.07630632902517576, 0.0, 0.8094420441961978, 0.5672688821592675, 0.4277164139955318, 0.4758982362949629], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.57780886], dtype=float32), -1.8138411]. 
=============================================
[2019-03-24 02:35:15,629] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.9681119e-22 1.2801304e-18 5.2832468e-27 2.9000805e-24], sum to 1.0000
[2019-03-24 02:35:15,636] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0711
[2019-03-24 02:35:15,643] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1260986.959866983 W.
[2019-03-24 02:35:15,648] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.56666666666667, 90.33333333333334, 1.0, 2.0, 0.3603001454940671, 1.0, 1.0, 0.3603001454940671, 1.0, 2.0, 0.5753822933928044, 6.9112, 6.9112, 121.94756008, 1260986.959866983, 1260986.959866983, 280152.5846036241], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2283000.0000, 
sim time next is 2283600.0000, 
raw observation next is [22.73333333333333, 89.66666666666667, 1.0, 2.0, 0.5398957309728125, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8640693645250354, 6.911199999999999, 6.9112, 121.9260426156618, 1269795.584909979, 1269795.584909979, 270398.5768058139], 
processed observation next is [1.0, 0.43478260869565216, 0.39753086419753075, 0.8966666666666667, 1.0, 1.0, 0.45225682258668154, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.830086705656294, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.45349842318213535, 0.45349842318213535, 0.5199972630881036], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5251653], dtype=float32), 1.2937603]. 
=============================================
[2019-03-24 02:35:15,860] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.00000000e+00 1.08114425e-19 1.70910232e-16 1.61387389e-23
 6.77099131e-22], sum to 1.0000
[2019-03-24 02:35:15,864] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7383
[2019-03-24 02:35:15,868] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1213512.113437936 W.
[2019-03-24 02:35:15,871] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.6, 86.0, 1.0, 2.0, 0.5191991137817188, 0.0, 1.0, 0.0, 1.0, 2.0, 0.829492324316427, 6.911199999999999, 6.9112, 121.9260426156618, 1213512.113437936, 1213512.113437936, 263168.3044447308], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2287200.0000, 
sim time next is 2287800.0000, 
raw observation next is [23.7, 85.5, 1.0, 2.0, 0.3407998981283326, 1.0, 1.0, 0.3407998981283326, 1.0, 2.0, 0.543117712770318, 6.9112, 6.9112, 121.94756008, 1179269.344828859, 1179269.344828859, 272170.0530533279], 
processed observation next is [1.0, 0.4782608695652174, 0.4333333333333333, 0.855, 1.0, 1.0, 0.21523797396230074, 1.0, 0.5, 0.21523797396230074, 1.0, 1.0, 0.4288971409628974, 0.0, 0.0, 0.8096049824067558, 0.4211676231531639, 0.4211676231531639, 0.5234039481794768], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.37199065], dtype=float32), 0.56319803]. 
=============================================
[2019-03-24 02:35:19,237] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.2361813e-20 9.4824743e-18 3.0482652e-26 3.6507375e-23], sum to 1.0000
[2019-03-24 02:35:19,248] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0534
[2019-03-24 02:35:19,256] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 905509.9239286004 W.
[2019-03-24 02:35:19,260] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.8, 41.33333333333334, 1.0, 2.0, 0.3654650948738693, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6061247526163706, 6.911200000000001, 6.9112, 121.9260425192522, 905509.9239286004, 905509.9239285999, 210155.5485348576], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2364000.0000, 
sim time next is 2364600.0000, 
raw observation next is [27.9, 41.16666666666667, 1.0, 2.0, 0.3631006282027134, 1.0, 1.0, 0.3631006282027134, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156324, 896720.4805142485, 896720.480514249, 198928.5495184017], 
processed observation next is [1.0, 0.34782608695652173, 0.5888888888888888, 0.41166666666666674, 1.0, 1.0, 0.24178646214608737, 1.0, 0.5, 0.24178646214608737, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288199407, 0.32025731446937444, 0.3202573144693746, 0.38255490292000327], 
reward next is 0.6174, 
noisyNet noise sample is [array([-0.25226846], dtype=float32), 1.1895822]. 
=============================================
[2019-03-24 02:35:20,378] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 5.1768647e-22 1.6945255e-19 2.2941805e-30 4.4559717e-27], sum to 1.0000
[2019-03-24 02:35:20,384] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8903
[2019-03-24 02:35:20,387] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5523284661779517, 6.9112, 6.9112, 121.9260426156618, 404564.438648834, 404564.438648834, 123022.8589030757], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2422800.0000, 
sim time next is 2423400.0000, 
raw observation next is [21.85, 62.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5449424959068229, 6.9112, 6.9112, 121.9260426156618, 398282.6655142977, 398282.6655142977, 122006.6748426219], 
processed observation next is [1.0, 0.043478260869565216, 0.36481481481481487, 0.6283333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43117811988352855, 0.0, 0.0, 0.8094621288201359, 0.14224380911224918, 0.14224380911224918, 0.23462822085119595], 
reward next is 0.7654, 
noisyNet noise sample is [array([0.44607922], dtype=float32), -0.29195738]. 
=============================================
[2019-03-24 02:35:21,639] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 02:35:21,640] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:35:21,640] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:35:21,641] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:35:21,643] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:35:21,643] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:35:21,644] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:35:21,643] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:35:21,644] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:35:21,646] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:35:21,644] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:35:21,663] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run29
[2019-03-24 02:35:21,690] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run29
[2019-03-24 02:35:21,690] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run29
[2019-03-24 02:35:21,691] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run29
[2019-03-24 02:35:21,743] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run29
[2019-03-24 02:36:04,757] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.21293199]
[2019-03-24 02:36:04,758] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.42062469, 67.4899396, 1.0, 2.0, 0.9107192158211679, 1.0, 2.0, 0.7687242698870185, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2631272.154162318, 2631272.154162318, 490663.6210399985]
[2019-03-24 02:36:04,758] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:36:04,760] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.18224828997391485
[2019-03-24 02:36:04,761] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 2631272.154162318 W.
[2019-03-24 02:36:41,111] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.21293199]
[2019-03-24 02:36:41,112] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.0, 55.0, 1.0, 2.0, 0.5790866479834842, 0.0, 2.0, 0.0, 1.0, 1.0, 0.921924803125179, 6.911199999999999, 6.9112, 121.9256378124188, 1320439.874189088, 1320439.874189089, 285811.5577315005]
[2019-03-24 02:36:41,114] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:36:41,117] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.4486129e-28 9.2320550e-25 4.5492657e-36 6.4175835e-33], sampled 0.5375029393886945
[2019-03-24 02:36:41,118] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1320439.874189088 W.
[2019-03-24 02:36:58,999] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.21293199]
[2019-03-24 02:36:59,000] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.0, 68.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6982787144169178, 6.911200000000001, 6.9112, 121.9260426156618, 521783.3696408105, 521783.36964081, 144202.9332465554]
[2019-03-24 02:36:59,002] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:36:59,005] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.7023686e-30 1.9767458e-26 1.5379908e-38 3.8043486e-35], sampled 0.12111276641178748
[2019-03-24 02:36:59,355] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 02:36:59,624] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 02:36:59,921] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 02:37:00,030] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 02:37:00,243] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 02:37:01,260] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 700000, evaluation results [700000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 02:37:03,486] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 6.3247497e-31 1.9305337e-27 1.2690705e-38 8.3098963e-37], sum to 1.0000
[2019-03-24 02:37:03,494] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2609
[2019-03-24 02:37:03,497] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5523284661779517, 6.9112, 6.9112, 121.9260426156618, 404564.438648834, 404564.438648834, 123022.8589030757], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2422800.0000, 
sim time next is 2423400.0000, 
raw observation next is [21.85, 62.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5449424959068229, 6.9112, 6.9112, 121.9260426156618, 398282.6655142977, 398282.6655142977, 122006.6748426219], 
processed observation next is [1.0, 0.043478260869565216, 0.36481481481481487, 0.6283333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43117811988352855, 0.0, 0.0, 0.8094621288201359, 0.14224380911224918, 0.14224380911224918, 0.23462822085119595], 
reward next is 0.7654, 
noisyNet noise sample is [array([-0.5852184], dtype=float32), 0.5842299]. 
=============================================
[2019-03-24 02:37:04,199] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.00000000e+00 2.25274629e-28 1.00773904e-23 1.38261990e-34
 5.82827732e-31], sum to 1.0000
[2019-03-24 02:37:04,203] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2973
[2019-03-24 02:37:04,209] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1334459.246181827 W.
[2019-03-24 02:37:04,211] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.8, 39.66666666666667, 1.0, 1.0, 0.9322349386262367, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.251947776790574, 6.9112, 121.9242431561772, 1334459.246181827, 1159968.504053996, 228897.1257930161], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2449200.0000, 
sim time next is 2449800.0000, 
raw observation next is [29.05, 38.5, 1.0, 2.0, 0.3425457604030851, 1.0, 1.0, 0.3425457604030851, 1.0, 1.0, 0.5573481997467621, 6.9112, 6.9112, 121.94756008, 1248028.729283586, 1248028.729283586, 271865.8800944647], 
processed observation next is [1.0, 0.34782608695652173, 0.6314814814814815, 0.385, 1.0, 1.0, 0.21731638143224416, 1.0, 0.5, 0.21731638143224416, 1.0, 0.5, 0.4466852496834526, 0.0, 0.0, 0.8096049824067558, 0.44572454617270924, 0.44572454617270924, 0.5228190001816628], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.45596272], dtype=float32), -0.38323894]. 
=============================================
[2019-03-24 02:37:08,777] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.9127002e-24 1.1392607e-21 1.4218443e-31 3.8530245e-29], sum to 1.0000
[2019-03-24 02:37:08,784] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7842
[2019-03-24 02:37:08,788] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.66666666666667, 50.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.739826822919724, 6.911199999999999, 6.9112, 121.9260426156618, 552175.4521932893, 552175.4521932898, 147243.8684118034], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2529600.0000, 
sim time next is 2530200.0000, 
raw observation next is [26.93333333333333, 49.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7632981025286134, 6.9112, 6.9112, 121.9260426156618, 569856.6919778766, 569856.6919778766, 150107.8440992575], 
processed observation next is [1.0, 0.2608695652173913, 0.5530864197530863, 0.4983333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7041226281607668, 0.0, 0.0, 0.8094621288201359, 0.20352024713495592, 0.20352024713495592, 0.28866893096011054], 
reward next is 0.7113, 
noisyNet noise sample is [array([-0.8601806], dtype=float32), -2.0023842]. 
=============================================
[2019-03-24 02:37:10,036] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 8.9485242e-18 3.2434335e-14 6.8363910e-23 7.4342179e-20], sum to 1.0000
[2019-03-24 02:37:10,044] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7392
[2019-03-24 02:37:10,052] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1543254.303892685 W.
[2019-03-24 02:37:10,060] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.40000000000001, 30.0, 1.0, 2.0, 0.4330138754090153, 1.0, 2.0, 0.4330138754090153, 1.0, 2.0, 0.6955690852844094, 6.911200000000001, 6.9112, 121.94756008, 1543254.303892685, 1543254.303892685, 311704.9627467565], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2547600.0000, 
sim time next is 2548200.0000, 
raw observation next is [32.5, 30.0, 1.0, 2.0, 0.4380732668332787, 1.0, 2.0, 0.4380732668332787, 1.0, 2.0, 0.7031421115509567, 6.9112, 6.9112, 121.94756008, 1558336.673287642, 1558336.673287642, 314064.6002140869], 
processed observation next is [1.0, 0.4782608695652174, 0.7592592592592593, 0.3, 1.0, 1.0, 0.33103960337295085, 1.0, 1.0, 0.33103960337295085, 1.0, 1.0, 0.6289276394386958, 0.0, 0.0, 0.8096049824067558, 0.5565488118884435, 0.5565488118884435, 0.6039703850270901], 
reward next is 0.3960, 
noisyNet noise sample is [array([0.9306905], dtype=float32), 0.1463134]. 
=============================================
[2019-03-24 02:37:19,126] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.000000e+00 2.728351e-28 6.996899e-26 5.214548e-35 7.804391e-32], sum to 1.0000
[2019-03-24 02:37:19,133] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0875
[2019-03-24 02:37:19,140] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 727087.960380671 W.
[2019-03-24 02:37:19,144] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.1, 56.0, 1.0, 2.0, 0.637984176867282, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727087.960380671, 727087.960380671, 164734.947915145], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2739600.0000, 
sim time next is 2740200.0000, 
raw observation next is [31.25, 54.33333333333334, 1.0, 2.0, 0.3170419142052306, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5047410527490237, 6.911199999999999, 6.9112, 121.9260426156618, 722640.7762249318, 722640.7762249323, 199880.6331859832], 
processed observation next is [0.0, 0.7391304347826086, 0.7129629629629629, 0.5433333333333334, 1.0, 1.0, 0.18695465976813166, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.38092631593627957, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2580859915089042, 0.2580859915089044, 0.3843858330499677], 
reward next is 0.6156, 
noisyNet noise sample is [array([0.51390976], dtype=float32), -0.6646519]. 
=============================================
[2019-03-24 02:37:22,097] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.8385120e-12 3.7766004e-09 1.3046545e-14 3.3752065e-13], sum to 1.0000
[2019-03-24 02:37:22,104] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2395
[2019-03-24 02:37:22,110] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2469439.001351627 W.
[2019-03-24 02:37:22,116] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.9, 55.5, 1.0, 2.0, 0.8162909531830258, 1.0, 2.0, 0.7215101385679474, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2469439.001351627, 2469439.001351627, 461951.2638281487], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2824200.0000, 
sim time next is 2824800.0000, 
raw observation next is [32.86666666666667, 54.33333333333333, 1.0, 2.0, 0.9976525486598495, 1.0, 2.0, 0.9976525486598495, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2276130.016135766, 2276130.016135766, 432196.891303655], 
processed observation next is [1.0, 0.6956521739130435, 0.7728395061728395, 0.5433333333333333, 1.0, 1.0, 0.9972054150712495, 1.0, 1.0, 0.9972054150712495, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.8129035771913451, 0.8129035771913451, 0.8311478678916442], 
reward next is 0.1689, 
noisyNet noise sample is [array([-0.7801036], dtype=float32), 0.19048935]. 
=============================================
[2019-03-24 02:37:25,735] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9544108e-01 1.2453531e-04 4.3378659e-03 1.8588798e-07 9.6345735e-05], sum to 1.0000
[2019-03-24 02:37:25,743] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4196
[2019-03-24 02:37:25,748] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 964903.9829697903 W.
[2019-03-24 02:37:25,754] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.2787751929186167, 1.0, 2.0, 0.2787751929186167, 1.0, 2.0, 0.4442962325371064, 6.911199999999999, 6.9112, 121.94756008, 964903.9829697903, 964903.9829697908, 248084.7338811322], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2863800.0000, 
sim time next is 2864400.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.7096543665012003, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 834895.9369759203, 834895.9369759199, 179222.2865118373], 
processed observation next is [1.0, 0.13043478260869565, 0.37037037037037035, 1.0, 1.0, 1.0, 0.6543504363109527, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.298177120348543, 0.2981771203485428, 0.3446582432919948], 
reward next is 0.6553, 
noisyNet noise sample is [array([-0.56105566], dtype=float32), -0.49447381]. 
=============================================
[2019-03-24 02:37:29,741] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.0409720e-01 7.7610269e-07 9.5885694e-02 7.4176004e-10 1.6370232e-05], sum to 1.0000
[2019-03-24 02:37:29,749] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8043
[2019-03-24 02:37:29,761] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 773570.2149771011 W.
[2019-03-24 02:37:29,767] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.6787495153374068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 773570.2149771011, 773570.2149771011, 172159.7819342432], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2926800.0000, 
sim time next is 2927400.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.2273289464227893, 1.0, 1.0, 0.2273289464227893, 1.0, 1.0, 0.3619150862919942, 6.9112, 6.9112, 121.94756008, 777261.5913068763, 777261.5913068763, 229730.0970393047], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.89, 1.0, 1.0, 0.08015350764617775, 1.0, 0.5, 0.08015350764617775, 1.0, 0.5, 0.20239385786499273, 0.0, 0.0, 0.8096049824067558, 0.27759342546674154, 0.27759342546674154, 0.44178864815250907], 
reward next is 0.5582, 
noisyNet noise sample is [array([-0.45264703], dtype=float32), 0.6538058]. 
=============================================
[2019-03-24 02:37:37,150] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9945468e-01 4.1127322e-07 1.4968633e-04 3.3382013e-09 3.9530193e-04], sum to 1.0000
[2019-03-24 02:37:37,156] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9590
[2019-03-24 02:37:37,162] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1753109.19203145 W.
[2019-03-24 02:37:37,168] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.16666666666666, 89.0, 1.0, 2.0, 0.5124211763475364, 1.0, 2.0, 0.5124211763475364, 1.0, 2.0, 0.8157912011379141, 6.911199999999999, 6.9112, 121.94756008, 1753109.19203145, 1753109.19203145, 349727.3414686522], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3057000.0000, 
sim time next is 3057600.0000, 
raw observation next is [27.33333333333334, 89.0, 1.0, 2.0, 0.4927435250780572, 1.0, 2.0, 0.4927435250780572, 1.0, 2.0, 0.7844637394605422, 6.9112, 6.9112, 121.94756008, 1685723.970340418, 1685723.970340418, 340041.7431324694], 
processed observation next is [1.0, 0.391304347826087, 0.5679012345679014, 0.89, 1.0, 1.0, 0.39612324414054423, 1.0, 1.0, 0.39612324414054423, 1.0, 1.0, 0.7305796743256776, 0.0, 0.0, 0.8096049824067558, 0.6020442751215779, 0.6020442751215779, 0.6539264291009027], 
reward next is 0.3461, 
noisyNet noise sample is [array([-0.7595969], dtype=float32), 0.5287204]. 
=============================================
[2019-03-24 02:37:39,321] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9950218e-01 1.2289800e-07 4.7316920e-04 6.5227594e-11 2.4585450e-05], sum to 1.0000
[2019-03-24 02:37:39,327] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2752
[2019-03-24 02:37:39,335] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2068871.785416119 W.
[2019-03-24 02:37:39,339] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.9, 52.5, 1.0, 2.0, 0.6046095489588242, 1.0, 1.0, 0.6046095489588242, 1.0, 1.0, 0.9625580927007744, 6.911199999999999, 6.9112, 121.94756008, 2068871.785416119, 2068871.78541612, 397892.8352004735], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3141000.0000, 
sim time next is 3141600.0000, 
raw observation next is [29.93333333333334, 52.33333333333333, 1.0, 2.0, 0.8050228149980837, 1.0, 2.0, 0.8050228149980837, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260420698361, 1836196.186224334, 1836196.186224333, 345832.4449994915], 
processed observation next is [1.0, 0.34782608695652173, 0.6641975308641977, 0.5233333333333333, 1.0, 1.0, 0.7678843035691473, 1.0, 1.0, 0.7678843035691473, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621251964209, 0.6557843522229764, 0.655784352222976, 0.6650623942297914], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3959231], dtype=float32), -1.0702424]. 
=============================================
[2019-03-24 02:37:46,518] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.3900541e-21 9.6507698e-20 1.2092064e-30 3.1282450e-23], sum to 1.0000
[2019-03-24 02:37:46,530] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2978
[2019-03-24 02:37:46,538] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.66666666666666, 59.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8075975838586077, 6.911200000000001, 6.9112, 121.9260426156618, 598987.7343990449, 598987.7343990445, 161678.2569738674], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3231600.0000, 
sim time next is 3232200.0000, 
raw observation next is [27.83333333333334, 58.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8103537690384301, 6.911200000000001, 6.9112, 121.9260426156618, 600847.979080516, 600847.9790805156, 162103.4525722235], 
processed observation next is [0.0, 0.391304347826087, 0.58641975308642, 0.5866666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7629422112980377, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21458856395732714, 0.21458856395732698, 0.3117374087927375], 
reward next is 0.6883, 
noisyNet noise sample is [array([0.3245181], dtype=float32), -0.18925957]. 
=============================================
[2019-03-24 02:37:50,091] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.7991408e-18 1.0626757e-17 1.2714055e-24 3.5889547e-18], sum to 1.0000
[2019-03-24 02:37:50,104] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8167
[2019-03-24 02:37:50,108] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.75, 94.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7805170101328328, 6.9112, 6.9112, 121.9260426156618, 581624.7681033005, 581624.7681033005, 156769.7871873562], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3301800.0000, 
sim time next is 3302400.0000, 
raw observation next is [21.8, 95.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7904167150084029, 6.9112, 6.9112, 121.9260426156618, 588348.2121808582, 588348.2121808582, 158437.3064553347], 
processed observation next is [0.0, 0.21739130434782608, 0.362962962962963, 0.9533333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7380208937605037, 0.0, 0.0, 0.8094621288201359, 0.21012436149316366, 0.21012436149316366, 0.3046871277987206], 
reward next is 0.6953, 
noisyNet noise sample is [array([-0.0046708], dtype=float32), -1.0893732]. 
=============================================
[2019-03-24 02:37:52,529] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 02:37:52,531] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:37:52,532] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:37:52,531] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:37:52,533] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:37:52,534] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:37:52,540] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:37:52,542] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:37:52,538] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:37:52,544] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:37:52,545] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:37:52,563] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run30
[2019-03-24 02:37:52,587] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run30
[2019-03-24 02:37:52,615] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run30
[2019-03-24 02:37:52,615] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run30
[2019-03-24 02:37:52,673] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run30
[2019-03-24 02:37:55,977] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.21693677]
[2019-03-24 02:37:55,978] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [15.26666666666667, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.348168630469053, 6.9112, 6.9112, 121.9260426156618, 248578.2059632587, 248578.2059632587, 76410.5871973429]
[2019-03-24 02:37:55,979] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:37:55,982] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.2283588e-16 3.6038457e-15 2.5480339e-22 4.4176950e-16], sampled 0.7460524823001558
[2019-03-24 02:38:07,297] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.21693677]
[2019-03-24 02:38:07,299] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.53333333333333, 24.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5783317514057583, 6.9112, 6.9112, 121.9260426156618, 412949.5291546411, 412949.5291546411, 104897.8345740161]
[2019-03-24 02:38:07,301] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:38:07,304] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.4048480e-16 2.1225957e-15 1.1492427e-22 2.5210379e-16], sampled 0.8420203227313613
[2019-03-24 02:38:24,829] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.21693677]
[2019-03-24 02:38:24,830] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.25, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7790999216956047, 6.9112, 6.9112, 121.9260426156618, 579677.9447072243, 579677.9447072243, 157208.4311743299]
[2019-03-24 02:38:24,833] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:38:24,837] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.2503455e-17 2.2988749e-16 4.1021749e-24 2.3981409e-17], sampled 0.8967636597554464
[2019-03-24 02:38:40,076] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.21693677]
[2019-03-24 02:38:40,078] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.6, 90.33333333333334, 1.0, 2.0, 0.48691802770056, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7808917366105139, 6.9112, 6.9112, 121.925868190604, 1151965.678294179, 1151965.678294179, 251455.5354970617]
[2019-03-24 02:38:40,079] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:38:40,081] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 9.4571215e-13 5.0072706e-12 1.3379117e-17 9.1199433e-13], sampled 0.9350376085636484
[2019-03-24 02:38:40,082] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1151965.678294179 W.
[2019-03-24 02:39:27,189] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.21693677]
[2019-03-24 02:39:27,192] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.7, 34.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6452152022304051, 6.9112, 6.9112, 121.9260426156618, 471277.6486797426, 471277.6486797426, 130745.193675665]
[2019-03-24 02:39:27,193] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:39:27,196] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 7.2238861e-17 6.8449749e-16 2.1162163e-23 7.6084655e-17], sampled 0.372888905029901
[2019-03-24 02:39:31,161] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 02:39:31,229] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 02:39:31,286] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 02:39:31,394] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 02:39:31,581] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 02:39:32,598] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 725000, evaluation results [725000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 02:39:35,091] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9997985e-01 2.2440206e-06 1.1531159e-05 2.3351150e-08 6.2646363e-06], sum to 1.0000
[2019-03-24 02:39:35,097] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3660
[2019-03-24 02:39:35,102] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 783767.9220673472 W.
[2019-03-24 02:39:35,105] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.45, 94.0, 1.0, 2.0, 0.340674350637051, 1.0, 2.0, 0.340674350637051, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783767.9220673472, 783767.9220673472, 190857.7893527974], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3385800.0000, 
sim time next is 3386400.0000, 
raw observation next is [23.26666666666667, 94.0, 1.0, 2.0, 0.3220423080742605, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5136488719108098, 6.911199999999999, 6.9112, 121.9260426156618, 746638.4551639886, 746638.4551639891, 200998.612916603], 
processed observation next is [1.0, 0.17391304347826086, 0.41728395061728407, 0.94, 1.0, 1.0, 0.19290750961221487, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.3920610898885122, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26665659112999596, 0.2666565911299961, 0.38653579407039035], 
reward next is 0.6135, 
noisyNet noise sample is [array([-0.9494781], dtype=float32), -0.22820494]. 
=============================================
[2019-03-24 02:39:36,246] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9983835e-01 2.1108368e-05 4.8975886e-05 2.9594281e-07 9.1239257e-05], sum to 1.0000
[2019-03-24 02:39:36,251] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2981
[2019-03-24 02:39:36,260] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 780887.5957126544 W.
[2019-03-24 02:39:36,268] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.3425833480963187, 1.0, 1.0, 0.3425833480963187, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 780887.5957126544, 780887.5957126544, 190993.9594902078], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3445200.0000, 
sim time next is 3445800.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.6875566718570826, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783612.8541783638, 783612.8541783638, 173801.0730933874], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.89, 1.0, 1.0, 0.6280436569727174, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27986173363512995, 0.27986173363512995, 0.3342328328718988], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.24198058], dtype=float32), 1.568193]. 
=============================================
[2019-03-24 02:39:40,382] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.1589048e-04 6.7024525e-11 2.7250219e-04 5.3953340e-09 9.9931157e-01], sum to 1.0000
[2019-03-24 02:39:40,390] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4421
[2019-03-24 02:39:40,395] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.2071253083465528, 1.0, 2.0, 0.2071253083465528, 1.0, 2.0, 0.32975023648807, 6.9112, 6.9112, 121.94756008, 708151.3237532412, 708151.3237532412, 222936.2186271023], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3520800.0000, 
sim time next is 3521400.0000, 
raw observation next is [27.0, 79.00000000000001, 1.0, 2.0, 0.2122050352754933, 1.0, 2.0, 0.2122050352754933, 1.0, 2.0, 0.3378373271940998, 6.9112, 6.9112, 121.94756008, 725526.8796552117, 725526.8796552117, 224622.8873172506], 
processed observation next is [1.0, 0.782608695652174, 0.5555555555555556, 0.7900000000000001, 1.0, 1.0, 0.06214885151844441, 1.0, 1.0, 0.06214885151844441, 1.0, 1.0, 0.17229665899262475, 0.0, 0.0, 0.8096049824067558, 0.2591167427340042, 0.2591167427340042, 0.4319670909947127], 
reward next is 0.5680, 
noisyNet noise sample is [array([-0.94556123], dtype=float32), 1.4446037]. 
=============================================
[2019-03-24 02:39:42,308] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0263496e-03 2.7472716e-10 6.0566726e-06 6.8907942e-11 9.9896765e-01], sum to 1.0000
[2019-03-24 02:39:42,319] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5098
[2019-03-24 02:39:42,324] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.5, 65.0, 1.0, 2.0, 0.3897405788464436, 1.0, 2.0, 0.3897405788464436, 1.0, 2.0, 0.6204796944880493, 6.911199999999999, 6.9112, 121.94756008, 1333047.016036475, 1333047.016036475, 292617.1090406642], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3517200.0000, 
sim time next is 3517800.0000, 
raw observation next is [27.41666666666667, 67.33333333333334, 1.0, 2.0, 0.2256437775106668, 1.0, 2.0, 0.2256437775106668, 1.0, 2.0, 0.3592322425017753, 6.911199999999999, 6.9112, 121.94756008, 771496.9223172578, 771496.9223172583, 229154.6971678301], 
processed observation next is [1.0, 0.7391304347826086, 0.5709876543209879, 0.6733333333333335, 1.0, 1.0, 0.07814735417936525, 1.0, 1.0, 0.07814735417936525, 1.0, 1.0, 0.19904030312721913, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2755346151133064, 0.2755346151133065, 0.44068210993813484], 
reward next is 0.5593, 
noisyNet noise sample is [array([0.22497983], dtype=float32), -0.11154826]. 
=============================================
[2019-03-24 02:39:46,175] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.5654392e-06 2.0877653e-12 1.6878726e-08 5.3918916e-14 9.9999547e-01], sum to 1.0000
[2019-03-24 02:39:46,179] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8073
[2019-03-24 02:39:46,184] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.4274499348960821, 1.0, 2.0, 0.4274499348960821, 1.0, 2.0, 0.6805142174270615, 6.9112, 6.9112, 121.94756008, 1462149.097320546, 1462149.097320546, 309315.4121830208], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3597600.0000, 
sim time next is 3598200.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.4319736117168659, 1.0, 2.0, 0.4319736117168659, 1.0, 2.0, 0.6877160582516181, 6.911199999999999, 6.9112, 121.94756008, 1477637.858665269, 1477637.85866527, 311371.4573656775], 
processed observation next is [1.0, 0.6521739130434783, 0.48148148148148145, 0.83, 1.0, 1.0, 0.32377810918674504, 1.0, 1.0, 0.32377810918674504, 1.0, 1.0, 0.6096450728145225, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5277278066661676, 0.5277278066661679, 0.5987912641647645], 
reward next is 0.4012, 
noisyNet noise sample is [array([-0.9414339], dtype=float32), -0.13237546]. 
=============================================
[2019-03-24 02:39:46,315] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1758015e-05 3.9523948e-13 1.2103686e-08 1.8969379e-12 9.9998820e-01], sum to 1.0000
[2019-03-24 02:39:46,325] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4993
[2019-03-24 02:39:46,332] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.58333333333333, 83.16666666666667, 1.0, 2.0, 0.3174723525981613, 1.0, 2.0, 0.3174723525981613, 1.0, 2.0, 0.5064550248631586, 6.9112, 6.9112, 121.94756008, 1105453.257203004, 1105453.257203004, 262845.2616761928], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3581400.0000, 
sim time next is 3582000.0000, 
raw observation next is [23.7, 82.0, 1.0, 2.0, 0.3541337915749423, 1.0, 2.0, 0.3541337915749423, 1.0, 2.0, 0.5648956414229052, 6.9112, 6.9112, 121.94756008, 1232692.370575916, 1232692.370575916, 277620.9284241783], 
processed observation next is [1.0, 0.4782608695652174, 0.4333333333333333, 0.82, 1.0, 1.0, 0.23111165663683605, 1.0, 1.0, 0.23111165663683605, 1.0, 1.0, 0.4561195517786314, 0.0, 0.0, 0.8096049824067558, 0.4402472752056843, 0.4402472752056843, 0.5338864008157275], 
reward next is 0.4661, 
noisyNet noise sample is [array([-1.153497], dtype=float32), -1.7745689]. 
=============================================
[2019-03-24 02:39:46,356] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[58.061512]
 [57.91    ]
 [57.5999  ]
 [57.486073]
 [57.347218]], R is [[57.85109329]
 [57.76711273]
 [57.67636871]
 [57.55933762]
 [57.44771957]].
[2019-03-24 02:39:46,440] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.2433523e-06 3.6213471e-10 1.4024666e-07 2.1823808e-10 9.9999356e-01], sum to 1.0000
[2019-03-24 02:39:46,447] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3207
[2019-03-24 02:39:46,454] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.35, 85.5, 1.0, 2.0, 0.3621325261882237, 1.0, 2.0, 0.3621325261882237, 1.0, 2.0, 0.5772487906031696, 6.911200000000001, 6.9112, 121.94756008, 1255221.576006969, 1255221.576006969, 280950.0852534301], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3580200.0000, 
sim time next is 3580800.0000, 
raw observation next is [23.46666666666667, 84.33333333333334, 1.0, 2.0, 0.3274492419271597, 1.0, 2.0, 0.3274492419271597, 1.0, 2.0, 0.5221401776243108, 6.911199999999999, 6.9112, 121.94756008, 1137376.926971783, 1137376.926971784, 266799.9833908223], 
processed observation next is [1.0, 0.43478260869565216, 0.42469135802469143, 0.8433333333333334, 1.0, 1.0, 0.19934433562757106, 1.0, 1.0, 0.19934433562757106, 1.0, 1.0, 0.4026752220303884, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.40620604534706534, 0.4062060453470657, 0.5130768911361967], 
reward next is 0.4869, 
noisyNet noise sample is [array([-0.7773163], dtype=float32), -1.1324943]. 
=============================================
[2019-03-24 02:40:00,290] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.3054250e-06 3.5612407e-12 2.7471665e-09 3.8794695e-14 9.9999070e-01], sum to 1.0000
[2019-03-24 02:40:00,300] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4138
[2019-03-24 02:40:00,303] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.01666666666667, 52.66666666666667, 1.0, 2.0, 0.233207749694071, 1.0, 2.0, 0.233207749694071, 1.0, 2.0, 0.3712743325591308, 6.9112, 6.9112, 121.94756008, 797372.2915404413, 797372.2915404413, 231749.8423929991], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3855000.0000, 
sim time next is 3855600.0000, 
raw observation next is [33.0, 53.0, 1.0, 2.0, 0.2344032607289914, 1.0, 2.0, 0.2344032607289914, 1.0, 2.0, 0.3731776250618003, 6.9112, 6.9112, 121.94756008, 801462.0598873411, 801462.0598873411, 232162.9410944053], 
processed observation next is [0.0, 0.6521739130434783, 0.7777777777777778, 0.53, 1.0, 1.0, 0.08857531039165642, 1.0, 1.0, 0.08857531039165642, 1.0, 1.0, 0.21647203132725035, 0.0, 0.0, 0.8096049824067558, 0.28623644995976466, 0.28623644995976466, 0.4464671944123179], 
reward next is 0.5535, 
noisyNet noise sample is [array([-0.29774413], dtype=float32), 0.96663713]. 
=============================================
[2019-03-24 02:40:07,182] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4767928e-06 3.2887339e-11 6.5664629e-08 3.1651507e-12 9.9999845e-01], sum to 1.0000
[2019-03-24 02:40:07,193] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9783
[2019-03-24 02:40:07,200] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.75, 72.33333333333334, 1.0, 2.0, 0.2508887535146131, 1.0, 2.0, 0.2508887535146131, 1.0, 2.0, 0.3994230664715275, 6.9112, 6.9112, 121.94756008, 857860.122798651, 857860.122798651, 237940.8104365331], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3953400.0000, 
sim time next is 3954000.0000, 
raw observation next is [29.6, 73.66666666666667, 1.0, 2.0, 0.2474499709437374, 1.0, 2.0, 0.2474499709437374, 1.0, 2.0, 0.3939484126253637, 6.9112, 6.9112, 121.94756008, 846095.4564687535, 846095.4564687535, 236723.0453363306], 
processed observation next is [0.0, 0.782608695652174, 0.6518518518518519, 0.7366666666666667, 1.0, 1.0, 0.10410710826635407, 1.0, 1.0, 0.10410710826635407, 1.0, 1.0, 0.24243551578170458, 0.0, 0.0, 0.8096049824067558, 0.30217694873884055, 0.30217694873884055, 0.4552366256467896], 
reward next is 0.5448, 
noisyNet noise sample is [array([-0.5587296], dtype=float32), -0.7113855]. 
=============================================
[2019-03-24 02:40:07,221] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[56.499527]
 [56.537582]
 [56.556812]
 [56.56606 ]
 [56.60367 ]], R is [[56.47660065]
 [56.45425797]
 [56.43186569]
 [56.41030121]
 [56.39042664]].
[2019-03-24 02:40:10,062] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0902288e-04 1.6986457e-09 4.7312076e-07 2.4994439e-11 9.9989045e-01], sum to 1.0000
[2019-03-24 02:40:10,071] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3467
[2019-03-24 02:40:10,078] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.33333333333334, 87.33333333333334, 1.0, 2.0, 0.5101870905046588, 1.0, 2.0, 0.5101870905046588, 1.0, 2.0, 0.8122344637169568, 6.9112, 6.9112, 121.94756008, 1745458.410930614, 1745458.410930614, 348617.1309365925], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4029600.0000, 
sim time next is 4030200.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.5171758002395728, 1.0, 2.0, 0.5171758002395728, 1.0, 2.0, 0.8233607172213259, 6.911200000000001, 6.9112, 121.94756008, 1769391.947669066, 1769391.947669066, 352099.1149114064], 
processed observation next is [1.0, 0.6521739130434783, 0.5370370370370371, 0.865, 1.0, 1.0, 0.42520928599949137, 1.0, 1.0, 0.42520928599949137, 1.0, 1.0, 0.7792008965266572, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.631925695596095, 0.631925695596095, 0.6771136825219354], 
reward next is 0.3229, 
noisyNet noise sample is [array([0.8574518], dtype=float32), 1.0921019]. 
=============================================
[2019-03-24 02:40:10,952] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.1463979e-05 1.6785153e-11 2.4056364e-08 4.0166746e-12 9.9993849e-01], sum to 1.0000
[2019-03-24 02:40:10,959] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1072
[2019-03-24 02:40:10,964] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.2166235683096003, 1.0, 2.0, 0.2166235683096003, 1.0, 2.0, 0.3448717756859727, 6.911199999999999, 6.9112, 121.94756008, 740641.0965323588, 740641.0965323593, 226101.7560003363], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4039200.0000, 
sim time next is 4039800.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.219292083120001, 1.0, 2.0, 0.219292083120001, 1.0, 2.0, 0.3491201381715906, 6.911200000000001, 6.9112, 121.94756008, 749769.2729968632, 749769.2729968628, 227000.189606614], 
processed observation next is [1.0, 0.782608695652174, 0.5185185185185185, 0.89, 1.0, 1.0, 0.07058581323809644, 1.0, 1.0, 0.07058581323809644, 1.0, 1.0, 0.18640017271448822, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.26777474035602256, 0.26777474035602244, 0.43653882616656536], 
reward next is 0.5635, 
noisyNet noise sample is [array([0.6238072], dtype=float32), 0.75243336]. 
=============================================
[2019-03-24 02:40:17,623] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999988e-01 5.3602172e-15 7.3248341e-10 4.8638756e-17 6.4775172e-08], sum to 1.0000
[2019-03-24 02:40:17,630] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5298
[2019-03-24 02:40:17,638] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.33333333333334, 99.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7452132525854043, 6.9112, 6.9112, 121.9260426156618, 556863.2356760966, 556863.2356760966, 150313.9505728249], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4169400.0000, 
sim time next is 4170000.0000, 
raw observation next is [20.66666666666667, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.727351479464538, 6.911199999999999, 6.9112, 121.9260426156618, 543338.7417447858, 543338.7417447862, 148857.0976475441], 
processed observation next is [1.0, 0.2608695652173913, 0.3209876543209878, 0.98, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6591893493306724, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19404955062313778, 0.19404955062313792, 0.2862636493222002], 
reward next is 0.7137, 
noisyNet noise sample is [array([-0.50350636], dtype=float32), 0.55813396]. 
=============================================
[2019-03-24 02:40:17,667] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[71.578   ]
 [71.586716]
 [71.407455]
 [71.3868  ]
 [71.363235]], R is [[71.38169098]
 [71.3788147 ]
 [71.38941956]
 [71.40086365]
 [71.41296387]].
[2019-03-24 02:40:19,642] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9999666e-01 5.2375432e-10 9.3025420e-08 2.0497349e-12 3.1723589e-06], sum to 1.0000
[2019-03-24 02:40:19,653] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7331
[2019-03-24 02:40:19,656] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.5, 36.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.782695083606947, 6.911200000000001, 6.9112, 121.9260426156618, 579819.3499331633, 579819.3499331628, 158859.0208679439], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4213800.0000, 
sim time next is 4214400.0000, 
raw observation next is [33.33333333333334, 36.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7878355815165863, 6.9112, 6.9112, 121.9260426156618, 583457.4554271629, 583457.4554271629, 159561.7128235836], 
processed observation next is [1.0, 0.782608695652174, 0.7901234567901239, 0.3666666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7347944768957329, 0.0, 0.0, 0.8094621288201359, 0.2083776626525582, 0.2083776626525582, 0.30684944773766076], 
reward next is 0.6932, 
noisyNet noise sample is [array([-1.689336], dtype=float32), 0.51677763]. 
=============================================
[2019-03-24 02:40:23,785] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 02:40:23,787] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:40:23,788] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:40:23,788] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:40:23,790] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:40:23,791] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:40:23,792] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:40:23,793] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:40:23,793] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:40:23,790] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:40:23,795] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:40:23,806] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run31
[2019-03-24 02:40:23,830] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run31
[2019-03-24 02:40:23,831] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run31
[2019-03-24 02:40:23,853] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run31
[2019-03-24 02:40:23,899] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run31
[2019-03-24 02:40:45,173] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.22530119]
[2019-03-24 02:40:45,174] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.73333333333333, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5880350318487954, 6.911200000000001, 6.9112, 121.9260426156618, 434446.66292571, 434446.6629257095, 127990.9867348824]
[2019-03-24 02:40:45,176] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:40:45,179] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 6.1516721e-13 4.5391180e-09 6.3510246e-14 3.3033796e-08], sampled 0.6079869633963445
[2019-03-24 02:41:00,267] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.22530119]
[2019-03-24 02:41:00,267] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.2, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9007380312360388, 6.9112, 6.9112, 121.9260426156618, 658565.8866727044, 658565.8866727044, 176170.8290573609]
[2019-03-24 02:41:00,269] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:41:00,271] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.9797956e-13 3.6262866e-09 4.3290817e-14 3.2142459e-08], sampled 0.7556006649147682
[2019-03-24 02:41:05,007] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.22530119]
[2019-03-24 02:41:05,008] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.04232613, 101.665555095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7899494997496792, 6.9112, 6.9112, 121.9260426156618, 588792.0765558524, 588792.0765558524, 157806.2212330313]
[2019-03-24 02:41:05,009] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:41:05,011] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.3758667e-12 7.8445082e-09 1.4985046e-13 5.1919717e-08], sampled 0.608925278460673
[2019-03-24 02:41:10,422] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.22530119]
[2019-03-24 02:41:10,422] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.25, 87.5, 1.0, 2.0, 0.8485564840431509, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9253988359832, 1682362.984145599, 1682362.984145598, 346084.0547860761]
[2019-03-24 02:41:10,423] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:41:10,425] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9996436e-01 4.4750004e-09 2.9550781e-06 1.4992290e-09 3.2636617e-05], sampled 0.7677574573192949
[2019-03-24 02:41:10,427] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1682362.984145599 W.
[2019-03-24 02:41:15,909] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.22530119]
[2019-03-24 02:41:15,910] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.11666666666667, 64.83333333333333, 1.0, 2.0, 0.57415769305972, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9140777463616913, 6.911200000000002, 6.9112, 121.9255736170328, 1309191.211469885, 1309191.211469884, 283945.8569113317]
[2019-03-24 02:41:15,913] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:41:15,917] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9993491e-01 1.2650626e-09 1.9098281e-06 6.2743988e-10 6.3236374e-05], sampled 0.7495935901552209
[2019-03-24 02:41:15,918] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1309191.211469885 W.
[2019-03-24 02:41:40,929] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.22530119]
[2019-03-24 02:41:40,930] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.33333333333334, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.730282805460906, 6.9112, 6.9112, 121.9260426156618, 545238.1012693141, 545238.1012693141, 149719.4340793227]
[2019-03-24 02:41:40,931] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:41:40,933] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 7.3636263e-13 5.3859783e-09 8.1784135e-14 4.2616776e-08], sampled 0.38818165173224384
[2019-03-24 02:41:56,845] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.22530119]
[2019-03-24 02:41:56,846] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.07588164666667, 67.81614398666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7706358108451304, 6.9112, 6.9112, 121.9260426156618, 572579.4999186881, 572579.4999186881, 156624.661245214]
[2019-03-24 02:41:56,846] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:41:56,849] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9999988e-01 3.0636045e-12 1.4870793e-08 3.9909387e-13 1.1688856e-07], sampled 0.44920526396342475
[2019-03-24 02:42:01,665] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8363.4563 2339483817.1046 616.0000
[2019-03-24 02:42:01,930] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8559.5091 2258259887.1738 536.0000
[2019-03-24 02:42:01,974] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8402.8787 2292985444.6117 697.0000
[2019-03-24 02:42:02,222] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.1015 2219203276.8673 543.0000
[2019-03-24 02:42:02,237] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 02:42:03,252] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 750000, evaluation results [750000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8559.509129880978, 2258259887.1737776, 536.0, 8633.101490608233, 2219203276.8672857, 543.0, 8363.456347717898, 2339483817.1046495, 616.0, 8402.878669289861, 2292985444.6116962, 697.0]
[2019-03-24 02:42:20,200] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6912621e-03 5.0369246e-15 9.9012630e-12 1.1957814e-11 9.9830878e-01], sum to 1.0000
[2019-03-24 02:42:20,212] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3806
[2019-03-24 02:42:20,215] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.13333333333333, 96.0, 1.0, 2.0, 0.1910646486378696, 1.0, 2.0, 0.1910646486378696, 1.0, 2.0, 0.3043255681401659, 6.911199999999999, 6.9112, 121.94756008, 657775.8732603106, 657775.8732603111, 217706.1161075413], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4566000.0000, 
sim time next is 4566600.0000, 
raw observation next is [23.1, 97.0, 1.0, 2.0, 0.1922371510909975, 1.0, 2.0, 0.1922371510909975, 1.0, 2.0, 0.3061410782209974, 6.9112, 6.9112, 121.94756008, 660529.5832855297, 660529.5832855297, 218084.1672891986], 
processed observation next is [0.0, 0.8695652173913043, 0.41111111111111115, 0.97, 1.0, 1.0, 0.03837756082261608, 1.0, 1.0, 0.03837756082261608, 1.0, 1.0, 0.13267634777624673, 0.0, 0.0, 0.8096049824067558, 0.23590342260197492, 0.23590342260197492, 0.41939262940230504], 
reward next is 0.5806, 
noisyNet noise sample is [array([-0.6279381], dtype=float32), -1.3519204]. 
=============================================
[2019-03-24 02:42:23,777] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9861793e-02 2.0916166e-10 1.3853117e-10 6.0615934e-10 9.7013825e-01], sum to 1.0000
[2019-03-24 02:42:23,787] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2224
[2019-03-24 02:42:23,791] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.6, 65.0, 1.0, 2.0, 0.5652241638476101, 1.0, 2.0, 0.5652241638476101, 1.0, 2.0, 0.8998552769112779, 6.911199999999999, 6.9112, 121.94756008, 1933955.743189931, 1933955.743189931, 376753.7561549293], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4640400.0000, 
sim time next is 4641000.0000, 
raw observation next is [29.33333333333334, 67.33333333333334, 1.0, 2.0, 0.2860135552842121, 1.0, 2.0, 0.2860135552842121, 1.0, 2.0, 0.4553428948236605, 6.911199999999999, 6.9112, 121.94756008, 978038.4506195487, 978038.4506195491, 250757.533865435], 
processed observation next is [1.0, 0.7391304347826086, 0.6419753086419755, 0.6733333333333335, 1.0, 1.0, 0.1500161372431096, 1.0, 1.0, 0.1500161372431096, 1.0, 1.0, 0.31917861852957563, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3492994466498388, 0.349299446649839, 0.48222602666429804], 
reward next is 0.5178, 
noisyNet noise sample is [array([-1.540737], dtype=float32), 0.50175565]. 
=============================================
[2019-03-24 02:42:23,816] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[39.115543]
 [39.408825]
 [38.9904  ]
 [38.96568 ]
 [38.664677]], R is [[40.70234299]
 [40.57079315]
 [40.4821167 ]
 [40.37210083]
 [40.21157455]].
[2019-03-24 02:42:33,158] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.3384524e-04 6.4290388e-16 1.0299444e-13 1.4321962e-13 9.9956614e-01], sum to 1.0000
[2019-03-24 02:42:33,164] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6343
[2019-03-24 02:42:33,172] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.91666666666667, 93.33333333333334, 1.0, 2.0, 0.2367397167721546, 1.0, 2.0, 0.2367397167721546, 1.0, 2.0, 0.376897339175577, 6.9112, 6.9112, 121.94756008, 809454.9926113973, 809454.9926113973, 232972.5900934313], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4835400.0000, 
sim time next is 4836000.0000, 
raw observation next is [25.73333333333333, 94.66666666666667, 1.0, 2.0, 0.2366860238540019, 1.0, 2.0, 0.2366860238540019, 1.0, 2.0, 0.3768118583012218, 6.911200000000001, 6.9112, 121.94756008, 809271.3101193979, 809271.3101193975, 232953.9497034711], 
processed observation next is [1.0, 1.0, 0.5086419753086419, 0.9466666666666668, 1.0, 1.0, 0.09129288554047844, 1.0, 1.0, 0.09129288554047844, 1.0, 1.0, 0.22101482287652727, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.289025467899785, 0.28902546789978484, 0.4479883648143675], 
reward next is 0.5520, 
noisyNet noise sample is [array([-0.76807123], dtype=float32), 0.2568487]. 
=============================================
[2019-03-24 02:42:33,197] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[54.00906 ]
 [53.94404 ]
 [53.867607]
 [53.820053]
 [53.76887 ]], R is [[54.06568146]
 [54.07699966]
 [54.08826065]
 [54.09949493]
 [54.11046219]].
[2019-03-24 02:42:41,566] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6883150e-02 2.2833515e-12 4.2932265e-14 2.2295986e-08 9.7311687e-01], sum to 1.0000
[2019-03-24 02:42:41,578] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0602
[2019-03-24 02:42:41,585] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.86666666666667, 99.33333333333334, 1.0, 2.0, 0.1953876631497649, 1.0, 2.0, 0.1953876631497649, 1.0, 2.0, 0.3111010169480819, 6.9112, 6.9112, 121.94756008, 669589.2893743045, 669589.2893743045, 219099.7987036749], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5016000.0000, 
sim time next is 5016600.0000, 
raw observation next is [22.8, 99.0, 1.0, 2.0, 0.1931938947830133, 1.0, 2.0, 0.1931938947830133, 1.0, 2.0, 0.3076589837237612, 6.9112, 6.9112, 121.94756008, 663662.0104023876, 663662.0104023876, 218392.790023987], 
processed observation next is [0.0, 0.043478260869565216, 0.4, 0.99, 1.0, 1.0, 0.03951654140834916, 1.0, 1.0, 0.03951654140834916, 1.0, 1.0, 0.1345737296547015, 0.0, 0.0, 0.8096049824067558, 0.2370221465722813, 0.2370221465722813, 0.41998613466151347], 
reward next is 0.5800, 
noisyNet noise sample is [array([-0.4138962], dtype=float32), -0.15271054]. 
=============================================
[2019-03-24 02:42:43,042] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4421006e-04 1.6552990e-18 7.3894371e-20 5.7002729e-14 9.9985576e-01], sum to 1.0000
[2019-03-24 02:42:43,049] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6947
[2019-03-24 02:42:43,057] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 99.00000000000001, 1.0, 2.0, 0.215226249214496, 1.0, 2.0, 0.215226249214496, 1.0, 2.0, 0.3426471981790607, 6.911199999999999, 6.9112, 121.94756008, 735861.3368186769, 735861.3368186774, 225632.8968177532], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5001000.0000, 
sim time next is 5001600.0000, 
raw observation next is [24.0, 98.0, 1.0, 2.0, 0.213739187978656, 1.0, 2.0, 0.213739187978656, 1.0, 2.0, 0.3402797482614002, 6.911200000000001, 6.9112, 121.94756008, 730774.6320878646, 730774.6320878641, 225135.1252896349], 
processed observation next is [1.0, 0.9130434782608695, 0.4444444444444444, 0.98, 1.0, 1.0, 0.06397522378411427, 1.0, 1.0, 0.06397522378411427, 1.0, 1.0, 0.1753496853267502, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2609909400313802, 0.26099094003138, 0.43295216401852865], 
reward next is 0.5670, 
noisyNet noise sample is [array([-0.6530653], dtype=float32), -0.083682835]. 
=============================================
[2019-03-24 02:42:43,233] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.6766232e-05 5.5353557e-17 3.7371847e-19 1.2661521e-12 9.9993324e-01], sum to 1.0000
[2019-03-24 02:42:43,239] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1525
[2019-03-24 02:42:43,245] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 97.0, 1.0, 2.0, 0.1879258125935853, 1.0, 2.0, 0.1879258125935853, 1.0, 2.0, 0.2993492263464297, 6.911200000000001, 6.9112, 121.94756008, 647475.0639214312, 647475.0639214308, 216698.0082553732], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5023800.0000, 
sim time next is 5024400.0000, 
raw observation next is [23.0, 98.0, 1.0, 2.0, 0.1904736530209959, 1.0, 2.0, 0.1904736530209959, 1.0, 2.0, 0.3033318195625744, 6.911200000000001, 6.9112, 121.94756008, 654444.4218144172, 654444.4218144168, 217516.4573098376], 
processed observation next is [0.0, 0.13043478260869565, 0.4074074074074074, 0.98, 1.0, 1.0, 0.03627815835832844, 1.0, 1.0, 0.03627815835832844, 1.0, 1.0, 0.12916477445321795, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.23373015064800615, 0.23373015064800598, 0.4183008794419954], 
reward next is 0.5817, 
noisyNet noise sample is [array([1.035792], dtype=float32), 2.2096941]. 
=============================================
[2019-03-24 02:42:45,575] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.3663535e-05 9.1265610e-17 5.1363127e-20 1.4236259e-12 9.9996638e-01], sum to 1.0000
[2019-03-24 02:42:45,584] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2764
[2019-03-24 02:42:45,593] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.26666666666667, 67.66666666666667, 1.0, 2.0, 0.2521646635299219, 1.0, 2.0, 0.2521646635299219, 1.0, 2.0, 0.4014543567693872, 6.9112, 6.9112, 121.94756008, 862225.2762256707, 862225.2762256707, 238394.3244083577], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5062800.0000, 
sim time next is 5063400.0000, 
raw observation next is [31.45, 68.5, 1.0, 2.0, 0.2586144069529668, 1.0, 2.0, 0.2586144069529668, 1.0, 2.0, 0.4117225583523534, 6.911199999999999, 6.9112, 121.94756008, 884291.5698248325, 884291.569824833, 240700.7577311697], 
processed observation next is [0.0, 0.6086956521739131, 0.7203703703703703, 0.685, 1.0, 1.0, 0.11739810351543664, 1.0, 1.0, 0.11739810351543664, 1.0, 1.0, 0.2646531979404417, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.31581841779458303, 0.3158184177945832, 0.46288607255994174], 
reward next is 0.5371, 
noisyNet noise sample is [array([0.08917981], dtype=float32), 1.708036]. 
=============================================
[2019-03-24 02:42:49,979] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.2776302e-06 1.1285610e-19 4.9173549e-21 1.0283802e-15 9.9999273e-01], sum to 1.0000
[2019-03-24 02:42:49,989] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8661
[2019-03-24 02:42:49,992] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.18333333333333, 76.16666666666667, 1.0, 2.0, 0.2760994656637279, 1.0, 2.0, 0.2760994656637279, 1.0, 2.0, 0.4395593412684921, 6.9112, 6.9112, 121.94756008, 944115.817748599, 944115.817748599, 247070.2392276923], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5140200.0000, 
sim time next is 5140800.0000, 
raw observation next is [30.3, 76.0, 1.0, 2.0, 0.2781629348150235, 1.0, 2.0, 0.2781629348150235, 1.0, 2.0, 0.4428444513598532, 6.9112, 6.9112, 121.94756008, 951176.1815871573, 951176.1815871573, 247833.1767725741], 
processed observation next is [0.0, 0.5217391304347826, 0.6777777777777778, 0.76, 1.0, 1.0, 0.14067016049407563, 1.0, 1.0, 0.14067016049407563, 1.0, 1.0, 0.30355556419981644, 0.0, 0.0, 0.8096049824067558, 0.3397057791382705, 0.3397057791382705, 0.47660226302418096], 
reward next is 0.5234, 
noisyNet noise sample is [array([0.5325075], dtype=float32), -0.5265596]. 
=============================================
[2019-03-24 02:42:54,416] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 02:42:54,417] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:42:54,417] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:42:54,419] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:42:54,420] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:42:54,421] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:42:54,422] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:42:54,423] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:42:54,425] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:42:54,427] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:42:54,427] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:42:54,448] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run32
[2019-03-24 02:42:54,449] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run32
[2019-03-24 02:42:54,473] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run32
[2019-03-24 02:42:54,532] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run32
[2019-03-24 02:42:54,532] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run32
[2019-03-24 02:43:37,285] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.22935006]
[2019-03-24 02:43:37,286] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.58333333333334, 56.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2392135138931372, 6.9112, 6.9112, 121.94756008, 534180.3043214307, 534180.3043214307, 201357.7845190521]
[2019-03-24 02:43:37,287] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:43:37,290] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.5645802e-03 2.2970740e-12 1.8105851e-13 4.1615791e-10 9.9843544e-01], sampled 0.9676899782025806
[2019-03-24 02:43:42,677] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.22935006]
[2019-03-24 02:43:42,678] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.99165070833333, 91.289690835, 1.0, 2.0, 0.4095874595906651, 1.0, 2.0, 0.4095874595906651, 1.0, 2.0, 0.6520765750006304, 6.9112, 6.9112, 121.94756008, 1400992.258301151, 1400992.258301151, 301307.4395749266]
[2019-03-24 02:43:42,679] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:43:42,680] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.1443905e-03 2.7512504e-11 2.5282010e-12 3.1687455e-09 9.9785560e-01], sampled 0.7124775584166628
[2019-03-24 02:43:44,725] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.22935006]
[2019-03-24 02:43:44,726] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.93212700666666, 44.90831457833333, 1.0, 2.0, 0.1743951908927397, 1.0, 2.0, 0.1743951908927397, 1.0, 2.0, 0.2793137264115414, 6.911200000000001, 6.9112, 121.94756008, 616374.9947616992, 616374.9947616988, 212194.4462201659]
[2019-03-24 02:43:44,727] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:43:44,730] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.6475180e-03 1.0290045e-12 7.8958650e-14 2.1185990e-10 9.9835253e-01], sampled 0.007586001431427847
[2019-03-24 02:44:05,601] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.22935006]
[2019-03-24 02:44:05,602] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.33333333333334, 80.33333333333334, 1.0, 2.0, 0.1743252904291094, 1.0, 2.0, 0.1743252904291094, 1.0, 2.0, 0.278571351674304, 6.9112, 6.9112, 121.94756008, 611468.083073138, 611468.083073138, 212280.2843500403]
[2019-03-24 02:44:05,603] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:44:05,606] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.2650417e-03 1.0046128e-12 8.2522015e-14 2.0151698e-10 9.9773490e-01], sampled 0.5046604331576808
[2019-03-24 02:44:16,789] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.22935006]
[2019-03-24 02:44:16,790] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.33333333333334, 70.83333333333334, 1.0, 2.0, 0.162402223839403, 1.0, 2.0, 0.162402223839403, 1.0, 2.0, 0.2603001363402712, 6.9112, 6.9112, 121.94756008, 575202.2555641498, 575202.2555641498, 208446.6000085691]
[2019-03-24 02:44:16,792] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:44:16,795] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.2987019e-03 1.1026687e-11 1.1431563e-12 1.3776711e-09 9.9570125e-01], sampled 0.04876206326084587
[2019-03-24 02:44:19,600] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.22935006]
[2019-03-24 02:44:19,601] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.62649103166666, 60.00224979166666, 1.0, 2.0, 0.1913654190993211, 1.0, 2.0, 0.1913654190993211, 1.0, 2.0, 0.3047433689857715, 6.9112, 6.9112, 121.94756008, 657272.6089404625, 657272.6089404625, 217803.1599654938]
[2019-03-24 02:44:19,602] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:44:19,605] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.5892702e-03 7.8994771e-12 7.7593265e-13 1.0665296e-09 9.9641079e-01], sampled 0.1371111463416551
[2019-03-24 02:44:33,031] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4400.8318 2874029181.4796 9.0000
[2019-03-24 02:44:33,179] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4284.0505 2918473060.8315 34.0000
[2019-03-24 02:44:33,243] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4625.0994 2892939899.1403 13.0000
[2019-03-24 02:44:33,668] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4507.6775 3105560752.2763 5.0000
[2019-03-24 02:44:33,672] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4500.2007 2938640524.3744 30.0000
[2019-03-24 02:44:34,685] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 775000, evaluation results [775000.0, 4507.677496093036, 3105560752.276286, 5.0, 4625.099371867721, 2892939899.1402545, 13.0, 4400.831783393684, 2874029181.4796453, 9.0, 4500.200738421423, 2938640524.3744473, 30.0, 4284.050531000356, 2918473060.831481, 34.0]
[2019-03-24 02:44:34,802] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0477486e-02 8.7389462e-10 6.6572838e-11 6.7627248e-08 9.8952240e-01], sum to 1.0000
[2019-03-24 02:44:34,817] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5103
[2019-03-24 02:44:34,824] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.98333333333333, 78.0, 1.0, 2.0, 0.5980763998469633, 1.0, 2.0, 0.5980763998469633, 1.0, 2.0, 0.9521571065448794, 6.9112, 6.9112, 121.94756008, 2046490.840063918, 2046490.840063918, 394328.5138260337], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5226600.0000, 
sim time next is 5227200.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.6134373426977203, 1.0, 2.0, 0.6134373426977203, 1.0, 2.0, 0.9766122278342675, 6.9112, 6.9112, 121.94756008, 2099114.503995996, 2099114.503995996, 402745.5469068641], 
processed observation next is [1.0, 0.5217391304347826, 0.5925925925925926, 0.79, 1.0, 1.0, 0.539806360354429, 1.0, 1.0, 0.539806360354429, 1.0, 1.0, 0.9707652847928344, 0.0, 0.0, 0.8096049824067558, 0.7496837514271414, 0.7496837514271414, 0.7745106671285849], 
reward next is 0.2255, 
noisyNet noise sample is [array([-0.00328297], dtype=float32), 0.30649075]. 
=============================================
[2019-03-24 02:44:34,939] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5569942e-03 1.0033021e-10 5.6525080e-12 1.1256921e-09 9.9844307e-01], sum to 1.0000
[2019-03-24 02:44:34,947] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7295
[2019-03-24 02:44:34,952] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.33333333333334, 100.0, 1.0, 2.0, 0.2461809949257507, 1.0, 2.0, 0.2461809949257507, 1.0, 2.0, 0.3919281614770651, 6.9112, 6.9112, 121.94756008, 841754.1169711077, 841754.1169711077, 236275.3355104837], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5206800.0000, 
sim time next is 5207400.0000, 
raw observation next is [23.5, 100.0, 1.0, 2.0, 0.2527269495109459, 1.0, 2.0, 0.2527269495109459, 1.0, 2.0, 0.4023495343635534, 6.911199999999999, 6.9112, 121.94756008, 864148.9813584094, 864148.9813584097, 238594.4739668215], 
processed observation next is [1.0, 0.2608695652173913, 0.42592592592592593, 1.0, 1.0, 1.0, 0.1103892256082689, 1.0, 1.0, 0.1103892256082689, 1.0, 1.0, 0.25293691795444173, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3086246361994319, 0.30862463619943203, 0.45883552685927215], 
reward next is 0.5412, 
noisyNet noise sample is [array([-0.05093653], dtype=float32), -0.6405824]. 
=============================================
[2019-03-24 02:44:37,431] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7915093e-04 9.2585241e-14 3.4180325e-15 5.3696235e-11 9.9982089e-01], sum to 1.0000
[2019-03-24 02:44:37,441] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8844
[2019-03-24 02:44:37,448] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.2, 84.33333333333334, 1.0, 2.0, 0.2848261069161704, 1.0, 2.0, 0.2848261069161704, 1.0, 2.0, 0.4534524383492446, 6.9112, 6.9112, 121.94756008, 973975.3282108229, 973975.3282108229, 250313.0030530194], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5280000.0000, 
sim time next is 5280600.0000, 
raw observation next is [25.15, 84.16666666666666, 1.0, 2.0, 0.2734242012065284, 1.0, 2.0, 0.2734242012065284, 1.0, 2.0, 0.4353002331253498, 6.9112, 6.9112, 121.94756008, 934962.2325645986, 934962.2325645986, 246084.635398731], 
processed observation next is [1.0, 0.08695652173913043, 0.487037037037037, 0.8416666666666666, 1.0, 1.0, 0.13502881096015285, 1.0, 1.0, 0.13502881096015285, 1.0, 1.0, 0.29412529140668725, 0.0, 0.0, 0.8096049824067558, 0.3339150830587852, 0.3339150830587852, 0.4732396834590981], 
reward next is 0.5268, 
noisyNet noise sample is [array([0.05906523], dtype=float32), -1.2556467]. 
=============================================
[2019-03-24 02:44:38,015] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0743201e-03 8.7470429e-18 7.8878123e-17 7.5234534e-15 9.9892563e-01], sum to 1.0000
[2019-03-24 02:44:38,022] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7115
[2019-03-24 02:44:38,027] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.25, 86.0, 1.0, 2.0, 0.1993521123056969, 1.0, 2.0, 0.1993521123056969, 1.0, 2.0, 0.3175816573666784, 6.911200000000001, 6.9112, 121.94756008, 687505.8814494036, 687505.8814494031, 220390.5283033766], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5286600.0000, 
sim time next is 5287200.0000, 
raw observation next is [24.13333333333333, 86.33333333333334, 1.0, 2.0, 0.1941920158757314, 1.0, 2.0, 0.1941920158757314, 1.0, 2.0, 0.3094278934703316, 6.911200000000001, 6.9112, 121.94756008, 670942.8983296241, 670942.8983296236, 218709.4235317539], 
processed observation next is [1.0, 0.17391304347826086, 0.44938271604938257, 0.8633333333333334, 1.0, 1.0, 0.04070478080444214, 1.0, 1.0, 0.04070478080444214, 1.0, 1.0, 0.1367848668379145, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.23962246368915147, 0.2396224636891513, 0.42059504525337293], 
reward next is 0.5794, 
noisyNet noise sample is [array([0.72031873], dtype=float32), 0.015744686]. 
=============================================
[2019-03-24 02:44:39,505] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6048842e-04 2.4249913e-11 7.3954628e-13 5.8763255e-10 9.9983954e-01], sum to 1.0000
[2019-03-24 02:44:39,512] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0204
[2019-03-24 02:44:39,515] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.2, 68.0, 1.0, 2.0, 0.3163430283210463, 1.0, 2.0, 0.3163430283210463, 1.0, 2.0, 0.5036284036602782, 6.911199999999999, 6.9112, 121.94756008, 1081824.885300457, 1081824.885300458, 262377.9742584599], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5317800.0000, 
sim time next is 5318400.0000, 
raw observation next is [27.4, 67.0, 1.0, 2.0, 0.4354656781628387, 1.0, 2.0, 0.4354656781628387, 1.0, 2.0, 0.6932755417622711, 6.911199999999999, 6.9112, 121.94756008, 1489594.670565726, 1489594.670565726, 312966.3701108519], 
processed observation next is [1.0, 0.5652173913043478, 0.5703703703703703, 0.67, 1.0, 1.0, 0.3279353311462366, 1.0, 1.0, 0.3279353311462366, 1.0, 1.0, 0.6165944272028389, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5319980966306165, 0.5319980966306165, 0.6018584040593306], 
reward next is 0.3981, 
noisyNet noise sample is [array([-1.2218894], dtype=float32), -0.16757408]. 
=============================================
[2019-03-24 02:44:40,385] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.9066174e-03 1.8093649e-12 1.5418651e-13 7.4404989e-11 9.9309337e-01], sum to 1.0000
[2019-03-24 02:44:40,391] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9096
[2019-03-24 02:44:40,395] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.45, 72.0, 1.0, 2.0, 0.3727073731342595, 1.0, 2.0, 0.3727073731342595, 1.0, 2.0, 0.5933622762614701, 6.9112, 6.9112, 121.94756008, 1274739.11660511, 1274739.11660511, 285332.9571347913], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5315400.0000, 
sim time next is 5316000.0000, 
raw observation next is [26.63333333333333, 71.0, 1.0, 2.0, 0.4176301115502992, 1.0, 2.0, 0.4176301115502992, 1.0, 2.0, 0.6648807388512559, 6.9112, 6.9112, 121.94756008, 1428527.768823709, 1428527.768823709, 304891.2002118095], 
processed observation next is [1.0, 0.5217391304347826, 0.5419753086419752, 0.71, 1.0, 1.0, 0.30670251375035623, 1.0, 1.0, 0.30670251375035623, 1.0, 1.0, 0.5811009235640698, 0.0, 0.0, 0.8096049824067558, 0.5101884888656104, 0.5101884888656104, 0.5863292311765567], 
reward next is 0.4137, 
noisyNet noise sample is [array([-0.05036463], dtype=float32), 0.28248036]. 
=============================================
[2019-03-24 02:44:40,422] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[45.355118]
 [44.97515 ]
 [44.328175]
 [44.913094]
 [45.011574]], R is [[45.23596954]
 [45.2348938 ]
 [45.20860291]
 [45.09502792]
 [45.05728149]].
[2019-03-24 02:44:43,083] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.6608082e-03 5.8083902e-14 8.3993725e-16 3.0043432e-14 9.9133915e-01], sum to 1.0000
[2019-03-24 02:44:43,091] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3644
[2019-03-24 02:44:43,095] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.3, 91.0, 1.0, 2.0, 0.2117640610215613, 1.0, 2.0, 0.2117640610215613, 1.0, 2.0, 0.3371352818203112, 6.9112, 6.9112, 121.94756008, 724018.4812324957, 724018.4812324957, 224475.8941868221], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5377200.0000, 
sim time next is 5377800.0000, 
raw observation next is [24.35, 91.0, 1.0, 2.0, 0.2185839228111887, 1.0, 2.0, 0.2185839228111887, 1.0, 2.0, 0.3479927238967904, 6.911200000000001, 6.9112, 121.94756008, 747346.861658191, 747346.8616581905, 226761.3784095321], 
processed observation next is [1.0, 0.21739130434782608, 0.4574074074074075, 0.91, 1.0, 1.0, 0.06974276525141514, 1.0, 1.0, 0.06974276525141514, 1.0, 1.0, 0.18499090487098802, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2669095934493539, 0.2669095934493537, 0.4360795738644848], 
reward next is 0.5639, 
noisyNet noise sample is [array([-0.8796192], dtype=float32), 2.1722252]. 
=============================================
[2019-03-24 02:44:43,704] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.8353254e-01 5.1740069e-14 4.3265423e-14 7.3212573e-12 3.1646746e-01], sum to 1.0000
[2019-03-24 02:44:43,713] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2197
[2019-03-24 02:44:43,723] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 688112.5706099408 W.
[2019-03-24 02:44:43,729] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.2, 91.0, 1.0, 2.0, 0.2012668553443242, 1.0, 2.0, 0.2012668553443242, 1.0, 2.0, 0.320423388512028, 6.911200000000001, 6.9112, 121.94756008, 688112.5706099408, 688112.5706099403, 221008.9157226438], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5376000.0000, 
sim time next is 5376600.0000, 
raw observation next is [24.25, 91.0, 1.0, 2.0, 0.300422229208084, 1.0, 2.0, 0.300422229208084, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686235.6816183855, 686235.6816183855, 180636.9560981043], 
processed observation next is [1.0, 0.21739130434782608, 0.4537037037037037, 0.91, 1.0, 1.0, 0.16716932048581426, 1.0, 1.0, 0.16716932048581426, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24508417200656624, 0.24508417200656624, 0.3473787617271237], 
reward next is 0.6526, 
noisyNet noise sample is [array([1.548468], dtype=float32), 1.5864367]. 
=============================================
[2019-03-24 02:44:46,293] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9815434e-01 4.0583381e-10 4.9878223e-11 1.2303550e-08 1.8455891e-03], sum to 1.0000
[2019-03-24 02:44:46,303] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8340
[2019-03-24 02:44:46,310] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 882333.5566279601 W.
[2019-03-24 02:44:46,313] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.73333333333333, 87.0, 1.0, 2.0, 0.3870631226829516, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6162170970771104, 6.911199999999999, 6.9112, 121.9260426156618, 882333.5566279601, 882333.5566279605, 220147.1354596802], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5437200.0000, 
sim time next is 5437800.0000, 
raw observation next is [27.65, 87.5, 1.0, 2.0, 0.3862559121648701, 1.0, 1.0, 0.3862559121648701, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 880492.4149241204, 880492.4149241209, 202449.6559724773], 
processed observation next is [1.0, 0.9565217391304348, 0.5796296296296296, 0.875, 1.0, 1.0, 0.26935227638675013, 1.0, 0.5, 0.26935227638675013, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3144615767586144, 0.3144615767586146, 0.3893262614855333], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.45408806], dtype=float32), 0.67211145]. 
=============================================
[2019-03-24 02:44:48,265] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.2188836e-05 2.5368141e-13 5.2818444e-16 2.8670801e-09 9.9995780e-01], sum to 1.0000
[2019-03-24 02:44:48,273] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7234
[2019-03-24 02:44:48,279] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 89.33333333333334, 1.0, 2.0, 0.5752439364852421, 1.0, 2.0, 0.5752439364852421, 1.0, 2.0, 0.915807081271601, 6.911199999999999, 6.9112, 121.94756008, 1968276.899219117, 1968276.899219118, 382052.2921886598], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5474400.0000, 
sim time next is 5475000.0000, 
raw observation next is [28.15, 88.66666666666667, 1.0, 2.0, 0.5979421932531167, 1.0, 2.0, 0.5979421932531167, 1.0, 2.0, 0.9519434452766721, 6.911199999999999, 6.9112, 121.94756008, 2046031.087502918, 2046031.087502919, 394255.5349718799], 
processed observation next is [1.0, 0.34782608695652173, 0.5981481481481481, 0.8866666666666667, 1.0, 1.0, 0.521359753872758, 1.0, 1.0, 0.521359753872758, 1.0, 1.0, 0.93992930659584, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7307253883938992, 0.7307253883938996, 0.7581837210997691], 
reward next is 0.2418, 
noisyNet noise sample is [array([1.6599066], dtype=float32), 0.70687664]. 
=============================================
[2019-03-24 02:44:48,299] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[37.453712]
 [37.65116 ]
 [38.130383]
 [38.659786]
 [38.853027]], R is [[36.96537399]
 [36.86100769]
 [36.77927399]
 [36.74200439]
 [36.83907318]].
[2019-03-24 02:44:55,965] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.6043845e-04 3.6897441e-19 2.7701463e-22 1.3191027e-13 9.9963951e-01], sum to 1.0000
[2019-03-24 02:44:55,974] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7939
[2019-03-24 02:44:55,980] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.8, 93.0, 1.0, 2.0, 0.232963887824669, 1.0, 2.0, 0.232963887824669, 1.0, 2.0, 0.3708860965210162, 6.9112, 6.9112, 121.94756008, 796538.058043301, 796538.058043301, 231665.6761005787], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5601600.0000, 
sim time next is 5602200.0000, 
raw observation next is [25.68333333333333, 93.16666666666667, 1.0, 2.0, 0.2325048717736608, 1.0, 2.0, 0.2325048717736608, 1.0, 2.0, 0.370155328018702, 6.9112, 6.9112, 121.94756008, 794967.8003974764, 794967.8003974764, 231507.3418446963], 
processed observation next is [1.0, 0.8695652173913043, 0.50679012345679, 0.9316666666666668, 1.0, 1.0, 0.08631532354007239, 1.0, 1.0, 0.08631532354007239, 1.0, 1.0, 0.21269416002337746, 0.0, 0.0, 0.8096049824067558, 0.2839170715705273, 0.2839170715705273, 0.44520642662441595], 
reward next is 0.5548, 
noisyNet noise sample is [array([0.85754246], dtype=float32), -1.1527294]. 
=============================================
[2019-03-24 02:45:03,971] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.00000000e+00 1.03047316e-22 1.30355350e-24 1.29000624e-21
 1.83859677e-12], sum to 1.0000
[2019-03-24 02:45:03,976] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7381
[2019-03-24 02:45:03,980] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.4, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7387843423913458, 6.911199999999999, 6.9112, 121.9260426156618, 551548.2291505411, 551548.2291505416, 150754.1381436141], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5736600.0000, 
sim time next is 5737200.0000, 
raw observation next is [23.6, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7448778774898102, 6.911200000000001, 6.9112, 121.9260426156618, 555998.5738849213, 555998.5738849208, 151595.6284596979], 
processed observation next is [0.0, 0.391304347826087, 0.4296296296296297, 0.77, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6810973468622628, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19857091924461473, 0.19857091924461456, 0.2915300547301883], 
reward next is 0.7085, 
noisyNet noise sample is [array([-1.2727907], dtype=float32), 1.3892049]. 
=============================================
[2019-03-24 02:45:07,964] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.1144754e-21 7.0677848e-23 1.5859263e-18 2.3728516e-10], sum to 1.0000
[2019-03-24 02:45:07,971] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1402
[2019-03-24 02:45:07,974] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.11666666666667, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8075303021212499, 6.9112, 6.9112, 121.9260426156618, 602675.2901447616, 602675.2901447616, 159200.5335034451], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5811000.0000, 
sim time next is 5811600.0000, 
raw observation next is [22.23333333333333, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7729813259379745, 6.911200000000001, 6.9112, 121.9260426156618, 576905.2046614945, 576905.204661494, 154998.837512852], 
processed observation next is [1.0, 0.2608695652173913, 0.37901234567901226, 0.87, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7162266574224682, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20603757309339088, 0.2060375730933907, 0.2980746875247154], 
reward next is 0.7019, 
noisyNet noise sample is [array([-1.184749], dtype=float32), -0.13254783]. 
=============================================
[2019-03-24 02:45:07,999] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9435270e-01 1.8146698e-14 4.2911341e-17 1.3529047e-10 5.6472500e-03], sum to 1.0000
[2019-03-24 02:45:08,005] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8859
[2019-03-24 02:45:08,010] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 984519.3885217751 W.
[2019-03-24 02:45:08,014] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.1, 58.66666666666667, 1.0, 2.0, 0.7982635223588522, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 984519.3885217751, 984519.3885217747, 198701.937358675], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5823600.0000, 
sim time next is 5824200.0000, 
raw observation next is [25.25, 56.83333333333334, 1.0, 2.0, 0.3983742614390994, 1.0, 1.0, 0.3983742614390994, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 974632.6391729994, 974632.6391729994, 208372.9781750416], 
processed observation next is [1.0, 0.391304347826087, 0.49074074074074076, 0.5683333333333335, 1.0, 1.0, 0.2837788826655945, 1.0, 0.5, 0.2837788826655945, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.34808308541892835, 0.34808308541892835, 0.40071726572123384], 
reward next is 0.5993, 
noisyNet noise sample is [array([1.1337417], dtype=float32), -0.7057041]. 
=============================================
[2019-03-24 02:45:08,582] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 3.6342103e-19 2.7882169e-22 3.1750474e-16 3.9839958e-09], sum to 1.0000
[2019-03-24 02:45:08,589] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9207
[2019-03-24 02:45:08,595] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.86666666666667, 49.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6372944566893355, 6.9112, 6.9112, 121.9260426156618, 475641.8363223913, 475641.8363223913, 136416.6612304895], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5854800.0000, 
sim time next is 5855400.0000, 
raw observation next is [26.7, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6420937537517868, 6.911200000000001, 6.9112, 121.9260426156618, 479378.4566022526, 479378.4566022522, 137150.0138856039], 
processed observation next is [1.0, 0.782608695652174, 0.5444444444444444, 0.51, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5526171921897335, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17120659164366164, 0.1712065916436615, 0.2637500267030844], 
reward next is 0.7362, 
noisyNet noise sample is [array([-0.8747699], dtype=float32), 0.41225892]. 
=============================================
[2019-03-24 02:45:13,422] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9999893e-01 1.6282061e-23 1.8470113e-25 2.1327520e-18 1.1046294e-06], sum to 1.0000
[2019-03-24 02:45:13,429] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4712
[2019-03-24 02:45:13,434] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.06666666666667, 59.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7729678669294003, 6.911200000000001, 6.9112, 121.9260426156618, 575298.3605007052, 575298.3605007047, 156349.8409842486], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5944200.0000, 
sim time next is 5944800.0000, 
raw observation next is [26.93333333333334, 60.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7735665901371386, 6.9112, 6.9112, 121.9260426156618, 575769.0626480659, 575769.0626480659, 156406.3963884203], 
processed observation next is [1.0, 0.8260869565217391, 0.5530864197530867, 0.6033333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7169582376714231, 0.0, 0.0, 0.8094621288201359, 0.20563180808859494, 0.20563180808859494, 0.3007815315161929], 
reward next is 0.6992, 
noisyNet noise sample is [array([0.40439072], dtype=float32), 1.5381166]. 
=============================================
[2019-03-24 02:45:21,990] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9998808e-01 4.6414261e-16 1.1549270e-18 7.6197364e-12 1.1863260e-05], sum to 1.0000
[2019-03-24 02:45:21,996] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4165
[2019-03-24 02:45:22,004] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1645037.934054812 W.
[2019-03-24 02:45:22,008] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.63333333333333, 61.66666666666667, 1.0, 2.0, 0.4808617795994619, 1.0, 2.0, 0.4808617795994619, 1.0, 2.0, 0.7655476136971833, 6.9112, 6.9112, 121.94756008, 1645037.934054812, 1645037.934054812, 334295.1146351009], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6090000.0000, 
sim time next is 6090600.0000, 
raw observation next is [28.76666666666667, 60.83333333333333, 1.0, 2.0, 0.8058892076151641, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1633662.257714544, 1633662.257714544, 337401.3432973645], 
processed observation next is [1.0, 0.4782608695652174, 0.6209876543209878, 0.6083333333333333, 1.0, 1.0, 0.7689157233513859, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.5834508063266228, 0.5834508063266228, 0.6488487371103163], 
reward next is 0.3512, 
noisyNet noise sample is [array([0.49267057], dtype=float32), -1.1139294]. 
=============================================
[2019-03-24 02:45:25,583] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 02:45:25,584] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:45:25,585] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:45:25,585] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:45:25,586] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:45:25,587] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:45:25,588] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:45:25,588] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:45:25,590] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:45:25,590] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:45:25,592] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:45:25,608] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run33
[2019-03-24 02:45:25,608] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run33
[2019-03-24 02:45:25,632] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run33
[2019-03-24 02:45:25,659] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run33
[2019-03-24 02:45:25,681] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run33
[2019-03-24 02:45:40,294] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.23370966]
[2019-03-24 02:45:40,295] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.68095057333333, 64.82091983000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6118108315847096, 6.9112, 6.9112, 121.9260426156618, 455851.1867543792, 455851.1867543792, 132939.513626021]
[2019-03-24 02:45:40,298] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:45:40,304] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 4.6237167e-18 2.5073586e-18 1.9174007e-15 1.0362994e-11], sampled 0.13661845677123663
[2019-03-24 02:45:56,052] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.23370966]
[2019-03-24 02:45:56,053] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.0, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6266794381954713, 6.9112, 6.9112, 121.9260426156618, 467008.9872590883, 467008.9872590883, 134477.8742068073]
[2019-03-24 02:45:56,055] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:45:56,057] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.1517203e-18 6.9601076e-19 6.0670651e-16 4.2909834e-12], sampled 0.0628336292359768
[2019-03-24 02:46:19,243] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.23370966]
[2019-03-24 02:46:19,247] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.07267876, 99.014793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8068665251698034, 6.9112, 6.9112, 121.9260426156618, 596643.5995589994, 596643.5995589994, 162272.3197941951]
[2019-03-24 02:46:19,247] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:46:19,250] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.8736155e-18 1.5509032e-18 1.2781025e-15 7.6776571e-12], sampled 0.7080321550055332
[2019-03-24 02:46:36,430] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.23370966]
[2019-03-24 02:46:36,432] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.81666666666667, 70.33333333333333, 1.0, 2.0, 0.7178737749471283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818183.8974090284, 818183.8974090284, 179558.2774629252]
[2019-03-24 02:46:36,433] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:46:36,435] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.1997213e-18 2.5232661e-19 7.5207177e-16 1.0387275e-11], sampled 0.20067321581715014
[2019-03-24 02:46:36,437] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 818183.8974090284 W.
[2019-03-24 02:46:38,254] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.23370966]
[2019-03-24 02:46:38,255] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.9, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8597710810519296, 6.9112, 6.9112, 121.9260426156618, 633081.7549482768, 633081.7549482768, 169769.1336286567]
[2019-03-24 02:46:38,255] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:46:38,257] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.7349095e-20 1.7620671e-20 3.2451609e-17 5.1179032e-13], sampled 0.843651891999569
[2019-03-24 02:47:01,048] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.23370966]
[2019-03-24 02:47:01,049] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.7, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4691331103139398, 6.911200000000001, 6.9112, 121.9260426156618, 334976.5147017079, 334976.5147017075, 108560.8104443203]
[2019-03-24 02:47:01,051] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:47:01,053] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 3.8173194e-18 2.3897835e-18 1.6829013e-15 9.1625431e-12], sampled 0.5924994924824917
[2019-03-24 02:47:03,588] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.23370966]
[2019-03-24 02:47:03,589] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.36666666666667, 83.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6501751965909968, 6.9112, 6.9112, 121.9260426156618, 485267.5968747713, 485267.5968747713, 137741.9688379283]
[2019-03-24 02:47:03,589] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:47:03,594] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 6.3664022e-18 3.7829778e-18 2.5334175e-15 1.2452634e-11], sampled 0.7189517342941905
[2019-03-24 02:47:04,345] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.7414 2219189295.2583 543.0000
[2019-03-24 02:47:04,352] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 02:47:04,371] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 02:47:04,417] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 02:47:04,459] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 02:47:05,477] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 800000, evaluation results [800000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.741374971278, 2219189295.2583184, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 02:47:14,920] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.9784497e-17 1.2269970e-17 3.7027042e-14 4.8147751e-08], sum to 1.0000
[2019-03-24 02:47:14,930] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6599
[2019-03-24 02:47:14,939] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 705847.7008035043 W.
[2019-03-24 02:47:14,944] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.43333333333333, 85.0, 1.0, 2.0, 0.2064518377666553, 1.0, 1.0, 0.2064518377666553, 1.0, 2.0, 0.3286780493914677, 6.911200000000001, 6.9112, 121.94756008, 705847.7008035043, 705847.7008035039, 222713.6842108649], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6336600.0000, 
sim time next is 6337200.0000, 
raw observation next is [25.66666666666667, 84.0, 1.0, 2.0, 0.3116335983195321, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4961308377224399, 6.911199999999999, 6.9112, 121.9260426156618, 710307.7686829177, 710307.7686829182, 198396.7722283018], 
processed observation next is [0.0, 0.34782608695652173, 0.506172839506173, 0.84, 1.0, 1.0, 0.18051618847563344, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.37016354715304983, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25368134595818487, 0.25368134595818503, 0.38153225428519577], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9950262], dtype=float32), -0.7130049]. 
=============================================
[2019-03-24 02:47:16,120] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 6.0939038e-23 7.1542698e-21 5.7843686e-19 7.1035268e-13], sum to 1.0000
[2019-03-24 02:47:16,127] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2941
[2019-03-24 02:47:16,131] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.66666666666666, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.928054712210071, 6.911199999999999, 6.9112, 121.9260426156618, 676356.1104079626, 676356.110407963, 180242.5423486725], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6331200.0000, 
sim time next is 6331800.0000, 
raw observation next is [24.73333333333333, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9339782695011618, 6.9112, 6.9112, 121.9260426156618, 679923.454435276, 679923.454435276, 181176.7816811645], 
processed observation next is [0.0, 0.2608695652173913, 0.4716049382716048, 0.87, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9174728368764523, 0.0, 0.0, 0.8094621288201359, 0.2428298051554557, 0.2428298051554557, 0.34841688784839325], 
reward next is 0.6516, 
noisyNet noise sample is [array([-1.3468494], dtype=float32), 0.96319956]. 
=============================================
[2019-03-24 02:47:17,643] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.1130645e-17 8.0751332e-18 5.9252055e-14 3.1017407e-08], sum to 1.0000
[2019-03-24 02:47:17,653] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6309
[2019-03-24 02:47:17,661] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 783257.7524666307 W.
[2019-03-24 02:47:17,663] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.11666666666667, 69.33333333333333, 1.0, 2.0, 0.2290817733224881, 1.0, 1.0, 0.2290817733224881, 1.0, 2.0, 0.3647056438019015, 6.9112, 6.9112, 121.94756008, 783257.7524666307, 783257.7524666307, 230330.2835439598], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6382200.0000, 
sim time next is 6382800.0000, 
raw observation next is [29.0, 70.0, 1.0, 2.0, 0.2291456284239212, 1.0, 2.0, 0.2291456284239212, 1.0, 2.0, 0.3648073032029984, 6.9112, 6.9112, 121.94756008, 783476.1921945001, 783476.1921945001, 230352.1806389777], 
processed observation next is [0.0, 0.9130434782608695, 0.6296296296296297, 0.7, 1.0, 1.0, 0.0823162243141919, 1.0, 1.0, 0.0823162243141919, 1.0, 1.0, 0.20600912900374801, 0.0, 0.0, 0.8096049824067558, 0.27981292578375005, 0.27981292578375005, 0.4429849627672648], 
reward next is 0.5570, 
noisyNet noise sample is [array([-1.4846482], dtype=float32), 0.022303313]. 
=============================================
[2019-03-24 02:47:18,660] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9771440e-01 1.9758215e-09 1.8846438e-10 6.8797817e-07 2.2848647e-03], sum to 1.0000
[2019-03-24 02:47:18,666] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1956
[2019-03-24 02:47:18,673] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2000580.260040896 W.
[2019-03-24 02:47:18,676] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.9, 88.5, 1.0, 2.0, 0.5846742790866203, 1.0, 1.0, 0.5846742790866203, 1.0, 1.0, 0.9308204938178122, 6.9112, 6.9112, 121.94756008, 2000580.260040896, 2000580.260040896, 387088.600946565], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6424200.0000, 
sim time next is 6424800.0000, 
raw observation next is [26.13333333333333, 87.66666666666666, 1.0, 2.0, 0.5264118509300632, 1.0, 2.0, 0.5264118509300632, 1.0, 2.0, 0.8380648107177578, 6.911199999999999, 6.9112, 121.94756008, 1801022.712282686, 1801022.712282686, 356741.3755684916], 
processed observation next is [1.0, 0.34782608695652173, 0.5234567901234567, 0.8766666666666666, 1.0, 1.0, 0.4362045844405513, 1.0, 1.0, 0.4362045844405513, 1.0, 1.0, 0.7975810133971972, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6432223972438165, 0.6432223972438165, 0.6860411068624838], 
reward next is 0.3140, 
noisyNet noise sample is [array([-1.3884696], dtype=float32), -1.8285469]. 
=============================================
[2019-03-24 02:47:21,566] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.0528309e-03 4.9227750e-13 1.6300551e-12 4.8836182e-07 9.9594671e-01], sum to 1.0000
[2019-03-24 02:47:21,574] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4478
[2019-03-24 02:47:21,578] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.9, 54.5, 1.0, 2.0, 0.6087182118043775, 1.0, 2.0, 0.6087182118043775, 1.0, 2.0, 0.9690992177607023, 6.911199999999999, 6.9112, 121.94756008, 2082947.330585564, 2082947.330585565, 400146.1851745872], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6449400.0000, 
sim time next is 6450000.0000, 
raw observation next is [31.83333333333334, 54.66666666666667, 1.0, 2.0, 0.5967835296696242, 1.0, 2.0, 0.5967835296696242, 1.0, 2.0, 0.9500988151167135, 6.911200000000001, 6.9112, 121.94756008, 2042061.85459279, 2042061.85459279, 393625.880288095], 
processed observation next is [1.0, 0.6521739130434783, 0.7345679012345682, 0.5466666666666667, 1.0, 1.0, 0.5199803924638383, 1.0, 1.0, 0.5199803924638383, 1.0, 1.0, 0.9376235188958917, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7293078052117107, 0.7293078052117107, 0.756972846707875], 
reward next is 0.2430, 
noisyNet noise sample is [array([0.6783745], dtype=float32), -1.0331831]. 
=============================================
[2019-03-24 02:47:21,597] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[35.500988]
 [35.397205]
 [35.25285 ]
 [35.01747 ]
 [34.938385]], R is [[35.5850296 ]
 [35.45966721]
 [35.34220505]
 [35.21849442]
 [35.06464386]].
[2019-03-24 02:47:24,687] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5089988e-03 8.8006528e-13 5.3818529e-14 6.3667488e-07 9.9749041e-01], sum to 1.0000
[2019-03-24 02:47:24,700] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3281
[2019-03-24 02:47:24,706] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.5, 84.0, 1.0, 2.0, 0.2955065124032541, 1.0, 2.0, 0.2955065124032541, 1.0, 2.0, 0.4704559917212048, 6.9112, 6.9112, 121.94756008, 1010521.518894259, 1010521.518894259, 254339.5603610057], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6494400.0000, 
sim time next is 6495000.0000, 
raw observation next is [26.46666666666667, 84.33333333333333, 1.0, 2.0, 0.3270072054692482, 1.0, 2.0, 0.3270072054692482, 1.0, 2.0, 0.5206061209882182, 6.911199999999999, 6.9112, 121.94756008, 1118320.680309133, 1118320.680309134, 266585.5769246672], 
processed observation next is [1.0, 0.17391304347826086, 0.5358024691358025, 0.8433333333333333, 1.0, 1.0, 0.19881810174910503, 1.0, 1.0, 0.19881810174910503, 1.0, 1.0, 0.40075765123527274, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.39940024296754745, 0.3994002429675479, 0.5126645710089754], 
reward next is 0.4873, 
noisyNet noise sample is [array([0.45558316], dtype=float32), -0.38292298]. 
=============================================
[2019-03-24 02:47:24,728] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[38.140846]
 [38.178085]
 [38.17607 ]
 [38.292397]
 [38.294907]], R is [[38.08869553]
 [38.21869659]
 [38.35258102]
 [38.48125839]
 [38.60371399]].
[2019-03-24 02:47:25,123] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0025196e-03 1.3266310e-15 4.2685704e-15 2.9835710e-11 9.9899751e-01], sum to 1.0000
[2019-03-24 02:47:25,130] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6048
[2019-03-24 02:47:25,137] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.3, 87.0, 1.0, 2.0, 0.2665480949551766, 1.0, 2.0, 0.2665480949551766, 1.0, 2.0, 0.424353248034051, 6.9112, 6.9112, 121.94756008, 911435.7051739999, 911435.7051739999, 243569.7068239468], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6501600.0000, 
sim time next is 6502200.0000, 
raw observation next is [26.3, 87.16666666666667, 1.0, 2.0, 0.2904201717725799, 1.0, 2.0, 0.2904201717725799, 1.0, 2.0, 0.4623583717866218, 6.911199999999999, 6.9112, 121.94756008, 993116.8710934117, 993116.8710934122, 252414.0580502173], 
processed observation next is [1.0, 0.2608695652173913, 0.5296296296296297, 0.8716666666666667, 1.0, 1.0, 0.1552621092530713, 1.0, 1.0, 0.1552621092530713, 1.0, 1.0, 0.32794796473327725, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3546845968190756, 0.35468459681907577, 0.4854116500965718], 
reward next is 0.5146, 
noisyNet noise sample is [array([-0.12833698], dtype=float32), -1.6021327]. 
=============================================
[2019-03-24 02:47:30,947] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.4370166e-20 4.5876450e-19 6.2776403e-15 8.8952845e-09], sum to 1.0000
[2019-03-24 02:47:30,953] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1160
[2019-03-24 02:47:30,961] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.46666666666667, 51.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7189381091332652, 6.911200000000001, 6.9112, 121.9260426156618, 528971.8065439806, 528971.8065439801, 139513.8429375958], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6595800.0000, 
sim time next is 6596400.0000, 
raw observation next is [24.63333333333334, 50.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.970524341791008, 7.135660871915008, 6.9112, 121.9253231032527, 829252.1338949471, 714308.7836993913, 167021.294884961], 
processed observation next is [1.0, 0.34782608695652173, 0.4679012345679015, 0.5033333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9631554272387599, 0.02244608719150083, 0.0, 0.8094573520059797, 0.29616147639105256, 0.25511027989263974, 0.32119479785569427], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.8820984], dtype=float32), 0.42485324]. 
=============================================
[2019-03-24 02:47:36,640] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.1538965e-19 5.9706000e-20 1.1193062e-15 2.0946915e-08], sum to 1.0000
[2019-03-24 02:47:36,651] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0143
[2019-03-24 02:47:36,659] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1001886.121546726 W.
[2019-03-24 02:47:36,663] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.8, 28.66666666666667, 1.0, 2.0, 0.401281540029516, 1.0, 2.0, 0.401281540029516, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1001886.121546726, 1001886.121546727, 209675.8681109352], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6704400.0000, 
sim time next is 6705000.0000, 
raw observation next is [29.85, 28.5, 1.0, 2.0, 0.399918047393295, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6734919537607519, 6.911199999999999, 6.9112, 121.9260426156618, 1002156.222507453, 1002156.222507454, 219326.2327280179], 
processed observation next is [1.0, 0.6086956521739131, 0.6611111111111112, 0.285, 1.0, 1.0, 0.28561672308725594, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.5918649422009398, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.35791293660980467, 0.357912936609805, 0.4217812167846498], 
reward next is 0.5782, 
noisyNet noise sample is [array([0.76293653], dtype=float32), -0.30630723]. 
=============================================
[2019-03-24 02:47:36,680] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[57.349422]
 [56.959503]
 [56.647263]
 [56.351097]
 [56.3101  ]], R is [[57.39711761]
 [57.41992569]
 [57.42876434]
 [56.85447693]
 [56.28593445]].
[2019-03-24 02:47:39,783] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 3.2396172e-26 4.4755328e-25 3.0735946e-24 1.3431232e-16], sum to 1.0000
[2019-03-24 02:47:39,791] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0221
[2019-03-24 02:47:39,796] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5743443904667657, 6.911200000000001, 6.9112, 121.9260426156618, 413895.4883950916, 413895.4883950911, 122239.2000208982], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6757200.0000, 
sim time next is 6757800.0000, 
raw observation next is [18.25, 83.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5471295892867025, 6.9112, 6.9112, 121.9260426156618, 394496.7307818769, 394496.7307818769, 120079.8219470575], 
processed observation next is [1.0, 0.21739130434782608, 0.23148148148148148, 0.8350000000000002, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4339119866083781, 0.0, 0.0, 0.8094621288201359, 0.14089168956495604, 0.14089168956495604, 0.23092273451357212], 
reward next is 0.7691, 
noisyNet noise sample is [array([-0.92232084], dtype=float32), -1.2903255]. 
=============================================
[2019-03-24 02:47:45,863] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.8379525e-26 5.8915950e-27 1.1823565e-18 1.5329198e-10], sum to 1.0000
[2019-03-24 02:47:45,872] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7596
[2019-03-24 02:47:45,875] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.7, 49.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7955549533951067, 6.911200000000001, 6.9112, 121.9260426156618, 590381.8640986828, 590381.8640986823, 160026.3137557431], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6871200.0000, 
sim time next is 6871800.0000, 
raw observation next is [29.85, 49.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8022685018268279, 6.911200000000001, 6.9112, 121.9260426156618, 594869.120835499, 594869.1208354986, 161079.2544209599], 
processed observation next is [0.0, 0.5217391304347826, 0.6611111111111112, 0.4916666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7528356272835348, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21245325744124965, 0.2124532574412495, 0.3097677969633844], 
reward next is 0.6902, 
noisyNet noise sample is [array([-0.97534317], dtype=float32), -0.9789734]. 
=============================================
[2019-03-24 02:47:47,299] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 9.0175116e-24 7.5190806e-24 2.5192157e-20 2.4537679e-08], sum to 1.0000
[2019-03-24 02:47:47,309] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4733
[2019-03-24 02:47:47,312] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.3, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6844262273748077, 6.911199999999999, 6.9112, 121.9260426156618, 511264.0078017961, 511264.0078017966, 142107.8124055055], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6928800.0000, 
sim time next is 6929400.0000, 
raw observation next is [21.2, 86.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6825357195069925, 6.911199999999999, 6.9112, 121.9260426156618, 509836.258487676, 509836.2584876765, 141867.9759643795], 
processed observation next is [0.0, 0.17391304347826086, 0.34074074074074073, 0.8633333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6031696493837406, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18208437803131286, 0.18208437803131303, 0.27282303070072983], 
reward next is 0.7272, 
noisyNet noise sample is [array([1.1643996], dtype=float32), 0.974329]. 
=============================================
[2019-03-24 02:47:47,784] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999952e-01 8.9972831e-21 5.5758759e-20 4.3463629e-14 4.5881475e-07], sum to 1.0000
[2019-03-24 02:47:47,790] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4781
[2019-03-24 02:47:47,797] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6706856609108979, 6.9112, 6.9112, 121.9260426156618, 500766.2468977118, 500766.2468977118, 140164.6719584739], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6908400.0000, 
sim time next is 6909000.0000, 
raw observation next is [23.55, 68.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6699676843534692, 6.911200000000001, 6.9112, 121.9260426156618, 500220.2143803765, 500220.214380376, 140072.1374928007], 
processed observation next is [0.0, 1.0, 0.4277777777777778, 0.685, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5874596054418365, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17865007656442017, 0.17865007656442, 0.2693694951784629], 
reward next is 0.7306, 
noisyNet noise sample is [array([0.35370615], dtype=float32), -0.3460477]. 
=============================================
[2019-03-24 02:47:47,814] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[62.39637 ]
 [62.420715]
 [62.444267]
 [62.478188]
 [62.510925]], R is [[62.47019577]
 [62.57594681]
 [62.67950439]
 [62.78077316]
 [62.87965393]].
[2019-03-24 02:47:49,732] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 6.0992198e-26 3.0504768e-25 7.2765069e-20 4.8555208e-11], sum to 1.0000
[2019-03-24 02:47:49,738] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8089
[2019-03-24 02:47:49,742] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.1, 46.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8607808830417601, 6.911200000000001, 6.9112, 121.9260426156618, 634130.5586927861, 634130.5586927857, 169815.0466928135], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6971400.0000, 
sim time next is 6972000.0000, 
raw observation next is [31.13333333333333, 45.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8498496932324406, 6.911199999999999, 6.9112, 121.9260426156618, 627150.8974876625, 627150.897487663, 168107.5052430508], 
processed observation next is [0.0, 0.6956521739130435, 0.7086419753086418, 0.4566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8123121165405508, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2239824633884509, 0.22398246338845107, 0.32328366392894387], 
reward next is 0.6767, 
noisyNet noise sample is [array([-1.2858076], dtype=float32), -0.0795338]. 
=============================================
[2019-03-24 02:47:49,754] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[71.18024 ]
 [71.12801 ]
 [71.06847 ]
 [71.061844]
 [71.00249 ]], R is [[71.18743896]
 [71.14899445]
 [71.10722351]
 [71.05895996]
 [71.01265717]].
[2019-03-24 02:47:49,942] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 7.4129070e-24 1.8688503e-24 1.2791736e-18 1.4511649e-10], sum to 1.0000
[2019-03-24 02:47:49,951] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8289
[2019-03-24 02:47:49,957] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.36666666666667, 54.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.749525050343079, 6.9112, 6.9112, 121.9260426156618, 559447.7986281158, 559447.7986281158, 152163.5538113487], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6981600.0000, 
sim time next is 6982200.0000, 
raw observation next is [27.1, 55.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7456533404174716, 6.9112, 6.9112, 121.9260426156618, 556716.5510250116, 556716.5510250116, 151494.0382269839], 
processed observation next is [0.0, 0.8260869565217391, 0.5592592592592593, 0.555, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6820666755218393, 0.0, 0.0, 0.8094621288201359, 0.19882733965178984, 0.19882733965178984, 0.2913346888980459], 
reward next is 0.7087, 
noisyNet noise sample is [array([-1.6281064], dtype=float32), -0.1801222]. 
=============================================
[2019-03-24 02:47:54,287] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.4690765e-20 4.3754934e-18 1.7053333e-14 3.9145652e-11], sum to 1.0000
[2019-03-24 02:47:54,293] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2982
[2019-03-24 02:47:54,298] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.28333333333333, 83.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7901462050950784, 6.911199999999999, 6.9112, 121.9260426156618, 590405.27673453, 590405.2767345305, 155765.5025420518], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7027800.0000, 
sim time next is 7028400.0000, 
raw observation next is [22.46666666666667, 82.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9559505988530839, 7.79332170378769, 6.9112, 121.922879413214, 1166179.184305535, 714465.7482070562, 174506.3266038535], 
processed observation next is [1.0, 0.34782608695652173, 0.3876543209876544, 0.8266666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9449382485663549, 0.08821217037876901, 0.0, 0.8094411284453813, 0.4164925658234053, 0.2551663386453772, 0.33558908962279516], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.54737604], dtype=float32), 0.6329859]. 
=============================================
[2019-03-24 02:47:55,346] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 3.4295402e-29 1.5013397e-28 2.8973697e-25 2.7812937e-20], sum to 1.0000
[2019-03-24 02:47:55,360] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7894
[2019-03-24 02:47:55,362] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7782139901989595, 6.911200000000001, 6.9112, 121.9260426156618, 579720.0812891101, 579720.0812891097, 156633.9307013343], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7066800.0000, 
sim time next is 7067400.0000, 
raw observation next is [23.56666666666667, 80.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7787397175495447, 6.9112, 6.9112, 121.9260426156618, 580123.5632637322, 580123.5632637322, 156688.9069810422], 
processed observation next is [1.0, 0.8260869565217391, 0.4283950617283952, 0.8016666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.723424646936931, 0.0, 0.0, 0.8094621288201359, 0.20718698687990436, 0.20718698687990436, 0.30132482111738884], 
reward next is 0.6987, 
noisyNet noise sample is [array([-0.7160225], dtype=float32), 1.3927858]. 
=============================================
[2019-03-24 02:47:56,358] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.5947541e-32 1.7105616e-33 1.1608853e-27 2.8614035e-21], sum to 1.0000
[2019-03-24 02:47:56,367] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8457
[2019-03-24 02:47:56,371] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.38333333333333, 77.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7524360077601955, 6.9112, 6.9112, 121.9260426156618, 562101.359691781, 562101.359691781, 149616.4166140935], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7096200.0000, 
sim time next is 7096800.0000, 
raw observation next is [22.26666666666667, 78.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6828658008984975, 6.9112, 6.9112, 121.9260426156618, 510088.6091138676, 510088.6091138676, 141917.4669193671], 
processed observation next is [1.0, 0.13043478260869565, 0.38024691358024704, 0.7833333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6035822511231218, 0.0, 0.0, 0.8094621288201359, 0.1821745032549527, 0.1821745032549527, 0.2729182056141675], 
reward next is 0.7271, 
noisyNet noise sample is [array([0.31306073], dtype=float32), 0.8596352]. 
=============================================
[2019-03-24 02:47:56,786] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 02:47:56,789] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:47:56,789] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:47:56,790] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:47:56,790] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:47:56,791] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:47:56,792] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:47:56,792] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:47:56,792] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:47:56,793] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:47:56,796] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:47:56,811] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run34
[2019-03-24 02:47:56,834] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run34
[2019-03-24 02:47:56,836] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run34
[2019-03-24 02:47:56,857] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run34
[2019-03-24 02:47:56,902] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run34
[2019-03-24 02:48:09,645] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.24034333]
[2019-03-24 02:48:09,647] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.93333333333334, 62.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.649245973704891, 6.911200000000001, 6.9112, 121.9260426156618, 483727.6433094683, 483727.6433094678, 136628.0734603229]
[2019-03-24 02:48:09,647] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:48:09,651] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 8.9607762e-28 5.3180257e-27 3.8299285e-22 6.2482892e-19], sampled 0.8863776324388197
[2019-03-24 02:48:10,988] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.24034333]
[2019-03-24 02:48:10,989] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.5, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4259596255870595, 6.911200000000001, 6.9112, 121.9260426156618, 304128.8158059905, 304128.81580599, 88100.0254447933]
[2019-03-24 02:48:10,991] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:48:10,993] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.5457523e-26 8.5663404e-26 3.6507273e-21 4.1786621e-18], sampled 0.015453039634797494
[2019-03-24 02:48:22,310] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.24034333]
[2019-03-24 02:48:22,311] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.92548192, 66.67174610000001, 1.0, 2.0, 0.6063475124853462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156585, 713634.1432349349, 713634.1432349354, 160215.7735232262]
[2019-03-24 02:48:22,312] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:48:22,316] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 5.8892281e-22 1.9864795e-21 1.6177188e-17 6.0644306e-15], sampled 0.011389067421497034
[2019-03-24 02:48:22,317] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 713634.1432349349 W.
[2019-03-24 02:48:44,574] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.24034333]
[2019-03-24 02:48:44,575] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.73955442333333, 105.84006055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8287912739244806, 6.911199999999999, 6.9112, 121.9260426156618, 614835.3870715155, 614835.387071516, 164280.0921128619]
[2019-03-24 02:48:44,577] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:48:44,579] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.00000000e+00 2.01944232e-27 1.13767694e-26 7.25983617e-22
 1.10189246e-18], sampled 0.8137756814781274
[2019-03-24 02:48:50,601] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.24034333]
[2019-03-24 02:48:50,602] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.16666666666667, 44.33333333333334, 1.0, 2.0, 0.8300164639444552, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9924715504872262, 6.9112, 6.9112, 121.9260426156618, 1666605.802846606, 1666605.802846606, 341439.9970071541]
[2019-03-24 02:48:50,604] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:48:50,606] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.0837027e-22 2.8953523e-22 4.6573685e-18 2.8221270e-15], sampled 0.8938747202014121
[2019-03-24 02:48:50,607] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1666605.802846606 W.
[2019-03-24 02:49:01,793] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.24034333]
[2019-03-24 02:49:01,794] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8079032049112878, 6.911200000000001, 6.9112, 121.9260426156618, 599099.5893014569, 599099.5893014565, 161765.5673926293]
[2019-03-24 02:49:01,796] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:49:01,799] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.4952674e-27 1.4009529e-26 8.6852743e-22 1.2885524e-18], sampled 0.3393935538964191
[2019-03-24 02:49:05,712] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.24034333]
[2019-03-24 02:49:05,712] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.80482018666667, 94.76870431666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8496651728298944, 6.9112, 6.9112, 121.9260426156618, 620491.5052795276, 620491.5052795276, 169628.4275949084]
[2019-03-24 02:49:05,713] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:49:05,716] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.00000000e+00 1.79190660e-27 1.06349004e-26 6.61194686e-22
 9.74280622e-19], sampled 0.5647862316136206
[2019-03-24 02:49:16,280] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.24034333]
[2019-03-24 02:49:16,281] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.81440145, 60.08443842, 1.0, 2.0, 0.7417193062829055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 845376.4067864292, 845376.4067864292, 184200.0572041175]
[2019-03-24 02:49:16,282] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:49:16,284] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 6.5829442e-25 1.7940638e-24 8.5335881e-20 1.0823096e-16], sampled 0.17189559905337337
[2019-03-24 02:49:16,285] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 845376.4067864292 W.
[2019-03-24 02:49:23,293] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.24034333]
[2019-03-24 02:49:23,294] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.95195883333333, 75.77815646, 1.0, 2.0, 0.6244002307551892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 741699.4952596065, 741699.4952596065, 163683.5823890566]
[2019-03-24 02:49:23,295] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:49:23,297] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.8831412e-21 9.8614776e-21 7.6026924e-17 2.8042017e-14], sampled 0.4342392177024197
[2019-03-24 02:49:23,299] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 741699.4952596065 W.
[2019-03-24 02:49:35,387] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 02:49:35,612] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 02:49:35,685] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 02:49:35,874] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7840.8063 2529759975.6925 831.0000
[2019-03-24 02:49:35,893] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8558.6972 2258279932.1894 536.0000
[2019-03-24 02:49:36,909] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 825000, evaluation results [825000.0, 7840.806321330914, 2529759975.692537, 831.0, 8558.697174170602, 2258279932.1894197, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 02:49:39,725] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.2320347e-24 9.7965220e-24 9.8271590e-20 2.6895932e-14], sum to 1.0000
[2019-03-24 02:49:39,733] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7371
[2019-03-24 02:49:39,740] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 997062.691725878 W.
[2019-03-24 02:49:39,747] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 60.0, 1.0, 2.0, 0.4030363662734425, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6671903834458364, 6.9112, 6.9112, 121.9260426156618, 997062.691725878, 997062.691725878, 221504.0831432314], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7135200.0000, 
sim time next is 7135800.0000, 
raw observation next is [23.95, 60.33333333333333, 1.0, 2.0, 0.800124944225807, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 997710.9841917207, 997710.9841917207, 199365.6050696931], 
processed observation next is [1.0, 0.6086956521739131, 0.4425925925925926, 0.6033333333333333, 1.0, 1.0, 0.7620535050307227, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.35632535149704314, 0.35632535149704314, 0.3833953943647944], 
reward next is 0.6166, 
noisyNet noise sample is [array([0.32969287], dtype=float32), -2.3826668]. 
=============================================
[2019-03-24 02:49:47,856] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.5147895e-25 2.1128253e-26 1.2440477e-19 1.7256064e-14], sum to 1.0000
[2019-03-24 02:49:47,864] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1183
[2019-03-24 02:49:47,871] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 883705.094253199 W.
[2019-03-24 02:49:47,874] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.2, 77.0, 1.0, 2.0, 0.3660844800305616, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5931777926745496, 6.911199999999999, 6.9112, 121.9260426156618, 883705.094253199, 883705.0942531994, 212112.7884235549], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7297200.0000, 
sim time next is 7297800.0000, 
raw observation next is [23.4, 76.16666666666667, 1.0, 2.0, 0.3897843790165583, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6314005509668263, 6.9112, 6.9112, 121.9260426156618, 940537.447827064, 940537.447827064, 219191.3712088028], 
processed observation next is [1.0, 0.4782608695652174, 0.42222222222222217, 0.7616666666666667, 1.0, 1.0, 0.2735528321625694, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5392506887085329, 0.0, 0.0, 0.8094621288201359, 0.3359062313668086, 0.3359062313668086, 0.42152186770923616], 
reward next is 0.5785, 
noisyNet noise sample is [array([-1.4265845], dtype=float32), 0.15981442]. 
=============================================
[2019-03-24 02:49:53,333] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.1080552e-25 1.8473314e-24 2.7678623e-20 1.8629644e-16], sum to 1.0000
[2019-03-24 02:49:53,341] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7189
[2019-03-24 02:49:53,348] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 745594.1891514595 W.
[2019-03-24 02:49:53,352] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.06666666666667, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9613888742470398, 6.972369825065252, 6.9112, 121.9258465330581, 745594.1891514595, 714269.8217973476, 169970.8023658935], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7374000.0000, 
sim time next is 7374600.0000, 
raw observation next is [19.1, 95.0, 1.0, 1.0, 0.6612646118775815, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260057803166, 828088.5566921736, 828088.5566921731, 171677.6270268938], 
processed observation next is [1.0, 0.34782608695652173, 0.262962962962963, 0.95, 1.0, 0.5, 0.5967435855685493, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094618842717499, 0.2957459131043477, 0.29574591310434756, 0.33014928274402655], 
reward next is 0.6699, 
noisyNet noise sample is [array([0.36633518], dtype=float32), 0.18338244]. 
=============================================
[2019-03-24 02:49:53,583] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 8.0644841e-25 2.3087261e-24 2.2691092e-19 1.1035226e-14], sum to 1.0000
[2019-03-24 02:49:53,592] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5039
[2019-03-24 02:49:53,603] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 89.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.672942654357055, 6.911199999999999, 6.9112, 121.9260426156614, 502838.1723674622, 502838.1723674627, 141435.7722971349], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7407000.0000, 
sim time next is 7407600.0000, 
raw observation next is [20.93333333333333, 89.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6765111766466109, 6.911200000000001, 6.9112, 121.9260426156618, 505470.5603012649, 505470.5603012645, 141650.2830030979], 
processed observation next is [1.0, 0.7391304347826086, 0.3308641975308641, 0.8966666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5956389708082636, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18052520010759462, 0.18052520010759446, 0.27240439039057285], 
reward next is 0.7276, 
noisyNet noise sample is [array([1.7635666], dtype=float32), 0.3154321]. 
=============================================
[2019-03-24 02:49:56,817] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.4753068e-31 1.0003062e-28 2.4750974e-24 7.3994981e-21], sum to 1.0000
[2019-03-24 02:49:56,825] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5161
[2019-03-24 02:49:56,837] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.7, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7260255284448287, 6.9112, 6.9112, 121.9260426156618, 541789.3584816528, 541789.3584816528, 149583.678710553], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7468200.0000, 
sim time next is 7468800.0000, 
raw observation next is [22.86666666666667, 83.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7298918482795707, 6.9112, 6.9112, 121.9260426156618, 544509.3103551534, 544509.3103551534, 150211.1421937576], 
processed observation next is [0.0, 0.43478260869565216, 0.4024691358024693, 0.8333333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6623648103494634, 0.0, 0.0, 0.8094621288201359, 0.1944676108411262, 0.1944676108411262, 0.2888675811418416], 
reward next is 0.7111, 
noisyNet noise sample is [array([0.35576537], dtype=float32), -0.6740285]. 
=============================================
[2019-03-24 02:49:58,487] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 7.8738171e-27 1.2614757e-27 4.6629768e-22 4.6914241e-19], sum to 1.0000
[2019-03-24 02:49:58,495] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8237
[2019-03-24 02:49:58,502] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.8, 90.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6550220315914762, 6.9112, 6.9112, 121.9260426156618, 489341.5033948969, 489341.5033948969, 139147.8211283712], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7461000.0000, 
sim time next is 7461600.0000, 
raw observation next is [20.96666666666667, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6608245785735277, 6.9112, 6.9112, 121.9260426156618, 493753.5928773811, 493753.5928773811, 140022.2240066952], 
processed observation next is [0.0, 0.34782608695652173, 0.3320987654320988, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5760307232169096, 0.0, 0.0, 0.8094621288201359, 0.17634056888477895, 0.17634056888477895, 0.2692735077051831], 
reward next is 0.7307, 
noisyNet noise sample is [array([-2.329009], dtype=float32), 1.037746]. 
=============================================
[2019-03-24 02:50:02,794] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.7104663e-30 3.3306642e-28 1.0965930e-24 6.1713199e-21], sum to 1.0000
[2019-03-24 02:50:02,802] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5186
[2019-03-24 02:50:02,809] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 62.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8728953502104213, 6.9112, 6.9112, 121.9260426156618, 640646.0460006793, 640646.0460006793, 171982.6880457157], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7573800.0000, 
sim time next is 7574400.0000, 
raw observation next is [28.0, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8633231388839593, 6.9112, 6.9112, 121.9260426156618, 634595.4140411126, 634595.4140411126, 170509.9153665907], 
processed observation next is [0.0, 0.6956521739130435, 0.5925925925925926, 0.62, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8291539236049491, 0.0, 0.0, 0.8094621288201359, 0.22664121930039738, 0.22664121930039738, 0.3279036833972898], 
reward next is 0.6721, 
noisyNet noise sample is [array([-0.576416], dtype=float32), 1.21139]. 
=============================================
[2019-03-24 02:50:03,805] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.8681171e-26 6.5668169e-25 2.4395383e-20 2.5693085e-17], sum to 1.0000
[2019-03-24 02:50:03,811] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5545
[2019-03-24 02:50:03,816] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.96666666666667, 83.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8255334999290207, 6.911200000000001, 6.9112, 121.9260426156618, 610695.8372560407, 610695.8372560402, 164560.7792852857], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7591800.0000, 
sim time next is 7592400.0000, 
raw observation next is [23.9, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8246889851897918, 6.911200000000001, 6.9112, 121.9260426156618, 610196.2859273349, 610196.2859273345, 164411.2102596388], 
processed observation next is [0.0, 0.9130434782608695, 0.4407407407407407, 0.84, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7808612314872398, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2179272449740482, 0.21792724497404803, 0.31617540434545927], 
reward next is 0.6838, 
noisyNet noise sample is [array([1.0370336], dtype=float32), -0.16630758]. 
=============================================
[2019-03-24 02:50:11,495] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 9.8814805e-27 1.5941698e-25 2.6068301e-20 3.3798573e-17], sum to 1.0000
[2019-03-24 02:50:11,500] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6077
[2019-03-24 02:50:11,502] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.1, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4791286478954532, 6.911200000000001, 6.9112, 121.9260426156618, 342147.3830642386, 342147.3830642382, 113572.953399381], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7701000.0000, 
sim time next is 7701600.0000, 
raw observation next is [19.0, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4684835062603037, 6.911200000000001, 6.9112, 121.9260426156618, 335304.0101204352, 335304.0101204347, 113045.8317867431], 
processed observation next is [1.0, 0.13043478260869565, 0.25925925925925924, 0.75, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.33560438282537963, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11975143218586971, 0.11975143218586953, 0.21739583035912136], 
reward next is 0.7826, 
noisyNet noise sample is [array([1.7976321], dtype=float32), -0.7905093]. 
=============================================
[2019-03-24 02:50:18,395] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.2873539e-25 4.8443605e-24 1.7630833e-19 8.2058699e-17], sum to 1.0000
[2019-03-24 02:50:18,404] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5592
[2019-03-24 02:50:18,411] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.38333333333333, 72.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6887334440268866, 6.9112, 6.9112, 121.9260426156618, 514639.5537558011, 514639.5537558011, 143117.5972811321], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7861800.0000, 
sim time next is 7862400.0000, 
raw observation next is [23.3, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6920796458175041, 6.911200000000001, 6.9112, 121.9260426156618, 517148.2805920946, 517148.2805920942, 143522.1392698637], 
processed observation next is [1.0, 0.0, 0.41851851851851857, 0.73, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6150995572718801, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18469581449717665, 0.18469581449717648, 0.2760041139805071], 
reward next is 0.7240, 
noisyNet noise sample is [array([0.735021], dtype=float32), 0.07243902]. 
=============================================
[2019-03-24 02:50:21,059] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.1285766e-18 1.3053445e-17 1.4065894e-14 9.7392320e-13], sum to 1.0000
[2019-03-24 02:50:21,065] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4845
[2019-03-24 02:50:21,074] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1231888.685390561 W.
[2019-03-24 02:50:21,080] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.53333333333333, 51.0, 1.0, 2.0, 0.5224248038297671, 1.0, 2.0, 0.5224248038297671, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1231888.685390561, 1231888.685390561, 244248.6274771154], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7906800.0000, 
sim time next is 7907400.0000, 
raw observation next is [28.7, 50.5, 1.0, 2.0, 0.5036630907687757, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8090525104902717, 6.9112, 6.9112, 121.9260426156618, 1196415.35456695, 1196415.35456695, 257069.5205528012], 
processed observation next is [1.0, 0.5217391304347826, 0.6185185185185185, 0.505, 1.0, 1.0, 0.4091227271056853, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.7613156381128396, 0.0, 0.0, 0.8094621288201359, 0.42729119805962495, 0.42729119805962495, 0.49436446260154077], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.28075895], dtype=float32), -0.08546178]. 
=============================================
[2019-03-24 02:50:22,952] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:50:22,952] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:22,979] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run5
[2019-03-24 02:50:23,698] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:50:23,699] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:23,701] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run5
[2019-03-24 02:50:23,782] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:50:23,783] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:23,784] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run5
[2019-03-24 02:50:23,934] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:50:23,934] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:23,936] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run5
[2019-03-24 02:50:24,105] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:50:24,105] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:24,106] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run5
[2019-03-24 02:50:24,169] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:50:24,170] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:24,171] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run5
[2019-03-24 02:50:24,209] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:50:24,210] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:24,212] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run5
[2019-03-24 02:50:24,238] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:50:24,239] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:24,246] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run5
[2019-03-24 02:50:24,313] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:50:24,313] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:24,314] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run5
[2019-03-24 02:50:24,422] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:50:24,423] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:24,424] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run5
[2019-03-24 02:50:24,533] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:50:24,533] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:24,535] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run5
[2019-03-24 02:50:24,601] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:50:24,601] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:24,602] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run5
[2019-03-24 02:50:24,673] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:50:24,673] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:24,675] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run5
[2019-03-24 02:50:24,703] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:50:24,703] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:24,705] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run5
[2019-03-24 02:50:24,729] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:50:24,729] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:24,731] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run5
[2019-03-24 02:50:24,776] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 02:50:24,776] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:24,777] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run5
[2019-03-24 02:50:29,833] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 02:50:29,834] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:50:29,835] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:29,835] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:50:29,838] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:50:29,839] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:50:29,839] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:29,840] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:50:29,841] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:29,843] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:29,842] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:50:29,861] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run35
[2019-03-24 02:50:29,861] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run35
[2019-03-24 02:50:29,905] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run35
[2019-03-24 02:50:29,906] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run35
[2019-03-24 02:50:29,906] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run35
[2019-03-24 02:50:49,798] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.24866763]
[2019-03-24 02:50:49,800] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.42293916333333, 36.59126179, 1.0, 2.0, 0.5728493390372149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 711825.1692470436, 711825.1692470436, 155670.9437932973]
[2019-03-24 02:50:49,803] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:50:49,805] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.1257748e-18 6.2429048e-19 1.7002513e-13 5.3896397e-08], sampled 0.16294234789579487
[2019-03-24 02:50:49,808] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 711825.1692470436 W.
[2019-03-24 02:50:54,562] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.24866763]
[2019-03-24 02:50:54,564] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.63764496666667, 68.55986098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7515229096903675, 6.911200000000001, 6.9112, 121.9260426156618, 558538.5001838856, 558538.5001838851, 146174.0705597842]
[2019-03-24 02:50:54,564] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:50:54,566] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 6.3274638e-20 1.3418307e-19 1.6394143e-15 1.4288928e-10], sampled 0.2755551606480884
[2019-03-24 02:51:01,437] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.24866763]
[2019-03-24 02:51:01,438] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.91666666666667, 70.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7602200200523858, 6.9112, 6.9112, 121.9260426156618, 566694.7454810615, 566694.7454810615, 154171.4703328217]
[2019-03-24 02:51:01,440] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:51:01,444] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.1450767e-22 3.9951554e-22 6.8133159e-18 1.8536745e-12], sampled 0.30325625244956156
[2019-03-24 02:51:03,238] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.24866763]
[2019-03-24 02:51:03,239] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.65239756, 85.23579893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8558780892981149, 6.9112, 6.9112, 121.9260426156618, 628378.8056333166, 628378.8056333166, 169732.2359860293]
[2019-03-24 02:51:03,240] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:51:03,242] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.4193804e-21 3.4958890e-21 7.7713255e-17 1.6544389e-11], sampled 0.8837897884421162
[2019-03-24 02:51:13,902] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.24866763]
[2019-03-24 02:51:13,903] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.36666666666667, 66.66666666666667, 1.0, 2.0, 0.7410102801186829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 844567.8472202101, 844567.8472202101, 184060.1265356071]
[2019-03-24 02:51:13,904] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:51:13,906] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 9.7783766e-24 8.4277836e-24 1.1570581e-17 5.0052011e-11], sampled 0.3492790183341128
[2019-03-24 02:51:13,908] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 844567.8472202101 W.
[2019-03-24 02:51:33,392] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.24866763]
[2019-03-24 02:51:33,392] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.0, 70.83333333333333, 1.0, 2.0, 0.828484626226719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 944328.3200474208, 944328.3200474208, 201904.1090829918]
[2019-03-24 02:51:33,394] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:51:33,397] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 5.8129835e-22 3.9132219e-22 3.8498177e-16 7.5519763e-10], sampled 0.6325800969975347
[2019-03-24 02:51:33,398] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 944328.3200474208 W.
[2019-03-24 02:52:08,670] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 02:52:08,879] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 02:52:08,913] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 02:52:08,953] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 02:52:09,059] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7840.1135 2529851152.3099 831.0000
[2019-03-24 02:52:10,076] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 850000, evaluation results [850000.0, 7840.11350377941, 2529851152.3098564, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 02:52:12,980] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.2558644e-23 1.8219765e-23 1.8072034e-17 4.4946395e-12], sum to 1.0000
[2019-03-24 02:52:12,987] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2285
[2019-03-24 02:52:12,996] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1591746.170572422 W.
[2019-03-24 02:52:13,001] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.38333333333333, 11.5, 1.0, 2.0, 0.6438166645950528, 1.0, 1.0, 0.6438166645950528, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1591746.170572422, 1591746.170572422, 288316.8294347376], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 141000.0000, 
sim time next is 141600.0000, 
raw observation next is [37.36666666666667, 11.0, 1.0, 2.0, 0.673668977651125, 1.0, 2.0, 0.673668977651125, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1668079.786732326, 1668079.786732327, 299530.5519565557], 
processed observation next is [1.0, 0.6521739130434783, 0.9395061728395062, 0.11, 1.0, 1.0, 0.6115106876799107, 1.0, 1.0, 0.6115106876799107, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5957427809758308, 0.5957427809758311, 0.5760202922241455], 
reward next is 0.4240, 
noisyNet noise sample is [array([-2.0071647], dtype=float32), 1.0355183]. 
=============================================
[2019-03-24 02:52:14,835] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.00000000e+00 2.90351054e-25 6.46969835e-24 1.06280844e-19
 3.45112536e-16], sum to 1.0000
[2019-03-24 02:52:14,840] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5759
[2019-03-24 02:52:14,848] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.55, 13.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6492959446699936, 6.911200000000001, 6.9112, 121.9260426156618, 463635.816029716, 463635.8160297155, 117516.7726089404], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 163800.0000, 
sim time next is 164400.0000, 
raw observation next is [31.46666666666667, 12.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6466019878568421, 6.9112, 6.9112, 121.9260426156618, 461711.5919513475, 461711.5919513475, 116422.8857902282], 
processed observation next is [1.0, 0.9130434782608695, 0.7209876543209878, 0.1266666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5582524848210526, 0.0, 0.0, 0.8094621288201359, 0.16489699712548125, 0.16489699712548125, 0.2238901649812081], 
reward next is 0.7761, 
noisyNet noise sample is [array([-0.66732824], dtype=float32), 2.3396118]. 
=============================================
[2019-03-24 02:52:18,205] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 4.8122926e-32 1.6794116e-31 8.6048797e-28 4.9235983e-23], sum to 1.0000
[2019-03-24 02:52:18,213] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8407
[2019-03-24 02:52:18,216] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.4, 14.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6838815577787478, 6.9112, 6.9112, 121.9260426156618, 489741.8559548255, 489741.8559548255, 130769.3280383742], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 226800.0000, 
sim time next is 227400.0000, 
raw observation next is [33.43333333333333, 14.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7163778858904388, 6.911200000000001, 6.9112, 121.9260426156618, 513743.9417870803, 513743.9417870798, 133982.8703655083], 
processed observation next is [0.0, 0.6521739130434783, 0.7938271604938271, 0.1416666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6454723573630485, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18347997920967155, 0.18347997920967135, 0.257659366087516], 
reward next is 0.7423, 
noisyNet noise sample is [array([-0.9659559], dtype=float32), -0.6921134]. 
=============================================
[2019-03-24 02:52:25,847] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.8100658e-18 4.4012691e-20 1.1808833e-13 5.0337599e-11], sum to 1.0000
[2019-03-24 02:52:25,853] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9480
[2019-03-24 02:52:25,859] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 832210.5245812905 W.
[2019-03-24 02:52:25,863] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.01666666666667, 35.5, 1.0, 2.0, 0.3267663705036152, 1.0, 1.0, 0.3267663705036152, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156461, 832210.5245812905, 832210.5245812905, 189825.08756243], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 377400.0000, 
sim time next is 378000.0000, 
raw observation next is [26.2, 35.0, 1.0, 2.0, 0.2385575879756271, 1.0, 2.0, 0.2385575879756271, 1.0, 1.0, 0.4088263747121922, 6.911199999999999, 6.9112, 121.94756008, 905597.9024457944, 905597.9024457949, 229708.3293907987], 
processed observation next is [1.0, 0.391304347826087, 0.5259259259259259, 0.35, 1.0, 1.0, 0.09352093806622273, 1.0, 1.0, 0.09352093806622273, 1.0, 0.5, 0.2610329683902402, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.32342782230206946, 0.3234278223020696, 0.4417467872899975], 
reward next is 0.5583, 
noisyNet noise sample is [array([0.04172188], dtype=float32), -0.7291743]. 
=============================================
[2019-03-24 02:52:25,888] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[50.924416]
 [51.211216]
 [52.515114]
 [57.493355]
 [58.29521 ]], R is [[51.27072525]
 [51.39297104]
 [51.55113602]
 [51.64152908]
 [51.12511444]].
[2019-03-24 02:52:30,910] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.3847351e-21 1.5170635e-19 2.0360544e-15 8.6545067e-13], sum to 1.0000
[2019-03-24 02:52:30,917] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3808
[2019-03-24 02:52:30,922] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 54.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7436163748229834, 6.9112, 6.9112, 121.9260426156618, 540590.25075108, 540590.25075108, 139177.3751181042], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 460200.0000, 
sim time next is 460800.0000, 
raw observation next is [23.3, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6532611805749444, 6.9112, 6.9112, 121.9260426156618, 475514.505404903, 475514.505404903, 130817.4438425588], 
processed observation next is [1.0, 0.34782608695652173, 0.41851851851851857, 0.53, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5665764757186805, 0.0, 0.0, 0.8094621288201359, 0.16982660907317965, 0.16982660907317965, 0.25157200738953617], 
reward next is 0.7484, 
noisyNet noise sample is [array([0.20556065], dtype=float32), 0.10321067]. 
=============================================
[2019-03-24 02:52:37,069] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.4569639e-14 5.6026754e-14 6.3161069e-12 2.6276075e-08], sum to 1.0000
[2019-03-24 02:52:37,076] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6671
[2019-03-24 02:52:37,082] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1325478.571907367 W.
[2019-03-24 02:52:37,088] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.7, 34.66666666666667, 1.0, 2.0, 0.5464084932980187, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8881721962305497, 6.911199999999999, 6.9112, 121.9260426156618, 1325478.571907367, 1325478.571907367, 271137.2284143025], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 569400.0000, 
sim time next is 570000.0000, 
raw observation next is [30.8, 34.33333333333334, 1.0, 2.0, 0.5813287530655871, 1.0, 1.0, 0.5813287530655871, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1406779.39273244, 1406779.39273244, 265109.8749824413], 
processed observation next is [1.0, 0.6086956521739131, 0.6962962962962963, 0.34333333333333343, 1.0, 1.0, 0.5015818488876036, 1.0, 0.5, 0.5015818488876036, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5024212116901572, 0.5024212116901572, 0.509826682658541], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.49651396], dtype=float32), 0.17262517]. 
=============================================
[2019-03-24 02:52:37,114] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[38.61609 ]
 [38.561787]
 [38.566574]
 [38.406765]
 [37.871063]], R is [[38.14042282]
 [38.23759842]
 [38.28099823]
 [38.36063004]
 [38.43927002]].
[2019-03-24 02:52:43,432] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.7256223e-23 5.7825011e-24 1.0340981e-18 9.6888202e-16], sum to 1.0000
[2019-03-24 02:52:43,439] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9734
[2019-03-24 02:52:43,442] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.13333333333334, 25.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6285921362472587, 6.9112, 6.9112, 121.9260426156618, 462060.6947410977, 462060.6947410977, 130540.9837533989], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 678000.0000, 
sim time next is 678600.0000, 
raw observation next is [30.95, 25.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6244578954758829, 6.9112, 6.9112, 121.9260426156618, 458991.5483983823, 458991.5483983823, 130143.1708828906], 
processed observation next is [1.0, 0.8695652173913043, 0.7018518518518518, 0.255, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5305723693448536, 0.0, 0.0, 0.8094621288201359, 0.16392555299942227, 0.16392555299942227, 0.2502753286209435], 
reward next is 0.7497, 
noisyNet noise sample is [array([-0.29615277], dtype=float32), 0.7607326]. 
=============================================
[2019-03-24 02:52:53,608] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.000000e+00 8.917652e-25 3.990173e-23 6.610919e-20 5.671632e-16], sum to 1.0000
[2019-03-24 02:52:53,620] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5785
[2019-03-24 02:52:53,625] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.43333333333334, 60.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6587615272290042, 6.911199999999999, 6.9112, 121.9260426156618, 491177.7974385223, 491177.7974385227, 137974.6692688449], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 864600.0000, 
sim time next is 865200.0000, 
raw observation next is [24.26666666666667, 61.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6557241368549793, 6.911200000000001, 6.9112, 121.9260426156618, 488801.8696444911, 488801.8696444906, 137541.022061527], 
processed observation next is [0.0, 0.0, 0.4543209876543211, 0.6133333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5696551710687241, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17457209630160397, 0.17457209630160378, 0.26450196550293653], 
reward next is 0.7355, 
noisyNet noise sample is [array([-0.5426968], dtype=float32), 0.45765308]. 
=============================================
[2019-03-24 02:52:55,704] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.5270151e-25 1.0992699e-23 4.2140329e-21 1.3815518e-16], sum to 1.0000
[2019-03-24 02:52:55,720] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5658
[2019-03-24 02:52:55,725] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.63333333333334, 50.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7091166391763422, 6.911199999999999, 6.9112, 121.9260426156618, 529888.6139624728, 529888.6139624732, 146197.3740204464], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 912000.0000, 
sim time next is 912600.0000, 
raw observation next is [27.85, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7113942471390261, 6.9112, 6.9112, 121.9260426156618, 531559.5881168756, 531559.5881168756, 146613.0312858199], 
processed observation next is [0.0, 0.5652173913043478, 0.5870370370370371, 0.5, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6392428089237825, 0.0, 0.0, 0.8094621288201359, 0.1898427100417413, 0.1898427100417413, 0.28194813708811517], 
reward next is 0.7181, 
noisyNet noise sample is [array([-0.95304775], dtype=float32), -0.76239103]. 
=============================================
[2019-03-24 02:53:01,005] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 02:53:01,007] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:53:01,008] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:53:01,008] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:53:01,010] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:53:01,011] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:53:01,012] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:53:01,013] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:53:01,014] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:53:01,015] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:53:01,016] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:53:01,034] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run36
[2019-03-24 02:53:01,060] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run36
[2019-03-24 02:53:01,084] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run36
[2019-03-24 02:53:01,108] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run36
[2019-03-24 02:53:01,109] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run36
[2019-03-24 02:53:27,081] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.2545516]
[2019-03-24 02:53:27,082] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.75197532833334, 71.16511370833334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5503863306975892, 6.9112, 6.9112, 121.9260426156618, 397412.153549308, 397412.153549308, 120549.6087404054]
[2019-03-24 02:53:27,083] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:53:27,086] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 4.5535970e-25 5.2844041e-24 4.8432249e-20 6.6341494e-16], sampled 0.605098055664485
[2019-03-24 02:53:29,416] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.2545516]
[2019-03-24 02:53:29,416] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.33333333333334, 81.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6195857436133352, 6.9112, 6.9112, 121.9260426156618, 461930.3922645499, 461930.3922645499, 134005.3327012753]
[2019-03-24 02:53:29,418] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:53:29,421] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.8682601e-25 4.4550778e-24 4.2109174e-20 5.9818743e-16], sampled 0.9351923330775666
[2019-03-24 02:53:46,299] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.2545516]
[2019-03-24 02:53:46,299] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 84.0, 1.0, 2.0, 0.6732636780072142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 767314.8816924101, 767314.8816924101, 171145.5379362593]
[2019-03-24 02:53:46,300] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:53:46,303] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 4.7240608e-24 4.4577488e-23 3.0870448e-19 3.0697770e-15], sampled 0.32791505627326334
[2019-03-24 02:53:46,304] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 767314.8816924101 W.
[2019-03-24 02:53:53,691] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.2545516]
[2019-03-24 02:53:53,692] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.08333333333334, 78.16666666666667, 1.0, 2.0, 0.7562022276113578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 861892.6335938053, 861892.6335938053, 187062.3931892429]
[2019-03-24 02:53:53,694] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:53:53,696] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.2406505e-23 1.9383755e-22 1.0653378e-18 8.1850572e-15], sampled 0.004421776663099841
[2019-03-24 02:53:53,697] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 861892.6335938053 W.
[2019-03-24 02:54:00,756] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.2545516]
[2019-03-24 02:54:00,758] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.0, 94.0, 1.0, 2.0, 0.7820151006977833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 891330.3442817377, 891330.3442817377, 192258.9681069805]
[2019-03-24 02:54:00,761] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:54:00,766] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 7.0056705e-23 6.1793259e-22 2.6372896e-18 1.6009128e-14], sampled 0.7795796359833024
[2019-03-24 02:54:00,767] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 891330.3442817377 W.
[2019-03-24 02:54:26,086] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.2545516]
[2019-03-24 02:54:26,088] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.36364845666667, 49.06126545000001, 1.0, 2.0, 0.623006238783171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 710010.2297855435, 710010.229785543, 162078.9993826321]
[2019-03-24 02:54:26,092] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:54:26,094] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 4.2802800e-21 3.0994451e-20 6.9117491e-17 2.0453513e-13], sampled 0.27697588398461237
[2019-03-24 02:54:26,095] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 710010.2297855435 W.
[2019-03-24 02:54:31,291] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.2545516]
[2019-03-24 02:54:31,293] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.06413194666667, 83.08993433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6746848077534311, 6.911199999999999, 6.9112, 121.9260426156618, 503898.4480012141, 503898.4480012145, 140868.8369890852]
[2019-03-24 02:54:31,294] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:54:31,296] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.2618930e-25 4.9226005e-24 4.5725297e-20 6.3716809e-16], sampled 0.23624260827434185
[2019-03-24 02:54:39,449] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 02:54:39,454] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 02:54:39,532] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 02:54:39,568] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 02:54:39,864] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 02:54:40,880] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 875000, evaluation results [875000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 02:54:41,584] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.2326796e-26 8.5253628e-26 1.8349739e-20 5.5394009e-17], sum to 1.0000
[2019-03-24 02:54:41,591] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1669
[2019-03-24 02:54:41,597] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.05, 47.0, 1.0, 2.0, 0.2261729003320053, 1.0, 1.0, 0.2261729003320053, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 562044.0682946106, 562044.0682946111, 165591.7797547949], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1098600.0000, 
sim time next is 1099200.0000, 
raw observation next is [25.8, 48.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5717730628996766, 6.911200000000001, 6.9112, 121.9260426156618, 424799.4226510399, 424799.4226510394, 128051.093457435], 
processed observation next is [1.0, 0.7391304347826086, 0.5111111111111112, 0.48, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.46471632862459566, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15171407951822855, 0.15171407951822835, 0.2462521028027596], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4657948], dtype=float32), 2.184692]. 
=============================================
[2019-03-24 02:54:48,541] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.0528143e-17 9.9656785e-18 4.6745209e-13 2.0838435e-09], sum to 1.0000
[2019-03-24 02:54:48,548] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7909
[2019-03-24 02:54:48,558] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 777724.903363761 W.
[2019-03-24 02:54:48,562] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.95, 65.5, 1.0, 2.0, 0.3072918028332785, 1.0, 2.0, 0.3072918028332785, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 777724.903363761, 777724.9033637614, 184852.9369045801], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1161000.0000, 
sim time next is 1161600.0000, 
raw observation next is [21.0, 65.33333333333333, 1.0, 2.0, 0.3051543112338352, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5252265296620979, 6.911199999999997, 6.9112, 121.9260426156618, 773839.9529549028, 773839.9529549042, 191040.8254808753], 
processed observation next is [1.0, 0.43478260869565216, 0.3333333333333333, 0.6533333333333333, 1.0, 1.0, 0.1728027514688514, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.40653316207762236, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.2763714117696081, 0.2763714117696086, 0.36738620284783713], 
reward next is 0.6326, 
noisyNet noise sample is [array([-1.0198498], dtype=float32), -0.54775447]. 
=============================================
[2019-03-24 02:54:49,396] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.00000000e+00 1.10047406e-23 4.78695391e-24 4.80242369e-18
 3.96963448e-14], sum to 1.0000
[2019-03-24 02:54:49,404] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6538
[2019-03-24 02:54:49,412] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 818109.8419342745 W.
[2019-03-24 02:54:49,419] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.56666666666667, 70.5, 1.0, 2.0, 0.6504774003864318, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818109.8419342745, 818109.8419342745, 169721.2542301792], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1180200.0000, 
sim time next is 1180800.0000, 
raw observation next is [21.5, 71.0, 1.0, 2.0, 0.3214848331283101, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5409031082540205, 6.911199999999999, 6.9112, 121.9260426156618, 805021.408342445, 805021.4083424455, 196802.4660104453], 
processed observation next is [1.0, 0.6956521739130435, 0.35185185185185186, 0.71, 1.0, 1.0, 0.19224384896227395, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.42612888531752563, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2875076458365875, 0.28750764583658767, 0.3784662807893179], 
reward next is 0.6215, 
noisyNet noise sample is [array([-0.34643942], dtype=float32), 0.8006119]. 
=============================================
[2019-03-24 02:54:53,689] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.5260376e-18 3.5285180e-18 2.8395794e-14 8.1485191e-10], sum to 1.0000
[2019-03-24 02:54:53,698] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5047
[2019-03-24 02:54:53,705] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 716111.2929045995 W.
[2019-03-24 02:54:53,709] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 81.0, 1.0, 2.0, 0.2872982767710436, 1.0, 2.0, 0.2872982767710436, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716111.2929045995, 716111.2929045995, 179754.9724424943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1242000.0000, 
sim time next is 1242600.0000, 
raw observation next is [20.5, 79.83333333333333, 1.0, 2.0, 0.7112359476564597, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 892798.8648029657, 892798.8648029652, 181314.794386307], 
processed observation next is [1.0, 0.391304347826087, 0.3148148148148148, 0.7983333333333333, 1.0, 1.0, 0.6562332710195948, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3188567374296306, 0.31885673742963044, 0.34868229689674424], 
reward next is 0.6513, 
noisyNet noise sample is [array([1.4787467], dtype=float32), -2.2198172]. 
=============================================
[2019-03-24 02:54:54,425] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.6464740e-23 3.3823198e-25 1.2854993e-17 3.3539071e-13], sum to 1.0000
[2019-03-24 02:54:54,433] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4941
[2019-03-24 02:54:54,437] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.13333333333333, 61.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6752271366188489, 6.911200000000001, 6.9112, 121.9260426156618, 504494.9710044519, 504494.9710044515, 141451.3154073545], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1277400.0000, 
sim time next is 1278000.0000, 
raw observation next is [25.0, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6798881021565465, 6.9112, 6.9112, 121.9260426156618, 507987.2172869714, 507987.2172869714, 141980.998238477], 
processed observation next is [1.0, 0.8260869565217391, 0.48148148148148145, 0.62, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5998601276956831, 0.0, 0.0, 0.8094621288201359, 0.18142400617391835, 0.18142400617391835, 0.2730403812278404], 
reward next is 0.7270, 
noisyNet noise sample is [array([1.6669554], dtype=float32), 0.12146804]. 
=============================================
[2019-03-24 02:54:54,456] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[71.27712 ]
 [71.10922 ]
 [71.19112 ]
 [71.00996 ]
 [71.140625]], R is [[71.44561768]
 [71.45914459]
 [71.47323608]
 [71.48687744]
 [71.50028992]].
[2019-03-24 02:54:55,124] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.1079234e-19 5.8411367e-18 1.4304687e-14 3.1963540e-10], sum to 1.0000
[2019-03-24 02:54:55,131] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6668
[2019-03-24 02:54:55,136] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1168458.831126627 W.
[2019-03-24 02:54:55,140] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 58.0, 1.0, 2.0, 0.4839255519171893, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7841523233205104, 6.911199999999999, 6.9112, 121.9260426156618, 1168458.831126627, 1168458.831126627, 249406.7493669786], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1260000.0000, 
sim time next is 1260600.0000, 
raw observation next is [26.03333333333333, 57.66666666666667, 1.0, 2.0, 0.5198552787212235, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8433272640875583, 6.911199999999999, 6.9112, 121.9260426156618, 1257428.271667158, 1257428.271667159, 261778.0990736418], 
processed observation next is [1.0, 0.6086956521739131, 0.519753086419753, 0.5766666666666667, 1.0, 1.0, 0.42839914133478985, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8041590801094478, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4490815255954136, 0.4490815255954139, 0.503419421295465], 
reward next is 0.4966, 
noisyNet noise sample is [array([-1.1935894], dtype=float32), 1.6802396]. 
=============================================
[2019-03-24 02:54:57,833] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.9894753e-20 1.4760137e-19 8.6637256e-16 1.4222637e-10], sum to 1.0000
[2019-03-24 02:54:57,843] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1248
[2019-03-24 02:54:57,849] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 861098.6433166163 W.
[2019-03-24 02:54:57,855] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 63.0, 1.0, 2.0, 0.3501289272974909, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5760194166893178, 6.911199999999999, 6.9112, 121.9260426156618, 861098.6433166163, 861098.6433166167, 206320.8830947581], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1328400.0000, 
sim time next is 1329000.0000, 
raw observation next is [24.35, 61.33333333333333, 1.0, 2.0, 0.8867646161052966, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.922956422363411, 6.9112, 121.9260008528098, 1104942.986418446, 1098922.649453396, 218255.9495505996], 
processed observation next is [1.0, 0.391304347826087, 0.4574074074074075, 0.6133333333333333, 1.0, 1.0, 0.8651959715539245, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0011756422363411012, 0.0, 0.809461851558229, 0.39462249514944503, 0.39247237480478425, 0.4197229799049992], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.07236847], dtype=float32), -0.52910215]. 
=============================================
[2019-03-24 02:54:57,870] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[55.893024]
 [55.88627 ]
 [56.371437]
 [57.746758]
 [61.913506]], R is [[55.5404129 ]
 [54.98500824]
 [55.07667542]
 [55.20488358]
 [55.25003052]].
[2019-03-24 02:54:57,994] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.2022417e-20 1.3271543e-19 3.7973533e-16 4.5436064e-12], sum to 1.0000
[2019-03-24 02:54:58,000] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9072
[2019-03-24 02:54:58,006] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.43333333333333, 91.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5806562758677867, 6.9112, 6.9112, 121.9260426156618, 426536.9013107782, 426536.9013107782, 126045.3566385871], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1312800.0000, 
sim time next is 1313400.0000, 
raw observation next is [18.36666666666667, 91.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5724805849913193, 6.9112, 6.9112, 121.9260426156618, 420364.8545599969, 420364.8545599969, 125243.5044501836], 
processed observation next is [1.0, 0.17391304347826086, 0.2358024691358026, 0.9166666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.465600731239149, 0.0, 0.0, 0.8094621288201359, 0.1501303051999989, 0.1501303051999989, 0.24085289317342998], 
reward next is 0.7591, 
noisyNet noise sample is [array([0.5281909], dtype=float32), -0.12213979]. 
=============================================
[2019-03-24 02:54:58,121] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.8190884e-18 8.9652275e-19 1.3085529e-13 2.2783451e-09], sum to 1.0000
[2019-03-24 02:54:58,128] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9519
[2019-03-24 02:54:58,139] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1174704.133611665 W.
[2019-03-24 02:54:58,144] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 42.0, 1.0, 2.0, 0.474488946597983, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7860451192976321, 6.911199999999999, 6.9112, 121.925971260434, 1174704.133611665, 1174704.133611666, 244334.8987072871], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1336800.0000, 
sim time next is 1337400.0000, 
raw observation next is [27.8, 41.5, 1.0, 2.0, 0.9186787001237413, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.171044547229557, 6.9112, 121.9249337555404, 1278018.023265517, 1144955.600593168, 225762.6694180968], 
processed observation next is [1.0, 0.4782608695652174, 0.5851851851851853, 0.415, 1.0, 1.0, 0.9031889287187397, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.025984454722955696, 0.0, 0.8094547671420631, 0.45643500830911327, 0.40891271449756, 0.4341589796501862], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5073818], dtype=float32), -0.3223068]. 
=============================================
[2019-03-24 02:55:02,523] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.8797909e-23 1.1243954e-21 2.2965061e-18 3.1906634e-11], sum to 1.0000
[2019-03-24 02:55:02,535] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0441
[2019-03-24 02:55:02,537] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.5, 46.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5474881852203336, 6.9112, 6.9112, 121.9260426156618, 402611.0206456096, 402611.0206456096, 123362.813634825], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1408800.0000, 
sim time next is 1409400.0000, 
raw observation next is [25.85, 45.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5544876219540175, 6.911199999999999, 6.9112, 121.9260426156618, 408501.5092546438, 408501.5092546442, 124345.7712436462], 
processed observation next is [0.0, 0.30434782608695654, 0.5129629629629631, 0.455, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4431095274425218, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1458933961623728, 0.14589339616237293, 0.23912648316085808], 
reward next is 0.7609, 
noisyNet noise sample is [array([-1.7833462], dtype=float32), -0.45970622]. 
=============================================
[2019-03-24 02:55:02,830] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 4.6851693e-32 7.6830762e-31 6.1592690e-24 5.4681231e-17], sum to 1.0000
[2019-03-24 02:55:02,836] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1887
[2019-03-24 02:55:02,841] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.0, 26.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6272852181562566, 6.911200000000001, 6.9112, 121.9260426156618, 465251.0213970454, 465251.0213970449, 132742.7489549461], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1425600.0000, 
sim time next is 1426200.0000, 
raw observation next is [32.16666666666667, 25.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6530540922742303, 6.911200000000001, 6.9112, 121.9260426156618, 484556.1246496861, 484556.1246496856, 135380.6411532239], 
processed observation next is [0.0, 0.5217391304347826, 0.7469135802469138, 0.2566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5663176153427878, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17305575880345933, 0.17305575880345914, 0.26034738683312286], 
reward next is 0.7397, 
noisyNet noise sample is [array([0.33774012], dtype=float32), 0.776361]. 
=============================================
[2019-03-24 02:55:19,414] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 4.0311076e-26 1.0071467e-24 5.2643119e-21 3.9877637e-18], sum to 1.0000
[2019-03-24 02:55:19,421] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4736
[2019-03-24 02:55:19,428] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.2, 76.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7082142966506648, 6.911200000000001, 6.9112, 121.9260426156618, 529192.7914925759, 529192.7914925754, 146213.0232602983], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1711200.0000, 
sim time next is 1711800.0000, 
raw observation next is [23.15, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7111315391532466, 6.911200000000001, 6.9112, 121.9260426156618, 531346.4804360449, 531346.4804360444, 146652.4588493773], 
processed observation next is [1.0, 0.8260869565217391, 0.4129629629629629, 0.77, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6389144239415581, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1897666001557303, 0.18976660015573013, 0.28202395932572555], 
reward next is 0.7180, 
noisyNet noise sample is [array([0.6008511], dtype=float32), -0.7272471]. 
=============================================
[2019-03-24 02:55:28,526] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.4344750e-25 9.1468769e-24 2.5643584e-21 3.5321022e-17], sum to 1.0000
[2019-03-24 02:55:28,536] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0633
[2019-03-24 02:55:28,543] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1468597.48220582 W.
[2019-03-24 02:55:28,548] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.3, 60.0, 1.0, 2.0, 0.6410676205226734, 1.0, 2.0, 0.6410676205226734, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1468597.48220582, 1468597.48220582, 282793.1488594858], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1958400.0000, 
sim time next is 1959000.0000, 
raw observation next is [28.4, 59.66666666666666, 1.0, 2.0, 0.6097742007585878, 0.0, 1.0, 0.0, 1.0, 1.0, 0.97200583849496, 6.911199999999999, 6.9112, 121.9260426156618, 1409300.571964838, 1409300.571964838, 297394.4623895549], 
processed observation next is [1.0, 0.6956521739130435, 0.6074074074074074, 0.5966666666666666, 1.0, 1.0, 0.5354454770935568, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9650072981186999, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.503321632844585, 0.503321632844585, 0.571912427672221], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.266402], dtype=float32), -0.96298707]. 
=============================================
[2019-03-24 02:55:28,560] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[63.029594]
 [62.686596]
 [62.090023]
 [61.28484 ]
 [60.942677]], R is [[62.8736763 ]
 [62.70110703]
 [62.45794678]
 [62.21905899]
 [61.59687042]].
[2019-03-24 02:55:29,425] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.2499903e-26 7.9318534e-26 1.3759251e-22 2.1839475e-18], sum to 1.0000
[2019-03-24 02:55:29,435] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8251
[2019-03-24 02:55:29,440] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.75, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6253302616733502, 6.911200000000001, 6.9112, 121.9260426156618, 465733.599980825, 465733.5999808246, 134075.1682105939], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1906200.0000, 
sim time next is 1906800.0000, 
raw observation next is [19.66666666666667, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6202815849093517, 6.911199999999999, 6.9112, 121.9260426156618, 461735.2258255976, 461735.2258255981, 133359.3064332964], 
processed observation next is [1.0, 0.043478260869565216, 0.28395061728395077, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5253519811366896, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16490543779485628, 0.16490543779485647, 0.25646020467941616], 
reward next is 0.7435, 
noisyNet noise sample is [array([-1.1356542], dtype=float32), -0.90832543]. 
=============================================
[2019-03-24 02:55:32,153] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 02:55:32,155] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:55:32,156] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:55:32,156] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:55:32,157] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:55:32,157] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:55:32,158] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:55:32,159] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:55:32,160] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:55:32,158] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:55:32,161] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:55:32,179] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run37
[2019-03-24 02:55:32,180] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run37
[2019-03-24 02:55:32,224] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run37
[2019-03-24 02:55:32,226] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run37
[2019-03-24 02:55:32,276] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run37
[2019-03-24 02:55:46,034] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.25783807]
[2019-03-24 02:55:46,036] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.18716321, 50.38543111666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5189011070742671, 6.911200000000001, 6.9112, 121.9260426156618, 379398.3226307902, 379398.3226307897, 119902.940676603]
[2019-03-24 02:55:46,037] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:55:46,041] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.2312771e-30 8.7352828e-29 5.2611293e-25 3.8616500e-20], sampled 0.5641353163699229
[2019-03-24 02:55:55,266] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.25783807]
[2019-03-24 02:55:55,268] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.97001982, 52.045393275, 1.0, 2.0, 0.7272555434788065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156525, 901445.5658880937, 901445.5658880937, 184248.9651793734]
[2019-03-24 02:55:55,270] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 02:55:55,273] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 5.0717140e-25 8.7876107e-24 1.2616583e-20 1.3396692e-16], sampled 0.2533588956583981
[2019-03-24 02:55:55,275] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 901445.5658880937 W.
[2019-03-24 02:56:16,992] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.25783807]
[2019-03-24 02:56:16,992] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.7328517, 83.18768865999999, 1.0, 2.0, 0.7352839534460097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 838037.6875767612, 838037.6875767612, 182928.9456696025]
[2019-03-24 02:56:16,992] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:56:17,010] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 5.3343180e-28 1.4123177e-26 4.6548877e-23 1.4884992e-18], sampled 0.6044416258012407
[2019-03-24 02:56:17,011] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 838037.6875767612 W.
[2019-03-24 02:56:42,003] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.25783807]
[2019-03-24 02:56:42,004] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.31666666666666, 67.5, 1.0, 2.0, 0.7186992871469325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819125.2630469892, 819125.2630469892, 179717.0451935891]
[2019-03-24 02:56:42,005] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 02:56:42,007] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.3128429e-28 3.7954637e-27 1.4770696e-23 5.9113397e-19], sampled 0.0651439531239979
[2019-03-24 02:56:42,010] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 819125.2630469892 W.
[2019-03-24 02:57:10,593] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 02:57:10,789] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 02:57:10,804] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 02:57:10,840] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 02:57:10,866] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 02:57:11,883] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 900000, evaluation results [900000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 02:57:24,951] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.1646618e-15 3.0889007e-15 7.2959512e-12 5.4928044e-09], sum to 1.0000
[2019-03-24 02:57:24,959] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7439
[2019-03-24 02:57:24,966] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 699279.8214007891 W.
[2019-03-24 02:57:24,971] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.35, 88.5, 1.0, 2.0, 0.2038903731553693, 1.0, 1.0, 0.2038903731553693, 1.0, 1.0, 0.3246549066639424, 6.911200000000001, 6.9112, 121.94756008, 699279.8214007891, 699279.8214007886, 221877.2536906161], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2187000.0000, 
sim time next is 2187600.0000, 
raw observation next is [24.4, 88.33333333333334, 1.0, 2.0, 0.2226728456765842, 1.0, 2.0, 0.2226728456765842, 1.0, 2.0, 0.3545024222654208, 6.911199999999999, 6.9112, 121.94756008, 761333.9881540261, 761333.9881540266, 228144.1422683298], 
processed observation next is [1.0, 0.30434782608695654, 0.4592592592592592, 0.8833333333333334, 1.0, 1.0, 0.07461053056736215, 1.0, 1.0, 0.07461053056736215, 1.0, 1.0, 0.19312802783177596, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.27190499576929505, 0.2719049957692952, 0.4387387351314035], 
reward next is 0.5613, 
noisyNet noise sample is [array([-0.95219916], dtype=float32), 0.12494764]. 
=============================================
[2019-03-24 02:57:26,902] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.7724685e-21 3.6879340e-20 1.2109910e-18 1.5366658e-15], sum to 1.0000
[2019-03-24 02:57:26,909] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4530
[2019-03-24 02:57:26,917] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.7, 95.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8518227748610667, 6.911200000000001, 6.9112, 121.9260426156618, 628605.945992335, 628605.9459923345, 168358.1969638034], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2236200.0000, 
sim time next is 2236800.0000, 
raw observation next is [22.7, 95.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8552198472314626, 6.911199999999999, 6.9112, 121.9260426156618, 630959.913985625, 630959.9139856255, 168836.3900100939], 
processed observation next is [1.0, 0.9130434782608695, 0.39629629629629626, 0.9533333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8190248090393282, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2253428264234375, 0.22534282642343767, 0.3246853654040267], 
reward next is 0.6753, 
noisyNet noise sample is [array([-0.9732683], dtype=float32), 0.7196379]. 
=============================================
[2019-03-24 02:57:48,739] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.5071402e-29 3.3053863e-29 2.5845164e-24 1.5689242e-22], sum to 1.0000
[2019-03-24 02:57:48,747] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3469
[2019-03-24 02:57:48,752] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.28333333333333, 93.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7432691477099088, 6.911200000000001, 6.9112, 121.9260426156618, 554976.0192901063, 554976.0192901058, 151157.0499057712], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2602200.0000, 
sim time next is 2602800.0000, 
raw observation next is [21.2, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7415302778340288, 6.911199999999999, 6.9112, 121.9260426156618, 553714.780050567, 553714.7800505675, 150896.7007057587], 
processed observation next is [0.0, 0.13043478260869565, 0.34074074074074073, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6769128472925359, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19775527858948821, 0.19775527858948838, 0.2901859628956898], 
reward next is 0.7098, 
noisyNet noise sample is [array([0.1100294], dtype=float32), 0.754232]. 
=============================================
[2019-03-24 02:57:56,449] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.6532709e-12 2.1921602e-11 1.2888360e-09 9.9314921e-09], sum to 1.0000
[2019-03-24 02:57:56,454] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0469
[2019-03-24 02:57:56,459] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 751894.4035702609 W.
[2019-03-24 02:57:56,464] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.66666666666667, 94.0, 1.0, 2.0, 0.6597399492486619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 751894.4035702609, 751894.4035702604, 168659.7049301215], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2766000.0000, 
sim time next is 2766600.0000, 
raw observation next is [24.5, 94.0, 1.0, 2.0, 0.3260730340744356, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5191188897038382, 6.9112, 6.9112, 121.9260426156618, 743235.5905917881, 743235.5905917881, 202382.9697472476], 
processed observation next is [1.0, 0.0, 0.46296296296296297, 0.94, 1.0, 1.0, 0.1977059929457567, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.39889861212979777, 0.0, 0.0, 0.8094621288201359, 0.26544128235421, 0.26544128235421, 0.38919801874470694], 
reward next is 0.6108, 
noisyNet noise sample is [array([-0.51350784], dtype=float32), 2.7053049]. 
=============================================
[2019-03-24 02:58:00,163] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9999976e-01 2.2925235e-10 2.0486699e-09 3.7701939e-09 2.3193161e-07], sum to 1.0000
[2019-03-24 02:58:00,170] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6880
[2019-03-24 02:58:00,177] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2445241.677431889 W.
[2019-03-24 02:58:00,182] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.66666666666667, 55.66666666666667, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 7.141446967396269, 6.9112, 121.9250798143314, 2445241.677431889, 2327335.581949338, 443048.4272770145], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2816400.0000, 
sim time next is 2817000.0000, 
raw observation next is [32.7, 56.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.673702080218743, 6.9112, 121.9228488112673, 2718149.998987583, 2327691.010439479, 443048.5676116437], 
processed observation next is [1.0, 0.6086956521739131, 0.7666666666666667, 0.56, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.25, 0.07625020802187432, 0.0, 0.809440925280279, 0.9707678567812796, 0.8313182180140996, 0.8520164761762379], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04976254], dtype=float32), 0.7849393]. 
=============================================
[2019-03-24 02:58:00,200] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[23.615107]
 [23.710903]
 [23.893059]
 [23.453794]
 [23.470728]], R is [[23.20466042]
 [22.97261429]
 [22.89913368]
 [22.83041954]
 [22.60211563]].
[2019-03-24 02:58:03,029] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 02:58:03,030] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 02:58:03,031] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 02:58:03,032] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 02:58:03,031] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 02:58:03,033] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:58:03,034] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:58:03,034] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 02:58:03,033] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:58:03,034] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:58:03,036] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 02:58:03,053] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run38
[2019-03-24 02:58:03,077] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run38
[2019-03-24 02:58:03,078] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run38
[2019-03-24 02:58:03,079] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run38
[2019-03-24 02:58:03,123] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run38
[2019-03-24 02:58:11,130] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.25898707]
[2019-03-24 02:58:11,131] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.5, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4398536649290214, 6.911200000000001, 6.9112, 121.9260426156618, 314050.9835448316, 314050.9835448312, 101876.4923710735]
[2019-03-24 02:58:11,132] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:58:11,136] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.00000000e+00 1.03752334e-19 1.46999083e-18 6.34124350e-18
 6.47731245e-14], sampled 0.8127457745692
[2019-03-24 02:58:17,542] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.25898707]
[2019-03-24 02:58:17,543] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4863832872519395, 6.911199999999999, 6.9112, 121.9260426156618, 347280.1758565473, 347280.1758565478, 103574.9898399329]
[2019-03-24 02:58:17,544] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:58:17,549] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.9759238e-20 4.5684523e-19 2.0398450e-18 2.7158890e-14], sampled 0.08709375302838818
[2019-03-24 02:58:43,941] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.25898707]
[2019-03-24 02:58:43,942] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.0, 53.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.307717609639747, 6.9112, 121.9243944583087, 1365991.99715475, 1162942.285475745, 245586.536100865]
[2019-03-24 02:58:43,942] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:58:43,944] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.2220136e-16 1.0538240e-15 3.9644721e-15 9.4869364e-12], sampled 0.46383099527946614
[2019-03-24 02:58:43,945] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1365991.99715475 W.
[2019-03-24 02:58:47,254] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.25898707]
[2019-03-24 02:58:47,255] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.08333333333334, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8977114052703533, 6.9112, 6.9112, 121.9260426156618, 657622.8504923469, 657622.8504923469, 175509.8140504001]
[2019-03-24 02:58:47,256] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:58:47,259] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.0387579e-21 1.9472413e-20 9.6879510e-20 2.6719464e-15], sampled 0.3633196819934371
[2019-03-24 02:59:15,022] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.25898707]
[2019-03-24 02:59:15,024] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.51382004333333, 48.22571124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7412381240210962, 6.911200000000001, 6.9112, 121.9260426156618, 553530.8215475961, 553530.8215475957, 147904.292969189]
[2019-03-24 02:59:15,024] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 02:59:15,027] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.6193031e-20 2.5615064e-19 1.1734642e-18 1.7947608e-14], sampled 0.14002686424874677
[2019-03-24 02:59:20,774] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.25898707]
[2019-03-24 02:59:20,774] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.25, 82.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8311031316675804, 6.911199999999999, 6.9112, 121.9260426156618, 614411.7547102575, 614411.7547102579, 165393.6218643791]
[2019-03-24 02:59:20,776] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:59:20,778] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.3369348e-20 5.0546748e-19 2.2623772e-18 2.9588799e-14], sampled 0.41382975515358644
[2019-03-24 02:59:27,538] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.25898707]
[2019-03-24 02:59:27,538] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.0, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8805345914161226, 6.9112, 6.9112, 121.9260426156618, 643743.4870863497, 643743.4870863497, 173509.2514376383]
[2019-03-24 02:59:27,540] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 02:59:27,542] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.6376881e-21 4.5451222e-20 2.2566100e-19 5.2383262e-15], sampled 0.6494282973724959
[2019-03-24 02:59:31,637] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.25898707]
[2019-03-24 02:59:31,638] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.66666666666666, 25.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8598236945383119, 6.9112, 6.9112, 121.9260426156618, 635226.8858653243, 635226.8858653243, 155784.8094280679]
[2019-03-24 02:59:31,639] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 02:59:31,642] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.0429172e-21 5.3042068e-20 2.5709531e-19 5.6662934e-15], sampled 0.007808534435242542
[2019-03-24 02:59:40,457] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 02:59:40,967] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 02:59:41,045] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 02:59:41,227] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 02:59:41,460] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 02:59:42,480] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 925000, evaluation results [925000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 02:59:55,170] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.3645731e-19 6.7172042e-20 2.8260887e-17 1.9494073e-13], sum to 1.0000
[2019-03-24 02:59:55,176] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2046
[2019-03-24 02:59:55,182] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.5, 70.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9379325436066612, 6.911200000000001, 6.9112, 121.9260426156618, 681224.9146569681, 681224.9146569676, 181967.9887872149], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3191400.0000, 
sim time next is 3192000.0000, 
raw observation next is [27.33333333333334, 73.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9746655744634497, 6.911199999999999, 6.9112, 121.9259540531216, 704058.2470126123, 704058.2470126128, 187609.545127598], 
processed observation next is [1.0, 0.9565217391304348, 0.5679012345679014, 0.7333333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.968331968079312, -8.881784197001253e-17, 0.0, 0.8094615408569675, 0.2514493739330758, 0.251449373933076, 0.36078758678384226], 
reward next is 0.6392, 
noisyNet noise sample is [array([-1.206556], dtype=float32), 0.82683736]. 
=============================================
[2019-03-24 02:59:55,198] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[50.039593]
 [50.145535]
 [50.198708]
 [50.166092]
 [50.144188]], R is [[49.85656738]
 [50.00806427]
 [50.16527176]
 [50.32829666]
 [50.49482346]].
[2019-03-24 02:59:55,904] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 5.5133806e-19 1.2454823e-18 1.1372532e-16 1.1082227e-13], sum to 1.0000
[2019-03-24 02:59:55,910] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0545
[2019-03-24 02:59:55,914] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.16666666666666, 59.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8632275129634037, 6.9112, 6.9112, 121.9260426156618, 636270.5159193099, 636270.5159193099, 170033.9273779268], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3109200.0000, 
sim time next is 3109800.0000, 
raw observation next is [28.08333333333334, 58.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8446126679016768, 6.9112, 6.9112, 121.9260426156618, 624120.1705360747, 624120.1705360747, 167179.7901064656], 
processed observation next is [1.0, 1.0, 0.5956790123456792, 0.5883333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.805765834877096, 0.0, 0.0, 0.8094621288201359, 0.22290006090574097, 0.22290006090574097, 0.3214995963585877], 
reward next is 0.6785, 
noisyNet noise sample is [array([0.7173977], dtype=float32), -0.53972155]. 
=============================================
[2019-03-24 02:59:57,465] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 8.9605027e-13 6.6101647e-12 3.6907990e-12 4.7780055e-09], sum to 1.0000
[2019-03-24 02:59:57,471] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1842
[2019-03-24 02:59:57,477] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1661995.082840063 W.
[2019-03-24 02:59:57,481] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.91666666666667, 33.0, 1.0, 2.0, 0.4765146940648078, 1.0, 2.0, 0.4765146940648078, 1.0, 2.0, 0.7603626780470618, 6.9112, 6.9112, 121.94756008, 1661995.082840063, 1661995.082840063, 332319.0378593967], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3150600.0000, 
sim time next is 3151200.0000, 
raw observation next is [32.93333333333334, 34.0, 1.0, 2.0, 0.6994909712004905, 1.0, 2.0, 0.6994909712004905, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1641752.443438697, 1641752.443438697, 306217.7674517531], 
processed observation next is [1.0, 0.4782608695652174, 0.7753086419753088, 0.34, 1.0, 1.0, 0.6422511561910601, 1.0, 1.0, 0.6422511561910601, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5863401583709632, 0.5863401583709632, 0.5888803220226021], 
reward next is 0.4111, 
noisyNet noise sample is [array([-1.0139927], dtype=float32), 0.48322067]. 
=============================================
[2019-03-24 03:00:05,710] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.6460069e-22 7.6152624e-24 1.9149316e-21 1.2391428e-16], sum to 1.0000
[2019-03-24 03:00:05,715] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7677
[2019-03-24 03:00:05,723] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8958926361058718, 6.9112, 6.9112, 121.9260426156618, 656662.0565633776, 656662.0565633776, 175189.1355223592], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3318600.0000, 
sim time next is 3319200.0000, 
raw observation next is [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8960266905002201, 6.9112, 6.9112, 121.9260426156618, 656760.3247411128, 656760.3247411128, 175206.8695079228], 
processed observation next is [0.0, 0.43478260869565216, 0.4444444444444444, 0.89, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8700333631252751, 0.0, 0.0, 0.8094621288201359, 0.2345572588361117, 0.2345572588361117, 0.33693628751523613], 
reward next is 0.6631, 
noisyNet noise sample is [array([-0.0731926], dtype=float32), 0.103465684]. 
=============================================
[2019-03-24 03:00:06,033] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 9.5225861e-29 1.0848048e-26 2.6147470e-28 1.6225060e-20], sum to 1.0000
[2019-03-24 03:00:06,040] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5762
[2019-03-24 03:00:06,044] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.95, 98.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8258164527609045, 6.9112, 6.9112, 121.9260426156618, 611861.3777230855, 611861.3777230855, 164235.7192461581], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3304200.0000, 
sim time next is 3304800.0000, 
raw observation next is [22.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8404838240287745, 6.911200000000001, 6.9112, 121.9260426156618, 621525.7125061658, 621525.7125061655, 166505.6296613319], 
processed observation next is [0.0, 0.2608695652173913, 0.37037037037037035, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.800604780035968, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22197346875220209, 0.22197346875220197, 0.32020313396409983], 
reward next is 0.6798, 
noisyNet noise sample is [array([-0.49202853], dtype=float32), 1.6045396]. 
=============================================
[2019-03-24 03:00:06,756] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.5091584e-23 3.8836115e-23 4.3213773e-21 1.8643711e-17], sum to 1.0000
[2019-03-24 03:00:06,764] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5181
[2019-03-24 03:00:06,767] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8570600184220634, 6.9112, 6.9112, 121.9260426156618, 633268.8527949427, 633268.8527949427, 168771.4447046293], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3307200.0000, 
sim time next is 3307800.0000, 
raw observation next is [22.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8557541448503357, 6.911200000000001, 6.9112, 121.9260426156618, 632303.5394192906, 632303.5394192901, 168605.6332044787], 
processed observation next is [0.0, 0.2608695652173913, 0.37037037037037035, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8196926810629196, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22582269264974664, 0.22582269264974647, 0.3242416023163052], 
reward next is 0.6758, 
noisyNet noise sample is [array([0.20906134], dtype=float32), 0.5682181]. 
=============================================
[2019-03-24 03:00:10,206] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9999213e-01 9.2888968e-09 1.6906444e-08 3.0718769e-07 7.4675804e-06], sum to 1.0000
[2019-03-24 03:00:10,211] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2643
[2019-03-24 03:00:10,221] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 972238.7673317653 W.
[2019-03-24 03:00:10,266] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.00000000000001, 1.0, 2.0, 0.284318594718325, 1.0, 2.0, 0.284318594718325, 1.0, 1.0, 0.4526444624017563, 6.9112, 6.9112, 121.94756008, 972238.7673317653, 972238.7673317653, 250123.2516229626], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3381000.0000, 
sim time next is 3381600.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.791728356852832, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 907414.1554888913, 907414.1554888913, 194494.1363220359], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.7520575676819429, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32407648410317547, 0.32407648410317547, 0.3740271852346844], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5574882], dtype=float32), 0.9178382]. 
=============================================
[2019-03-24 03:00:14,433] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.8426713e-01 2.0789173e-09 1.6459849e-11 5.4225572e-03 2.1031034e-01], sum to 1.0000
[2019-03-24 03:00:14,438] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2897
[2019-03-24 03:00:14,445] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 781362.7408134479 W.
[2019-03-24 03:00:14,449] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.91666666666667, 88.33333333333334, 1.0, 2.0, 0.2285278158107011, 1.0, 1.0, 0.2285278158107011, 1.0, 2.0, 0.363823725402, 6.9112, 6.9112, 121.94756008, 781362.7408134479, 781362.7408134479, 230140.4169496004], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3449400.0000, 
sim time next is 3450000.0000, 
raw observation next is [25.83333333333334, 87.66666666666667, 1.0, 2.0, 0.6751181685297567, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769429.4950614396, 769429.4950614396, 171485.2143376273], 
processed observation next is [1.0, 0.9565217391304348, 0.5123456790123458, 0.8766666666666667, 1.0, 1.0, 0.613235914916377, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27479624823622845, 0.27479624823622845, 0.32977925834159094], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.476792], dtype=float32), -1.6204034]. 
=============================================
[2019-03-24 03:00:14,463] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[40.55976 ]
 [40.67798 ]
 [40.69682 ]
 [41.01432 ]
 [40.950653]], R is [[40.17316055]
 [39.77143097]
 [39.37371826]
 [39.61109543]
 [39.77131653]].
[2019-03-24 03:00:16,690] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9995613e-01 5.2464815e-09 9.6435967e-12 2.5270733e-06 4.1342544e-05], sum to 1.0000
[2019-03-24 03:00:16,696] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4110
[2019-03-24 03:00:16,703] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1883744.362219976 W.
[2019-03-24 03:00:16,716] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.8258468667181266, 1.0, 2.0, 0.8258468667181266, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1883744.362219976, 1883744.362219976, 354550.714149937], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3513600.0000, 
sim time next is 3514200.0000, 
raw observation next is [27.08333333333333, 80.83333333333333, 1.0, 2.0, 0.7603490947476987, 1.0, 2.0, 0.7603490947476987, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1734199.892156144, 1734199.892156145, 327642.3111646799], 
processed observation next is [1.0, 0.6956521739130435, 0.5586419753086418, 0.8083333333333332, 1.0, 1.0, 0.71470130327107, 1.0, 1.0, 0.71470130327107, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.61935710434148, 0.6193571043414804, 0.6300813676243844], 
reward next is 0.3699, 
noisyNet noise sample is [array([-0.08761854], dtype=float32), -2.6379783]. 
=============================================
[2019-03-24 03:00:19,837] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 7.6731151e-13 5.6138374e-16 1.4514736e-08 2.7054403e-10], sum to 1.0000
[2019-03-24 03:00:19,847] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7660
[2019-03-24 03:00:19,857] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 98.0, 1.0, 2.0, 0.5815566931442585, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 674424.7586509723, 674424.7586509723, 155491.0246729831], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3640800.0000, 
sim time next is 3641400.0000, 
raw observation next is [23.0, 97.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9084842472217535, 6.9112, 6.9112, 121.9260426156618, 664842.4804206024, 664842.4804206024, 177082.698089609], 
processed observation next is [1.0, 0.13043478260869565, 0.4074074074074074, 0.97, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.8856053090271917, 0.0, 0.0, 0.8094621288201359, 0.237443743007358, 0.237443743007358, 0.340543650172325], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.95697016], dtype=float32), 0.19846804]. 
=============================================
[2019-03-24 03:00:23,138] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.2562081e-20 1.0535187e-22 4.2994723e-15 3.3038357e-14], sum to 1.0000
[2019-03-24 03:00:23,145] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4696
[2019-03-24 03:00:23,150] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.75, 78.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8433841785460436, 6.9112, 6.9112, 121.9260426156618, 622910.5811059331, 622910.5811059331, 167123.4366371497], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3613800.0000, 
sim time next is 3614400.0000, 
raw observation next is [24.7, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8360755751361182, 6.911200000000001, 6.9112, 121.9260426156618, 618619.3433118764, 618619.343311876, 165828.3154931659], 
processed observation next is [1.0, 0.8695652173913043, 0.4703703703703703, 0.78, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7950944689201478, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22093547975424158, 0.2209354797542414, 0.3189006067176267], 
reward next is 0.6811, 
noisyNet noise sample is [array([0.08195962], dtype=float32), -0.6558571]. 
=============================================
[2019-03-24 03:00:33,864] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 03:00:33,865] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:00:33,865] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:00:33,868] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:00:33,870] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:00:33,871] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:00:33,872] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:00:33,873] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:00:33,873] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:00:33,874] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:00:33,874] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:00:33,886] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run39
[2019-03-24 03:00:33,909] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run39
[2019-03-24 03:00:33,910] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run39
[2019-03-24 03:00:33,934] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run39
[2019-03-24 03:00:33,979] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run39
[2019-03-24 03:01:01,830] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.26175308]
[2019-03-24 03:01:01,831] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.91379801166667, 92.41944788166667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6576030969300499, 6.911200000000001, 6.9112, 121.9260426156618, 490736.5735994133, 490736.5735994129, 138392.4449968975]
[2019-03-24 03:01:01,832] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:01:01,833] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.9370937e-19 2.4359023e-20 4.7310619e-15 1.7899413e-17], sampled 0.5335614940598079
[2019-03-24 03:01:08,299] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.26175308]
[2019-03-24 03:01:08,300] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [36.255646435, 33.916900785, 1.0, 2.0, 0.8203644487387258, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1650184.098338667, 1650184.098338668, 340311.4255817922]
[2019-03-24 03:01:08,300] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:01:08,302] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.1508559e-14 2.0877746e-16 8.9905569e-11 4.3750873e-13], sampled 0.09044454874398877
[2019-03-24 03:01:08,303] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1650184.098338667 W.
[2019-03-24 03:01:21,063] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.26175308]
[2019-03-24 03:01:21,064] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [34.5, 64.0, 1.0, 2.0, 0.9325728589398024, 1.0, 2.0, 0.9325728589398024, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425093562, 2127474.733769248, 2127474.733769248, 401584.3836654251]
[2019-03-24 03:01:21,065] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:01:21,068] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.9648653e-13 9.1081262e-16 1.4402296e-09 5.1971825e-12], sampled 0.5981429246825241
[2019-03-24 03:01:21,069] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2127474.733769248 W.
[2019-03-24 03:01:41,224] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.26175308]
[2019-03-24 03:01:41,224] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.19723064, 68.40023778666668, 1.0, 2.0, 0.891357757271855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1016040.259857225, 1016040.259857225, 215545.577708766]
[2019-03-24 03:01:41,225] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:01:41,227] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.00000000e+00 5.34508791e-15 6.85322777e-17 2.26754795e-11
 1.12616425e-13], sampled 0.920593007810835
[2019-03-24 03:01:41,228] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1016040.259857225 W.
[2019-03-24 03:01:43,727] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.26175308]
[2019-03-24 03:01:43,728] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.53460636833334, 100.7753887533333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6939671149028256, 6.911200000000001, 6.9112, 121.9260426156618, 518273.6938756799, 518273.6938756795, 142854.373097116]
[2019-03-24 03:01:43,729] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:01:43,731] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.0000867e-21 1.0591722e-22 8.5229302e-17 1.7082263e-19], sampled 0.10135421296103597
[2019-03-24 03:02:08,912] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00081642], dtype=float32), 0.26175308]
[2019-03-24 03:02:08,913] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.40801720666667, 55.28546576666668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3775927511971994, 6.9112, 6.9112, 121.9260426156618, 269589.5203111649, 269589.5203111649, 83461.56462599045]
[2019-03-24 03:02:08,914] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:02:08,918] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.00000000e+00 2.07450552e-19 1.11442086e-20 2.14917331e-15
 8.19910688e-18], sampled 0.27845474719339114
[2019-03-24 03:02:12,413] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 03:02:12,509] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 03:02:12,594] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 03:02:12,623] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 03:02:12,765] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 03:02:13,782] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 950000, evaluation results [950000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 03:02:13,793] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 8.4633639e-21 8.1266618e-22 1.7354861e-17 4.5737029e-18], sum to 1.0000
[2019-03-24 03:02:13,794] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1301
[2019-03-24 03:02:13,802] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.66666666666667, 58.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9368454526546379, 6.911200000000001, 6.9112, 121.9260426156618, 680264.0793679003, 680264.0793678998, 181844.4423360495], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3832800.0000, 
sim time next is 3833400.0000, 
raw observation next is [29.83333333333333, 58.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9536766114540661, 6.911200000000001, 6.9112, 121.9260426156618, 690236.9111943071, 690236.9111943067, 184488.4993059133], 
processed observation next is [0.0, 0.34782608695652173, 0.6604938271604937, 0.5883333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9420957643175826, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24651318256939542, 0.24651318256939525, 0.3547855755882948], 
reward next is 0.6452, 
noisyNet noise sample is [array([-0.03659307], dtype=float32), 1.6156921]. 
=============================================
[2019-03-24 03:02:16,089] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 9.9737897e-16 4.2139749e-18 2.4486540e-11 3.1917662e-14], sum to 1.0000
[2019-03-24 03:02:16,097] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8077
[2019-03-24 03:02:16,105] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 832900.584353447 W.
[2019-03-24 03:02:16,110] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.58333333333333, 89.83333333333334, 1.0, 2.0, 0.3653895849963545, 0.0, 2.0, 0.0, 1.0, 1.0, 0.581712119222204, 6.911199999999999, 6.9112, 121.9260426156618, 832900.584353447, 832900.5843534474, 213663.5440109347], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3885000.0000, 
sim time next is 3885600.0000, 
raw observation next is [26.46666666666667, 90.66666666666667, 1.0, 2.0, 0.3690760334603157, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5875810652360748, 6.9112, 6.9112, 121.9260426156618, 841308.4054575977, 841308.4054575977, 214752.553173615], 
processed observation next is [0.0, 1.0, 0.5358024691358025, 0.9066666666666667, 1.0, 1.0, 0.24890003983370917, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.48447633154509345, 0.0, 0.0, 0.8094621288201359, 0.30046728766342773, 0.30046728766342773, 0.4129856791800288], 
reward next is 0.5870, 
noisyNet noise sample is [array([0.14532179], dtype=float32), -1.293922]. 
=============================================
[2019-03-24 03:02:16,720] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 6.2740080e-13 3.0730843e-13 2.0377845e-10 8.3993663e-12], sum to 1.0000
[2019-03-24 03:02:16,735] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6404
[2019-03-24 03:02:16,745] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 822011.335879338 W.
[2019-03-24 03:02:16,750] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 91.5, 1.0, 2.0, 0.2404100780677211, 1.0, 2.0, 0.2404100780677211, 1.0, 1.0, 0.3827406738934412, 6.9112, 6.9112, 121.94756008, 822011.335879338, 822011.335879338, 234250.6367445192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3894600.0000, 
sim time next is 3895200.0000, 
raw observation next is [26.0, 91.0, 1.0, 2.0, 0.7182259668894655, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818585.5162776831, 818585.5162776831, 179622.9126477991], 
processed observation next is [0.0, 0.08695652173913043, 0.5185185185185185, 0.91, 1.0, 1.0, 0.664554722487459, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2923519700991725, 0.2923519700991725, 0.3454286781688444], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.17879671], dtype=float32), -0.05524526]. 
=============================================
[2019-03-24 03:02:17,069] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.00000000e+00 9.59438583e-13 2.21994108e-13 2.02145785e-08
 1.04906965e-10], sum to 1.0000
[2019-03-24 03:02:17,071] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4547
[2019-03-24 03:02:17,079] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 818623.550539503 W.
[2019-03-24 03:02:17,084] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 91.0, 1.0, 2.0, 0.2394197959795622, 1.0, 1.0, 0.2394197959795622, 1.0, 1.0, 0.3811641125578561, 6.9112, 6.9112, 121.94756008, 818623.550539503, 818623.550539503, 233905.0716484635], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3895200.0000, 
sim time next is 3895800.0000, 
raw observation next is [26.16666666666667, 90.66666666666667, 1.0, 2.0, 0.2399317330758354, 1.0, 2.0, 0.2399317330758354, 1.0, 2.0, 0.3819791330877503, 6.911199999999999, 6.9112, 121.94756008, 820374.9011488765, 820374.901148877, 234083.6468582244], 
processed observation next is [0.0, 0.08695652173913043, 0.5246913580246916, 0.9066666666666667, 1.0, 1.0, 0.09515682509028024, 1.0, 1.0, 0.09515682509028024, 1.0, 1.0, 0.22747391635968783, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.29299103612459876, 0.2929910361245989, 0.45016085934273925], 
reward next is 0.5498, 
noisyNet noise sample is [array([0.46522608], dtype=float32), 1.0895807]. 
=============================================
[2019-03-24 03:02:22,462] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.0926898e-09 2.3164881e-10 4.9168509e-08 5.3386953e-09], sum to 1.0000
[2019-03-24 03:02:22,470] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4670
[2019-03-24 03:02:22,475] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 753039.752670781 W.
[2019-03-24 03:02:22,482] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.65, 86.5, 1.0, 2.0, 0.3303722137468299, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5259633237567971, 6.911199999999999, 6.9112, 121.9260426156618, 753039.752670781, 753039.7526707815, 203586.0590737525], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3979800.0000, 
sim time next is 3980400.0000, 
raw observation next is [25.6, 86.66666666666667, 1.0, 2.0, 0.3291396701191313, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5240010741603573, 6.9112, 6.9112, 121.9260426156618, 750228.9576958519, 750228.9576958519, 203240.3863036935], 
processed observation next is [1.0, 0.043478260869565216, 0.5037037037037038, 0.8666666666666667, 1.0, 1.0, 0.201356750141823, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.40500134270044663, 0.0, 0.0, 0.8094621288201359, 0.26793891346280424, 0.26793891346280424, 0.3908468967378721], 
reward next is 0.6092, 
noisyNet noise sample is [array([0.33001631], dtype=float32), 0.5975962]. 
=============================================
[2019-03-24 03:02:23,804] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9994099e-01 2.3135158e-07 7.0952684e-09 5.2838659e-05 6.0107609e-06], sum to 1.0000
[2019-03-24 03:02:23,811] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9179
[2019-03-24 03:02:23,819] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1552430.710776235 W.
[2019-03-24 03:02:23,822] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.45, 94.0, 1.0, 2.0, 0.6807245768269266, 1.0, 1.0, 0.6807245768269266, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1552430.710776235, 1552430.710776235, 296931.9843650396], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4005000.0000, 
sim time next is 4005600.0000, 
raw observation next is [24.5, 94.0, 1.0, 2.0, 0.760359605937342, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1581697.383425946, 1581697.383425947, 328490.5683745779], 
processed observation next is [1.0, 0.34782608695652173, 0.46296296296296297, 0.94, 1.0, 1.0, 0.7147138165920738, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5648919226521236, 0.564891922652124, 0.6317126314895729], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1426562], dtype=float32), 1.067133]. 
=============================================
[2019-03-24 03:02:28,091] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.8265238e-23 1.9034579e-24 4.3010055e-19 1.3442078e-19], sum to 1.0000
[2019-03-24 03:02:28,098] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9467
[2019-03-24 03:02:28,102] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.05, 98.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7235364836325247, 6.9112, 6.9112, 121.9260426156618, 540687.16215807, 540687.16215807, 147162.6294122075], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4081800.0000, 
sim time next is 4082400.0000, 
raw observation next is [20.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7249593283815575, 6.9112, 6.9112, 121.9260426156618, 541762.5891343155, 541762.5891343155, 147547.8764503377], 
processed observation next is [1.0, 0.2608695652173913, 0.2962962962962963, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6561991604769468, 0.0, 0.0, 0.8094621288201359, 0.19348663897654125, 0.19348663897654125, 0.28374591625064943], 
reward next is 0.7163, 
noisyNet noise sample is [array([0.41672173], dtype=float32), -0.2702955]. 
=============================================
[2019-03-24 03:02:29,223] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.8003847e-13 6.9706407e-16 3.8929020e-09 8.7192829e-11], sum to 1.0000
[2019-03-24 03:02:29,228] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9848
[2019-03-24 03:02:29,235] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2015471.17452134 W.
[2019-03-24 03:02:29,239] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 70.66666666666667, 1.0, 2.0, 0.8835317431731611, 1.0, 2.0, 0.8835317431731611, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2015471.17452134, 2015471.17452134, 379480.0636718941], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4117800.0000, 
sim time next is 4118400.0000, 
raw observation next is [29.0, 70.0, 1.0, 2.0, 0.8745474417005944, 1.0, 2.0, 0.8745474417005944, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1994953.715590351, 1994953.715590351, 375521.4403343106], 
processed observation next is [1.0, 0.6956521739130435, 0.6296296296296297, 0.7, 1.0, 1.0, 0.8506517163102314, 1.0, 1.0, 0.8506517163102314, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7124834698536968, 0.7124834698536968, 0.7221566160275203], 
reward next is 0.2778, 
noisyNet noise sample is [array([-0.5805365], dtype=float32), 0.55615526]. 
=============================================
[2019-03-24 03:02:33,436] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 8.3416784e-17 1.9520199e-16 7.0095216e-15 4.4647296e-14], sum to 1.0000
[2019-03-24 03:02:33,444] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7585
[2019-03-24 03:02:33,453] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1652536.253604423 W.
[2019-03-24 03:02:33,457] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.1, 31.0, 1.0, 2.0, 0.4767261418606364, 1.0, 2.0, 0.4767261418606364, 1.0, 2.0, 0.7598933453440049, 6.9112, 6.9112, 121.94756008, 1652536.253604423, 1652536.253604423, 332416.5087560376], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4201200.0000, 
sim time next is 4201800.0000, 
raw observation next is [34.08333333333334, 31.5, 1.0, 2.0, 0.673455901418808, 1.0, 2.0, 0.673455901418808, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1574941.193710113, 1574941.193710113, 296128.4027290742], 
processed observation next is [1.0, 0.6521739130434783, 0.8179012345679015, 0.315, 1.0, 1.0, 0.6112570254985809, 1.0, 1.0, 0.6112570254985809, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5624789977536118, 0.5624789977536118, 0.5694776975559119], 
reward next is 0.4305, 
noisyNet noise sample is [array([-0.03431579], dtype=float32), 0.2025042]. 
=============================================
[2019-03-24 03:02:45,712] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 4.1617373e-25 2.9181789e-25 1.1924574e-18 1.2311191e-23], sum to 1.0000
[2019-03-24 03:02:45,718] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2429
[2019-03-24 03:02:45,725] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.4, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7933339986548111, 6.911199999999999, 6.9112, 121.9260426156618, 589962.3460578196, 589962.34605782, 159131.8183538486], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4424400.0000, 
sim time next is 4425000.0000, 
raw observation next is [22.33333333333334, 91.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7929054445404793, 6.9112, 6.9112, 121.9260426156618, 589647.4828861657, 589647.4828861657, 159076.746517584], 
processed observation next is [0.0, 0.21739130434782608, 0.38271604938271625, 0.9150000000000001, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7411318056755991, 0.0, 0.0, 0.8094621288201359, 0.2105883867450592, 0.2105883867450592, 0.30591682022612304], 
reward next is 0.6941, 
noisyNet noise sample is [array([1.010115], dtype=float32), 0.40875068]. 
=============================================
[2019-03-24 03:02:45,738] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[60.141235]
 [60.213543]
 [60.249203]
 [60.29354 ]
 [60.33892 ]], R is [[60.1612854 ]
 [60.25365067]
 [60.34512329]
 [60.4356842 ]
 [60.52531052]].
[2019-03-24 03:02:47,067] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.5143156e-20 5.6213446e-21 1.0128767e-15 1.3381050e-18], sum to 1.0000
[2019-03-24 03:02:47,073] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3000
[2019-03-24 03:02:47,081] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 697698.9938273837 W.
[2019-03-24 03:02:47,085] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.96666666666667, 92.66666666666667, 1.0, 2.0, 0.2040695243672627, 1.0, 2.0, 0.2040695243672627, 1.0, 1.0, 0.3248853288731039, 6.911199999999999, 6.9112, 121.94756008, 697698.9938273837, 697698.9938273841, 221928.5354466613], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4497600.0000, 
sim time next is 4498200.0000, 
raw observation next is [23.95, 92.0, 1.0, 2.0, 0.2020051564409677, 1.0, 2.0, 0.2020051564409677, 1.0, 2.0, 0.3215987879026725, 6.911199999999999, 6.9112, 121.94756008, 690637.8899129847, 690637.8899129851, 221250.742553807], 
processed observation next is [0.0, 0.043478260869565216, 0.4425925925925926, 0.92, 1.0, 1.0, 0.05000613862019964, 1.0, 1.0, 0.05000613862019964, 1.0, 1.0, 0.15199848487834058, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2466563892546374, 0.24665638925463756, 0.42548219721885966], 
reward next is 0.5745, 
noisyNet noise sample is [array([-0.6831632], dtype=float32), -0.24587467]. 
=============================================
[2019-03-24 03:02:53,460] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.2368922e-20 4.6185495e-19 8.3684585e-15 6.5745571e-19], sum to 1.0000
[2019-03-24 03:02:53,467] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4219
[2019-03-24 03:02:53,471] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 99.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9216181273025515, 6.911200000000001, 6.9112, 121.9260426156618, 672276.3542064632, 672276.3542064627, 179261.3483129072], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4569000.0000, 
sim time next is 4569600.0000, 
raw observation next is [23.0, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9174181176782177, 6.9112, 6.9112, 121.9260426156618, 670466.84784311, 670466.84784311, 178461.4230074861], 
processed observation next is [0.0, 0.9130434782608695, 0.4074074074074074, 0.98, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8967726470977722, 0.0, 0.0, 0.8094621288201359, 0.23945244565825358, 0.23945244565825358, 0.34319504424516556], 
reward next is 0.6568, 
noisyNet noise sample is [array([0.84089494], dtype=float32), -0.084965944]. 
=============================================
[2019-03-24 03:02:54,103] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.1271568e-21 1.2317634e-22 2.0725856e-17 3.7449266e-19], sum to 1.0000
[2019-03-24 03:02:54,109] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1531
[2019-03-24 03:02:54,114] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.78059601574742, 6.911200000000001, 6.9112, 121.9260426156618, 581640.2062659106, 581640.2062659102, 156813.0998586145], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4579800.0000, 
sim time next is 4580400.0000, 
raw observation next is [21.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7787798980080992, 6.911199999999999, 6.9112, 121.9260426156618, 580309.507824069, 580309.5078240695, 156575.6099988146], 
processed observation next is [1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7234748725101239, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2072533956514532, 0.20725339565145337, 0.3011069423054127], 
reward next is 0.6989, 
noisyNet noise sample is [array([0.45207092], dtype=float32), 0.32336697]. 
=============================================
[2019-03-24 03:03:05,025] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 03:03:05,026] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:03:05,027] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:03:05,028] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:03:05,028] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:03:05,029] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:03:05,030] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:03:05,032] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:03:05,030] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:03:05,033] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:03:05,034] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:03:05,057] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run40
[2019-03-24 03:03:05,082] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run40
[2019-03-24 03:03:05,107] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run40
[2019-03-24 03:03:05,131] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run40
[2019-03-24 03:03:05,160] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run40
[2019-03-24 03:03:29,055] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00312541], dtype=float32), 0.2613956]
[2019-03-24 03:03:29,056] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.63333333333333, 77.33333333333334, 1.0, 2.0, 0.7367985026070452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 929138.3123281476, 929138.3123281476, 186466.5646262525]
[2019-03-24 03:03:29,056] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:03:29,059] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9999988e-01 1.3834952e-12 1.9474940e-12 7.8843065e-08 1.2974755e-10], sampled 0.5060903448126993
[2019-03-24 03:03:29,060] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 929138.3123281476 W.
[2019-03-24 03:03:34,017] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00312541], dtype=float32), 0.2613956]
[2019-03-24 03:03:34,018] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.65306289833334, 107.7517730083333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8794925310992775, 6.911200000000001, 6.9112, 121.9260426156618, 651119.9018615985, 651119.901861598, 171196.2385665169]
[2019-03-24 03:03:34,021] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:03:34,024] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 6.4115146e-18 1.5186291e-16 1.0043751e-12 2.4954063e-15], sampled 0.290746823755513
[2019-03-24 03:03:37,214] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00312541], dtype=float32), 0.2613956]
[2019-03-24 03:03:37,214] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.4, 59.0, 1.0, 2.0, 0.5787363171669254, 0.0, 2.0, 0.0, 1.0, 1.0, 0.921466524727379, 6.911199999999999, 6.9112, 121.9258408998829, 1322491.898624613, 1322491.898624613, 285641.3446774]
[2019-03-24 03:03:37,215] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:03:37,218] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9999893e-01 1.0821413e-12 4.7021658e-13 1.1320896e-06 3.1863134e-10], sampled 0.003819549580423187
[2019-03-24 03:03:37,219] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1322491.898624613 W.
[2019-03-24 03:03:55,276] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00312541], dtype=float32), 0.2613956]
[2019-03-24 03:03:55,276] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.4, 94.0, 1.0, 2.0, 0.7524015776847944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 860534.9805504632, 860534.9805504632, 186451.6835783528]
[2019-03-24 03:03:55,277] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:03:55,280] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 9.7198471e-15 4.6893963e-14 5.7593058e-10 1.2552881e-12], sampled 0.7564223472196656
[2019-03-24 03:03:55,282] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 860534.9805504632 W.
[2019-03-24 03:04:03,756] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00312541], dtype=float32), 0.2613956]
[2019-03-24 03:04:03,757] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.47509011166667, 92.63039131666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9566833665025378, 6.932313844038153, 6.9112, 121.925865454087, 725072.4247982478, 714260.2652271072, 177564.0806373575]
[2019-03-24 03:04:03,758] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:04:03,760] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.1755730e-17 8.5296350e-16 3.7313715e-12 1.2166657e-14], sampled 0.2914905737640059
[2019-03-24 03:04:03,761] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 725072.4247982478 W.
[2019-03-24 03:04:07,463] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00312541], dtype=float32), 0.2613956]
[2019-03-24 03:04:07,464] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.13372618333333, 80.15584676666667, 1.0, 2.0, 0.683272599590274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 778727.7886366702, 778727.7886366697, 173000.267447955]
[2019-03-24 03:04:07,465] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:04:07,469] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.9435216e-15 2.0583277e-14 2.9220051e-10 5.7145759e-13], sampled 0.7652176072840449
[2019-03-24 03:04:07,470] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 778727.7886366702 W.
[2019-03-24 03:04:07,691] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00312541], dtype=float32), 0.2613956]
[2019-03-24 03:04:07,693] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.68998912, 77.59223702333334, 1.0, 2.0, 0.9212002957811882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1050080.460633138, 1050080.460633138, 222272.4640410026]
[2019-03-24 03:04:07,694] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:04:07,697] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.3209301e-14 3.9966657e-14 1.4367588e-09 1.8251518e-12], sampled 0.8754151914004114
[2019-03-24 03:04:07,697] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1050080.460633138 W.
[2019-03-24 03:04:27,392] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00312541], dtype=float32), 0.2613956]
[2019-03-24 03:04:27,393] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.93333333333334, 69.66666666666667, 1.0, 2.0, 1.005418459164775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.205227195488484, 6.9112, 121.9248003315957, 1301864.864645201, 1151298.194816833, 242321.7678025345]
[2019-03-24 03:04:27,396] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:04:27,400] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9998581e-01 4.6723623e-12 1.0652569e-12 1.4198620e-05 2.0307338e-09], sampled 0.10882342030617831
[2019-03-24 03:04:27,401] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1301864.864645201 W.
[2019-03-24 03:04:40,240] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00312541], dtype=float32), 0.2613956]
[2019-03-24 03:04:40,244] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.8, 32.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5660341570856202, 6.9112, 6.9112, 121.9260426156618, 405263.2160703617, 405263.2160703617, 120642.8747476243]
[2019-03-24 03:04:40,244] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:04:40,248] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.6921485e-17 7.6668859e-16 3.4430586e-12 1.1052035e-14], sampled 0.25456239961249894
[2019-03-24 03:04:40,516] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00312541], dtype=float32), 0.2613956]
[2019-03-24 03:04:40,517] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.55410177, 74.05613941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.824065139746638, 6.911199999999999, 6.9112, 121.9260426156618, 608695.029525626, 608695.0295256265, 164684.5619460212]
[2019-03-24 03:04:40,519] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:04:40,521] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 7.2091034e-17 1.4139159e-15 5.5158196e-12 1.9336346e-14], sampled 0.5664813196396113
[2019-03-24 03:04:43,099] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 03:04:43,390] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 03:04:43,552] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 03:04:43,651] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 03:04:43,675] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 03:04:44,690] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 975000, evaluation results [975000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 03:04:46,530] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.6041579e-01 3.1796404e-08 1.2488773e-09 2.3958313e-01 1.0759197e-06], sum to 1.0000
[2019-03-24 03:04:46,535] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9211
[2019-03-24 03:04:46,541] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.26666666666667, 88.16666666666667, 1.0, 2.0, 0.5134662481604982, 1.0, 1.0, 0.5134662481604982, 1.0, 2.0, 0.8174549894997624, 6.9112, 6.9112, 121.94756008, 1756688.135047658, 1756688.135047658, 350247.6098006803], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4810200.0000, 
sim time next is 4810800.0000, 
raw observation next is [27.53333333333334, 87.33333333333334, 1.0, 2.0, 0.8101061865708274, 1.0, 2.0, 0.8101061865708274, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260425169185, 1847802.966032832, 1847802.966032832, 347949.2373149457], 
processed observation next is [1.0, 0.6956521739130435, 0.5753086419753088, 0.8733333333333334, 1.0, 1.0, 0.7739359363938422, 1.0, 1.0, 0.7739359363938422, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621281645831, 0.6599296307260114, 0.6599296307260114, 0.6691331486825879], 
reward next is 0.3309, 
noisyNet noise sample is [array([-0.4808196], dtype=float32), -0.5278379]. 
=============================================
[2019-03-24 03:04:51,112] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9441258e-04 1.1672100e-11 4.7195853e-14 9.9900562e-01 7.2313102e-09], sum to 1.0000
[2019-03-24 03:04:51,119] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9134
[2019-03-24 03:04:51,125] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 2654604.114858566 W.
[2019-03-24 03:04:51,130] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.83333333333334, 80.66666666666667, 1.0, 2.0, 0.9243318036153478, 1.0, 2.0, 0.7755305637841085, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2654604.114858566, 2654604.114858567, 494961.7141345475], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4893000.0000, 
sim time next is 4893600.0000, 
raw observation next is [30.66666666666667, 82.33333333333334, 1.0, 2.0, 0.8828672528266179, 1.0, 2.0, 0.7547982883897437, 1.0, 2.0, 0.9977734948820727, 6.911200000000003, 6.9112, 121.94756008, 2583535.820329469, 2583535.820329468, 481994.3665168728], 
processed observation next is [1.0, 0.6521739130434783, 0.6913580246913582, 0.8233333333333335, 1.0, 1.0, 0.8605562533650214, 1.0, 1.0, 0.7080932004639806, 1.0, 1.0, 0.9972168686025908, 2.6645352591003756e-16, 0.0, 0.8096049824067558, 0.9226913644033818, 0.9226913644033815, 0.9269122433016784], 
reward next is 0.0731, 
noisyNet noise sample is [array([-0.031881], dtype=float32), 1.2603974]. 
=============================================
[2019-03-24 03:04:51,385] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.8090817e-03 1.5720180e-09 3.0858059e-11 9.9419075e-01 8.9009475e-08], sum to 1.0000
[2019-03-24 03:04:51,393] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9114
[2019-03-24 03:04:51,399] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.4016405358880876, 1.0, 2.0, 0.4016405358880876, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 915583.4923511527, 915583.4923511527, 206643.6013089397], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4903200.0000, 
sim time next is 4903800.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 0.4097018370656857, 1.0, 2.0, 0.4097018370656857, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 933971.3072920672, 933971.3072920676, 208873.1355794741], 
processed observation next is [1.0, 0.782608695652174, 0.6296296296296297, 0.89, 1.0, 1.0, 0.2972640917448639, 1.0, 1.0, 0.2972640917448639, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3335611811757383, 0.3335611811757384, 0.40167910688360403], 
reward next is 0.5983, 
noisyNet noise sample is [array([0.06219276], dtype=float32), 2.0901515]. 
=============================================
[2019-03-24 03:04:51,570] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3397228e-03 1.1180451e-11 8.6917046e-14 9.9766028e-01 6.4427502e-10], sum to 1.0000
[2019-03-24 03:04:51,577] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9783
[2019-03-24 03:04:51,585] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.4192672716405669, 1.0, 2.0, 0.4192672716405669, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 955790.620458339, 955790.6204583395, 211547.878979727], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4905000.0000, 
sim time next is 4905600.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 0.4382659691498077, 1.0, 2.0, 0.4382659691498077, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 999129.5980529427, 999129.5980529427, 216954.4265786692], 
processed observation next is [1.0, 0.782608695652174, 0.6296296296296297, 0.89, 1.0, 1.0, 0.3312690108926283, 1.0, 1.0, 0.3312690108926283, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3568319993046224, 0.3568319993046224, 0.4172200511128254], 
reward next is 0.5828, 
noisyNet noise sample is [array([0.4082889], dtype=float32), 0.21005955]. 
=============================================
[2019-03-24 03:04:56,027] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4910813e-05 2.7915257e-16 7.5750616e-21 9.9998510e-01 1.3631922e-13], sum to 1.0000
[2019-03-24 03:04:56,036] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0843
[2019-03-24 03:04:56,040] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 86.5, 1.0, 2.0, 0.6606473008559691, 1.0, 2.0, 0.6606473008559691, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1506598.310007861, 1506598.310007862, 289535.8730011513], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4969800.0000, 
sim time next is 4970400.0000, 
raw observation next is [26.0, 87.33333333333333, 1.0, 2.0, 0.5650714149510173, 1.0, 2.0, 0.5650714149510173, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1288455.300622295, 1288455.300622295, 256240.4622210196], 
processed observation next is [1.0, 0.5217391304347826, 0.5185185185185185, 0.8733333333333333, 1.0, 1.0, 0.4822278749416873, 1.0, 1.0, 0.4822278749416873, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.46016260736510534, 0.46016260736510534, 0.4927701196558069], 
reward next is 0.5072, 
noisyNet noise sample is [array([-0.48030564], dtype=float32), -0.033479955]. 
=============================================
[2019-03-24 03:05:01,358] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2298972e-05 1.4356010e-21 3.7743149e-24 9.9998772e-01 2.1845956e-18], sum to 1.0000
[2019-03-24 03:05:01,365] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7887
[2019-03-24 03:05:01,370] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.3341430884985953, 1.0, 2.0, 0.3341430884985953, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 761639.2330084585, 761639.233008459, 188856.4659682175], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5043600.0000, 
sim time next is 5044200.0000, 
raw observation next is [26.33333333333334, 87.33333333333334, 1.0, 2.0, 0.3383649172684933, 1.0, 2.0, 0.3383649172684933, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 771267.2285145546, 771267.228514555, 189922.6496723739], 
processed observation next is [0.0, 0.391304347826087, 0.5308641975308644, 0.8733333333333334, 1.0, 1.0, 0.21233918722439682, 1.0, 1.0, 0.21233918722439682, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27545258161234093, 0.2754525816123411, 0.3652358647545652], 
reward next is 0.6348, 
noisyNet noise sample is [array([1.2475133], dtype=float32), -1.1300126]. 
=============================================
[2019-03-24 03:05:02,601] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1387118e-06 1.1825550e-23 2.1214529e-29 9.9999881e-01 3.1875731e-20], sum to 1.0000
[2019-03-24 03:05:02,611] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3970
[2019-03-24 03:05:02,617] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.4084675907300974, 1.0, 2.0, 0.4084675907300974, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 931155.9647937408, 931155.9647937412, 208529.2711345514], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5072400.0000, 
sim time next is 5073000.0000, 
raw observation next is [30.83333333333334, 70.83333333333334, 1.0, 2.0, 0.3879029110485162, 1.0, 2.0, 0.3879029110485162, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 884249.0088389845, 884249.0088389845, 202894.9908481929], 
processed observation next is [0.0, 0.7391304347826086, 0.6975308641975311, 0.7083333333333335, 1.0, 1.0, 0.2713129893434717, 1.0, 1.0, 0.2713129893434717, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31580321744249445, 0.31580321744249445, 0.3901826747080632], 
reward next is 0.6098, 
noisyNet noise sample is [array([-1.0400692], dtype=float32), -0.48100564]. 
=============================================
[2019-03-24 03:05:02,642] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[73.54342 ]
 [73.46391 ]
 [73.381584]
 [73.34624 ]
 [73.35315 ]], R is [[73.54863739]
 [73.41213226]
 [73.27389526]
 [73.1343689 ]
 [72.99647522]].
[2019-03-24 03:05:03,390] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.6506882e-01 8.6916431e-15 1.1652358e-17 3.4931131e-02 1.0036937e-13], sum to 1.0000
[2019-03-24 03:05:03,396] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5082
[2019-03-24 03:05:03,405] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 799964.0075151563 W.
[2019-03-24 03:05:03,408] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.28333333333333, 98.83333333333334, 1.0, 2.0, 0.3509479994226563, 1.0, 1.0, 0.3509479994226563, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 799964.0075151563, 799964.0075151568, 193137.2489292745], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5123400.0000, 
sim time next is 5124000.0000, 
raw observation next is [25.56666666666667, 97.66666666666667, 1.0, 2.0, 0.3586478785030692, 1.0, 2.0, 0.3586478785030692, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 817524.7603789673, 817524.7603789677, 195131.1703762495], 
processed observation next is [0.0, 0.30434782608695654, 0.5024691358024692, 0.9766666666666667, 1.0, 1.0, 0.23648556964651093, 1.0, 1.0, 0.23648556964651093, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.291973128706774, 0.29197312870677417, 0.3752522507235567], 
reward next is 0.6247, 
noisyNet noise sample is [array([-0.94393796], dtype=float32), -1.5232083]. 
=============================================
[2019-03-24 03:05:03,420] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[48.502346]
 [48.977707]
 [48.63476 ]
 [48.514423]
 [48.632206]], R is [[49.18905258]
 [49.32574463]
 [49.48959732]
 [48.99470139]
 [49.09941101]].
[2019-03-24 03:05:08,474] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.9134890e-01 1.8770882e-08 9.0065302e-11 6.0865104e-01 7.1350847e-08], sum to 1.0000
[2019-03-24 03:05:08,481] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8260
[2019-03-24 03:05:08,484] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.3544743974042205, 1.0, 2.0, 0.3544743974042205, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 810857.3761983442, 810857.3761983446, 194185.5474149108], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5205600.0000, 
sim time next is 5206200.0000, 
raw observation next is [23.16666666666667, 100.0, 1.0, 2.0, 0.3755473313747474, 1.0, 2.0, 0.3755473313747474, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 856380.2568257162, 856380.2568257166, 199592.6465316544], 
processed observation next is [1.0, 0.2608695652173913, 0.4135802469135804, 1.0, 1.0, 1.0, 0.2566039659223183, 1.0, 1.0, 0.2566039659223183, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3058500917234701, 0.3058500917234702, 0.38383201256087385], 
reward next is 0.6162, 
noisyNet noise sample is [array([1.2352569], dtype=float32), 0.22326522]. 
=============================================
[2019-03-24 03:05:10,254] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4055705e-04 6.4327118e-14 5.0159915e-16 9.9965942e-01 2.5434616e-11], sum to 1.0000
[2019-03-24 03:05:10,262] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3007
[2019-03-24 03:05:10,267] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.2, 98.66666666666666, 1.0, 2.0, 0.3621339021561911, 1.0, 2.0, 0.3621339021561911, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 827531.2491712257, 827531.2491712262, 196139.3672794667], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5204400.0000, 
sim time next is 5205000.0000, 
raw observation next is [23.1, 99.33333333333334, 1.0, 2.0, 0.3561664109186437, 1.0, 2.0, 0.3561664109186437, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 814348.640447709, 814348.6404477095, 194606.0761142389], 
processed observation next is [1.0, 0.21739130434782608, 0.41111111111111115, 0.9933333333333334, 1.0, 1.0, 0.23353144156981395, 1.0, 1.0, 0.23353144156981395, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29083880015989605, 0.2908388001598962, 0.37424245406584405], 
reward next is 0.6258, 
noisyNet noise sample is [array([0.3024129], dtype=float32), 1.2719916]. 
=============================================
[2019-03-24 03:05:10,288] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[38.35895 ]
 [38.41804 ]
 [38.411697]
 [38.37329 ]
 [38.584732]], R is [[38.44139862]
 [38.67979431]
 [38.91537857]
 [39.15182877]
 [39.35750198]].
[2019-03-24 03:05:12,870] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.9538928e-08 9.0824657e-20 1.2939913e-24 9.9999988e-01 6.9617605e-17], sum to 1.0000
[2019-03-24 03:05:12,877] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6656
[2019-03-24 03:05:12,881] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.5, 88.33333333333333, 1.0, 2.0, 0.2854047694313814, 1.0, 2.0, 0.2854047694313814, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 667300.9630467413, 667300.9630467418, 177799.4581387494], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5290800.0000, 
sim time next is 5291400.0000, 
raw observation next is [23.4, 88.66666666666667, 1.0, 2.0, 0.2810516846876309, 1.0, 2.0, 0.2810516846876309, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 657943.4551882119, 657943.4551882123, 176807.2813424737], 
processed observation next is [1.0, 0.21739130434782608, 0.42222222222222217, 0.8866666666666667, 1.0, 1.0, 0.14410914843765585, 1.0, 1.0, 0.14410914843765585, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2349798054243614, 0.23497980542436156, 0.3400140025816802], 
reward next is 0.6600, 
noisyNet noise sample is [array([0.84423196], dtype=float32), 0.19658013]. 
=============================================
[2019-03-24 03:05:14,608] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.8454480e-04 5.4461261e-22 1.2075218e-26 9.9911541e-01 1.4584185e-17], sum to 1.0000
[2019-03-24 03:05:14,616] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7113
[2019-03-24 03:05:14,622] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.6, 88.0, 1.0, 2.0, 0.2886909132159867, 1.0, 2.0, 0.2886909132159867, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 674268.0760706217, 674268.0760706217, 178548.4768783957], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5290200.0000, 
sim time next is 5290800.0000, 
raw observation next is [23.5, 88.33333333333333, 1.0, 2.0, 0.2854047694313814, 1.0, 2.0, 0.2854047694313814, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 667300.9630467413, 667300.9630467418, 177799.4581387494], 
processed observation next is [1.0, 0.21739130434782608, 0.42592592592592593, 0.8833333333333333, 1.0, 1.0, 0.14929139218021592, 1.0, 1.0, 0.14929139218021592, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23832177251669334, 0.2383217725166935, 0.3419220348822104], 
reward next is 0.6581, 
noisyNet noise sample is [array([0.41910788], dtype=float32), -1.6786131]. 
=============================================
[2019-03-24 03:05:16,770] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.0095699e-03 2.2588815e-17 2.1664462e-23 9.9099040e-01 9.5408148e-15], sum to 1.0000
[2019-03-24 03:05:16,778] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2286
[2019-03-24 03:05:16,783] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.06666666666667, 80.33333333333334, 1.0, 2.0, 0.3085802328440104, 1.0, 2.0, 0.3085802328440104, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 703345.0271769385, 703345.027176939, 182532.3645130256], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5355600.0000, 
sim time next is 5356200.0000, 
raw observation next is [25.98333333333333, 80.66666666666666, 1.0, 2.0, 0.3076103186799872, 1.0, 2.0, 0.3076103186799872, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 701133.2967930906, 701133.2967930911, 182296.8821666068], 
processed observation next is [1.0, 1.0, 0.5179012345679012, 0.8066666666666665, 1.0, 1.0, 0.17572656985712765, 1.0, 1.0, 0.17572656985712765, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25040474885467523, 0.2504047488546754, 0.35057092724347466], 
reward next is 0.6494, 
noisyNet noise sample is [array([-0.00429878], dtype=float32), 1.3040692]. 
=============================================
[2019-03-24 03:05:18,166] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9427052e-06 1.4176302e-20 1.1163776e-24 9.9999011e-01 3.9842463e-16], sum to 1.0000
[2019-03-24 03:05:18,175] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7178
[2019-03-24 03:05:18,182] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.45, 83.5, 1.0, 2.0, 0.6498297982499027, 1.0, 2.0, 0.6498297982499027, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1481905.25476884, 1481905.25476884, 285608.561402698], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5391000.0000, 
sim time next is 5391600.0000, 
raw observation next is [26.63333333333333, 82.66666666666667, 1.0, 2.0, 0.6325929809794458, 1.0, 2.0, 0.6325929809794458, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1442560.509417825, 1442560.509417826, 279434.5255584315], 
processed observation next is [1.0, 0.391304347826087, 0.5419753086419752, 0.8266666666666667, 1.0, 1.0, 0.5626106916421973, 1.0, 1.0, 0.5626106916421973, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5152001819349374, 0.5152001819349379, 0.5373740876123683], 
reward next is 0.4626, 
noisyNet noise sample is [array([0.3851027], dtype=float32), -0.005559696]. 
=============================================
[2019-03-24 03:05:18,638] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.7518067e-02 4.3480348e-18 3.5254280e-21 9.5248187e-01 1.4834890e-15], sum to 1.0000
[2019-03-24 03:05:18,649] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9928
[2019-03-24 03:05:18,654] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.56666666666667, 91.0, 1.0, 2.0, 0.372691545061175, 1.0, 2.0, 0.372691545061175, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 849554.5277904281, 849554.5277904281, 198818.9344171535], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5381400.0000, 
sim time next is 5382000.0000, 
raw observation next is [24.6, 91.0, 1.0, 2.0, 0.3618764685814599, 1.0, 2.0, 0.3618764685814599, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 824888.1739753722, 824888.1739753727, 195971.6786702698], 
processed observation next is [1.0, 0.30434782608695654, 0.46666666666666673, 0.91, 1.0, 1.0, 0.24032912926364272, 1.0, 1.0, 0.24032912926364272, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2946029192769187, 0.29460291927691884, 0.3768686128274419], 
reward next is 0.6231, 
noisyNet noise sample is [array([0.26751304], dtype=float32), 0.4646673]. 
=============================================
[2019-03-24 03:05:18,681] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[55.792202]
 [55.818714]
 [55.88207 ]
 [55.9832  ]
 [55.807858]], R is [[55.87390518]
 [55.93282318]
 [55.98984146]
 [56.05143738]
 [56.12902451]].
[2019-03-24 03:05:19,671] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2250181e-02 1.4792741e-15 4.9370299e-21 9.8774987e-01 6.1314472e-14], sum to 1.0000
[2019-03-24 03:05:19,679] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9445
[2019-03-24 03:05:19,684] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.16666666666667, 83.16666666666667, 1.0, 2.0, 0.8186241632679652, 1.0, 2.0, 0.8186241632679652, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1867252.262114341, 1867252.262114341, 351511.4216726196], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5411400.0000, 
sim time next is 5412000.0000, 
raw observation next is [28.33333333333334, 82.33333333333334, 1.0, 2.0, 0.8552532162937503, 1.0, 2.0, 0.8552532162937503, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1950893.06539179, 1950893.06539179, 367116.0107351269], 
processed observation next is [1.0, 0.6521739130434783, 0.6049382716049385, 0.8233333333333335, 1.0, 1.0, 0.8276824003497028, 1.0, 1.0, 0.8276824003497028, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6967475233542106, 0.6967475233542106, 0.7059923283367825], 
reward next is 0.2940, 
noisyNet noise sample is [array([-1.2075455], dtype=float32), 0.24750106]. 
=============================================
[2019-03-24 03:05:19,704] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[48.322495]
 [48.152348]
 [47.891666]
 [47.75607 ]
 [47.58485 ]], R is [[48.22742081]
 [48.06916428]
 [47.91379929]
 [47.74736023]
 [47.58692932]].
[2019-03-24 03:05:21,893] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2758540e-02 1.0916256e-18 1.2253101e-22 9.7724140e-01 1.3435654e-14], sum to 1.0000
[2019-03-24 03:05:21,907] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6903
[2019-03-24 03:05:21,915] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 92.5, 1.0, 2.0, 0.3687997659703711, 1.0, 2.0, 0.3687997659703711, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 840678.3086473894, 840678.3086473899, 197791.5839188067], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5448600.0000, 
sim time next is 5449200.0000, 
raw observation next is [26.43333333333333, 92.66666666666667, 1.0, 2.0, 0.3672740406199094, 1.0, 2.0, 0.3672740406199094, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 837198.5213613972, 837198.5213613972, 197389.4660411775], 
processed observation next is [1.0, 0.043478260869565216, 0.5345679012345678, 0.9266666666666667, 1.0, 1.0, 0.24675481026179694, 1.0, 1.0, 0.24675481026179694, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2989994719147847, 0.2989994719147847, 0.37959512700226444], 
reward next is 0.6204, 
noisyNet noise sample is [array([1.5933452], dtype=float32), 1.49824]. 
=============================================
[2019-03-24 03:05:27,576] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 7.0714399e-19 9.4152329e-22 5.1016812e-11 2.1371195e-18], sum to 1.0000
[2019-03-24 03:05:27,582] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6345
[2019-03-24 03:05:27,587] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 822831.1655460024 W.
[2019-03-24 03:05:27,591] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.4, 93.0, 1.0, 2.0, 0.3609745480347336, 1.0, 2.0, 0.3609745480347336, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 822831.1655460024, 822831.1655460029, 195736.9468046394], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5544000.0000, 
sim time next is 5544600.0000, 
raw observation next is [25.38333333333333, 93.0, 1.0, 2.0, 0.4180041823176143, 1.0, 2.0, 0.4180041823176143, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 952909.4045742936, 952909.4045742941, 211189.935802832], 
processed observation next is [1.0, 0.17391304347826086, 0.49567901234567885, 0.93, 1.0, 1.0, 0.30714783609239804, 1.0, 1.0, 0.30714783609239804, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.340324787347962, 0.3403247873479622, 0.4061344919285231], 
reward next is 0.5939, 
noisyNet noise sample is [array([1.1509303], dtype=float32), -0.45249483]. 
=============================================
[2019-03-24 03:05:27,797] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999881e-01 5.5817898e-12 2.5188567e-13 1.1763518e-06 2.1501511e-11], sum to 1.0000
[2019-03-24 03:05:27,805] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7959
[2019-03-24 03:05:27,813] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1479518.572893833 W.
[2019-03-24 03:05:27,816] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.9, 83.0, 1.0, 2.0, 0.6487842251670757, 1.0, 2.0, 0.6487842251670757, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1479518.572893833, 1479518.572893834, 285230.5983782322], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5562000.0000, 
sim time next is 5562600.0000, 
raw observation next is [25.96666666666667, 82.66666666666667, 1.0, 2.0, 0.772577143019352, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1595641.487128913, 1595641.487128913, 330846.8464740322], 
processed observation next is [1.0, 0.391304347826087, 0.517283950617284, 0.8266666666666667, 1.0, 1.0, 0.7292585035944666, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.5698719596888975, 0.5698719596888975, 0.636243935526985], 
reward next is 0.3638, 
noisyNet noise sample is [array([-0.65141773], dtype=float32), -0.6777411]. 
=============================================
[2019-03-24 03:05:36,005] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 03:05:36,007] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:05:36,007] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:05:36,008] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:05:36,011] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:05:36,013] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:05:36,014] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:05:36,024] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run41
[2019-03-24 03:05:36,046] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:05:36,048] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:05:36,051] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run41
[2019-03-24 03:05:36,073] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:05:36,075] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run41
[2019-03-24 03:05:36,076] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:05:36,102] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run41
[2019-03-24 03:05:36,103] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run41
[2019-03-24 03:05:41,817] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00474075], dtype=float32), 0.26313195]
[2019-03-24 03:05:41,818] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.35, 24.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5980679003638174, 6.911200000000001, 6.9112, 121.9260426156618, 439795.2922707893, 439795.2922707889, 127828.6079012723]
[2019-03-24 03:05:41,819] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:05:41,823] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.6488052e-29 4.4403224e-29 5.9974391e-22 8.9354483e-28], sampled 0.5541629476513723
[2019-03-24 03:06:02,876] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00474075], dtype=float32), 0.26313195]
[2019-03-24 03:06:02,877] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.0, 95.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6005897442627828, 6.911200000000001, 6.9112, 121.9260426156618, 446374.3297372902, 446374.3297372898, 130871.1130521443]
[2019-03-24 03:06:02,877] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:06:02,882] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.5154717e-28 1.9471367e-28 1.7309932e-21 3.6474452e-27], sampled 0.3148217105715444
[2019-03-24 03:06:22,995] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00474075], dtype=float32), 0.26313195]
[2019-03-24 03:06:22,997] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.95, 86.5, 1.0, 2.0, 0.9152495019419161, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1758492.156499495, 1758492.156499495, 360282.1080677927]
[2019-03-24 03:06:22,998] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:06:23,000] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.2927650e-21 8.4679132e-22 3.1248213e-16 9.5168866e-21], sampled 0.11890395103882268
[2019-03-24 03:06:23,001] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1758492.156499495 W.
[2019-03-24 03:06:25,488] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00474075], dtype=float32), 0.26313195]
[2019-03-24 03:06:25,489] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.456870505, 100.145096715, 1.0, 2.0, 0.8499710156909176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 968834.5468653396, 968834.5468653392, 206500.7127184933]
[2019-03-24 03:06:25,489] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:06:25,494] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.6280323e-25 1.9164623e-25 3.2482168e-19 2.6014406e-24], sampled 0.9821530002489391
[2019-03-24 03:06:25,495] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 968834.5468653396 W.
[2019-03-24 03:06:51,790] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00474075], dtype=float32), 0.26313195]
[2019-03-24 03:06:51,790] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.33333333333334, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7464959465190777, 6.9112, 6.9112, 121.9260426156618, 557028.121884207, 557028.121884207, 151999.9275972199]
[2019-03-24 03:06:51,791] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:06:51,793] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 7.9830506e-29 1.0846878e-28 1.0901049e-21 2.0878666e-27], sampled 0.42160990142514754
[2019-03-24 03:07:01,030] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00474075], dtype=float32), 0.26313195]
[2019-03-24 03:07:01,031] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.25, 62.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7096876053874992, 6.9112, 6.9112, 121.9260426156618, 530333.20189525, 530333.20189525, 146125.0715145734]
[2019-03-24 03:07:01,032] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:07:01,037] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 5.4794699e-29 6.3573148e-29 8.1644776e-22 1.2585149e-27], sampled 0.13077584987441793
[2019-03-24 03:07:14,764] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 03:07:14,948] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 03:07:15,215] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 03:07:15,216] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 03:07:15,225] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 03:07:16,242] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1000000, evaluation results [1000000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 03:07:17,966] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.4501405e-29 4.1886229e-32 2.5301321e-24 1.7404953e-28], sum to 1.0000
[2019-03-24 03:07:17,971] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4550
[2019-03-24 03:07:17,974] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.3, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7766159831125975, 6.911199999999999, 6.9112, 121.9260426156618, 578769.4928491709, 578769.4928491714, 156256.8353515546], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5716800.0000, 
sim time next is 5717400.0000, 
raw observation next is [21.25, 96.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7713304480815941, 6.911199999999999, 6.9112, 121.9260426156618, 575038.6463976405, 575038.6463976409, 155446.9595731638], 
processed observation next is [0.0, 0.17391304347826086, 0.3425925925925926, 0.9683333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7141630601019927, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20537094514201445, 0.20537094514201462, 0.2989364607176227], 
reward next is 0.7011, 
noisyNet noise sample is [array([-1.3544911], dtype=float32), 1.1222862]. 
=============================================
[2019-03-24 03:07:20,264] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 6.3761470e-26 4.3029081e-27 4.0339853e-18 4.8621706e-24], sum to 1.0000
[2019-03-24 03:07:20,269] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6014
[2019-03-24 03:07:20,273] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.63333333333333, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7547642627320285, 6.9112, 6.9112, 121.9260426156618, 563491.4813876618, 563491.4813876618, 152598.7830535196], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5802000.0000, 
sim time next is 5802600.0000, 
raw observation next is [21.56666666666667, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7486853011604744, 6.911200000000001, 6.9112, 121.9260426156618, 558960.1968251583, 558960.1968251579, 151876.8220215128], 
processed observation next is [1.0, 0.13043478260869565, 0.35432098765432113, 0.915, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.685856626450593, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19962864172327083, 0.19962864172327066, 0.29207081157983233], 
reward next is 0.7079, 
noisyNet noise sample is [array([-2.474697], dtype=float32), -1.2222549]. 
=============================================
[2019-03-24 03:07:31,319] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 4.8243708e-31 1.2239643e-30 9.7067550e-25 3.7555941e-29], sum to 1.0000
[2019-03-24 03:07:31,367] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6106
[2019-03-24 03:07:31,373] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.6, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7407571311776342, 6.9112, 6.9112, 121.9260426156618, 553105.8715461107, 553105.8715461107, 150857.0749609627], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5962800.0000, 
sim time next is 5963400.0000, 
raw observation next is [22.6, 82.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7358977833524565, 6.9112, 6.9112, 121.9260426156618, 549577.7700985565, 549577.7700985565, 150128.85739761], 
processed observation next is [1.0, 0.0, 0.39259259259259266, 0.825, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6698722291905707, 0.0, 0.0, 0.8094621288201359, 0.19627777503519875, 0.19627777503519875, 0.28870934114925], 
reward next is 0.7113, 
noisyNet noise sample is [array([0.00286157], dtype=float32), 0.40395045]. 
=============================================
[2019-03-24 03:07:31,575] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.00000000e+00 3.75943952e-27 1.42933026e-27 4.82181724e-22
 1.00683835e-26], sum to 1.0000
[2019-03-24 03:07:31,584] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5335
[2019-03-24 03:07:31,588] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.53333333333333, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.700746010314613, 6.9112, 6.9112, 121.9260426156618, 523661.1529169891, 523661.1529169891, 144827.7974240418], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5967600.0000, 
sim time next is 5968200.0000, 
raw observation next is [22.51666666666667, 78.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.696883113843699, 6.911199999999999, 6.9112, 121.9260426156618, 520758.8166230709, 520758.8166230714, 144187.6605325645], 
processed observation next is [1.0, 0.043478260869565216, 0.3895061728395063, 0.785, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6211038923046238, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18598529165109676, 0.18598529165109692, 0.27728396256262405], 
reward next is 0.7227, 
noisyNet noise sample is [array([0.15492918], dtype=float32), -0.23126698]. 
=============================================
[2019-03-24 03:07:49,306] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.7477624e-32 6.8406608e-33 6.5468604e-24 4.1261611e-29], sum to 1.0000
[2019-03-24 03:07:49,314] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3562
[2019-03-24 03:07:49,317] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.28333333333333, 88.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9172334198008038, 6.9112, 6.9112, 121.9260426156618, 670749.9509127312, 670749.9509127312, 178355.1753846481], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6315000.0000, 
sim time next is 6315600.0000, 
raw observation next is [24.26666666666667, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9151920428312048, 6.9112, 6.9112, 121.9260426156618, 669417.758575858, 669417.758575858, 178048.7443494075], 
processed observation next is [0.0, 0.08695652173913043, 0.4543209876543211, 0.88, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8939900535390061, 0.0, 0.0, 0.8094621288201359, 0.23907777091994928, 0.23907777091994928, 0.34240143144116825], 
reward next is 0.6576, 
noisyNet noise sample is [array([-0.38127482], dtype=float32), -0.9709689]. 
=============================================
[2019-03-24 03:07:50,494] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 8.3004197e-23 9.7630155e-25 1.7531181e-18 3.0505514e-22], sum to 1.0000
[2019-03-24 03:07:50,503] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5840
[2019-03-24 03:07:50,509] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.2, 87.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8970297373435692, 6.911200000000001, 6.9112, 121.9260426156618, 657654.2757354273, 657654.2757354268, 175304.9430691881], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6327000.0000, 
sim time next is 6327600.0000, 
raw observation next is [24.26666666666667, 87.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.899866273219458, 6.911200000000001, 6.9112, 121.9260426156618, 659315.7648712201, 659315.7648712196, 175771.3658995793], 
processed observation next is [0.0, 0.21739130434782608, 0.4543209876543211, 0.8733333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8748328415243225, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23546991602543574, 0.23546991602543557, 0.338021857499191], 
reward next is 0.6620, 
noisyNet noise sample is [array([-0.6909098], dtype=float32), 0.04720919]. 
=============================================
[2019-03-24 03:07:56,146] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.1881790e-05 4.5407719e-14 2.0225241e-15 9.9992812e-01 5.6651846e-11], sum to 1.0000
[2019-03-24 03:07:56,153] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3235
[2019-03-24 03:07:56,161] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.93333333333333, 92.0, 1.0, 2.0, 0.4044903985347226, 1.0, 2.0, 0.4044903985347226, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 922083.9740201008, 922083.9740201012, 207425.8019756007], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6416400.0000, 
sim time next is 6417000.0000, 
raw observation next is [24.95, 92.0, 1.0, 2.0, 0.412314396243708, 1.0, 2.0, 0.412314396243708, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 939930.6452137652, 939930.6452137647, 209597.1195127164], 
processed observation next is [1.0, 0.2608695652173913, 0.47962962962962963, 0.92, 1.0, 1.0, 0.30037428124250953, 1.0, 1.0, 0.30037428124250953, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3356895161477733, 0.33568951614777315, 0.40307138367830075], 
reward next is 0.5969, 
noisyNet noise sample is [array([-0.34862748], dtype=float32), 0.8784018]. 
=============================================
[2019-03-24 03:07:56,178] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[32.780464]
 [32.954853]
 [33.559807]
 [33.418102]
 [33.678326]], R is [[32.91648483]
 [33.18842316]
 [33.46411514]
 [33.73389816]
 [33.99710464]].
[2019-03-24 03:07:59,338] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6654209e-07 1.7248504e-20 1.8825388e-23 9.9999976e-01 7.9042887e-15], sum to 1.0000
[2019-03-24 03:07:59,350] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6248
[2019-03-24 03:07:59,358] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.3, 86.5, 1.0, 2.0, 0.4129199262486338, 1.0, 2.0, 0.4129199262486338, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 941311.8867313592, 941311.8867313592, 209766.5537060167], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6499800.0000, 
sim time next is 6500400.0000, 
raw observation next is [26.3, 86.66666666666667, 1.0, 2.0, 0.4027890323245532, 1.0, 2.0, 0.4027890323245532, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 918203.1839134406, 918203.183913441, 206956.9927503764], 
processed observation next is [1.0, 0.21739130434782608, 0.5296296296296297, 0.8666666666666667, 1.0, 1.0, 0.2890345622911348, 1.0, 1.0, 0.2890345622911348, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3279297085405145, 0.3279297085405147, 0.3979942168276469], 
reward next is 0.6020, 
noisyNet noise sample is [array([3.3429692], dtype=float32), 0.41983655]. 
=============================================
[2019-03-24 03:08:03,814] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.6706069e-09 3.7130864e-29 3.6374094e-29 1.0000000e+00 4.3339240e-21], sum to 1.0000
[2019-03-24 03:08:03,823] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2918
[2019-03-24 03:08:03,827] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.46666666666667, 84.0, 1.0, 2.0, 0.3382111477427079, 1.0, 2.0, 0.3382111477427079, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 770916.5508003717, 770916.5508003721, 189883.4108517964], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6558000.0000, 
sim time next is 6558600.0000, 
raw observation next is [26.43333333333333, 83.5, 1.0, 2.0, 0.3358373817865905, 1.0, 2.0, 0.3358373817865905, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 765503.1004737375, 765503.1004737379, 189283.2752469242], 
processed observation next is [1.0, 0.9130434782608695, 0.5345679012345678, 0.835, 1.0, 1.0, 0.20933021641260774, 1.0, 1.0, 0.20933021641260774, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2733939644549062, 0.2733939644549064, 0.3640062985517773], 
reward next is 0.6360, 
noisyNet noise sample is [array([0.21825539], dtype=float32), -0.8219429]. 
=============================================
[2019-03-24 03:08:07,386] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 03:08:07,390] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:08:07,391] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:08:07,392] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:08:07,393] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:08:07,393] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:08:07,394] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:08:07,395] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:08:07,396] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:08:07,397] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:08:07,398] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:08:07,414] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run42
[2019-03-24 03:08:07,414] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run42
[2019-03-24 03:08:07,464] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run42
[2019-03-24 03:08:07,465] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run42
[2019-03-24 03:08:07,511] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run42
[2019-03-24 03:08:15,461] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00424274], dtype=float32), 0.26547]
[2019-03-24 03:08:15,463] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [15.7, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3946656239180415, 6.9112, 6.9112, 121.9260426156618, 281781.2612793219, 281781.2612793219, 91090.20444319617]
[2019-03-24 03:08:15,463] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:08:15,465] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9999774e-01 2.5257695e-15 6.7152809e-16 2.2161871e-06 6.9170093e-13], sampled 0.08107915278650424
[2019-03-24 03:08:29,626] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00424274], dtype=float32), 0.26547]
[2019-03-24 03:08:29,627] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.63333333333333, 76.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7691718185223272, 6.9112, 6.9112, 121.9260426156618, 574141.7462042167, 574141.7462042167, 154444.2083453857]
[2019-03-24 03:08:29,628] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:08:29,630] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9991357e-01 8.4463313e-17 3.8741562e-18 8.6378473e-05 1.8506239e-13], sampled 0.6418075852518698
[2019-03-24 03:08:33,072] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00424274], dtype=float32), 0.26547]
[2019-03-24 03:08:33,073] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.85160210333333, 77.52392858333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6673878409419735, 6.911199999999999, 6.9112, 121.9260426156618, 498663.3826820865, 498663.382682087, 140732.9317715095]
[2019-03-24 03:08:33,074] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:08:33,076] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9996006e-01 2.5119533e-15 2.5356257e-16 3.9918010e-05 1.7268463e-12], sampled 0.2404937486885702
[2019-03-24 03:08:59,886] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00424274], dtype=float32), 0.26547]
[2019-03-24 03:08:59,887] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.566392465, 73.97500983333333, 1.0, 2.0, 0.2531806771268801, 1.0, 2.0, 0.2531806771268801, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 601073.5529380975, 601073.552938098, 170738.8432190642]
[2019-03-24 03:08:59,887] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:08:59,890] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.83504222e-02 2.25615968e-19 2.55406453e-22 9.71649528e-01
 1.02827725e-14], sampled 0.24539444590129889
[2019-03-24 03:09:12,222] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00424274], dtype=float32), 0.26547]
[2019-03-24 03:09:12,223] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.5, 83.0, 1.0, 2.0, 0.3262325621821257, 1.0, 1.0, 0.3262325621821257, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 743599.3878536073, 743599.3878536078, 186875.2899640273]
[2019-03-24 03:09:12,224] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:09:12,227] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.9686459e-01 1.4079260e-14 1.0945432e-16 6.0313547e-01 4.4109952e-11], sampled 0.2847028587712701
[2019-03-24 03:09:12,228] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 743599.3878536073 W.
[2019-03-24 03:09:31,134] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00424274], dtype=float32), 0.26547]
[2019-03-24 03:09:31,135] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.7, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.665088062416642, 6.911200000000001, 6.9112, 121.9260426156618, 496854.840986979, 496854.8409869785, 140174.5155957551]
[2019-03-24 03:09:31,136] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:09:31,142] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9999368e-01 3.4375178e-16 4.5028884e-17 6.3494963e-06 2.4024204e-13], sampled 0.2720955550583697
[2019-03-24 03:09:38,629] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00424274], dtype=float32), 0.26547]
[2019-03-24 03:09:38,630] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.08333333333334, 20.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6185562973291295, 6.911200000000001, 6.9112, 121.9260426156618, 441686.0196846836, 441686.0196846832, 123189.511895691]
[2019-03-24 03:09:38,635] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:09:38,637] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9999666e-01 2.1824613e-15 4.9230550e-16 3.3722276e-06 7.1730897e-13], sampled 0.5913444449543346
[2019-03-24 03:09:45,557] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8428.2724 2346404649.5509 136.0000
[2019-03-24 03:09:46,054] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8527.4890 2312243306.2188 178.0000
[2019-03-24 03:09:46,082] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8464.1952 2285340131.4550 128.0000
[2019-03-24 03:09:46,083] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8022.6811 2533906153.4142 176.0000
[2019-03-24 03:09:46,277] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8585.6268 2255145491.7061 176.0000
[2019-03-24 03:09:47,292] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1025000, evaluation results [1025000.0, 8022.681057829099, 2533906153.4142327, 176.0, 8464.195228631695, 2285340131.4549537, 128.0, 8585.626806940127, 2255145491.706084, 176.0, 8428.272426484438, 2346404649.5508966, 136.0, 8527.488992344257, 2312243306.2188225, 178.0]
[2019-03-24 03:09:58,828] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 4.2053235e-31 1.8370637e-32 4.7301112e-20 2.7930671e-25], sum to 1.0000
[2019-03-24 03:09:58,832] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8912
[2019-03-24 03:09:58,835] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.4, 49.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7789095950266052, 6.911199999999999, 6.9112, 121.9260426156618, 578912.4971410721, 578912.4971410725, 157537.6639957305], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6870000.0000, 
sim time next is 6870600.0000, 
raw observation next is [29.55, 49.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7875626416027892, 6.9112, 6.9112, 121.9260426156618, 584910.2742605347, 584910.2742605347, 158819.2653879251], 
processed observation next is [0.0, 0.5217391304347826, 0.65, 0.495, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7344533020034866, 0.0, 0.0, 0.8094621288201359, 0.20889652652161952, 0.20889652652161952, 0.30542166420754824], 
reward next is 0.6946, 
noisyNet noise sample is [array([0.5178675], dtype=float32), 2.7943594]. 
=============================================
[2019-03-24 03:10:01,264] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.4548595e-26 1.0610414e-28 1.9019642e-15 8.6703355e-24], sum to 1.0000
[2019-03-24 03:10:01,271] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3587
[2019-03-24 03:10:01,278] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.05, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6826263221173653, 6.9112, 6.9112, 121.9260426156618, 509972.4726175907, 509972.4726175907, 142064.6625446494], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6916200.0000, 
sim time next is 6916800.0000, 
raw observation next is [23.0, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6832689488271932, 6.9112, 6.9112, 121.9260426156618, 510471.8530456896, 510471.8530456896, 142192.8267659287], 
processed observation next is [0.0, 0.043478260869565216, 0.4074074074074074, 0.74, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6040861860339916, 0.0, 0.0, 0.8094621288201359, 0.18231137608774628, 0.18231137608774628, 0.27344774378063214], 
reward next is 0.7266, 
noisyNet noise sample is [array([0.37914643], dtype=float32), 0.5568886]. 
=============================================
[2019-03-24 03:10:01,375] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 4.5923129e-37 1.1325881e-35 7.5471959e-21 4.5385281e-32], sum to 1.0000
[2019-03-24 03:10:01,383] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2925
[2019-03-24 03:10:01,395] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.9, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6872723388018621, 6.9112, 6.9112, 121.9260426156618, 513497.7399163669, 513497.7399163669, 142739.0858061071], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6918000.0000, 
sim time next is 6918600.0000, 
raw observation next is [22.85, 75.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6883953704568957, 6.911199999999999, 6.9112, 121.9260426156618, 514351.767464844, 514351.7674648445, 142917.1176942664], 
processed observation next is [0.0, 0.043478260869565216, 0.4018518518518519, 0.755, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6104942130711196, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18369705980887285, 0.18369705980887305, 0.2748406109505123], 
reward next is 0.7252, 
noisyNet noise sample is [array([-1.6207951], dtype=float32), -0.57051295]. 
=============================================
[2019-03-24 03:10:02,068] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 4.1782044e-31 1.0010457e-30 1.6138394e-20 1.0824805e-28], sum to 1.0000
[2019-03-24 03:10:02,082] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5141
[2019-03-24 03:10:02,089] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.4, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7118995152564724, 6.9112, 6.9112, 121.9260426156618, 531971.3705828723, 531971.3705828723, 146490.3563729688], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6901200.0000, 
sim time next is 6901800.0000, 
raw observation next is [25.25, 62.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7096876053874992, 6.9112, 6.9112, 121.9260426156618, 530333.20189525, 530333.20189525, 146125.0715145734], 
processed observation next is [0.0, 0.9130434782608695, 0.49074074074074076, 0.625, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.637109506734374, 0.0, 0.0, 0.8094621288201359, 0.1894047149625893, 0.1894047149625893, 0.2810097529126412], 
reward next is 0.7190, 
noisyNet noise sample is [array([-1.807428], dtype=float32), -0.35021797]. 
=============================================
[2019-03-24 03:10:04,262] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.3095334e-33 1.3011126e-34 3.6448673e-22 1.1207968e-31], sum to 1.0000
[2019-03-24 03:10:04,270] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4757
[2019-03-24 03:10:04,277] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 49.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8987876723245237, 6.911199999999999, 6.9112, 121.9260426156618, 657542.2444355449, 657542.2444355454, 175831.6988628607], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6969000.0000, 
sim time next is 6969600.0000, 
raw observation next is [31.0, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8907776880502863, 6.911200000000001, 6.9112, 121.9260426156618, 652648.6042078888, 652648.6042078884, 174570.5184991144], 
processed observation next is [0.0, 0.6956521739130435, 0.7037037037037037, 0.49, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8634721100628578, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23308878721710316, 0.233088787217103, 0.33571253557522], 
reward next is 0.6643, 
noisyNet noise sample is [array([-2.3260665], dtype=float32), -0.37379873]. 
=============================================
[2019-03-24 03:10:04,785] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 5.2902560e-38 0.0000000e+00 1.6739069e-21 2.0688166e-33], sum to 1.0000
[2019-03-24 03:10:04,793] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2902
[2019-03-24 03:10:04,799] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.03333333333334, 49.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.778690445634959, 6.911200000000001, 6.9112, 121.9260426156618, 579745.1660463713, 579745.1660463709, 156922.4000704287], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6978000.0000, 
sim time next is 6978600.0000, 
raw observation next is [28.75, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7757374224286613, 6.911199999999999, 6.9112, 121.9260426156618, 577835.0687358053, 577835.0687358058, 156363.4908534303], 
processed observation next is [0.0, 0.782608695652174, 0.6203703703703703, 0.505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7196717780358266, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20636966740564477, 0.20636966740564494, 0.30069902087198136], 
reward next is 0.6993, 
noisyNet noise sample is [array([1.3442473], dtype=float32), 0.18395688]. 
=============================================
[2019-03-24 03:10:16,709] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 3.9068817e-30 8.2979835e-30 5.7709026e-19 2.9984986e-27], sum to 1.0000
[2019-03-24 03:10:16,719] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6209
[2019-03-24 03:10:16,722] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.78333333333333, 94.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7360965225537508, 6.9112, 6.9112, 121.9260426156618, 549211.2350413629, 549211.2350413629, 146581.1839086839], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7179000.0000, 
sim time next is 7179600.0000, 
raw observation next is [19.76666666666667, 94.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6872069977865966, 6.911199999999999, 6.9112, 121.9260426156618, 512650.2314944922, 512650.2314944926, 141228.2136394888], 
processed observation next is [1.0, 0.08695652173913043, 0.2876543209876544, 0.9466666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6090087472332456, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18308936839089007, 0.1830893683908902, 0.27159271853747846], 
reward next is 0.7284, 
noisyNet noise sample is [array([-0.43757913], dtype=float32), 0.64106214]. 
=============================================
[2019-03-24 03:10:20,690] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 4.9286044e-35 8.9550281e-37 2.8899878e-23 2.3849126e-32], sum to 1.0000
[2019-03-24 03:10:20,698] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0513
[2019-03-24 03:10:20,704] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.5, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6602666962045969, 6.9112, 6.9112, 121.9260426156618, 491725.6265626905, 491725.6265626905, 137534.2847997877], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7268400.0000, 
sim time next is 7269000.0000, 
raw observation next is [20.48333333333333, 86.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.659655850799578, 6.911200000000002, 6.9112, 121.9260426156618, 491320.6875995891, 491320.6875995882, 137520.0435283354], 
processed observation next is [1.0, 0.13043478260869565, 0.31419753086419744, 0.8633333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5745698134994724, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.1754716741427104, 0.17547167414271006, 0.2644616221698758], 
reward next is 0.7355, 
noisyNet noise sample is [array([0.61931896], dtype=float32), -0.14010389]. 
=============================================
[2019-03-24 03:10:20,714] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.070015]
 [72.243904]
 [72.28182 ]
 [72.44113 ]
 [72.59467 ]], R is [[71.9651413 ]
 [71.98100281]
 [71.99682617]
 [72.01126862]
 [72.02400208]].
[2019-03-24 03:10:22,409] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.9173413e-31 1.5464385e-31 9.4759013e-24 4.7163444e-28], sum to 1.0000
[2019-03-24 03:10:22,418] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3992
[2019-03-24 03:10:22,433] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.63333333333333, 84.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6214305590896432, 6.911200000000001, 6.9112, 121.9260426156618, 462693.5316151819, 462693.5316151814, 133565.1984820974], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7263600.0000, 
sim time next is 7264200.0000, 
raw observation next is [20.61666666666667, 84.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6224193459329661, 6.911199999999999, 6.9112, 121.9260426156618, 463442.769738181, 463442.7697381815, 133673.8978624782], 
processed observation next is [1.0, 0.043478260869565216, 0.319135802469136, 0.8483333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5280241824162076, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16551527490649323, 0.1655152749064934, 0.2570651881970734], 
reward next is 0.7429, 
noisyNet noise sample is [array([-0.31367052], dtype=float32), 0.5238166]. 
=============================================
[2019-03-24 03:10:27,619] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.4286063e-26 8.6522451e-28 1.5903886e-14 1.9340925e-21], sum to 1.0000
[2019-03-24 03:10:27,627] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9795
[2019-03-24 03:10:27,631] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.5, 93.5, 1.0, 2.0, 0.1837943948042015, 1.0, 1.0, 0.1837943948042015, 1.0, 2.0, 0.298699301012316, 6.9112, 6.9112, 121.94756008, 668320.9083638169, 668320.9083638169, 214382.705240507], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7389000.0000, 
sim time next is 7389600.0000, 
raw observation next is [20.6, 93.33333333333334, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9198222936122431, 6.9112, 6.9112, 121.9260426156618, 687330.1495850726, 687330.1495850726, 171557.5077980294], 
processed observation next is [1.0, 0.5217391304347826, 0.3185185185185186, 0.9333333333333335, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8997778670153039, 0.0, 0.0, 0.8094621288201359, 0.24547505342324022, 0.24547505342324022, 0.3299182842269796], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.80667186], dtype=float32), 0.3152129]. 
=============================================
[2019-03-24 03:10:31,348] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.4632475e-32 2.6364474e-31 5.9562424e-21 5.9644977e-28], sum to 1.0000
[2019-03-24 03:10:31,356] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3643
[2019-03-24 03:10:31,361] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.28333333333333, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6417168534878875, 6.9112, 6.9112, 121.9260426156618, 478582.9441831722, 478582.9441831722, 136383.4063476695], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7426200.0000, 
sim time next is 7426800.0000, 
raw observation next is [20.3, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6398126754037092, 6.911200000000001, 6.9112, 121.9260426156618, 477198.1306143558, 477198.1306143554, 136234.900341332], 
processed observation next is [1.0, 1.0, 0.3074074074074074, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5497658442546365, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17042790379084136, 0.17042790379084122, 0.2619901929641], 
reward next is 0.7380, 
noisyNet noise sample is [array([0.697965], dtype=float32), 2.9632072]. 
=============================================
[2019-03-24 03:10:37,218] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.6877092e-31 9.5623678e-30 1.7871462e-22 1.2886203e-27], sum to 1.0000
[2019-03-24 03:10:37,228] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4030
[2019-03-24 03:10:37,233] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.16666666666666, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8556433424841623, 6.9112, 6.9112, 121.9260426156618, 629577.981908564, 629577.981908564, 169363.8732740527], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7566600.0000, 
sim time next is 7567200.0000, 
raw observation next is [27.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8431492236789868, 6.9112, 6.9112, 121.9260426156618, 621568.7504674372, 621568.7504674372, 167448.6546310794], 
processed observation next is [0.0, 0.6086956521739131, 0.5555555555555556, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8039365295987335, 0.0, 0.0, 0.8094621288201359, 0.22198883945265616, 0.22198883945265616, 0.32201664352130654], 
reward next is 0.6780, 
noisyNet noise sample is [array([-2.5790102], dtype=float32), -0.65779644]. 
=============================================
[2019-03-24 03:10:38,373] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 03:10:38,375] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:10:38,376] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:10:38,377] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:10:38,377] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:10:38,378] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:10:38,379] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:10:38,379] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:10:38,380] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:10:38,381] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:10:38,386] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:10:38,402] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run43
[2019-03-24 03:10:38,425] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run43
[2019-03-24 03:10:38,452] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run43
[2019-03-24 03:10:38,479] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run43
[2019-03-24 03:10:38,479] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run43
[2019-03-24 03:10:47,333] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00115586], dtype=float32), 0.27471465]
[2019-03-24 03:10:47,334] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.75220135833333, 34.57146621333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8314621217674348, 6.911200000000001, 6.9112, 121.9260426156618, 610410.862001631, 610410.8620016305, 150721.2075525854]
[2019-03-24 03:10:47,336] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:10:47,338] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 8.8643946e-27 3.0571723e-27 5.5682110e-18 1.0188009e-24], sampled 0.9081121942050596
[2019-03-24 03:11:00,395] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00115586], dtype=float32), 0.27471465]
[2019-03-24 03:11:00,399] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.6, 73.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.739401943273713, 6.911199999999999, 6.9112, 121.9260426156618, 552490.8291008882, 552490.8291008887, 149787.0555111804]
[2019-03-24 03:11:00,400] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:11:00,404] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.0318108e-29 4.5361789e-30 3.0978964e-20 1.8206528e-27], sampled 0.4386916799063808
[2019-03-24 03:11:07,257] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00115586], dtype=float32), 0.27471465]
[2019-03-24 03:11:07,259] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.53333333333333, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9108287465632298, 6.9112, 6.9112, 121.9260426156618, 664968.2585516499, 664968.2585516499, 177704.0983250283]
[2019-03-24 03:11:07,260] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:11:07,263] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.8204050e-30 1.0856305e-30 1.6286824e-20 5.7170181e-28], sampled 0.6012161976859016
[2019-03-24 03:11:46,001] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00115586], dtype=float32), 0.27471465]
[2019-03-24 03:11:46,002] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.65, 77.0, 1.0, 2.0, 0.8665704106515179, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260423568663, 1702924.990609777, 1702924.990609776, 349845.1115609751]
[2019-03-24 03:11:46,003] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:11:46,005] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.6127275e-25 6.8340569e-27 3.6980726e-15 3.4531279e-23], sampled 0.35573143275109087
[2019-03-24 03:11:46,007] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1702924.990609777 W.
[2019-03-24 03:11:49,530] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00115586], dtype=float32), 0.27471465]
[2019-03-24 03:11:49,533] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.5, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5885121212611947, 6.9112, 6.9112, 121.9260426156618, 434984.5085578357, 434984.5085578357, 128140.3424965213]
[2019-03-24 03:11:49,534] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:11:49,537] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 5.9520875e-28 3.2316406e-28 3.2405806e-19 7.1543336e-26], sampled 0.47799880237138037
[2019-03-24 03:12:16,130] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 03:12:16,877] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8362.6141 2339451215.1939 616.0000
[2019-03-24 03:12:17,083] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 03:12:17,157] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 03:12:17,184] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.1034 2219148757.5167 543.0000
[2019-03-24 03:12:18,201] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1050000, evaluation results [1050000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.103357014354, 2219148757.516729, 543.0, 8362.614081096275, 2339451215.1938696, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 03:12:19,476] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.7955979e-31 3.1656968e-32 2.1644453e-21 1.7877418e-27], sum to 1.0000
[2019-03-24 03:12:19,483] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9626
[2019-03-24 03:12:19,489] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.16666666666666, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8556433424841623, 6.9112, 6.9112, 121.9260426156618, 629577.981908564, 629577.981908564, 169363.8732740527], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7566600.0000, 
sim time next is 7567200.0000, 
raw observation next is [27.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8431492236789868, 6.9112, 6.9112, 121.9260426156618, 621568.7504674372, 621568.7504674372, 167448.6546310794], 
processed observation next is [0.0, 0.6086956521739131, 0.5555555555555556, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8039365295987335, 0.0, 0.0, 0.8094621288201359, 0.22198883945265616, 0.22198883945265616, 0.32201664352130654], 
reward next is 0.6780, 
noisyNet noise sample is [array([0.9542735], dtype=float32), 0.5040004]. 
=============================================
[2019-03-24 03:12:35,642] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 4.2512270e-24 7.1675350e-24 8.0418575e-14 4.2297794e-23], sum to 1.0000
[2019-03-24 03:12:35,652] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5749
[2019-03-24 03:12:35,659] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1396508.014477781 W.
[2019-03-24 03:12:35,663] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.36666666666667, 51.5, 1.0, 2.0, 0.5873982722533975, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9438511742067468, 6.911199999999999, 6.9112, 121.9260426156618, 1396508.014477781, 1396508.014477782, 287657.8330111693], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7906200.0000, 
sim time next is 7906800.0000, 
raw observation next is [28.53333333333333, 51.0, 1.0, 2.0, 0.5209188181516964, 1.0, 1.0, 0.5209188181516964, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1231918.864677367, 1231918.864677367, 243911.101527367], 
processed observation next is [1.0, 0.5217391304347826, 0.6123456790123456, 0.51, 1.0, 1.0, 0.42966525970440045, 1.0, 0.5, 0.42966525970440045, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.43997102309905967, 0.43997102309905967, 0.46905981062955193], 
reward next is 0.5309, 
noisyNet noise sample is [array([-0.51921904], dtype=float32), 0.7539385]. 
=============================================
[2019-03-24 03:12:36,967] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.4979012e-21 5.2436029e-23 1.5711212e-12 1.1156889e-19], sum to 1.0000
[2019-03-24 03:12:36,975] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6672
[2019-03-24 03:12:36,979] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1274726.30224311 W.
[2019-03-24 03:12:36,984] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.03333333333333, 49.5, 1.0, 2.0, 0.539498753577298, 1.0, 1.0, 0.539498753577298, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9258163080806, 1274726.30224311, 1274726.30224311, 249883.2562129575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7908600.0000, 
sim time next is 7909200.0000, 
raw observation next is [29.2, 49.0, 1.0, 2.0, 0.937865970866792, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.047837685893252, 6.9112, 121.9253665216105, 1192065.075625618, 1122094.75590618, 228704.1991447948], 
processed observation next is [1.0, 0.5652173913043478, 0.637037037037037, 0.49, 1.0, 1.0, 0.9260309176985619, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.013663768589325187, 0.0, 0.8094576402587236, 0.4257375270091493, 0.40074812710935, 0.4398157675861439], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8041332], dtype=float32), -0.113742344]. 
=============================================
[2019-03-24 03:12:36,993] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:12:36,994] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:12:37,055] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run6
[2019-03-24 03:12:38,375] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:12:38,375] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:12:38,380] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run6
[2019-03-24 03:12:38,439] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:12:38,439] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:12:38,442] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run6
[2019-03-24 03:12:38,616] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:12:38,616] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:12:38,622] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run6
[2019-03-24 03:12:38,718] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:12:38,719] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:12:38,720] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:12:38,720] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:12:38,723] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:12:38,724] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:12:38,728] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run6
[2019-03-24 03:12:38,750] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run6
[2019-03-24 03:12:38,754] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run6
[2019-03-24 03:12:38,809] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:12:38,810] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:12:38,820] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run6
[2019-03-24 03:12:38,953] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:12:38,954] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:12:38,957] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run6
[2019-03-24 03:12:39,140] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:12:39,140] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:12:39,144] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run6
[2019-03-24 03:12:39,177] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:12:39,178] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:12:39,184] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run6
[2019-03-24 03:12:39,184] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:12:39,184] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:12:39,190] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run6
[2019-03-24 03:12:39,258] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:12:39,258] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:12:39,262] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run6
[2019-03-24 03:12:39,345] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:12:39,345] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:12:39,348] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run6
[2019-03-24 03:12:39,566] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:12:39,567] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:12:39,571] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run6
[2019-03-24 03:12:39,709] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:12:39,709] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:12:39,712] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run6
[2019-03-24 03:12:41,085] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.4314769e-29 1.0692607e-29 1.6302940e-18 2.6574956e-27], sum to 1.0000
[2019-03-24 03:12:41,090] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1440
[2019-03-24 03:12:41,095] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.63333333333333, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4864763014543007, 6.9112, 6.9112, 121.9260426156618, 347346.6718483305, 347346.6718483305, 111814.0457053425], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6000.0000, 
sim time next is 6600.0000, 
raw observation next is [18.61666666666667, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.483586507057767, 6.911200000000001, 6.9112, 121.9260426156618, 345282.8161442537, 345282.8161442532, 111386.2758748588], 
processed observation next is [1.0, 0.043478260869565216, 0.24506172839506188, 0.75, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.35448313382220875, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12331529148009061, 0.12331529148009042, 0.21420437668242076], 
reward next is 0.7858, 
noisyNet noise sample is [array([1.5514416], dtype=float32), -1.108579]. 
=============================================
[2019-03-24 03:12:43,088] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1061385: loss 1.0665
[2019-03-24 03:12:43,090] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1061387: learning rate 0.0000
[2019-03-24 03:12:44,744] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.4474477e-31 1.4675159e-31 3.8371498e-16 1.0117236e-27], sum to 1.0000
[2019-03-24 03:12:44,752] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3069
[2019-03-24 03:12:44,756] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.46666666666667, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6924839370904614, 6.9112, 6.9112, 121.9260426156618, 517471.7594653413, 517471.7594653413, 143722.7668137634], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 76800.0000, 
sim time next is 77400.0000, 
raw observation next is [26.3, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.693741126045107, 6.911200000000001, 6.9112, 121.9260426156618, 518417.6413683541, 518417.6413683537, 143925.6548014273], 
processed observation next is [1.0, 0.9130434782608695, 0.5296296296296297, 0.56, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6171764075563837, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18514915763155504, 0.18514915763155487, 0.2767801053873602], 
reward next is 0.7232, 
noisyNet noise sample is [array([0.14941241], dtype=float32), -0.73734367]. 
=============================================
[2019-03-24 03:12:48,328] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1063909: loss 0.1671
[2019-03-24 03:12:48,331] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1063911: learning rate 0.0000
[2019-03-24 03:12:48,358] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1063925: loss 0.0144
[2019-03-24 03:12:48,362] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1063925: learning rate 0.0000
[2019-03-24 03:12:48,374] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1063930: loss 0.1174
[2019-03-24 03:12:48,380] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1063930: learning rate 0.0000
[2019-03-24 03:12:48,409] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1063942: loss 0.3321
[2019-03-24 03:12:48,410] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1063942: learning rate 0.0000
[2019-03-24 03:12:48,478] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1063978: loss 1.1375
[2019-03-24 03:12:48,481] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1063978: learning rate 0.0000
[2019-03-24 03:12:48,551] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1064012: loss 0.5075
[2019-03-24 03:12:48,555] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1064013: learning rate 0.0000
[2019-03-24 03:12:48,593] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1064034: loss 0.8101
[2019-03-24 03:12:48,595] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1064034: learning rate 0.0000
[2019-03-24 03:12:48,685] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1064079: loss 0.9660
[2019-03-24 03:12:48,687] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1064079: learning rate 0.0000
[2019-03-24 03:12:48,735] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9424332e-01 3.4983173e-25 9.0634399e-30 5.7566701e-03 2.3268965e-20], sum to 1.0000
[2019-03-24 03:12:48,743] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4799
[2019-03-24 03:12:48,749] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1668119.120469766 W.
[2019-03-24 03:12:48,758] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [37.36666666666667, 11.0, 1.0, 2.0, 0.453528185156695, 1.0, 2.0, 0.453528185156695, 1.0, 1.0, 0.7436182627913746, 6.911199999999999, 6.9112, 121.94756008, 1668119.120469766, 1668119.120469766, 319998.2878280139], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 141600.0000, 
sim time next is 142200.0000, 
raw observation next is [37.34999999999999, 10.5, 1.0, 2.0, 0.7280079800816988, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9574632179204949, 6.911199999999999, 6.9112, 121.9260426156618, 1621202.156142388, 1621202.156142388, 306540.2247364002], 
processed observation next is [1.0, 0.6521739130434783, 0.9388888888888884, 0.105, 1.0, 1.0, 0.6761999762877366, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9468290224006187, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5790007700508528, 0.5790007700508528, 0.589500432185385], 
reward next is 0.4105, 
noisyNet noise sample is [array([-0.9506121], dtype=float32), 0.24472941]. 
=============================================
[2019-03-24 03:12:48,950] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1064211: loss 0.2233
[2019-03-24 03:12:48,952] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1064212: learning rate 0.0000
[2019-03-24 03:12:49,054] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1064257: loss 0.1376
[2019-03-24 03:12:49,059] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1064260: learning rate 0.0000
[2019-03-24 03:12:49,145] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1064302: loss 0.3123
[2019-03-24 03:12:49,146] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1064302: learning rate 0.0000
[2019-03-24 03:12:49,333] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1064393: loss 0.1142
[2019-03-24 03:12:49,334] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1064393: learning rate 0.0000
[2019-03-24 03:12:49,479] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1064465: loss 0.0250
[2019-03-24 03:12:49,481] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1064465: learning rate 0.0000
[2019-03-24 03:12:49,801] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1064622: loss 0.1919
[2019-03-24 03:12:49,802] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1064622: learning rate 0.0000
[2019-03-24 03:12:49,811] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1064627: loss 0.3705
[2019-03-24 03:12:49,813] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1064627: learning rate 0.0000
[2019-03-24 03:12:55,528] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.9097861e-31 1.2084778e-30 2.4871120e-21 2.9880264e-28], sum to 1.0000
[2019-03-24 03:12:55,533] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8311
[2019-03-24 03:12:55,537] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.86666666666667, 38.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4946945497841116, 6.911200000000001, 6.9112, 121.9260426156618, 353215.8267176038, 353215.8267176034, 99652.722935551], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 285600.0000, 
sim time next is 286200.0000, 
raw observation next is [23.1, 37.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4995754547466827, 6.911200000000001, 6.9112, 121.9260426156618, 356701.6419694376, 356701.6419694371, 100338.4218269122], 
processed observation next is [0.0, 0.30434782608695654, 0.41111111111111115, 0.375, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.37446931843335335, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12739344356051344, 0.12739344356051327, 0.19295850351329272], 
reward next is 0.8070, 
noisyNet noise sample is [array([-1.72593], dtype=float32), -0.9551917]. 
=============================================
[2019-03-24 03:12:58,914] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 8.2543166e-31 2.3020277e-29 2.3064168e-19 1.7598298e-28], sum to 1.0000
[2019-03-24 03:12:58,921] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4929
[2019-03-24 03:12:58,929] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.7, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.502543295436406, 6.9112, 6.9112, 121.9260426156618, 358821.2042698291, 358821.2042698291, 111663.2569125693], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 345600.0000, 
sim time next is 346200.0000, 
raw observation next is [22.55, 48.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4993592877329123, 6.911200000000001, 6.9112, 121.9260426156618, 356547.2607807575, 356547.2607807571, 110892.7900654733], 
processed observation next is [1.0, 0.0, 0.3907407407407408, 0.485, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3741991096661404, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1273383074216991, 0.12733830742169897, 0.21325536551052557], 
reward next is 0.7867, 
noisyNet noise sample is [array([1.2088745], dtype=float32), -0.15102287]. 
=============================================
[2019-03-24 03:12:59,499] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1069376: loss 0.0181
[2019-03-24 03:12:59,502] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1069378: learning rate 0.0000
[2019-03-24 03:13:04,600] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1071856: loss 0.0286
[2019-03-24 03:13:04,605] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1071856: learning rate 0.0000
[2019-03-24 03:13:04,639] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1071871: loss 0.0168
[2019-03-24 03:13:04,644] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1071871: learning rate 0.0000
[2019-03-24 03:13:04,678] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1071890: loss 0.0167
[2019-03-24 03:13:04,678] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1071890: learning rate 0.0000
[2019-03-24 03:13:04,693] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1071898: loss 0.0164
[2019-03-24 03:13:04,695] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1071898: learning rate 0.0000
[2019-03-24 03:13:04,721] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1071913: loss 0.0462
[2019-03-24 03:13:04,722] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1071913: learning rate 0.0000
[2019-03-24 03:13:04,883] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1071994: loss 0.0786
[2019-03-24 03:13:04,887] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1071994: learning rate 0.0000
[2019-03-24 03:13:04,918] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1072010: loss 0.0367
[2019-03-24 03:13:04,923] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1072010: learning rate 0.0000
[2019-03-24 03:13:05,083] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1072089: loss 0.0711
[2019-03-24 03:13:05,087] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1072091: learning rate 0.0000
[2019-03-24 03:13:05,161] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1072123: loss 0.3174
[2019-03-24 03:13:05,163] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1072125: learning rate 0.0000
[2019-03-24 03:13:05,407] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1072242: loss 0.0933
[2019-03-24 03:13:05,409] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1072242: learning rate 0.0000
[2019-03-24 03:13:05,463] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1072267: loss 0.0359
[2019-03-24 03:13:05,464] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1072267: learning rate 0.0000
[2019-03-24 03:13:05,777] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1072413: loss 0.0148
[2019-03-24 03:13:05,779] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1072414: learning rate 0.0000
[2019-03-24 03:13:05,836] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1072449: loss 0.0158
[2019-03-24 03:13:05,839] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1072450: learning rate 0.0000
[2019-03-24 03:13:06,103] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1072577: loss 0.0979
[2019-03-24 03:13:06,105] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1072577: learning rate 0.0000
[2019-03-24 03:13:06,172] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1072613: loss 0.0796
[2019-03-24 03:13:06,176] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1072613: learning rate 0.0000
[2019-03-24 03:13:06,266] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.2115643e-25 8.2426913e-27 2.9105456e-22 6.6319433e-25], sum to 1.0000
[2019-03-24 03:13:06,272] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1257
[2019-03-24 03:13:06,281] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1391282.724013809 W.
[2019-03-24 03:13:06,283] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.03333333333333, 27.66666666666667, 1.0, 2.0, 0.567365271539859, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9304597548331597, 6.911199999999999, 6.9112, 121.9260426156618, 1391282.724013809, 1391282.72401381, 278034.483921413], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 483000.0000, 
sim time next is 483600.0000, 
raw observation next is [32.06666666666667, 27.33333333333334, 1.0, 2.0, 0.5400270762998332, 0.0, 2.0, 0.0, 1.0, 2.0, 0.887312211232853, 6.9112, 6.9112, 121.9260426156618, 1326837.199787474, 1326837.199787474, 267829.4990461263], 
processed observation next is [1.0, 0.6086956521739131, 0.74320987654321, 0.2733333333333334, 1.0, 1.0, 0.45241318607122993, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8591402640410661, 0.0, 0.0, 0.8094621288201359, 0.4738704284955264, 0.4738704284955264, 0.5150567289348583], 
reward next is 0.4849, 
noisyNet noise sample is [array([-1.127623], dtype=float32), -0.5978427]. 
=============================================
[2019-03-24 03:13:09,803] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.2035665e-19 9.5893336e-21 2.1759161e-09 8.8341549e-18], sum to 1.0000
[2019-03-24 03:13:09,811] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9630
[2019-03-24 03:13:09,819] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1487328.397082429 W.
[2019-03-24 03:13:09,824] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.6, 35.0, 1.0, 2.0, 0.4132859581992056, 1.0, 1.0, 0.4132859581992056, 1.0, 1.0, 0.6670444037480487, 6.911200000000001, 6.9112, 121.94756008, 1487328.397082429, 1487328.397082428, 302535.8370691265], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 550800.0000, 
sim time next is 551400.0000, 
raw observation next is [30.3, 36.16666666666667, 1.0, 2.0, 0.5634357867808607, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9154579026820602, 6.9112, 6.9112, 121.9260424774044, 1366007.641663015, 1366007.641663015, 277450.8254941917], 
processed observation next is [1.0, 0.391304347826087, 0.6777777777777778, 0.3616666666666667, 1.0, 1.0, 0.4802806985486437, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8943223783525752, 0.0, 0.0, 0.8094621279022506, 0.4878598720225053, 0.4878598720225053, 0.5335592797965225], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.44991702], dtype=float32), -1.2667282]. 
=============================================
[2019-03-24 03:13:11,089] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 03:13:11,090] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:13:11,090] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:13:11,091] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:13:11,092] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:13:11,094] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:13:11,095] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:13:11,096] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:13:11,096] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:13:11,097] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:13:11,100] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:13:11,117] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run44
[2019-03-24 03:13:11,117] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run44
[2019-03-24 03:13:11,117] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run44
[2019-03-24 03:13:11,165] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run44
[2019-03-24 03:13:11,166] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run44
[2019-03-24 03:13:16,513] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00098664], dtype=float32), 0.2827567]
[2019-03-24 03:13:16,515] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.7, 41.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5377624622717747, 6.9112, 6.9112, 121.9260426156618, 385447.6350320969, 385447.6350320969, 118522.2188273881]
[2019-03-24 03:13:16,516] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:13:16,518] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 4.5230212e-26 2.8777956e-25 2.3284821e-19 1.2008806e-24], sampled 0.39647965961630505
[2019-03-24 03:13:24,293] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00098664], dtype=float32), 0.2827567]
[2019-03-24 03:13:24,294] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.255037085, 65.055064695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6020431792022415, 6.911200000000001, 6.9112, 121.9260426156618, 447220.2704016114, 447220.2704016109, 130831.0852894279]
[2019-03-24 03:13:24,297] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:13:24,300] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 6.2329090e-27 4.3507263e-26 5.1652712e-20 1.8664769e-25], sampled 0.6726897909212634
[2019-03-24 03:13:34,849] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00098664], dtype=float32), 0.2827567]
[2019-03-24 03:13:34,851] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [16.81464619, 104.0894114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5491970343955217, 6.911200000000001, 6.9112, 121.9260426156618, 401187.9692045165, 401187.9692045161, 122277.9548494081]
[2019-03-24 03:13:34,854] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:13:34,857] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.5795305e-27 3.1782303e-26 4.1941007e-20 1.3915845e-25], sampled 0.023813483731938034
[2019-03-24 03:13:40,952] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00098664], dtype=float32), 0.2827567]
[2019-03-24 03:13:40,953] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.46666666666667, 52.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8970662354750017, 6.9112, 6.9112, 121.9260426156618, 655020.2926263823, 655020.2926263823, 175846.2378056881]
[2019-03-24 03:13:40,953] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:13:40,957] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 9.9141838e-26 5.5661523e-25 4.8636116e-19 2.4987098e-24], sampled 0.9281349871076672
[2019-03-24 03:14:04,052] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00098664], dtype=float32), 0.2827567]
[2019-03-24 03:14:04,053] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.5, 89.0, 1.0, 2.0, 0.6402862017899474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425536774, 757047.7291238051, 757047.7291238051, 166404.2811335943]
[2019-03-24 03:14:04,054] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:14:04,055] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.5656546e-21 5.5095278e-21 8.3323637e-16 2.3834174e-20], sampled 0.3181589878675697
[2019-03-24 03:14:04,056] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 757047.7291238051 W.
[2019-03-24 03:14:05,815] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00098664], dtype=float32), 0.2827567]
[2019-03-24 03:14:05,815] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.95, 92.0, 1.0, 2.0, 0.594839358083459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690634.9745820821, 690634.9745820821, 157800.5193544068]
[2019-03-24 03:14:05,816] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:14:05,819] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.0550435e-21 5.1281034e-21 3.7067991e-16 1.6049129e-20], sampled 0.6725087843237657
[2019-03-24 03:14:05,820] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 690634.9745820821 W.
[2019-03-24 03:14:06,008] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00098664], dtype=float32), 0.2827567]
[2019-03-24 03:14:06,009] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9351684933201949, 6.911200000000001, 6.9112, 121.9260426156618, 681251.422701855, 681251.4227018545, 181262.420888822]
[2019-03-24 03:14:06,010] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:14:06,012] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 4.2194086e-27 2.9489627e-26 3.9202933e-20 1.2881546e-25], sampled 0.6091425238440524
[2019-03-24 03:14:18,955] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00098664], dtype=float32), 0.2827567]
[2019-03-24 03:14:18,955] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.98376477, 98.91076644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9056021915131206, 6.9112, 6.9112, 121.9260426156618, 661236.6199388263, 661236.6199388263, 176987.9802665661]
[2019-03-24 03:14:18,957] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:14:18,958] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.4325541e-27 2.3977275e-26 3.3996361e-20 1.0583145e-25], sampled 0.5900075939596869
[2019-03-24 03:14:24,097] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00098664], dtype=float32), 0.2827567]
[2019-03-24 03:14:24,099] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.83333333333334, 66.66666666666667, 1.0, 2.0, 0.5854215419095141, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9320101605685104, 6.911199999999999, 6.9112, 121.9260426156618, 1334897.353858443, 1334897.353858443, 288236.5926759021]
[2019-03-24 03:14:24,101] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:14:24,103] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.00000000e+00 1.26687655e-20 3.37719717e-20 6.63883629e-15
 1.94690063e-19], sampled 0.7750696764605178
[2019-03-24 03:14:24,105] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1334897.353858443 W.
[2019-03-24 03:14:24,498] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00098664], dtype=float32), 0.2827567]
[2019-03-24 03:14:24,500] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.9567433, 71.87739564500001, 1.0, 1.0, 0.6386958402301274, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727899.4029792685, 727899.4029792685, 164866.2459474868]
[2019-03-24 03:14:24,502] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:14:24,505] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.1082795e-23 9.4918603e-23 2.8075744e-17 3.9406202e-22], sampled 0.096924580591909
[2019-03-24 03:14:24,506] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 727899.4029792685 W.
[2019-03-24 03:14:37,974] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00098664], dtype=float32), 0.2827567]
[2019-03-24 03:14:37,975] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.30961304, 80.70256625, 1.0, 2.0, 0.8943013560481037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1019397.839079196, 1019397.839079196, 216196.9492525992]
[2019-03-24 03:14:37,976] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:14:37,982] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.1464336e-18 5.4685584e-18 2.2886453e-13 2.3443491e-17], sampled 0.678025944553888
[2019-03-24 03:14:37,983] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1019397.839079196 W.
[2019-03-24 03:14:49,632] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 03:14:49,635] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 03:14:49,698] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 03:14:49,908] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 03:14:49,940] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 03:14:50,955] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1075000, evaluation results [1075000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 03:14:52,251] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.0006536e-32 2.0985482e-29 1.3088122e-21 7.4350062e-29], sum to 1.0000
[2019-03-24 03:14:52,258] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6025
[2019-03-24 03:14:52,263] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.65, 36.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6355459944555039, 6.9112, 6.9112, 121.9260426156618, 473888.846009501, 473888.846009501, 135655.3865727358], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 589800.0000, 
sim time next is 590400.0000, 
raw observation next is [29.5, 37.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6341741107608978, 6.9112, 6.9112, 121.9260426156618, 472760.0555131723, 472760.0555131723, 135398.5156114662], 
processed observation next is [1.0, 0.8695652173913043, 0.6481481481481481, 0.37, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5427176384511222, 0.0, 0.0, 0.8094621288201359, 0.1688428769689901, 0.1688428769689901, 0.26038176079128117], 
reward next is 0.7396, 
noisyNet noise sample is [array([0.8100746], dtype=float32), -0.07275287]. 
=============================================
[2019-03-24 03:14:54,370] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.2605756e-28 4.5861891e-28 1.0427887e-19 9.5468917e-27], sum to 1.0000
[2019-03-24 03:14:54,377] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1687
[2019-03-24 03:14:54,380] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.45, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7751640148471388, 6.9112, 6.9112, 121.9260426156618, 574934.2751851243, 574934.2751851243, 147913.4980406406], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 631800.0000, 
sim time next is 632400.0000, 
raw observation next is [24.73333333333333, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8485399312068201, 6.9112, 6.9112, 121.9260426156618, 629862.4221150113, 629862.4221150113, 156388.9086544247], 
processed observation next is [1.0, 0.30434782608695654, 0.4716049382716048, 0.55, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8106749140085251, 0.0, 0.0, 0.8094621288201359, 0.22495086504107545, 0.22495086504107545, 0.3007479012585091], 
reward next is 0.6993, 
noisyNet noise sample is [array([1.0655202], dtype=float32), -0.7171882]. 
=============================================
[2019-03-24 03:14:55,929] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1077450: loss 0.5574
[2019-03-24 03:14:55,931] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1077451: learning rate 0.0000
[2019-03-24 03:15:00,574] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1079828: loss 19.8325
[2019-03-24 03:15:00,577] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1079828: learning rate 0.0000
[2019-03-24 03:15:00,749] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1079912: loss 9.8895
[2019-03-24 03:15:00,752] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1079913: learning rate 0.0000
[2019-03-24 03:15:00,757] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1079916: loss 15.5557
[2019-03-24 03:15:00,758] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1079916: learning rate 0.0000
[2019-03-24 03:15:00,842] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1079962: loss 9.7112
[2019-03-24 03:15:00,847] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1079962: learning rate 0.0000
[2019-03-24 03:15:00,867] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1079974: loss 7.0865
[2019-03-24 03:15:00,868] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1079974: learning rate 0.0000
[2019-03-24 03:15:00,989] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1080025: loss 2.3991
[2019-03-24 03:15:00,990] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1080025: learning rate 0.0000
[2019-03-24 03:15:01,007] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1080034: loss 5.5562
[2019-03-24 03:15:01,010] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1080035: learning rate 0.0000
[2019-03-24 03:15:01,216] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1080140: loss 0.6425
[2019-03-24 03:15:01,217] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1080140: learning rate 0.0000
[2019-03-24 03:15:01,385] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1080218: loss 0.5177
[2019-03-24 03:15:01,389] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1080219: learning rate 0.0000
[2019-03-24 03:15:01,404] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1080227: loss 0.3148
[2019-03-24 03:15:01,405] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1080227: learning rate 0.0000
[2019-03-24 03:15:01,435] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1080245: loss 1.5041
[2019-03-24 03:15:01,438] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1080245: learning rate 0.0000
[2019-03-24 03:15:01,857] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1080454: loss 0.3497
[2019-03-24 03:15:01,859] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1080455: learning rate 0.0000
[2019-03-24 03:15:02,055] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1080547: loss 1.6143
[2019-03-24 03:15:02,056] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1080547: learning rate 0.0000
[2019-03-24 03:15:02,171] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1080607: loss 0.7057
[2019-03-24 03:15:02,173] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1080607: learning rate 0.0000
[2019-03-24 03:15:02,433] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1080727: loss 0.3981
[2019-03-24 03:15:02,434] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1080727: learning rate 0.0000
[2019-03-24 03:15:11,798] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1085332: loss 0.0108
[2019-03-24 03:15:11,801] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1085333: learning rate 0.0000
[2019-03-24 03:15:16,872] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1087807: loss 0.0449
[2019-03-24 03:15:16,877] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1087807: learning rate 0.0000
[2019-03-24 03:15:16,912] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1087829: loss 0.0616
[2019-03-24 03:15:16,916] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1087831: learning rate 0.0000
[2019-03-24 03:15:16,932] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1087844: loss 0.0878
[2019-03-24 03:15:16,934] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1087844: learning rate 0.0000
[2019-03-24 03:15:17,131] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1087939: loss 0.1716
[2019-03-24 03:15:17,134] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1087939: learning rate 0.0000
[2019-03-24 03:15:17,170] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1087957: loss 0.2479
[2019-03-24 03:15:17,173] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1087957: learning rate 0.0000
[2019-03-24 03:15:17,226] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1087984: loss 0.1385
[2019-03-24 03:15:17,232] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1087985: learning rate 0.0000
[2019-03-24 03:15:17,481] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1088112: loss 0.1292
[2019-03-24 03:15:17,484] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1088112: learning rate 0.0000
[2019-03-24 03:15:17,503] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1088123: loss 0.2021
[2019-03-24 03:15:17,506] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1088123: learning rate 0.0000
[2019-03-24 03:15:17,549] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1088146: loss 0.2301
[2019-03-24 03:15:17,550] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1088146: learning rate 0.0000
[2019-03-24 03:15:17,563] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1088151: loss 0.2998
[2019-03-24 03:15:17,568] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1088151: learning rate 0.0000
[2019-03-24 03:15:17,827] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1088286: loss 0.2426
[2019-03-24 03:15:17,831] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1088286: learning rate 0.0000
[2019-03-24 03:15:18,193] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1088464: loss 0.3227
[2019-03-24 03:15:18,195] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1088465: learning rate 0.0000
[2019-03-24 03:15:18,214] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1088476: loss 0.4190
[2019-03-24 03:15:18,216] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1088476: learning rate 0.0000
[2019-03-24 03:15:18,468] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1088602: loss 0.4217
[2019-03-24 03:15:18,471] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1088605: learning rate 0.0000
[2019-03-24 03:15:18,587] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1088659: loss 0.2544
[2019-03-24 03:15:18,588] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1088660: learning rate 0.0000
[2019-03-24 03:15:23,163] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 6.4270805e-28 1.2619667e-27 7.4441706e-22 7.0342863e-26], sum to 1.0000
[2019-03-24 03:15:23,170] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7170
[2019-03-24 03:15:23,173] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.33333333333334, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4950311532013145, 6.911200000000001, 6.9112, 121.9260426156618, 355351.2188606191, 355351.2188606187, 115389.2617273835], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1146000.0000, 
sim time next is 1146600.0000, 
raw observation next is [19.4, 72.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5090089601822156, 6.9112, 6.9112, 121.9260426156618, 365379.4659833665, 365379.4659833665, 116461.3202733516], 
processed observation next is [1.0, 0.2608695652173913, 0.274074074074074, 0.725, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3862612002277695, 0.0, 0.0, 0.8094621288201359, 0.13049266642263088, 0.13049266642263088, 0.22396407744875307], 
reward next is 0.7760, 
noisyNet noise sample is [array([0.35265315], dtype=float32), 0.8709814]. 
=============================================
[2019-03-24 03:15:23,415] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.4440694e-28 1.6882278e-27 1.7360191e-21 1.4197025e-25], sum to 1.0000
[2019-03-24 03:15:23,425] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8037
[2019-03-24 03:15:23,428] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.01666666666667, 68.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5461901580742362, 6.9112, 6.9112, 121.9260426156618, 392517.6437145423, 392517.6437145423, 119544.7360597775], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1151400.0000, 
sim time next is 1152000.0000, 
raw observation next is [20.1, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5400828572285145, 6.9112, 6.9112, 121.9260426156618, 388218.5580073925, 388218.5580073925, 119086.1861654661], 
processed observation next is [1.0, 0.34782608695652173, 0.30000000000000004, 0.68, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.42510357153564304, 0.0, 0.0, 0.8094621288201359, 0.13864948500264018, 0.13864948500264018, 0.2290118964720502], 
reward next is 0.7710, 
noisyNet noise sample is [array([-1.1580967], dtype=float32), -0.072531514]. 
=============================================
[2019-03-24 03:15:23,454] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[59.721855]
 [59.805862]
 [59.962395]
 [59.995148]
 [60.00694 ]], R is [[59.79628754]
 [59.96843338]
 [60.14022446]
 [60.31391144]
 [60.48498154]].
[2019-03-24 03:15:26,139] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.2278030e-31 8.4539316e-31 6.9780722e-21 2.8083285e-29], sum to 1.0000
[2019-03-24 03:15:26,149] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0723
[2019-03-24 03:15:26,162] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.83333333333334, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5305875858659511, 6.9112, 6.9112, 121.9260426156618, 387355.9842235419, 387355.9842235419, 120616.4175673662], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1226400.0000, 
sim time next is 1227000.0000, 
raw observation next is [17.81666666666667, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5290510956567452, 6.911200000000001, 6.9112, 121.9260426156618, 386130.5317378118, 386130.5317378113, 120444.8799882571], 
processed observation next is [1.0, 0.17391304347826086, 0.21543209876543223, 0.93, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4113138695709315, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1379037613349328, 0.1379037613349326, 0.23162476920818673], 
reward next is 0.7684, 
noisyNet noise sample is [array([-1.0331829], dtype=float32), -1.8426274]. 
=============================================
[2019-03-24 03:15:26,204] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[64.59646 ]
 [64.687645]
 [64.80041 ]
 [64.9248  ]
 [65.153305]], R is [[64.67307281]
 [64.79438782]
 [64.91410065]
 [65.03220367]
 [65.1470871 ]].
[2019-03-24 03:15:28,186] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1093361: loss -126.9405
[2019-03-24 03:15:28,188] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1093361: learning rate 0.0000
[2019-03-24 03:15:33,381] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1095873: loss -38.3067
[2019-03-24 03:15:33,382] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1095873: learning rate 0.0000
[2019-03-24 03:15:33,404] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1095882: loss -32.0681
[2019-03-24 03:15:33,407] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1095883: learning rate 0.0000
[2019-03-24 03:15:33,512] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1095942: loss 46.9240
[2019-03-24 03:15:33,516] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1095943: learning rate 0.0000
[2019-03-24 03:15:33,575] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1095963: loss -84.3956
[2019-03-24 03:15:33,576] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1095963: learning rate 0.0000
[2019-03-24 03:15:33,706] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1096030: loss 46.3973
[2019-03-24 03:15:33,709] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1096030: learning rate 0.0000
[2019-03-24 03:15:33,712] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1096031: loss -123.1865
[2019-03-24 03:15:33,718] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1096031: learning rate 0.0000
[2019-03-24 03:15:33,873] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1096110: loss -67.2831
[2019-03-24 03:15:33,875] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1096110: learning rate 0.0000
[2019-03-24 03:15:33,894] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1096118: loss -56.6862
[2019-03-24 03:15:33,895] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1096118: learning rate 0.0000
[2019-03-24 03:15:33,943] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1096142: loss -66.9833
[2019-03-24 03:15:33,946] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1096143: learning rate 0.0000
[2019-03-24 03:15:33,970] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1096154: loss 0.6009
[2019-03-24 03:15:33,973] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1096154: learning rate 0.0000
[2019-03-24 03:15:34,364] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1096348: loss -5.5546
[2019-03-24 03:15:34,367] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1096348: learning rate 0.0000
[2019-03-24 03:15:34,685] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1096504: loss -41.4440
[2019-03-24 03:15:34,689] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1096504: learning rate 0.0000
[2019-03-24 03:15:34,753] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1096537: loss -46.4412
[2019-03-24 03:15:34,754] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1096537: learning rate 0.0000
[2019-03-24 03:15:35,015] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1096659: loss -88.5602
[2019-03-24 03:15:35,018] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1096660: learning rate 0.0000
[2019-03-24 03:15:35,187] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1096742: loss 20.4650
[2019-03-24 03:15:35,188] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1096742: learning rate 0.0000
[2019-03-24 03:15:41,811] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 03:15:41,812] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:15:41,812] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:15:41,813] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:15:41,814] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:15:41,816] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:15:41,817] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:15:41,817] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:15:41,818] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:15:41,819] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:15:41,828] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:15:41,840] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run45
[2019-03-24 03:15:41,840] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run45
[2019-03-24 03:15:41,862] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run45
[2019-03-24 03:15:41,907] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run45
[2019-03-24 03:15:41,930] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run45
[2019-03-24 03:15:45,420] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([3.4069697e-05], dtype=float32), 0.29052842]
[2019-03-24 03:15:45,421] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [12.46666666666667, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2784222007294777, 6.9112, 6.9112, 121.9260426156618, 198775.646850589, 198775.646850589, 68772.81723519134]
[2019-03-24 03:15:45,422] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:15:45,425] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.5465532e-37 9.5538067e-36 6.1772566e-28 2.9420612e-35], sampled 0.8983093067354482
[2019-03-24 03:16:29,543] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([3.4069697e-05], dtype=float32), 0.29052842]
[2019-03-24 03:16:29,544] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.0, 92.0, 1.0, 2.0, 0.7245762281431279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 825827.014875492, 825827.014875492, 180849.1527060161]
[2019-03-24 03:16:29,546] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:16:29,549] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.1887559e-33 1.8177404e-32 4.9542279e-25 6.2867166e-32], sampled 0.5785602000275026
[2019-03-24 03:16:29,551] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 825827.014875492 W.
[2019-03-24 03:16:30,472] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([3.4069697e-05], dtype=float32), 0.29052842]
[2019-03-24 03:16:30,474] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.66711572666667, 89.77070715, 1.0, 2.0, 0.9180249313479212, 1.0, 2.0, 0.9180249313479212, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2094247.684966893, 2094247.684966893, 394940.1429160006]
[2019-03-24 03:16:30,475] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:16:30,478] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.6548837e-30 5.5147590e-30 1.9004208e-21 7.3485536e-29], sampled 0.9605187846444931
[2019-03-24 03:16:30,479] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2094247.684966893 W.
[2019-03-24 03:16:31,570] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([3.4069697e-05], dtype=float32), 0.29052842]
[2019-03-24 03:16:31,570] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.13333333333333, 78.33333333333333, 1.0, 2.0, 0.9628131385192757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.915559216848669, 6.9112, 121.9258458634451, 1099783.010811689, 1097550.705765069, 231880.4572243716]
[2019-03-24 03:16:31,572] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:16:31,574] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.4526978e-33 2.0297863e-32 3.4256131e-24 1.3823742e-31], sampled 0.11472210467733601
[2019-03-24 03:16:31,574] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1099783.010811689 W.
[2019-03-24 03:16:56,268] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([3.4069697e-05], dtype=float32), 0.29052842]
[2019-03-24 03:16:56,269] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.06666666666667, 81.0, 1.0, 2.0, 0.5793181701009085, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9222933938762674, 6.9112, 6.9112, 121.9260426156618, 1320968.244963165, 1320968.244963165, 285904.546056174]
[2019-03-24 03:16:56,269] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:16:56,271] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 5.8439197e-34 5.1172851e-33 1.1189169e-24 3.4825457e-32], sampled 0.879341173340145
[2019-03-24 03:16:56,272] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1320968.244963165 W.
[2019-03-24 03:17:01,878] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([3.4069697e-05], dtype=float32), 0.29052842]
[2019-03-24 03:17:01,880] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.45537458, 55.25571775333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4483497648719572, 6.9112, 6.9112, 121.9260426156618, 320165.116232616, 320165.116232616, 107855.4050998437]
[2019-03-24 03:17:01,880] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:17:01,884] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 1.4151088e-37 2.4873390e-29 4.7203369e-37], sampled 0.08042085736509019
[2019-03-24 03:17:14,014] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([3.4069697e-05], dtype=float32), 0.29052842]
[2019-03-24 03:17:14,015] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.18552106, 64.37439959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7479060625515862, 6.911199999999999, 6.9112, 121.9260426156618, 556751.7531917106, 556751.753191711, 153277.5762651049]
[2019-03-24 03:17:14,016] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:17:14,018] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 3.0647698e-37 4.7648608e-29 1.0261274e-36], sampled 0.5048750491275474
[2019-03-24 03:17:20,068] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 03:17:20,456] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 03:17:20,479] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 03:17:20,705] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 03:17:20,861] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 03:17:21,878] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1100000, evaluation results [1100000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 03:17:24,589] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1101325: loss 0.1436
[2019-03-24 03:17:24,594] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1101326: learning rate 0.0000
[2019-03-24 03:17:27,905] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 4.2164221e-24 6.0108803e-23 9.9350951e-16 2.6674571e-21], sum to 1.0000
[2019-03-24 03:17:27,913] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5749
[2019-03-24 03:17:27,922] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 931048.8826617661 W.
[2019-03-24 03:17:27,928] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.63333333333333, 48.33333333333334, 1.0, 2.0, 0.2546796776785927, 1.0, 2.0, 0.2546796776785927, 1.0, 2.0, 0.415548185894887, 6.9112, 6.9112, 121.94756008, 931048.8826617661, 931048.8826617661, 238100.4975572953], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1600800.0000, 
sim time next is 1601400.0000, 
raw observation next is [26.71666666666667, 47.66666666666667, 1.0, 2.0, 0.260117830475754, 1.0, 2.0, 0.260117830475754, 1.0, 2.0, 0.4243116428164892, 6.911200000000002, 6.9112, 121.94756008, 950638.3876624506, 950638.3876624496, 240068.6008737645], 
processed observation next is [1.0, 0.5217391304347826, 0.5450617283950618, 0.47666666666666674, 1.0, 1.0, 0.11918789342351666, 1.0, 1.0, 0.11918789342351666, 1.0, 1.0, 0.28038955352061146, 1.7763568394002506e-16, 0.0, 0.8096049824067558, 0.3395137098794466, 0.3395137098794463, 0.46167038629570095], 
reward next is 0.5383, 
noisyNet noise sample is [array([0.60404885], dtype=float32), 1.9699867]. 
=============================================
[2019-03-24 03:17:29,659] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1103805: loss 0.1342
[2019-03-24 03:17:29,660] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1103805: learning rate 0.0000
[2019-03-24 03:17:29,681] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1103812: loss 0.2951
[2019-03-24 03:17:29,682] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1103812: learning rate 0.0000
[2019-03-24 03:17:29,814] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.5092279e-30 3.3282477e-30 4.2257291e-24 3.7127767e-28], sum to 1.0000
[2019-03-24 03:17:29,820] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4452
[2019-03-24 03:17:29,825] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.55, 49.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5895278884251131, 6.9112, 6.9112, 121.9260426156618, 436763.761748965, 436763.761748965, 128854.9242735935], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1627800.0000, 
sim time next is 1628400.0000, 
raw observation next is [25.4, 49.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5873573544679416, 6.911200000000001, 6.9112, 121.9260426156618, 434869.6162634756, 434869.6162634752, 128474.8528915526], 
processed observation next is [1.0, 0.8695652173913043, 0.49629629629629624, 0.4966666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4841966930849269, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15531057723695557, 0.15531057723695543, 0.2470670247914473], 
reward next is 0.7529, 
noisyNet noise sample is [array([1.1217893], dtype=float32), -0.3887494]. 
=============================================
[2019-03-24 03:17:29,838] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1103888: loss 0.3167
[2019-03-24 03:17:29,840] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1103889: loss 0.2931
[2019-03-24 03:17:29,840] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1103888: learning rate 0.0000
[2019-03-24 03:17:29,842] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1103889: learning rate 0.0000
[2019-03-24 03:17:30,047] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1103982: loss 0.3837
[2019-03-24 03:17:30,049] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1103983: learning rate 0.0000
[2019-03-24 03:17:30,057] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1103986: loss 0.3102
[2019-03-24 03:17:30,058] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1103987: learning rate 0.0000
[2019-03-24 03:17:30,211] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1104066: loss 0.0954
[2019-03-24 03:17:30,215] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1104067: learning rate 0.0000
[2019-03-24 03:17:30,275] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1104096: loss 0.0017
[2019-03-24 03:17:30,278] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1104097: learning rate 0.0000
[2019-03-24 03:17:30,281] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1104099: loss 0.0013
[2019-03-24 03:17:30,289] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1104100: learning rate 0.0000
[2019-03-24 03:17:30,388] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1104151: loss 0.0088
[2019-03-24 03:17:30,388] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1104151: learning rate 0.0000
[2019-03-24 03:17:30,953] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1104423: loss 0.0301
[2019-03-24 03:17:30,955] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1104423: learning rate 0.0000
[2019-03-24 03:17:30,972] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1104430: loss 0.0029
[2019-03-24 03:17:30,973] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1104430: learning rate 0.0000
[2019-03-24 03:17:31,125] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1104501: loss 0.0117
[2019-03-24 03:17:31,127] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1104501: learning rate 0.0000
[2019-03-24 03:17:31,327] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1104600: loss 0.0017
[2019-03-24 03:17:31,329] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1104601: learning rate 0.0000
[2019-03-24 03:17:31,532] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1104706: loss 0.1830
[2019-03-24 03:17:31,535] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1104707: learning rate 0.0000
[2019-03-24 03:17:34,066] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.0801766e-32 9.9410793e-32 1.5802637e-23 2.0622090e-30], sum to 1.0000
[2019-03-24 03:17:34,077] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4140
[2019-03-24 03:17:34,083] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.03333333333333, 82.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9019059129435748, 6.911200000000001, 6.9112, 121.9260426156618, 672048.9774859407, 672048.9774859402, 164599.6558086752], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1735800.0000, 
sim time next is 1736400.0000, 
raw observation next is [20.96666666666667, 82.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7582818178504576, 6.911200000000001, 6.9112, 121.9260426156618, 564927.1576799977, 564927.1576799973, 148083.5171994888], 
processed observation next is [1.0, 0.08695652173913043, 0.3320987654320988, 0.8266666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.697852272313072, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20175969917142778, 0.2017596991714276, 0.2847759946144015], 
reward next is 0.7152, 
noisyNet noise sample is [array([0.8295757], dtype=float32), -1.1381675]. 
=============================================
[2019-03-24 03:17:36,636] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.8246545e-25 1.5012068e-22 7.1201695e-17 9.6259376e-23], sum to 1.0000
[2019-03-24 03:17:36,643] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8525
[2019-03-24 03:17:36,651] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 972903.7281156497 W.
[2019-03-24 03:17:36,655] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.53333333333333, 87.66666666666667, 1.0, 2.0, 0.799196143825388, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 972903.7281156497, 972903.7281156497, 198509.3075248242], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1874400.0000, 
sim time next is 1875000.0000, 
raw observation next is [21.51666666666667, 87.83333333333334, 1.0, 2.0, 0.2753296736173558, 1.0, 1.0, 0.2753296736173558, 1.0, 1.0, 0.4443002415071338, 6.9112, 6.9112, 121.94756008, 990197.9929051863, 990197.9929051863, 246233.6836400871], 
processed observation next is [1.0, 0.6956521739130435, 0.35246913580246925, 0.8783333333333334, 1.0, 1.0, 0.1372972304968521, 1.0, 0.5, 0.1372972304968521, 1.0, 0.5, 0.30537530188391726, 0.0, 0.0, 0.8096049824067558, 0.3536421403232808, 0.3536421403232808, 0.4735263146924752], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7228316], dtype=float32), 0.32356337]. 
=============================================
[2019-03-24 03:17:36,672] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[49.609024]
 [49.59909 ]
 [49.631424]
 [49.232384]
 [49.160206]], R is [[49.31452942]
 [48.82138443]
 [48.33317184]
 [48.48083115]
 [48.5574646 ]].
[2019-03-24 03:17:36,681] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.3801636e-20 8.0080363e-20 3.7911026e-15 4.7934509e-20], sum to 1.0000
[2019-03-24 03:17:36,691] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9554
[2019-03-24 03:17:36,697] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 930130.5325290913 W.
[2019-03-24 03:17:36,701] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.28333333333333, 72.33333333333333, 1.0, 2.0, 0.2570911762727701, 1.0, 2.0, 0.2570911762727701, 1.0, 1.0, 0.4163423465533719, 6.911199999999999, 6.9112, 121.94756008, 930130.5325290913, 930130.5325290918, 239390.6269536173], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1759800.0000, 
sim time next is 1760400.0000, 
raw observation next is [23.4, 72.0, 1.0, 2.0, 0.2564540455111158, 1.0, 2.0, 0.2564540455111158, 1.0, 2.0, 0.414610343832799, 6.911200000000002, 6.9112, 121.94756008, 925280.7796442545, 925280.7796442535, 239256.1869561599], 
processed observation next is [1.0, 0.391304347826087, 0.42222222222222217, 0.72, 1.0, 1.0, 0.11482624465609022, 1.0, 1.0, 0.11482624465609022, 1.0, 1.0, 0.2682629297909987, 1.7763568394002506e-16, 0.0, 0.8096049824067558, 0.33045742130151945, 0.3304574213015191, 0.460108051838769], 
reward next is 0.5399, 
noisyNet noise sample is [array([1.6006577], dtype=float32), 1.0481108]. 
=============================================
[2019-03-24 03:17:41,028] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1109354: loss -33.4176
[2019-03-24 03:17:41,032] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1109354: learning rate 0.0000
[2019-03-24 03:17:41,147] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.7210469e-26 9.4452874e-26 6.6553776e-20 2.5364025e-25], sum to 1.0000
[2019-03-24 03:17:41,153] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3574
[2019-03-24 03:17:41,160] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1544685.124070195 W.
[2019-03-24 03:17:41,167] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.21666666666667, 60.16666666666666, 1.0, 2.0, 0.451554507327029, 1.0, 1.0, 0.451554507327029, 1.0, 2.0, 0.7188894817682472, 6.9112, 6.9112, 121.94756008, 1544685.124070195, 1544685.124070195, 320401.6297210251], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1957800.0000, 
sim time next is 1958400.0000, 
raw observation next is [28.3, 60.0, 1.0, 2.0, 0.4293433400894673, 1.0, 2.0, 0.4293433400894673, 1.0, 2.0, 0.6835285801588331, 6.911199999999999, 6.9112, 121.94756008, 1468631.949637988, 1468631.949637989, 310174.6014604347], 
processed observation next is [1.0, 0.6956521739130435, 0.6037037037037037, 0.6, 1.0, 1.0, 0.32064683343984196, 1.0, 1.0, 0.32064683343984196, 1.0, 1.0, 0.6044107251985413, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5245114105849956, 0.5245114105849961, 0.5964896181931436], 
reward next is 0.4035, 
noisyNet noise sample is [array([-0.07447562], dtype=float32), 0.43317974]. 
=============================================
[2019-03-24 03:17:42,344] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.4590121e-28 4.9005993e-26 1.5496818e-22 9.3624219e-26], sum to 1.0000
[2019-03-24 03:17:42,349] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2088
[2019-03-24 03:17:42,354] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.36666666666667, 88.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6986188611058759, 6.911200000000001, 6.9112, 121.9260426156618, 522067.5453342964, 522067.5453342959, 144797.7270789421], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1878000.0000, 
sim time next is 1878600.0000, 
raw observation next is [21.33333333333333, 88.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6969340790983822, 6.9112, 6.9112, 121.9260426156618, 520809.917261218, 520809.917261218, 144577.791714177], 
processed observation next is [1.0, 0.7391304347826086, 0.3456790123456788, 0.8883333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6211675988729778, 0.0, 0.0, 0.8094621288201359, 0.18600354187900645, 0.18600354187900645, 0.2780342148349558], 
reward next is 0.7220, 
noisyNet noise sample is [array([-0.5246337], dtype=float32), 0.22101003]. 
=============================================
[2019-03-24 03:17:46,176] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1111841: loss 72.8365
[2019-03-24 03:17:46,178] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1111842: learning rate 0.0000
[2019-03-24 03:17:46,248] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1111878: loss 31.9729
[2019-03-24 03:17:46,251] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1111878: learning rate 0.0000
[2019-03-24 03:17:46,344] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1111923: loss 125.5707
[2019-03-24 03:17:46,346] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1111925: learning rate 0.0000
[2019-03-24 03:17:46,471] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1111985: loss 42.6606
[2019-03-24 03:17:46,475] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1111985: learning rate 0.0000
[2019-03-24 03:17:46,535] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1112015: loss 73.3460
[2019-03-24 03:17:46,537] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1112016: learning rate 0.0000
[2019-03-24 03:17:46,540] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1112016: loss 8.2002
[2019-03-24 03:17:46,544] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1112017: learning rate 0.0000
[2019-03-24 03:17:46,579] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1112037: loss -4.5879
[2019-03-24 03:17:46,583] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1112037: learning rate 0.0000
[2019-03-24 03:17:46,624] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1112061: loss 139.8894
[2019-03-24 03:17:46,625] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1112061: learning rate 0.0000
[2019-03-24 03:17:46,663] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1112079: loss 104.3012
[2019-03-24 03:17:46,664] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1112079: learning rate 0.0000
[2019-03-24 03:17:46,820] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.2939641e-28 4.2095374e-27 1.2795452e-17 2.1198430e-24], sum to 1.0000
[2019-03-24 03:17:46,827] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6046
[2019-03-24 03:17:46,834] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 939902.2245810159 W.
[2019-03-24 03:17:46,837] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1112164: loss -33.1079
[2019-03-24 03:17:46,841] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.13333333333333, 86.66666666666667, 1.0, 2.0, 0.390851424698884, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6317997956193692, 6.911199999999999, 6.9112, 121.9260426156618, 939902.2245810159, 939902.2245810163, 219694.8471841039], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1938000.0000, 
sim time next is 1938600.0000, 
raw observation next is [22.25, 86.5, 1.0, 2.0, 0.7620201369454332, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 922777.8427010127, 922777.8427010127, 190624.6637472291], 
processed observation next is [1.0, 0.43478260869565216, 0.37962962962962965, 0.865, 1.0, 1.0, 0.7166906392207538, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3295635152503617, 0.3295635152503617, 0.3665858918215944], 
reward next is 0.6334, 
noisyNet noise sample is [array([0.7000395], dtype=float32), 1.1314543]. 
=============================================
[2019-03-24 03:17:46,844] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1112164: learning rate 0.0000
[2019-03-24 03:17:47,296] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1112386: loss 71.0504
[2019-03-24 03:17:47,298] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1112386: learning rate 0.0000
[2019-03-24 03:17:47,437] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1112454: loss 32.6137
[2019-03-24 03:17:47,439] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1112454: learning rate 0.0000
[2019-03-24 03:17:47,472] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1112474: loss -12.5109
[2019-03-24 03:17:47,474] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1112474: learning rate 0.0000
[2019-03-24 03:17:47,886] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1112677: loss 23.0935
[2019-03-24 03:17:47,888] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1112677: learning rate 0.0000
[2019-03-24 03:17:48,125] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1112796: loss 109.7480
[2019-03-24 03:17:48,128] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1112796: learning rate 0.0000
[2019-03-24 03:17:49,985] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 8.5808116e-30 2.9421279e-28 6.1462392e-25 8.6925067e-28], sum to 1.0000
[2019-03-24 03:17:49,992] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6365
[2019-03-24 03:17:49,998] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.33333333333334, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6084674600366925, 6.911200000000001, 6.9112, 121.9260426156618, 451999.6580332079, 451999.6580332075, 131446.9176104824], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2000400.0000, 
sim time next is 2001000.0000, 
raw observation next is [19.31666666666667, 92.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6081975329206407, 6.911199999999999, 6.9112, 121.9260426156618, 451808.4452332759, 451808.4452332763, 131428.1299481105], 
processed observation next is [0.0, 0.13043478260869565, 0.27098765432098776, 0.9283333333333332, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5102469161508009, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16136015901188425, 0.16136015901188439, 0.2527464037463663], 
reward next is 0.7473, 
noisyNet noise sample is [array([0.517919], dtype=float32), -0.26805183]. 
=============================================
[2019-03-24 03:17:50,021] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[70.43274]
 [70.42394]
 [70.40696]
 [70.45335]
 [70.55019]], R is [[70.44033051]
 [70.48314667]
 [70.52546692]
 [70.56726074]
 [70.60853577]].
[2019-03-24 03:17:50,590] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 6.4171768e-30 1.1819163e-30 1.4561967e-22 1.5205262e-29], sum to 1.0000
[2019-03-24 03:17:50,598] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9215
[2019-03-24 03:17:50,601] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.5, 64.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.839821792305207, 6.9112, 6.9112, 121.9260426156618, 618403.9938132049, 618403.9938132049, 167226.8667354549], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2035200.0000, 
sim time next is 2035800.0000, 
raw observation next is [27.65, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8461780905073077, 6.9112, 6.9112, 121.9260426156618, 622437.6532588879, 622437.6532588879, 168202.185297433], 
processed observation next is [0.0, 0.5652173913043478, 0.5796296296296296, 0.64, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8077226131341347, 0.0, 0.0, 0.8094621288201359, 0.22229916187817425, 0.22229916187817425, 0.3234657409566019], 
reward next is 0.6765, 
noisyNet noise sample is [array([1.446096], dtype=float32), -0.76749355]. 
=============================================
[2019-03-24 03:17:53,515] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 4.6455749e-38 3.0735233e-32 1.6854394e-37], sum to 1.0000
[2019-03-24 03:17:53,522] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1946
[2019-03-24 03:17:53,526] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.91666666666667, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7113629687655626, 6.9112, 6.9112, 121.9260426156618, 531438.348879268, 531438.348879268, 146935.3472600314], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2083800.0000, 
sim time next is 2084400.0000, 
raw observation next is [21.8, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7080814158387939, 6.911200000000001, 6.9112, 121.9260426156618, 529030.5022538377, 529030.5022538372, 146439.1322858296], 
processed observation next is [0.0, 0.13043478260869565, 0.362962962962963, 0.87, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6351017697984923, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18893946509065632, 0.18893946509065615, 0.2816137159342877], 
reward next is 0.7184, 
noisyNet noise sample is [array([-0.8708724], dtype=float32), 1.2354914]. 
=============================================
[2019-03-24 03:17:57,561] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1117416: loss -45.8945
[2019-03-24 03:17:57,562] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1117416: learning rate 0.0000
[2019-03-24 03:18:02,402] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1119785: loss -40.0710
[2019-03-24 03:18:02,404] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1119786: learning rate 0.0000
[2019-03-24 03:18:02,420] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1119792: loss -28.2490
[2019-03-24 03:18:02,425] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1119792: learning rate 0.0000
[2019-03-24 03:18:02,466] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1119815: loss -6.4887
[2019-03-24 03:18:02,468] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1119815: learning rate 0.0000
[2019-03-24 03:18:02,694] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1119932: loss -23.1419
[2019-03-24 03:18:02,697] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1119932: learning rate 0.0000
[2019-03-24 03:18:02,742] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1119954: loss -39.8584
[2019-03-24 03:18:02,743] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1119954: learning rate 0.0000
[2019-03-24 03:18:02,801] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1119981: loss -42.8504
[2019-03-24 03:18:02,805] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1119982: learning rate 0.0000
[2019-03-24 03:18:02,848] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1120008: loss -41.9982
[2019-03-24 03:18:02,851] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1120008: learning rate 0.0000
[2019-03-24 03:18:02,896] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1120030: loss -25.4578
[2019-03-24 03:18:02,898] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1120030: learning rate 0.0000
[2019-03-24 03:18:03,063] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1120112: loss -14.8932
[2019-03-24 03:18:03,067] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1120114: learning rate 0.0000
[2019-03-24 03:18:03,251] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1120202: loss -33.8715
[2019-03-24 03:18:03,254] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1120202: learning rate 0.0000
[2019-03-24 03:18:03,683] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1120413: loss 29.9125
[2019-03-24 03:18:03,685] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1120413: learning rate 0.0000
[2019-03-24 03:18:03,762] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1120456: loss 3.5033
[2019-03-24 03:18:03,766] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1120456: learning rate 0.0000
[2019-03-24 03:18:03,810] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1120474: loss -21.7053
[2019-03-24 03:18:03,816] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1120475: learning rate 0.0000
[2019-03-24 03:18:04,237] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1120683: loss -25.6824
[2019-03-24 03:18:04,239] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1120683: learning rate 0.0000
[2019-03-24 03:18:04,458] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1120792: loss -21.0521
[2019-03-24 03:18:04,459] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1120792: learning rate 0.0000
[2019-03-24 03:18:06,974] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.3481017e-30 2.8592422e-29 3.6863869e-20 1.5590565e-29], sum to 1.0000
[2019-03-24 03:18:06,983] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8207
[2019-03-24 03:18:06,993] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 94.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7863663774434527, 6.911200000000001, 6.9112, 121.9260426156618, 584614.3232041079, 584614.3232041076, 158366.4392089664], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2339400.0000, 
sim time next is 2340000.0000, 
raw observation next is [22.0, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7912937113458182, 6.9112, 6.9112, 121.9260426156618, 588096.0494287006, 588096.0494287006, 159070.4507338653], 
processed observation next is [1.0, 0.08695652173913043, 0.37037037037037035, 0.95, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7391171391822726, 0.0, 0.0, 0.8094621288201359, 0.21003430336739307, 0.21003430336739307, 0.3059047129497409], 
reward next is 0.6941, 
noisyNet noise sample is [array([-2.0176444], dtype=float32), 0.41504985]. 
=============================================
[2019-03-24 03:18:07,019] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[64.6051 ]
 [64.79583]
 [64.91131]
 [65.04272]
 [65.21058]], R is [[64.80660248]
 [64.85398865]
 [64.90206146]
 [64.95044708]
 [64.9990921 ]].
[2019-03-24 03:18:10,927] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.9499271e-25 3.5822552e-24 8.3276440e-20 5.0219285e-25], sum to 1.0000
[2019-03-24 03:18:10,935] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7071
[2019-03-24 03:18:10,940] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.53333333333333, 40.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6633848828664024, 6.9112, 6.9112, 121.9260426156618, 495646.9097925081, 495646.9097925081, 140209.2700462065], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2398200.0000, 
sim time next is 2398800.0000, 
raw observation next is [29.36666666666667, 41.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6670895946139838, 6.911199999999999, 6.9112, 121.9260426156618, 498394.2374046109, 498394.2374046114, 140522.1048425972], 
processed observation next is [1.0, 0.782608695652174, 0.64320987654321, 0.41, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5838619932674797, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17799794193021817, 0.17799794193021837, 0.27023481700499463], 
reward next is 0.7298, 
noisyNet noise sample is [array([-0.5263724], dtype=float32), 1.6844817]. 
=============================================
[2019-03-24 03:18:12,271] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 5.8924489e-27 1.0256317e-26 9.5960302e-21 4.0263587e-26], sum to 1.0000
[2019-03-24 03:18:12,281] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6890
[2019-03-24 03:18:12,285] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.4, 62.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5251363967674607, 6.9112, 6.9112, 121.9260426156618, 380752.5963645385, 380752.5963645385, 119100.6854648837], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2425200.0000, 
sim time next is 2425800.0000, 
raw observation next is [21.25, 62.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5217403138132997, 6.911200000000001, 6.9112, 121.9260426156618, 377177.751376021, 377177.7513760205, 118404.7785099442], 
processed observation next is [1.0, 0.043478260869565216, 0.3425925925925926, 0.6216666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4021753922666245, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13470633977715035, 0.13470633977715019, 0.22770149713450807], 
reward next is 0.7723, 
noisyNet noise sample is [array([1.260147], dtype=float32), -0.28879246]. 
=============================================
[2019-03-24 03:18:13,151] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 03:18:13,152] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:18:13,152] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:18:13,153] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:18:13,153] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:18:13,153] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:18:13,154] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:18:13,154] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:18:13,155] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:18:13,155] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:18:13,155] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:18:13,179] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run46
[2019-03-24 03:18:13,201] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run46
[2019-03-24 03:18:13,223] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run46
[2019-03-24 03:18:13,223] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run46
[2019-03-24 03:18:13,244] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run46
[2019-03-24 03:18:17,725] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00178063], dtype=float32), 0.29445386]
[2019-03-24 03:18:17,727] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [16.5, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.342233865042994, 6.9112, 6.9112, 121.9260426156618, 244340.3505496829, 244340.3505496829, 82354.53344415376]
[2019-03-24 03:18:17,728] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:18:17,733] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.0935226e-33 8.4450635e-32 1.7006918e-25 5.7732424e-32], sampled 0.7324147146570276
[2019-03-24 03:18:39,409] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00178063], dtype=float32), 0.29445386]
[2019-03-24 03:18:39,410] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.78333333333333, 49.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6194335042062088, 6.9112, 6.9112, 121.9260426156618, 462057.1269579526, 462057.1269579526, 134278.1265182227]
[2019-03-24 03:18:39,410] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:18:39,412] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.0237010e-33 4.0688691e-32 1.0912468e-25 2.8927100e-32], sampled 0.5070266394372365
[2019-03-24 03:18:40,594] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00178063], dtype=float32), 0.29445386]
[2019-03-24 03:18:40,595] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.49037629333333, 70.79690798166666, 1.0, 2.0, 0.6624568761140525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 754992.3638500529, 754992.3638500529, 169161.9657406688]
[2019-03-24 03:18:40,596] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:18:40,601] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.1938611e-30 2.4507949e-29 5.8504651e-23 2.6198876e-29], sampled 0.9967340554979127
[2019-03-24 03:18:40,602] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 754992.3638500529 W.
[2019-03-24 03:19:08,156] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00178063], dtype=float32), 0.29445386]
[2019-03-24 03:19:08,156] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 94.0, 1.0, 2.0, 0.6420257949137641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 731696.2475898293, 731696.2475898293, 165459.1078246272]
[2019-03-24 03:19:08,157] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:19:08,160] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.2607921e-31 4.9348442e-30 1.8065293e-23 5.4815784e-30], sampled 0.6167611658402016
[2019-03-24 03:19:08,161] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 731696.2475898293 W.
[2019-03-24 03:19:16,276] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00178063], dtype=float32), 0.29445386]
[2019-03-24 03:19:16,277] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.2, 91.33333333333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.323581009593468, 6.9112, 121.924329975862, 1374121.42121309, 1162948.452397387, 245581.7987173276]
[2019-03-24 03:19:16,278] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:19:16,281] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.4851673e-29 1.5669217e-28 2.0340531e-21 3.4598568e-28], sampled 0.6213397274240517
[2019-03-24 03:19:16,282] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1374121.42121309 W.
[2019-03-24 03:19:16,357] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00178063], dtype=float32), 0.29445386]
[2019-03-24 03:19:16,358] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.85820747333333, 82.09719229333334, 1.0, 2.0, 0.6807636502493555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 775866.8845065042, 775866.8845065042, 172533.2803489471]
[2019-03-24 03:19:16,359] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:19:16,363] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 9.8775939e-28 1.1423868e-26 2.0040856e-20 1.7244114e-26], sampled 0.5216599270996054
[2019-03-24 03:19:16,363] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 775866.8845065042 W.
[2019-03-24 03:19:18,235] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00178063], dtype=float32), 0.29445386]
[2019-03-24 03:19:18,236] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.9670648, 86.50782136, 1.0, 2.0, 0.697986082111005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 795505.4897557567, 795505.4897557567, 175765.2602569517]
[2019-03-24 03:19:18,238] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:19:18,240] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 5.8090615e-29 6.4654913e-28 3.8551423e-21 1.1961924e-27], sampled 0.4995359799263922
[2019-03-24 03:19:18,241] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 795505.4897557567 W.
[2019-03-24 03:19:18,291] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00178063], dtype=float32), 0.29445386]
[2019-03-24 03:19:18,292] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.0, 75.0, 1.0, 2.0, 0.8546538787161575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 974175.6740267192, 974175.6740267192, 207503.3565540314]
[2019-03-24 03:19:18,292] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:19:18,294] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.1527218e-34 2.6319831e-33 1.5385995e-25 4.3297498e-33], sampled 0.6685442863757028
[2019-03-24 03:19:18,295] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 974175.6740267192 W.
[2019-03-24 03:19:28,901] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00178063], dtype=float32), 0.29445386]
[2019-03-24 03:19:28,902] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.6, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9422197960068958, 6.9112, 6.9112, 121.9260426156618, 683784.4718009151, 683784.4718009151, 182640.8262141464]
[2019-03-24 03:19:28,904] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:19:28,906] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 4.1637346e-34 1.6607129e-32 6.0555890e-26 1.2160699e-32], sampled 0.37126378001998384
[2019-03-24 03:19:29,979] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00178063], dtype=float32), 0.29445386]
[2019-03-24 03:19:29,981] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.40835365333334, 56.3171593, 1.0, 2.0, 0.6974132816138897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 794852.3217098032, 794852.3217098027, 175652.8771327439]
[2019-03-24 03:19:29,982] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:19:29,984] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.000000e+00 3.151610e-33 7.185026e-32 1.170934e-24 9.729334e-32], sampled 0.1068252677455156
[2019-03-24 03:19:29,985] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 794852.3217098032 W.
[2019-03-24 03:19:49,844] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00178063], dtype=float32), 0.29445386]
[2019-03-24 03:19:49,845] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.583744305, 64.87649027500001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6115277258604556, 6.911199999999999, 6.9112, 121.9260426156618, 439998.9272862449, 439998.9272862453, 125144.5415871919]
[2019-03-24 03:19:49,847] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:19:49,850] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.1620957e-34 9.0606752e-33 3.5388833e-26 6.5260104e-33], sampled 0.2624563912545599
[2019-03-24 03:19:51,228] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 03:19:51,646] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 03:19:51,754] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 03:19:51,778] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 03:19:51,799] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 03:19:52,815] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1125000, evaluation results [1125000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 03:19:53,542] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1125358: loss -95.5259
[2019-03-24 03:19:53,544] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1125359: learning rate 0.0000
[2019-03-24 03:19:58,505] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.3277216e-26 5.4274730e-25 8.2672877e-19 5.2222582e-25], sum to 1.0000
[2019-03-24 03:19:58,513] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7323
[2019-03-24 03:19:58,515] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1127782: loss -133.0506
[2019-03-24 03:19:58,516] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1127782: learning rate 0.0000
[2019-03-24 03:19:58,526] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1470178.021323208 W.
[2019-03-24 03:19:58,529] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.6, 30.0, 1.0, 2.0, 0.6112965983834134, 1.0, 1.0, 0.6112965983834134, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1470178.021323208, 1470178.021323208, 275266.1286445322], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2548800.0000, 
sim time next is 2549400.0000, 
raw observation next is [32.7, 30.0, 1.0, 2.0, 0.5848348233892136, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9478903059495201, 6.9112, 6.9112, 121.9260426156618, 1412846.367108712, 1412846.367108712, 285747.6827839575], 
processed observation next is [1.0, 0.5217391304347826, 0.7666666666666667, 0.3, 1.0, 1.0, 0.5057557421300162, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9348628824369001, 0.0, 0.0, 0.8094621288201359, 0.5045879882531115, 0.5045879882531115, 0.5495147745845337], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.048391], dtype=float32), 1.4871231]. 
=============================================
[2019-03-24 03:19:58,661] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1127855: loss -33.6770
[2019-03-24 03:19:58,662] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1127855: learning rate 0.0000
[2019-03-24 03:19:58,669] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1127858: loss -42.5334
[2019-03-24 03:19:58,672] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1127858: learning rate 0.0000
[2019-03-24 03:19:58,899] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1127973: loss -72.3945
[2019-03-24 03:19:58,902] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1127974: learning rate 0.0000
[2019-03-24 03:19:58,922] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1127983: loss -93.2382
[2019-03-24 03:19:58,929] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1127984: learning rate 0.0000
[2019-03-24 03:19:58,944] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1127991: loss -22.9149
[2019-03-24 03:19:58,947] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1127991: learning rate 0.0000
[2019-03-24 03:19:59,012] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1128024: loss -76.5248
[2019-03-24 03:19:59,015] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1128026: learning rate 0.0000
[2019-03-24 03:19:59,122] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1128074: loss -73.3965
[2019-03-24 03:19:59,125] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1128074: learning rate 0.0000
[2019-03-24 03:19:59,288] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1128154: loss -82.6132
[2019-03-24 03:19:59,289] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1128154: learning rate 0.0000
[2019-03-24 03:19:59,421] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1128224: loss -72.8085
[2019-03-24 03:19:59,422] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1128224: learning rate 0.0000
[2019-03-24 03:19:59,599] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1128312: loss -103.8307
[2019-03-24 03:19:59,601] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1128312: learning rate 0.0000
[2019-03-24 03:19:59,748] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1128389: loss -134.9776
[2019-03-24 03:19:59,752] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1128389: learning rate 0.0000
[2019-03-24 03:19:59,969] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1128488: loss -104.9726
[2019-03-24 03:19:59,972] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1128489: learning rate 0.0000
[2019-03-24 03:20:00,475] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1128737: loss -23.9982
[2019-03-24 03:20:00,477] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1128737: learning rate 0.0000
[2019-03-24 03:20:00,712] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1128853: loss -122.7753
[2019-03-24 03:20:00,714] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1128853: learning rate 0.0000
[2019-03-24 03:20:05,701] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.5400652e-28 1.6653807e-26 5.4202658e-20 4.1510961e-26], sum to 1.0000
[2019-03-24 03:20:05,711] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0428
[2019-03-24 03:20:05,720] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1088155.241219077 W.
[2019-03-24 03:20:05,726] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.11666666666667, 93.33333333333334, 1.0, 2.0, 0.4772891596744644, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7598598864244792, 6.911199999999999, 6.9112, 121.9259722299014, 1088155.241219077, 1088155.241219077, 249149.3085515831], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2775000.0000, 
sim time next is 2775600.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.8851315690986099, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425941994, 1017414.465863104, 1017414.465863104, 214612.36605489], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.8632518679745356, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621286776479, 0.36336230923682283, 0.36336230923682283, 0.4127160885670962], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.52954733], dtype=float32), -0.7445411]. 
=============================================
[2019-03-24 03:20:10,454] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1133622: loss 1.8312
[2019-03-24 03:20:10,458] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1133622: learning rate 0.0000
[2019-03-24 03:20:14,670] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1135683: loss 0.2843
[2019-03-24 03:20:14,673] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1135684: learning rate 0.0000
[2019-03-24 03:20:14,719] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1135702: loss 1.7432
[2019-03-24 03:20:14,722] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1135702: learning rate 0.0000
[2019-03-24 03:20:14,907] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1135797: loss 1.1172
[2019-03-24 03:20:14,910] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1135798: learning rate 0.0000
[2019-03-24 03:20:15,117] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1135901: loss 0.1658
[2019-03-24 03:20:15,119] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1135902: learning rate 0.0000
[2019-03-24 03:20:15,322] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1136000: loss 0.9325
[2019-03-24 03:20:15,325] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1136000: learning rate 0.0000
[2019-03-24 03:20:15,379] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1136023: loss 0.9856
[2019-03-24 03:20:15,382] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1136024: learning rate 0.0000
[2019-03-24 03:20:15,471] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1136070: loss 0.4623
[2019-03-24 03:20:15,475] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1136071: learning rate 0.0000
[2019-03-24 03:20:15,480] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1136072: loss 0.6900
[2019-03-24 03:20:15,481] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1136072: learning rate 0.0000
[2019-03-24 03:20:15,497] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1136079: loss 0.2983
[2019-03-24 03:20:15,500] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1136080: learning rate 0.0000
[2019-03-24 03:20:15,629] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1136144: loss 0.8640
[2019-03-24 03:20:15,631] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1136146: learning rate 0.0000
[2019-03-24 03:20:15,900] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1136276: loss 0.0884
[2019-03-24 03:20:15,901] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1136276: learning rate 0.0000
[2019-03-24 03:20:16,165] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1136409: loss 0.2748
[2019-03-24 03:20:16,167] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1136409: learning rate 0.0000
[2019-03-24 03:20:16,416] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1136532: loss 0.0907
[2019-03-24 03:20:16,421] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1136532: learning rate 0.0000
[2019-03-24 03:20:16,921] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1136775: loss 0.1810
[2019-03-24 03:20:16,922] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1136775: learning rate 0.0000
[2019-03-24 03:20:17,114] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1136869: loss 0.7851
[2019-03-24 03:20:17,115] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1136869: learning rate 0.0000
[2019-03-24 03:20:18,766] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.1531622e-18 6.9232807e-17 3.2772357e-15 4.0142767e-17], sum to 1.0000
[2019-03-24 03:20:18,772] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2606
[2019-03-24 03:20:18,778] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1266304.825459711 W.
[2019-03-24 03:20:18,781] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.21666666666667, 92.33333333333334, 1.0, 2.0, 0.549358540354507, 1.0, 2.0, 0.549358540354507, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1266304.825459711, 1266304.825459712, 251731.4399905986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2887800.0000, 
sim time next is 2888400.0000, 
raw observation next is [23.43333333333334, 90.66666666666667, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.961245885371399, 6.9112, 121.9218406267946, 1732488.40638964, 1194789.592623933, 247319.2318980642], 
processed observation next is [1.0, 0.43478260869565216, 0.42345679012345705, 0.9066666666666667, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.10500458853713993, 0.0, 0.8094342319838183, 0.6187458594248714, 0.4267105687942618, 0.4756139074962773], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.45921436], dtype=float32), 0.7602862]. 
=============================================
[2019-03-24 03:20:24,745] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 9.6850091e-17 6.7931322e-16 2.4296259e-15 2.4618772e-16], sum to 1.0000
[2019-03-24 03:20:24,756] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2995
[2019-03-24 03:20:24,759] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 875435.7183817013 W.
[2019-03-24 03:20:24,763] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 100.0, 1.0, 2.0, 0.2560259578705095, 1.0, 1.0, 0.2560259578705095, 1.0, 1.0, 0.4076016631131801, 6.911199999999999, 6.9112, 121.94756008, 875435.7183817013, 875435.7183817016, 239772.3356807012], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3038400.0000, 
sim time next is 3039000.0000, 
raw observation next is [25.13333333333334, 98.16666666666667, 1.0, 2.0, 0.4182543730100883, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6658745834260165, 6.911199999999999, 6.9112, 121.9260426156618, 953480.1103014285, 953480.1103014289, 229802.5762330373], 
processed observation next is [1.0, 0.17391304347826086, 0.48641975308642, 0.9816666666666667, 1.0, 1.0, 0.30744568215486695, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.5823432292825206, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.34052861082193875, 0.3405286108219389, 0.44192803121737945], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9436602], dtype=float32), 1.5159391]. 
=============================================
[2019-03-24 03:20:24,776] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[32.53501 ]
 [32.083126]
 [32.140587]
 [32.53656 ]
 [32.48717 ]], R is [[32.73646164]
 [32.40909576]
 [32.7170372 ]
 [33.00056076]
 [33.28671646]].
[2019-03-24 03:20:26,669] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1141513: loss -24.0886
[2019-03-24 03:20:26,670] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1141513: learning rate 0.0000
[2019-03-24 03:20:27,095] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.2526248e-14 5.3351902e-14 3.6309337e-11 4.1849101e-13], sum to 1.0000
[2019-03-24 03:20:27,101] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0604
[2019-03-24 03:20:27,108] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2723884.44319792 W.
[2019-03-24 03:20:27,111] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.9647499937474059, 1.0, 2.0, 0.7957396588501378, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2723884.44319792, 2723884.443197921, 507959.5771747038], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3067200.0000, 
sim time next is 3067800.0000, 
raw observation next is [31.0, 78.33333333333334, 1.0, 2.0, 0.9174646140257275, 1.0, 2.0, 0.7720969689892986, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 122.3240536552102, 2642821.640457357, 2642821.640457357, 492900.4279867457], 
processed observation next is [1.0, 0.5217391304347826, 0.7037037037037037, 0.7833333333333334, 1.0, 1.0, 0.9017435881258661, 1.0, 1.0, 0.7286868678444031, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.812104508220428, 0.9438648715919131, 0.9438648715919131, 0.9478854384360494], 
reward next is 0.0521, 
noisyNet noise sample is [array([0.9017118], dtype=float32), -0.33395964]. 
=============================================
[2019-03-24 03:20:28,033] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.2909209e-15 6.7696466e-15 1.1497697e-13 1.4504452e-14], sum to 1.0000
[2019-03-24 03:20:28,041] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3745
[2019-03-24 03:20:28,049] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1635080.567226939 W.
[2019-03-24 03:20:28,054] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.1, 85.0, 1.0, 2.0, 0.4779537978461855, 1.0, 2.0, 0.4779537978461855, 1.0, 1.0, 0.7609180120396133, 6.9112, 6.9112, 121.94756008, 1635080.567226939, 1635080.567226939, 332900.340603384], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3083400.0000, 
sim time next is 3084000.0000, 
raw observation next is [27.46666666666667, 85.33333333333333, 1.0, 2.0, 0.7270044264926374, 1.0, 2.0, 0.7270044264926374, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1658076.983485826, 1658076.983485826, 314515.4338060934], 
processed observation next is [1.0, 0.6956521739130435, 0.5728395061728396, 0.8533333333333333, 1.0, 1.0, 0.6750052696340921, 1.0, 1.0, 0.6750052696340921, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5921703512449379, 0.5921703512449379, 0.6048373727040258], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.05346404], dtype=float32), 0.14764698]. 
=============================================
[2019-03-24 03:20:28,066] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[28.687075]
 [28.47823 ]
 [28.508118]
 [28.271852]
 [28.23189 ]], R is [[28.31381989]
 [28.03068161]
 [28.17522621]
 [28.26728439]
 [28.25931168]].
[2019-03-24 03:20:30,373] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 3.9404039e-25 5.8239644e-24 5.9046628e-21 1.2993144e-23], sum to 1.0000
[2019-03-24 03:20:30,384] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6850
[2019-03-24 03:20:30,394] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 780302.218261713 W.
[2019-03-24 03:20:30,398] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.5, 1.0, 2.0, 0.684653335386235, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 780302.218261713, 780302.218261713, 173257.538281651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3097800.0000, 
sim time next is 3098400.0000, 
raw observation next is [28.33333333333334, 71.66666666666667, 1.0, 2.0, 0.6746076505158625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768847.3679039475, 768847.3679039475, 171390.8831854957], 
processed observation next is [1.0, 0.8695652173913043, 0.6049382716049385, 0.7166666666666667, 1.0, 1.0, 0.6126281553760268, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27458834567998125, 0.27458834567998125, 0.32959785227979943], 
reward next is 0.6704, 
noisyNet noise sample is [array([0.90404177], dtype=float32), -0.5691671]. 
=============================================
[2019-03-24 03:20:31,178] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1143714: loss -80.6813
[2019-03-24 03:20:31,179] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1143714: learning rate 0.0000
[2019-03-24 03:20:31,243] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1143743: loss 9.0950
[2019-03-24 03:20:31,245] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1143743: learning rate 0.0000
[2019-03-24 03:20:31,393] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1143817: loss -25.4697
[2019-03-24 03:20:31,395] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1143817: learning rate 0.0000
[2019-03-24 03:20:31,607] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1143917: loss 46.8251
[2019-03-24 03:20:31,609] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1143917: learning rate 0.0000
[2019-03-24 03:20:31,767] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1143995: loss 8.3420
[2019-03-24 03:20:31,770] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1143995: learning rate 0.0000
[2019-03-24 03:20:31,855] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1144042: loss 63.6968
[2019-03-24 03:20:31,858] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1144044: learning rate 0.0000
[2019-03-24 03:20:31,913] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1144069: loss -45.8890
[2019-03-24 03:20:31,914] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1144069: learning rate 0.0000
[2019-03-24 03:20:31,922] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1144071: loss 62.6610
[2019-03-24 03:20:31,924] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1144071: learning rate 0.0000
[2019-03-24 03:20:31,951] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1144081: loss -65.0457
[2019-03-24 03:20:31,953] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1144081: learning rate 0.0000
[2019-03-24 03:20:32,053] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1144140: loss 1.7891
[2019-03-24 03:20:32,055] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1144141: learning rate 0.0000
[2019-03-24 03:20:32,248] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1144230: loss 0.0715
[2019-03-24 03:20:32,251] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1144230: learning rate 0.0000
[2019-03-24 03:20:32,739] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1144473: loss -36.2338
[2019-03-24 03:20:32,740] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1144474: learning rate 0.0000
[2019-03-24 03:20:32,916] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1144559: loss -45.4104
[2019-03-24 03:20:32,918] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1144559: learning rate 0.0000
[2019-03-24 03:20:33,580] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1144876: loss -65.0556
[2019-03-24 03:20:33,584] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1144877: learning rate 0.0000
[2019-03-24 03:20:33,619] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1144894: loss 68.7973
[2019-03-24 03:20:33,621] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1144894: learning rate 0.0000
[2019-03-24 03:20:38,168] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.3999153e-35 6.8269487e-33 4.8514472e-30 1.2950529e-32], sum to 1.0000
[2019-03-24 03:20:38,176] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5744
[2019-03-24 03:20:38,182] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 747149.29255941 W.
[2019-03-24 03:20:38,185] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.03333333333333, 92.33333333333334, 1.0, 2.0, 0.3277892207772475, 1.0, 1.0, 0.3277892207772475, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 747149.29255941, 747149.2925594103, 187263.2411936502], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3369000.0000, 
sim time next is 3369600.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3322145073897977, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5288963152357171, 6.911200000000001, 6.9112, 121.9260426156618, 757241.0914981683, 757241.0914981678, 204104.7103331347], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.2050172707021401, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.41112039404464634, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27044324696363153, 0.27044324696363137, 0.3925090583329513], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.35327056], dtype=float32), -1.0186238]. 
=============================================
[2019-03-24 03:20:43,329] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1149613: loss -251.2019
[2019-03-24 03:20:43,331] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1149614: learning rate 0.0000
[2019-03-24 03:20:44,127] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 03:20:44,132] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:20:44,133] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:20:44,133] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:20:44,134] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:20:44,135] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:20:44,135] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:20:44,136] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:20:44,137] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:20:44,137] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:20:44,142] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:20:44,158] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run47
[2019-03-24 03:20:44,158] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run47
[2019-03-24 03:20:44,206] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run47
[2019-03-24 03:20:44,206] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run47
[2019-03-24 03:20:44,207] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run47
[2019-03-24 03:20:52,770] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00651121], dtype=float32), 0.2930215]
[2019-03-24 03:20:52,772] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.86666666666667, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6113510768550375, 6.9112, 6.9112, 121.9260426156618, 447131.9430707164, 447131.9430707164, 127920.1883118029]
[2019-03-24 03:20:52,774] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:20:52,776] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 8.7120193e-22 1.9672807e-20 2.3449906e-19 2.9627958e-20], sampled 0.7603593427487064
[2019-03-24 03:20:56,550] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00651121], dtype=float32), 0.2930215]
[2019-03-24 03:20:56,550] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.93333333333333, 55.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6156690210264959, 6.9112, 6.9112, 121.9260426156618, 457874.0269773288, 457874.0269773288, 132544.3823069979]
[2019-03-24 03:20:56,551] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:20:56,554] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.1624614e-22 3.0131617e-21 3.8935411e-20 4.5985559e-21], sampled 0.11886597567295354
[2019-03-24 03:21:03,027] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00651121], dtype=float32), 0.2930215]
[2019-03-24 03:21:03,028] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.73333333333333, 31.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5956944050591783, 6.911200000000001, 6.9112, 121.9260426156618, 440678.6651728237, 440678.6651728232, 129024.8084113182]
[2019-03-24 03:21:03,030] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:21:03,032] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.8947003e-23 5.4736814e-22 7.8271529e-21 8.5259652e-22], sampled 0.0502470955875709
[2019-03-24 03:21:03,036] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00651121], dtype=float32), 0.2930215]
[2019-03-24 03:21:03,036] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.151573845, 55.53358825166667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5484599284435759, 6.911200000000001, 6.9112, 121.9260426156618, 401100.9235080042, 401100.9235080038, 122411.8340480957]
[2019-03-24 03:21:03,037] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:21:03,039] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 9.9794622e-23 2.6054073e-21 3.4137754e-20 3.9788381e-21], sampled 0.6868338119362907
[2019-03-24 03:21:12,231] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00651121], dtype=float32), 0.2930215]
[2019-03-24 03:21:12,232] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.4, 38.33333333333334, 1.0, 2.0, 0.4855162239597954, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7782959307529181, 6.911200000000001, 6.9112, 121.9258542367147, 1147267.006429828, 1147267.006429827, 251024.5464309864]
[2019-03-24 03:21:12,233] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:21:12,235] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 9.5334749e-17 8.8562991e-16 7.8668092e-15 1.2981158e-15], sampled 0.8317759799044487
[2019-03-24 03:21:12,236] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1147267.006429828 W.
[2019-03-24 03:21:20,278] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00651121], dtype=float32), 0.2930215]
[2019-03-24 03:21:20,279] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.352158425, 89.91352175, 1.0, 2.0, 0.692801855755957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 789593.9037849267, 789593.9037849267, 174787.4005427967]
[2019-03-24 03:21:20,281] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:21:20,282] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.0189740e-18 2.3452883e-17 2.6330602e-16 3.5985943e-17], sampled 0.6448398949451424
[2019-03-24 03:21:20,283] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 789593.9037849267 W.
[2019-03-24 03:21:22,703] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00651121], dtype=float32), 0.2930215]
[2019-03-24 03:21:22,705] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.06666666666667, 90.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7581281517179898, 6.911199999999999, 6.9112, 121.9260426156618, 564985.6132796364, 564985.6132796368, 154045.5620889715]
[2019-03-24 03:21:22,706] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:21:22,708] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.5743841e-22 6.3217428e-21 7.9172468e-20 9.5755526e-21], sampled 0.33037113201183976
[2019-03-24 03:21:58,322] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00651121], dtype=float32), 0.2930215]
[2019-03-24 03:21:58,324] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.0, 79.0, 1.0, 2.0, 0.7077012982029934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806583.8971691951, 806583.8971691951, 177608.3369277785]
[2019-03-24 03:21:58,324] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:21:58,327] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.9475899e-19 4.1443411e-18 4.4844551e-17 6.2440510e-18], sampled 0.6548314507602151
[2019-03-24 03:21:58,328] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 806583.8971691951 W.
[2019-03-24 03:22:07,599] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00651121], dtype=float32), 0.2930215]
[2019-03-24 03:22:07,601] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.7821006, 61.45272403999999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4601840213654706, 6.9112, 6.9112, 121.9260426156618, 328569.7578270808, 328569.7578270808, 96504.74112120587]
[2019-03-24 03:22:07,602] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:22:07,609] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.8657404e-21 4.0105820e-20 4.6146928e-19 5.9970103e-20], sampled 0.5076443755183441
[2019-03-24 03:22:11,492] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00651121], dtype=float32), 0.2930215]
[2019-03-24 03:22:11,493] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.03727413333333, 76.74695312, 1.0, 2.0, 0.814424098484578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 933097.6790673053, 933097.6790673053, 199189.9656031461]
[2019-03-24 03:22:11,494] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:22:11,499] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.5908049e-16 2.3177638e-15 1.8805453e-14 3.3182835e-15], sampled 0.7090014761764525
[2019-03-24 03:22:11,500] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 933097.6790673053 W.
[2019-03-24 03:22:22,646] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 03:22:22,982] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 03:22:23,023] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 03:22:23,120] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 03:22:23,313] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 03:22:24,329] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1150000, evaluation results [1150000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 03:22:25,029] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.1267127e-12 2.2060596e-12 8.3219660e-11 2.1006408e-12], sum to 1.0000
[2019-03-24 03:22:25,035] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8803
[2019-03-24 03:22:25,040] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1809214.665986651 W.
[2019-03-24 03:22:25,044] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.2, 78.00000000000001, 1.0, 2.0, 0.7932055790458677, 1.0, 2.0, 0.7932055790458677, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1809214.665986651, 1809214.665986651, 340954.4207325857], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3402600.0000, 
sim time next is 3403200.0000, 
raw observation next is [27.4, 77.0, 1.0, 2.0, 0.7928830614479606, 1.0, 2.0, 0.7928830614479606, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1808478.294121933, 1808478.294121933, 340821.9722761881], 
processed observation next is [1.0, 0.391304347826087, 0.5703703703703703, 0.77, 1.0, 1.0, 0.753432216009477, 1.0, 1.0, 0.753432216009477, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6458851050435475, 0.6458851050435475, 0.6554268697619001], 
reward next is 0.3446, 
noisyNet noise sample is [array([-0.12130456], dtype=float32), -0.8589631]. 
=============================================
[2019-03-24 03:22:27,685] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.7457728e-23 4.2296343e-23 1.4947348e-19 1.8585923e-23], sum to 1.0000
[2019-03-24 03:22:27,692] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8546
[2019-03-24 03:22:27,696] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2131543.951308532 W.
[2019-03-24 03:22:27,700] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.4, 59.33333333333333, 1.0, 2.0, 0.9343544630229286, 1.0, 2.0, 0.9343544630229286, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2131543.951308532, 2131543.951308532, 402399.6292808139], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3422400.0000, 
sim time next is 3423000.0000, 
raw observation next is [31.7, 59.16666666666667, 1.0, 2.0, 0.6549561898546012, 1.0, 2.0, 0.6408427569037353, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2193007.934024192, 2193007.934024193, 417355.3579591708], 
processed observation next is [1.0, 0.6086956521739131, 0.7296296296296296, 0.5916666666666667, 1.0, 1.0, 0.5892335593507158, 1.0, 1.0, 0.5724318534568277, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7832171192943542, 0.7832171192943546, 0.80260645761379], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5709702], dtype=float32), -0.9590353]. 
=============================================
[2019-03-24 03:22:27,722] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[44.544907]
 [44.215157]
 [44.610985]
 [44.353714]
 [44.16622 ]], R is [[43.82118225]
 [43.38297272]
 [43.17534637]
 [43.00423431]
 [42.85005951]].
[2019-03-24 03:22:27,771] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1151676: loss -97.8267
[2019-03-24 03:22:27,776] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1151679: learning rate 0.0000
[2019-03-24 03:22:27,926] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1151752: loss -156.8502
[2019-03-24 03:22:27,928] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1151754: learning rate 0.0000
[2019-03-24 03:22:27,996] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1151777: loss -162.4971
[2019-03-24 03:22:27,996] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1151777: learning rate 0.0000
[2019-03-24 03:22:28,260] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1151911: loss -144.0484
[2019-03-24 03:22:28,261] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1151911: learning rate 0.0000
[2019-03-24 03:22:28,290] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1151924: loss -133.4492
[2019-03-24 03:22:28,292] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1151924: learning rate 0.0000
[2019-03-24 03:22:28,339] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1151941: loss -142.8027
[2019-03-24 03:22:28,342] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1151941: learning rate 0.0000
[2019-03-24 03:22:28,434] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1151993: loss -225.1258
[2019-03-24 03:22:28,437] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1151993: learning rate 0.0000
[2019-03-24 03:22:28,691] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1152069: loss -88.8484
[2019-03-24 03:22:28,693] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1152069: learning rate 0.0000
[2019-03-24 03:22:28,744] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1152093: loss -81.6182
[2019-03-24 03:22:28,747] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1152093: learning rate 0.0000
[2019-03-24 03:22:28,936] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1152188: loss -7.6486
[2019-03-24 03:22:28,937] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1152188: learning rate 0.0000
[2019-03-24 03:22:28,988] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1152213: loss -163.2582
[2019-03-24 03:22:28,990] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1152213: learning rate 0.0000
[2019-03-24 03:22:29,645] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1152528: loss -120.6837
[2019-03-24 03:22:29,649] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1152528: learning rate 0.0000
[2019-03-24 03:22:29,684] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1152550: loss -100.2138
[2019-03-24 03:22:29,688] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1152551: learning rate 0.0000
[2019-03-24 03:22:30,196] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1152802: loss -74.0652
[2019-03-24 03:22:30,199] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1152802: learning rate 0.0000
[2019-03-24 03:22:30,390] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1152894: loss -58.4499
[2019-03-24 03:22:30,392] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1152894: learning rate 0.0000
[2019-03-24 03:22:31,204] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.6907276e-13 1.5587132e-12 2.2623509e-11 2.0512359e-12], sum to 1.0000
[2019-03-24 03:22:31,211] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7283
[2019-03-24 03:22:31,224] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1933163.105269433 W.
[2019-03-24 03:22:31,227] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.00000000e+00 8.13544978e-12 1.46955313e-11 1.61036379e-10
 1.25959625e-11], sum to 1.0000
[2019-03-24 03:22:31,228] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.16666666666666, 84.83333333333333, 1.0, 2.0, 0.5649927553296372, 1.0, 2.0, 0.5649927553296372, 1.0, 1.0, 0.8994868670142157, 6.911200000000001, 6.9112, 121.94756008, 1933163.105269433, 1933163.105269432, 376632.025562169], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3513000.0000, 
sim time next is 3513600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.8258286596455954, 1.0, 2.0, 0.8258286596455954, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1883702.788364673, 1883702.788364673, 354543.0245223832], 
processed observation next is [1.0, 0.6956521739130435, 0.5555555555555556, 0.84, 1.0, 1.0, 0.7926531662447563, 1.0, 1.0, 0.7926531662447563, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6727509958445261, 0.6727509958445261, 0.6818135086968907], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13369606], dtype=float32), 1.9164616]. 
=============================================
[2019-03-24 03:22:31,233] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2718
[2019-03-24 03:22:31,248] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 951743.1024782661 W.
[2019-03-24 03:22:31,251] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.16666666666666, 99.00000000000001, 1.0, 2.0, 0.4174928885879916, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6646622754262222, 6.911199999999999, 6.9112, 121.9260426156618, 951743.1024782661, 951743.1024782666, 229559.6820358253], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3471000.0000, 
sim time next is 3471600.0000, 
raw observation next is [24.33333333333333, 98.0, 1.0, 2.0, 0.2630807953586092, 1.0, 1.0, 0.2630807953586092, 1.0, 2.0, 0.4188331941542515, 6.911199999999999, 6.9112, 121.94756008, 899572.6488408865, 899572.6488408869, 242311.5531700506], 
processed observation next is [1.0, 0.17391304347826086, 0.45679012345678993, 0.98, 1.0, 1.0, 0.12271523256977283, 1.0, 0.5, 0.12271523256977283, 1.0, 1.0, 0.27354149269281436, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.32127594601460235, 0.32127594601460246, 0.4659837560962512], 
reward next is 0.5340, 
noisyNet noise sample is [array([-0.6502445], dtype=float32), -0.055956043]. 
=============================================
[2019-03-24 03:22:31,582] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.00000000e+00 1.60654649e-11 7.14117723e-11 2.16897966e-09
 1.06407695e-10], sum to 1.0000
[2019-03-24 03:22:31,588] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9144
[2019-03-24 03:22:31,596] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 877249.8887382353 W.
[2019-03-24 03:22:31,600] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 94.00000000000001, 1.0, 2.0, 0.2565562184777547, 1.0, 2.0, 0.2565562184777547, 1.0, 1.0, 0.4084458552692969, 6.911199999999999, 6.9112, 121.94756008, 877249.8887382353, 877249.8887382358, 239962.2242684641], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3478200.0000, 
sim time next is 3478800.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3374663598150442, 1.0, 2.0, 0.3374663598150442, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769218.0336360091, 769218.0336360091, 189694.8688366732], 
processed observation next is [1.0, 0.2608695652173913, 0.48148148148148145, 0.94, 1.0, 1.0, 0.21126947597029072, 1.0, 1.0, 0.21126947597029072, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2747207262985747, 0.2747207262985747, 0.36479782468591004], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3362832], dtype=float32), -0.38988352]. 
=============================================
[2019-03-24 03:22:34,454] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.6989764e-18 6.7956912e-18 1.8269802e-16 1.0393738e-18], sum to 1.0000
[2019-03-24 03:22:34,462] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8763
[2019-03-24 03:22:34,467] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 93.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9069414605620538, 6.911199999999999, 6.9112, 121.9260426156618, 669125.4269153902, 669125.4269153905, 175540.4384458815], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3567000.0000, 
sim time next is 3567600.0000, 
raw observation next is [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9130023901741355, 6.9112, 6.9112, 121.9260426156618, 672755.6473275264, 672755.6473275264, 176587.4446153484], 
processed observation next is [1.0, 0.30434782608695654, 0.4074074074074074, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8912529877176695, 0.0, 0.0, 0.8094621288201359, 0.24026987404554512, 0.24026987404554512, 0.33959123964490073], 
reward next is 0.6604, 
noisyNet noise sample is [array([0.33839616], dtype=float32), -0.70932126]. 
=============================================
[2019-03-24 03:22:35,894] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.8791464e-22 5.2192247e-20 2.2936069e-19 1.5977110e-20], sum to 1.0000
[2019-03-24 03:22:35,901] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5373
[2019-03-24 03:22:35,908] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1492574.218682191 W.
[2019-03-24 03:22:35,910] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.6545036873497401, 1.0, 1.0, 0.6545036873497401, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1492574.218682191, 1492574.218682191, 287299.2780283585], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3598800.0000, 
sim time next is 3599400.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.6516294231534945, 1.0, 2.0, 0.6516294231534945, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1486013.193681024, 1486013.193681025, 286257.9249070873], 
processed observation next is [1.0, 0.6521739130434783, 0.48148148148148145, 0.83, 1.0, 1.0, 0.5852731228017791, 1.0, 1.0, 0.5852731228017791, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5307189977432228, 0.5307189977432232, 0.5504960094367063], 
reward next is 0.4495, 
noisyNet noise sample is [array([-1.3007666], dtype=float32), -0.7145047]. 
=============================================
[2019-03-24 03:22:40,051] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1157617: loss 12.4046
[2019-03-24 03:22:40,052] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1157618: learning rate 0.0000
[2019-03-24 03:22:44,238] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1159665: loss 14.7318
[2019-03-24 03:22:44,240] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1159665: learning rate 0.0000
[2019-03-24 03:22:44,380] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1159739: loss -21.9799
[2019-03-24 03:22:44,382] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1159739: learning rate 0.0000
[2019-03-24 03:22:44,494] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1159791: loss -18.5838
[2019-03-24 03:22:44,495] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1159792: learning rate 0.0000
[2019-03-24 03:22:44,540] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1159811: loss -37.3730
[2019-03-24 03:22:44,544] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1159813: learning rate 0.0000
[2019-03-24 03:22:44,878] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1159973: loss -5.8360
[2019-03-24 03:22:44,878] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1159973: learning rate 0.0000
[2019-03-24 03:22:44,922] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1159989: loss -36.0451
[2019-03-24 03:22:44,924] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1159989: learning rate 0.0000
[2019-03-24 03:22:44,972] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1160018: loss 6.9059
[2019-03-24 03:22:44,974] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1160019: learning rate 0.0000
[2019-03-24 03:22:45,015] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1160042: loss -11.5891
[2019-03-24 03:22:45,018] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1160043: learning rate 0.0000
[2019-03-24 03:22:45,161] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1160112: loss 11.2991
[2019-03-24 03:22:45,163] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1160112: learning rate 0.0000
[2019-03-24 03:22:45,189] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1160124: loss -24.2729
[2019-03-24 03:22:45,190] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1160124: learning rate 0.0000
[2019-03-24 03:22:45,470] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1160256: loss -7.3846
[2019-03-24 03:22:45,471] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1160257: learning rate 0.0000
[2019-03-24 03:22:45,486] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 4.4634151e-23 3.9585946e-22 2.1060502e-18 1.9063011e-22], sum to 1.0000
[2019-03-24 03:22:45,493] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1242
[2019-03-24 03:22:45,503] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 842894.1256150671 W.
[2019-03-24 03:22:45,509] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.2, 59.0, 1.0, 2.0, 0.3697712953427746, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5886879447960481, 6.911199999999999, 6.9112, 121.9260426156111, 842894.1256150671, 842894.1256150675, 214962.2597137759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3778200.0000, 
sim time next is 3778800.0000, 
raw observation next is [33.46666666666667, 55.0, 1.0, 2.0, 0.7250516052752377, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 826369.1123070301, 826369.1123070297, 180946.2376455415], 
processed observation next is [1.0, 0.7391304347826086, 0.7950617283950618, 0.55, 1.0, 1.0, 0.672680482470521, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2951318258239393, 0.29513182582393915, 0.34797353393373365], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3548383], dtype=float32), -0.7609135]. 
=============================================
[2019-03-24 03:22:46,067] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1160549: loss 10.2759
[2019-03-24 03:22:46,068] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1160549: learning rate 0.0000
[2019-03-24 03:22:46,212] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1160621: loss -26.5221
[2019-03-24 03:22:46,215] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1160621: learning rate 0.0000
[2019-03-24 03:22:46,545] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1160786: loss -66.8293
[2019-03-24 03:22:46,548] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1160787: learning rate 0.0000
[2019-03-24 03:22:46,655] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1160837: loss -28.4608
[2019-03-24 03:22:46,657] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1160838: learning rate 0.0000
[2019-03-24 03:22:56,374] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1165584: loss 108.8190
[2019-03-24 03:22:56,376] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1165585: learning rate 0.0000
[2019-03-24 03:22:59,689] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 3.9547467e-14 1.4633793e-12 5.2421227e-12 7.7522434e-13], sum to 1.0000
[2019-03-24 03:22:59,693] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6210
[2019-03-24 03:22:59,701] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1039062.569768817 W.
[2019-03-24 03:22:59,713] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 93.0, 1.0, 2.0, 0.4557706097945649, 1.0, 1.0, 0.4557706097945649, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1039062.569768817, 1039062.569768816, 222042.9878792339], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3996000.0000, 
sim time next is 3996600.0000, 
raw observation next is [24.56666666666667, 93.16666666666667, 1.0, 2.0, 0.8314382400468056, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 947697.0075639188, 947697.0075639188, 202514.2030070716], 
processed observation next is [1.0, 0.2608695652173913, 0.46543209876543223, 0.9316666666666668, 1.0, 1.0, 0.799331238150959, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33846321698711385, 0.33846321698711385, 0.3894503903982146], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0632787], dtype=float32), -1.0440216]. 
=============================================
[2019-03-24 03:23:00,738] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1167712: loss 16.6535
[2019-03-24 03:23:00,739] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1167712: learning rate 0.0000
[2019-03-24 03:23:00,743] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1167714: loss 91.9974
[2019-03-24 03:23:00,746] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1167716: learning rate 0.0000
[2019-03-24 03:23:00,933] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1167810: loss 42.4561
[2019-03-24 03:23:00,937] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1167810: learning rate 0.0000
[2019-03-24 03:23:01,109] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1167895: loss -17.6892
[2019-03-24 03:23:01,110] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1167895: learning rate 0.0000
[2019-03-24 03:23:01,207] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1167944: loss 45.9741
[2019-03-24 03:23:01,209] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1167944: learning rate 0.0000
[2019-03-24 03:23:01,250] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1167962: loss -64.2716
[2019-03-24 03:23:01,252] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1167963: learning rate 0.0000
[2019-03-24 03:23:01,375] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1168027: loss -110.3998
[2019-03-24 03:23:01,378] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1168028: learning rate 0.0000
[2019-03-24 03:23:01,420] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1168045: loss 32.8897
[2019-03-24 03:23:01,422] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1168045: learning rate 0.0000
[2019-03-24 03:23:01,503] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1168084: loss -90.5785
[2019-03-24 03:23:01,507] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1168086: learning rate 0.0000
[2019-03-24 03:23:01,576] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1168119: loss 59.8390
[2019-03-24 03:23:01,577] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1168119: learning rate 0.0000
[2019-03-24 03:23:02,104] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1168375: loss -126.2649
[2019-03-24 03:23:02,106] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1168375: learning rate 0.0000
[2019-03-24 03:23:02,497] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1168571: loss -130.0783
[2019-03-24 03:23:02,500] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1168571: learning rate 0.0000
[2019-03-24 03:23:03,011] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1168817: loss -115.0515
[2019-03-24 03:23:03,014] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1168817: learning rate 0.0000
[2019-03-24 03:23:03,103] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1168865: loss 81.7371
[2019-03-24 03:23:03,105] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1168866: learning rate 0.0000
[2019-03-24 03:23:03,243] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1168935: loss -8.5823
[2019-03-24 03:23:03,248] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1168936: learning rate 0.0000
[2019-03-24 03:23:04,450] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.6675955e-24 2.3186953e-20 4.6620186e-21 1.5967041e-22], sum to 1.0000
[2019-03-24 03:23:04,456] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6546
[2019-03-24 03:23:04,460] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.6, 77.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8484217371904779, 6.9112, 6.9112, 121.9260426156618, 620558.9171944353, 620558.9171944353, 169281.4179023054], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4123800.0000, 
sim time next is 4124400.0000, 
raw observation next is [24.4, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8175040132797842, 6.911200000000001, 6.9112, 121.9260426156618, 603134.7000894673, 603134.7000894669, 164060.0525074487], 
processed observation next is [1.0, 0.7391304347826086, 0.4592592592592592, 0.8066666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7718800165997303, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21540525003195263, 0.21540525003195246, 0.3155001009758629], 
reward next is 0.6845, 
noisyNet noise sample is [array([1.8485464], dtype=float32), -1.2952732]. 
=============================================
[2019-03-24 03:23:07,619] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 5.1385564e-30 2.2172962e-28 6.6434976e-30 2.0759834e-29], sum to 1.0000
[2019-03-24 03:23:07,627] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6005
[2019-03-24 03:23:07,632] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7389321470284195, 6.9112, 6.9112, 121.9260426156618, 551674.3193541915, 551674.3193541915, 150748.7744354657], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4170600.0000, 
sim time next is 4171200.0000, 
raw observation next is [21.33333333333334, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7512982496418321, 6.911199999999999, 6.9112, 121.9260426156618, 560446.5946044732, 560446.5946044737, 152740.434444339], 
processed observation next is [1.0, 0.2608695652173913, 0.3456790123456792, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6891228120522902, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20015949807302616, 0.20015949807302633, 0.2937316047006519], 
reward next is 0.7063, 
noisyNet noise sample is [array([-0.55237156], dtype=float32), 1.1661732]. 
=============================================
[2019-03-24 03:23:10,239] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 6.1324776e-37 2.2202687e-34 3.2090058e-32 3.3117911e-33], sum to 1.0000
[2019-03-24 03:23:10,245] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0485
[2019-03-24 03:23:10,253] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.13333333333333, 59.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8828263198381749, 6.9112, 6.9112, 121.9260426156618, 646108.8661326368, 646108.8661326368, 173673.3159213982], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4222200.0000, 
sim time next is 4222800.0000, 
raw observation next is [29.0, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.917471923738955, 6.9112, 6.9112, 121.9260426156618, 667303.5507137891, 667303.5507137891, 179029.2178959782], 
processed observation next is [1.0, 0.9130434782608695, 0.6296296296296297, 0.62, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8968399046736938, 0.0, 0.0, 0.8094621288201359, 0.2383226966834961, 0.2383226966834961, 0.34428695749226573], 
reward next is 0.6557, 
noisyNet noise sample is [array([-0.09761664], dtype=float32), -0.14375524]. 
=============================================
[2019-03-24 03:23:10,718] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 4.0847981e-30 1.1276657e-26 2.5051973e-26 7.2492981e-28], sum to 1.0000
[2019-03-24 03:23:10,725] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4976
[2019-03-24 03:23:10,730] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8105243777882681, 6.911200000000001, 6.9112, 121.9260426156618, 602390.7041604364, 602390.7041604359, 161462.7111188758], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4228200.0000, 
sim time next is 4228800.0000, 
raw observation next is [26.0, 63.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7814577261184339, 6.911200000000001, 6.9112, 121.9260426156618, 582381.4739451443, 582381.4739451439, 156839.6860473413], 
processed observation next is [1.0, 0.9565217391304348, 0.5185185185185185, 0.6333333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7268221576480424, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20799338355183727, 0.2079933835518371, 0.3016147808602717], 
reward next is 0.6984, 
noisyNet noise sample is [array([-0.23339376], dtype=float32), 0.24862634]. 
=============================================
[2019-03-24 03:23:12,562] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1173473: loss -18.8002
[2019-03-24 03:23:12,568] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1173473: learning rate 0.0000
[2019-03-24 03:23:13,147] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.5399655e-25 1.3216498e-23 3.3113927e-22 1.6147236e-23], sum to 1.0000
[2019-03-24 03:23:13,158] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9992
[2019-03-24 03:23:13,169] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.4, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6971516728572822, 6.911199999999999, 6.9112, 121.9260426156618, 520974.327480688, 520974.3274806884, 144439.0987625931], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4240800.0000, 
sim time next is 4241400.0000, 
raw observation next is [24.0, 68.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9556908454261173, 9.129880282669331, 6.9112, 122.0496423611125, 1852081.072211578, 714766.7051551132, 169099.5304636139], 
processed observation next is [1.0, 0.08695652173913043, 0.4444444444444444, 0.6883333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9446135567826466, 0.22186802826693314, 0.0, 0.8102827025952525, 0.6614575257898493, 0.2552738232696833, 0.325191404737719], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.43460184], dtype=float32), 1.0426561]. 
=============================================
[2019-03-24 03:23:15,722] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 03:23:15,723] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:23:15,724] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:23:15,724] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:23:15,725] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:23:15,725] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:23:15,726] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:23:15,727] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:23:15,727] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:23:15,728] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:23:15,729] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:23:15,749] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run48
[2019-03-24 03:23:15,749] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run48
[2019-03-24 03:23:15,797] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run48
[2019-03-24 03:23:15,822] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run48
[2019-03-24 03:23:15,823] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run48
[2019-03-24 03:23:29,279] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00937963], dtype=float32), 0.29471028]
[2019-03-24 03:23:29,279] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.31666666666667, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4522572858401382, 6.9112, 6.9112, 121.9260426156618, 322908.9053485381, 322908.9053485381, 89267.4833364016]
[2019-03-24 03:23:29,280] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:23:29,284] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.3463098e-22 2.6031136e-20 1.8902643e-19 1.1044499e-20], sampled 0.38649620649686134
[2019-03-24 03:23:31,838] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00937963], dtype=float32), 0.29471028]
[2019-03-24 03:23:31,839] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.85, 25.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6052256045801272, 6.911200000000001, 6.9112, 121.9260426156618, 444719.8286648262, 444719.8286648257, 128314.0272146919]
[2019-03-24 03:23:31,840] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:23:31,843] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.5407457e-24 1.2406532e-21 1.0220884e-20 4.9964647e-22], sampled 0.28389658692091047
[2019-03-24 03:24:00,302] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00937963], dtype=float32), 0.29471028]
[2019-03-24 03:24:00,303] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.2, 59.33333333333333, 1.0, 2.0, 0.9476496022207587, 1.0, 2.0, 0.9476496022207587, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2161910.88716102, 2161910.88716102, 408546.0578621977]
[2019-03-24 03:24:00,304] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:24:00,306] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.2418290e-26 6.0371430e-24 6.2040048e-23 2.0947783e-24], sampled 0.749661265808352
[2019-03-24 03:24:00,307] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2161910.88716102 W.
[2019-03-24 03:24:04,034] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00937963], dtype=float32), 0.29471028]
[2019-03-24 03:24:04,034] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.05837787666667, 92.69186067833334, 1.0, 2.0, 0.9426517975808995, 1.0, 2.0, 0.9426517975808995, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2150495.465230505, 2150495.465230505, 406229.3824380699]
[2019-03-24 03:24:04,035] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:24:04,037] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.6263117e-19 1.2629652e-17 7.4499281e-17 5.7168727e-18], sampled 0.3409660612298614
[2019-03-24 03:24:04,038] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2150495.465230505 W.
[2019-03-24 03:24:34,572] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00937963], dtype=float32), 0.29471028]
[2019-03-24 03:24:34,573] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.3, 89.0, 1.0, 2.0, 0.9038374308001571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1030275.144814337, 1030275.144814337, 218326.5796852445]
[2019-03-24 03:24:34,574] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:24:34,577] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.0037625e-19 8.9492753e-18 5.2372021e-17 4.1493398e-18], sampled 0.17772473096957453
[2019-03-24 03:24:34,578] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1030275.144814337 W.
[2019-03-24 03:24:36,662] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00937963], dtype=float32), 0.29471028]
[2019-03-24 03:24:36,665] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.1, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4913941132404097, 6.911199999999999, 6.9112, 121.9260426156618, 350858.7498424756, 350858.749842476, 112751.8922847858]
[2019-03-24 03:24:36,666] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:24:36,669] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.1612242e-23 2.9617884e-21 2.3316897e-20 1.2054262e-21], sampled 0.5612357142840371
[2019-03-24 03:24:54,250] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 03:24:54,282] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 03:24:54,369] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 03:24:54,410] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 03:24:54,419] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 03:24:55,434] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1175000, evaluation results [1175000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 03:24:56,750] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1175638: loss -14.8903
[2019-03-24 03:24:56,751] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1175638: learning rate 0.0000
[2019-03-24 03:24:57,068] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1175797: loss -12.0348
[2019-03-24 03:24:57,070] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1175797: learning rate 0.0000
[2019-03-24 03:24:57,078] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1175798: loss -6.2244
[2019-03-24 03:24:57,079] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1175798: learning rate 0.0000
[2019-03-24 03:24:57,288] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1175899: loss -6.2757
[2019-03-24 03:24:57,290] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1175900: learning rate 0.0000
[2019-03-24 03:24:57,388] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1175950: loss -6.9907
[2019-03-24 03:24:57,391] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1175950: learning rate 0.0000
[2019-03-24 03:24:57,413] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1175962: loss -15.6461
[2019-03-24 03:24:57,416] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1175963: learning rate 0.0000
[2019-03-24 03:24:57,418] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1175963: loss -16.5336
[2019-03-24 03:24:57,422] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1175964: learning rate 0.0000
[2019-03-24 03:24:57,523] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1176015: loss 7.8184
[2019-03-24 03:24:57,526] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1176015: learning rate 0.0000
[2019-03-24 03:24:57,627] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1176062: loss -8.3296
[2019-03-24 03:24:57,629] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1176062: learning rate 0.0000
[2019-03-24 03:24:57,679] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1176087: loss 31.9803
[2019-03-24 03:24:57,680] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1176087: learning rate 0.0000
[2019-03-24 03:24:58,150] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.00000000e+00 3.09340031e-18 2.44673706e-17 7.25008904e-16
 1.09706136e-17], sum to 1.0000
[2019-03-24 03:24:58,154] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2252
[2019-03-24 03:24:58,161] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2136471.299120362 W.
[2019-03-24 03:24:58,168] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.9, 53.0, 1.0, 2.0, 0.6243413095699873, 1.0, 2.0, 0.6243413095699873, 1.0, 2.0, 0.9939716982123257, 6.911200000000001, 6.9112, 121.94756008, 2136471.299120362, 2136471.299120362, 408797.4077653938], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4370400.0000, 
sim time next is 4371000.0000, 
raw observation next is [32.08333333333333, 53.0, 1.0, 2.0, 0.6579500174890243, 1.0, 2.0, 0.6423396707209467, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2198136.780624002, 2198136.780624002, 418131.664929464], 
processed observation next is [1.0, 0.6086956521739131, 0.743827160493827, 0.53, 1.0, 1.0, 0.592797639867886, 1.0, 1.0, 0.5742138937154126, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.785048850222858, 0.785048850222858, 0.8040993556335846], 
reward next is 0.1959, 
noisyNet noise sample is [array([-0.62832063], dtype=float32), -2.0316746]. 
=============================================
[2019-03-24 03:24:58,181] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1176331: loss -5.7692
[2019-03-24 03:24:58,186] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1176332: learning rate 0.0000
[2019-03-24 03:24:58,188] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[35.89605 ]
 [35.491013]
 [35.593597]
 [35.26423 ]
 [34.917007]], R is [[35.6137352 ]
 [35.47145081]
 [35.11673737]
 [34.76557159]
 [34.41791534]].
[2019-03-24 03:24:58,498] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.0477894e-18 1.5073802e-16 3.7219051e-15 1.6187877e-16], sum to 1.0000
[2019-03-24 03:24:58,506] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5301
[2019-03-24 03:24:58,510] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2298233.818588557 W.
[2019-03-24 03:24:58,521] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.6, 49.0, 1.0, 2.0, 1.007328431143811, 1.0, 2.0, 1.007328431143811, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2298233.818588557, 2298233.818588558, 436872.8725593999], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4381200.0000, 
sim time next is 4381800.0000, 
raw observation next is [32.33333333333334, 50.66666666666667, 1.0, 2.0, 0.446210344313766, 1.0, 2.0, 0.446210344313766, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1017252.677550642, 1017252.677550642, 219249.0835132822], 
processed observation next is [1.0, 0.7391304347826086, 0.7530864197530868, 0.5066666666666667, 1.0, 1.0, 0.340726600373531, 1.0, 1.0, 0.340726600373531, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3633045276966579, 0.3633045276966579, 0.4216328529101581], 
reward next is 0.5784, 
noisyNet noise sample is [array([-1.6224792], dtype=float32), -2.9986873]. 
=============================================
[2019-03-24 03:24:58,549] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1176509: loss -51.3753
[2019-03-24 03:24:58,550] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1176511: learning rate 0.0000
[2019-03-24 03:24:59,054] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1176753: loss 25.6222
[2019-03-24 03:24:59,055] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1176753: learning rate 0.0000
[2019-03-24 03:24:59,088] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1176772: loss -9.3409
[2019-03-24 03:24:59,093] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1176774: learning rate 0.0000
[2019-03-24 03:24:59,115] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1176782: loss 2.0666
[2019-03-24 03:24:59,116] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1176782: learning rate 0.0000
[2019-03-24 03:25:01,433] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.6951125e-28 3.6355321e-24 2.3504669e-23 3.4103953e-25], sum to 1.0000
[2019-03-24 03:25:01,443] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3994
[2019-03-24 03:25:01,446] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.26666666666667, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7922318983918605, 6.911200000000001, 6.9112, 121.9260426156618, 589161.1846985806, 589161.1846985802, 158985.3698583283], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4425600.0000, 
sim time next is 4426200.0000, 
raw observation next is [22.2, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7915663688342057, 6.9112, 6.9112, 121.9260426156618, 588683.007064521, 588683.007064521, 158893.7707956303], 
processed observation next is [0.0, 0.21739130434782608, 0.37777777777777777, 0.925, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7394579610427571, 0.0, 0.0, 0.8094621288201359, 0.2102439310944718, 0.2102439310944718, 0.30556494383775057], 
reward next is 0.6944, 
noisyNet noise sample is [array([-0.44223753], dtype=float32), 0.9912565]. 
=============================================
[2019-03-24 03:25:08,531] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1181360: loss 33.0250
[2019-03-24 03:25:08,534] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1181360: learning rate 0.0000
[2019-03-24 03:25:08,943] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.3878931e-29 3.0164678e-25 2.3005937e-24 1.5192239e-26], sum to 1.0000
[2019-03-24 03:25:08,948] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2007
[2019-03-24 03:25:08,952] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.31666666666667, 99.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8009673314466034, 6.911200000000001, 6.9112, 121.9260426156618, 595537.9283003111, 595537.9283003106, 160133.6173379797], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4578600.0000, 
sim time next is 4579200.0000, 
raw observation next is [21.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.785631186009043, 6.9112, 6.9112, 121.9260426156618, 585090.7789500315, 585090.7789500315, 157646.2218834291], 
processed observation next is [1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7320389825113038, 0.0, 0.0, 0.8094621288201359, 0.2089609924821541, 0.2089609924821541, 0.3031658113142867], 
reward next is 0.6968, 
noisyNet noise sample is [array([-0.80095965], dtype=float32), 1.4873955]. 
=============================================
[2019-03-24 03:25:12,360] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 4.0561417e-19 5.8065710e-17 6.1969989e-17 2.8856014e-17], sum to 1.0000
[2019-03-24 03:25:12,367] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6302
[2019-03-24 03:25:12,373] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1937592.415468347 W.
[2019-03-24 03:25:12,377] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.58333333333334, 64.33333333333334, 1.0, 2.0, 0.8494286545107833, 1.0, 2.0, 0.8494286545107833, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1937592.415468347, 1937592.415468348, 364602.0162269757], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4630200.0000, 
sim time next is 4630800.0000, 
raw observation next is [29.66666666666667, 64.66666666666667, 1.0, 2.0, 0.8672917796195667, 1.0, 2.0, 0.8672917796195667, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1978384.296357171, 1978384.296357172, 372344.7230883715], 
processed observation next is [1.0, 0.6086956521739131, 0.6543209876543211, 0.6466666666666667, 1.0, 1.0, 0.842014023356627, 1.0, 1.0, 0.842014023356627, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7065658201275611, 0.7065658201275614, 0.7160475444007144], 
reward next is 0.2840, 
noisyNet noise sample is [array([-0.41069537], dtype=float32), 0.12425131]. 
=============================================
[2019-03-24 03:25:13,266] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.2083261e-18 6.3472732e-17 5.7104923e-16 2.0901812e-16], sum to 1.0000
[2019-03-24 03:25:13,276] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7821
[2019-03-24 03:25:13,282] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1806083.364769372 W.
[2019-03-24 03:25:13,286] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.5, 64.0, 1.0, 2.0, 0.5278895099011071, 1.0, 2.0, 0.5278895099011071, 1.0, 2.0, 0.8404172919236528, 6.9112, 6.9112, 121.94756008, 1806083.364769372, 1806083.364769372, 357488.3681008422], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4629600.0000, 
sim time next is 4630200.0000, 
raw observation next is [29.58333333333334, 64.33333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.214606453508499, 6.9112, 121.9250003755001, 2033609.816926276, 1878239.922702874, 383044.1668746615], 
processed observation next is [1.0, 0.6086956521739131, 0.6512345679012348, 0.6433333333333334, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.030340645350849904, 0.0, 0.8094552094293157, 0.7262892203308129, 0.6707999723938836, 0.7366233978358875], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3013914], dtype=float32), 1.6959591]. 
=============================================
[2019-03-24 03:25:13,315] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1183694: loss 89.2390
[2019-03-24 03:25:13,318] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1183695: learning rate 0.0000
[2019-03-24 03:25:13,497] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1183784: loss 52.8437
[2019-03-24 03:25:13,498] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1183784: learning rate 0.0000
[2019-03-24 03:25:13,519] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1183794: loss 34.0215
[2019-03-24 03:25:13,520] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1183794: learning rate 0.0000
[2019-03-24 03:25:13,662] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1183865: loss 15.1486
[2019-03-24 03:25:13,666] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1183865: learning rate 0.0000
[2019-03-24 03:25:13,839] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1183949: loss 129.6931
[2019-03-24 03:25:13,843] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1183950: learning rate 0.0000
[2019-03-24 03:25:13,890] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1183970: loss -18.8015
[2019-03-24 03:25:13,892] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1183970: learning rate 0.0000
[2019-03-24 03:25:13,912] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1183978: loss 68.1801
[2019-03-24 03:25:13,913] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1183978: learning rate 0.0000
[2019-03-24 03:25:13,956] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1184000: loss 14.1796
[2019-03-24 03:25:13,958] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1184002: learning rate 0.0000
[2019-03-24 03:25:13,974] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1184011: loss 80.1720
[2019-03-24 03:25:13,975] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1184011: learning rate 0.0000
[2019-03-24 03:25:14,098] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1184068: loss 23.3314
[2019-03-24 03:25:14,101] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1184070: learning rate 0.0000
[2019-03-24 03:25:14,712] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1184370: loss -55.1179
[2019-03-24 03:25:14,712] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1184370: learning rate 0.0000
[2019-03-24 03:25:15,043] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1184532: loss 100.0494
[2019-03-24 03:25:15,044] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1184532: learning rate 0.0000
[2019-03-24 03:25:15,359] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1184688: loss 62.7364
[2019-03-24 03:25:15,360] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1184688: learning rate 0.0000
[2019-03-24 03:25:15,426] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.5305358e-14 4.2011876e-12 2.4337854e-12 8.1163207e-13], sum to 1.0000
[2019-03-24 03:25:15,432] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7893
[2019-03-24 03:25:15,437] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 941029.6159321222 W.
[2019-03-24 03:25:15,441] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.58333333333333, 94.83333333333334, 1.0, 2.0, 0.4111427907353483, 1.0, 1.0, 0.4111427907353483, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 941029.6159321222, 941029.6159321222, 209452.6284467213], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4684200.0000, 
sim time next is 4684800.0000, 
raw observation next is [23.46666666666667, 94.66666666666667, 1.0, 2.0, 0.3793383302199517, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6043832553102736, 6.911199999999999, 6.9112, 121.9260426156618, 873163.5000813991, 873163.5000813996, 217666.8722765072], 
processed observation next is [1.0, 0.21739130434782608, 0.42469135802469143, 0.9466666666666668, 1.0, 1.0, 0.2611170597856568, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.5054790691378419, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31184410717192823, 0.3118441071719284, 0.41859013899328307], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.33028015], dtype=float32), -1.4914398]. 
=============================================
[2019-03-24 03:25:15,509] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1184763: loss 104.6355
[2019-03-24 03:25:15,514] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1184763: learning rate 0.0000
[2019-03-24 03:25:15,707] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1184855: loss 30.5329
[2019-03-24 03:25:15,709] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1184855: learning rate 0.0000
[2019-03-24 03:25:16,326] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.5821435e-15 8.2671188e-14 1.8753228e-14 2.2474620e-14], sum to 1.0000
[2019-03-24 03:25:16,341] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2085
[2019-03-24 03:25:16,351] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 757255.0500704441 W.
[2019-03-24 03:25:16,356] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3322206282287294, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5289060598106381, 6.911200000000001, 6.9112, 121.9260426156618, 757255.0500704441, 757255.0500704437, 204106.4628994058], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4666800.0000, 
sim time next is 4667400.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3324373029207225, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5292510129768931, 6.911199999999999, 6.9112, 121.9260426156618, 757749.1768371576, 757749.176837158, 204167.4507630165], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.2052825034770506, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4115637662211164, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27062470601327054, 0.2706247060132707, 0.39262971300580096], 
reward next is 0.6074, 
noisyNet noise sample is [array([-0.1233771], dtype=float32), -1.3841889]. 
=============================================
[2019-03-24 03:25:19,797] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.7950737e-20 1.1222331e-18 4.5594708e-18 5.4080858e-18], sum to 1.0000
[2019-03-24 03:25:19,803] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6196
[2019-03-24 03:25:19,810] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 921062.8442199142 W.
[2019-03-24 03:25:19,815] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.1, 93.0, 1.0, 2.0, 0.4040427287434952, 1.0, 2.0, 0.4040427287434952, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 921062.8442199142, 921062.8442199146, 207301.6541245644], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4761000.0000, 
sim time next is 4761600.0000, 
raw observation next is [24.06666666666667, 93.33333333333334, 1.0, 2.0, 0.3605557385781077, 0.0, 1.0, 0.0, 1.0, 1.0, 0.574059721698273, 6.9112, 6.9112, 121.9260426156618, 823171.0146390621, 823171.0146390621, 212219.6149814017], 
processed observation next is [1.0, 0.08695652173913043, 0.4469135802469137, 0.9333333333333335, 1.0, 1.0, 0.2387568316406044, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4675746521228412, 0.0, 0.0, 0.8094621288201359, 0.2939896480853793, 0.2939896480853793, 0.4081146441950033], 
reward next is 0.5919, 
noisyNet noise sample is [array([-0.3256752], dtype=float32), 2.7919123]. 
=============================================
[2019-03-24 03:25:20,674] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 7.5759048e-19 2.3262142e-15 1.5203514e-15 1.1216442e-15], sum to 1.0000
[2019-03-24 03:25:20,678] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9501
[2019-03-24 03:25:20,685] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 766977.0902901596 W.
[2019-03-24 03:25:20,690] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.05, 93.16666666666667, 1.0, 2.0, 0.3364837192656543, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5356930395806048, 6.9112, 6.9112, 121.9260426156618, 766977.0902901596, 766977.0902901596, 205309.596314652], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4745400.0000, 
sim time next is 4746000.0000, 
raw observation next is [25.1, 92.33333333333334, 1.0, 2.0, 0.3345374282667788, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5325944809241224, 6.911199999999999, 6.9112, 121.9260426156618, 762538.5304706338, 762538.5304706342, 204759.1436273761], 
processed observation next is [1.0, 0.9565217391304348, 0.4851851851851852, 0.9233333333333335, 1.0, 1.0, 0.20778265269854618, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.415743101155153, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27233518945379775, 0.2723351894537979, 0.3937675838988002], 
reward next is 0.6062, 
noisyNet noise sample is [array([0.44720802], dtype=float32), -1.4607798]. 
=============================================
[2019-03-24 03:25:20,707] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[34.817238]
 [34.45461 ]
 [34.303997]
 [34.593113]
 [34.552616]], R is [[34.8607254 ]
 [34.51211929]
 [34.83708191]
 [35.09306335]
 [34.74213409]].
[2019-03-24 03:25:21,679] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.1962603e-13 1.2843776e-12 2.6409170e-12 6.1400201e-13], sum to 1.0000
[2019-03-24 03:25:21,690] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8349
[2019-03-24 03:25:21,694] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 804456.785193713 W.
[2019-03-24 03:25:21,697] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 94.00000000000001, 1.0, 2.0, 0.3529179684799725, 1.0, 2.0, 0.3529179684799725, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 804456.785193713, 804456.7851937135, 193643.6944546009], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4763400.0000, 
sim time next is 4764000.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.2200726396033196, 1.0, 2.0, 0.2200726396033196, 1.0, 1.0, 0.3503628095139839, 6.9112, 6.9112, 121.94756008, 752439.3395509324, 752439.3395509324, 227263.7398032966], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.07151504714680905, 1.0, 1.0, 0.07151504714680905, 1.0, 0.5, 0.18795351189247986, 0.0, 0.0, 0.8096049824067558, 0.2687283355539044, 0.2687283355539044, 0.4370456534678781], 
reward next is 0.5630, 
noisyNet noise sample is [array([-1.1898884], dtype=float32), -1.5125422]. 
=============================================
[2019-03-24 03:25:21,711] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[25.558647]
 [25.35971 ]
 [25.36394 ]
 [25.708212]
 [25.749912]], R is [[25.55002213]
 [25.92213058]
 [26.2935257 ]
 [26.62967491]
 [26.95541   ]].
[2019-03-24 03:25:22,892] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 4.2960272e-16 1.4722442e-14 5.3705978e-14 3.3579729e-16], sum to 1.0000
[2019-03-24 03:25:22,897] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2776
[2019-03-24 03:25:22,906] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 850029.6745063278 W.
[2019-03-24 03:25:22,909] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.26666666666667, 92.33333333333334, 1.0, 2.0, 0.3728998719110688, 1.0, 2.0, 0.3728998719110688, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 850029.6745063278, 850029.6745063278, 198876.8010759818], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4816200.0000, 
sim time next is 4816800.0000, 
raw observation next is [27.0, 94.0, 1.0, 2.0, 0.3910075503488917, 1.0, 2.0, 0.3910075503488917, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 891330.3442817377, 891330.3442817377, 203736.0164897671], 
processed observation next is [1.0, 0.782608695652174, 0.5555555555555556, 0.94, 1.0, 1.0, 0.2750089885105853, 1.0, 1.0, 0.2750089885105853, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3183322658149063, 0.3183322658149063, 0.39180003171109057], 
reward next is 0.6082, 
noisyNet noise sample is [array([-0.73105305], dtype=float32), -0.4223541]. 
=============================================
[2019-03-24 03:25:25,157] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1189445: loss 31.1792
[2019-03-24 03:25:25,159] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1189445: learning rate 0.0000
[2019-03-24 03:25:25,258] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.8288713e-17 3.3403439e-15 3.4168476e-14 4.3785034e-16], sum to 1.0000
[2019-03-24 03:25:25,267] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3792
[2019-03-24 03:25:25,275] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1505958.535868988 W.
[2019-03-24 03:25:25,280] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.33333333333334, 94.83333333333334, 1.0, 2.0, 0.6940211183016711, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 123.484564562216, 1505958.535868988, 1505958.535868987, 316516.5724360736], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4846200.0000, 
sim time next is 4846800.0000, 
raw observation next is [25.26666666666667, 94.66666666666667, 1.0, 2.0, 0.3879439264753644, 1.0, 1.0, 0.3879439264753644, 1.0, 2.0, 0.6176193654004083, 6.9112, 6.9112, 121.94756008, 1326896.524244359, 1326896.524244359, 291841.1886089272], 
processed observation next is [1.0, 0.08695652173913043, 0.49135802469135814, 0.9466666666666668, 1.0, 1.0, 0.2713618172325767, 1.0, 0.5, 0.2713618172325767, 1.0, 1.0, 0.5220242067505103, 0.0, 0.0, 0.8096049824067558, 0.4738916158015568, 0.4738916158015568, 0.5612330550171677], 
reward next is 0.4388, 
noisyNet noise sample is [array([-0.04696002], dtype=float32), 1.4004945]. 
=============================================
[2019-03-24 03:25:29,823] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1191702: loss -136.7417
[2019-03-24 03:25:29,824] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1191703: learning rate 0.0000
[2019-03-24 03:25:30,033] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1191806: loss -7.4267
[2019-03-24 03:25:30,037] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1191806: learning rate 0.0000
[2019-03-24 03:25:30,039] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1191806: loss -18.4979
[2019-03-24 03:25:30,044] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1191809: learning rate 0.0000
[2019-03-24 03:25:30,190] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1191881: loss -55.4754
[2019-03-24 03:25:30,192] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1191881: learning rate 0.0000
[2019-03-24 03:25:30,232] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1191900: loss -75.0165
[2019-03-24 03:25:30,233] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1191900: learning rate 0.0000
[2019-03-24 03:25:30,247] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1191903: loss -46.6754
[2019-03-24 03:25:30,254] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1191903: learning rate 0.0000
[2019-03-24 03:25:30,367] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1191965: loss -100.2960
[2019-03-24 03:25:30,369] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1191966: learning rate 0.0000
[2019-03-24 03:25:30,461] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1192005: loss 3.1728
[2019-03-24 03:25:30,463] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1192005: learning rate 0.0000
[2019-03-24 03:25:30,566] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1192059: loss -64.9494
[2019-03-24 03:25:30,567] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1192059: learning rate 0.0000
[2019-03-24 03:25:30,578] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1192061: loss -65.8051
[2019-03-24 03:25:30,581] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1192062: learning rate 0.0000
[2019-03-24 03:25:31,381] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1192449: loss -24.3862
[2019-03-24 03:25:31,385] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1192449: learning rate 0.0000
[2019-03-24 03:25:31,412] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1192460: loss -30.4311
[2019-03-24 03:25:31,413] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1192460: learning rate 0.0000
[2019-03-24 03:25:31,857] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1192681: loss -34.3542
[2019-03-24 03:25:31,859] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1192682: learning rate 0.0000
[2019-03-24 03:25:32,147] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1192822: loss -38.1696
[2019-03-24 03:25:32,147] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1192822: learning rate 0.0000
[2019-03-24 03:25:32,292] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1192893: loss -45.2515
[2019-03-24 03:25:32,293] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1192893: learning rate 0.0000
[2019-03-24 03:25:33,603] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7589636e-03 2.6519857e-18 8.3565169e-08 9.9606615e-01 2.1749060e-03], sum to 1.0000
[2019-03-24 03:25:33,611] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7750
[2019-03-24 03:25:33,617] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.8, 96.0, 1.0, 2.0, 0.2748389244980903, 1.0, 2.0, 0.2748389244980903, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 639641.646868539, 639641.6468685395, 175179.3355762807], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5020200.0000, 
sim time next is 5020800.0000, 
raw observation next is [22.86666666666667, 95.33333333333334, 1.0, 2.0, 0.2745122111106609, 1.0, 2.0, 0.2745122111106609, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 639095.5090791225, 639095.5090791229, 175113.1191046606], 
processed observation next is [0.0, 0.08695652173913043, 0.4024691358024693, 0.9533333333333335, 1.0, 1.0, 0.13632406084602486, 1.0, 1.0, 0.13632406084602486, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22824839609968658, 0.22824839609968675, 0.33675599827819347], 
reward next is 0.6632, 
noisyNet noise sample is [array([0.31531048], dtype=float32), -1.5752774]. 
=============================================
[2019-03-24 03:25:35,872] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.5144245e-04 2.0748602e-21 4.4441751e-12 9.6630603e-01 3.2942515e-02], sum to 1.0000
[2019-03-24 03:25:35,881] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8867
[2019-03-24 03:25:35,886] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.4, 75.0, 1.0, 2.0, 0.2393748830362179, 1.0, 2.0, 0.2393748830362179, 1.0, 2.0, 0.3810926096893396, 6.911199999999999, 6.9112, 121.94756008, 818469.9023402728, 818469.9023402733, 233889.4119888339], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5052000.0000, 
sim time next is 5052600.0000, 
raw observation next is [29.55, 76.0, 1.0, 2.0, 0.3742460265142854, 1.0, 2.0, 0.3742460265142854, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 853099.957662602, 853099.9576626024, 199233.9191390348], 
processed observation next is [0.0, 0.4782608695652174, 0.65, 0.76, 1.0, 1.0, 0.25505479346938736, 1.0, 1.0, 0.25505479346938736, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3046785563080721, 0.3046785563080723, 0.38314215219045156], 
reward next is 0.6169, 
noisyNet noise sample is [array([-0.78845257], dtype=float32), 1.7421259]. 
=============================================
[2019-03-24 03:25:41,381] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1197323: loss -66.1616
[2019-03-24 03:25:41,386] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1197324: learning rate 0.0000
[2019-03-24 03:25:45,527] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.6723471e-01 1.0929072e-19 1.9368967e-13 1.3276525e-01 7.0882598e-11], sum to 1.0000
[2019-03-24 03:25:45,534] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6742
[2019-03-24 03:25:45,540] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1817794.316912528 W.
[2019-03-24 03:25:45,544] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.5313089565251077, 1.0, 2.0, 0.5313089565251077, 1.0, 1.0, 0.8458611623126634, 6.911199999999999, 6.9112, 121.94756008, 1817794.316912528, 1817794.316912528, 359221.5130987399], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5216400.0000, 
sim time next is 5217000.0000, 
raw observation next is [26.16666666666667, 88.16666666666667, 1.0, 2.0, 0.4787564696661429, 1.0, 2.0, 0.4787564696661429, 1.0, 2.0, 0.7621958917181817, 6.911199999999999, 6.9112, 121.94756008, 1637829.025157957, 1637829.025157958, 333284.8723035723], 
processed observation next is [1.0, 0.391304347826087, 0.5246913580246916, 0.8816666666666667, 1.0, 1.0, 0.37947198769778917, 1.0, 1.0, 0.37947198769778917, 1.0, 1.0, 0.7027448646477271, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5849389375564132, 0.5849389375564136, 0.640932446737639], 
reward next is 0.3591, 
noisyNet noise sample is [array([0.17204712], dtype=float32), 0.7083896]. 
=============================================
[2019-03-24 03:25:45,565] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[47.243816]
 [47.470127]
 [47.036816]
 [46.843933]
 [47.295387]], R is [[47.45254898]
 [46.97802353]
 [46.84662247]
 [46.69948578]
 [46.23249054]].
[2019-03-24 03:25:46,195] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1199658: loss 3.0173
[2019-03-24 03:25:46,203] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1199661: learning rate 0.0000
[2019-03-24 03:25:46,515] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1199815: loss 29.5274
[2019-03-24 03:25:46,518] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1199816: learning rate 0.0000
[2019-03-24 03:25:46,589] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1199851: loss 21.6445
[2019-03-24 03:25:46,591] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1199852: learning rate 0.0000
[2019-03-24 03:25:46,597] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1199854: loss 10.8863
[2019-03-24 03:25:46,599] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1199854: learning rate 0.0000
[2019-03-24 03:25:46,612] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4028496e-02 8.5800854e-20 1.2211078e-15 9.8597151e-01 2.1609652e-12], sum to 1.0000
[2019-03-24 03:25:46,624] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4654
[2019-03-24 03:25:46,629] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.75, 74.83333333333333, 1.0, 2.0, 0.557288701537718, 1.0, 2.0, 0.557288701537718, 1.0, 2.0, 0.8872217624739648, 6.911199999999999, 6.9112, 121.94756008, 1906775.000266976, 1906775.000266977, 372595.8730816843], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5223000.0000, 
sim time next is 5223600.0000, 
raw observation next is [27.9, 73.0, 1.0, 2.0, 0.8296816639605805, 1.0, 2.0, 0.8296816639605805, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156251, 1892500.744698668, 1892500.744698668, 356171.4919125498], 
processed observation next is [1.0, 0.4782608695652174, 0.5888888888888888, 0.73, 1.0, 1.0, 0.7972400761435482, 1.0, 1.0, 0.7972400761435482, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288198922, 0.6758931231066672, 0.6758931231066672, 0.6849451767549035], 
reward next is 0.3151, 
noisyNet noise sample is [array([0.13419262], dtype=float32), -1.4814413]. 
=============================================
[2019-03-24 03:25:46,638] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1199869: loss 1.0966
[2019-03-24 03:25:46,639] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1199869: learning rate 0.0000
[2019-03-24 03:25:46,750] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1199926: loss 0.5330
[2019-03-24 03:25:46,752] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1199928: learning rate 0.0000
[2019-03-24 03:25:46,872] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1199987: loss -47.0218
[2019-03-24 03:25:46,874] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1199987: learning rate 0.0000
[2019-03-24 03:25:46,896] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 03:25:46,902] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:25:46,903] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:25:46,903] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:25:46,904] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:25:46,904] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:25:46,906] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:25:46,906] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:25:46,907] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:25:46,907] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:25:46,911] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:25:46,925] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run49
[2019-03-24 03:25:46,945] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run49
[2019-03-24 03:25:46,968] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run49
[2019-03-24 03:25:46,969] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run49
[2019-03-24 03:25:46,996] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run49
[2019-03-24 03:25:59,911] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00930629], dtype=float32), 0.2990303]
[2019-03-24 03:25:59,911] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.33333333333334, 29.33333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 400018.5092101801, 400018.5092101805, 150392.360313784]
[2019-03-24 03:25:59,912] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:25:59,915] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.4430311e-02 1.7127352e-21 4.0036991e-17 9.3556970e-01 3.2095794e-13], sampled 0.40109011292595564
[2019-03-24 03:26:00,654] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00930629], dtype=float32), 0.2990303]
[2019-03-24 03:26:00,654] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.83333333333333, 51.83333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 271679.1755236288, 271679.1755236292, 107913.1270962781]
[2019-03-24 03:26:00,655] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:26:00,658] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1270983e-01 5.2192067e-19 4.6255584e-15 8.8729018e-01 9.5628193e-12], sampled 0.5397723898165462
[2019-03-24 03:26:01,788] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00930629], dtype=float32), 0.2990303]
[2019-03-24 03:26:01,790] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.97828674, 59.84573947, 1.0, 2.0, 0.2138373129488615, 1.0, 2.0, 0.2138373129488615, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 541743.1315534641, 541743.1315534646, 163092.5056348442]
[2019-03-24 03:26:01,791] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:26:01,792] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.5661123e-02 1.0036487e-20 1.7090530e-16 9.2433888e-01 9.1829181e-13], sampled 0.5710984813911353
[2019-03-24 03:26:27,113] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00930629], dtype=float32), 0.2990303]
[2019-03-24 03:26:27,115] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [37.0, 27.0, 1.0, 2.0, 0.2570358857163347, 1.0, 2.0, 0.2570358857163347, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 601885.8009809228, 601885.8009809228, 171255.9310725207]
[2019-03-24 03:26:27,115] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:26:27,117] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.4331286e-02 3.3272851e-24 2.8108440e-19 9.5566875e-01 7.5890628e-15], sampled 0.11769482260257202
[2019-03-24 03:26:27,483] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00930629], dtype=float32), 0.2990303]
[2019-03-24 03:26:27,484] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.33333333333333, 84.83333333333333, 1.0, 2.0, 0.3149949474689727, 1.0, 2.0, 0.3149949474689727, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717972.8938473574, 717972.8938473574, 184097.7604174937]
[2019-03-24 03:26:27,485] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:26:27,490] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.5494001e-02 2.8689773e-23 1.4266850e-18 9.5450598e-01 2.8107582e-14], sampled 0.6891538150718041
[2019-03-24 03:26:36,388] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00930629], dtype=float32), 0.2990303]
[2019-03-24 03:26:36,389] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.18594214, 67.08165471, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7189002992876201, 6.9112, 6.9112, 121.9260426156618, 535853.2394278313, 535853.2394278313, 149370.6383722073]
[2019-03-24 03:26:36,389] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:26:36,392] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.9955174e-02 2.2472686e-23 1.2970404e-18 9.5004481e-01 2.3702426e-14], sampled 0.7593237767715414
[2019-03-24 03:27:01,043] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00930629], dtype=float32), 0.2990303]
[2019-03-24 03:27:01,044] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.51212401333333, 83.85565216833334, 1.0, 2.0, 0.3481323510784992, 1.0, 2.0, 0.3481323510784992, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 793542.5909350552, 793542.5909350556, 192413.398369781]
[2019-03-24 03:27:01,046] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:27:01,050] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.2834435e-02 2.9911091e-23 1.4027105e-18 9.5716560e-01 2.9211314e-14], sampled 0.1784666303316701
[2019-03-24 03:27:03,808] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00930629], dtype=float32), 0.2990303]
[2019-03-24 03:27:03,809] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 80.0, 1.0, 2.0, 0.2957678270280621, 1.0, 2.0, 0.2957678270280621, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 674128.9489234821, 674128.9489234821, 179448.2301375046]
[2019-03-24 03:27:03,810] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:27:03,813] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.6260166e-02 6.5467685e-22 1.9914158e-17 9.3373978e-01 1.7606695e-13], sampled 0.10038739525816076
[2019-03-24 03:27:04,314] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00930629], dtype=float32), 0.2990303]
[2019-03-24 03:27:04,315] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.09778355333334, 85.45819236833334, 1.0, 2.0, 0.6671794566286794, 1.0, 2.0, 0.6671794566286794, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1521509.612577695, 1521509.612577695, 291926.1724315389]
[2019-03-24 03:27:04,317] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:27:04,320] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.8859926e-02 9.5763795e-23 3.1404834e-18 9.6114010e-01 5.9280062e-14], sampled 0.7551967892187745
[2019-03-24 03:27:10,342] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00930629], dtype=float32), 0.2990303]
[2019-03-24 03:27:10,343] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 94.0, 1.0, 2.0, 0.2689406233580953, 1.0, 2.0, 0.2689406233580953, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 626638.9178908801, 626638.9178908806, 173844.5777676507]
[2019-03-24 03:27:10,345] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:27:10,350] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.5984918e-02 9.0108868e-22 2.2147902e-17 9.4401515e-01 2.2441527e-13], sampled 0.2759582213789745
[2019-03-24 03:27:21,276] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00930629], dtype=float32), 0.2990303]
[2019-03-24 03:27:21,277] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.01100225666666, 69.24146203666666, 1.0, 2.0, 0.2895087557752979, 1.0, 2.0, 0.2895087557752979, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 683973.2670540749, 683973.2670540754, 179079.8423355962]
[2019-03-24 03:27:21,278] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:27:21,281] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.5351626e-02 3.8745553e-22 1.1601425e-17 9.4464839e-01 1.3223870e-13], sampled 0.426164779742888
[2019-03-24 03:27:25,336] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7471.9710 2397504364.4130 58.0000
[2019-03-24 03:27:25,728] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6686.9962 2484174908.1720 74.0000
[2019-03-24 03:27:25,766] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6904.6716 2426765396.6894 64.0000
[2019-03-24 03:27:25,799] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7147.7079 2452583794.8509 90.0000
[2019-03-24 03:27:25,887] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7167.2195 2658113578.6145 108.0000
[2019-03-24 03:27:26,903] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1200000, evaluation results [1200000.0, 7167.219452063917, 2658113578.6145473, 108.0, 6904.671631833176, 2426765396.6894116, 64.0, 7471.971025293023, 2397504364.4129977, 58.0, 6686.996225169935, 2484174908.1720324, 74.0, 7147.707885402823, 2452583794.850923, 90.0]
[2019-03-24 03:27:26,980] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1200039: loss 0.0060
[2019-03-24 03:27:26,982] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1200040: learning rate 0.0000
[2019-03-24 03:27:26,995] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1200044: loss 3.2797
[2019-03-24 03:27:26,998] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1200045: learning rate 0.0000
[2019-03-24 03:27:27,082] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1200081: loss 0.0639
[2019-03-24 03:27:27,088] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1200084: learning rate 0.0000
[2019-03-24 03:27:27,706] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1200392: loss 4.6727
[2019-03-24 03:27:27,711] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1200392: learning rate 0.0000
[2019-03-24 03:27:27,769] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1200423: loss 0.1733
[2019-03-24 03:27:27,772] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1200424: learning rate 0.0000
[2019-03-24 03:27:28,322] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1200698: loss -52.9527
[2019-03-24 03:27:28,324] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1200699: learning rate 0.0000
[2019-03-24 03:27:28,706] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1200887: loss 0.0576
[2019-03-24 03:27:28,711] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1200888: learning rate 0.0000
[2019-03-24 03:27:28,768] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1200914: loss 0.2828
[2019-03-24 03:27:28,771] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1200914: learning rate 0.0000
[2019-03-24 03:27:29,583] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.9523899e-02 2.6298343e-16 3.8254673e-12 9.2047608e-01 4.8730773e-11], sum to 1.0000
[2019-03-24 03:27:29,591] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1303
[2019-03-24 03:27:29,595] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.5, 77.33333333333333, 1.0, 2.0, 0.8673816740903474, 1.0, 2.0, 0.8673816740903474, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1978589.582313126, 1978589.582313127, 372384.8417005101], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5406600.0000, 
sim time next is 5407200.0000, 
raw observation next is [28.8, 76.0, 1.0, 2.0, 0.8999708938418408, 1.0, 2.0, 0.8999708938418408, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2053014.501035657, 2053014.501035657, 386796.2474990918], 
processed observation next is [1.0, 0.6086956521739131, 0.6222222222222222, 0.76, 1.0, 1.0, 0.8809177307640962, 1.0, 1.0, 0.8809177307640962, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7332194646555917, 0.7332194646555917, 0.7438389374982535], 
reward next is 0.2562, 
noisyNet noise sample is [array([-0.9101304], dtype=float32), 1.1475983]. 
=============================================
[2019-03-24 03:27:34,798] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.95697653e-01 6.94937705e-13 2.04410533e-09 1.04302146e-01
 1.66839797e-07], sum to 1.0000
[2019-03-24 03:27:34,810] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7461
[2019-03-24 03:27:34,817] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1115120.022629366 W.
[2019-03-24 03:27:34,825] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.9, 87.33333333333334, 1.0, 2.0, 0.4891079137357691, 1.0, 2.0, 0.4891079137357691, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1115120.022629366, 1115120.022629366, 232034.0739317354], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5365200.0000, 
sim time next is 5365800.0000, 
raw observation next is [24.85, 87.5, 1.0, 2.0, 0.2970897444645748, 1.0, 2.0, 0.2970897444645748, 1.0, 1.0, 0.4729765487250958, 6.911199999999999, 6.9112, 121.94756008, 1015939.167592549, 1015939.167592549, 254941.8566547251], 
processed observation next is [1.0, 0.08695652173913043, 0.475925925925926, 0.875, 1.0, 1.0, 0.16320207674354145, 1.0, 1.0, 0.16320207674354145, 1.0, 0.5, 0.3412206859063697, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.36283541699733896, 0.36283541699733896, 0.49027280125908673], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7456175], dtype=float32), 0.20912366]. 
=============================================
[2019-03-24 03:27:37,673] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1205267: loss -1.9268
[2019-03-24 03:27:37,675] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1205267: learning rate 0.0000
[2019-03-24 03:27:40,510] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 6.5072417e-18 1.3273538e-16 1.3511330e-11 6.0963963e-14], sum to 1.0000
[2019-03-24 03:27:40,515] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8537
[2019-03-24 03:27:40,524] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1709033.412827425 W.
[2019-03-24 03:27:40,532] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.35, 80.0, 1.0, 2.0, 0.8719217844322905, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1709033.412827425, 1709033.412827426, 350970.1667813945], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5503800.0000, 
sim time next is 5504400.0000, 
raw observation next is [27.0, 81.0, 1.0, 2.0, 1.00376336248109, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1859539.555651007, 1859539.555651007, 380309.877874115], 
processed observation next is [1.0, 0.7391304347826086, 0.5555555555555556, 0.81, 1.0, 1.0, 1.004480193429869, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6641212698753597, 0.6641212698753597, 0.7313651497579134], 
reward next is 0.2686, 
noisyNet noise sample is [array([-0.9238094], dtype=float32), -0.6466412]. 
=============================================
[2019-03-24 03:27:41,527] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 4.4717364e-21 5.8669486e-19 6.1257954e-13 5.0850850e-16], sum to 1.0000
[2019-03-24 03:27:41,552] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3306
[2019-03-24 03:27:41,556] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 780070.3958602778 W.
[2019-03-24 03:27:41,559] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.66666666666667, 91.66666666666666, 1.0, 2.0, 0.2281500314938337, 1.0, 1.0, 0.2281500314938337, 1.0, 1.0, 0.3632222804659708, 6.9112, 6.9112, 121.94756008, 780070.3958602778, 780070.3958602778, 230011.0313811848], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5532000.0000, 
sim time next is 5532600.0000, 
raw observation next is [25.63333333333333, 91.83333333333333, 1.0, 2.0, 0.341774029695162, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5441153860777632, 6.911199999999999, 6.9112, 121.9260426156618, 779041.8905194663, 779041.8905194667, 206813.872489106], 
processed observation next is [1.0, 0.0, 0.5049382716049381, 0.9183333333333333, 1.0, 1.0, 0.2163976543990024, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.43014423259720397, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2782292466140951, 0.27822924661409526, 0.39771898555597307], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2765822], dtype=float32), 0.6239871]. 
=============================================
[2019-03-24 03:27:42,590] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1207651: loss 9.5850
[2019-03-24 03:27:42,593] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1207652: learning rate 0.0000
[2019-03-24 03:27:42,813] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1207758: loss 9.3645
[2019-03-24 03:27:42,820] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1207758: learning rate 0.0000
[2019-03-24 03:27:42,886] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1207795: loss -21.3844
[2019-03-24 03:27:42,893] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1207795: learning rate 0.0000
[2019-03-24 03:27:42,985] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1207837: loss 68.3290
[2019-03-24 03:27:42,988] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1207837: learning rate 0.0000
[2019-03-24 03:27:43,132] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1207907: loss -70.5524
[2019-03-24 03:27:43,133] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1207907: learning rate 0.0000
[2019-03-24 03:27:43,297] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1207987: loss 82.7180
[2019-03-24 03:27:43,299] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1207988: learning rate 0.0000
[2019-03-24 03:27:43,374] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1208026: loss -104.7983
[2019-03-24 03:27:43,376] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1208026: learning rate 0.0000
[2019-03-24 03:27:43,390] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1208034: loss -10.3921
[2019-03-24 03:27:43,393] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1208034: learning rate 0.0000
[2019-03-24 03:27:43,447] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1208060: loss 69.5227
[2019-03-24 03:27:43,449] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1208060: learning rate 0.0000
[2019-03-24 03:27:43,506] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1208086: loss 26.7495
[2019-03-24 03:27:43,508] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1208086: learning rate 0.0000
[2019-03-24 03:27:44,235] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1208447: loss 54.8802
[2019-03-24 03:27:44,236] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1208447: loss 54.2320
[2019-03-24 03:27:44,236] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1208447: learning rate 0.0000
[2019-03-24 03:27:44,241] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1208451: learning rate 0.0000
[2019-03-24 03:27:44,738] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1208693: loss 52.2149
[2019-03-24 03:27:44,742] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1208693: learning rate 0.0000
[2019-03-24 03:27:45,087] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1208859: loss 2.7250
[2019-03-24 03:27:45,088] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1208860: learning rate 0.0000
[2019-03-24 03:27:45,310] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1208963: loss 20.1466
[2019-03-24 03:27:45,312] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1208964: learning rate 0.0000
[2019-03-24 03:27:46,258] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 6.3931260e-25 1.1412267e-21 2.3877541e-16 3.8792327e-21], sum to 1.0000
[2019-03-24 03:27:46,264] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7572
[2019-03-24 03:27:46,274] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 745968.6624897894 W.
[2019-03-24 03:27:46,280] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.51666666666667, 95.66666666666666, 1.0, 2.0, 0.6545430137007567, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 745968.6624897894, 745968.662489789, 167714.902133252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5608200.0000, 
sim time next is 5608800.0000, 
raw observation next is [24.4, 96.0, 1.0, 2.0, 0.6502805858600901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 741108.5163858549, 741108.5163858549, 166942.901748316], 
processed observation next is [1.0, 0.9565217391304348, 0.4592592592592592, 0.96, 1.0, 1.0, 0.5836673641191549, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2646816129949482, 0.2646816129949482, 0.3210440418236846], 
reward next is 0.6790, 
noisyNet noise sample is [array([-0.8442443], dtype=float32), -0.3807742]. 
=============================================
[2019-03-24 03:27:48,059] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.8841436e-28 6.9502432e-25 1.7427679e-20 9.4344628e-23], sum to 1.0000
[2019-03-24 03:27:48,064] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4202
[2019-03-24 03:27:48,068] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.5, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9347087470681742, 6.911199999999999, 6.9112, 121.9260426156618, 679310.3689453211, 679310.3689453214, 181459.9182780607], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5623800.0000, 
sim time next is 5624400.0000, 
raw observation next is [23.5, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9342215889335521, 6.911200000000001, 6.9112, 121.9260426156618, 678962.8545391515, 678962.8545391511, 181392.1421971376], 
processed observation next is [0.0, 0.08695652173913043, 0.42592592592592593, 0.97, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9177769861669401, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2424867337639827, 0.24248673376398253, 0.3488310426868031], 
reward next is 0.6512, 
noisyNet noise sample is [array([1.208633], dtype=float32), 0.80192965]. 
=============================================
[2019-03-24 03:27:51,040] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.5402602e-34 3.0421023e-30 2.7665927e-22 8.4301867e-26], sum to 1.0000
[2019-03-24 03:27:51,047] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7206
[2019-03-24 03:27:51,052] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 789751.4009918829 W.
[2019-03-24 03:27:51,055] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 88.66666666666667, 1.0, 2.0, 0.3464699875381064, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5515915039004007, 6.911199999999999, 6.9112, 121.9260426156618, 789751.4009918829, 789751.4009918834, 208157.5032287767], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5692800.0000, 
sim time next is 5693400.0000, 
raw observation next is [25.75, 89.0, 1.0, 2.0, 0.2275113023209594, 1.0, 1.0, 0.2275113023209594, 1.0, 2.0, 0.3622054028207981, 6.9112, 6.9112, 121.94756008, 777885.4016345369, 777885.4016345369, 229792.4575638973], 
processed observation next is [0.0, 0.9130434782608695, 0.5092592592592593, 0.89, 1.0, 1.0, 0.08037059800114214, 1.0, 0.5, 0.08037059800114214, 1.0, 1.0, 0.20275675352599762, 0.0, 0.0, 0.8096049824067558, 0.2778162148694775, 0.2778162148694775, 0.441908572238264], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.4239056], dtype=float32), -2.023893]. 
=============================================
[2019-03-24 03:27:52,091] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.8898687e-33 9.4130398e-30 1.2379928e-19 2.1135394e-29], sum to 1.0000
[2019-03-24 03:27:52,100] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3654
[2019-03-24 03:27:52,104] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.95, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8192043169782859, 6.9112, 6.9112, 121.9260426156618, 607666.6994001782, 607666.6994001782, 163115.5652008934], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5710200.0000, 
sim time next is 5710800.0000, 
raw observation next is [21.9, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8165745117026666, 6.9112, 6.9112, 121.9260426156618, 605987.5222317474, 605987.5222317474, 162661.7588853603], 
processed observation next is [0.0, 0.08695652173913043, 0.36666666666666664, 0.97, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7707181396283332, 0.0, 0.0, 0.8094621288201359, 0.21642411508276693, 0.21642411508276693, 0.312811074779539], 
reward next is 0.6872, 
noisyNet noise sample is [array([1.5271417], dtype=float32), -0.51657736]. 
=============================================
[2019-03-24 03:27:53,689] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1213044: loss 0.4061
[2019-03-24 03:27:53,691] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1213045: learning rate 0.0000
[2019-03-24 03:27:55,793] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 4.3443997e-37 2.1911781e-37 1.0467136e-28 7.1476522e-33], sum to 1.0000
[2019-03-24 03:27:55,802] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9165
[2019-03-24 03:27:55,806] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.61666666666667, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7603889714354469, 6.9112, 6.9112, 121.9260426156618, 566813.5136709724, 566813.5136709724, 154197.6318660628], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5793000.0000, 
sim time next is 5793600.0000, 
raw observation next is [22.53333333333333, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7553388401666112, 6.9112, 6.9112, 121.9260426156618, 563273.1499564175, 563273.1499564175, 153399.5525040425], 
processed observation next is [1.0, 0.043478260869565216, 0.3901234567901234, 0.86, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6941735502082641, 0.0, 0.0, 0.8094621288201359, 0.20116898212729198, 0.20116898212729198, 0.294999139430851], 
reward next is 0.7050, 
noisyNet noise sample is [array([0.8933595], dtype=float32), 0.017319508]. 
=============================================
[2019-03-24 03:27:56,705] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.2880730e-36 4.9084410e-25 3.4454706e-30], sum to 1.0000
[2019-03-24 03:27:56,711] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7650
[2019-03-24 03:27:56,717] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 689948.9039283122 W.
[2019-03-24 03:27:56,722] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.96666666666667, 68.0, 1.0, 2.0, 0.3027055635978625, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4819171156797505, 6.911199999999999, 6.9112, 121.9260426156618, 689948.9039283122, 689948.9039283127, 195973.7095449244], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5764800.0000, 
sim time next is 5765400.0000, 
raw observation next is [27.8, 68.5, 1.0, 2.0, 0.3003014108357545, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4781813109372461, 6.911199999999999, 6.9112, 121.9260426156618, 686856.5556603873, 686856.5556603877, 195288.0747641704], 
processed observation next is [0.0, 0.7391304347826086, 0.5851851851851853, 0.685, 1.0, 1.0, 0.16702548909018394, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.34772663867155756, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2453059127358526, 0.24530591273585275, 0.3755539899310969], 
reward next is 0.6244, 
noisyNet noise sample is [array([-1.8603228], dtype=float32), -0.27751845]. 
=============================================
[2019-03-24 03:27:56,938] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.9738714e-34 3.5881820e-29 8.1307904e-21 2.1419649e-28], sum to 1.0000
[2019-03-24 03:27:56,949] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8037
[2019-03-24 03:27:56,957] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.33333333333334, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8941397915910101, 6.9112, 6.9112, 121.9260426156618, 667457.4028083998, 667457.4028083998, 169661.9231578305], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5807400.0000, 
sim time next is 5808000.0000, 
raw observation next is [21.46666666666667, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8124582112287534, 6.9112, 6.9112, 121.9260426156618, 606429.1810520081, 606429.1810520081, 159712.762025851], 
processed observation next is [1.0, 0.21739130434782608, 0.35061728395061736, 0.93, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7655727640359417, 0.0, 0.0, 0.8094621288201359, 0.21658185037571717, 0.21658185037571717, 0.3071399269727904], 
reward next is 0.6929, 
noisyNet noise sample is [array([0.9816302], dtype=float32), 0.5433598]. 
=============================================
[2019-03-24 03:27:56,972] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[59.648685]
 [59.907246]
 [59.94434 ]
 [60.0756  ]
 [60.340282]], R is [[59.47898865]
 [59.55792999]
 [59.67472076]
 [59.78986359]
 [59.90289688]].
[2019-03-24 03:27:58,941] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1215630: loss 3.3347
[2019-03-24 03:27:58,942] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1215630: learning rate 0.0000
[2019-03-24 03:27:59,260] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1215787: loss 4.2320
[2019-03-24 03:27:59,263] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1215788: learning rate 0.0000
[2019-03-24 03:27:59,281] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1215796: loss 2.3976
[2019-03-24 03:27:59,283] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1215796: learning rate 0.0000
[2019-03-24 03:27:59,352] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1215830: loss 2.9608
[2019-03-24 03:27:59,356] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1215830: learning rate 0.0000
[2019-03-24 03:27:59,403] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1215854: loss 1.8205
[2019-03-24 03:27:59,403] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1215854: learning rate 0.0000
[2019-03-24 03:27:59,704] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1216000: loss 3.0519
[2019-03-24 03:27:59,713] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1216003: learning rate 0.0000
[2019-03-24 03:27:59,782] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1216041: loss 3.3510
[2019-03-24 03:27:59,784] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1216042: learning rate 0.0000
[2019-03-24 03:27:59,825] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1216061: loss 3.9264
[2019-03-24 03:27:59,828] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1216063: learning rate 0.0000
[2019-03-24 03:27:59,855] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1216074: loss 2.3825
[2019-03-24 03:27:59,856] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1216074: learning rate 0.0000
[2019-03-24 03:27:59,960] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1216128: loss 4.2609
[2019-03-24 03:27:59,962] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1216128: learning rate 0.0000
[2019-03-24 03:28:00,800] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1216540: loss 4.6459
[2019-03-24 03:28:00,802] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1216540: learning rate 0.0000
[2019-03-24 03:28:00,827] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1216549: loss 5.2299
[2019-03-24 03:28:00,830] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1216549: learning rate 0.0000
[2019-03-24 03:28:01,363] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1216819: loss 4.5329
[2019-03-24 03:28:01,364] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1216820: learning rate 0.0000
[2019-03-24 03:28:01,664] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1216963: loss 0.9998
[2019-03-24 03:28:01,666] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1216964: learning rate 0.0000
[2019-03-24 03:28:01,895] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1217070: loss 2.4947
[2019-03-24 03:28:01,897] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1217072: learning rate 0.0000
[2019-03-24 03:28:07,326] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.7118841e-36 4.6442577e-33 3.5109684e-26 1.6066399e-28], sum to 1.0000
[2019-03-24 03:28:07,332] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0067
[2019-03-24 03:28:07,339] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.3, 82.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7803512748511473, 6.911200000000001, 6.9112, 121.9260426156618, 581141.2121369696, 581141.2121369691, 157015.547310901], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5956200.0000, 
sim time next is 5956800.0000, 
raw observation next is [23.1, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7783348354530428, 6.9112, 6.9112, 121.9260426156618, 579615.5525728362, 579615.5525728362, 156787.3850999702], 
processed observation next is [1.0, 0.9565217391304348, 0.41111111111111115, 0.84, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7229185443163035, 0.0, 0.0, 0.8094621288201359, 0.20700555449029864, 0.20700555449029864, 0.3015142021153273], 
reward next is 0.6985, 
noisyNet noise sample is [array([0.26652116], dtype=float32), 0.8906876]. 
=============================================
[2019-03-24 03:28:10,163] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1221113: loss 0.7160
[2019-03-24 03:28:10,164] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1221114: learning rate 0.0000
[2019-03-24 03:28:11,422] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 9.2185110e-24 4.0757560e-22 2.3900790e-15 2.0180104e-19], sum to 1.0000
[2019-03-24 03:28:11,429] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6140
[2019-03-24 03:28:11,438] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 913680.1475355922 W.
[2019-03-24 03:28:11,444] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.51666666666667, 75.16666666666667, 1.0, 1.0, 0.7727722984482431, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9259961894354, 913680.1475355922, 913680.1475355922, 191963.5941225777], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6077400.0000, 
sim time next is 6078000.0000, 
raw observation next is [26.53333333333333, 70.33333333333334, 1.0, 2.0, 0.3817041351399467, 1.0, 1.0, 0.3817041351399467, 1.0, 1.0, 0.6078501724916665, 6.9112, 6.9112, 121.94756008, 1311533.953176479, 1311533.953176479, 289196.7162121322], 
processed observation next is [1.0, 0.34782608695652173, 0.5382716049382715, 0.7033333333333335, 1.0, 1.0, 0.2639334942142223, 1.0, 0.5, 0.2639334942142223, 1.0, 0.5, 0.5098127156145831, 0.0, 0.0, 0.8096049824067558, 0.46840498327731395, 0.46840498327731395, 0.5561475311771773], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.17627789], dtype=float32), -1.1435727]. 
=============================================
[2019-03-24 03:28:11,460] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[36.520897]
 [37.172234]
 [37.09366 ]
 [37.124733]
 [37.70162 ]], R is [[36.47766876]
 [36.74373245]
 [36.63924408]
 [36.93291473]
 [37.22471619]].
[2019-03-24 03:28:15,414] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1223610: loss 2.5862
[2019-03-24 03:28:15,416] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1223610: learning rate 0.0000
[2019-03-24 03:28:15,596] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1223697: loss 2.6864
[2019-03-24 03:28:15,599] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1223698: learning rate 0.0000
[2019-03-24 03:28:15,681] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1223742: loss 2.2432
[2019-03-24 03:28:15,687] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1223744: learning rate 0.0000
[2019-03-24 03:28:15,845] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1223820: loss 3.4633
[2019-03-24 03:28:15,848] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1223820: learning rate 0.0000
[2019-03-24 03:28:15,883] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1223837: loss 3.6494
[2019-03-24 03:28:15,884] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1223837: learning rate 0.0000
[2019-03-24 03:28:16,077] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1223934: loss 1.5654
[2019-03-24 03:28:16,078] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1223935: learning rate 0.0000
[2019-03-24 03:28:16,103] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1223949: loss 1.9114
[2019-03-24 03:28:16,107] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1223949: learning rate 0.0000
[2019-03-24 03:28:16,279] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1224036: loss 1.9690
[2019-03-24 03:28:16,280] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1224036: learning rate 0.0000
[2019-03-24 03:28:16,292] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1224041: loss 2.1831
[2019-03-24 03:28:16,295] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1224041: learning rate 0.0000
[2019-03-24 03:28:16,456] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1224118: loss 1.3450
[2019-03-24 03:28:16,458] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1224118: learning rate 0.0000
[2019-03-24 03:28:17,287] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1224527: loss 0.0874
[2019-03-24 03:28:17,293] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1224528: learning rate 0.0000
[2019-03-24 03:28:17,326] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1224540: loss 0.1487
[2019-03-24 03:28:17,330] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1224541: learning rate 0.0000
[2019-03-24 03:28:17,551] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.7315642e-25 2.4540205e-23 2.1727483e-16 7.0596040e-20], sum to 1.0000
[2019-03-24 03:28:17,561] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5672
[2019-03-24 03:28:17,567] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1930481.624846716 W.
[2019-03-24 03:28:17,571] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.96666666666667, 51.66666666666667, 1.0, 2.0, 0.8463146917204395, 1.0, 1.0, 0.8463146917204395, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9258785666955, 1930481.624846716, 1930481.624846715, 363262.1182484517], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6194400.0000, 
sim time next is 6195000.0000, 
raw observation next is [29.98333333333333, 51.33333333333333, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9882905247834822, 7.045508999358715, 6.9112, 121.9252920092352, 1959101.437182046, 1890323.648523672, 382316.1901954151], 
processed observation next is [1.0, 0.6956521739130435, 0.6660493827160493, 0.5133333333333333, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9853631559793526, 0.013430899935871477, 0.0, 0.809457145574039, 0.6996790847078735, 0.6751155887584543, 0.7352234426834906], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9251356], dtype=float32), -0.27418324]. 
=============================================
[2019-03-24 03:28:17,587] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[42.241604]
 [42.03781 ]
 [41.65098 ]
 [41.074814]
 [40.857082]], R is [[41.78478241]
 [41.66835403]
 [41.25167084]
 [40.83915329]
 [40.43076324]].
[2019-03-24 03:28:17,683] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1224714: loss 2.1299
[2019-03-24 03:28:17,685] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1224715: learning rate 0.0000
[2019-03-24 03:28:18,129] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1224933: loss 2.0073
[2019-03-24 03:28:18,133] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1224933: learning rate 0.0000
[2019-03-24 03:28:18,261] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 03:28:18,263] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:28:18,264] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:28:18,265] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:28:18,266] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:28:18,266] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:28:18,266] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:28:18,266] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:28:18,267] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:28:18,268] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:28:18,270] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:28:18,289] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run50
[2019-03-24 03:28:18,290] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run50
[2019-03-24 03:28:18,309] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run50
[2019-03-24 03:28:18,312] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run50
[2019-03-24 03:28:18,387] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run50
[2019-03-24 03:28:22,438] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01415907], dtype=float32), 0.29994625]
[2019-03-24 03:28:22,438] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.86666666666667, 30.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5147342559009205, 6.911200000000001, 6.9112, 121.9260426156618, 367527.764116126, 367527.7641161255, 106402.49087463]
[2019-03-24 03:28:22,439] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:28:22,442] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 7.6597472e-25 4.3063016e-22 4.3972650e-17 9.4815925e-21], sampled 0.27714338670090555
[2019-03-24 03:28:23,059] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01415907], dtype=float32), 0.29994625]
[2019-03-24 03:28:23,061] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.83333333333334, 52.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4474458481564361, 6.9112, 6.9112, 121.9260426156618, 319472.8531089611, 319472.8531089611, 93548.16946047287]
[2019-03-24 03:28:23,063] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:28:23,066] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 9.0202251e-25 5.4186893e-22 4.3859399e-17 9.4368844e-21], sampled 0.8370274904168581
[2019-03-24 03:28:24,932] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01415907], dtype=float32), 0.29994625]
[2019-03-24 03:28:24,932] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.67717370833333, 40.87873330666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.684793500870204, 6.911199999999999, 6.9112, 121.9260426156618, 511690.1836292362, 511690.1836292366, 142670.0969743376]
[2019-03-24 03:28:24,934] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:28:24,936] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.6698774e-27 1.5756520e-24 7.6491123e-19 6.9340697e-23], sampled 0.9407343944055444
[2019-03-24 03:29:00,012] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01415907], dtype=float32), 0.29994625]
[2019-03-24 03:29:00,013] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.33333333333334, 81.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.158626562754387, 6.9112, 121.9249478872739, 2004913.156436431, 1878209.779203456, 383246.4725920904]
[2019-03-24 03:29:00,014] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:29:00,017] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 5.5293766e-23 7.2079614e-21 1.4160210e-15 6.8031056e-19], sampled 0.592659476105323
[2019-03-24 03:29:00,017] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2004913.156436431 W.
[2019-03-24 03:29:02,407] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01415907], dtype=float32), 0.29994625]
[2019-03-24 03:29:02,408] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.2, 93.33333333333334, 1.0, 2.0, 0.6813678306552569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 776555.8182133221, 776555.8182133221, 172645.2883383279]
[2019-03-24 03:29:02,409] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:29:02,411] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.7344920e-26 7.2338987e-24 5.1135776e-18 7.1835825e-22], sampled 0.34588801006986936
[2019-03-24 03:29:02,413] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 776555.8182133221 W.
[2019-03-24 03:29:28,835] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01415907], dtype=float32), 0.29994625]
[2019-03-24 03:29:28,869] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.85016225, 48.995448185, 1.0, 1.0, 0.5527792373801831, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9259072702673, 679035.5569602576, 679035.5569602576, 152071.3573040204]
[2019-03-24 03:29:28,870] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:29:28,874] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 5.4798210e-23 1.3090625e-20 1.0362993e-15 4.5045444e-19], sampled 0.14403261418555935
[2019-03-24 03:29:31,948] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01415907], dtype=float32), 0.29994625]
[2019-03-24 03:29:31,950] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.66666666666667, 71.5, 1.0, 2.0, 0.6723961350671249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 766325.6535660009, 766325.6535660009, 170983.8273343123]
[2019-03-24 03:29:31,950] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:29:31,953] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.3876393e-27 7.1879024e-25 9.4638230e-19 9.2597515e-23], sampled 0.5713477785204529
[2019-03-24 03:29:31,955] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 766325.6535660009 W.
[2019-03-24 03:29:56,716] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 03:29:56,787] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 03:29:56,896] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 03:29:56,962] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 03:29:57,013] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 03:29:58,031] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1225000, evaluation results [1225000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 03:29:58,235] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1225096: loss 2.5532
[2019-03-24 03:29:58,237] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1225096: learning rate 0.0000
[2019-03-24 03:30:04,941] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 5.0148211e-27 2.0047086e-24 1.2102337e-18 7.2239985e-24], sum to 1.0000
[2019-03-24 03:30:04,947] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3663
[2019-03-24 03:30:04,956] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 740218.9410213553 W.
[2019-03-24 03:30:04,962] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.8, 62.66666666666667, 1.0, 2.0, 0.6495004107501783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740218.9410213553, 740218.9410213553, 166802.889488688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6276000.0000, 
sim time next is 6276600.0000, 
raw observation next is [29.85, 62.5, 1.0, 2.0, 0.6518416880168916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742888.5275919669, 742888.5275919669, 167226.1142869899], 
processed observation next is [0.0, 0.6521739130434783, 0.6611111111111112, 0.625, 1.0, 1.0, 0.585525819067728, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26531733128284535, 0.26531733128284535, 0.32158868132113444], 
reward next is 0.6784, 
noisyNet noise sample is [array([0.7269017], dtype=float32), 0.083062395]. 
=============================================
[2019-03-24 03:30:06,763] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1229242: loss 311.5583
[2019-03-24 03:30:06,768] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1229242: learning rate 0.0000
[2019-03-24 03:30:11,457] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1231533: loss 173.6012
[2019-03-24 03:30:11,458] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1231533: learning rate 0.0000
[2019-03-24 03:30:11,879] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1231743: loss 184.0169
[2019-03-24 03:30:11,880] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1231743: learning rate 0.0000
[2019-03-24 03:30:12,056] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1231828: loss 122.5870
[2019-03-24 03:30:12,058] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1231828: learning rate 0.0000
[2019-03-24 03:30:12,095] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1231842: loss 70.5742
[2019-03-24 03:30:12,097] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1231843: learning rate 0.0000
[2019-03-24 03:30:12,180] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1231885: loss 100.2728
[2019-03-24 03:30:12,182] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1231886: learning rate 0.0000
[2019-03-24 03:30:12,253] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1231921: loss 90.4870
[2019-03-24 03:30:12,258] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1231921: learning rate 0.0000
[2019-03-24 03:30:12,262] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1231924: loss 102.5426
[2019-03-24 03:30:12,264] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1231925: learning rate 0.0000
[2019-03-24 03:30:12,333] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1231962: loss 81.4981
[2019-03-24 03:30:12,336] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1231962: learning rate 0.0000
[2019-03-24 03:30:12,419] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1232000: loss 109.0592
[2019-03-24 03:30:12,421] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1232000: learning rate 0.0000
[2019-03-24 03:30:12,721] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1232146: loss 80.1921
[2019-03-24 03:30:12,723] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1232146: learning rate 0.0000
[2019-03-24 03:30:13,365] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1232459: loss 70.1021
[2019-03-24 03:30:13,365] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1232459: learning rate 0.0000
[2019-03-24 03:30:13,456] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1232502: loss 32.4796
[2019-03-24 03:30:13,457] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1232502: learning rate 0.0000
[2019-03-24 03:30:13,765] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1232653: loss 28.9362
[2019-03-24 03:30:13,769] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1232654: learning rate 0.0000
[2019-03-24 03:30:14,061] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.9491563e-01 6.2892030e-07 5.8990420e-04 7.3583588e-02 4.3091029e-01], sum to 1.0000
[2019-03-24 03:30:14,068] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4503
[2019-03-24 03:30:14,074] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1044718.613760473 W.
[2019-03-24 03:30:14,079] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.63333333333333, 83.33333333333334, 1.0, 2.0, 0.305499947463031, 1.0, 2.0, 0.305499947463031, 1.0, 2.0, 0.4863658657998278, 6.9112, 6.9112, 121.94756008, 1044718.613760473, 1044718.613760473, 258164.6981480993], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6492000.0000, 
sim time next is 6492600.0000, 
raw observation next is [26.6, 83.5, 1.0, 2.0, 0.450651078706468, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7174511939816982, 6.911199999999999, 6.9112, 121.9260426156618, 1027383.274923648, 1027383.274923649, 240246.9227892422], 
processed observation next is [1.0, 0.13043478260869565, 0.5407407407407407, 0.835, 1.0, 1.0, 0.3460131889362714, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.6468139924771227, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3669225981870171, 0.3669225981870175, 0.462013313056235], 
reward next is 0.5380, 
noisyNet noise sample is [array([0.21625963], dtype=float32), 0.07286993]. 
=============================================
[2019-03-24 03:30:14,340] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1232930: loss 28.5844
[2019-03-24 03:30:14,344] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1232931: learning rate 0.0000
[2019-03-24 03:30:14,743] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1233125: loss 25.5376
[2019-03-24 03:30:14,745] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1233125: learning rate 0.0000
[2019-03-24 03:30:22,788] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1237044: loss 0.0078
[2019-03-24 03:30:22,790] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1237044: learning rate 0.0000
[2019-03-24 03:30:27,805] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1239494: loss 0.1440
[2019-03-24 03:30:27,808] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1239496: learning rate 0.0000
[2019-03-24 03:30:28,070] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1239622: loss 0.0247
[2019-03-24 03:30:28,072] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1239622: learning rate 0.0000
[2019-03-24 03:30:28,343] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1239760: loss 0.0153
[2019-03-24 03:30:28,345] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1239761: learning rate 0.0000
[2019-03-24 03:30:28,347] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1239762: loss 0.0482
[2019-03-24 03:30:28,350] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1239762: learning rate 0.0000
[2019-03-24 03:30:28,420] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1239800: loss 0.1081
[2019-03-24 03:30:28,423] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1239800: learning rate 0.0000
[2019-03-24 03:30:28,706] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1239942: loss 0.4329
[2019-03-24 03:30:28,712] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1239943: learning rate 0.0000
[2019-03-24 03:30:28,899] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1240036: loss 0.2814
[2019-03-24 03:30:28,901] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1240036: learning rate 0.0000
[2019-03-24 03:30:28,911] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1240040: loss 0.2478
[2019-03-24 03:30:28,913] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1240040: learning rate 0.0000
[2019-03-24 03:30:28,927] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1240047: loss 0.6900
[2019-03-24 03:30:28,928] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1240047: learning rate 0.0000
[2019-03-24 03:30:29,015] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1240093: loss 0.0603
[2019-03-24 03:30:29,017] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1240093: learning rate 0.0000
[2019-03-24 03:30:29,776] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1240462: loss 0.8463
[2019-03-24 03:30:29,780] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1240462: learning rate 0.0000
[2019-03-24 03:30:29,911] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1240527: loss 0.2451
[2019-03-24 03:30:29,912] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1240528: learning rate 0.0000
[2019-03-24 03:30:30,144] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1240640: loss 0.0113
[2019-03-24 03:30:30,146] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1240641: learning rate 0.0000
[2019-03-24 03:30:30,498] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8084518e-06 1.3012405e-32 7.1593822e-23 8.3697125e-17 9.9999821e-01], sum to 1.0000
[2019-03-24 03:30:30,504] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7648
[2019-03-24 03:30:30,513] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.98333333333333, 50.5, 1.0, 2.0, 0.3721467641615147, 1.0, 2.0, 0.3721467641615147, 1.0, 2.0, 0.596097419008972, 6.9112, 6.9112, 121.94756008, 1316304.174076129, 1316304.174076129, 285015.8782733012], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6792600.0000, 
sim time next is 6793200.0000, 
raw observation next is [28.0, 51.0, 1.0, 2.0, 0.3719305356642184, 1.0, 2.0, 0.3719305356642184, 1.0, 2.0, 0.5952858197319939, 6.911200000000001, 6.9112, 121.94756008, 1312406.828788655, 1312406.828788655, 284957.6082370094], 
processed observation next is [1.0, 0.6521739130434783, 0.5925925925925926, 0.51, 1.0, 1.0, 0.2522982567431172, 1.0, 1.0, 0.2522982567431172, 1.0, 1.0, 0.4941072746649923, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.46871672456737684, 0.46871672456737684, 0.5479954004557873], 
reward next is 0.4520, 
noisyNet noise sample is [array([-0.31313494], dtype=float32), 0.17364582]. 
=============================================
[2019-03-24 03:30:31,018] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1241066: loss 0.4615
[2019-03-24 03:30:31,020] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1241066: learning rate 0.0000
[2019-03-24 03:30:31,323] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9999595e-01 1.7778832e-31 2.0497066e-23 9.8246826e-20 4.0817554e-06], sum to 1.0000
[2019-03-24 03:30:31,335] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2031
[2019-03-24 03:30:31,339] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.1, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7743573569285047, 6.9112, 6.9112, 121.9260426156618, 576656.8201737145, 576656.8201737145, 156303.2822150541], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6818400.0000, 
sim time next is 6819000.0000, 
raw observation next is [24.01666666666667, 77.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7775508421126167, 6.911200000000001, 6.9112, 121.9260426156618, 578964.3497979699, 578964.3497979695, 156738.5071558079], 
processed observation next is [1.0, 0.9565217391304348, 0.4450617283950618, 0.7766666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7219385526407709, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20677298207070355, 0.20677298207070338, 0.30142020606886133], 
reward next is 0.6986, 
noisyNet noise sample is [array([1.5717441], dtype=float32), -0.6517192]. 
=============================================
[2019-03-24 03:30:31,351] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[78.44158 ]
 [78.624405]
 [79.10982 ]
 [79.34387 ]
 [79.838   ]], R is [[77.88705444]
 [77.80760193]
 [77.72957611]
 [77.6529541 ]
 [77.57776642]].
[2019-03-24 03:30:31,466] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1241288: loss 4.1175
[2019-03-24 03:30:31,472] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1241289: learning rate 0.0000
[2019-03-24 03:30:39,200] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1245087: loss -9.7820
[2019-03-24 03:30:39,204] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1245088: learning rate 0.0000
[2019-03-24 03:30:44,283] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1247559: loss 6.9588
[2019-03-24 03:30:44,285] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1247559: learning rate 0.0000
[2019-03-24 03:30:44,505] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1247667: loss 45.2778
[2019-03-24 03:30:44,508] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1247669: learning rate 0.0000
[2019-03-24 03:30:44,676] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9976760e-01 4.5570377e-18 4.0791487e-14 1.7980431e-11 2.3241056e-04], sum to 1.0000
[2019-03-24 03:30:44,684] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5607
[2019-03-24 03:30:44,692] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1429415.060734553 W.
[2019-03-24 03:30:44,696] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.06666666666667, 63.66666666666666, 1.0, 2.0, 0.9980836841939614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.388061874570272, 6.9112, 121.9242173706525, 1429415.060734553, 1185222.815160846, 242734.7451318541], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7044000.0000, 
sim time next is 7044600.0000, 
raw observation next is [27.23333333333333, 62.83333333333334, 1.0, 2.0, 0.5818947707400149, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9302051709336423, 6.911200000000001, 6.9112, 121.9257554543701, 1363244.699374214, 1363244.699374214, 286187.4489129804], 
processed observation next is [1.0, 0.5217391304347826, 0.5641975308641974, 0.6283333333333334, 1.0, 1.0, 0.5022556794523987, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.9127564636670529, 8.881784197001253e-17, 0.0, 0.8094602223677858, 0.48687310691936214, 0.48687310691936214, 0.5503604786788084], 
reward next is 0.4496, 
noisyNet noise sample is [array([0.5431005], dtype=float32), -1.2953252]. 
=============================================
[2019-03-24 03:30:44,710] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1247771: loss 47.7403
[2019-03-24 03:30:44,713] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1247771: learning rate 0.0000
[2019-03-24 03:30:44,759] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1247787: loss -2.3657
[2019-03-24 03:30:44,763] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1247787: learning rate 0.0000
[2019-03-24 03:30:44,934] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1247869: loss -2.2264
[2019-03-24 03:30:44,939] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1247870: learning rate 0.0000
[2019-03-24 03:30:45,102] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1247949: loss 5.9005
[2019-03-24 03:30:45,107] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1247950: learning rate 0.0000
[2019-03-24 03:30:45,220] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1248011: loss -0.8284
[2019-03-24 03:30:45,223] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1248011: learning rate 0.0000
[2019-03-24 03:30:45,311] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1248049: loss -35.2429
[2019-03-24 03:30:45,313] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1248050: learning rate 0.0000
[2019-03-24 03:30:45,340] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1248068: loss -68.0389
[2019-03-24 03:30:45,345] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1248069: learning rate 0.0000
[2019-03-24 03:30:45,417] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1248103: loss 73.3499
[2019-03-24 03:30:45,419] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1248103: learning rate 0.0000
[2019-03-24 03:30:46,127] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1248453: loss 43.3357
[2019-03-24 03:30:46,128] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1248453: learning rate 0.0000
[2019-03-24 03:30:46,549] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1248660: loss -26.4484
[2019-03-24 03:30:46,551] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1248660: learning rate 0.0000
[2019-03-24 03:30:46,741] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1248756: loss 27.0536
[2019-03-24 03:30:46,742] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1248756: learning rate 0.0000
[2019-03-24 03:30:47,522] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1249132: loss -19.3978
[2019-03-24 03:30:47,524] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1249133: learning rate 0.0000
[2019-03-24 03:30:47,892] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1249318: loss -22.3469
[2019-03-24 03:30:47,893] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1249318: learning rate 0.0000
[2019-03-24 03:30:49,292] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 03:30:49,294] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:30:49,295] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:30:49,295] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:30:49,296] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:30:49,296] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:30:49,297] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:30:49,298] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:30:49,298] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:30:49,300] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:30:49,299] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:30:49,318] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run51
[2019-03-24 03:30:49,346] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run51
[2019-03-24 03:30:49,347] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run51
[2019-03-24 03:30:49,347] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run51
[2019-03-24 03:30:49,422] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run51
[2019-03-24 03:30:58,766] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01430389], dtype=float32), 0.3114916]
[2019-03-24 03:30:58,768] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.78333333333333, 24.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9324382349319477, 6.9112, 6.9112, 121.9260426156618, 694092.6741572254, 694092.6741572254, 167586.5788487842]
[2019-03-24 03:30:58,769] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:30:58,773] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9999928e-01 2.5889017e-27 7.0189170e-20 1.8474292e-16 6.9407236e-07], sampled 0.8429806763848355
[2019-03-24 03:30:58,773] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 694092.6741572254 W.
[2019-03-24 03:31:06,269] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01430389], dtype=float32), 0.3114916]
[2019-03-24 03:31:06,269] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.55780614, 67.96520692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6545942717750745, 6.9112, 6.9112, 121.9260426156618, 485940.3296729833, 485940.3296729833, 135700.7413328087]
[2019-03-24 03:31:06,270] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:31:06,272] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.8580658e-27 8.2564102e-20 1.0142178e-16 4.2940869e-08], sampled 0.24587278319536632
[2019-03-24 03:31:19,416] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01430389], dtype=float32), 0.3114916]
[2019-03-24 03:31:19,417] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.75, 59.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8259620573850002, 6.911200000000001, 6.9112, 121.9260426156618, 611388.6586564931, 611388.6586564926, 164477.2543543824]
[2019-03-24 03:31:19,417] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:31:19,419] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9999976e-01 8.8173624e-31 2.4483736e-22 2.2112337e-18 2.9719186e-07], sampled 0.38439931570522823
[2019-03-24 03:31:21,679] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01430389], dtype=float32), 0.3114916]
[2019-03-24 03:31:21,681] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.66666666666667, 73.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9169209848196023, 6.911200000000001, 6.9112, 121.9260426156618, 669029.4066591186, 669029.4066591181, 178594.3256155897]
[2019-03-24 03:31:21,682] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:31:21,685] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.000000e+00 7.687247e-29 4.132668e-21 8.405527e-18 1.514418e-08], sampled 0.34945629236366493
[2019-03-24 03:31:44,996] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01430389], dtype=float32), 0.3114916]
[2019-03-24 03:31:44,997] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.13333333333333, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7305522246901311, 6.911199999999999, 6.9112, 121.9260426156618, 545869.7678061078, 545869.7678061082, 147569.3786147819]
[2019-03-24 03:31:44,998] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:31:45,001] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.8588155e-27 4.3365060e-20 6.7198796e-17 5.5338926e-08], sampled 0.8201057021904293
[2019-03-24 03:31:48,807] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01430389], dtype=float32), 0.3114916]
[2019-03-24 03:31:48,807] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.0, 70.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.740534100335359, 6.911200000000001, 6.9112, 121.9260426156618, 552086.0939760252, 552086.0939760248, 151790.9677369016]
[2019-03-24 03:31:48,808] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:31:48,811] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 4.4643403e-28 1.4348146e-20 2.2363109e-17 1.8750175e-08], sampled 0.5513714648417987
[2019-03-24 03:32:03,106] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01430389], dtype=float32), 0.3114916]
[2019-03-24 03:32:03,107] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.98333333333333, 72.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8600725439324944, 6.9112, 6.9112, 121.9260426156618, 633864.6358115331, 633864.6358115331, 169652.5846849256]
[2019-03-24 03:32:03,108] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:32:03,113] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9999988e-01 1.8193732e-29 1.8450451e-21 7.7302518e-18 1.0861257e-07], sampled 0.07297433673041176
[2019-03-24 03:32:26,787] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01430389], dtype=float32), 0.3114916]
[2019-03-24 03:32:26,789] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.82736947, 14.44563667, 1.0, 2.0, 0.6394850520489355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 825151.0477433519, 825151.0477433519, 154864.2532103084]
[2019-03-24 03:32:26,789] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:32:26,793] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9844533e-01 1.0420017e-27 1.2553465e-19 1.8258464e-15 1.5547335e-03], sampled 0.4962763000436011
[2019-03-24 03:32:26,794] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 825151.0477433519 W.
[2019-03-24 03:32:27,204] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8550.4937 2258595680.0605 533.0000
[2019-03-24 03:32:27,414] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8354.7358 2339573219.8281 609.0000
[2019-03-24 03:32:27,754] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7828.2277 2530809901.7119 793.0000
[2019-03-24 03:32:27,772] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8624.3840 2219670284.6913 541.0000
[2019-03-24 03:32:27,823] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8400.2176 2293402254.3997 687.0000
[2019-03-24 03:32:28,838] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1250000, evaluation results [1250000.0, 7828.227710967149, 2530809901.7119336, 793.0, 8550.49370016535, 2258595680.060485, 533.0, 8624.384018467277, 2219670284.6913342, 541.0, 8354.7357803683, 2339573219.828057, 609.0, 8400.217553617278, 2293402254.399713, 687.0]
[2019-03-24 03:32:31,142] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.8969716e-01 1.2643488e-18 4.9203083e-11 2.4416460e-11 1.0302868e-02], sum to 1.0000
[2019-03-24 03:32:31,148] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5059
[2019-03-24 03:32:31,156] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.85, 90.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6133221966070712, 6.911199999999999, 6.9112, 121.9260426156618, 456447.7302453273, 456447.7302453278, 132588.0504277539], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7191000.0000, 
sim time next is 7191600.0000, 
raw observation next is [19.93333333333333, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6111427339458478, 6.911200000000001, 6.9112, 121.9260426156618, 454894.6098204996, 454894.6098204992, 132438.3775918866], 
processed observation next is [1.0, 0.21739130434782608, 0.293827160493827, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5139284174323098, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16246236065017844, 0.16246236065017827, 0.25468918767670495], 
reward next is 0.7453, 
noisyNet noise sample is [array([0.61109716], dtype=float32), 1.5735666]. 
=============================================
[2019-03-24 03:32:35,015] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1253036: loss 1.9849
[2019-03-24 03:32:35,019] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1253037: learning rate 0.0000
[2019-03-24 03:32:38,446] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4107568e-05 2.4221768e-32 4.1544064e-21 1.6417205e-21 9.9998593e-01], sum to 1.0000
[2019-03-24 03:32:38,453] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9339
[2019-03-24 03:32:38,457] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 65.33333333333334, 1.0, 2.0, 0.3689341388928367, 1.0, 2.0, 0.3689341388928367, 1.0, 2.0, 0.5894789370191805, 6.9112, 6.9112, 121.94756008, 1294002.996177849, 1294002.996177849, 283755.6495634318], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7305600.0000, 
sim time next is 7306200.0000, 
raw observation next is [26.2, 64.5, 1.0, 2.0, 0.4033098771182062, 1.0, 2.0, 0.4033098771182062, 1.0, 2.0, 0.6434098494654347, 6.9112, 6.9112, 121.94756008, 1404855.172181752, 1404855.172181752, 298612.1042560975], 
processed observation next is [1.0, 0.5652173913043478, 0.5259259259259259, 0.645, 1.0, 1.0, 0.28965461561691214, 1.0, 1.0, 0.28965461561691214, 1.0, 1.0, 0.5542623118317933, 0.0, 0.0, 0.8096049824067558, 0.5017339900649115, 0.5017339900649115, 0.5742540466463414], 
reward next is 0.4257, 
noisyNet noise sample is [array([-1.3206587], dtype=float32), -1.2568659]. 
=============================================
[2019-03-24 03:32:40,054] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1255487: loss 0.7536
[2019-03-24 03:32:40,055] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1255488: learning rate 0.0000
[2019-03-24 03:32:40,358] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1255638: loss 0.0092
[2019-03-24 03:32:40,362] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1255638: learning rate 0.0000
[2019-03-24 03:32:40,589] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9979955e-01 1.2683971e-20 7.6111787e-17 4.7469945e-12 2.0050822e-04], sum to 1.0000
[2019-03-24 03:32:40,597] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7129
[2019-03-24 03:32:40,601] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.76666666666667, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6368476782525725, 6.9112, 6.9112, 121.9260426156618, 474673.5228734468, 474673.5228734468, 135578.4573232082], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7359600.0000, 
sim time next is 7360200.0000, 
raw observation next is [19.7, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6350311283239362, 6.911200000000001, 6.9112, 121.9260426156618, 473345.7990671538, 473345.7990671533, 135425.7060720485], 
processed observation next is [1.0, 0.17391304347826086, 0.28518518518518515, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5437889104049202, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1690520710954121, 0.1690520710954119, 0.2604340501385548], 
reward next is 0.7396, 
noisyNet noise sample is [array([-0.32782573], dtype=float32), -0.38251135]. 
=============================================
[2019-03-24 03:32:40,621] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1255766: loss -2.4620
[2019-03-24 03:32:40,628] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1255769: learning rate 0.0000
[2019-03-24 03:32:40,689] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1255802: loss 0.2110
[2019-03-24 03:32:40,691] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1255802: learning rate 0.0000
[2019-03-24 03:32:40,869] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1255893: loss 0.2665
[2019-03-24 03:32:40,874] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1255893: learning rate 0.0000
[2019-03-24 03:32:40,878] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1255895: loss 0.3807
[2019-03-24 03:32:40,882] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1255896: learning rate 0.0000
[2019-03-24 03:32:40,965] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1255939: loss 0.0247
[2019-03-24 03:32:40,969] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1255940: learning rate 0.0000
[2019-03-24 03:32:41,096] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1255999: loss 0.1207
[2019-03-24 03:32:41,099] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1255999: learning rate 0.0000
[2019-03-24 03:32:41,177] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1256042: loss 0.5518
[2019-03-24 03:32:41,179] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1256042: learning rate 0.0000
[2019-03-24 03:32:41,267] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1256082: loss 0.0862
[2019-03-24 03:32:41,270] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1256083: learning rate 0.0000
[2019-03-24 03:32:41,787] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1256339: loss 0.0239
[2019-03-24 03:32:41,789] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1256339: learning rate 0.0000
[2019-03-24 03:32:42,144] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1256513: loss 0.1327
[2019-03-24 03:32:42,145] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1256513: learning rate 0.0000
[2019-03-24 03:32:42,643] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1256755: loss 0.0077
[2019-03-24 03:32:42,645] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1256756: learning rate 0.0000
[2019-03-24 03:32:43,185] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1257016: loss 0.0491
[2019-03-24 03:32:43,187] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1257016: learning rate 0.0000
[2019-03-24 03:32:43,744] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1257291: loss 0.0533
[2019-03-24 03:32:43,747] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1257292: learning rate 0.0000
[2019-03-24 03:32:46,556] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 5.6726016e-25 6.0804572e-16 3.9528255e-17 2.5418010e-11], sum to 1.0000
[2019-03-24 03:32:46,561] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3489
[2019-03-24 03:32:46,564] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.3, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6731343788120792, 6.911199999999999, 6.9112, 121.9260426156618, 503020.7948164151, 503020.7948164156, 141854.4789759575], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7462800.0000, 
sim time next is 7463400.0000, 
raw observation next is [21.45, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6788014717298921, 6.911199999999999, 6.9112, 121.9260426156618, 507249.6834899749, 507249.6834899753, 142696.4129326668], 
processed observation next is [0.0, 0.391304347826087, 0.35, 0.885, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5985018396623651, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1811606012464196, 0.18116060124641975, 0.27441617871666696], 
reward next is 0.7256, 
noisyNet noise sample is [array([-0.23076022], dtype=float32), 0.13736655]. 
=============================================
[2019-03-24 03:32:51,215] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.3215960e-28 2.9536972e-22 4.8276428e-18 7.0620533e-13], sum to 1.0000
[2019-03-24 03:32:51,226] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0775
[2019-03-24 03:32:51,229] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.03333333333334, 77.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8318991964837318, 6.9112, 6.9112, 121.9260426156618, 614476.3394502717, 614476.3394502717, 165666.4839199629], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7489200.0000, 
sim time next is 7489800.0000, 
raw observation next is [25.0, 77.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8311644086637827, 6.9112, 6.9112, 121.9260426156618, 613986.5031546819, 613986.5031546819, 165557.5741297115], 
processed observation next is [0.0, 0.6956521739130435, 0.48148148148148145, 0.775, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7889555108297283, 0.0, 0.0, 0.8094621288201359, 0.21928089398381495, 0.21928089398381495, 0.31837995024944515], 
reward next is 0.6816, 
noisyNet noise sample is [array([0.5338649], dtype=float32), 0.012085982]. 
=============================================
[2019-03-24 03:32:51,458] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1261054: loss -31.9054
[2019-03-24 03:32:51,461] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1261056: learning rate 0.0000
[2019-03-24 03:32:56,446] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1263504: loss 0.4520
[2019-03-24 03:32:56,448] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1263504: learning rate 0.0000
[2019-03-24 03:32:56,719] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1263639: loss 2.1948
[2019-03-24 03:32:56,728] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1263639: learning rate 0.0000
[2019-03-24 03:32:56,950] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1263750: loss 1.0453
[2019-03-24 03:32:56,955] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1263751: learning rate 0.0000
[2019-03-24 03:32:57,105] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1263830: loss 0.0661
[2019-03-24 03:32:57,109] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1263830: learning rate 0.0000
[2019-03-24 03:32:57,189] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1263867: loss 0.0743
[2019-03-24 03:32:57,191] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1263868: learning rate 0.0000
[2019-03-24 03:32:57,262] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1263905: loss 0.0727
[2019-03-24 03:32:57,265] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1263905: learning rate 0.0000
[2019-03-24 03:32:57,290] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1263921: loss 0.1923
[2019-03-24 03:32:57,294] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1263921: learning rate 0.0000
[2019-03-24 03:32:57,497] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1264016: loss 0.0377
[2019-03-24 03:32:57,500] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1264017: learning rate 0.0000
[2019-03-24 03:32:57,516] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1264025: loss 0.1097
[2019-03-24 03:32:57,517] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1264025: learning rate 0.0000
[2019-03-24 03:32:57,614] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1264077: loss 0.1698
[2019-03-24 03:32:57,616] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1264077: learning rate 0.0000
[2019-03-24 03:32:58,157] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1264341: loss 0.1035
[2019-03-24 03:32:58,164] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1264341: learning rate 0.0000
[2019-03-24 03:32:58,486] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1264500: loss -7.7963
[2019-03-24 03:32:58,487] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1264500: learning rate 0.0000
[2019-03-24 03:32:59,044] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1264775: loss -12.2335
[2019-03-24 03:32:59,046] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1264775: learning rate 0.0000
[2019-03-24 03:33:00,119] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1265299: loss -106.0360
[2019-03-24 03:33:00,121] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1265299: learning rate 0.0000
[2019-03-24 03:33:00,350] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1265408: loss -19.1864
[2019-03-24 03:33:00,351] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1265409: learning rate 0.0000
[2019-03-24 03:33:05,793] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.9543918e-03 1.7802323e-16 7.4244756e-11 9.8985842e-10 9.9104553e-01], sum to 1.0000
[2019-03-24 03:33:05,800] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7601
[2019-03-24 03:33:05,805] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.31666666666667, 45.5, 1.0, 2.0, 0.2441854677005103, 1.0, 1.0, 0.2441854677005103, 1.0, 2.0, 0.4035745546704652, 6.9112, 6.9112, 121.94756008, 904774.200977453, 904774.200977453, 233651.1657761729], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7807800.0000, 
sim time next is 7808400.0000, 
raw observation next is [26.5, 45.0, 1.0, 2.0, 0.237815013471832, 1.0, 2.0, 0.237815013471832, 1.0, 2.0, 0.3919229331289407, 6.9112, 6.9112, 121.94756008, 878812.4183062708, 878812.4183062708, 231585.5637749998], 
processed observation next is [1.0, 0.391304347826087, 0.5370370370370371, 0.45, 1.0, 1.0, 0.09263692079980002, 1.0, 1.0, 0.09263692079980002, 1.0, 1.0, 0.2399036664111759, 0.0, 0.0, 0.8096049824067558, 0.3138615779665253, 0.3138615779665253, 0.4453568534134612], 
reward next is 0.5546, 
noisyNet noise sample is [array([-0.7415562], dtype=float32), 0.38696435]. 
=============================================
[2019-03-24 03:33:08,164] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.8608997e-01 2.9376110e-18 5.1888905e-12 1.7692361e-09 5.1391006e-01], sum to 1.0000
[2019-03-24 03:33:08,172] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0266
[2019-03-24 03:33:08,177] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1381717.106828997 W.
[2019-03-24 03:33:08,181] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.1, 34.5, 1.0, 2.0, 0.5728014177664342, 1.0, 1.0, 0.5728014177664342, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1381717.106828997, 1381717.106828997, 262037.5694899707], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7835400.0000, 
sim time next is 7836000.0000, 
raw observation next is [31.13333333333333, 35.0, 1.0, 2.0, 0.5752281276249748, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9327659451495772, 6.911199999999999, 6.9112, 121.9260426156618, 1390622.805335901, 1390622.805335901, 282061.5674511439], 
processed observation next is [1.0, 0.6956521739130435, 0.7086419753086418, 0.35, 1.0, 1.0, 0.49431919955354137, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9159574314369714, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4966510019056789, 0.4966510019056789, 0.5424260912521999], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.39337203], dtype=float32), 0.44143254]. 
=============================================
[2019-03-24 03:33:08,202] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[54.99299 ]
 [54.429764]
 [54.450584]
 [53.9561  ]
 [54.007507]], R is [[54.35518646]
 [53.81163406]
 [53.27351761]
 [52.74078369]
 [52.70365906]].
[2019-03-24 03:33:08,463] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:33:08,464] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:08,532] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run7
[2019-03-24 03:33:10,786] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 8.5024615e-27 1.5478341e-20 4.7273873e-20 1.6692571e-15], sum to 1.0000
[2019-03-24 03:33:10,797] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6138
[2019-03-24 03:33:10,807] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.8, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6353953339962553, 6.911199999999999, 6.9112, 121.9260426156618, 472251.8701632455, 472251.8701632459, 134233.4410474738], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7880400.0000, 
sim time next is 7881000.0000, 
raw observation next is [19.93333333333333, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6962068804396645, 6.9112, 6.9112, 121.9260426156618, 517394.9871402792, 517394.9871402792, 140307.2616053842], 
processed observation next is [1.0, 0.21739130434782608, 0.293827160493827, 0.88, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6202586005495806, 0.0, 0.0, 0.8094621288201359, 0.18478392397867113, 0.18478392397867113, 0.2698216569334312], 
reward next is 0.7302, 
noisyNet noise sample is [array([-1.8334299], dtype=float32), -0.06224117]. 
=============================================
[2019-03-24 03:33:10,825] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[63.64917 ]
 [63.86965 ]
 [63.88202 ]
 [64.0303  ]
 [64.028114]], R is [[63.80380249]
 [63.90762329]
 [64.0087738 ]
 [64.10676575]
 [64.20067596]].
[2019-03-24 03:33:11,098] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.9727082e-26 1.2383133e-20 5.9876668e-18 5.6901117e-18], sum to 1.0000
[2019-03-24 03:33:11,100] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5525
[2019-03-24 03:33:11,108] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.2, 79.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6328530642710185, 6.911200000000001, 6.9112, 121.9260426156618, 470918.9867755907, 470918.9867755902, 134438.3205353153], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7886400.0000, 
sim time next is 7887000.0000, 
raw observation next is [21.35, 78.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6345032704245321, 6.9112, 6.9112, 121.9260426156618, 472260.8182454483, 472260.8182454483, 134700.1199351659], 
processed observation next is [1.0, 0.2608695652173913, 0.3462962962962963, 0.7883333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5431290880306652, 0.0, 0.0, 0.8094621288201359, 0.16866457794480297, 0.16866457794480297, 0.25903869218301134], 
reward next is 0.7410, 
noisyNet noise sample is [array([2.314681], dtype=float32), -0.80209905]. 
=============================================
[2019-03-24 03:33:11,148] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[61.23871 ]
 [61.245354]
 [61.41749 ]
 [61.518578]
 [61.621998]], R is [[61.28944778]
 [61.41802216]
 [61.54532623]
 [61.67084503]
 [61.78905106]].
[2019-03-24 03:33:13,390] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:33:13,390] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:13,417] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run7
[2019-03-24 03:33:13,510] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:33:13,511] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:13,528] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run7
[2019-03-24 03:33:13,701] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:33:13,701] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:13,715] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run7
[2019-03-24 03:33:13,961] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:33:13,961] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:13,965] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run7
[2019-03-24 03:33:13,986] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:33:13,987] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:13,992] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run7
[2019-03-24 03:33:14,029] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:33:14,029] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:14,034] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run7
[2019-03-24 03:33:14,063] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:33:14,064] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:14,065] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:33:14,065] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:14,069] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run7
[2019-03-24 03:33:14,095] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:33:14,097] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:14,107] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run7
[2019-03-24 03:33:14,141] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run7
[2019-03-24 03:33:14,171] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:33:14,172] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:14,180] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run7
[2019-03-24 03:33:14,341] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:33:14,341] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:14,344] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run7
[2019-03-24 03:33:14,409] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:33:14,409] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:14,413] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run7
[2019-03-24 03:33:14,529] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:33:14,529] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:14,532] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run7
[2019-03-24 03:33:14,833] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:33:14,833] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:14,836] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run7
[2019-03-24 03:33:14,913] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:33:14,914] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:14,917] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run7
[2019-03-24 03:33:21,306] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 03:33:21,312] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:33:21,313] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:33:21,313] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:21,314] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:33:21,313] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:21,317] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:33:21,317] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:21,316] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:33:21,318] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:21,320] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:33:21,337] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run52
[2019-03-24 03:33:21,369] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run52
[2019-03-24 03:33:21,390] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run52
[2019-03-24 03:33:21,416] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run52
[2019-03-24 03:33:21,417] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run52
[2019-03-24 03:33:45,700] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02081867], dtype=float32), 0.3203752]
[2019-03-24 03:33:45,701] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.9, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6714254419753622, 6.911200000000001, 6.9112, 121.9260426156618, 501739.0532805936, 501739.0532805931, 141860.5341639325]
[2019-03-24 03:33:45,702] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:33:45,704] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.7640357e-25 3.3428736e-19 1.3615960e-17 3.7565915e-17], sampled 0.003366669161037117
[2019-03-24 03:33:54,440] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02081867], dtype=float32), 0.3203752]
[2019-03-24 03:33:54,441] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.0, 94.0, 1.0, 2.0, 0.7396871156825428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 853497.5089342619, 853497.5089342619, 184320.3269493743]
[2019-03-24 03:33:54,442] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:33:54,444] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.5261858e-22 6.9556559e-17 4.5890017e-15 2.9477939e-14], sampled 0.5785843512878803
[2019-03-24 03:33:54,445] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 853497.5089342619 W.
[2019-03-24 03:34:05,663] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02081867], dtype=float32), 0.3203752]
[2019-03-24 03:34:05,664] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.1, 64.0, 1.0, 2.0, 0.9796003467319704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.018977247903631, 6.9112, 121.9254883760485, 1171931.019372478, 1116739.686309276, 235848.7147948344]
[2019-03-24 03:34:05,665] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:34:05,667] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.00000000e+00 4.88079128e-24 1.03519586e-17 1.46955579e-15
 4.07236128e-14], sampled 0.04675847071143768
[2019-03-24 03:34:05,668] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1171931.019372478 W.
[2019-03-24 03:34:40,866] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02081867], dtype=float32), 0.3203752]
[2019-03-24 03:34:40,866] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.9, 73.0, 1.0, 2.0, 0.5619699359890727, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8946744401776839, 6.911200000000001, 6.9112, 121.9260425466375, 1281377.506004448, 1281377.506004448, 279358.9940736451]
[2019-03-24 03:34:40,867] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:34:40,872] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.5434760e-21 4.8208023e-16 3.2628546e-14 2.8783348e-13], sampled 0.6447173048117473
[2019-03-24 03:34:40,873] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1281377.506004448 W.
[2019-03-24 03:34:52,707] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02081867], dtype=float32), 0.3203752]
[2019-03-24 03:34:52,709] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.83333333333334, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5034898687536863, 6.911200000000001, 6.9112, 121.9260426156618, 363070.6056715272, 363070.6056715267, 116623.1062581459]
[2019-03-24 03:34:52,711] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:34:52,714] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.0141902e-25 3.3947394e-19 1.3010295e-17 3.3731724e-17], sampled 0.022201487877188675
[2019-03-24 03:34:59,357] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 03:34:59,844] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 03:34:59,983] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 03:35:00,027] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 03:35:00,049] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 03:35:01,067] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1275000, evaluation results [1275000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 03:35:06,215] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 3.4787483e-32 9.6247164e-25 3.8909723e-20 1.8655084e-18], sum to 1.0000
[2019-03-24 03:35:06,221] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2233
[2019-03-24 03:35:06,225] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.1, 28.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6079551476798267, 6.9112, 6.9112, 121.9260426156618, 446980.8524579622, 446980.8524579622, 128685.6463736377], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 213600.0000, 
sim time next is 214200.0000, 
raw observation next is [30.3, 27.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6115625327412142, 6.911199999999999, 6.9112, 121.9260426156618, 449103.6518738228, 449103.6518738233, 128761.4134901223], 
processed observation next is [0.0, 0.4782608695652174, 0.6777777777777778, 0.27, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5144531659265177, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16039416138350815, 0.16039416138350832, 0.2476181028656198], 
reward next is 0.7524, 
noisyNet noise sample is [array([1.0651121], dtype=float32), -1.0136085]. 
=============================================
[2019-03-24 03:35:06,451] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.5504832e-38 5.8213182e-25 3.9494178e-25 7.0393672e-24], sum to 1.0000
[2019-03-24 03:35:06,459] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4480
[2019-03-24 03:35:06,468] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.33333333333333, 31.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5929932918851337, 6.911200000000001, 6.9112, 121.9260426156618, 437406.34360575, 437406.3436057496, 128057.5441332686], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 211800.0000, 
sim time next is 212400.0000, 
raw observation next is [29.7, 30.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5996282584636136, 6.911200000000001, 6.9112, 121.9260426156618, 441810.1954580636, 441810.1954580632, 128406.1016365985], 
processed observation next is [0.0, 0.4782608695652174, 0.6555555555555556, 0.3, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4995353230795169, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.157789355520737, 0.15778935552073686, 0.2469348108396125], 
reward next is 0.7531, 
noisyNet noise sample is [array([-0.01935297], dtype=float32), -0.72054976]. 
=============================================
[2019-03-24 03:35:11,765] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.3693267e-38 2.9602997e-27 1.3187037e-23 1.5890956e-23], sum to 1.0000
[2019-03-24 03:35:11,772] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2342
[2019-03-24 03:35:11,775] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.46666666666667, 33.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5270837704458836, 6.911200000000001, 6.9112, 121.9260426156618, 376347.6611536575, 376347.6611536571, 104778.7081912947], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 291000.0000, 
sim time next is 291600.0000, 
raw observation next is [24.6, 33.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5294685093335407, 6.911200000000001, 6.9112, 121.9260426156618, 378050.828972721, 378050.8289727205, 105248.935799265], 
processed observation next is [0.0, 0.391304347826087, 0.46666666666666673, 0.33, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.41183563666692585, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13501815320454322, 0.13501815320454302, 0.20240179961397117], 
reward next is 0.7976, 
noisyNet noise sample is [array([-0.01879555], dtype=float32), 1.1832652]. 
=============================================
[2019-03-24 03:35:16,106] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 3.5510846e-24 3.7365646e-19 3.1660593e-17 7.7609864e-17], sum to 1.0000
[2019-03-24 03:35:16,110] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7657
[2019-03-24 03:35:16,114] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 49.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5507666245059876, 6.9112, 6.9112, 121.9260426156618, 393261.9971985405, 393261.9971985405, 110908.1918610773], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 369600.0000, 
sim time next is 370200.0000, 
raw observation next is [22.2, 47.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5531412063676806, 6.9112, 6.9112, 121.9260426156618, 394957.9483206547, 394957.9483206547, 111651.2796370376], 
processed observation next is [1.0, 0.2608695652173913, 0.37777777777777777, 0.47666666666666674, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4414265079596007, 0.0, 0.0, 0.8094621288201359, 0.14105641011451953, 0.14105641011451953, 0.2147139993019954], 
reward next is 0.7853, 
noisyNet noise sample is [array([-0.57974416], dtype=float32), 0.8478959]. 
=============================================
[2019-03-24 03:35:28,580] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 8.1365963e-20 2.1652790e-14 7.7358335e-13 9.4137997e-10], sum to 1.0000
[2019-03-24 03:35:28,586] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9428
[2019-03-24 03:35:28,591] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.73333333333333, 54.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5632672345479641, 6.9112, 6.9112, 121.9260426156618, 413940.9884732394, 413940.9884732394, 124601.1114283045], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 611400.0000, 
sim time next is 612000.0000, 
raw observation next is [23.6, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5622927087150368, 6.911200000000001, 6.9112, 121.9260426156618, 413022.0947804286, 413022.0947804282, 124418.1189638292], 
processed observation next is [1.0, 0.08695652173913043, 0.4296296296296297, 0.55, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45286588589379595, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14750789099301023, 0.14750789099301007, 0.23926561339197921], 
reward next is 0.7607, 
noisyNet noise sample is [array([-1.7976203], dtype=float32), 0.5223014]. 
=============================================
[2019-03-24 03:35:28,608] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[53.179913]
 [53.455944]
 [53.587425]
 [53.661976]
 [53.851288]], R is [[53.1766243 ]
 [53.40524292]
 [53.63100052]
 [53.85369873]
 [54.07362366]].
[2019-03-24 03:35:29,115] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.2014659e-26 8.1304654e-17 6.6914451e-14 4.0910578e-12], sum to 1.0000
[2019-03-24 03:35:29,120] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1268
[2019-03-24 03:35:29,126] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.13333333333334, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5714280237589464, 6.9112, 6.9112, 121.9260426156618, 420512.8664451787, 420512.8664451787, 125600.4656116662], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 609600.0000, 
sim time next is 610200.0000, 
raw observation next is [24.0, 53.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5692456383905755, 6.9112, 6.9112, 121.9260426156618, 418723.6066734471, 418723.6066734471, 125316.0103782187], 
processed observation next is [1.0, 0.043478260869565216, 0.4444444444444444, 0.535, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.46155704798821934, 0.0, 0.0, 0.8094621288201359, 0.14954414524051682, 0.14954414524051682, 0.24099232765042058], 
reward next is 0.7590, 
noisyNet noise sample is [array([-1.7663382], dtype=float32), 0.6708999]. 
=============================================
[2019-03-24 03:35:34,571] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.000000e+00 5.101443e-24 1.164817e-17 1.587429e-16 5.413009e-14], sum to 1.0000
[2019-03-24 03:35:34,578] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3576
[2019-03-24 03:35:34,583] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.5, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8414087724930476, 6.911199999999999, 6.9112, 121.9260426156618, 622423.8085279473, 622423.8085279478, 154222.9226260671], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 720000.0000, 
sim time next is 720600.0000, 
raw observation next is [24.63333333333333, 53.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9646146483830733, 7.510208315803556, 6.9112, 121.9240879395817, 1021139.047195226, 714398.1683904169, 167763.4715249112], 
processed observation next is [1.0, 0.34782608695652173, 0.46790123456790106, 0.5383333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9557683104788417, 0.05990083158035562, 0.0, 0.8094491518036839, 0.36469251685543785, 0.25514220299657747, 0.32262206062482923], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3929387], dtype=float32), 0.21514979]. 
=============================================
[2019-03-24 03:35:38,962] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.0318892e-21 9.7422638e-16 9.2614284e-12 5.3934390e-10], sum to 1.0000
[2019-03-24 03:35:38,973] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6227
[2019-03-24 03:35:38,982] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1163550.549621328 W.
[2019-03-24 03:35:38,986] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.86666666666667, 56.16666666666667, 1.0, 2.0, 0.4724384200682916, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7782027312722447, 6.911199999999999, 6.9112, 121.9260426156618, 1163550.549621328, 1163550.549621329, 244107.6394364308], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 989400.0000, 
sim time next is 990000.0000, 
raw observation next is [25.0, 56.0, 1.0, 2.0, 0.437831583609725, 1.0, 1.0, 0.437831583609725, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1074093.150613432, 1074093.150613432, 219792.77398989], 
processed observation next is [1.0, 0.4782608695652174, 0.48148148148148145, 0.56, 1.0, 1.0, 0.3307518852496727, 1.0, 0.5, 0.3307518852496727, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3836046966476543, 0.3836046966476543, 0.42267841151901925], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.90067947], dtype=float32), -0.10121218]. 
=============================================
[2019-03-24 03:35:39,005] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[50.835823]
 [50.48575 ]
 [50.220623]
 [49.72693 ]
 [49.23272 ]], R is [[50.75122833]
 [50.24371719]
 [49.7412796 ]
 [49.24386597]
 [48.7514267 ]].
[2019-03-24 03:35:41,742] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 4.4016978e-31 7.2366106e-22 5.9154392e-21 3.6099080e-18], sum to 1.0000
[2019-03-24 03:35:41,750] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9047
[2019-03-24 03:35:41,754] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.76666666666667, 36.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7190065444205083, 6.9112, 6.9112, 121.9260426156618, 536909.3928697594, 536909.3928697594, 148288.1133301182], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 831000.0000, 
sim time next is 831600.0000, 
raw observation next is [31.8, 36.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7213629780670928, 6.9112, 6.9112, 121.9260426156618, 538629.9263188443, 538629.9263188443, 148619.3352354634], 
processed observation next is [0.0, 0.6521739130434783, 0.7333333333333334, 0.36, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6517037225838659, 0.0, 0.0, 0.8094621288201359, 0.19236783082815867, 0.19236783082815867, 0.2858064139143527], 
reward next is 0.7142, 
noisyNet noise sample is [array([0.16991897], dtype=float32), -0.921427]. 
=============================================
[2019-03-24 03:35:42,652] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.7092422e-24 7.5255066e-17 6.6941189e-16 1.8206717e-14], sum to 1.0000
[2019-03-24 03:35:42,660] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3353
[2019-03-24 03:35:42,663] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.53333333333333, 70.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6193922297384217, 6.911200000000001, 6.9112, 121.9260426156618, 451267.209296388, 451267.2092963876, 127913.7503708655], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1051800.0000, 
sim time next is 1052400.0000, 
raw observation next is [20.46666666666667, 70.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5880352766117085, 6.9112, 6.9112, 121.9260426156618, 428296.3629871624, 428296.3629871624, 125097.1342698011], 
processed observation next is [1.0, 0.17391304347826086, 0.31358024691358033, 0.7066666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4850440957646356, 0.0, 0.0, 0.8094621288201359, 0.15296298678112943, 0.15296298678112943, 0.2405714120573098], 
reward next is 0.7594, 
noisyNet noise sample is [array([-0.81103647], dtype=float32), -0.3721717]. 
=============================================
[2019-03-24 03:35:42,971] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.00000000e+00 1.14216275e-29 3.27689151e-19 2.30802979e-17
 3.75306985e-16], sum to 1.0000
[2019-03-24 03:35:42,979] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8063
[2019-03-24 03:35:42,986] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.05, 58.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6642846220970419, 6.9112, 6.9112, 121.9260426156618, 495740.4223061135, 495740.4223061135, 139105.3344055066], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 862200.0000, 
sim time next is 862800.0000, 
raw observation next is [24.9, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6612234665157243, 6.911200000000001, 6.9112, 121.9260426156618, 493354.4601766877, 493354.4601766872, 138648.0557115433], 
processed observation next is [0.0, 1.0, 0.47777777777777775, 0.59, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5765293331446553, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17619802149167418, 0.17619802149167402, 0.26663087636835253], 
reward next is 0.7334, 
noisyNet noise sample is [array([-0.6381574], dtype=float32), -0.32272944]. 
=============================================
[2019-03-24 03:35:51,569] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 7.4679641e-33 6.2291486e-21 7.3617782e-19 2.5020011e-16], sum to 1.0000
[2019-03-24 03:35:51,580] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6723
[2019-03-24 03:35:51,583] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.13333333333334, 47.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5701550972030982, 6.911200000000001, 6.9112, 121.9260426156618, 424083.2854933984, 424083.285493398, 128288.4686885737], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1012800.0000, 
sim time next is 1013400.0000, 
raw observation next is [25.65, 48.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.555650160688633, 6.911200000000001, 6.9112, 121.9260426156618, 411708.5562696191, 411708.5562696187, 125798.7092257175], 
processed observation next is [1.0, 0.7391304347826086, 0.5055555555555555, 0.485, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44456270086079125, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14703877009629254, 0.14703877009629238, 0.24192059466484134], 
reward next is 0.7581, 
noisyNet noise sample is [array([-0.2304696], dtype=float32), -0.7753247]. 
=============================================
[2019-03-24 03:35:52,344] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 03:35:52,347] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:35:52,349] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:35:52,351] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:35:52,353] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:35:52,353] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:35:52,355] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:35:52,354] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:35:52,357] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:35:52,358] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:35:52,358] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:35:52,379] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run53
[2019-03-24 03:35:52,406] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run53
[2019-03-24 03:35:52,407] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run53
[2019-03-24 03:35:52,408] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run53
[2019-03-24 03:35:52,496] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run53
[2019-03-24 03:35:55,422] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02643776], dtype=float32), 0.3297823]
[2019-03-24 03:35:55,423] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [41.39035693333334, 9.606317034166668, 1.0, 2.0, 0.9756869208772367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.558836893894661, 6.9112, 121.9232584280598, 1548551.795521476, 1216911.393917644, 239371.9874999058]
[2019-03-24 03:35:55,424] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:35:55,427] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.7963045e-30 9.8479770e-22 6.1766962e-19 4.3211952e-14], sampled 0.4229138061647084
[2019-03-24 03:35:55,429] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1548551.795521476 W.
[2019-03-24 03:36:44,195] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02643776], dtype=float32), 0.3297823]
[2019-03-24 03:36:44,198] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.66666666666667, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8450314345310324, 6.9112, 6.9112, 121.9260426156618, 622193.5781624797, 622193.5781624797, 167899.0056880662]
[2019-03-24 03:36:44,200] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:36:44,203] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 5.8948592e-33 1.9777433e-24 3.2238317e-22 9.8092609e-19], sampled 0.93903308484878
[2019-03-24 03:37:24,138] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02643776], dtype=float32), 0.3297823]
[2019-03-24 03:37:24,140] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.495536655613838, 6.9112, 6.9112, 121.9260426156618, 358490.4373315665, 358490.4373315665, 116436.0075666239]
[2019-03-24 03:37:24,142] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:37:24,144] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.1889292e-31 2.8412025e-23 3.6543224e-21 7.5111912e-18], sampled 0.06044556417667013
[2019-03-24 03:37:30,873] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 03:37:30,897] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 03:37:30,984] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 03:37:31,038] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 03:37:31,206] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 03:37:32,221] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1300000, evaluation results [1300000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 03:37:38,965] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9967849e-01 6.1445100e-21 2.3067247e-13 1.9159860e-07 3.2123120e-04], sum to 1.0000
[2019-03-24 03:37:38,971] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2499
[2019-03-24 03:37:38,976] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1100014.66990259 W.
[2019-03-24 03:37:38,982] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.73333333333333, 32.66666666666667, 1.0, 2.0, 0.450120934965356, 1.0, 2.0, 0.450120934965356, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1100014.66990259, 1100014.669902591, 223319.7166908023], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1347600.0000, 
sim time next is 1348200.0000, 
raw observation next is [30.75, 32.5, 1.0, 2.0, 0.898869419165764, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.999565969802566, 6.9112, 121.9256138190874, 1158388.887148446, 1113137.771691079, 220999.5514374958], 
processed observation next is [1.0, 0.6086956521739131, 0.6944444444444444, 0.325, 1.0, 1.0, 0.8796064513878143, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.008836596980256583, 0.0, 0.809459282056799, 0.4137103168387307, 0.39754920417538536, 0.4249991373797996], 
reward next is 0.1332, 
noisyNet noise sample is [array([-1.6881795], dtype=float32), -0.06217702]. 
=============================================
[2019-03-24 03:37:39,312] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.2685643e-20 1.3891465e-15 4.8348337e-13 2.5109883e-09], sum to 1.0000
[2019-03-24 03:37:39,318] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3334
[2019-03-24 03:37:39,321] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.3, 65.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8116248098628757, 6.9112, 6.9112, 121.9260426156618, 593611.3552084342, 593611.3552084342, 147564.0031606257], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1164600.0000, 
sim time next is 1165200.0000, 
raw observation next is [21.36666666666667, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8479456489408155, 6.911200000000001, 6.9112, 121.9260426156618, 618265.9323143841, 618265.9323143837, 150626.8908431231], 
processed observation next is [1.0, 0.4782608695652174, 0.3469135802469137, 0.65, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8099320611760193, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22080926154085148, 0.22080926154085131, 0.28966709777523675], 
reward next is 0.7103, 
noisyNet noise sample is [array([-0.5309038], dtype=float32), 0.013313384]. 
=============================================
[2019-03-24 03:37:46,302] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.00000000e+00 1.06118016e-26 9.19208785e-20 2.35672293e-17
 3.69168765e-15], sum to 1.0000
[2019-03-24 03:37:46,307] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5853
[2019-03-24 03:37:46,314] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.7, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5758084461689269, 6.9112, 6.9112, 121.9260426156618, 425891.0697441535, 425891.0697441535, 127158.4238283086], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1317600.0000, 
sim time next is 1318200.0000, 
raw observation next is [19.93333333333333, 85.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6118626773132825, 6.911200000000001, 6.9112, 121.9260426156618, 453123.1915112764, 453123.1915112759, 130823.7720392104], 
processed observation next is [1.0, 0.2608695652173913, 0.293827160493827, 0.8516666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.514828346641603, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1618297112540273, 0.1618297112540271, 0.2515841769984815], 
reward next is 0.7484, 
noisyNet noise sample is [array([0.10363507], dtype=float32), -0.5008137]. 
=============================================
[2019-03-24 03:37:46,705] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 8.9032999e-27 1.2102290e-18 2.0120255e-16 3.3640555e-13], sum to 1.0000
[2019-03-24 03:37:46,711] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1657
[2019-03-24 03:37:46,716] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6619637434601932, 6.911199999999999, 6.9112, 121.9260426156618, 494261.0894141995, 494261.0894141999, 139271.3296130356], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1288800.0000, 
sim time next is 1289400.0000, 
raw observation next is [21.8, 80.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6599242786417951, 6.911200000000001, 6.9112, 121.9260426156618, 492677.7867240984, 492677.7867240979, 138954.5656639212], 
processed observation next is [1.0, 0.9565217391304348, 0.362962962962963, 0.8016666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5749053483022439, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1759563524014637, 0.17595635240146354, 0.2672203185844639], 
reward next is 0.7328, 
noisyNet noise sample is [array([-1.4889457], dtype=float32), -0.3301276]. 
=============================================
[2019-03-24 03:37:49,494] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.8603661e-30 2.1106936e-23 3.2020238e-17 2.2340918e-19], sum to 1.0000
[2019-03-24 03:37:49,503] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3058
[2019-03-24 03:37:49,508] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.75, 46.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6062472885624866, 6.911200000000001, 6.9112, 121.9260426156618, 450914.5900464834, 450914.590046483, 131677.7710123553], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1367400.0000, 
sim time next is 1368000.0000, 
raw observation next is [26.5, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6108727730928722, 6.911200000000001, 6.9112, 121.9260426156618, 454464.1091072896, 454464.1091072892, 132212.9807632729], 
processed observation next is [1.0, 0.8695652173913043, 0.5370370370370371, 0.48, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5135909663660903, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16230861039546057, 0.1623086103954604, 0.25425573223706327], 
reward next is 0.7457, 
noisyNet noise sample is [array([-2.5079777], dtype=float32), -1.915621]. 
=============================================
[2019-03-24 03:37:49,528] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[75.50543 ]
 [75.36698 ]
 [75.497055]
 [75.34133 ]
 [75.57669 ]], R is [[75.15640259]
 [75.15161133]
 [75.147789  ]
 [75.14461517]
 [75.14201355]].
[2019-03-24 03:37:50,149] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 7.9387371e-23 2.4240423e-16 7.7832595e-15 2.6579305e-09], sum to 1.0000
[2019-03-24 03:37:50,158] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4747
[2019-03-24 03:37:50,166] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1365033.159258663 W.
[2019-03-24 03:37:50,168] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.86666666666667, 30.66666666666667, 1.0, 2.0, 0.93966413908396, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.295774322800474, 6.9112, 121.9244136225289, 1365033.159258663, 1168099.364291401, 230623.3358648114], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1352400.0000, 
sim time next is 1353000.0000, 
raw observation next is [30.88333333333333, 30.33333333333333, 1.0, 2.0, 0.3411235653711844, 1.0, 1.0, 0.3411235653711844, 1.0, 1.0, 0.5568563144655297, 6.911200000000001, 6.9112, 121.94756008, 1248041.888526141, 1248041.88852614, 271094.5014373378], 
processed observation next is [1.0, 0.6521739130434783, 0.6993827160493825, 0.3033333333333333, 1.0, 1.0, 0.21562329210855283, 1.0, 0.5, 0.21562329210855283, 1.0, 0.5, 0.44607039308191215, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4457292459021932, 0.44572924590219287, 0.521335579687188], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3106275], dtype=float32), 0.79497]. 
=============================================
[2019-03-24 03:37:50,181] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[59.910892]
 [59.329502]
 [59.391525]
 [59.218254]
 [59.27699 ]], R is [[59.39899826]
 [58.80500793]
 [58.75550461]
 [58.16794968]
 [57.58626938]].
[2019-03-24 03:38:00,630] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.7410262e-21 1.1481770e-16 1.6551064e-13 5.1095593e-11], sum to 1.0000
[2019-03-24 03:38:00,639] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0712
[2019-03-24 03:38:00,648] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 691998.7321059558 W.
[2019-03-24 03:38:00,653] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 7.9310750e-24 5.9930202e-16 1.7455459e-16 7.6743706e-10], sum to 1.0000
[2019-03-24 03:38:00,656] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9318024115258265, 6.9112, 6.9112, 121.9260426156618, 691998.7321059558, 691998.7321059558, 166214.0892410668], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1569600.0000, 
sim time next is 1570200.0000, 
raw observation next is [20.28333333333333, 83.66666666666667, 1.0, 1.0, 0.6438668023346508, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 807801.0694925624, 807801.0694925624, 168465.5641288413], 
processed observation next is [1.0, 0.17391304347826086, 0.3067901234567901, 0.8366666666666667, 1.0, 0.5, 0.5760319075412509, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28850038196162947, 0.28850038196162947, 0.3239722387093102], 
reward next is 0.6760, 
noisyNet noise sample is [array([0.9009489], dtype=float32), -1.8075583]. 
=============================================
[2019-03-24 03:38:00,667] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9595
[2019-03-24 03:38:00,671] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.35, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7379154805983245, 6.911200000000001, 6.9112, 121.9260426156618, 546626.1992381256, 546626.1992381251, 143473.5545604586], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1575000.0000, 
sim time next is 1575600.0000, 
raw observation next is [20.56666666666667, 79.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7263324670984866, 6.911200000000001, 6.9112, 121.9260426156618, 537926.6563096775, 537926.656309677, 142187.2226967893], 
processed observation next is [1.0, 0.21739130434782608, 0.3172839506172841, 0.7966666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6579155838731082, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19211666296774196, 0.1921166629677418, 0.27343696672459483], 
reward next is 0.7266, 
noisyNet noise sample is [array([-0.51081675], dtype=float32), 1.0922478]. 
=============================================
[2019-03-24 03:38:10,178] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 5.6862938e-25 1.1099116e-19 3.8308336e-15 2.2472668e-16], sum to 1.0000
[2019-03-24 03:38:10,187] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5766
[2019-03-24 03:38:10,190] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.96666666666667, 88.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6567098850987585, 6.9112, 6.9112, 121.9260426156618, 488138.3618033805, 488138.3618033805, 136374.8767075045], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1746600.0000, 
sim time next is 1747200.0000, 
raw observation next is [20.13333333333333, 87.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6240726641744738, 6.9112, 6.9112, 121.9260426156618, 464082.0078806899, 464082.0078806899, 133324.7198139239], 
processed observation next is [1.0, 0.21739130434782608, 0.30123456790123443, 0.8733333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5300908302180922, 0.0, 0.0, 0.8094621288201359, 0.16574357424310354, 0.16574357424310354, 0.2563936919498537], 
reward next is 0.7436, 
noisyNet noise sample is [array([-1.4615986], dtype=float32), -0.4672498]. 
=============================================
[2019-03-24 03:38:15,907] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 5.5929607e-21 2.1952247e-17 2.0847366e-14 4.2695426e-13], sum to 1.0000
[2019-03-24 03:38:15,916] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6079
[2019-03-24 03:38:15,925] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 880902.4263924062 W.
[2019-03-24 03:38:15,933] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.83333333333334, 77.16666666666667, 1.0, 2.0, 0.3576359469887094, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5892773129322378, 6.9112, 6.9112, 121.9260426156618, 880902.4263924062, 880902.4263924062, 208360.7015727427], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1851000.0000, 
sim time next is 1851600.0000, 
raw observation next is [21.86666666666667, 77.33333333333334, 1.0, 2.0, 0.3599533609542628, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5926338472175062, 6.911199999999999, 6.9112, 121.9260426156618, 885942.467518155, 885942.4675181555, 209086.8625381695], 
processed observation next is [1.0, 0.43478260869565216, 0.36543209876543226, 0.7733333333333334, 1.0, 1.0, 0.2380397154217414, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.49079230902188276, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3164080241136268, 0.31640802411362695, 0.40209012026571056], 
reward next is 0.5979, 
noisyNet noise sample is [array([-0.2839519], dtype=float32), 1.4034495]. 
=============================================
[2019-03-24 03:38:16,606] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 9.2334197e-27 8.2880880e-21 5.6273336e-20 7.1745831e-19], sum to 1.0000
[2019-03-24 03:38:16,612] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4877
[2019-03-24 03:38:16,623] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.25, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.880070624910134, 6.911199999999999, 6.9112, 121.9260426156618, 643823.4212184609, 643823.4212184612, 173365.7425870138], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2039400.0000, 
sim time next is 2040000.0000, 
raw observation next is [28.3, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8835173871089471, 6.911200000000001, 6.9112, 121.9260426156618, 645897.0565159271, 645897.0565159266, 173906.6409801134], 
processed observation next is [0.0, 0.6086956521739131, 0.6037037037037037, 0.63, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8543967338861838, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23067752018425966, 0.2306775201842595, 0.33443584803867965], 
reward next is 0.6656, 
noisyNet noise sample is [array([0.72228956], dtype=float32), -1.3328246]. 
=============================================
[2019-03-24 03:38:16,641] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[69.96341]
 [69.96262]
 [69.96862]
 [70.0037 ]
 [70.01034]], R is [[69.93586731]
 [69.90311432]
 [69.87181854]
 [69.84214783]
 [69.81430054]].
[2019-03-24 03:38:23,476] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 03:38:23,482] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:38:23,484] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:23,484] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:38:23,485] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:38:23,485] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:23,486] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:23,486] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:38:23,486] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:38:23,487] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:23,488] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:38:23,513] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run54
[2019-03-24 03:38:23,539] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run54
[2019-03-24 03:38:23,539] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run54
[2019-03-24 03:38:23,562] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run54
[2019-03-24 03:38:23,585] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run54
[2019-03-24 03:38:26,667] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02968248], dtype=float32), 0.33287466]
[2019-03-24 03:38:26,668] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [12.0, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2675733450284806, 6.911200000000001, 6.9112, 121.9260426156618, 191029.2932108395, 191029.2932108391, 67810.72871368959]
[2019-03-24 03:38:26,671] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:38:26,675] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 8.0425221e-24 8.2879113e-18 2.5004948e-15 1.1268298e-14], sampled 0.6192147301285496
[2019-03-24 03:38:35,954] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02968248], dtype=float32), 0.33287466]
[2019-03-24 03:38:35,956] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.73117084, 62.99558288, 1.0, 1.0, 0.6741155082409358, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9259367364071, 831369.9532203549, 831369.9532203544, 173817.5769143529]
[2019-03-24 03:38:35,958] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:38:35,959] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.5967849e-20 2.7784904e-15 4.1314554e-13 1.6066744e-12], sampled 0.3543602530873875
[2019-03-24 03:38:35,960] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 831369.9532203549 W.
[2019-03-24 03:38:53,693] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02968248], dtype=float32), 0.33287466]
[2019-03-24 03:38:53,694] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.53333333333333, 58.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6814765193139724, 6.911199999999999, 6.9112, 121.9260426156618, 506952.4114968951, 506952.4114968955, 139198.8715251165]
[2019-03-24 03:38:53,695] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:38:53,698] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.00000000e+00 7.44907784e-24 8.25843475e-18 2.57441286e-15
 1.20093255e-14], sampled 0.13528704799000457
[2019-03-24 03:39:08,754] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02968248], dtype=float32), 0.33287466]
[2019-03-24 03:39:08,755] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.56689489333333, 89.96585979, 1.0, 2.0, 0.8277500303218465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 943490.49309597, 943490.49309597, 201752.5550985915]
[2019-03-24 03:39:08,756] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:39:08,759] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 5.4501346e-23 8.4842632e-17 5.6220186e-14 4.9745212e-13], sampled 0.6864858642897174
[2019-03-24 03:39:08,759] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 943490.49309597 W.
[2019-03-24 03:39:23,707] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02968248], dtype=float32), 0.33287466]
[2019-03-24 03:39:23,709] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.025152795, 77.970471935, 1.0, 2.0, 0.6705736972599148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 764247.5971988098, 764247.5971988098, 170645.2744124072]
[2019-03-24 03:39:23,711] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:39:23,714] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 6.4311861e-25 3.6890915e-18 5.0595463e-15 6.2067322e-14], sampled 0.12030413719201627
[2019-03-24 03:39:23,715] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 764247.5971988098 W.
[2019-03-24 03:39:27,300] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02968248], dtype=float32), 0.33287466]
[2019-03-24 03:39:27,303] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.83333333333333, 81.5, 1.0, 2.0, 0.605375231823688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 697050.7161854638, 697050.7161854634, 159353.7184109399]
[2019-03-24 03:39:27,305] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:39:27,308] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.4456521e-23 3.0341719e-17 2.1538117e-14 1.9148479e-13], sampled 0.2788434004790111
[2019-03-24 03:39:27,309] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 697050.7161854638 W.
[2019-03-24 03:40:01,665] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 03:40:01,864] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 03:40:02,392] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 03:40:02,430] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 03:40:02,572] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 03:40:03,589] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1325000, evaluation results [1325000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 03:40:09,833] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 7.9230835e-26 1.2736313e-20 7.7421756e-18 6.7537730e-18], sum to 1.0000
[2019-03-24 03:40:09,841] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2666
[2019-03-24 03:40:09,845] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.6, 83.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7355429809906308, 6.911200000000001, 6.9112, 121.9260426156618, 549077.8126293137, 549077.8126293133, 150449.1517018186], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2080200.0000, 
sim time next is 2080800.0000, 
raw observation next is [22.5, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7299296041147968, 6.9112, 6.9112, 121.9260426156618, 544980.9924952004, 544980.9924952004, 149669.0646216027], 
processed observation next is [0.0, 0.08695652173913043, 0.3888888888888889, 0.84, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6624120051434959, 0.0, 0.0, 0.8094621288201359, 0.19463606874828585, 0.19463606874828585, 0.2878251242723129], 
reward next is 0.7122, 
noisyNet noise sample is [array([0.51404405], dtype=float32), 1.2142417]. 
=============================================
[2019-03-24 03:40:11,276] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.1309127e-28 8.9668947e-21 1.4395653e-16 2.1613804e-17], sum to 1.0000
[2019-03-24 03:40:11,284] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3317
[2019-03-24 03:40:11,288] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9071979858851856, 6.9112, 6.9112, 121.9260426156618, 660926.101084681, 660926.101084681, 177463.0010043189], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2127600.0000, 
sim time next is 2128200.0000, 
raw observation next is [31.08333333333334, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9035930908109652, 6.911200000000001, 6.9112, 121.9260426156618, 658730.7007236711, 658730.7007236707, 176905.6967450317], 
processed observation next is [0.0, 0.6521739130434783, 0.7067901234567904, 0.505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8794913635137064, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23526096454416826, 0.2352609645441681, 0.3402032629712148], 
reward next is 0.6598, 
noisyNet noise sample is [array([-0.42058635], dtype=float32), -0.5099195]. 
=============================================
[2019-03-24 03:40:15,629] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.6158072e-01 1.8594789e-09 8.3637906e-07 3.4263268e-02 5.0415522e-01], sum to 1.0000
[2019-03-24 03:40:15,639] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7662
[2019-03-24 03:40:15,645] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.46666666666667, 92.33333333333333, 1.0, 2.0, 0.604225751876712, 1.0, 2.0, 0.604225751876712, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1377813.89514321, 1377813.89514321, 269497.0730917211], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2200200.0000, 
sim time next is 2200800.0000, 
raw observation next is [24.63333333333334, 91.66666666666667, 1.0, 2.0, 0.394516992394532, 1.0, 2.0, 0.394516992394532, 1.0, 1.0, 0.6280839004135352, 6.911199999999999, 6.9112, 121.94756008, 1349398.383861239, 1349398.38386124, 294688.6033267018], 
processed observation next is [1.0, 0.4782608695652174, 0.4679012345679015, 0.9166666666666667, 1.0, 1.0, 0.27918689570777616, 1.0, 1.0, 0.27918689570777616, 1.0, 0.5, 0.535104875516919, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4819279942361568, 0.4819279942361571, 0.5667088525513496], 
reward next is 0.4333, 
noisyNet noise sample is [array([2.5591264], dtype=float32), -0.7493159]. 
=============================================
[2019-03-24 03:40:22,300] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.5125917e-29 7.3803292e-21 1.8994381e-18 1.4158946e-18], sum to 1.0000
[2019-03-24 03:40:22,308] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1579
[2019-03-24 03:40:22,315] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.83333333333334, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8233217344925718, 6.9112, 6.9112, 121.9260426156618, 611981.4234870921, 611981.4234870921, 163018.1935937611], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2344800.0000, 
sim time next is 2345400.0000, 
raw observation next is [21.8, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8171738310098347, 6.911200000000001, 6.9112, 121.9260426156618, 607564.5329286212, 607564.5329286207, 162173.8964161371], 
processed observation next is [1.0, 0.13043478260869565, 0.362962962962963, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7714672887622933, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21698733318879326, 0.2169873331887931, 0.3118728777233406], 
reward next is 0.6881, 
noisyNet noise sample is [array([0.15993644], dtype=float32), -0.06585275]. 
=============================================
[2019-03-24 03:40:22,997] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 8.1684796e-26 1.4804007e-19 1.5691588e-13 1.7888959e-18], sum to 1.0000
[2019-03-24 03:40:23,003] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6269
[2019-03-24 03:40:23,009] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.7, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7907034321732587, 6.9112, 6.9112, 121.9260426156618, 588301.5979496023, 588301.5979496023, 158634.704856337], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2347200.0000, 
sim time next is 2347800.0000, 
raw observation next is [21.68333333333333, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9085772548546754, 6.9112, 6.9112, 121.9260426156618, 676144.3946712234, 676144.3946712234, 173299.8744250476], 
processed observation next is [1.0, 0.17391304347826086, 0.35864197530864184, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8857215685683442, 0.0, 0.0, 0.8094621288201359, 0.24148014095400835, 0.24148014095400835, 0.3332689892789377], 
reward next is 0.6667, 
noisyNet noise sample is [array([-0.61141753], dtype=float32), -1.2003748]. 
=============================================
[2019-03-24 03:40:24,883] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.1213285e-21 1.5622349e-15 6.6398409e-10 1.5167543e-11], sum to 1.0000
[2019-03-24 03:40:24,890] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4803
[2019-03-24 03:40:24,900] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1076554.373097676 W.
[2019-03-24 03:40:24,905] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.1, 37.66666666666667, 1.0, 2.0, 0.298961958142367, 1.0, 2.0, 0.298961958142367, 1.0, 1.0, 0.4827612975868686, 6.911199999999999, 6.9112, 121.94756008, 1076554.373097676, 1076554.373097676, 255085.4824980723], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2377200.0000, 
sim time next is 2377800.0000, 
raw observation next is [30.2, 37.5, 1.0, 2.0, 0.278350161336126, 1.0, 2.0, 0.278350161336126, 1.0, 2.0, 0.4497602492314079, 6.9112, 6.9112, 121.94756008, 1003384.743671063, 1003384.743671063, 247280.0004679994], 
processed observation next is [1.0, 0.5217391304347826, 0.674074074074074, 0.375, 1.0, 1.0, 0.1408930492096738, 1.0, 1.0, 0.1408930492096738, 1.0, 1.0, 0.3122003115392598, 0.0, 0.0, 0.8096049824067558, 0.35835169416823676, 0.35835169416823676, 0.4755384624384604], 
reward next is 0.5245, 
noisyNet noise sample is [array([1.7727991], dtype=float32), -2.7585661]. 
=============================================
[2019-03-24 03:40:25,796] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.6397802e-23 9.0563990e-16 6.5160546e-12 2.7786138e-14], sum to 1.0000
[2019-03-24 03:40:25,807] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8544
[2019-03-24 03:40:25,816] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1583167.542509952 W.
[2019-03-24 03:40:25,819] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.96666666666667, 37.0, 1.0, 2.0, 0.445944218439989, 1.0, 1.0, 0.445944218439989, 1.0, 2.0, 0.7152110890732164, 6.9112, 6.9112, 121.94756008, 1583167.542509952, 1583167.542509952, 317741.1896112749], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2387400.0000, 
sim time next is 2388000.0000, 
raw observation next is [30.93333333333333, 37.0, 1.0, 2.0, 0.401079653764094, 1.0, 2.0, 0.401079653764094, 1.0, 2.0, 0.64258243694902, 6.911199999999999, 6.9112, 121.94756008, 1419640.872434261, 1419640.872434262, 297496.0232576465], 
processed observation next is [1.0, 0.6521739130434783, 0.7012345679012344, 0.37, 1.0, 1.0, 0.2869995878143976, 1.0, 1.0, 0.2869995878143976, 1.0, 1.0, 0.5532280461862749, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5070145972979504, 0.5070145972979507, 0.5721077370339356], 
reward next is 0.4279, 
noisyNet noise sample is [array([-2.0390837], dtype=float32), -0.05441918]. 
=============================================
[2019-03-24 03:40:25,836] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[60.73482 ]
 [60.588234]
 [60.54193 ]
 [59.92111 ]
 [59.75299 ]], R is [[61.29907608]
 [61.07504272]
 [60.9141922 ]
 [60.76764297]
 [60.61875916]].
[2019-03-24 03:40:29,879] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 6.6169394e-23 3.8072415e-18 2.2255936e-12 4.0194734e-16], sum to 1.0000
[2019-03-24 03:40:29,887] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7212
[2019-03-24 03:40:29,894] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5195252555284818, 6.9112, 6.9112, 121.9260426156618, 378915.3677143677, 378915.3677143677, 119549.21856209], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2440800.0000, 
sim time next is 2441400.0000, 
raw observation next is [22.06666666666667, 62.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6158554590125995, 6.911200000000001, 6.9112, 121.9260426156618, 450508.8200909126, 450508.8200909122, 128361.7997736271], 
processed observation next is [1.0, 0.2608695652173913, 0.3728395061728396, 0.6283333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5198193237657494, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16089600717532593, 0.1608960071753258, 0.2468496149492829], 
reward next is 0.7532, 
noisyNet noise sample is [array([-0.50263715], dtype=float32), -1.4788405]. 
=============================================
[2019-03-24 03:40:32,826] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 6.7778257e-26 1.7607578e-19 6.4203567e-16 1.9598458e-17], sum to 1.0000
[2019-03-24 03:40:32,835] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5513
[2019-03-24 03:40:32,839] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.76666666666667, 38.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6230287753962501, 6.911200000000001, 6.9112, 121.9260426156618, 463494.3185337581, 463494.3185337576, 133378.9424852834], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2496000.0000, 
sim time next is 2496600.0000, 
raw observation next is [28.6, 39.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6218016586164004, 6.9112, 6.9112, 121.9260426156618, 462600.5349625243, 462600.5349625243, 133275.6638062445], 
processed observation next is [1.0, 0.9130434782608695, 0.6148148148148148, 0.39, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5272520732705004, 0.0, 0.0, 0.8094621288201359, 0.16521447677233012, 0.16521447677233012, 0.2562993534735471], 
reward next is 0.7437, 
noisyNet noise sample is [array([-0.72764415], dtype=float32), 0.2180382]. 
=============================================
[2019-03-24 03:40:33,195] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 5.1418165e-28 1.1502576e-19 6.0598694e-13 1.2300755e-18], sum to 1.0000
[2019-03-24 03:40:33,202] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9715
[2019-03-24 03:40:33,208] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.6, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7041371061301384, 6.9112, 6.9112, 121.9260426156618, 524731.2009297628, 524731.2009297628, 142390.7445065273], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2527200.0000, 
sim time next is 2527800.0000, 
raw observation next is [25.86666666666667, 53.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7255703441431971, 6.911199999999999, 6.9112, 121.9260426156618, 540936.756262765, 540936.7562627655, 144924.0516935964], 
processed observation next is [1.0, 0.2608695652173913, 0.5135802469135804, 0.5316666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6569629301789964, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19319169866527322, 0.1931916986652734, 0.27870009941076235], 
reward next is 0.7213, 
noisyNet noise sample is [array([-0.08810297], dtype=float32), 0.42937067]. 
=============================================
[2019-03-24 03:40:36,179] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.0071026e-26 6.4895104e-20 1.0421551e-14 1.0626919e-17], sum to 1.0000
[2019-03-24 03:40:36,187] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3585
[2019-03-24 03:40:36,192] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.1, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7939974036170276, 6.9112, 6.9112, 121.9260426156618, 590327.3042822233, 590327.3042822233, 159285.3554653808], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2588400.0000, 
sim time next is 2589000.0000, 
raw observation next is [24.86666666666667, 73.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7923482498974079, 6.9112, 6.9112, 121.9260426156618, 589214.7691414302, 589214.7691414302, 159018.3528559218], 
processed observation next is [1.0, 1.0, 0.47654320987654336, 0.7333333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.74043531237176, 0.0, 0.0, 0.8094621288201359, 0.21043384612193933, 0.21043384612193933, 0.3058045247229266], 
reward next is 0.6942, 
noisyNet noise sample is [array([1.1626548], dtype=float32), -1.7137443]. 
=============================================
[2019-03-24 03:40:36,213] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[64.53037 ]
 [64.47953 ]
 [64.54053 ]
 [64.58161 ]
 [64.629814]], R is [[64.56053925]
 [64.60861969]
 [64.65556335]
 [64.70140839]
 [64.74610901]].
[2019-03-24 03:40:41,845] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.00000000e+00 1.27350243e-24 1.23673656e-20 6.45100509e-13
 1.71683255e-16], sum to 1.0000
[2019-03-24 03:40:41,857] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2840
[2019-03-24 03:40:41,861] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.2, 89.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8424738908085375, 6.911200000000001, 6.9112, 121.9260426156618, 623030.849051087, 623030.8490510866, 166743.7543243661], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2684400.0000, 
sim time next is 2685000.0000, 
raw observation next is [23.25, 88.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.834100549205375, 6.911200000000001, 6.9112, 121.9260426156618, 617486.7309674809, 617486.7309674805, 165460.8780195042], 
processed observation next is [0.0, 0.043478260869565216, 0.4166666666666667, 0.8816666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7926256865067188, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2205309753455289, 0.22053097534552873, 0.3181939961913542], 
reward next is 0.6818, 
noisyNet noise sample is [array([-0.7591941], dtype=float32), -0.3656887]. 
=============================================
[2019-03-24 03:40:41,872] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[64.08659 ]
 [64.01257 ]
 [63.92547 ]
 [63.94229 ]
 [63.831375]], R is [[64.15396118]
 [64.1917572 ]
 [64.2266922 ]
 [64.25875854]
 [64.28787231]].
[2019-03-24 03:40:44,535] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.6431305e-26 1.2130247e-19 1.5875380e-16 1.4977842e-17], sum to 1.0000
[2019-03-24 03:40:44,550] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0687
[2019-03-24 03:40:44,554] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 697495.0524135059 W.
[2019-03-24 03:40:44,559] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.85, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9674418183864834, 6.911200000000001, 6.9112, 121.9259916328817, 697495.0524135059, 697495.0524135054, 186753.1374258359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2727000.0000, 
sim time next is 2727600.0000, 
raw observation next is [30.8, 56.0, 1.0, 1.0, 0.6151841153585227, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 703002.4446780473, 703002.4446780473, 160804.2070868549], 
processed observation next is [0.0, 0.5652173913043478, 0.6962962962962963, 0.56, 1.0, 0.5, 0.5418858516172889, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2510723016707312, 0.2510723016707312, 0.3092388597824133], 
reward next is 0.6908, 
noisyNet noise sample is [array([0.23603721], dtype=float32), -0.11960002]. 
=============================================
[2019-03-24 03:40:44,847] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.8910575e-23 3.7670508e-18 1.5372103e-16 5.5976707e-16], sum to 1.0000
[2019-03-24 03:40:44,855] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3148
[2019-03-24 03:40:44,860] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 755375.0179594709 W.
[2019-03-24 03:40:44,864] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.3, 67.0, 1.0, 2.0, 0.3313962324726651, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5275935949182884, 6.911199999999999, 6.9112, 121.9260426156618, 755375.0179594709, 755375.0179594713, 203874.9474673081], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2748600.0000, 
sim time next is 2749200.0000, 
raw observation next is [29.06666666666667, 68.66666666666667, 1.0, 2.0, 0.2232150952250321, 1.0, 1.0, 0.2232150952250321, 1.0, 2.0, 0.3553657012063848, 6.9112, 6.9112, 121.94756008, 763188.8999826472, 763188.8999826472, 228328.2188069025], 
processed observation next is [0.0, 0.8260869565217391, 0.6320987654320989, 0.6866666666666668, 1.0, 1.0, 0.07525606574408585, 1.0, 0.5, 0.07525606574408585, 1.0, 1.0, 0.19420712650798094, 0.0, 0.0, 0.8096049824067558, 0.27256746427951684, 0.27256746427951684, 0.4390927284748125], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2217705], dtype=float32), 0.10891423]. 
=============================================
[2019-03-24 03:40:48,042] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2292328e-10 6.9493223e-22 1.5678111e-14 3.4851404e-05 9.9996519e-01], sum to 1.0000
[2019-03-24 03:40:48,049] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5349
[2019-03-24 03:40:48,055] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.2, 60.33333333333334, 1.0, 2.0, 0.606704773243892, 1.0, 2.0, 0.606704773243892, 1.0, 2.0, 0.9658937579992933, 6.911199999999998, 6.9112, 121.94756008, 2076049.621926128, 2076049.621926129, 399040.8023235681], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2812800.0000, 
sim time next is 2813400.0000, 
raw observation next is [32.3, 59.0, 1.0, 2.0, 0.6392393806092267, 1.0, 2.0, 0.632984352281048, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2166083.318844995, 2166083.318844995, 413311.7379940742], 
processed observation next is [1.0, 0.5652173913043478, 0.7518518518518518, 0.59, 1.0, 1.0, 0.5705230721538412, 1.0, 1.0, 0.5630766098583905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7736011853017839, 0.7736011853017839, 0.7948302653732195], 
reward next is 0.2052, 
noisyNet noise sample is [array([0.73766154], dtype=float32), -0.59263283]. 
=============================================
[2019-03-24 03:40:51,162] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.9990718e-05 3.1172655e-17 6.4828226e-11 1.5355024e-06 9.9994850e-01], sum to 1.0000
[2019-03-24 03:40:51,166] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8570
[2019-03-24 03:40:51,171] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.08333333333333, 69.5, 1.0, 2.0, 0.2272976279242207, 1.0, 2.0, 0.2272976279242207, 1.0, 2.0, 0.3618652262223008, 6.911200000000001, 6.9112, 121.94756008, 777154.4557892631, 777154.4557892627, 229719.3888755768], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2839800.0000, 
sim time next is 2840400.0000, 
raw observation next is [29.0, 70.0, 1.0, 2.0, 0.2271386887270497, 1.0, 2.0, 0.2271386887270497, 1.0, 2.0, 0.3616121898441163, 6.911200000000001, 6.9112, 121.94756008, 776610.7507360775, 776610.7507360772, 229665.0541456826], 
processed observation next is [1.0, 0.9130434782608695, 0.6296296296296297, 0.7, 1.0, 1.0, 0.07992701038934488, 1.0, 1.0, 0.07992701038934488, 1.0, 1.0, 0.20201523730514537, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.277360982405742, 0.27736098240574186, 0.4416635656647742], 
reward next is 0.5583, 
noisyNet noise sample is [array([2.154566], dtype=float32), -0.5067735]. 
=============================================
[2019-03-24 03:40:54,609] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4604438e-09 5.5950972e-18 1.9681687e-12 1.0858829e-06 9.9999893e-01], sum to 1.0000
[2019-03-24 03:40:54,617] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4753
[2019-03-24 03:40:54,620] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.4, 83.0, 1.0, 2.0, 0.5580653047395766, 1.0, 2.0, 0.5580653047395766, 1.0, 2.0, 0.8884581400635243, 6.9112, 6.9112, 121.94756008, 1909435.004364894, 1909435.004364894, 373001.2828411407], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2900400.0000, 
sim time next is 2901000.0000, 
raw observation next is [26.75, 81.5, 1.0, 2.0, 0.5654320780094776, 1.0, 2.0, 0.5654320780094776, 1.0, 2.0, 0.9001862830282623, 6.911200000000001, 6.9112, 121.94756008, 1934667.907068612, 1934667.907068612, 376863.1523825629], 
processed observation next is [1.0, 0.5652173913043478, 0.5462962962962963, 0.815, 1.0, 1.0, 0.48265723572556857, 1.0, 1.0, 0.48265723572556857, 1.0, 1.0, 0.8752328537853279, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6909528239530758, 0.6909528239530758, 0.7247368315049287], 
reward next is 0.2753, 
noisyNet noise sample is [array([0.45894018], dtype=float32), 0.38959214]. 
=============================================
[2019-03-24 03:40:54,636] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[49.16429 ]
 [48.96192 ]
 [48.772377]
 [48.809063]
 [48.85556 ]], R is [[49.18876648]
 [48.97956848]
 [48.78000641]
 [48.61331558]
 [48.54685974]].
[2019-03-24 03:40:54,918] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 03:40:54,919] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:40:54,921] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:40:54,922] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:40:54,923] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:40:54,925] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:40:54,926] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:40:54,926] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:40:54,928] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:40:54,928] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:40:54,930] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:40:54,951] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run55
[2019-03-24 03:40:54,975] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run55
[2019-03-24 03:40:54,976] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run55
[2019-03-24 03:40:55,024] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run55
[2019-03-24 03:40:55,026] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run55
[2019-03-24 03:41:00,520] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03126964], dtype=float32), 0.3373509]
[2019-03-24 03:41:00,522] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.5, 29.0, 1.0, 2.0, 0.2804350221184362, 1.0, 2.0, 0.2804350221184362, 1.0, 2.0, 0.4711109523962242, 6.9112, 6.9112, 121.94756008, 1052440.369026678, 1052440.369026678, 245825.5678247764]
[2019-03-24 03:41:00,522] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:41:00,524] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.73053886e-05 8.03862143e-18 1.15662105e-10 1.61945388e-06
 9.99981046e-01], sampled 0.8211937501241124
[2019-03-24 03:41:17,677] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03126964], dtype=float32), 0.3373509]
[2019-03-24 03:41:17,677] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.34363637666667, 91.33613869999999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7186760242191076, 6.911200000000001, 6.9112, 121.9260426156618, 536892.8956555277, 536892.8956555272, 147784.3098145321]
[2019-03-24 03:41:17,678] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:41:17,680] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9998605e-01 1.4639994e-18 4.5523502e-11 9.1161310e-09 1.3909186e-05], sampled 0.147360930986272
[2019-03-24 03:41:33,871] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03126964], dtype=float32), 0.3373509]
[2019-03-24 03:41:33,873] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.5, 72.0, 1.0, 2.0, 0.4553240311914965, 1.0, 2.0, 0.4553240311914965, 1.0, 2.0, 0.7290257434125686, 6.9112, 6.9112, 123.1448387354088, 1608791.275628678, 1608791.275628678, 322454.1493847148]
[2019-03-24 03:41:33,874] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:41:33,877] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.2223088e-05 9.3546217e-19 3.5393705e-11 8.1343643e-07 9.9998701e-01], sampled 0.37256032842432074
[2019-03-24 03:41:41,781] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03126964], dtype=float32), 0.3373509]
[2019-03-24 03:41:41,783] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 89.0, 1.0, 2.0, 0.4165994581180715, 1.0, 2.0, 0.4165994581180715, 1.0, 2.0, 0.6632399050211105, 6.9112, 6.9112, 121.94756008, 1424999.080364631, 1424999.080364631, 304429.9459348659]
[2019-03-24 03:41:41,784] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:41:41,786] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.2722641e-04 8.1089359e-18 2.0187822e-10 2.3133559e-06 9.9987042e-01], sampled 0.10599101759653862
[2019-03-24 03:41:42,801] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03126964], dtype=float32), 0.3373509]
[2019-03-24 03:41:42,801] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.019848445, 69.00744234333334, 1.0, 2.0, 0.2949932906653532, 1.0, 2.0, 0.2949932906653532, 1.0, 2.0, 0.4696389260000015, 6.911200000000001, 6.9112, 121.94756008, 1008765.337892648, 1008765.337892648, 254144.6193358969]
[2019-03-24 03:41:42,803] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:41:42,805] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.3674186e-06 1.3179308e-18 3.1453416e-11 7.4235874e-07 9.9999487e-01], sampled 0.170172020101516
[2019-03-24 03:41:46,003] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03126964], dtype=float32), 0.3373509]
[2019-03-24 03:41:46,004] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.4, 67.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8728582369258387, 6.9112, 6.9112, 121.9260426156618, 639724.8158941063, 639724.8158941063, 172177.370979269]
[2019-03-24 03:41:46,004] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:41:46,006] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9999845e-01 1.8293456e-19 7.6308109e-12 1.2063862e-09 1.5849749e-06], sampled 0.06727204915029861
[2019-03-24 03:42:07,927] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03126964], dtype=float32), 0.3373509]
[2019-03-24 03:42:07,928] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.0, 55.0, 1.0, 2.0, 0.5061582168818818, 1.0, 2.0, 0.5061582168818818, 1.0, 2.0, 0.8058203656982422, 6.911200000000001, 6.9112, 121.94756008, 1731661.420858171, 1731661.42085817, 346621.8532910358]
[2019-03-24 03:42:07,929] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:42:07,934] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.0498712e-08 9.0099945e-21 7.7245529e-13 6.9642091e-08 9.9999988e-01], sampled 0.24061236903384386
[2019-03-24 03:42:16,273] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03126964], dtype=float32), 0.3373509]
[2019-03-24 03:42:16,274] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.75, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6643499405236079, 6.911200000000001, 6.9112, 121.9260426156618, 496424.1671620638, 496424.1671620634, 140576.818836152]
[2019-03-24 03:42:16,276] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:42:16,279] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9999893e-01 1.3917359e-19 5.8091943e-12 8.5762264e-10 1.0565971e-06], sampled 0.1660741066834197
[2019-03-24 03:42:18,157] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03126964], dtype=float32), 0.3373509]
[2019-03-24 03:42:18,167] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [18.91666666666667, 81.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7239036746325858, 6.9112, 6.9112, 121.9260426156618, 526221.8555945905, 526221.8555945905, 137230.1585521342]
[2019-03-24 03:42:18,168] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:42:18,171] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9999726e-01 3.5437630e-19 1.2943866e-11 2.0938620e-09 2.7314411e-06], sampled 0.9130986094095551
[2019-03-24 03:42:22,149] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03126964], dtype=float32), 0.3373509]
[2019-03-24 03:42:22,149] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.66666666666667, 70.33333333333334, 1.0, 2.0, 0.4058627081100824, 1.0, 2.0, 0.4058627081100824, 1.0, 2.0, 0.6465118689540217, 6.9112, 6.9112, 121.94756008, 1399213.717331928, 1399213.717331928, 299721.6469332667]
[2019-03-24 03:42:22,150] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:42:22,154] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.3467575e-07 5.4077910e-19 9.7669667e-12 3.1732617e-07 9.9999940e-01], sampled 0.770051247315764
[2019-03-24 03:42:33,322] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7834.6020 2558061884.4279 124.0000
[2019-03-24 03:42:33,585] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7991.0855 2552601571.6530 72.0000
[2019-03-24 03:42:33,691] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 7943.7908 2590857160.2604 85.0000
[2019-03-24 03:42:33,934] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7800.0771 2518832020.4225 111.0000
[2019-03-24 03:42:34,024] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7496.0740 2790599532.3368 82.0000
[2019-03-24 03:42:35,041] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1350000, evaluation results [1350000.0, 7496.073968715875, 2790599532.3368087, 82.0, 7991.085492519223, 2552601571.653013, 72.0, 7800.077088138046, 2518832020.4224663, 111.0, 7943.790751641044, 2590857160.260414, 85.0, 7834.602038383367, 2558061884.4279375, 124.0]
[2019-03-24 03:43:00,513] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9996340e-01 9.3357863e-13 8.1263984e-10 2.7543070e-08 3.6636116e-05], sum to 1.0000
[2019-03-24 03:43:00,521] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8694
[2019-03-24 03:43:00,529] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 898601.1461327029 W.
[2019-03-24 03:43:00,536] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 85.66666666666666, 1.0, 2.0, 0.3941952267400104, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6275716390123611, 6.9112, 6.9112, 121.9260426156618, 898601.1461327029, 898601.1461327029, 222313.8269560849], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3397200.0000, 
sim time next is 3397800.0000, 
raw observation next is [25.56666666666667, 84.33333333333333, 1.0, 2.0, 0.7899808757147005, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 904310.8304719392, 904310.8304719392, 194078.4927235338], 
processed observation next is [1.0, 0.30434782608695654, 0.5024691358024692, 0.8433333333333333, 1.0, 1.0, 0.7499772329936911, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3229681537399783, 0.3229681537399783, 0.3732278706221804], 
reward next is 0.6268, 
noisyNet noise sample is [array([1.0156502], dtype=float32), -0.41842827]. 
=============================================
[2019-03-24 03:43:00,790] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.5517356e-13 1.3604223e-10 3.2550929e-09 3.1280645e-09], sum to 1.0000
[2019-03-24 03:43:00,795] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2529
[2019-03-24 03:43:00,803] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 717778.6502371904 W.
[2019-03-24 03:43:00,806] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.3, 93.0, 1.0, 2.0, 0.3149097672014421, 1.0, 2.0, 0.3149097672014421, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 717778.6502371904, 717778.6502371908, 184076.9348449738], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3373200.0000, 
sim time next is 3373800.0000, 
raw observation next is [24.18333333333333, 92.66666666666667, 1.0, 2.0, 0.3095045525449184, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4927950947420651, 6.911199999999999, 6.9112, 121.9260426156618, 706990.7820902194, 706990.7820902199, 197791.7264075007], 
processed observation next is [1.0, 0.043478260869565216, 0.45123456790123445, 0.9266666666666667, 1.0, 1.0, 0.17798161017252187, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.36599386842758136, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25249670788936407, 0.25249670788936424, 0.38036870462980904], 
reward next is 0.6196, 
noisyNet noise sample is [array([0.10224442], dtype=float32), -1.3069824]. 
=============================================
[2019-03-24 03:43:03,451] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.00000000e+00 1.58615376e-21 1.10078867e-16 3.81282451e-17
 3.68857316e-13], sum to 1.0000
[2019-03-24 03:43:03,454] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1162
[2019-03-24 03:43:03,460] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 758365.3115629163 W.
[2019-03-24 03:43:03,464] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.2218050046394529, 1.0, 1.0, 0.2218050046394529, 1.0, 1.0, 0.3531207910706984, 6.9112, 6.9112, 121.94756008, 758365.3115629163, 758365.3115629163, 227849.879955538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3458400.0000, 
sim time next is 3459000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6654945721288602, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758456.0941385138, 758456.0941385138, 169713.2773008697], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6017792525343574, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27087717647804066, 0.27087717647804066, 0.3263716871170571], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9817668], dtype=float32), 0.43609953]. 
=============================================
[2019-03-24 03:43:03,478] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[46.84551]
 [47.28787]
 [48.39038]
 [49.22039]
 [50.5545 ]], R is [[45.45369339]
 [44.99915695]
 [45.22290039]
 [45.33276367]
 [45.44192886]].
[2019-03-24 03:43:03,741] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.00000000e+00 1.02812537e-14 3.47989380e-11 2.40608367e-11
 1.13502836e-11], sum to 1.0000
[2019-03-24 03:43:03,749] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4007
[2019-03-24 03:43:03,756] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 785378.6426938763 W.
[2019-03-24 03:43:03,759] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.2297017589536313, 1.0, 1.0, 0.2297017589536313, 1.0, 2.0, 0.3656926811182039, 6.911200000000001, 6.9112, 121.94756008, 785378.6426938763, 785378.6426938758, 230542.9844719321], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3447000.0000, 
sim time next is 3447600.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.2301799579058695, 1.0, 2.0, 0.2301799579058695, 1.0, 2.0, 0.3664539894240197, 6.9112, 6.9112, 121.94756008, 787014.5031372863, 787014.5031372863, 230707.1888917027], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.89, 1.0, 1.0, 0.08354756893555894, 1.0, 1.0, 0.08354756893555894, 1.0, 1.0, 0.2080674867800246, 0.0, 0.0, 0.8096049824067558, 0.28107660826331654, 0.28107660826331654, 0.4436676709455821], 
reward next is 0.5563, 
noisyNet noise sample is [array([-0.1163124], dtype=float32), -0.3560657]. 
=============================================
[2019-03-24 03:43:04,153] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.0330628e-15 5.6072963e-13 5.3971768e-13 5.3818829e-12], sum to 1.0000
[2019-03-24 03:43:04,161] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3553
[2019-03-24 03:43:04,167] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 719278.9785051141 W.
[2019-03-24 03:43:04,170] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.65, 67.5, 1.0, 2.0, 0.3155676949153196, 0.0, 2.0, 0.0, 1.0, 1.0, 0.502394047627515, 6.911200000000001, 6.9112, 121.9260426156618, 719278.9785051141, 719278.9785051136, 199477.811879532], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3432600.0000, 
sim time next is 3433200.0000, 
raw observation next is [29.76666666666667, 67.0, 1.0, 2.0, 0.2134901816964255, 1.0, 1.0, 0.2134901816964255, 1.0, 2.0, 0.3398833221505208, 6.911199999999999, 6.9112, 121.94756008, 729922.8739370254, 729922.8739370259, 225051.8950959777], 
processed observation next is [1.0, 0.7391304347826086, 0.6580246913580248, 0.67, 1.0, 1.0, 0.06367878773383988, 1.0, 0.5, 0.06367878773383988, 1.0, 1.0, 0.174854152688151, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2606867406917948, 0.260686740691795, 0.43279210595380324], 
reward next is 0.5672, 
noisyNet noise sample is [array([-0.04475386], dtype=float32), 0.6060524]. 
=============================================
[2019-03-24 03:43:16,660] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0620360e-03 4.6888284e-15 1.0431676e-09 8.1818565e-05 9.9785608e-01], sum to 1.0000
[2019-03-24 03:43:16,669] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2272
[2019-03-24 03:43:16,672] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.08333333333334, 98.33333333333334, 1.0, 2.0, 0.184580994912756, 1.0, 2.0, 0.184580994912756, 1.0, 2.0, 0.2947567134701737, 6.9112, 6.9112, 121.94756008, 645644.117351395, 645644.117351395, 215547.0531058475], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3658200.0000, 
sim time next is 3658800.0000, 
raw observation next is [22.06666666666667, 98.66666666666667, 1.0, 2.0, 0.2725961477532932, 1.0, 2.0, 0.2725961477532932, 1.0, 2.0, 0.4348699974765026, 6.9112, 6.9112, 121.94756008, 949150.7189497959, 949150.7189497959, 245781.3543207782], 
processed observation next is [1.0, 0.34782608695652173, 0.3728395061728396, 0.9866666666666667, 1.0, 1.0, 0.13404303303963477, 1.0, 1.0, 0.13404303303963477, 1.0, 1.0, 0.29358749684562824, 0.0, 0.0, 0.8096049824067558, 0.3389823996249271, 0.3389823996249271, 0.47265645061688116], 
reward next is 0.5273, 
noisyNet noise sample is [array([0.16506049], dtype=float32), 2.422729]. 
=============================================
[2019-03-24 03:43:18,574] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.7856320e-12 2.5859563e-09 3.0979552e-09 2.1640634e-08], sum to 1.0000
[2019-03-24 03:43:18,582] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2256
[2019-03-24 03:43:18,591] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 815911.9380370079 W.
[2019-03-24 03:43:18,596] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.8, 89.5, 1.0, 2.0, 0.2386271625318931, 1.0, 1.0, 0.2386271625318931, 1.0, 2.0, 0.3799022142948977, 6.911199999999999, 6.9112, 121.94756008, 815911.9380370079, 815911.9380370084, 233628.8721599937], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3695400.0000, 
sim time next is 3696000.0000, 
raw observation next is [26.73333333333333, 89.66666666666667, 1.0, 2.0, 0.2406006191870473, 1.0, 2.0, 0.2406006191870473, 1.0, 2.0, 0.3830440215608995, 6.911200000000001, 6.9112, 121.94756008, 822663.1845992169, 822663.1845992164, 234317.1901212557], 
processed observation next is [1.0, 0.782608695652174, 0.545679012345679, 0.8966666666666667, 1.0, 1.0, 0.09595311807981823, 1.0, 1.0, 0.09595311807981823, 1.0, 1.0, 0.22880502695112437, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.293808280214006, 0.29380828021400585, 0.4506099810024148], 
reward next is 0.5494, 
noisyNet noise sample is [array([1.5758889], dtype=float32), 0.10176628]. 
=============================================
[2019-03-24 03:43:18,611] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[26.589918]
 [26.637476]
 [26.621574]
 [26.576744]
 [26.399145]], R is [[26.80079842]
 [26.53279114]
 [26.26746368]
 [26.00478935]
 [25.74474144]].
[2019-03-24 03:43:26,490] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 03:43:26,493] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:43:26,495] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:43:26,495] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:43:26,497] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:43:26,495] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:43:26,498] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:43:26,500] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:43:26,500] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:43:26,501] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:43:26,504] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:43:26,527] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run56
[2019-03-24 03:43:26,560] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run56
[2019-03-24 03:43:26,581] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run56
[2019-03-24 03:43:26,622] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run56
[2019-03-24 03:43:26,646] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run56
[2019-03-24 03:43:28,154] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03005604], dtype=float32), 0.3386391]
[2019-03-24 03:43:28,156] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.7, 25.0, 1.0, 2.0, 0.5282286309951013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672069.0866313069, 672069.0866313069, 148413.7910782953]
[2019-03-24 03:43:28,157] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:43:28,160] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.1513097e-14 4.9005687e-12 1.6290564e-11 1.0924443e-10], sampled 0.6883725435927338
[2019-03-24 03:43:36,620] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03005604], dtype=float32), 0.3386391]
[2019-03-24 03:43:36,622] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.0, 41.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4344939035946971, 6.911200000000001, 6.9112, 121.9260426156618, 310223.3952542403, 310223.3952542398, 86949.9432119599]
[2019-03-24 03:43:36,623] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:43:36,625] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.00000000e+00 9.93586572e-21 1.28624492e-17 1.09813735e-17
 1.99346081e-16], sampled 0.23891304430299443
[2019-03-24 03:43:38,249] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03005604], dtype=float32), 0.3386391]
[2019-03-24 03:43:38,250] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.0, 52.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6079870886648912, 6.9112, 6.9112, 121.9260426156618, 450849.4549141222, 450849.4549141222, 130843.1427848006]
[2019-03-24 03:43:38,253] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:43:38,258] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 6.2395920e-20 6.5409175e-17 5.8525146e-17 9.4011933e-16], sampled 0.8313618452908513
[2019-03-24 03:43:57,713] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03005604], dtype=float32), 0.3386391]
[2019-03-24 03:43:57,714] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.91666666666667, 83.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9088301809545158, 6.911199999999999, 6.9112, 121.9260426156618, 665002.414893846, 665002.4148938465, 177147.8759738918]
[2019-03-24 03:43:57,715] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:43:57,719] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 4.4050671e-19 3.5995433e-16 3.3415402e-16 4.7038522e-15], sampled 0.12460306834651791
[2019-03-24 03:43:58,509] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03005604], dtype=float32), 0.3386391]
[2019-03-24 03:43:58,511] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.33333333333334, 47.0, 1.0, 2.0, 0.6534052107774927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 744671.302979553, 744671.302979553, 167509.2074645445]
[2019-03-24 03:43:58,514] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:43:58,516] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.9448758e-15 1.9295913e-12 1.2895036e-11 8.9072791e-11], sampled 0.9120437679320162
[2019-03-24 03:43:58,518] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 744671.302979553 W.
[2019-03-24 03:44:04,825] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03005604], dtype=float32), 0.3386391]
[2019-03-24 03:44:04,826] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.38602758333333, 73.96800911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9078855541666967, 6.911200000000001, 6.9112, 121.9260426156618, 662959.2846409971, 662959.2846409966, 177283.4035698041]
[2019-03-24 03:44:04,827] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:44:04,829] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 4.2658073e-20 4.5406061e-17 3.9677210e-17 6.5197958e-16], sampled 0.4803168396850245
[2019-03-24 03:44:13,848] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03005604], dtype=float32), 0.3386391]
[2019-03-24 03:44:13,849] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.05, 68.0, 1.0, 2.0, 0.6998212213864782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 797598.1144787406, 797598.1144787406, 176117.8329186275]
[2019-03-24 03:44:13,849] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:44:13,852] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.0868073e-15 5.9288148e-13 1.3281719e-12 1.0680924e-11], sampled 0.3247775950846358
[2019-03-24 03:44:13,853] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 797598.1144787406 W.
[2019-03-24 03:44:23,757] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03005604], dtype=float32), 0.3386391]
[2019-03-24 03:44:23,760] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.7723651, 79.40802215, 1.0, 2.0, 0.760792584003102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 867127.5196645649, 867127.5196645649, 187967.0676574709]
[2019-03-24 03:44:23,760] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:44:23,763] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.6301831e-13 6.7290319e-11 1.1632743e-09 5.9265881e-09], sampled 0.9888419036454527
[2019-03-24 03:44:23,764] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 867127.5196645649 W.
[2019-03-24 03:44:46,797] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03005604], dtype=float32), 0.3386391]
[2019-03-24 03:44:46,798] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.0, 59.5, 1.0, 2.0, 0.8117735923325607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426113077, 925269.1501826051, 925269.1501826056, 198386.7898584286]
[2019-03-24 03:44:46,800] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:44:46,805] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.8351707e-14 2.1361777e-11 4.6288182e-10 2.6101932e-09], sampled 0.7696976072760655
[2019-03-24 03:44:46,806] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 925269.1501826051 W.
[2019-03-24 03:45:04,207] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 03:45:04,482] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.2390 2292980111.6144 697.0000
[2019-03-24 03:45:04,748] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 03:45:04,846] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 03:45:04,956] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 03:45:05,972] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1375000, evaluation results [1375000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.238967854026, 2292980111.6144123, 697.0]
[2019-03-24 03:45:08,227] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.6343061e-16 3.4084524e-13 1.4780579e-13 8.5990598e-12], sum to 1.0000
[2019-03-24 03:45:08,234] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3765
[2019-03-24 03:45:08,246] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 830078.1982215302 W.
[2019-03-24 03:45:08,250] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.65, 90.5, 1.0, 2.0, 0.7283041750759928, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 830078.1982215302, 830078.1982215302, 181574.3620676308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3915000.0000, 
sim time next is 3915600.0000, 
raw observation next is [26.86666666666667, 89.33333333333334, 1.0, 2.0, 0.7465004605591261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 850828.7638538975, 850828.7638538975, 185136.8211238134], 
processed observation next is [0.0, 0.30434782608695654, 0.5506172839506175, 0.8933333333333334, 1.0, 1.0, 0.6982148339989597, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30386741566210623, 0.30386741566210623, 0.3560323483150258], 
reward next is 0.6440, 
noisyNet noise sample is [array([-1.2099026], dtype=float32), 1.779543]. 
=============================================
[2019-03-24 03:45:11,258] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 4.8455100e-15 1.0240962e-13 3.4532082e-11 1.6064117e-11], sum to 1.0000
[2019-03-24 03:45:11,265] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8226
[2019-03-24 03:45:11,270] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 809153.9153157745 W.
[2019-03-24 03:45:11,274] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.53333333333333, 85.0, 1.0, 2.0, 0.3549775285536361, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5651357862683914, 6.9112, 6.9112, 121.9260426156618, 809153.9153157745, 809153.9153157745, 210614.5722904557], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3969600.0000, 
sim time next is 3970200.0000, 
raw observation next is [26.41666666666667, 84.0, 1.0, 2.0, 0.3492474701869404, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5560133467336392, 6.911199999999999, 6.9112, 121.9260426156618, 796085.7445326438, 796085.7445326443, 208955.8156119809], 
processed observation next is [0.0, 0.9565217391304348, 0.5339506172839508, 0.84, 1.0, 1.0, 0.22529460736540527, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.445016683417049, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2843163373330871, 0.28431633733308725, 0.40183810694611716], 
reward next is 0.5982, 
noisyNet noise sample is [array([-0.52447873], dtype=float32), 0.30719864]. 
=============================================
[2019-03-24 03:45:12,020] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 7.4932796e-17 2.9695896e-13 4.4911042e-14 1.9591481e-12], sum to 1.0000
[2019-03-24 03:45:12,027] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4933
[2019-03-24 03:45:12,031] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 924379.2956836972 W.
[2019-03-24 03:45:12,038] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.4054966799559235, 1.0, 2.0, 0.4054966799559235, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 924379.2956836972, 924379.2956836977, 207706.2375813673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3944400.0000, 
sim time next is 3945000.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.8132753416285039, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 926981.8970524673, 926981.8970524669, 198705.8674555715], 
processed observation next is [0.0, 0.6521739130434783, 0.7037037037037037, 0.7, 1.0, 1.0, 0.7777087400339332, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33106496323302403, 0.33106496323302387, 0.3821266681837914], 
reward next is 0.6179, 
noisyNet noise sample is [array([0.70236546], dtype=float32), -1.3293766]. 
=============================================
[2019-03-24 03:45:12,058] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[38.52372 ]
 [38.65873 ]
 [38.77452 ]
 [39.038284]
 [38.700207]], R is [[38.5547142 ]
 [38.76972961]
 [38.98487091]
 [39.20360565]
 [39.34100342]].
[2019-03-24 03:45:33,650] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.0866229e-22 7.5102093e-20 5.6590644e-20 2.1772824e-20], sum to 1.0000
[2019-03-24 03:45:33,656] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0870
[2019-03-24 03:45:33,664] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 686987.9522092352 W.
[2019-03-24 03:45:33,667] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.46666666666667, 90.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9465268023212409, 6.9112, 6.9112, 121.9260426156618, 686987.9522092352, 686987.9522092352, 183224.2543729087], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4526400.0000, 
sim time next is 4527000.0000, 
raw observation next is [24.6, 90.0, 1.0, 1.0, 0.3028850914041118, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4822911324566703, 6.911199999999999, 6.9112, 121.9260426156618, 692678.0259451283, 692678.0259451288, 195985.0879374861], 
processed observation next is [0.0, 0.391304347826087, 0.46666666666666673, 0.9, 1.0, 0.5, 0.17010129929060927, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.35286391557083785, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24738500926611726, 0.24738500926611742, 0.37689439987978096], 
reward next is 0.6231, 
noisyNet noise sample is [array([-0.09357711], dtype=float32), -3.1828203]. 
=============================================
[2019-03-24 03:45:33,681] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[42.210537]
 [42.28956 ]
 [42.39358 ]
 [42.487717]
 [42.56365 ]], R is [[37.75307465]
 [38.02318954]
 [38.29270172]
 [38.56190491]
 [38.83145905]].
[2019-03-24 03:45:34,947] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.0078095e-13 2.0152117e-10 2.7068790e-11 9.4541242e-10], sum to 1.0000
[2019-03-24 03:45:34,957] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6639
[2019-03-24 03:45:34,967] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2194184.289391207 W.
[2019-03-24 03:45:34,973] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.63333333333333, 53.0, 1.0, 2.0, 0.6556428574963656, 1.0, 2.0, 0.6411860907246175, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2194184.289391207, 2194184.289391207, 417533.2413399899], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4372800.0000, 
sim time next is 4373400.0000, 
raw observation next is [32.81666666666666, 53.0, 1.0, 2.0, 0.6682291409917076, 1.0, 2.0, 0.6474792324722884, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2215746.584958458, 2215746.584958458, 420811.8152406397], 
processed observation next is [1.0, 0.6086956521739131, 0.7709876543209875, 0.53, 1.0, 1.0, 0.6050346916567948, 1.0, 1.0, 0.5803324196098671, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.7913380660565921, 0.7913380660565921, 0.8092534908473841], 
reward next is 0.1907, 
noisyNet noise sample is [array([-1.7147354], dtype=float32), 0.3645199]. 
=============================================
[2019-03-24 03:45:40,118] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 7.4350607e-22 1.9657544e-16 1.2989263e-18 6.7592660e-17], sum to 1.0000
[2019-03-24 03:45:40,124] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8376
[2019-03-24 03:45:40,131] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 697666.157942256 W.
[2019-03-24 03:45:40,137] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.96666666666667, 92.66666666666667, 1.0, 2.0, 0.3052991054906455, 1.0, 2.0, 0.3052991054906455, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 697666.157942256, 697666.1579422564, 181827.205652258], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4497600.0000, 
sim time next is 4498200.0000, 
raw observation next is [23.95, 92.0, 1.0, 2.0, 0.2020094823714063, 1.0, 2.0, 0.2020094823714063, 1.0, 1.0, 0.3216056749248165, 6.9112, 6.9112, 121.94756008, 690652.6865505431, 690652.6865505431, 221252.1603899478], 
processed observation next is [0.0, 0.043478260869565216, 0.4425925925925926, 0.92, 1.0, 1.0, 0.05001128853738847, 1.0, 1.0, 0.05001128853738847, 1.0, 0.5, 0.1520070936560206, 0.0, 0.0, 0.8096049824067558, 0.2466616737680511, 0.2466616737680511, 0.4254849238268227], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.42977232], dtype=float32), -0.555918]. 
=============================================
[2019-03-24 03:45:42,217] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.4284459e-25 6.4609565e-20 1.0015235e-22 1.6461468e-20], sum to 1.0000
[2019-03-24 03:45:42,222] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2938
[2019-03-24 03:45:42,225] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.13333333333333, 88.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9123026215527449, 6.9112, 6.9112, 121.9260426156618, 667138.5671758221, 667138.5671758221, 177693.6089513804], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4533600.0000, 
sim time next is 4534200.0000, 
raw observation next is [23.85, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9034267833135493, 6.911200000000001, 6.9112, 121.9260426156618, 661928.611616873, 661928.6116168725, 176243.608545551], 
processed observation next is [0.0, 0.4782608695652174, 0.43888888888888894, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8792834791419365, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23640307557745463, 0.23640307557745446, 0.3389300164337519], 
reward next is 0.6611, 
noisyNet noise sample is [array([0.11213553], dtype=float32), -1.6063993]. 
=============================================
[2019-03-24 03:45:49,811] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.0900947e-15 7.9685156e-12 1.1880075e-11 1.9862509e-11], sum to 1.0000
[2019-03-24 03:45:49,821] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9726
[2019-03-24 03:45:49,826] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 754632.9334911053 W.
[2019-03-24 03:45:49,828] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.83333333333334, 94.83333333333333, 1.0, 2.0, 0.2207139039710724, 1.0, 2.0, 0.2207139039710724, 1.0, 1.0, 0.3513837232719687, 6.9112, 6.9112, 121.94756008, 754632.9334911053, 754632.9334911053, 227480.5138618108], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4672200.0000, 
sim time next is 4672800.0000, 
raw observation next is [24.8, 95.0, 1.0, 2.0, 0.3304038308996794, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5260136592938323, 6.911199999999999, 6.9112, 121.9260426156618, 753111.8551907017, 753111.8551907021, 203595.7215645772], 
processed observation next is [1.0, 0.08695652173913043, 0.4740740740740741, 0.95, 1.0, 1.0, 0.20286170345199928, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.40751707411729027, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26896851971096486, 0.268968519710965, 0.3915302337780331], 
reward next is 0.6085, 
noisyNet noise sample is [array([1.2382885], dtype=float32), 0.4661096]. 
=============================================
[2019-03-24 03:45:52,783] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.2418135e-13 7.5416950e-11 2.2630155e-11 1.2104094e-10], sum to 1.0000
[2019-03-24 03:45:52,787] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0496
[2019-03-24 03:45:52,793] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1212285.43763926 W.
[2019-03-24 03:45:52,798] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3544616429035545, 1.0, 1.0, 0.3544616429035545, 1.0, 1.0, 0.5643144795122388, 6.911199999999999, 6.9112, 121.94756008, 1212285.43763926, 1212285.43763926, 277708.914477054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4698600.0000, 
sim time next is 4699200.0000, 
raw observation next is [23.33333333333334, 98.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.471991395129503, 6.9112, 121.9238008227581, 1458529.071213331, 1171359.034089209, 246062.2605733258], 
processed observation next is [1.0, 0.391304347826087, 0.4197530864197533, 0.98, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.056079139512950335, 0.0, 0.8094472456465557, 0.5209032397190468, 0.4183425121747175, 0.47319665494870344], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.60932666], dtype=float32), 0.37969983]. 
=============================================
[2019-03-24 03:45:57,451] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 03:45:57,452] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:45:57,452] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:45:57,452] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:45:57,453] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:45:57,453] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:45:57,454] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:45:57,455] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:45:57,453] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:45:57,458] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:45:57,459] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:45:57,476] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run57
[2019-03-24 03:45:57,503] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run57
[2019-03-24 03:45:57,503] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run57
[2019-03-24 03:45:57,545] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run57
[2019-03-24 03:45:57,547] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run57
[2019-03-24 03:46:00,563] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02854899], dtype=float32), 0.33948064]
[2019-03-24 03:46:00,567] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.53117506333334, 4.908303112499999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6656105029176577, 6.9112, 6.9112, 121.9260426156618, 475288.989153152, 475288.989153152, 112692.4039419982]
[2019-03-24 03:46:00,568] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:46:00,571] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 6.0942739e-16 1.7280082e-13 1.2477396e-13 3.2915971e-13], sampled 0.6152989621078234
[2019-03-24 03:46:07,488] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02854899], dtype=float32), 0.33948064]
[2019-03-24 03:46:07,492] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.86433595, 58.09541994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5280436533615114, 6.911200000000001, 6.9112, 121.9260426156618, 382689.8799081481, 382689.8799081477, 119270.1599224035]
[2019-03-24 03:46:07,493] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:46:07,497] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.00000000e+00 5.49032066e-17 1.83744502e-14 1.16684675e-14
 3.20461905e-14], sampled 0.34382925386929075
[2019-03-24 03:46:17,682] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02854899], dtype=float32), 0.33948064]
[2019-03-24 03:46:17,684] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.66666666666666, 33.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.749354711064503, 6.9112, 6.9112, 121.9260426156618, 559972.3340150488, 559972.3340150488, 149940.069388506]
[2019-03-24 03:46:17,686] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:46:17,688] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 7.4867438e-15 1.3411496e-12 9.3899888e-13 2.2714122e-12], sampled 0.8681705766483752
[2019-03-24 03:46:32,198] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02854899], dtype=float32), 0.33948064]
[2019-03-24 03:46:32,199] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.46666666666667, 81.66666666666667, 1.0, 2.0, 0.6083787106221915, 1.0, 1.0, 0.6083787106221915, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9248318338891, 1387292.461739708, 1387292.461739707, 270934.6390373444]
[2019-03-24 03:46:32,200] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:46:32,202] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.0733671e-12 5.0123400e-10 2.4739646e-09 5.0475228e-09], sampled 0.6433145509926106
[2019-03-24 03:46:32,203] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1387292.461739708 W.
[2019-03-24 03:46:32,373] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02854899], dtype=float32), 0.33948064]
[2019-03-24 03:46:32,376] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.95, 69.33333333333333, 1.0, 2.0, 0.7203951195961978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 821059.094418736, 821059.094418736, 180043.6456367432]
[2019-03-24 03:46:32,377] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:46:32,380] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.1324350e-12 2.0069954e-10 5.4268312e-10 1.1953915e-09], sampled 0.18694176208093194
[2019-03-24 03:46:32,381] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 821059.094418736 W.
[2019-03-24 03:46:51,899] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02854899], dtype=float32), 0.33948064]
[2019-03-24 03:46:51,899] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.17420787, 68.73031067, 1.0, 2.0, 0.7000497544277988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 799711.8070569516, 799711.8070569516, 176243.7131266964]
[2019-03-24 03:46:51,900] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:46:51,903] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.4187320e-12 2.5097613e-10 8.6178692e-10 1.8501735e-09], sampled 0.578024857135993
[2019-03-24 03:46:51,904] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 799711.8070569516 W.
[2019-03-24 03:46:54,244] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02854899], dtype=float32), 0.33948064]
[2019-03-24 03:46:54,246] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.268523105, 82.52123054500001, 1.0, 2.0, 0.651564166527224, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9257268549634, 1457519.891912316, 1457519.891912316, 308660.5758886242]
[2019-03-24 03:46:54,247] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:46:54,249] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 5.5977326e-13 1.2125213e-10 5.6700811e-10 1.2260523e-09], sampled 0.9725620408642063
[2019-03-24 03:46:54,250] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1457519.891912316 W.
[2019-03-24 03:47:16,807] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02854899], dtype=float32), 0.33948064]
[2019-03-24 03:47:16,809] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.25, 84.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8614343949271623, 6.911200000000001, 6.9112, 121.9260426156618, 634069.3158591433, 634069.3158591428, 170045.9161711701]
[2019-03-24 03:47:16,810] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:47:16,813] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 7.3428617e-15 1.4338629e-12 1.0923453e-12 2.6682174e-12], sampled 0.020276022481689582
[2019-03-24 03:47:26,935] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02854899], dtype=float32), 0.33948064]
[2019-03-24 03:47:26,938] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.0, 52.0, 1.0, 2.0, 0.7235646621946747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 837207.7659336728, 837207.7659336728, 181279.1188947072]
[2019-03-24 03:47:26,939] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:47:26,941] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.7137945e-12 4.1757234e-10 1.2387360e-09 2.6370754e-09], sampled 0.1757748493398289
[2019-03-24 03:47:26,942] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 837207.7659336728 W.
[2019-03-24 03:47:31,037] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02854899], dtype=float32), 0.33948064]
[2019-03-24 03:47:31,038] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.39856386, 80.50499575, 1.0, 2.0, 0.7614021704385519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 867822.7005204874, 867822.7005204874, 188108.9907274937]
[2019-03-24 03:47:31,038] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:47:31,041] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.5238960e-12 2.8317587e-10 3.5159292e-10 6.9470224e-10], sampled 0.9554161259759448
[2019-03-24 03:47:31,042] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 867822.7005204874 W.
[2019-03-24 03:47:35,940] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 03:47:36,164] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 03:47:36,191] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 03:47:36,452] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 03:47:36,530] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 03:47:37,547] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1400000, evaluation results [1400000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 03:47:38,434] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9999988e-01 1.1085614e-12 9.6214973e-11 1.6838285e-08 8.9822898e-08], sum to 1.0000
[2019-03-24 03:47:38,439] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8184
[2019-03-24 03:47:38,445] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1599102.755705485 W.
[2019-03-24 03:47:38,449] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.33333333333333, 92.83333333333334, 1.0, 2.0, 0.7011695656211252, 1.0, 2.0, 0.7011695656211252, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425587212, 1599102.755705485, 1599102.755705485, 304607.3520907468], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4788600.0000, 
sim time next is 4789200.0000, 
raw observation next is [24.66666666666666, 91.66666666666667, 1.0, 2.0, 0.77934201609011, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156444, 1603362.453353398, 1603362.453353399, 332162.649004801], 
processed observation next is [1.0, 0.43478260869565216, 0.4691358024691356, 0.9166666666666667, 1.0, 1.0, 0.7373119239167976, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288200204, 0.5726294476262136, 0.5726294476262139, 0.6387743250092327], 
reward next is 0.3612, 
noisyNet noise sample is [array([0.62196183], dtype=float32), 0.7499853]. 
=============================================
[2019-03-24 03:47:47,321] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2768356e-02 2.6674916e-09 7.0113665e-06 1.0303290e-01 8.7419170e-01], sum to 1.0000
[2019-03-24 03:47:47,329] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1012
[2019-03-24 03:47:47,332] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.33333333333333, 81.66666666666667, 1.0, 2.0, 0.2105104341989773, 1.0, 2.0, 0.2105104341989773, 1.0, 2.0, 0.3356556131454154, 6.9112, 6.9112, 121.94756008, 730769.456590201, 730769.456590201, 224048.3020777717], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4952400.0000, 
sim time next is 4953000.0000, 
raw observation next is [24.41666666666667, 79.83333333333333, 1.0, 2.0, 0.2851353868138052, 1.0, 2.0, 0.2851353868138052, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 668279.8510557725, 668279.851055773, 177806.7216410752], 
processed observation next is [1.0, 0.30434782608695654, 0.4598765432098767, 0.7983333333333333, 1.0, 1.0, 0.1489706985878633, 1.0, 1.0, 0.1489706985878633, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23867137537706162, 0.2386713753770618, 0.3419360031559138], 
reward next is 0.6581, 
noisyNet noise sample is [array([0.12294234], dtype=float32), -0.60364467]. 
=============================================
[2019-03-24 03:47:47,351] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[22.858438]
 [23.021538]
 [22.891806]
 [22.425459]
 [22.340212]], R is [[23.29252625]
 [23.6287384 ]
 [23.92553902]
 [24.22503281]
 [23.98278236]].
[2019-03-24 03:47:47,814] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5484833e-06 4.6699858e-17 1.0437747e-10 9.6496997e-06 9.9998879e-01], sum to 1.0000
[2019-03-24 03:47:47,821] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6474
[2019-03-24 03:47:47,829] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.498131537458419, 1.0, 2.0, 0.498131537458419, 1.0, 2.0, 0.7930416306453908, 6.911200000000001, 6.9112, 121.94756008, 1704174.468388404, 1704174.468388404, 342672.9161776064], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4978800.0000, 
sim time next is 4979400.0000, 
raw observation next is [28.0, 74.83333333333334, 1.0, 2.0, 0.5753609354538424, 1.0, 2.0, 0.5753609354538424, 1.0, 2.0, 0.915993347440003, 6.911200000000001, 6.9112, 121.94756008, 1968677.668582822, 1968677.668582821, 382114.4821111963], 
processed observation next is [1.0, 0.6521739130434783, 0.5925925925925926, 0.7483333333333334, 1.0, 1.0, 0.4944773041117171, 1.0, 1.0, 0.4944773041117171, 1.0, 1.0, 0.8949916843000039, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7030991673510079, 0.7030991673510075, 0.7348355425215314], 
reward next is 0.2652, 
noisyNet noise sample is [array([0.11668947], dtype=float32), 1.3341569]. 
=============================================
[2019-03-24 03:47:48,920] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.2222836e-06 1.5102128e-14 2.9374519e-08 4.3176065e-04 9.9955899e-01], sum to 1.0000
[2019-03-24 03:47:48,928] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2600
[2019-03-24 03:47:48,932] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.53333333333333, 94.0, 1.0, 2.0, 0.2134479215855105, 1.0, 2.0, 0.2134479215855105, 1.0, 2.0, 0.3398160426776283, 6.911200000000001, 6.9112, 121.94756008, 729778.317863112, 729778.3178631115, 225037.773124074], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4998000.0000, 
sim time next is 4998600.0000, 
raw observation next is [24.4, 95.5, 1.0, 2.0, 0.2143575853930651, 1.0, 2.0, 0.2143575853930651, 1.0, 2.0, 0.3412642570849372, 6.9112, 6.9112, 121.94756008, 732889.9444112263, 732889.9444112263, 225341.9743036109], 
processed observation next is [1.0, 0.8695652173913043, 0.4592592592592592, 0.955, 1.0, 1.0, 0.06471141118222035, 1.0, 1.0, 0.06471141118222035, 1.0, 1.0, 0.17658032135617147, 0.0, 0.0, 0.8096049824067558, 0.26174640871829513, 0.26174640871829513, 0.43334995058386716], 
reward next is 0.5667, 
noisyNet noise sample is [array([-0.51188695], dtype=float32), 0.8202329]. 
=============================================
[2019-03-24 03:47:50,702] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.3299129e-13 1.7921517e-20 1.3195160e-12 4.0887135e-06 9.9999595e-01], sum to 1.0000
[2019-03-24 03:47:50,715] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2076
[2019-03-24 03:47:50,719] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.1961269548516565, 1.0, 2.0, 0.1961269548516565, 1.0, 2.0, 0.3122404995328285, 6.911200000000001, 6.9112, 121.94756008, 670532.0471552748, 670532.0471552743, 219333.8251756009], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5011800.0000, 
sim time next is 5012400.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.1963769476021801, 1.0, 2.0, 0.1963769476021801, 1.0, 2.0, 0.3126384961333574, 6.9112, 6.9112, 121.94756008, 671387.1134128519, 671387.1134128519, 219414.9554174058], 
processed observation next is [0.0, 0.0, 0.4074074074074074, 1.0, 1.0, 1.0, 0.04330589000259536, 1.0, 1.0, 0.04330589000259536, 1.0, 1.0, 0.14079812016669677, 0.0, 0.0, 0.8096049824067558, 0.2397811119331614, 0.2397811119331614, 0.42195183734116504], 
reward next is 0.5780, 
noisyNet noise sample is [array([-1.4017926], dtype=float32), 0.024248388]. 
=============================================
[2019-03-24 03:47:51,132] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.8287278e-08 4.1321086e-17 4.3722192e-12 2.6277524e-08 9.9999988e-01], sum to 1.0000
[2019-03-24 03:47:51,139] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0187
[2019-03-24 03:47:51,145] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 77.66666666666667, 1.0, 2.0, 0.2722251934254616, 1.0, 2.0, 0.2722251934254616, 1.0, 2.0, 0.4333913736889342, 6.911200000000001, 6.9112, 121.94756008, 930859.7876924915, 930859.7876924911, 245644.2004485303], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5055600.0000, 
sim time next is 5056200.0000, 
raw observation next is [30.0, 77.0, 1.0, 2.0, 0.2730969271731226, 1.0, 2.0, 0.2730969271731226, 1.0, 2.0, 0.4347792022055966, 6.911200000000001, 6.9112, 121.94756008, 933842.4514308575, 933842.4514308571, 245964.3373049245], 
processed observation next is [0.0, 0.5217391304347826, 0.6666666666666666, 0.77, 1.0, 1.0, 0.13463919901562216, 1.0, 1.0, 0.13463919901562216, 1.0, 1.0, 0.29347400275699576, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3335151612253063, 0.3335151612253061, 0.47300834097100863], 
reward next is 0.5270, 
noisyNet noise sample is [array([0.9348652], dtype=float32), -0.42723134]. 
=============================================
[2019-03-24 03:47:51,539] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.5123124e-15 7.6971180e-26 1.1173337e-18 8.7087122e-11 1.0000000e+00], sum to 1.0000
[2019-03-24 03:47:51,549] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6982
[2019-03-24 03:47:51,554] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.66666666666667, 80.66666666666667, 1.0, 2.0, 0.2333285160254349, 1.0, 2.0, 0.2333285160254349, 1.0, 2.0, 0.371466596491747, 6.9112, 6.9112, 121.94756008, 797785.4246028624, 797785.4246028624, 231791.5358971353], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5046600.0000, 
sim time next is 5047200.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.2345428589284658, 1.0, 2.0, 0.2345428589284658, 1.0, 2.0, 0.3733998699417594, 6.911199999999999, 6.9112, 121.94756008, 801939.6180039499, 801939.6180039503, 232211.2301612628], 
processed observation next is [0.0, 0.43478260869565216, 0.5925925925925926, 0.79, 1.0, 1.0, 0.08874149872436404, 1.0, 1.0, 0.08874149872436404, 1.0, 1.0, 0.21674983742719922, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.28640700642998207, 0.28640700642998224, 0.44656005800242843], 
reward next is 0.5534, 
noisyNet noise sample is [array([-0.12160653], dtype=float32), 0.9075745]. 
=============================================
[2019-03-24 03:47:52,021] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.4912438e-07 2.0765552e-18 2.1039470e-12 9.2847145e-08 9.9999905e-01], sum to 1.0000
[2019-03-24 03:47:52,029] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7581
[2019-03-24 03:47:52,035] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.66666666666667, 72.33333333333334, 1.0, 2.0, 0.2721441738748854, 1.0, 2.0, 0.2721441738748854, 1.0, 2.0, 0.4332623879257943, 6.9112, 6.9112, 121.94756008, 930582.5774062426, 930582.5774062426, 245614.468237487], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5066400.0000, 
sim time next is 5067000.0000, 
raw observation next is [31.5, 73.0, 1.0, 2.0, 0.2883130025890261, 1.0, 2.0, 0.2883130025890261, 1.0, 2.0, 0.4590036898206949, 6.9112, 6.9112, 121.94756008, 985906.589433276, 985906.589433276, 251620.5856483589], 
processed observation next is [0.0, 0.6521739130434783, 0.7222222222222222, 0.73, 1.0, 1.0, 0.15275357451074534, 1.0, 1.0, 0.15275357451074534, 1.0, 1.0, 0.3237546122758686, 0.0, 0.0, 0.8096049824067558, 0.35210949622617, 0.35210949622617, 0.4838857416314594], 
reward next is 0.5161, 
noisyNet noise sample is [array([0.86066306], dtype=float32), 1.8982979]. 
=============================================
[2019-03-24 03:47:52,049] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[52.13197 ]
 [52.04787 ]
 [51.92954 ]
 [51.832115]
 [51.72335 ]], R is [[52.17648315]
 [52.18238449]
 [52.18538666]
 [52.18003845]
 [52.18590927]].
[2019-03-24 03:47:52,457] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.7714672e-05 8.4604505e-15 8.7637858e-10 5.4110300e-05 9.9990821e-01], sum to 1.0000
[2019-03-24 03:47:52,464] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2012
[2019-03-24 03:47:52,474] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.91666666666667, 88.33333333333334, 1.0, 2.0, 0.2190494111682759, 1.0, 2.0, 0.2190494111682759, 1.0, 2.0, 0.3487337965211707, 6.9112, 6.9112, 121.94756008, 748939.1616639057, 748939.1616639057, 226918.3223332269], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5043000.0000, 
sim time next is 5043600.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.2227630553494672, 1.0, 2.0, 0.2227630553494672, 1.0, 2.0, 0.3546460390025745, 6.9112, 6.9112, 121.94756008, 761642.5745254003, 761642.5745254003, 228174.7541901129], 
processed observation next is [0.0, 0.391304347826087, 0.5185185185185185, 0.89, 1.0, 1.0, 0.07471792303507999, 1.0, 1.0, 0.07471792303507999, 1.0, 1.0, 0.19330754875321812, 0.0, 0.0, 0.8096049824067558, 0.27201520518764294, 0.27201520518764294, 0.43879760421175557], 
reward next is 0.5612, 
noisyNet noise sample is [array([-0.29318237], dtype=float32), 1.420507]. 
=============================================
[2019-03-24 03:47:58,984] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.38977034e-08 1.90461066e-20 1.10645035e-11 1.28988671e-04
 9.99871016e-01], sum to 1.0000
[2019-03-24 03:47:58,990] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3173
[2019-03-24 03:47:58,997] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.16666666666667, 100.0, 1.0, 2.0, 0.2504574223500685, 1.0, 2.0, 0.2504574223500685, 1.0, 2.0, 0.398736373210097, 6.9112, 6.9112, 121.94756008, 856384.4548319797, 856384.4548319797, 237787.702210372], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5206200.0000, 
sim time next is 5206800.0000, 
raw observation next is [23.33333333333334, 100.0, 1.0, 2.0, 0.2461809949257507, 1.0, 2.0, 0.2461809949257507, 1.0, 2.0, 0.3919281614770651, 6.9112, 6.9112, 121.94756008, 841754.1169711077, 841754.1169711077, 236275.3355104837], 
processed observation next is [1.0, 0.2608695652173913, 0.4197530864197533, 1.0, 1.0, 1.0, 0.10259642253065561, 1.0, 1.0, 0.10259642253065561, 1.0, 1.0, 0.23991020184633136, 0.0, 0.0, 0.8096049824067558, 0.30062647034682416, 0.30062647034682416, 0.45437564521246865], 
reward next is 0.5456, 
noisyNet noise sample is [array([-1.4124794], dtype=float32), 0.26534978]. 
=============================================
[2019-03-24 03:48:05,040] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8756287e-05 1.6785531e-13 1.0710501e-08 2.0441673e-06 9.9997914e-01], sum to 1.0000
[2019-03-24 03:48:05,046] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6944
[2019-03-24 03:48:05,050] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.63333333333334, 85.66666666666667, 1.0, 2.0, 0.3511235584608446, 1.0, 2.0, 0.3511235584608446, 1.0, 2.0, 0.5594434537125565, 6.9112, 6.9112, 121.94756008, 1212845.056647518, 1212845.056647518, 276384.582112268], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5305800.0000, 
sim time next is 5306400.0000, 
raw observation next is [23.8, 85.0, 1.0, 2.0, 0.3376508492938935, 1.0, 2.0, 0.3376508492938935, 1.0, 2.0, 0.5378856164284913, 6.9112, 6.9112, 121.94756008, 1164508.655570065, 1164508.655570065, 270890.9405703784], 
processed observation next is [1.0, 0.43478260869565216, 0.43703703703703706, 0.85, 1.0, 1.0, 0.21148910630225418, 1.0, 1.0, 0.21148910630225418, 1.0, 1.0, 0.4223570205356141, 0.0, 0.0, 0.8096049824067558, 0.4158959484178803, 0.4158959484178803, 0.5209441164814969], 
reward next is 0.4791, 
noisyNet noise sample is [array([0.04237229], dtype=float32), -0.3304048]. 
=============================================
[2019-03-24 03:48:06,297] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3945827e-07 5.1631476e-18 6.8362976e-12 1.6050143e-08 9.9999976e-01], sum to 1.0000
[2019-03-24 03:48:06,303] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3858
[2019-03-24 03:48:06,311] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.4, 67.5, 1.0, 2.0, 0.1923948357685053, 1.0, 2.0, 0.1923948357685053, 1.0, 2.0, 0.3062988444058188, 6.9112, 6.9112, 121.94756008, 657766.9539792762, 657766.9539792762, 218126.8005757637], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5333400.0000, 
sim time next is 5334000.0000, 
raw observation next is [28.36666666666667, 67.66666666666666, 1.0, 2.0, 0.1947223561259759, 1.0, 2.0, 0.1947223561259759, 1.0, 2.0, 0.310004332616958, 6.9112, 6.9112, 121.94756008, 665727.8256691744, 665727.8256691744, 218878.6409489777], 
processed observation next is [1.0, 0.7391304347826086, 0.606172839506173, 0.6766666666666665, 1.0, 1.0, 0.04133613824520942, 1.0, 1.0, 0.04133613824520942, 1.0, 1.0, 0.13750541577119746, 0.0, 0.0, 0.8096049824067558, 0.23775993773899087, 0.23775993773899087, 0.42092046336341865], 
reward next is 0.5791, 
noisyNet noise sample is [array([-1.2372555], dtype=float32), -0.94259036]. 
=============================================
[2019-03-24 03:48:06,330] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[52.221943]
 [51.624916]
 [50.85499 ]
 [49.40944 ]
 [49.211906]], R is [[52.70417404]
 [52.7576561 ]
 [52.80872726]
 [52.81155777]
 [52.58415222]].
[2019-03-24 03:48:06,522] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9716090e-08 1.6304823e-16 3.1932050e-13 9.0946877e-09 1.0000000e+00], sum to 1.0000
[2019-03-24 03:48:06,531] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0434
[2019-03-24 03:48:06,536] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.41666666666667, 66.16666666666667, 1.0, 2.0, 0.5223219236568779, 1.0, 2.0, 0.5223219236568779, 1.0, 2.0, 0.8315535132992147, 6.911199999999999, 6.9112, 121.94756008, 1787015.772822323, 1787015.772822324, 354679.9814987641], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5328600.0000, 
sim time next is 5329200.0000, 
raw observation next is [28.43333333333333, 66.33333333333334, 1.0, 2.0, 0.5324332711162145, 1.0, 2.0, 0.5324332711162145, 1.0, 2.0, 0.8476511077580756, 6.9112, 6.9112, 121.94756008, 1821644.913367005, 1821644.913367005, 359792.7537282027], 
processed observation next is [1.0, 0.6956521739130435, 0.6086419753086418, 0.6633333333333334, 1.0, 1.0, 0.4433729418050173, 1.0, 1.0, 0.4433729418050173, 1.0, 1.0, 0.8095638846975944, 0.0, 0.0, 0.8096049824067558, 0.6505874690596447, 0.6505874690596447, 0.6919091417850052], 
reward next is 0.3081, 
noisyNet noise sample is [array([-0.3477583], dtype=float32), 0.9219839]. 
=============================================
[2019-03-24 03:48:14,001] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.54244541e-12 2.52814975e-20 7.57378152e-15 1.16236874e-10
 1.00000000e+00], sum to 1.0000
[2019-03-24 03:48:14,008] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7398
[2019-03-24 03:48:14,011] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.7, 83.0, 1.0, 2.0, 0.794261085443276, 1.0, 2.0, 0.7104952046980726, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2431687.968664587, 2431687.968664587, 455530.0707808626], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5481600.0000, 
sim time next is 5482200.0000, 
raw observation next is [29.85, 82.5, 1.0, 2.0, 0.8249509840925182, 1.0, 2.0, 0.7258401540226939, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2484279.523490266, 2484279.523490266, 464504.1901517587], 
processed observation next is [1.0, 0.43478260869565216, 0.6611111111111112, 0.825, 1.0, 1.0, 0.791608314395855, 1.0, 1.0, 0.6736192309793975, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.8872426869608092, 0.8872426869608092, 0.8932772887533822], 
reward next is 0.1067, 
noisyNet noise sample is [array([-0.5942905], dtype=float32), 0.33252436]. 
=============================================
[2019-03-24 03:48:16,866] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2090059e-11 1.6664056e-24 3.2798836e-17 1.3076693e-10 1.0000000e+00], sum to 1.0000
[2019-03-24 03:48:16,878] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1466
[2019-03-24 03:48:16,881] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.84999999999999, 66.0, 1.0, 2.0, 0.7964976008663675, 1.0, 2.0, 0.7116134624096184, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2435520.45481198, 2435520.454811979, 456177.1777184426], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5491800.0000, 
sim time next is 5492400.0000, 
raw observation next is [33.03333333333333, 65.0, 1.0, 2.0, 0.7407364219232788, 1.0, 2.0, 0.6837328729380742, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2339973.173079789, 2339973.173079789, 440366.0204077727], 
processed observation next is [1.0, 0.5652173913043478, 0.7790123456790122, 0.65, 1.0, 1.0, 0.6913528832419986, 1.0, 1.0, 0.6234915154024693, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.8357047046713533, 0.8357047046713533, 0.846857731553409], 
reward next is 0.1531, 
noisyNet noise sample is [array([-0.20254779], dtype=float32), -0.08412045]. 
=============================================
[2019-03-24 03:48:18,874] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5251345e-08 9.2961634e-17 2.6960650e-10 3.4573656e-08 1.0000000e+00], sum to 1.0000
[2019-03-24 03:48:18,881] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6855
[2019-03-24 03:48:18,887] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.4, 86.0, 1.0, 2.0, 0.2395026633120144, 1.0, 2.0, 0.2395026633120144, 1.0, 2.0, 0.3812960400499207, 6.9112, 6.9112, 121.94756008, 818907.0416467083, 818907.0416467083, 233933.9677085378], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5556600.0000, 
sim time next is 5557200.0000, 
raw observation next is [25.4, 85.66666666666667, 1.0, 2.0, 0.2426639950627963, 1.0, 2.0, 0.2426639950627963, 1.0, 2.0, 0.3863289831545528, 6.9112, 6.9112, 121.94756008, 829722.1107376833, 829722.1107376833, 235039.1981796317], 
processed observation next is [1.0, 0.30434782608695654, 0.49629629629629624, 0.8566666666666667, 1.0, 1.0, 0.09840951793190035, 1.0, 1.0, 0.09840951793190035, 1.0, 1.0, 0.23291122894319094, 0.0, 0.0, 0.8096049824067558, 0.2963293252634583, 0.2963293252634583, 0.4519984580377533], 
reward next is 0.5480, 
noisyNet noise sample is [array([-1.1980759], dtype=float32), -0.9713107]. 
=============================================
[2019-03-24 03:48:24,248] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.8687750e-01 9.8442271e-15 4.0042619e-10 1.6497101e-08 1.3122444e-02], sum to 1.0000
[2019-03-24 03:48:24,254] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0487
[2019-03-24 03:48:24,262] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 804934.1800767842 W.
[2019-03-24 03:48:24,266] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 79.0, 1.0, 2.0, 0.2354182173662478, 1.0, 2.0, 0.2354182173662478, 1.0, 2.0, 0.3747934690831424, 6.9112, 6.9112, 121.94756008, 804934.1800767842, 804934.1800767842, 232514.2778096902], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5659200.0000, 
sim time next is 5659800.0000, 
raw observation next is [28.2, 78.33333333333334, 1.0, 2.0, 0.7079015107558698, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806812.2042463484, 806812.2042463484, 177647.0298737185], 
processed observation next is [0.0, 0.5217391304347826, 0.6, 0.7833333333333334, 1.0, 1.0, 0.6522637032807974, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28814721580226726, 0.28814721580226726, 0.34162890360330483], 
reward next is 0.6584, 
noisyNet noise sample is [array([0.9112403], dtype=float32), 1.4120946]. 
=============================================
[2019-03-24 03:48:26,342] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.6557858e-16 2.7402277e-12 1.8047004e-12 2.0943281e-08], sum to 1.0000
[2019-03-24 03:48:26,349] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0796
[2019-03-24 03:48:26,359] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 870312.4414858783 W.
[2019-03-24 03:48:26,367] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.66666666666666, 86.33333333333334, 1.0, 2.0, 0.2545284776578528, 1.0, 2.0, 0.2545284776578528, 1.0, 2.0, 0.4052176258451048, 6.9112, 6.9112, 121.94756008, 870312.4414858783, 870312.4414858783, 239236.9294346377], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5688600.0000, 
sim time next is 5689200.0000, 
raw observation next is [27.43333333333333, 86.66666666666667, 1.0, 2.0, 0.3771746629389899, 1.0, 2.0, 0.3771746629389899, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 859779.5769704703, 859779.5769704706, 200013.1089534175], 
processed observation next is [0.0, 0.8695652173913043, 0.5716049382716049, 0.8666666666666667, 1.0, 1.0, 0.2585412654035594, 1.0, 1.0, 0.2585412654035594, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3070641346323108, 0.3070641346323109, 0.3846405941411875], 
reward next is 0.6154, 
noisyNet noise sample is [array([-1.7189789], dtype=float32), 1.7479932]. 
=============================================
[2019-03-24 03:48:28,902] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 03:48:28,904] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:48:28,908] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:48:28,909] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:48:28,912] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:48:28,911] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:48:28,914] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:48:28,919] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:48:28,919] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:48:28,920] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:48:28,915] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:48:28,943] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run58
[2019-03-24 03:48:28,966] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run58
[2019-03-24 03:48:28,967] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run58
[2019-03-24 03:48:29,017] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run58
[2019-03-24 03:48:29,045] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run58
[2019-03-24 03:48:49,875] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03380572], dtype=float32), 0.3495751]
[2019-03-24 03:48:49,876] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.0, 66.0, 1.0, 2.0, 0.6735359578915886, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9818346786031936, 6.911199999999999, 6.9112, 121.9260426156618, 1496685.89127445, 1496685.891274451, 309552.8491669449]
[2019-03-24 03:48:49,876] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:48:49,879] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 6.5290743e-25 3.2162348e-18 4.1012197e-17 7.0498295e-14], sampled 0.07146655750538466
[2019-03-24 03:48:49,880] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1496685.89127445 W.
[2019-03-24 03:48:54,849] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03380572], dtype=float32), 0.3495751]
[2019-03-24 03:48:54,852] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.1, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8894522538031101, 6.911200000000001, 6.9112, 121.9260426156618, 652940.2185374176, 652940.2185374171, 174114.3079579854]
[2019-03-24 03:48:54,852] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:48:54,854] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.3339432e-30 5.8555561e-23 1.8709842e-23 3.5034737e-20], sampled 0.21118682145844359
[2019-03-24 03:48:55,935] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03380572], dtype=float32), 0.3495751]
[2019-03-24 03:48:55,935] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.23333333333333, 81.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.762807449993399, 6.911200000000001, 6.9112, 121.9260426156618, 568649.8671169098, 568649.8671169094, 154457.3685094063]
[2019-03-24 03:48:55,936] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:48:55,939] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.5365301e-31 1.5417972e-23 4.3267482e-24 9.7647112e-21], sampled 0.5432152253411356
[2019-03-24 03:49:08,663] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03380572], dtype=float32), 0.3495751]
[2019-03-24 03:49:08,664] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.66666666666667, 68.16666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9289883577229388, 6.911200000000001, 6.9112, 121.9260426156618, 675815.4196120918, 675815.4196120914, 180572.7890255228]
[2019-03-24 03:49:08,665] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:49:08,667] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 6.7269620e-31 8.2977603e-23 9.6228901e-23 3.0376083e-19], sampled 0.3561011394139969
[2019-03-24 03:49:16,839] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03380572], dtype=float32), 0.3495751]
[2019-03-24 03:49:16,840] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.19564582, 94.19836329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.646076565916683, 6.911199999999999, 6.9112, 121.9260426156618, 481040.1175642812, 481040.1175642816, 135996.3303060232]
[2019-03-24 03:49:16,842] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:49:16,846] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 9.3802362e-31 4.0072572e-23 1.1319730e-23 2.2138823e-20], sampled 0.6735190874704658
[2019-03-24 03:49:20,976] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03380572], dtype=float32), 0.3495751]
[2019-03-24 03:49:20,980] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.7, 86.0, 1.0, 2.0, 0.5839012848260426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 678668.9812822536, 678668.9812822532, 155960.0744194104]
[2019-03-24 03:49:20,981] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:49:20,986] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.0251897e-26 9.2303883e-20 8.8986798e-20 8.2634807e-17], sampled 0.1287837009713252
[2019-03-24 03:49:44,407] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03380572], dtype=float32), 0.3495751]
[2019-03-24 03:49:44,408] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.45, 71.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.819932091142572, 6.911199999999999, 6.9112, 121.9260426156618, 608079.854497078, 608079.8544970785, 163262.448335242]
[2019-03-24 03:49:44,409] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:49:44,414] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 7.0647869e-32 7.3255375e-24 2.4544405e-24 6.5711652e-21], sampled 0.474579385907998
[2019-03-24 03:49:56,098] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03380572], dtype=float32), 0.3495751]
[2019-03-24 03:49:56,099] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.8, 77.0, 1.0, 2.0, 0.6479655472720778, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1453412.821888628, 1453412.821888629, 308029.4315515338]
[2019-03-24 03:49:56,100] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:49:56,104] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.000000e+00 7.610724e-26 6.382740e-19 7.557522e-18 1.578000e-14], sampled 0.6201543770594411
[2019-03-24 03:49:56,105] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1453412.821888628 W.
[2019-03-24 03:50:07,091] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03380572], dtype=float32), 0.3495751]
[2019-03-24 03:50:07,092] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.89486477, 86.21947622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7388048302442317, 6.911200000000001, 6.9112, 121.9260426156618, 550597.6938174737, 550597.6938174732, 151754.9988998105]
[2019-03-24 03:50:07,093] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:50:07,096] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.8010343e-32 1.8354602e-24 2.4043142e-25 5.1771611e-22], sampled 0.9069801498445681
[2019-03-24 03:50:07,406] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 03:50:07,932] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 03:50:08,003] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 03:50:08,068] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 03:50:08,236] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 03:50:09,253] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1425000, evaluation results [1425000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 03:50:12,674] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 2.3280831e-26 2.4315587e-19 1.4472789e-17 6.8555551e-17], sum to 1.0000
[2019-03-24 03:50:12,681] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5068
[2019-03-24 03:50:12,687] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.9, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8586485235009769, 6.911200000000001, 6.9112, 121.9260426156618, 641051.1475365313, 641051.1475365309, 165124.9455628959], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5799600.0000, 
sim time next is 5800200.0000, 
raw observation next is [21.83333333333333, 89.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8632978019403781, 6.911200000000001, 6.9112, 121.9260426156618, 644525.8278643484, 644525.827864348, 165691.7895234186], 
processed observation next is [1.0, 0.13043478260869565, 0.36419753086419737, 0.895, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8291222524254727, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23018779566583872, 0.23018779566583855, 0.31863805677580503], 
reward next is 0.6814, 
noisyNet noise sample is [array([0.05475765], dtype=float32), 1.1577184]. 
=============================================
[2019-03-24 03:50:14,337] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.2665962e-15 1.2688345e-10 2.1339052e-11 1.6314835e-09], sum to 1.0000
[2019-03-24 03:50:14,343] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2642
[2019-03-24 03:50:14,352] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1314087.893305966 W.
[2019-03-24 03:50:14,355] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.9, 45.0, 1.0, 2.0, 0.5397438967609084, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8797655370380396, 6.911199999999999, 6.9112, 121.9260426156618, 1314087.893305966, 1314087.893305967, 268453.7727668748], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5842800.0000, 
sim time next is 5843400.0000, 
raw observation next is [27.91666666666666, 44.66666666666666, 1.0, 2.0, 0.4940703105054291, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8071082827067134, 6.911199999999999, 6.9112, 121.9260426156618, 1206083.420889378, 1206083.420889379, 252141.2878269651], 
processed observation next is [1.0, 0.6521739130434783, 0.5895061728395059, 0.44666666666666655, 1.0, 1.0, 0.39770275060170135, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7588853533833917, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4307440788890636, 0.4307440788890639, 0.4848870919749329], 
reward next is 0.5151, 
noisyNet noise sample is [array([0.7565201], dtype=float32), 0.53350604]. 
=============================================
[2019-03-24 03:50:14,458] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.4186674e-19 9.2866123e-13 4.9081177e-12 7.9438144e-11], sum to 1.0000
[2019-03-24 03:50:14,465] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6128
[2019-03-24 03:50:14,477] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1315537.415403809 W.
[2019-03-24 03:50:14,480] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.95, 44.0, 1.0, 2.0, 0.538840282681526, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8802842385006369, 6.911200000000001, 6.9112, 121.9260426156618, 1315537.415403809, 1315537.415403809, 267917.4875529343], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5844600.0000, 
sim time next is 5845200.0000, 
raw observation next is [27.96666666666667, 43.66666666666666, 1.0, 2.0, 0.3479467578266897, 1.0, 1.0, 0.3479467578266897, 1.0, 2.0, 0.5636351433032191, 6.9112, 6.9112, 121.94756008, 1259660.214051598, 1259660.214051598, 274330.3404143102], 
processed observation next is [1.0, 0.6521739130434783, 0.5913580246913581, 0.4366666666666666, 1.0, 1.0, 0.22374614026986872, 1.0, 0.5, 0.22374614026986872, 1.0, 1.0, 0.4545439291290238, 0.0, 0.0, 0.8096049824067558, 0.4498786478755707, 0.4498786478755707, 0.5275583469505966], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.903471], dtype=float32), 0.41713482]. 
=============================================
[2019-03-24 03:50:19,265] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9901438e-01 3.2773902e-16 2.0091650e-12 2.3583366e-10 9.8554569e-04], sum to 1.0000
[2019-03-24 03:50:19,271] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7889
[2019-03-24 03:50:19,277] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1322326.746104181 W.
[2019-03-24 03:50:19,283] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.55, 42.5, 1.0, 2.0, 0.5542343060861978, 1.0, 2.0, 0.5542343060861978, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1322326.746104181, 1322326.746104181, 255242.2582977825], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5926200.0000, 
sim time next is 5926800.0000, 
raw observation next is [29.5, 43.0, 1.0, 2.0, 0.5337656230467137, 1.0, 2.0, 0.5337656230467137, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1276241.775620181, 1276241.775620181, 248597.4315719635], 
processed observation next is [1.0, 0.6086956521739131, 0.6481481481481481, 0.43, 1.0, 1.0, 0.44495907505561155, 1.0, 1.0, 0.44495907505561155, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.45580063415006467, 0.45580063415006467, 0.47807198379223753], 
reward next is 0.5219, 
noisyNet noise sample is [array([0.24694514], dtype=float32), -1.2726811]. 
=============================================
[2019-03-24 03:50:29,409] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.4000713e-05 2.4025368e-18 4.3106252e-12 3.7529985e-10 9.9993598e-01], sum to 1.0000
[2019-03-24 03:50:29,417] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0972
[2019-03-24 03:50:29,421] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.35, 81.0, 1.0, 2.0, 0.1901633391007558, 1.0, 2.0, 0.1901633391007558, 1.0, 2.0, 0.3035972537113084, 6.9112, 6.9112, 121.94756008, 664467.8164116845, 664467.8164116845, 217343.6230304859], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6075000.0000, 
sim time next is 6075600.0000, 
raw observation next is [24.4, 80.66666666666666, 1.0, 2.0, 0.1939092233394926, 1.0, 2.0, 0.1939092233394926, 1.0, 2.0, 0.3095473183913167, 6.9112, 6.9112, 121.94756008, 677261.9131993186, 677261.9131993186, 218556.0848398341], 
processed observation next is [1.0, 0.30434782608695654, 0.4592592592592592, 0.8066666666666665, 1.0, 1.0, 0.040368123023205464, 1.0, 1.0, 0.040368123023205464, 1.0, 1.0, 0.13693414798914588, 0.0, 0.0, 0.8096049824067558, 0.24187925471404234, 0.24187925471404234, 0.42030016315352714], 
reward next is 0.5797, 
noisyNet noise sample is [array([-0.13238937], dtype=float32), -0.11875158]. 
=============================================
[2019-03-24 03:50:30,741] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3021546e-04 3.3717268e-17 2.3862159e-09 6.5395284e-08 9.9976975e-01], sum to 1.0000
[2019-03-24 03:50:30,748] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6077
[2019-03-24 03:50:30,751] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.76666666666667, 73.83333333333334, 1.0, 2.0, 0.1819147378320281, 1.0, 2.0, 0.1819147378320281, 1.0, 2.0, 0.2900968870031871, 6.911199999999999, 6.9112, 121.94756008, 631940.0872538568, 631940.0872538573, 214754.6202179308], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6131400.0000, 
sim time next is 6132000.0000, 
raw observation next is [25.63333333333334, 74.66666666666667, 1.0, 2.0, 0.1818242024144137, 1.0, 2.0, 0.1818242024144137, 1.0, 2.0, 0.2899554025112394, 6.911200000000001, 6.9112, 121.94756008, 631662.453093972, 631662.4530939716, 214725.5906027586], 
processed observation next is [1.0, 1.0, 0.5049382716049385, 0.7466666666666667, 1.0, 1.0, 0.025981193350492482, 1.0, 1.0, 0.025981193350492482, 1.0, 1.0, 0.11244425313904925, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.22559373324784715, 0.22559373324784698, 0.41293382808222806], 
reward next is 0.5871, 
noisyNet noise sample is [array([-1.235301], dtype=float32), 0.4680357]. 
=============================================
[2019-03-24 03:50:30,770] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[48.332993]
 [48.28454 ]
 [48.20166 ]
 [48.182877]
 [48.16118 ]], R is [[48.4669342 ]
 [48.5692749 ]
 [48.67047119]
 [48.77042007]
 [48.86917114]].
[2019-03-24 03:50:31,921] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.0724684e-11 2.2982442e-23 7.1268420e-13 1.5857299e-14 1.0000000e+00], sum to 1.0000
[2019-03-24 03:50:31,929] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1176
[2019-03-24 03:50:31,934] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.4, 66.0, 1.0, 2.0, 0.1881184615898863, 1.0, 2.0, 0.1881184615898863, 1.0, 2.0, 0.2997082913393768, 6.911200000000001, 6.9112, 121.94756008, 649186.7516719615, 649186.751671961, 216757.0107366731], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6120000.0000, 
sim time next is 6120600.0000, 
raw observation next is [27.31666666666666, 66.33333333333333, 1.0, 2.0, 0.1874493701390113, 1.0, 2.0, 0.1874493701390113, 1.0, 2.0, 0.2986570691537959, 6.911200000000001, 6.9112, 121.94756008, 647152.4152933495, 647152.4152933491, 216541.9482774327], 
processed observation next is [1.0, 0.8695652173913043, 0.5672839506172836, 0.6633333333333333, 1.0, 1.0, 0.032677821594061074, 1.0, 1.0, 0.032677821594061074, 1.0, 1.0, 0.12332133644224488, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2311258626047677, 0.23112586260476753, 0.4164268236104475], 
reward next is 0.5836, 
noisyNet noise sample is [array([-1.6487159], dtype=float32), -0.69841915]. 
=============================================
[2019-03-24 03:50:35,007] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9537563e-08 3.4837860e-22 1.7196125e-15 5.7113798e-18 1.0000000e+00], sum to 1.0000
[2019-03-24 03:50:35,014] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7979
[2019-03-24 03:50:35,020] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.16666666666667, 72.66666666666667, 1.0, 2.0, 0.1696386098329778, 1.0, 2.0, 0.1696386098329778, 1.0, 2.0, 0.2714970946232096, 6.9112, 6.9112, 121.94756008, 598212.2606880603, 598212.2606880603, 210748.8550999885], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6218400.0000, 
sim time next is 6219000.0000, 
raw observation next is [25.1, 73.0, 1.0, 2.0, 0.1693979014521676, 1.0, 2.0, 0.1693979014521676, 1.0, 2.0, 0.2711372100156289, 6.911200000000001, 6.9112, 121.94756008, 597540.4388927204, 597540.4388927199, 210669.6908697893], 
processed observation next is [1.0, 1.0, 0.4851851851851852, 0.73, 1.0, 1.0, 0.011187977919247137, 1.0, 1.0, 0.011187977919247137, 1.0, 1.0, 0.08892151251953612, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.213407299604543, 0.21340729960454283, 0.405134020903441], 
reward next is 0.5949, 
noisyNet noise sample is [array([0.12583962], dtype=float32), -0.6202731]. 
=============================================
[2019-03-24 03:50:35,036] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[64.05284 ]
 [64.049736]
 [64.01754 ]
 [63.9276  ]
 [63.91553 ]], R is [[64.01922607]
 [63.97375107]
 [63.92837143]
 [63.88286972]
 [63.83669281]].
[2019-03-24 03:50:35,680] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.2438404e-23 5.3015328e-14 8.0059230e-14 1.3255192e-09], sum to 1.0000
[2019-03-24 03:50:35,690] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7027
[2019-03-24 03:50:35,704] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 783205.419611781 W.
[2019-03-24 03:50:35,707] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.9, 56.33333333333333, 1.0, 2.0, 0.2290664751879525, 1.0, 2.0, 0.2290664751879525, 1.0, 1.0, 0.3646812886734954, 6.9112, 6.9112, 121.94756008, 783205.419611781, 783205.419611781, 230325.0378692757], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6363600.0000, 
sim time next is 6364200.0000, 
raw observation next is [31.95, 56.16666666666667, 1.0, 2.0, 0.6879341807329039, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 784043.323573039, 784043.323573039, 173872.8176822191], 
processed observation next is [0.0, 0.6521739130434783, 0.7388888888888888, 0.5616666666666668, 1.0, 1.0, 0.6284930723010761, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2800154727046568, 0.2800154727046568, 0.3343708032350367], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.58108175], dtype=float32), -0.47062874]. 
=============================================
[2019-03-24 03:50:50,891] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.3229666e-13 2.1498381e-22 1.7154185e-16 3.0007512e-13 1.0000000e+00], sum to 1.0000
[2019-03-24 03:50:50,898] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5834
[2019-03-24 03:50:50,901] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.3, 89.0, 1.0, 2.0, 0.3012807125049876, 1.0, 2.0, 0.3012807125049876, 1.0, 2.0, 0.4796487063357332, 6.9112, 6.9112, 121.94756008, 1030280.391341557, 1030280.391341557, 256542.9354896053], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6508800.0000, 
sim time next is 6509400.0000, 
raw observation next is [26.43333333333333, 88.33333333333334, 1.0, 2.0, 0.3576015709757516, 1.0, 2.0, 0.3576015709757516, 1.0, 2.0, 0.5693133472634948, 6.9112, 6.9112, 121.94756008, 1223032.798280388, 1223032.798280388, 279007.7735568641], 
processed observation next is [1.0, 0.34782608695652173, 0.5345679012345678, 0.8833333333333334, 1.0, 1.0, 0.23523996544732337, 1.0, 1.0, 0.23523996544732337, 1.0, 1.0, 0.46164168407936845, 0.0, 0.0, 0.8096049824067558, 0.4367974279572814, 0.4367974279572814, 0.5365534106862772], 
reward next is 0.4634, 
noisyNet noise sample is [array([0.5350431], dtype=float32), 0.30765614]. 
=============================================
[2019-03-24 03:50:58,981] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.0185637e-32 2.7918328e-24 1.5515738e-23 2.6660283e-17], sum to 1.0000
[2019-03-24 03:50:58,989] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1991
[2019-03-24 03:50:58,995] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.8, 39.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5247944085310586, 6.9112, 6.9112, 121.9260426156618, 374714.55125822, 374714.55125822, 115557.1931819773], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6650400.0000, 
sim time next is 6651000.0000, 
raw observation next is [24.7, 39.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5227935135951703, 6.9112, 6.9112, 121.9260426156618, 373283.7423361991, 373283.7423361991, 115526.5354048124], 
processed observation next is [1.0, 1.0, 0.4703703703703703, 0.395, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4034918919939629, 0.0, 0.0, 0.8094621288201359, 0.13331562226292826, 0.13331562226292826, 0.22216641424002384], 
reward next is 0.7778, 
noisyNet noise sample is [array([1.0261692], dtype=float32), 1.1616417]. 
=============================================
[2019-03-24 03:50:59,015] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[75.3021  ]
 [75.20483 ]
 [75.09915 ]
 [74.94364 ]
 [74.913734]], R is [[75.45947266]
 [75.48265076]
 [75.50565338]
 [75.5283432 ]
 [75.54695129]].
[2019-03-24 03:51:00,493] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 03:51:00,495] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:51:00,496] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:51:00,496] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:51:00,498] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:51:00,499] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:51:00,500] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:51:00,500] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:51:00,501] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:51:00,501] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:51:00,502] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:51:00,523] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run59
[2019-03-24 03:51:00,546] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run59
[2019-03-24 03:51:00,547] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run59
[2019-03-24 03:51:00,599] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run59
[2019-03-24 03:51:00,625] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run59
[2019-03-24 03:51:19,151] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03054439], dtype=float32), 0.3565485]
[2019-03-24 03:51:19,152] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.26666666666667, 70.33333333333333, 1.0, 2.0, 0.7118042972891001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 891173.973132316, 891173.9731323156, 181385.7638371169]
[2019-03-24 03:51:19,152] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:51:19,155] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.4608754e-01 1.0349561e-22 1.6593020e-15 9.2036437e-13 5.3912483e-02], sampled 0.7856554019174856
[2019-03-24 03:51:19,156] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 891173.973132316 W.
[2019-03-24 03:51:20,171] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03054439], dtype=float32), 0.3565485]
[2019-03-24 03:51:20,171] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.4522133, 53.98934025333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6087684314542982, 6.911200000000001, 6.9112, 121.9260426156618, 451644.7944578769, 451644.7944578764, 131062.7378799228]
[2019-03-24 03:51:20,172] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:51:20,174] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.8128902e-33 3.9030465e-26 9.1476002e-26 5.2211960e-20], sampled 0.5562813951648402
[2019-03-24 03:51:27,973] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03054439], dtype=float32), 0.3565485]
[2019-03-24 03:51:27,974] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.16666666666667, 82.16666666666667, 1.0, 2.0, 0.2788722227919573, 1.0, 1.0, 0.2788722227919573, 1.0, 1.0, 0.4471307882222705, 6.9112, 6.9112, 121.94756008, 988899.5954810221, 988899.5954810221, 247886.8731331904]
[2019-03-24 03:51:27,975] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 03:51:27,977] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.9410252e-01 7.4336427e-23 1.8181454e-15 1.8257516e-12 7.0589751e-01], sampled 0.21957922417160092
[2019-03-24 03:51:27,977] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 988899.5954810221 W.
[2019-03-24 03:51:34,899] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03054439], dtype=float32), 0.3565485]
[2019-03-24 03:51:34,900] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.99025515, 99.10026297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8384207211875477, 6.9112, 6.9112, 121.9260426156618, 619117.5988611476, 619117.5988611476, 166539.5354762998]
[2019-03-24 03:51:34,900] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:51:34,903] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.5504418e-33 2.7076276e-26 6.8510530e-26 4.7521400e-20], sampled 0.28391115193593475
[2019-03-24 03:52:21,924] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03054439], dtype=float32), 0.3565485]
[2019-03-24 03:52:21,925] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.06666666666667, 75.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9116568357740553, 6.911199999999999, 6.9112, 121.9260426156618, 666595.7834663255, 666595.7834663258, 177620.8278078601]
[2019-03-24 03:52:21,927] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:52:21,929] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.5877993e-30 2.6399719e-22 2.2518963e-20 4.3217620e-11], sampled 0.9027625904248047
[2019-03-24 03:52:40,158] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8508.3980 2289083676.5156 327.0000
[2019-03-24 03:52:40,159] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8596.6631 2245669035.5302 365.0000
[2019-03-24 03:52:40,188] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8438.9017 2319385068.4825 397.0000
[2019-03-24 03:52:40,249] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8424.6375 2361778333.3445 301.0000
[2019-03-24 03:52:40,401] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7942.1741 2564041099.2361 358.0000
[2019-03-24 03:52:41,416] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1450000, evaluation results [1450000.0, 7942.17411412597, 2564041099.2361474, 358.0, 8508.398011417208, 2289083676.5156417, 327.0, 8596.663052991242, 2245669035.530196, 365.0, 8424.637463344125, 2361778333.3444934, 301.0, 8438.901673678463, 2319385068.482493, 397.0]
[2019-03-24 03:52:41,602] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.4652654e-26 1.1780564e-19 7.1070752e-21 2.2725736e-12], sum to 1.0000
[2019-03-24 03:52:41,607] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0806
[2019-03-24 03:52:41,612] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.93333333333333, 43.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5338525306899464, 6.9112, 6.9112, 121.9260426156618, 387655.9611142322, 387655.9611142322, 120034.7311700924], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6646800.0000, 
sim time next is 6647400.0000, 
raw observation next is [24.95, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5265666174376736, 6.9112, 6.9112, 121.9260426156618, 380831.146496664, 380831.146496664, 118852.2770342155], 
processed observation next is [1.0, 0.9565217391304348, 0.47962962962962963, 0.42, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.408208271797092, 0.0, 0.0, 0.8094621288201359, 0.13601112374880855, 0.13601112374880855, 0.2285620712196452], 
reward next is 0.7714, 
noisyNet noise sample is [array([0.6156726], dtype=float32), -1.2293127]. 
=============================================
[2019-03-24 03:52:44,243] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.8201991e-09 7.7208909e-23 4.7610769e-16 3.9195445e-13 1.0000000e+00], sum to 1.0000
[2019-03-24 03:52:44,252] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9200
[2019-03-24 03:52:44,255] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.75, 34.5, 1.0, 2.0, 0.3025738008339212, 1.0, 2.0, 0.3025738008339212, 1.0, 2.0, 0.5026272507736466, 6.9112, 6.9112, 121.94756008, 1126189.315597682, 1126189.315597682, 254829.6222886368], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6695400.0000, 
sim time next is 6696000.0000, 
raw observation next is [27.9, 34.0, 1.0, 2.0, 0.2821166240786655, 1.0, 2.0, 0.2821166240786655, 1.0, 2.0, 0.4689515575788459, 6.911199999999999, 6.9112, 121.94756008, 1050553.608555172, 1050553.608555172, 247052.2669254189], 
processed observation next is [1.0, 0.5217391304347826, 0.5888888888888888, 0.34, 1.0, 1.0, 0.14537693342698274, 1.0, 1.0, 0.14537693342698274, 1.0, 1.0, 0.3361894469735573, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3751977173411329, 0.3751977173411329, 0.47510051331811326], 
reward next is 0.5249, 
noisyNet noise sample is [array([0.68822616], dtype=float32), 0.22760196]. 
=============================================
[2019-03-24 03:52:44,274] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[55.068394]
 [54.748257]
 [54.588654]
 [54.351543]
 [53.789948]], R is [[55.14382553]
 [55.10233307]
 [55.06259155]
 [55.026474  ]
 [54.99448776]].
[2019-03-24 03:52:49,820] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.3403092e-33 1.0857398e-27 1.0823118e-27 4.3555530e-21], sum to 1.0000
[2019-03-24 03:52:49,828] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3072
[2019-03-24 03:52:49,835] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.0, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8596272679086703, 6.9112, 6.9112, 121.9260426156618, 632607.0959418337, 632607.0959418337, 169848.8558312177], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6958800.0000, 
sim time next is 6959400.0000, 
raw observation next is [30.16666666666666, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8630791304127021, 6.911200000000001, 6.9112, 121.9260426156618, 634757.7788137669, 634757.7788137665, 170392.7839648295], 
processed observation next is [0.0, 0.5652173913043478, 0.6728395061728393, 0.515, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8288489130158777, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22669920671920246, 0.22669920671920235, 0.3276784307015952], 
reward next is 0.6723, 
noisyNet noise sample is [array([-0.81509155], dtype=float32), 0.15554735]. 
=============================================
[2019-03-24 03:52:53,778] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 6.5720780e-33 2.4555994e-26 6.1658324e-30 3.5131541e-25], sum to 1.0000
[2019-03-24 03:52:53,786] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7219
[2019-03-24 03:52:53,790] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.45, 69.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.671415163359468, 6.9112, 6.9112, 121.9260426156618, 501373.0894758395, 501373.0894758395, 140355.970336357], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6910200.0000, 
sim time next is 6910800.0000, 
raw observation next is [23.4, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.672866284785294, 6.911200000000001, 6.9112, 121.9260426156618, 502491.7898492599, 502491.7898492594, 140576.7820677835], 
processed observation next is [0.0, 1.0, 0.42222222222222217, 0.7, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5910828559816175, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17946135351759282, 0.17946135351759265, 0.27033996551496825], 
reward next is 0.7297, 
noisyNet noise sample is [array([0.79718626], dtype=float32), 1.1630771]. 
=============================================
[2019-03-24 03:52:54,083] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1239739e-05 7.3474012e-23 9.6232197e-16 1.7368647e-09 9.9998879e-01], sum to 1.0000
[2019-03-24 03:52:54,090] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3261
[2019-03-24 03:52:54,095] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.56666666666667, 74.66666666666667, 1.0, 2.0, 0.3678105673122087, 1.0, 2.0, 0.3678105673122087, 1.0, 2.0, 0.5868291505948215, 6.911200000000001, 6.9112, 121.94756008, 1281691.441163808, 1281691.441163808, 283320.8637477002], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7035600.0000, 
sim time next is 7036200.0000, 
raw observation next is [24.75, 74.0, 1.0, 2.0, 0.3706671269138062, 1.0, 2.0, 0.3706671269138062, 1.0, 2.0, 0.5912572548716041, 6.911200000000001, 6.9112, 121.94756008, 1290154.664434381, 1290154.664434381, 284528.844494831], 
processed observation next is [1.0, 0.43478260869565216, 0.4722222222222222, 0.74, 1.0, 1.0, 0.25079419870691216, 1.0, 1.0, 0.25079419870691216, 1.0, 1.0, 0.48907156858950507, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.46076952301227897, 0.46076952301227897, 0.547170854797752], 
reward next is 0.4528, 
noisyNet noise sample is [array([-0.8323806], dtype=float32), -0.5426839]. 
=============================================
[2019-03-24 03:52:54,913] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 6.5206347e-33 2.7908660e-30 4.8087693e-32 7.1242325e-28], sum to 1.0000
[2019-03-24 03:52:54,920] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4616
[2019-03-24 03:52:54,925] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.6, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7949245175318278, 6.911200000000001, 6.9112, 121.9260426156618, 590847.6961084912, 590847.6961084907, 159491.3889104591], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6886800.0000, 
sim time next is 6887400.0000, 
raw observation next is [28.48333333333333, 53.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.791683931130284, 6.911200000000001, 6.9112, 121.9260426156618, 588635.1604891293, 588635.1604891288, 158984.2174579172], 
processed observation next is [0.0, 0.7391304347826086, 0.6104938271604937, 0.5333333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7396049139128549, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21022684303183187, 0.2102268430318317, 0.30573887972676383], 
reward next is 0.6943, 
noisyNet noise sample is [array([-0.94787014], dtype=float32), -0.292974]. 
=============================================
[2019-03-24 03:53:00,918] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.7723545e-09 9.1339759e-24 1.1446652e-16 4.7075116e-16 1.0000000e+00], sum to 1.0000
[2019-03-24 03:53:00,922] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4811
[2019-03-24 03:53:00,927] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.9, 64.5, 1.0, 2.0, 0.3158621074867349, 1.0, 2.0, 0.3158621074867349, 1.0, 2.0, 0.5033166187002529, 6.911199999999999, 6.9112, 121.94756008, 1091932.941997464, 1091932.941997464, 262228.6109411178], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7043400.0000, 
sim time next is 7044000.0000, 
raw observation next is [27.06666666666667, 63.66666666666666, 1.0, 2.0, 0.3647575370991218, 1.0, 2.0, 0.3647575370991218, 1.0, 2.0, 0.5811101116182155, 6.911200000000001, 6.9112, 121.94756008, 1258921.941055392, 1258921.941055391, 282041.5509693763], 
processed observation next is [1.0, 0.5217391304347826, 0.5580246913580248, 0.6366666666666666, 1.0, 1.0, 0.24375897273704974, 1.0, 1.0, 0.24375897273704974, 1.0, 1.0, 0.4763876395227693, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4496149789483543, 0.44961497894835395, 0.5423875980180313], 
reward next is 0.4576, 
noisyNet noise sample is [array([-1.5670329], dtype=float32), 0.28644064]. 
=============================================
[2019-03-24 03:53:00,952] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[55.85831 ]
 [55.858486]
 [55.801983]
 [55.566647]
 [55.211514]], R is [[55.85718918]
 [55.79433441]
 [55.71910858]
 [55.57927322]
 [55.41149521]].
[2019-03-24 03:53:01,435] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.7280778e-09 1.6043388e-26 2.3087583e-19 2.7254564e-15 1.0000000e+00], sum to 1.0000
[2019-03-24 03:53:01,443] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6767
[2019-03-24 03:53:01,447] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 64.0, 1.0, 2.0, 0.3958016230053306, 1.0, 2.0, 0.3958016230053306, 1.0, 2.0, 0.6301960063166535, 6.9112, 6.9112, 121.94756008, 1356681.157206632, 1356681.157206632, 295267.6864787205], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7052400.0000, 
sim time next is 7053000.0000, 
raw observation next is [26.73333333333333, 65.16666666666667, 1.0, 2.0, 0.4276869218339552, 1.0, 2.0, 0.4276869218339552, 1.0, 2.0, 0.6810385630874644, 6.9112, 6.9112, 121.94756008, 1468582.533829437, 1468582.533829437, 309461.6053368805], 
processed observation next is [1.0, 0.6521739130434783, 0.545679012345679, 0.6516666666666667, 1.0, 1.0, 0.3186749069451847, 1.0, 1.0, 0.3186749069451847, 1.0, 1.0, 0.6012982038593304, 0.0, 0.0, 0.8096049824067558, 0.5244937620819419, 0.5244937620819419, 0.5951184718016932], 
reward next is 0.4049, 
noisyNet noise sample is [array([-0.58271974], dtype=float32), 1.7788713]. 
=============================================
[2019-03-24 03:53:01,478] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[61.004936]
 [60.82052 ]
 [60.67299 ]
 [60.371475]
 [60.115112]], R is [[60.80302048]
 [60.62717056]
 [60.40333176]
 [60.16923904]
 [59.91213989]].
[2019-03-24 03:53:02,695] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.4417744e-10 7.9662744e-25 1.2257847e-18 4.4639102e-15 1.0000000e+00], sum to 1.0000
[2019-03-24 03:53:02,704] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1602
[2019-03-24 03:53:02,713] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.2, 76.0, 1.0, 2.0, 0.3508026655356489, 1.0, 2.0, 0.3508026655356489, 1.0, 2.0, 0.5605362649815867, 6.9112, 6.9112, 121.94756008, 1230594.721478843, 1230594.721478843, 276200.6406257917], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7034400.0000, 
sim time next is 7035000.0000, 
raw observation next is [24.38333333333333, 75.33333333333334, 1.0, 2.0, 0.3807622164999948, 1.0, 2.0, 0.3807622164999948, 1.0, 2.0, 0.607746457427688, 6.911200000000001, 6.9112, 121.94756008, 1329591.764012283, 1329591.764012282, 288810.0758472043], 
processed observation next is [1.0, 0.43478260869565216, 0.4586419753086418, 0.7533333333333334, 1.0, 1.0, 0.26281216249999384, 1.0, 1.0, 0.26281216249999384, 1.0, 1.0, 0.5096830717846099, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4748542014329582, 0.47485420143295787, 0.5554039920138545], 
reward next is 0.4446, 
noisyNet noise sample is [array([0.6672233], dtype=float32), 0.4930174]. 
=============================================
[2019-03-24 03:53:02,737] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[63.502983]
 [63.452343]
 [63.546654]
 [63.252575]
 [63.181065]], R is [[63.24537277]
 [63.08176422]
 [62.95944977]
 [62.83589172]
 [62.69814682]].
[2019-03-24 03:53:03,170] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.5980806e-30 4.6550503e-22 6.8296403e-23 1.0618737e-09], sum to 1.0000
[2019-03-24 03:53:03,177] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5331
[2019-03-24 03:53:03,188] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.16666666666667, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7290412697813319, 6.911199999999999, 6.9112, 121.9260426156618, 543725.5530917026, 543725.5530917031, 145531.1698323735], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7200600.0000, 
sim time next is 7201200.0000, 
raw observation next is [21.33333333333334, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9574204863599898, 6.930972012522068, 6.9112, 121.9259792352794, 724384.9771385507, 714259.9447880886, 172253.414881585], 
processed observation next is [1.0, 0.34782608695652173, 0.3456790123456792, 0.82, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9467756079499873, 0.0019772012522068392, 0.0, 0.8094617080403077, 0.25870892040662524, 0.2550928374243173, 0.33125656707997114], 
reward next is 0.5699, 
noisyNet noise sample is [array([0.10462352], dtype=float32), 0.5908082]. 
=============================================
[2019-03-24 03:53:06,430] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.6537483e-22 2.3792333e-17 7.2140864e-16 5.7609050e-08], sum to 1.0000
[2019-03-24 03:53:06,436] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6741
[2019-03-24 03:53:06,442] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 868530.9025365709 W.
[2019-03-24 03:53:06,445] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.05, 65.66666666666666, 1.0, 2.0, 0.6966934225281385, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 868530.9025365709, 868530.9025365709, 178359.8975955982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7145400.0000, 
sim time next is 7146000.0000, 
raw observation next is [23.0, 66.0, 1.0, 2.0, 0.7452523246506698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 931975.3715948617, 931975.3715948613, 188042.5613068669], 
processed observation next is [1.0, 0.7391304347826086, 0.4074074074074074, 0.66, 1.0, 1.0, 0.696728957917464, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3328483469981649, 0.33284834699816473, 0.3616203102055133], 
reward next is 0.6384, 
noisyNet noise sample is [array([0.3542178], dtype=float32), 0.8137286]. 
=============================================
[2019-03-24 03:53:06,458] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[58.30177 ]
 [58.26862 ]
 [57.61071 ]
 [57.18346 ]
 [56.891056]], R is [[58.40554428]
 [58.47849274]
 [57.89370728]
 [57.31476974]
 [56.74162292]].
[2019-03-24 03:53:10,798] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.0388417e-30 1.5309408e-26 2.0883944e-25 2.1851682e-22], sum to 1.0000
[2019-03-24 03:53:10,806] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5899
[2019-03-24 03:53:10,816] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.41666666666667, 71.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7876004973839904, 6.911200000000001, 6.9112, 121.9260426156618, 588459.4273215273, 588459.4273215268, 153882.0956949716], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7217400.0000, 
sim time next is 7218000.0000, 
raw observation next is [23.5, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8056431768094063, 6.911199999999999, 6.9112, 121.9260426156618, 601970.9034722741, 601970.9034722745, 156090.8222095194], 
processed observation next is [1.0, 0.5652173913043478, 0.42592592592592593, 0.71, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.757053971011758, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21498960838295503, 0.2149896083829552, 0.3001746580952296], 
reward next is 0.6998, 
noisyNet noise sample is [array([1.5820343], dtype=float32), 2.03576]. 
=============================================
[2019-03-24 03:53:10,832] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[65.81004]
 [65.63047]
 [65.69969]
 [64.97037]
 [64.89005]], R is [[66.2461853 ]
 [66.28779602]
 [66.33049011]
 [66.37119293]
 [66.35427094]].
[2019-03-24 03:53:12,430] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 8.1972454e-37 1.4691324e-34 7.8855499e-32], sum to 1.0000
[2019-03-24 03:53:12,441] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5354
[2019-03-24 03:53:12,445] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.4, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6298336820069425, 6.9112, 6.9112, 121.9260426156618, 469078.1328911004, 469078.1328911004, 134509.3550774937], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7250400.0000, 
sim time next is 7251000.0000, 
raw observation next is [21.31666666666667, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6268120614414653, 6.9112, 6.9112, 121.9260426156618, 466707.0884256142, 466707.0884256142, 134098.4709168143], 
processed observation next is [1.0, 0.9565217391304348, 0.34506172839506183, 0.7933333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5335150768018315, 0.0, 0.0, 0.8094621288201359, 0.16668110300914793, 0.16668110300914793, 0.2578816748400275], 
reward next is 0.7421, 
noisyNet noise sample is [array([0.01123519], dtype=float32), -0.36528036]. 
=============================================
[2019-03-24 03:53:12,474] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[85.62361 ]
 [85.418106]
 [85.33746 ]
 [85.27602 ]
 [85.28953 ]], R is [[85.63137054]
 [85.51638031]
 [85.40148926]
 [85.28681183]
 [85.17281342]].
[2019-03-24 03:53:13,055] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.2062148e-27 2.4750810e-22 4.9590053e-20 5.5385189e-15], sum to 1.0000
[2019-03-24 03:53:13,067] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3813
[2019-03-24 03:53:13,077] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 895639.2739472945 W.
[2019-03-24 03:53:13,079] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.5, 95.0, 1.0, 2.0, 0.3640604068105375, 1.0, 1.0, 0.3640604068105375, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 895639.2739472945, 895639.2739472949, 199098.1028706568], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7380000.0000, 
sim time next is 7380600.0000, 
raw observation next is [19.53333333333333, 95.0, 1.0, 2.0, 0.364647022490476, 1.0, 2.0, 0.364647022490476, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 895245.7741287709, 895245.7741287709, 199206.2714916992], 
processed observation next is [1.0, 0.43478260869565216, 0.2790123456790123, 0.95, 1.0, 1.0, 0.24362740772675712, 1.0, 1.0, 0.24362740772675712, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31973063361741816, 0.31973063361741816, 0.3830889836378831], 
reward next is 0.6169, 
noisyNet noise sample is [array([0.28569734], dtype=float32), -2.6142814]. 
=============================================
[2019-03-24 03:53:13,621] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.0107186e-31 4.5691305e-27 5.4893350e-25 1.2999781e-24], sum to 1.0000
[2019-03-24 03:53:13,628] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7564
[2019-03-24 03:53:13,632] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.55, 85.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6741339899501576, 6.9112, 6.9112, 121.9260426156618, 502023.6804105819, 502023.6804105819, 138919.3946171128], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7266600.0000, 
sim time next is 7267200.0000, 
raw observation next is [20.53333333333333, 85.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6660975527530208, 6.9112, 6.9112, 121.9260426156618, 496046.3072005826, 496046.3072005826, 138105.7454720921], 
processed observation next is [1.0, 0.08695652173913043, 0.3160493827160493, 0.8566666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5826219409412761, 0.0, 0.0, 0.8094621288201359, 0.17715939542877948, 0.17715939542877948, 0.2655879720617156], 
reward next is 0.7344, 
noisyNet noise sample is [array([0.10575052], dtype=float32), 1.2532297]. 
=============================================
[2019-03-24 03:53:18,693] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.9719653e-27 8.6682482e-25 3.2916633e-26 1.6560019e-22], sum to 1.0000
[2019-03-24 03:53:18,700] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3043
[2019-03-24 03:53:18,716] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.36666666666667, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6380039828107333, 6.911199999999999, 6.9112, 121.9260426156618, 475338.084300661, 475338.0843006615, 135489.1574444173], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7364400.0000, 
sim time next is 7365000.0000, 
raw observation next is [19.33333333333334, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6407842601845046, 6.911200000000001, 6.9112, 121.9260426156618, 477318.6169445714, 477318.6169445709, 135676.4026912526], 
processed observation next is [1.0, 0.21739130434782608, 0.27160493827160515, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5509803252306308, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1704709346230612, 0.17047093462306104, 0.2609161590216396], 
reward next is 0.7391, 
noisyNet noise sample is [array([0.4103143], dtype=float32), 0.7532239]. 
=============================================
[2019-03-24 03:53:18,733] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[60.64576 ]
 [60.79584 ]
 [60.884987]
 [60.902164]
 [61.005688]], R is [[60.63795471]
 [60.77101898]
 [60.90346527]
 [61.03409958]
 [61.15694427]].
[2019-03-24 03:53:20,510] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 6.0257969e-25 1.3058007e-20 1.3055796e-23 3.5274683e-18], sum to 1.0000
[2019-03-24 03:53:20,516] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8060
[2019-03-24 03:53:20,524] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1073943.07863134 W.
[2019-03-24 03:53:20,534] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.25, 90.5, 1.0, 2.0, 0.4474962637106614, 1.0, 2.0, 0.4474962637106614, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1073943.07863134, 1073943.07863134, 221903.298946416], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7399800.0000, 
sim time next is 7400400.0000, 
raw observation next is [21.23333333333333, 90.33333333333334, 1.0, 2.0, 0.9120877428018251, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.988663567334197, 6.9112, 121.9256861424923, 1150782.894683823, 1111114.740571101, 223481.5584547583], 
processed observation next is [1.0, 0.6521739130434783, 0.34197530864197523, 0.9033333333333334, 1.0, 1.0, 0.8953425509545537, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.007746356733419724, 0.0, 0.8094597622089964, 0.4109938909585082, 0.39682669306110746, 0.42977222779761215], 
reward next is 0.1829, 
noisyNet noise sample is [array([0.26278344], dtype=float32), 0.017180923]. 
=============================================
[2019-03-24 03:53:20,622] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.0701011e-22 4.8949369e-19 5.6254717e-18 3.7504810e-15], sum to 1.0000
[2019-03-24 03:53:20,631] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0470
[2019-03-24 03:53:20,638] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1039240.476183583 W.
[2019-03-24 03:53:20,644] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.05, 92.5, 1.0, 2.0, 0.4325629325672579, 1.0, 2.0, 0.4325629325672579, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1039240.476183583, 1039240.476183583, 217558.9432939722], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7392600.0000, 
sim time next is 7393200.0000, 
raw observation next is [21.13333333333333, 92.33333333333333, 1.0, 2.0, 0.292370691797561, 1.0, 2.0, 0.292370691797561, 1.0, 1.0, 0.4704797454852561, 6.911200000000001, 6.9112, 121.94756008, 1045771.532474916, 1045771.532474916, 252764.752427958], 
processed observation next is [1.0, 0.5652173913043478, 0.33827160493827146, 0.9233333333333333, 1.0, 1.0, 0.1575841569018583, 1.0, 1.0, 0.1575841569018583, 1.0, 0.5, 0.33809968185657013, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3734898330267557, 0.3734898330267557, 0.48608606236145774], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0956703], dtype=float32), 0.32090187]. 
=============================================
[2019-03-24 03:53:20,876] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 6.5917205e-23 4.2823604e-18 5.2297725e-18 6.1269811e-15], sum to 1.0000
[2019-03-24 03:53:20,883] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3237
[2019-03-24 03:53:20,890] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 927923.5188498716 W.
[2019-03-24 03:53:20,896] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [20.2, 94.0, 1.0, 2.0, 0.3803152490535743, 1.0, 1.0, 0.3803152490535743, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 927923.5188498716, 927923.518849872, 203294.2198626958], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7387200.0000, 
sim time next is 7387800.0000, 
raw observation next is [20.3, 93.83333333333334, 1.0, 2.0, 0.2798625636752253, 1.0, 2.0, 0.2798625636752253, 1.0, 1.0, 0.4535641898648098, 6.9112, 6.9112, 121.94756008, 1013765.559442778, 1013765.559442778, 247672.9850005144], 
processed observation next is [1.0, 0.5217391304347826, 0.3074074074074074, 0.9383333333333335, 1.0, 1.0, 0.142693528184792, 1.0, 1.0, 0.142693528184792, 1.0, 0.5, 0.3169552373310122, 0.0, 0.0, 0.8096049824067558, 0.3620591283724207, 0.3620591283724207, 0.47629420192406613], 
reward next is 0.5237, 
noisyNet noise sample is [array([-1.3898661], dtype=float32), 0.17298035]. 
=============================================
[2019-03-24 03:53:21,223] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 8.3276948e-38 1.7549364e-35 3.5617691e-35 4.0141872e-31], sum to 1.0000
[2019-03-24 03:53:21,229] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6988
[2019-03-24 03:53:21,234] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7112867496182608, 6.911200000000001, 6.9112, 121.9260426156618, 531227.4441082298, 531227.4441082294, 147267.3788165992], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7533600.0000, 
sim time next is 7534200.0000, 
raw observation next is [20.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7109167920392201, 6.9112, 6.9112, 121.9260426156618, 530951.0567205758, 530951.0567205758, 147225.7970273613], 
processed observation next is [0.0, 0.17391304347826086, 0.32962962962962955, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6386459900490251, 0.0, 0.0, 0.8094621288201359, 0.18962537740020563, 0.18962537740020563, 0.28312653274492555], 
reward next is 0.7169, 
noisyNet noise sample is [array([-0.9432803], dtype=float32), 1.8057654]. 
=============================================
[2019-03-24 03:53:22,881] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 4.8940571e-35 2.6692207e-34 1.1900002e-31], sum to 1.0000
[2019-03-24 03:53:22,890] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3435
[2019-03-24 03:53:22,894] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.3, 95.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6206951905942617, 6.911200000000001, 6.9112, 121.9260426156618, 462014.0378903494, 462014.0378903489, 133373.5922479874], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7443600.0000, 
sim time next is 7444200.0000, 
raw observation next is [19.25, 95.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.617569597837151, 6.9112, 6.9112, 121.9260426156618, 459649.9860126651, 459649.9860126651, 133036.0019716331], 
processed observation next is [0.0, 0.13043478260869565, 0.26851851851851855, 0.9566666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5219619972964388, 0.0, 0.0, 0.8094621288201359, 0.16416070929023754, 0.16416070929023754, 0.2558384653300636], 
reward next is 0.7442, 
noisyNet noise sample is [array([0.514438], dtype=float32), 0.5534811]. 
=============================================
[2019-03-24 03:53:23,690] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.5758405e-35], sum to 1.0000
[2019-03-24 03:53:23,697] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2136
[2019-03-24 03:53:23,702] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.7, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6807290299942506, 6.911200000000001, 6.9112, 121.9260426156618, 508452.9380729154, 508452.938072915, 141595.4379763264], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7410000.0000, 
sim time next is 7410600.0000, 
raw observation next is [20.65, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6780644309556187, 6.9112, 6.9112, 121.9260426156618, 506402.0382317566, 506402.0382317566, 141180.332442081], 
processed observation next is [1.0, 0.782608695652174, 0.3203703703703703, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5975805386945234, 0.0, 0.0, 0.8094621288201359, 0.18085787079705593, 0.18085787079705593, 0.27150063931169427], 
reward next is 0.7285, 
noisyNet noise sample is [array([-0.7758668], dtype=float32), -0.08413916]. 
=============================================
[2019-03-24 03:53:29,150] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 7.5205087e-33 2.2103218e-27 8.9184221e-28 2.2822417e-28], sum to 1.0000
[2019-03-24 03:53:29,159] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0038
[2019-03-24 03:53:29,164] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.46666666666667, 76.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8534148086268817, 6.9112, 6.9112, 121.9260426156618, 628185.7329483355, 628185.7329483355, 169013.9716161751], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7558800.0000, 
sim time next is 7559400.0000, 
raw observation next is [25.73333333333333, 75.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8570783109860945, 6.9112, 6.9112, 121.9260426156618, 630402.6490595455, 630402.6490595455, 169607.1758235095], 
processed observation next is [0.0, 0.4782608695652174, 0.5086419753086419, 0.7533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8213478887326181, 0.0, 0.0, 0.8094621288201359, 0.22514380323555197, 0.22514380323555197, 0.3261676458144413], 
reward next is 0.6738, 
noisyNet noise sample is [array([-0.22401378], dtype=float32), -0.29806504]. 
=============================================
[2019-03-24 03:53:29,810] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 5.6252088e-35 9.4869398e-30 1.4494217e-33 8.3530817e-31], sum to 1.0000
[2019-03-24 03:53:29,822] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0404
[2019-03-24 03:53:29,827] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.16666666666666, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8448177481290675, 6.911200000000001, 6.9112, 121.9260426156618, 622480.4378144743, 622480.4378144739, 167750.0592543077], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7567800.0000, 
sim time next is 7568400.0000, 
raw observation next is [27.33333333333334, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8524385235040911, 6.911200000000001, 6.9112, 121.9260426156618, 626950.3815509266, 626950.3815509261, 169023.6220428844], 
processed observation next is [0.0, 0.6086956521739131, 0.5679012345679014, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8155481543801137, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22391085055390236, 0.2239108505539022, 0.32504542700554695], 
reward next is 0.6750, 
noisyNet noise sample is [array([1.0691346], dtype=float32), 1.7922118]. 
=============================================
[2019-03-24 03:53:32,407] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.0331112e-37 9.5119340e-32 1.0822471e-32 1.6022873e-29], sum to 1.0000
[2019-03-24 03:53:32,414] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3339
[2019-03-24 03:53:32,421] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.55, 85.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.688689812487987, 6.9112, 6.9112, 121.9260426156618, 514631.1242548826, 514631.1242548826, 143272.311105622], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7608600.0000, 
sim time next is 7609200.0000, 
raw observation next is [21.43333333333333, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.681692874629367, 6.9112, 6.9112, 121.9260426156618, 509334.0629447504, 509334.0629447504, 142165.7678985657], 
processed observation next is [1.0, 0.043478260869565216, 0.3493827160493826, 0.8533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6021160932867087, 0.0, 0.0, 0.8094621288201359, 0.18190502248026802, 0.18190502248026802, 0.27339570749724174], 
reward next is 0.7266, 
noisyNet noise sample is [array([-0.02195806], dtype=float32), -0.018007258]. 
=============================================
[2019-03-24 03:53:32,732] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 03:53:32,733] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:53:32,734] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:53:32,734] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:53:32,734] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:53:32,735] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:53:32,736] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:53:32,736] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:53:32,737] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:53:32,736] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:53:32,737] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:53:32,761] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run60
[2019-03-24 03:53:32,785] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run60
[2019-03-24 03:53:32,786] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run60
[2019-03-24 03:53:32,832] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run60
[2019-03-24 03:53:32,857] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run60
[2019-03-24 03:53:49,919] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05089421], dtype=float32), 0.3661897]
[2019-03-24 03:53:49,921] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.76321328, 58.36714552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4870684804242597, 6.911200000000001, 6.9112, 121.9260426156618, 349922.8751067811, 349922.8751067806, 114885.0772376113]
[2019-03-24 03:53:49,922] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:53:49,924] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.00000000e+00 5.95267642e-36 3.15811180e-31 1.39927615e-33
 2.61564232e-30], sampled 0.43546639441821977
[2019-03-24 03:54:08,966] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05089421], dtype=float32), 0.3661897]
[2019-03-24 03:54:08,967] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.01661769166666, 36.74814936833333, 1.0, 2.0, 0.646545422522345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 799602.2916144229, 799602.2916144225, 168718.7384032798]
[2019-03-24 03:54:08,968] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:54:08,971] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.5494523e-28 2.6812357e-24 5.9008423e-26 3.9232192e-23], sampled 0.9457620729650914
[2019-03-24 03:54:08,972] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 799602.2916144229 W.
[2019-03-24 03:54:48,066] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05089421], dtype=float32), 0.3661897]
[2019-03-24 03:54:48,067] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.43287542666667, 44.42275871666667, 1.0, 2.0, 0.5099453779419801, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8214935501047245, 6.911199999999999, 6.9112, 121.9260426156618, 1218856.182439798, 1218856.182439798, 258969.7200358467]
[2019-03-24 03:54:48,068] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:54:48,072] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.6965453e-34 2.2849149e-29 2.0664525e-31 5.3797044e-28], sampled 0.456412371098295
[2019-03-24 03:54:48,072] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1218856.182439798 W.
[2019-03-24 03:55:11,719] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 03:55:11,807] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 03:55:11,929] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 03:55:12,170] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05089421], dtype=float32), 0.3661897]
[2019-03-24 03:55:12,171] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.88297681, 90.79514045500001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7178534894960947, 6.9112, 6.9112, 121.9260426156618, 535497.9741754394, 535497.9741754394, 148858.6442955899]
[2019-03-24 03:55:12,171] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 03:55:12,172] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.3769928e-34 1.0449935e-29 6.1448814e-32 7.8782554e-29], sampled 0.9909374072702869
[2019-03-24 03:55:12,286] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 03:55:12,435] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 03:55:13,451] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1475000, evaluation results [1475000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 03:55:20,521] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.9776091e-23 2.0527629e-19 3.4380275e-22 2.4211473e-18], sum to 1.0000
[2019-03-24 03:55:20,526] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6610
[2019-03-24 03:55:20,535] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1541654.768143291 W.
[2019-03-24 03:55:20,539] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.1, 51.0, 1.0, 2.0, 0.4467300712234891, 1.0, 2.0, 0.4467300712234891, 1.0, 2.0, 0.7116797724648314, 6.911200000000001, 6.9112, 121.94756008, 1541654.768143291, 1541654.768143291, 318238.515090186], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7749000.0000, 
sim time next is 7749600.0000, 
raw observation next is [29.06666666666667, 51.33333333333333, 1.0, 2.0, 0.4201065141482924, 1.0, 2.0, 0.4201065141482924, 1.0, 2.0, 0.6692983935189081, 6.911199999999999, 6.9112, 121.94756008, 1450317.968450327, 1450317.968450327, 306075.5092732644], 
processed observation next is [1.0, 0.6956521739130435, 0.6320987654320989, 0.5133333333333333, 1.0, 1.0, 0.3096506120813005, 1.0, 1.0, 0.3096506120813005, 1.0, 1.0, 0.5866229918986351, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5179707030179739, 0.5179707030179739, 0.5886067486024315], 
reward next is 0.4114, 
noisyNet noise sample is [array([1.2900103], dtype=float32), -1.0483754]. 
=============================================
[2019-03-24 03:55:26,042] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:55:26,042] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:55:26,096] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run8
[2019-03-24 03:55:27,040] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 3.0357093e-26 4.0885544e-23 4.1272935e-22 4.5004005e-21], sum to 1.0000
[2019-03-24 03:55:27,046] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0236
[2019-03-24 03:55:27,050] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.76666666666667, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7190295135452274, 6.911200000000001, 6.9112, 121.9260426156386, 537135.1743089128, 537135.1743089124, 145889.6707467165], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7872000.0000, 
sim time next is 7872600.0000, 
raw observation next is [21.63333333333333, 82.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7036622193370452, 6.911199999999999, 6.9112, 121.9260426156618, 525574.1766121723, 525574.1766121726, 144021.9550630186], 
processed observation next is [1.0, 0.08695652173913043, 0.35679012345678995, 0.825, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6295777741713066, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1877050630757758, 0.18770506307577595, 0.27696529819811266], 
reward next is 0.7230, 
noisyNet noise sample is [array([-0.73520476], dtype=float32), -1.3829126]. 
=============================================
[2019-03-24 03:55:31,907] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:55:31,908] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:55:31,914] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run8
[2019-03-24 03:55:31,988] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:55:31,989] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:55:31,996] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run8
[2019-03-24 03:55:32,017] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:55:32,019] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:55:32,026] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run8
[2019-03-24 03:55:32,042] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:55:32,043] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:55:32,046] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:55:32,047] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:55:32,057] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run8
[2019-03-24 03:55:32,059] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run8
[2019-03-24 03:55:32,098] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:55:32,099] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:55:32,104] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run8
[2019-03-24 03:55:32,134] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:55:32,135] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:55:32,136] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:55:32,138] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:55:32,141] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:55:32,141] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:55:32,148] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run8
[2019-03-24 03:55:32,171] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run8
[2019-03-24 03:55:32,203] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run8
[2019-03-24 03:55:32,311] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:55:32,312] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:55:32,315] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run8
[2019-03-24 03:55:32,344] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:55:32,345] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:55:32,350] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run8
[2019-03-24 03:55:32,385] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:55:32,386] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:55:32,390] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run8
[2019-03-24 03:55:32,593] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:55:32,593] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:55:32,596] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run8
[2019-03-24 03:55:32,677] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:55:32,677] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:55:32,697] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 03:55:32,697] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:55:32,700] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run8
[2019-03-24 03:55:32,681] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run8
[2019-03-24 03:55:36,962] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.9898854e-25 1.3235986e-21 6.9328689e-26 8.0995853e-21], sum to 1.0000
[2019-03-24 03:55:36,971] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3254
[2019-03-24 03:55:36,979] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1485988.094151828 W.
[2019-03-24 03:55:36,985] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 37.0, 1.0, 2.0, 0.6359918117635349, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9576281466188471, 6.911199999999999, 6.9112, 121.9260426156618, 1485988.094151828, 1485988.094151828, 295105.7103355893], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 54000.0000, 
sim time next is 54600.0000, 
raw observation next is [29.98333333333333, 37.16666666666667, 1.0, 2.0, 0.5303066470481697, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8643910337276735, 6.911199999999999, 6.9112, 121.9260426156618, 1291107.10683459, 1291107.10683459, 265054.6083516181], 
processed observation next is [1.0, 0.6521739130434783, 0.6660493827160493, 0.3716666666666667, 1.0, 1.0, 0.4408412464859162, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8304887921595918, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.46110968101235356, 0.46110968101235356, 0.5097204006761886], 
reward next is 0.4903, 
noisyNet noise sample is [array([-0.74226105], dtype=float32), -0.73130167]. 
=============================================
[2019-03-24 03:55:37,383] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.4150701e-38 9.5362347e-33 3.7543223e-35 3.6912575e-34], sum to 1.0000
[2019-03-24 03:55:37,392] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3085
[2019-03-24 03:55:37,398] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.5, 40.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6323375994272868, 6.9112, 6.9112, 121.9260426156618, 472510.084085794, 472510.084085794, 137343.1982600304], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 62400.0000, 
sim time next is 63000.0000, 
raw observation next is [29.4, 40.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6289956922847961, 6.9112, 6.9112, 121.9260426156618, 469884.1350781145, 469884.1350781145, 136443.1935904121], 
processed observation next is [1.0, 0.7391304347826086, 0.6444444444444444, 0.405, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5362446153559951, 0.0, 0.0, 0.8094621288201359, 0.16781576252789804, 0.16781576252789804, 0.26239075690463864], 
reward next is 0.7376, 
noisyNet noise sample is [array([-0.7160854], dtype=float32), 0.86569273]. 
=============================================
[2019-03-24 03:55:37,415] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[73.25633]
 [69.94014]
 [68.11443]
 [67.90753]
 [67.58945]], R is [[73.79395294]
 [73.79189301]
 [73.05397797]
 [72.84527588]
 [72.11682129]].
[2019-03-24 03:55:37,755] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 5.6643803e-34 1.3914012e-29 2.6151808e-32 1.5207814e-29], sum to 1.0000
[2019-03-24 03:55:37,765] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7423
[2019-03-24 03:55:37,772] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.3, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.693741126045107, 6.911200000000001, 6.9112, 121.9260426156618, 518417.6413683541, 518417.6413683537, 143925.6548014273], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 77400.0000, 
sim time next is 78000.0000, 
raw observation next is [26.13333333333333, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6935995330052935, 6.911200000000001, 6.9112, 121.9260426156618, 518315.7892717841, 518315.7892717836, 143969.896134311], 
processed observation next is [1.0, 0.9130434782608695, 0.5234567901234567, 0.57, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6169994162566169, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18511278188278002, 0.18511278188277985, 0.276865184873675], 
reward next is 0.7231, 
noisyNet noise sample is [array([-0.1675008], dtype=float32), 0.50466555]. 
=============================================
[2019-03-24 03:55:37,806] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[68.327934]
 [68.43194 ]
 [68.70037 ]
 [68.50237 ]
 [68.39444 ]], R is [[68.48569489]
 [68.52406311]
 [68.56243134]
 [68.60145569]
 [68.64108276]].
[2019-03-24 03:55:40,439] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.3557372e-28 9.7062416e-24 1.1957282e-25 1.4395053e-23], sum to 1.0000
[2019-03-24 03:55:40,445] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2141
[2019-03-24 03:55:40,450] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.5, 73.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6881839992793007, 6.9112, 6.9112, 121.9260426156618, 513295.1017620845, 513295.1017620845, 141225.4192745326], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 112800.0000, 
sim time next is 113400.0000, 
raw observation next is [22.6, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6946790536821178, 6.911199999999999, 6.9112, 121.9260426156618, 518298.9091919371, 518298.9091919376, 142111.9704732226], 
processed observation next is [1.0, 0.30434782608695654, 0.39259259259259266, 0.735, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6183488171026472, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18510675328283469, 0.18510675328283485, 0.2732922509100435], 
reward next is 0.7267, 
noisyNet noise sample is [array([-0.5249577], dtype=float32), -0.6475807]. 
=============================================
[2019-03-24 03:55:40,960] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.1964602e-31 3.2190432e-27 1.3340273e-26 2.3402831e-25], sum to 1.0000
[2019-03-24 03:55:40,965] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9155
[2019-03-24 03:55:40,969] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.06666666666667, 66.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4500100664745044, 6.9112, 6.9112, 121.9260426156618, 321304.0685284725, 321304.0685284725, 95458.41872056002], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 362400.0000, 
sim time next is 363000.0000, 
raw observation next is [17.88333333333333, 67.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4384892950037876, 6.9112, 6.9112, 121.9260426156618, 313076.6386555835, 313076.6386555835, 94000.22842082875], 
processed observation next is [1.0, 0.17391304347826086, 0.2179012345679011, 0.6716666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.29811161875473446, 0.0, 0.0, 0.8094621288201359, 0.11181308523413697, 0.11181308523413697, 0.18076967004005529], 
reward next is 0.8192, 
noisyNet noise sample is [array([0.7743955], dtype=float32), -0.70221466]. 
=============================================
[2019-03-24 03:55:40,989] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[63.4308  ]
 [63.64495 ]
 [63.962383]
 [64.23663 ]
 [64.40872 ]], R is [[63.45536041]
 [63.63723373]
 [63.81361389]
 [63.98499298]
 [64.14927673]].
[2019-03-24 03:55:46,449] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.1355587e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 03:55:46,458] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4572
[2019-03-24 03:55:46,469] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.4, 18.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6613369155369804, 6.9112, 6.9112, 121.9260426156618, 478719.6717015516, 478719.6717015516, 130537.5531984048], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 237600.0000, 
sim time next is 238200.0000, 
raw observation next is [32.16666666666666, 18.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6614193556312689, 6.911200000000001, 6.9112, 121.9260426156618, 478964.5097568677, 478964.5097568673, 130613.6138145524], 
processed observation next is [0.0, 0.782608695652174, 0.7469135802469132, 0.1866666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5767741945390861, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17105875348459562, 0.17105875348459545, 0.25118002656644695], 
reward next is 0.7488, 
noisyNet noise sample is [array([-0.62259066], dtype=float32), -0.9152685]. 
=============================================
[2019-03-24 03:55:55,870] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 5.0519478e-30 2.4533628e-25 2.5599220e-28 3.7912113e-26], sum to 1.0000
[2019-03-24 03:55:55,876] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6179
[2019-03-24 03:55:55,880] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.65, 27.33333333333333, 1.0, 2.0, 0.1727487956477849, 1.0, 1.0, 0.1727487956477849, 1.0, 2.0, 0.2864629209586809, 6.911200000000001, 6.9112, 121.94756008, 641838.8885143178, 641838.8885143173, 209822.0176178709], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 407400.0000, 
sim time next is 408000.0000, 
raw observation next is [30.5, 27.66666666666667, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6207044017497122, 6.911200000000001, 6.9112, 121.9260426156289, 460343.8305205895, 460343.830520589, 132093.7579816978], 
processed observation next is [1.0, 0.7391304347826086, 0.6851851851851852, 0.2766666666666667, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.5258805021871402, 8.881784197001253e-17, 0.0, 0.8094621288199175, 0.16440851090021052, 0.16440851090021036, 0.2540264576571111], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.65682256], dtype=float32), -0.52353233]. 
=============================================
[2019-03-24 03:55:55,903] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[58.092087]
 [56.69255 ]
 [56.58911 ]
 [56.052338]
 [55.692223]], R is [[60.69686127]
 [60.68638992]
 [60.07952499]
 [59.47872925]
 [59.38516235]].
[2019-03-24 03:55:57,626] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 5.4372433e-29 8.9782399e-25 2.0125419e-29 2.8672870e-25], sum to 1.0000
[2019-03-24 03:55:57,634] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7635
[2019-03-24 03:55:57,638] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.45, 65.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8446434041949201, 6.911200000000001, 6.9112, 121.9260426156618, 607661.9530161567, 607661.9530161562, 147217.3523962665], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 439800.0000, 
sim time next is 440400.0000, 
raw observation next is [20.3, 66.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6771201101691172, 6.9112, 6.9112, 121.9260426156618, 486698.5514011913, 486698.5514011913, 130763.5688362177], 
processed observation next is [1.0, 0.08695652173913043, 0.3074074074074074, 0.6633333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5964001377113964, 0.0, 0.0, 0.8094621288201359, 0.17382091121471116, 0.17382091121471116, 0.25146840160811096], 
reward next is 0.7485, 
noisyNet noise sample is [array([-1.0247121], dtype=float32), -0.44757265]. 
=============================================
[2019-03-24 03:55:59,239] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.2634991e-26 2.1613326e-23 1.7619090e-24 9.6942154e-24], sum to 1.0000
[2019-03-24 03:55:59,248] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8626
[2019-03-24 03:55:59,256] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.1, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4683543106024143, 6.911200000000001, 6.9112, 121.9260426156618, 334404.5871047127, 334404.5871047123, 111326.6574379937], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 452400.0000, 
sim time next is 453000.0000, 
raw observation next is [19.4, 70.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4719407112448993, 6.9112, 6.9112, 121.9260426156618, 336965.8367064336, 336965.8367064336, 112821.7864266661], 
processed observation next is [1.0, 0.21739130434782608, 0.274074074074074, 0.705, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3399258890561241, 0.0, 0.0, 0.8094621288201359, 0.12034494168086915, 0.12034494168086915, 0.21696497389743483], 
reward next is 0.7830, 
noisyNet noise sample is [array([0.17519066], dtype=float32), 1.0351968]. 
=============================================
[2019-03-24 03:55:59,275] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[55.329227]
 [55.55557 ]
 [55.78953 ]
 [55.966217]
 [56.039143]], R is [[55.2959938 ]
 [55.52894592]
 [55.76231003]
 [55.99585724]
 [56.22797775]].
[2019-03-24 03:56:04,141] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.5680752e-31 7.8918976e-25 1.5755354e-27 2.2094676e-22], sum to 1.0000
[2019-03-24 03:56:04,146] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8989
[2019-03-24 03:56:04,154] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1325329.977698648 W.
[2019-03-24 03:56:04,161] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.7, 38.5, 1.0, 2.0, 0.5476388417343392, 1.0, 1.0, 0.5476388417343392, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1325329.977698648, 1325329.977698649, 253716.7500334017], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 552600.0000, 
sim time next is 553200.0000, 
raw observation next is [29.4, 39.66666666666667, 1.0, 2.0, 0.4908841049653286, 1.0, 2.0, 0.4908841049653286, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1188462.089124227, 1188462.089124227, 235441.4099481487], 
processed observation next is [1.0, 0.391304347826087, 0.6444444444444444, 0.3966666666666667, 1.0, 1.0, 0.39390964876824835, 1.0, 1.0, 0.39390964876824835, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.42445074611579536, 0.42445074611579536, 0.4527719422079783], 
reward next is 0.5472, 
noisyNet noise sample is [array([1.7120944], dtype=float32), 0.6571434]. 
=============================================
[2019-03-24 03:56:04,298] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.1857251e-27 2.2297597e-25 5.4186490e-29 1.0035652e-23], sum to 1.0000
[2019-03-24 03:56:04,313] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0384
[2019-03-24 03:56:04,320] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1065449.897761741 W.
[2019-03-24 03:56:04,331] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.8, 39.0, 1.0, 2.0, 0.4394259373169237, 1.0, 1.0, 0.4394259373169237, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9259307831912, 1065449.897761741, 1065449.89776174, 219889.9044493019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 565200.0000, 
sim time next is 565800.0000, 
raw observation next is [29.93333333333334, 38.33333333333334, 1.0, 2.0, 0.9092347995434947, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.010278920310692, 6.9112, 121.9256394662494, 1165862.423805605, 1115125.328796277, 223070.6896916884], 
processed observation next is [1.0, 0.5652173913043478, 0.6641975308641977, 0.3833333333333334, 1.0, 1.0, 0.8919461899327318, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.00990789203106921, 0.0, 0.8094594523272834, 0.41637943707343034, 0.3982590459986704, 0.42898209556093925], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.08274589], dtype=float32), 0.84976995]. 
=============================================
[2019-03-24 03:56:05,658] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.0795399e-35 7.6249477e-30 1.4428178e-34 1.0399000e-28], sum to 1.0000
[2019-03-24 03:56:05,667] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4576
[2019-03-24 03:56:05,676] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.73333333333333, 34.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6460729945008531, 6.911200000000001, 6.9112, 121.9260426156618, 482216.2654563689, 482216.2654563684, 137339.845954871], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 585600.0000, 
sim time next is 586200.0000, 
raw observation next is [30.56666666666666, 34.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6452480042218726, 6.9112, 6.9112, 121.9260426156618, 481574.8600070209, 481574.8600070209, 137217.2378475475], 
processed observation next is [1.0, 0.782608695652174, 0.687654320987654, 0.345, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5565600052773406, 0.0, 0.0, 0.8094621288201359, 0.1719910214310789, 0.1719910214310789, 0.263879303552976], 
reward next is 0.7361, 
noisyNet noise sample is [array([-1.2091364], dtype=float32), -0.2961571]. 
=============================================
[2019-03-24 03:56:05,758] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 9.8237511e-27 6.8111418e-23 3.8217686e-23 1.2042150e-25], sum to 1.0000
[2019-03-24 03:56:05,765] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2979
[2019-03-24 03:56:05,772] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1583316.820442641 W.
[2019-03-24 03:56:05,777] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.36666666666667, 32.66666666666667, 1.0, 2.0, 0.4427195462470373, 1.0, 2.0, 0.4427195462470373, 1.0, 1.0, 0.7122524356363522, 6.9112, 6.9112, 121.94756008, 1583316.820442641, 1583316.820442641, 316097.6134779237], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 573600.0000, 
sim time next is 574200.0000, 
raw observation next is [31.45, 32.5, 1.0, 2.0, 0.4442868486776819, 1.0, 2.0, 0.4442868486776819, 1.0, 2.0, 0.7137030223169087, 6.911199999999999, 6.9112, 121.94756008, 1583606.026442813, 1583606.026442813, 316897.7827564223], 
processed observation next is [1.0, 0.6521739130434783, 0.7203703703703703, 0.325, 1.0, 1.0, 0.33843672461628804, 1.0, 1.0, 0.33843672461628804, 1.0, 1.0, 0.642128777896136, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5655735808724333, 0.5655735808724333, 0.6094188129931198], 
reward next is 0.3906, 
noisyNet noise sample is [array([-0.6492625], dtype=float32), -0.33960426]. 
=============================================
[2019-03-24 03:56:06,145] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 03:56:06,149] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:56:06,150] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:56:06,150] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:56:06,152] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:56:06,154] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:56:06,156] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:56:06,156] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:56:06,159] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:56:06,165] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:56:06,167] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:56:06,175] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run61
[2019-03-24 03:56:06,203] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run61
[2019-03-24 03:56:06,203] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run61
[2019-03-24 03:56:06,204] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run61
[2019-03-24 03:56:06,280] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run61
[2019-03-24 03:56:13,086] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05465962], dtype=float32), 0.3738003]
[2019-03-24 03:56:13,088] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.9, 51.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3923235017067664, 6.9112, 6.9112, 121.9260426156618, 280108.7399827084, 280108.7399827084, 84617.23402997736]
[2019-03-24 03:56:13,089] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:56:13,093] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.3712833e-36 2.3167374e-31 1.3747521e-34 5.2562359e-32], sampled 0.07046173419705193
[2019-03-24 03:56:25,205] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05465962], dtype=float32), 0.3738003]
[2019-03-24 03:56:25,205] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.26666666666667, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6525805727327095, 6.9112, 6.9112, 121.9260426156618, 486920.04134081, 486920.04134081, 137782.7662767461]
[2019-03-24 03:56:25,206] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:56:25,209] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.6274722e-34 1.3721307e-29 1.2642136e-32 3.3951087e-30], sampled 0.9939925175820551
[2019-03-24 03:56:45,784] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05465962], dtype=float32), 0.3738003]
[2019-03-24 03:56:45,785] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.16666666666666, 60.83333333333334, 1.0, 2.0, 0.6812013667278225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 815190.5655976023, 815190.5655976023, 174357.6679355846]
[2019-03-24 03:56:45,785] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:56:45,787] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.5673437e-31 5.3675926e-27 8.7106877e-30 1.4900263e-27], sampled 0.8670902627130005
[2019-03-24 03:56:45,788] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 815190.5655976023 W.
[2019-03-24 03:56:53,958] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05465962], dtype=float32), 0.3738003]
[2019-03-24 03:56:53,958] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.73517027, 77.63569322333333, 1.0, 2.0, 0.6868493609594569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 782806.3156629537, 782806.3156629532, 173668.9605426106]
[2019-03-24 03:56:53,959] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:56:53,963] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 6.8480324e-38 2.0082212e-32 8.3240189e-36 4.2218107e-33], sampled 0.17987330425201342
[2019-03-24 03:56:53,964] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 782806.3156629537 W.
[2019-03-24 03:57:26,021] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05465962], dtype=float32), 0.3738003]
[2019-03-24 03:57:26,022] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.0, 90.0, 1.0, 2.0, 0.5656377499704175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672575.8109836952, 672575.8109836952, 153508.158011789]
[2019-03-24 03:57:26,023] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:57:26,027] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.9064700e-32 1.2383419e-27 1.7472390e-30 3.3138215e-28], sampled 0.7638291592474
[2019-03-24 03:57:48,982] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 03:57:49,359] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 03:57:49,720] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 03:57:49,749] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 03:57:49,931] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 03:57:50,947] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1500000, evaluation results [1500000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 03:58:02,627] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.9738271e-36 0.0000000e+00 2.5329970e-34], sum to 1.0000
[2019-03-24 03:58:02,632] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5920
[2019-03-24 03:58:02,636] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.58333333333333, 48.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6719439251736244, 6.911199999999999, 6.9112, 121.9260426156618, 501968.0350457384, 501968.0350457389, 140867.9255122298], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 814200.0000, 
sim time next is 814800.0000, 
raw observation next is [27.86666666666667, 47.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6766022035801927, 6.911200000000001, 6.9112, 121.9260426156618, 505538.3668183143, 505538.3668183138, 141659.0557188093], 
processed observation next is [0.0, 0.43478260869565216, 0.5876543209876545, 0.47666666666666674, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5957527544752409, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18054941672082653, 0.18054941672082636, 0.2724212609977102], 
reward next is 0.7276, 
noisyNet noise sample is [array([0.8591902], dtype=float32), -0.24683438]. 
=============================================
[2019-03-24 03:58:07,399] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.1293996e-38 7.5803278e-34 7.4727038e-38 1.6621689e-34], sum to 1.0000
[2019-03-24 03:58:07,410] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0692
[2019-03-24 03:58:07,414] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.13333333333333, 65.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5414187424915096, 6.9112, 6.9112, 121.9260426156618, 393305.6928160409, 393305.6928160409, 120717.1830423296], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 883200.0000, 
sim time next is 883800.0000, 
raw observation next is [21.2, 65.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5436046481998241, 6.911199999999999, 6.9112, 121.9260426156618, 395463.7512913987, 395463.7512913991, 121124.7698387957], 
processed observation next is [0.0, 0.21739130434782608, 0.34074074074074073, 0.655, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.42950581024978013, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1412370540326424, 0.14123705403264256, 0.23293224968999174], 
reward next is 0.7671, 
noisyNet noise sample is [array([0.3623238], dtype=float32), 1.851366]. 
=============================================
[2019-03-24 03:58:08,785] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.7443016e-38 1.3910436e-32 4.3543069e-36 2.6193541e-32], sum to 1.0000
[2019-03-24 03:58:08,793] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1779
[2019-03-24 03:58:08,798] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.46666666666667, 47.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.718876117284228, 6.9112, 6.9112, 121.9260426156618, 537098.5257895151, 537098.5257895151, 147646.5219604677], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 915600.0000, 
sim time next is 916200.0000, 
raw observation next is [28.45, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7160886733440897, 6.911200000000001, 6.9112, 121.9260426156618, 535068.6616440361, 535068.6616440356, 147136.4776365505], 
processed observation next is [0.0, 0.6086956521739131, 0.6092592592592593, 0.47, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6451108416801121, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19109595058715573, 0.19109595058715556, 0.28295476468567404], 
reward next is 0.7170, 
noisyNet noise sample is [array([-0.11640318], dtype=float32), 1.1895967]. 
=============================================
[2019-03-24 03:58:10,031] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.000000e+00 1.266129e-33 4.745850e-29 4.969068e-32 4.885715e-29], sum to 1.0000
[2019-03-24 03:58:10,037] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5047
[2019-03-24 03:58:10,045] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.05, 57.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5331963066314416, 6.9112, 6.9112, 121.9260426156618, 380713.2095367113, 380713.2095367113, 114709.3871684368], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 960600.0000, 
sim time next is 961200.0000, 
raw observation next is [21.0, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5226893687612535, 6.911199999999999, 6.9112, 121.9260426156618, 373209.2127697335, 373209.212769734, 113866.2093031883], 
processed observation next is [1.0, 0.13043478260869565, 0.3333333333333333, 0.58, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4033617109515668, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13328900456061912, 0.1332890045606193, 0.21897347942920828], 
reward next is 0.7810, 
noisyNet noise sample is [array([-0.22800647], dtype=float32), -0.5462791]. 
=============================================
[2019-03-24 03:58:12,730] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.6524454e-26 4.5902460e-22 2.2797057e-24 9.2906095e-22], sum to 1.0000
[2019-03-24 03:58:12,735] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6897
[2019-03-24 03:58:12,740] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 954871.7055994448 W.
[2019-03-24 03:58:12,743] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.93333333333333, 57.33333333333334, 1.0, 2.0, 0.3850030872920744, 1.0, 2.0, 0.3850030872920744, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 954871.7055994448, 954871.7055994453, 204989.091635569], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 985200.0000, 
sim time next is 985800.0000, 
raw observation next is [24.06666666666667, 57.16666666666666, 1.0, 2.0, 0.2660407487828623, 1.0, 2.0, 0.2660407487828623, 1.0, 1.0, 0.4384411367964807, 6.9112, 6.9112, 121.94756008, 983187.357076132, 983187.357076132, 241627.4041537355], 
processed observation next is [1.0, 0.391304347826087, 0.4469135802469137, 0.5716666666666665, 1.0, 1.0, 0.12623898664626468, 1.0, 1.0, 0.12623898664626468, 1.0, 0.5, 0.2980514209956009, 0.0, 0.0, 0.8096049824067558, 0.35113834181290426, 0.35113834181290426, 0.4646680849110298], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7031637], dtype=float32), 0.723718]. 
=============================================
[2019-03-24 03:58:16,550] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.4470735e-26 4.2345258e-23 6.5719825e-24 4.6815641e-23], sum to 1.0000
[2019-03-24 03:58:16,563] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5703
[2019-03-24 03:58:16,573] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 755086.0961524763 W.
[2019-03-24 03:58:16,578] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.2, 56.0, 1.0, 2.0, 0.5955555589591994, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156518, 755086.0961524763, 755086.0961524758, 159856.0163335233], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1069200.0000, 
sim time next is 1069800.0000, 
raw observation next is [23.3, 55.66666666666667, 1.0, 2.0, 0.2115530465650087, 1.0, 1.0, 0.2115530465650087, 1.0, 1.0, 0.3564700139586303, 6.9112, 6.9112, 121.94756008, 795375.2984491283, 795375.2984491283, 221439.690039943], 
processed observation next is [1.0, 0.391304347826087, 0.41851851851851857, 0.5566666666666668, 1.0, 1.0, 0.061372674482153215, 1.0, 0.5, 0.061372674482153215, 1.0, 0.5, 0.19558751744828787, 0.0, 0.0, 0.8096049824067558, 0.28406260658897436, 0.28406260658897436, 0.42584555776912114], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6168217], dtype=float32), -2.0766587]. 
=============================================
[2019-03-24 03:58:19,035] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.6933390e-34 4.6192085e-31 1.7189305e-30 1.2764904e-29], sum to 1.0000
[2019-03-24 03:58:19,047] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7336
[2019-03-24 03:58:19,053] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.05, 65.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5739899170114666, 6.9112, 6.9112, 121.9260426156618, 422823.4142250275, 422823.4142250275, 126043.8042370971], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1108200.0000, 
sim time next is 1108800.0000, 
raw observation next is [21.8, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5669870804247067, 6.9112, 6.9112, 121.9260426156618, 417457.0829316775, 417457.0829316775, 125315.6016477834], 
processed observation next is [1.0, 0.8695652173913043, 0.362962962962963, 0.67, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45873385053088334, 0.0, 0.0, 0.8094621288201359, 0.14909181533274196, 0.14909181533274196, 0.2409915416303527], 
reward next is 0.7590, 
noisyNet noise sample is [array([0.68425214], dtype=float32), -0.98619574]. 
=============================================
[2019-03-24 03:58:23,001] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.0522138e-35 2.7412023e-29 1.2657427e-33 2.9168247e-30], sum to 1.0000
[2019-03-24 03:58:23,008] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5219
[2019-03-24 03:58:23,014] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.7, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4959515300220375, 6.911200000000001, 6.9112, 121.9260426156618, 355623.7935002377, 355623.7935002372, 115325.0303690993], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1396800.0000, 
sim time next is 1397400.0000, 
raw observation next is [20.66666666666667, 62.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4918732132752688, 6.9112, 6.9112, 121.9260426156618, 352006.4417327219, 352006.4417327219, 114777.986535973], 
processed observation next is [0.0, 0.17391304347826086, 0.3209876543209878, 0.625, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3648415165940859, 0.0, 0.0, 0.8094621288201359, 0.12571658633311497, 0.12571658633311497, 0.22072689718456348], 
reward next is 0.7793, 
noisyNet noise sample is [array([-1.1777086], dtype=float32), 0.4232154]. 
=============================================
[2019-03-24 03:58:28,237] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.0468279e-34 5.4603411e-27 2.0859972e-33 1.0366082e-29], sum to 1.0000
[2019-03-24 03:58:28,248] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9766
[2019-03-24 03:58:28,258] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1111920.184197212 W.
[2019-03-24 03:58:28,261] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 54.33333333333334, 1.0, 2.0, 0.4588681298166992, 1.0, 1.0, 0.4588681298166992, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260425936844, 1111920.184197212, 1111920.184197212, 225655.6044236517], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1268400.0000, 
sim time next is 1269000.0000, 
raw observation next is [26.4, 54.0, 1.0, 2.0, 0.8964355379244894, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.925045247024645, 6.9112, 121.9258474267837, 1106400.695776216, 1099310.703175702, 220127.538366251], 
processed observation next is [1.0, 0.6956521739130435, 0.5333333333333333, 0.54, 1.0, 1.0, 0.8767089737196302, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.001384524702464507, 0.0, 0.8094608329689675, 0.39514310563436283, 0.39261096541989354, 0.42332218916586734], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6842296], dtype=float32), -0.45171997]. 
=============================================
[2019-03-24 03:58:28,272] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[69.89472 ]
 [69.657326]
 [69.71388 ]
 [68.365326]
 [67.86992 ]], R is [[70.23043823]
 [69.52813721]
 [68.83285522]
 [68.14452362]
 [67.46308136]].
[2019-03-24 03:58:37,908] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 6.1039234e-33 2.9152192e-25 2.1941992e-28 1.6406751e-26], sum to 1.0000
[2019-03-24 03:58:37,916] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4723
[2019-03-24 03:58:37,919] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.15, 34.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5952213231190487, 6.9112, 6.9112, 121.9260426156618, 441017.263544401, 441017.263544401, 129405.4471302224], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1461000.0000, 
sim time next is 1461600.0000, 
raw observation next is [29.0, 35.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5932741185805187, 6.9112, 6.9112, 121.9260426156618, 439541.4368777158, 439541.4368777158, 129203.3978902978], 
processed observation next is [0.0, 0.9565217391304348, 0.6296296296296297, 0.35, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.49159264822564835, 0.0, 0.0, 0.8094621288201359, 0.15697908459918422, 0.15697908459918422, 0.2484680728659573], 
reward next is 0.7515, 
noisyNet noise sample is [array([0.33079672], dtype=float32), -0.1129651]. 
=============================================
[2019-03-24 03:58:41,755] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 03:58:41,763] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 03:58:41,764] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:58:41,765] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 03:58:41,766] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:58:41,766] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 03:58:41,766] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:58:41,766] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 03:58:41,768] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 03:58:41,769] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:58:41,769] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 03:58:41,787] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run62
[2019-03-24 03:58:41,814] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run62
[2019-03-24 03:58:41,835] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run62
[2019-03-24 03:58:41,858] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run62
[2019-03-24 03:58:41,859] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run62
[2019-03-24 03:59:14,762] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06242504], dtype=float32), 0.37992242]
[2019-03-24 03:59:14,763] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8332608019308372, 6.911200000000001, 6.9112, 121.9260426156618, 613795.802222957, 613795.8022229566, 166338.8017946119]
[2019-03-24 03:59:14,763] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:59:14,767] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.1592958e-29 1.3613939e-24 4.2764966e-27 4.1083901e-25], sampled 0.29848239301499335
[2019-03-24 03:59:22,013] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06242504], dtype=float32), 0.37992242]
[2019-03-24 03:59:22,014] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.06666666666667, 82.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8600540153187598, 6.911200000000001, 6.9112, 121.9260426156618, 636939.5578105641, 636939.5578105637, 168632.9305456822]
[2019-03-24 03:59:22,014] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 03:59:22,017] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.7106308e-29 1.1997084e-24 3.7132318e-27 3.6110244e-25], sampled 0.948333314854314
[2019-03-24 03:59:30,285] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06242504], dtype=float32), 0.37992242]
[2019-03-24 03:59:30,287] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.0, 69.66666666666667, 1.0, 2.0, 0.424362317609426, 1.0, 2.0, 0.424362317609426, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 967412.9705385312, 967412.9705385317, 212981.9948454641]
[2019-03-24 03:59:30,288] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:59:30,291] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.5588552e-30 1.9749604e-25 4.3772406e-28 5.5762655e-26], sampled 0.9937375780952804
[2019-03-24 03:59:30,292] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 967412.9705385312 W.
[2019-03-24 03:59:36,341] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06242504], dtype=float32), 0.37992242]
[2019-03-24 03:59:36,341] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.59807776, 85.81956908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6929522773126205, 6.911200000000001, 6.9112, 121.9260426156618, 517835.4145072232, 517835.4145072227, 143997.8078098586]
[2019-03-24 03:59:36,344] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 03:59:36,348] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.5331098e-29 1.1344148e-24 3.4861566e-27 3.4072096e-25], sampled 0.5769224757987713
[2019-03-24 03:59:55,399] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06242504], dtype=float32), 0.37992242]
[2019-03-24 03:59:55,400] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.35, 44.5, 1.0, 2.0, 0.5651705666433225, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9118887361260295, 6.911199999999998, 6.9112, 121.9260425037664, 1355028.97750534, 1355028.97750534, 278805.8887760153]
[2019-03-24 03:59:55,401] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 03:59:55,403] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.7796388e-26 3.2509142e-22 1.6236854e-24 1.0822113e-22], sampled 0.11837764882239366
[2019-03-24 03:59:55,404] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1355028.97750534 W.
[2019-03-24 04:00:02,058] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06242504], dtype=float32), 0.37992242]
[2019-03-24 04:00:02,059] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.263125225, 53.29162025333333, 1.0, 2.0, 0.6416022349055374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 731213.2995729656, 731213.2995729656, 165384.4296636149]
[2019-03-24 04:00:02,059] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:00:02,063] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.1371972e-29 1.1209504e-24 3.1024977e-27 3.2989308e-25], sampled 0.23374668598616188
[2019-03-24 04:00:02,064] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 731213.2995729656 W.
[2019-03-24 04:00:17,441] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06242504], dtype=float32), 0.37992242]
[2019-03-24 04:00:17,442] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.0, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5042706154488901, 6.911200000000001, 6.9112, 121.9260426156618, 365852.4529408376, 365852.4529408371, 117521.6694005503]
[2019-03-24 04:00:17,445] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:00:17,448] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.2740899e-28 7.1055195e-24 2.6711668e-26 2.2227038e-24], sampled 0.6415465335254728
[2019-03-24 04:00:22,362] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 04:00:22,380] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 04:00:22,393] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 04:00:22,627] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 04:00:22,679] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 04:00:23,699] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1525000, evaluation results [1525000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 04:00:25,126] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 8.3630510e-26 4.8266622e-20 2.0155981e-23 1.3235582e-21], sum to 1.0000
[2019-03-24 04:00:25,133] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5072
[2019-03-24 04:00:25,138] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.6, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6487947003548254, 6.9112, 6.9112, 121.9260426156618, 482894.4651534687, 482894.4651534687, 136115.7289433646], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1557000.0000, 
sim time next is 1557600.0000, 
raw observation next is [22.5, 70.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6475460811508638, 6.911199999999999, 6.9112, 121.9260426156618, 481968.0724626838, 481968.0724626842, 135993.6748784478], 
processed observation next is [1.0, 0.0, 0.3888888888888889, 0.7066666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5594326014385796, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17213145445095848, 0.17213145445095865, 0.2615262978431689], 
reward next is 0.7385, 
noisyNet noise sample is [array([0.21592788], dtype=float32), -0.31160408]. 
=============================================
[2019-03-24 04:00:27,397] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.3320183e-24 2.3496547e-20 4.5354706e-22 5.6513788e-22], sum to 1.0000
[2019-03-24 04:00:27,403] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5997
[2019-03-24 04:00:27,408] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1189964.541471972 W.
[2019-03-24 04:00:27,420] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.26666666666667, 55.33333333333334, 1.0, 2.0, 0.4841512035398208, 0.0, 2.0, 0.0, 1.0, 2.0, 0.795843340918123, 6.9112, 6.9112, 121.9260426156618, 1189964.541471972, 1189964.541471972, 248222.0721107728], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1592400.0000, 
sim time next is 1593000.0000, 
raw observation next is [25.4, 55.0, 1.0, 2.0, 0.3277709570982434, 1.0, 1.0, 0.3277709570982434, 1.0, 2.0, 0.5328986197888848, 6.9112, 6.9112, 121.94756008, 1192913.983613595, 1192913.983613595, 265956.2290129316], 
processed observation next is [1.0, 0.43478260869565216, 0.49629629629629624, 0.55, 1.0, 1.0, 0.1997273298788612, 1.0, 0.5, 0.1997273298788612, 1.0, 1.0, 0.4161232747361059, 0.0, 0.0, 0.8096049824067558, 0.42604070843342673, 0.42604070843342673, 0.5114542865633299], 
reward next is 0.4885, 
noisyNet noise sample is [array([0.5540944], dtype=float32), 0.31399453]. 
=============================================
[2019-03-24 04:00:27,438] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[53.469585]
 [53.43619 ]
 [53.163666]
 [52.94581 ]
 [52.66673 ]], R is [[53.56394577]
 [53.55095673]
 [53.01544952]
 [52.48529434]
 [51.96044159]].
[2019-03-24 04:00:31,146] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 5.6298926e-26 1.0839301e-22 3.9930315e-25 4.4795833e-24], sum to 1.0000
[2019-03-24 04:00:31,151] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4876
[2019-03-24 04:00:31,156] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.2, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5775687644779999, 6.911200000000001, 6.9112, 121.9260426156618, 421382.3717020406, 421382.3717020401, 124484.6465756421], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1656000.0000, 
sim time next is 1656600.0000, 
raw observation next is [18.98333333333333, 82.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6063269537041386, 6.9112, 6.9112, 121.9260426156618, 442165.939018779, 442165.939018779, 126922.8904854066], 
processed observation next is [1.0, 0.17391304347826086, 0.25864197530864186, 0.825, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5079086921301732, 0.0, 0.0, 0.8094621288201359, 0.15791640679242108, 0.15791640679242108, 0.24408248170270502], 
reward next is 0.7559, 
noisyNet noise sample is [array([0.13086464], dtype=float32), -0.33258247]. 
=============================================
[2019-03-24 04:00:32,653] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.2217355e-23 1.3735996e-18 2.5560194e-20 1.0527255e-18], sum to 1.0000
[2019-03-24 04:00:32,663] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0486
[2019-03-24 04:00:32,669] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1146615.089993611 W.
[2019-03-24 04:00:32,674] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.35, 69.0, 1.0, 2.0, 0.4692227824279003, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7672194963956984, 6.911199999999999, 6.9112, 121.9260426156618, 1146615.089993611, 1146615.089993612, 243651.3898447315], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1695000.0000, 
sim time next is 1695600.0000, 
raw observation next is [23.4, 69.0, 1.0, 2.0, 0.318581788352061, 1.0, 1.0, 0.318581788352061, 1.0, 2.0, 0.5163259334992422, 6.9112, 6.9112, 121.94756008, 1154163.239835886, 1154163.239835886, 262496.7756859392], 
processed observation next is [1.0, 0.6521739130434783, 0.42222222222222217, 0.69, 1.0, 1.0, 0.18878784327626313, 1.0, 0.5, 0.18878784327626313, 1.0, 1.0, 0.3954074168740527, 0.0, 0.0, 0.8096049824067558, 0.41220115708424504, 0.41220115708424504, 0.5048014917037292], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.1351649], dtype=float32), -0.30905208]. 
=============================================
[2019-03-24 04:00:35,922] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.00000000e+00 1.84761561e-29 8.29474521e-25 2.45122734e-27
 1.19922856e-23], sum to 1.0000
[2019-03-24 04:00:35,927] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8217
[2019-03-24 04:00:35,931] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.45, 85.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6228709339756934, 6.9112, 6.9112, 121.9260426156618, 463569.3176326817, 463569.3176326817, 133529.0013342337], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1740600.0000, 
sim time next is 1741200.0000, 
raw observation next is [20.36666666666667, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6199831472791377, 6.911200000000001, 6.9112, 121.9260426156618, 461357.2801210554, 461357.2801210549, 133192.7566321994], 
processed observation next is [1.0, 0.13043478260869565, 0.3098765432098767, 0.86, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5249789340989222, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1647704571860912, 0.16477045718609104, 0.25613991660038343], 
reward next is 0.7439, 
noisyNet noise sample is [array([-0.34992424], dtype=float32), -0.8100881]. 
=============================================
[2019-03-24 04:00:36,606] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.4923481e-26 1.0165498e-23 1.5087704e-26 4.4568647e-23], sum to 1.0000
[2019-03-24 04:00:36,621] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5312
[2019-03-24 04:00:36,625] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.25, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6400179861749434, 6.9112, 6.9112, 121.9260426156618, 477044.036739402, 477044.036739402, 135903.2784872981], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1751400.0000, 
sim time next is 1752000.0000, 
raw observation next is [21.4, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6472135857573399, 6.911199999999999, 6.9112, 121.9260426156618, 482502.2868317083, 482502.2868317088, 136729.4305696], 
processed observation next is [1.0, 0.2608695652173913, 0.3481481481481481, 0.8066666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5590169821966748, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17232224529703866, 0.17232224529703885, 0.2629412126338461], 
reward next is 0.7371, 
noisyNet noise sample is [array([-0.33495837], dtype=float32), -1.3133825]. 
=============================================
[2019-03-24 04:00:36,643] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[55.11404 ]
 [55.162113]
 [55.20612 ]
 [55.46086 ]
 [55.731045]], R is [[55.15952682]
 [55.34658051]
 [55.53018951]
 [55.69768143]
 [55.87756729]].
[2019-03-24 04:00:47,296] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.0430379e-33 7.2488909e-26 1.3709064e-29 2.4736237e-25], sum to 1.0000
[2019-03-24 04:00:47,307] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8439
[2019-03-24 04:00:47,314] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1269321.586210068 W.
[2019-03-24 04:00:47,319] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.95, 63.16666666666667, 1.0, 2.0, 0.5419043665134814, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8662481193693867, 6.911199999999999, 6.9112, 121.9260426156618, 1269321.586210068, 1269321.586210069, 271278.8545415992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1950600.0000, 
sim time next is 1951200.0000, 
raw observation next is [27.2, 62.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.597867247787175, 6.9112, 121.9232702454092, 1562327.216064733, 1210700.2070981, 248103.0597879954], 
processed observation next is [1.0, 0.6086956521739131, 0.5629629629629629, 0.62, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.06866672477871746, 0.0, 0.8094437231647206, 0.5579740057374046, 0.4323929311064643, 0.47712126882306805], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.84346724], dtype=float32), -0.4428031]. 
=============================================
[2019-03-24 04:00:48,295] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.00000000e+00 1.10820522e-29 1.22736596e-26 1.90975875e-29
 1.24012948e-26], sum to 1.0000
[2019-03-24 04:00:48,303] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0850
[2019-03-24 04:00:48,312] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1535099.293571476 W.
[2019-03-24 04:00:48,319] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.6, 59.0, 1.0, 2.0, 0.7129650169179372, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9893599896077129, 6.911199999999999, 6.9112, 121.9260426156618, 1535099.293571476, 1535099.293571477, 318154.974222608], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1960200.0000, 
sim time next is 1960800.0000, 
raw observation next is [28.7, 58.66666666666667, 1.0, 2.0, 0.673180221681661, 1.0, 1.0, 0.673180221681661, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1542469.738599674, 1542469.738599674, 294505.2461961856], 
processed observation next is [1.0, 0.6956521739130435, 0.6185185185185185, 0.5866666666666667, 1.0, 1.0, 0.6109288353353107, 1.0, 0.5, 0.6109288353353107, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5508820494998836, 0.5508820494998836, 0.5663562426849723], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.53157353], dtype=float32), -0.8796133]. 
=============================================
[2019-03-24 04:00:49,300] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.000000e+00 7.819571e-29 3.417387e-26 8.235714e-27 7.264967e-28], sum to 1.0000
[2019-03-24 04:00:49,305] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4462
[2019-03-24 04:00:49,312] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1565347.679986951 W.
[2019-03-24 04:00:49,315] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.96666666666667, 82.33333333333334, 1.0, 2.0, 0.4575885816695672, 1.0, 2.0, 0.4575885816695672, 1.0, 2.0, 0.7284959246376499, 6.911200000000001, 6.9112, 121.94756008, 1565347.679986951, 1565347.67998695, 323227.0917031085], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2209200.0000, 
sim time next is 2209800.0000, 
raw observation next is [27.13333333333333, 81.66666666666666, 1.0, 2.0, 0.4517149359009277, 1.0, 2.0, 0.4517149359009277, 1.0, 2.0, 0.7191448892826879, 6.911199999999999, 6.9112, 121.94756008, 1545234.474420107, 1545234.474420107, 320476.4902812597], 
processed observation next is [1.0, 0.5652173913043478, 0.5604938271604937, 0.8166666666666665, 1.0, 1.0, 0.3472796855963425, 1.0, 1.0, 0.3472796855963425, 1.0, 1.0, 0.6489311116033599, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5518694551500382, 0.5518694551500382, 0.6163009428485764], 
reward next is 0.3837, 
noisyNet noise sample is [array([0.9965834], dtype=float32), 0.99228096]. 
=============================================
[2019-03-24 04:00:51,260] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 9.4240154e-34 3.2354150e-28 1.9371035e-30 4.1877827e-29], sum to 1.0000
[2019-03-24 04:00:51,268] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8719
[2019-03-24 04:00:51,278] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.15, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8717357576356268, 6.9112, 6.9112, 121.9260426156618, 638598.2588006834, 638598.2588006834, 172096.1983314953], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2038200.0000, 
sim time next is 2038800.0000, 
raw observation next is [28.2, 63.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8762665306174081, 6.911200000000001, 6.9112, 121.9260426156618, 641478.322903193, 641478.3229031925, 172778.6600641994], 
processed observation next is [0.0, 0.6086956521739131, 0.6, 0.6300000000000001, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.84533316327176, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22909940103685464, 0.22909940103685447, 0.3322666539696142], 
reward next is 0.6677, 
noisyNet noise sample is [array([0.9793995], dtype=float32), 0.8315315]. 
=============================================
[2019-03-24 04:01:00,468] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 4.4690877e-16 1.5947512e-13 4.9647126e-16 3.6783561e-14], sum to 1.0000
[2019-03-24 04:01:00,473] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2659
[2019-03-24 04:01:00,476] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1546876.479724841 W.
[2019-03-24 04:01:00,480] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.96666666666667, 82.33333333333334, 1.0, 2.0, 0.7298538006490334, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1546876.479724841, 1546876.479724842, 322721.7054544314], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2209200.0000, 
sim time next is 2209800.0000, 
raw observation next is [27.13333333333333, 81.66666666666666, 1.0, 2.0, 0.6775658326765903, 1.0, 1.0, 0.6775658326765903, 0.0, 1.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1545219.74854136, 1545219.748541361, 295759.8779782498], 
processed observation next is [1.0, 0.5652173913043478, 0.5604938271604937, 0.8166666666666665, 1.0, 1.0, 0.6161498008054647, 1.0, 0.5, 0.6161498008054647, 0.0, 0.5, -0.25, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.5518641959076286, 0.5518641959076289, 0.5687689961120188], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.1504432], dtype=float32), 0.4889672]. 
=============================================
[2019-03-24 04:01:01,926] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 8.3984050e-27 6.2651983e-23 2.4893766e-24 1.0050445e-22], sum to 1.0000
[2019-03-24 04:01:01,933] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9598
[2019-03-24 04:01:01,941] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.86666666666667, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8870048907951409, 6.9112, 6.9112, 121.9260426156618, 650171.8538421018, 650171.8538421018, 174011.5927947013], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2247600.0000, 
sim time next is 2248200.0000, 
raw observation next is [22.9, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8891045703521943, 6.911200000000001, 6.9112, 121.9260426156618, 651388.710388164, 651388.7103881636, 174357.2280480134], 
processed observation next is [1.0, 0.0, 0.4037037037037037, 0.98, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8613807129402429, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23263882513863002, 0.23263882513862985, 0.335302361630795], 
reward next is 0.6647, 
noisyNet noise sample is [array([2.1067674], dtype=float32), 2.0802596]. 
=============================================
[2019-03-24 04:01:02,486] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 3.6949401e-31 7.0753810e-26 1.5460221e-28 7.0698462e-27], sum to 1.0000
[2019-03-24 04:01:02,495] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6205
[2019-03-24 04:01:02,498] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.96666666666667, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8938247845381783, 6.911200000000001, 6.9112, 121.9260426156618, 654186.4281930837, 654186.4281930834, 175117.8283594365], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2249400.0000, 
sim time next is 2250000.0000, 
raw observation next is [23.0, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8966448609230174, 6.911199999999999, 6.9112, 121.9260426156618, 655913.0320072607, 655913.0320072612, 175559.515135272], 
processed observation next is [1.0, 0.043478260869565216, 0.4074074074074074, 0.98, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8708060761537717, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23425465428830738, 0.23425465428830755, 0.3376144521832154], 
reward next is 0.6624, 
noisyNet noise sample is [array([-1.6214181], dtype=float32), -0.8173677]. 
=============================================
[2019-03-24 04:01:02,510] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[58.76663 ]
 [58.905857]
 [59.100674]
 [59.722744]
 [60.661854]], R is [[58.78593826]
 [58.86131287]
 [58.93671799]
 [59.01204681]
 [59.08729172]].
[2019-03-24 04:01:08,669] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.8493935e-28 8.3990228e-25 1.3635345e-25 5.4544789e-24], sum to 1.0000
[2019-03-24 04:01:08,675] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2978
[2019-03-24 04:01:08,678] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.76666666666667, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.816669826244803, 6.911200000000001, 6.9112, 121.9260426156618, 607339.7255249544, 607339.7255249539, 162026.500312636], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2346000.0000, 
sim time next is 2346600.0000, 
raw observation next is [21.73333333333333, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8125251308363323, 6.9112, 6.9112, 121.9260426156618, 604401.6493859722, 604401.6493859722, 161422.8315192466], 
processed observation next is [1.0, 0.13043478260869565, 0.3604938271604937, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7656564135454152, 0.0, 0.0, 0.8094621288201359, 0.2158577319235615, 0.2158577319235615, 0.3104285221523973], 
reward next is 0.6896, 
noisyNet noise sample is [array([-2.6618252], dtype=float32), -1.208874]. 
=============================================
[2019-03-24 04:01:11,619] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.1929600e-37 2.2356297e-31 2.7694070e-33 5.4973331e-35], sum to 1.0000
[2019-03-24 04:01:11,625] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4467
[2019-03-24 04:01:11,629] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.93333333333333, 53.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6421889455666085, 6.9112, 6.9112, 121.9260426156618, 478884.467889408, 478884.467889408, 136370.6598891702], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2409600.0000, 
sim time next is 2410200.0000, 
raw observation next is [25.7, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6461579107245247, 6.911199999999999, 6.9112, 121.9260426156618, 481776.8396765483, 481776.8396765488, 136692.5249695722], 
processed observation next is [1.0, 0.9130434782608695, 0.5074074074074074, 0.54, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5576973884056557, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17206315702733868, 0.17206315702733885, 0.2628702403261004], 
reward next is 0.7371, 
noisyNet noise sample is [array([0.83096015], dtype=float32), 0.9299346]. 
=============================================
[2019-03-24 04:01:11,915] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 6.2994752e-36 7.9751894e-31 1.1935879e-30 8.9356349e-32], sum to 1.0000
[2019-03-24 04:01:11,922] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6516
[2019-03-24 04:01:11,926] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.03333333333333, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6606489316944025, 6.911200000000001, 6.9112, 121.9260426156618, 493528.9177967608, 493528.9177967603, 139684.3546810229], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2400000.0000, 
sim time next is 2400600.0000, 
raw observation next is [28.86666666666667, 42.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6591912059825044, 6.911200000000001, 6.9112, 121.9260426156618, 492407.9680281286, 492407.9680281281, 139446.3572391163], 
processed observation next is [1.0, 0.782608695652174, 0.6246913580246916, 0.425, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5739890074781304, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1758599885814745, 0.1758599885814743, 0.2681660716136852], 
reward next is 0.7318, 
noisyNet noise sample is [array([0.97192985], dtype=float32), 0.044000026]. 
=============================================
[2019-03-24 04:01:12,255] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 3.0694537e-27 3.8271208e-24 3.3956339e-26 1.7157650e-24], sum to 1.0000
[2019-03-24 04:01:12,268] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7689
[2019-03-24 04:01:12,274] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.1, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5175932097669693, 6.911199999999999, 6.9112, 121.9260426156618, 373027.1067022164, 373027.1067022169, 117652.0299105534], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2426400.0000, 
sim time next is 2427000.0000, 
raw observation next is [20.93333333333334, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.834127473382657, 6.9112, 6.9112, 121.9260426156618, 600558.0168356763, 600558.0168356763, 146290.2138171908], 
processed observation next is [1.0, 0.08695652173913043, 0.3308641975308645, 0.63, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7926593417283212, 0.0, 0.0, 0.8094621288201359, 0.21448500601274154, 0.21448500601274154, 0.28132733426382844], 
reward next is 0.7187, 
noisyNet noise sample is [array([1.1896853], dtype=float32), 1.2116243]. 
=============================================
[2019-03-24 04:01:12,295] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[57.74192 ]
 [57.68882 ]
 [57.96327 ]
 [58.27796 ]
 [58.549576]], R is [[57.68790436]
 [57.88477325]
 [58.07822418]
 [58.26840591]
 [58.45503616]].
[2019-03-24 04:01:14,817] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 04:01:14,818] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:01:14,819] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:01:14,820] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:01:14,822] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:01:14,822] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:01:14,823] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:01:14,823] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:01:14,823] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:01:14,827] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:01:14,828] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:01:14,843] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run63
[2019-03-24 04:01:14,868] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run63
[2019-03-24 04:01:14,891] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run63
[2019-03-24 04:01:14,914] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run63
[2019-03-24 04:01:14,914] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run63
[2019-03-24 04:01:39,845] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06167601], dtype=float32), 0.38261285]
[2019-03-24 04:01:39,846] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.2, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.668863530460174, 6.911200000000001, 6.9112, 121.9260426156618, 499628.1560318999, 499628.1560318994, 140441.3569835121]
[2019-03-24 04:01:39,848] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:01:39,850] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.3797149e-27 5.3465546e-23 2.9355965e-25 1.5611324e-23], sampled 0.1383876173406956
[2019-03-24 04:01:52,009] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06167601], dtype=float32), 0.38261285]
[2019-03-24 04:01:52,009] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.73173868666667, 83.02676166, 1.0, 2.0, 0.673786342369809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 767910.8577517978, 767910.8577517978, 171240.1168790937]
[2019-03-24 04:01:52,012] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:01:52,017] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 9.3855269e-25 5.0915358e-21 4.3943336e-23 1.6601014e-21], sampled 0.7423147904416098
[2019-03-24 04:01:52,018] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 767910.8577517978 W.
[2019-03-24 04:01:52,475] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06167601], dtype=float32), 0.38261285]
[2019-03-24 04:01:52,478] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.40620652666667, 41.82053619166667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.67045483943671, 6.911200000000001, 6.9112, 121.9260426156618, 500982.0963499522, 500982.0963499518, 141191.300753436]
[2019-03-24 04:01:52,479] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:01:52,481] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 4.5525328e-27 5.5109091e-23 3.0453960e-25 1.6120526e-23], sampled 0.10983801211060129
[2019-03-24 04:02:03,188] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06167601], dtype=float32), 0.38261285]
[2019-03-24 04:02:03,190] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 93.16666666666667, 1.0, 2.0, 0.7048308805072997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 803310.6999195664, 803310.6999195655, 177062.317823146]
[2019-03-24 04:02:03,190] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:02:03,193] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.4171549e-24 1.8892975e-20 1.8650777e-22 6.3595722e-21], sampled 0.5463737851637415
[2019-03-24 04:02:03,196] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 803310.6999195664 W.
[2019-03-24 04:02:23,029] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06167601], dtype=float32), 0.38261285]
[2019-03-24 04:02:23,030] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.11808165, 73.15634161, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8933583605213671, 6.911200000000001, 6.9112, 121.9260426156461, 655803.0823974439, 655803.0823974436, 174629.4842520837]
[2019-03-24 04:02:23,032] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:02:23,035] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.0828024e-24 9.8576794e-21 9.2725475e-23 3.2669779e-21], sampled 0.43173973836137614
[2019-03-24 04:02:29,743] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06167601], dtype=float32), 0.38261285]
[2019-03-24 04:02:29,744] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.01666666666667, 62.0, 1.0, 2.0, 0.8493638980362503, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1683284.589172727, 1683284.589172727, 346252.8326826186]
[2019-03-24 04:02:29,745] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:02:29,748] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.8108200e-24 9.1958363e-21 8.0770534e-23 3.1471118e-21], sampled 0.5822917599224723
[2019-03-24 04:02:29,748] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1683284.589172727 W.
[2019-03-24 04:02:55,017] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 04:02:55,358] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 04:02:55,532] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 04:02:55,633] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 04:02:55,729] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 04:02:56,747] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1550000, evaluation results [1550000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 04:02:57,537] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 7.7912762e-31 9.1476399e-25 3.3280953e-30 4.0618716e-26], sum to 1.0000
[2019-03-24 04:02:57,543] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6421
[2019-03-24 04:02:57,551] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1442555.393215242 W.
[2019-03-24 04:02:57,555] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.8, 23.0, 1.0, 2.0, 0.4036125441675565, 1.0, 2.0, 0.4036125441675565, 1.0, 2.0, 0.6491757492864617, 6.9112, 6.9112, 121.94756008, 1442555.393215242, 1442555.393215242, 298425.1901819944], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2471400.0000, 
sim time next is 2472000.0000, 
raw observation next is [34.73333333333333, 23.0, 1.0, 2.0, 0.4049923681447989, 1.0, 2.0, 0.4049923681447989, 1.0, 2.0, 0.6518216893966404, 6.9112, 6.9112, 121.94756008, 1449509.737961176, 1449509.737961176, 299000.7972997134], 
processed observation next is [1.0, 0.6086956521739131, 0.8419753086419751, 0.23, 1.0, 1.0, 0.2916575811247606, 1.0, 1.0, 0.2916575811247606, 1.0, 1.0, 0.5647771117458005, 0.0, 0.0, 0.8096049824067558, 0.5176820492718486, 0.5176820492718486, 0.5750015332686796], 
reward next is 0.4250, 
noisyNet noise sample is [array([0.5804096], dtype=float32), 0.016667785]. 
=============================================
[2019-03-24 04:02:57,574] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[59.840324]
 [59.334335]
 [59.243744]
 [58.638687]
 [58.289608]], R is [[59.91391754]
 [59.74088287]
 [59.5517807 ]
 [59.38424683]
 [58.79040527]].
[2019-03-24 04:02:59,347] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.1524526e-25 1.9704923e-23 6.6079525e-25 3.4656117e-23], sum to 1.0000
[2019-03-24 04:02:59,353] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3640
[2019-03-24 04:02:59,361] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.93333333333333, 49.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7632981025286134, 6.9112, 6.9112, 121.9260426156618, 569856.6919778766, 569856.6919778766, 150107.8440992575], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2530200.0000, 
sim time next is 2530800.0000, 
raw observation next is [27.2, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7381181336125349, 6.9112, 6.9112, 121.9260426156618, 551179.0459050236, 551179.0459050236, 147517.3915860565], 
processed observation next is [1.0, 0.30434782608695654, 0.5629629629629629, 0.49, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6726476670156686, 0.0, 0.0, 0.8094621288201359, 0.19684965925179412, 0.19684965925179412, 0.2836872915116471], 
reward next is 0.7163, 
noisyNet noise sample is [array([-0.53599036], dtype=float32), -0.0121148145]. 
=============================================
[2019-03-24 04:03:02,899] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.6449144e-30 4.6127906e-27 1.7767319e-30 2.9743910e-28], sum to 1.0000
[2019-03-24 04:03:02,902] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6846
[2019-03-24 04:03:02,909] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.6, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7685365422880568, 6.911199999999999, 6.9112, 121.9260426156618, 572984.2352414648, 572984.2352414653, 155087.1769102272], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2595600.0000, 
sim time next is 2596200.0000, 
raw observation next is [22.45, 86.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.766171456250902, 6.9112, 6.9112, 121.9260426156618, 571340.7734158846, 571340.7734158846, 154696.4570655738], 
processed observation next is [0.0, 0.043478260869565216, 0.387037037037037, 0.8683333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7077143203136274, 0.0, 0.0, 0.8094621288201359, 0.20405027621995878, 0.20405027621995878, 0.29749318666456503], 
reward next is 0.7025, 
noisyNet noise sample is [array([0.72761613], dtype=float32), -0.00997021]. 
=============================================
[2019-03-24 04:03:04,849] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.1796838e-27 2.4384461e-23 4.7565324e-26 4.2639277e-24], sum to 1.0000
[2019-03-24 04:03:04,855] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2251
[2019-03-24 04:03:04,861] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.61666666666667, 91.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7506100083475592, 6.9112, 6.9112, 121.9260426156618, 560297.2111160337, 560297.2111160337, 152239.3831109483], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2599800.0000, 
sim time next is 2600400.0000, 
raw observation next is [21.53333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7487683087860355, 6.911199999999999, 6.9112, 121.9260426156618, 558964.459920045, 558964.4599200455, 151967.5547108368], 
processed observation next is [0.0, 0.08695652173913043, 0.35308641975308636, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6859603859825444, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19963016425715893, 0.1996301642571591, 0.29224529752084], 
reward next is 0.7078, 
noisyNet noise sample is [array([-0.1310391], dtype=float32), -0.99977845]. 
=============================================
[2019-03-24 04:03:09,101] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.3358942e-29 3.0357588e-24 8.8843639e-28 5.5712266e-26], sum to 1.0000
[2019-03-24 04:03:09,109] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2523
[2019-03-24 04:03:09,114] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.85822932143453, 6.9112, 6.9112, 121.9260426156618, 633120.116427018, 633120.116427018, 169238.0493529657], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2710800.0000, 
sim time next is 2711400.0000, 
raw observation next is [27.16666666666666, 65.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.877512399979768, 6.911200000000001, 6.9112, 121.9260426156618, 647153.9873307901, 647153.9873307897, 171772.6643162328], 
processed observation next is [0.0, 0.391304347826087, 0.5617283950617282, 0.6533333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8468904999747101, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23112642404671077, 0.2311264240467106, 0.3303320467619862], 
reward next is 0.6697, 
noisyNet noise sample is [array([-0.18990944], dtype=float32), 0.34179896]. 
=============================================
[2019-03-24 04:03:10,060] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.0311076e-35 6.7068324e-28 1.8725760e-31 1.7648122e-27], sum to 1.0000
[2019-03-24 04:03:10,062] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6208
[2019-03-24 04:03:10,067] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6583760138337762, 6.911200000000001, 6.9112, 121.9260426156618, 491099.8216506319, 491099.8216506314, 138186.2558069391], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2700600.0000, 
sim time next is 2701200.0000, 
raw observation next is [22.0, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6674533760009899, 6.911199999999999, 6.9112, 121.9260426156618, 498369.2911149847, 498369.2911149852, 139857.8085006735], 
processed observation next is [0.0, 0.2608695652173913, 0.37037037037037035, 0.8, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5843167200012372, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17798903254106596, 0.17798903254106613, 0.26895732403975675], 
reward next is 0.7310, 
noisyNet noise sample is [array([0.73718715], dtype=float32), -1.2905614]. 
=============================================
[2019-03-24 04:03:10,215] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 9.3589440e-29 3.2147391e-25 2.7913735e-25 2.3457810e-24], sum to 1.0000
[2019-03-24 04:03:10,222] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7861
[2019-03-24 04:03:10,230] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 724195.6402040091 W.
[2019-03-24 04:03:10,235] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.7, 58.0, 1.0, 2.0, 0.2118158527842268, 1.0, 1.0, 0.2118158527842268, 1.0, 1.0, 0.3372177359932146, 6.9112, 6.9112, 121.94756008, 724195.6402040091, 724195.6402040091, 224493.1526692562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2728800.0000, 
sim time next is 2729400.0000, 
raw observation next is [30.91666666666666, 56.5, 1.0, 2.0, 0.633276737977088, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 721720.5335181016, 721720.5335181016, 163896.1032276598], 
processed observation next is [0.0, 0.6086956521739131, 0.7006172839506171, 0.565, 1.0, 1.0, 0.5634246880679619, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.257757333399322, 0.257757333399322, 0.3151848138993458], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8025995], dtype=float32), 1.0020866]. 
=============================================
[2019-03-24 04:03:10,715] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 6.2666645e-28 3.3336599e-23 5.4750484e-26 4.6114628e-23], sum to 1.0000
[2019-03-24 04:03:10,735] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9702
[2019-03-24 04:03:10,740] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.16666666666666, 65.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.877512399979768, 6.911200000000001, 6.9112, 121.9260426156618, 647153.9873307901, 647153.9873307897, 171772.6643162328], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2711400.0000, 
sim time next is 2712000.0000, 
raw observation next is [27.33333333333334, 64.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.861924231806771, 6.911199999999999, 6.9112, 121.9260426156618, 635328.977782657, 635328.9777826575, 169861.4206947723], 
processed observation next is [0.0, 0.391304347826087, 0.5679012345679014, 0.6466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8274052897584638, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22690320635094893, 0.2269032063509491, 0.3266565782591775], 
reward next is 0.6733, 
noisyNet noise sample is [array([-0.5261284], dtype=float32), 0.45202288]. 
=============================================
[2019-03-24 04:03:10,753] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[61.885227]
 [61.899822]
 [61.85165 ]
 [61.8164  ]
 [61.798397]], R is [[62.03038025]
 [62.07974243]
 [62.1334877 ]
 [62.18729782]
 [62.241436  ]].
[2019-03-24 04:03:16,315] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 5.7968970e-14 1.5414215e-11 1.1676756e-13 1.2382623e-11], sum to 1.0000
[2019-03-24 04:03:16,328] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1861
[2019-03-24 04:03:16,334] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1053810.626478867 W.
[2019-03-24 04:03:16,336] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.65, 52.5, 1.0, 2.0, 0.4622351980927711, 1.0, 2.0, 0.4622351980927711, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1053810.626478867, 1053810.626478867, 223951.3179009646], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2826600.0000, 
sim time next is 2827200.0000, 
raw observation next is [32.5, 53.0, 1.0, 2.0, 0.3219999900472412, 1.0, 2.0, 0.3219999900472412, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 733947.240364564, 733947.2403645645, 185824.6998242936], 
processed observation next is [1.0, 0.7391304347826086, 0.7592592592592593, 0.53, 1.0, 1.0, 0.1928571310086205, 1.0, 1.0, 0.1928571310086205, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2621240144159157, 0.2621240144159159, 0.3573551919697954], 
reward next is 0.6426, 
noisyNet noise sample is [array([1.7282168], dtype=float32), 1.1084744]. 
=============================================
[2019-03-24 04:03:17,219] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 5.5656599e-19 2.5314084e-15 2.6570936e-17 1.1938656e-15], sum to 1.0000
[2019-03-24 04:03:17,227] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0658
[2019-03-24 04:03:17,233] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8789968547693329, 6.9112, 6.9112, 121.9260426156618, 647491.8079330744, 647491.8079330744, 172180.7750235302], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2854800.0000, 
sim time next is 2855400.0000, 
raw observation next is [22.91666666666667, 93.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8713147037080088, 6.9112, 6.9112, 121.9260426156618, 642447.5054091283, 642447.5054091283, 171011.9420267422], 
processed observation next is [1.0, 0.043478260869565216, 0.4043209876543212, 0.9350000000000002, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8391433796350108, 0.0, 0.0, 0.8094621288201359, 0.22944553764611725, 0.22944553764611725, 0.32886911928219653], 
reward next is 0.6711, 
noisyNet noise sample is [array([0.20507309], dtype=float32), 0.39204082]. 
=============================================
[2019-03-24 04:03:25,848] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.1106143e-12 1.1973350e-10 1.0801170e-13 1.3387377e-11], sum to 1.0000
[2019-03-24 04:03:25,858] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6521
[2019-03-24 04:03:25,864] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1450184.966978805 W.
[2019-03-24 04:03:25,869] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.4239556058262571, 1.0, 1.0, 0.4239556058262571, 1.0, 2.0, 0.6749511317455474, 6.9112, 6.9112, 121.94756008, 1450184.966978805, 1450184.966978805, 307734.9644821594], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2991600.0000, 
sim time next is 2992200.0000, 
raw observation next is [25.16666666666667, 93.16666666666667, 1.0, 2.0, 0.7188268161941402, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1534290.099057136, 1534290.099057135, 320674.4294201654], 
processed observation next is [1.0, 0.6521739130434783, 0.4876543209876545, 0.9316666666666668, 1.0, 1.0, 0.6652700192787384, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5479607496632629, 0.5479607496632625, 0.6166815950387796], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.987191], dtype=float32), 0.7710471]. 
=============================================
[2019-03-24 04:03:27,945] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.9691403e-15 1.3962232e-11 1.1331459e-12 2.2720059e-12], sum to 1.0000
[2019-03-24 04:03:27,954] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2057
[2019-03-24 04:03:27,967] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 899603.0131238771 W.
[2019-03-24 04:03:27,974] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.93333333333333, 93.66666666666667, 1.0, 2.0, 0.2630896702114155, 1.0, 2.0, 0.2630896702114155, 1.0, 2.0, 0.4188473232089529, 6.9112, 6.9112, 121.94756008, 899603.0131238771, 899603.0131238771, 242314.7649568841], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3033600.0000, 
sim time next is 3034200.0000, 
raw observation next is [24.96666666666667, 93.83333333333334, 1.0, 2.0, 0.2582125689863288, 1.0, 2.0, 0.2582125689863288, 1.0, 2.0, 0.4110828192225169, 6.911199999999999, 6.9112, 121.94756008, 882916.7563404856, 882916.7563404861, 240556.3816282584], 
processed observation next is [1.0, 0.08695652173913043, 0.48024691358024696, 0.9383333333333335, 1.0, 1.0, 0.1169197249837248, 1.0, 1.0, 0.1169197249837248, 1.0, 1.0, 0.26385352402814605, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3153274129787449, 0.31532741297874506, 0.4626084262081892], 
reward next is 0.5374, 
noisyNet noise sample is [array([-2.292765], dtype=float32), -0.94268787]. 
=============================================
[2019-03-24 04:03:29,613] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 8.2825592e-13 4.5983098e-10 7.9165195e-13 1.2992338e-10], sum to 1.0000
[2019-03-24 04:03:29,620] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2290
[2019-03-24 04:03:29,629] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 827027.5515911544 W.
[2019-03-24 04:03:29,635] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.1, 80.5, 1.0, 2.0, 0.2418763579062674, 1.0, 1.0, 0.2418763579062674, 1.0, 2.0, 0.3850750391498074, 6.911200000000001, 6.9112, 121.94756008, 827027.5515911544, 827027.551591154, 234763.3106601861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3087000.0000, 
sim time next is 3087600.0000, 
raw observation next is [29.4, 78.66666666666667, 1.0, 2.0, 0.7322274496763722, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 834552.149937254, 834552.1499372531, 182342.885101099], 
processed observation next is [1.0, 0.7391304347826086, 0.6444444444444444, 0.7866666666666667, 1.0, 1.0, 0.6812231543766336, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.298054339263305, 0.29805433926330466, 0.3506593944251904], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.08150329], dtype=float32), 1.0362]. 
=============================================
[2019-03-24 04:03:31,538] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 4.5030235e-23 9.6098457e-20 2.9678603e-22 7.3743384e-20], sum to 1.0000
[2019-03-24 04:03:31,545] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6369
[2019-03-24 04:03:31,553] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.33333333333334, 47.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7159518227381116, 6.9112, 6.9112, 121.9260426156618, 534959.9507497996, 534959.9507497996, 147148.5105647655], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3117000.0000, 
sim time next is 3117600.0000, 
raw observation next is [28.4, 45.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6947784215617522, 6.911200000000001, 6.9112, 121.9260426156618, 519176.5806207775, 519176.580620777, 143886.7545677313], 
processed observation next is [1.0, 0.08695652173913043, 0.6074074074074074, 0.45, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6184730269521902, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18542020736456338, 0.18542020736456322, 0.2767052972456371], 
reward next is 0.7233, 
noisyNet noise sample is [array([-1.6746448], dtype=float32), 0.60691994]. 
=============================================
[2019-03-24 04:03:37,757] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.00000000e+00 1.90054604e-34 1.73488155e-27 1.00808276e-35
 5.21965834e-29], sum to 1.0000
[2019-03-24 04:03:37,767] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7529
[2019-03-24 04:03:37,773] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.66666666666666, 90.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8170615920700687, 6.911200000000001, 6.9112, 121.9260426156618, 606566.5065275935, 606566.506527593, 162623.4185691065], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3210000.0000, 
sim time next is 3210600.0000, 
raw observation next is [22.33333333333334, 92.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8122246650411111, 6.9112, 6.9112, 121.9260426156618, 603459.9388562782, 603459.9388562782, 161776.7597740178], 
processed observation next is [0.0, 0.13043478260869565, 0.38271604938271625, 0.9216666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7652808313013889, 0.0, 0.0, 0.8094621288201359, 0.21552140673438508, 0.21552140673438508, 0.3111091534115727], 
reward next is 0.6889, 
noisyNet noise sample is [array([-0.29745707], dtype=float32), 0.71087396]. 
=============================================
[2019-03-24 04:03:47,858] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 04:03:47,860] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:03:47,861] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:03:47,862] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:03:47,862] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:03:47,862] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:03:47,866] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:03:47,863] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:03:47,866] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:03:47,869] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:03:47,870] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:03:47,891] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run64
[2019-03-24 04:03:47,915] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run64
[2019-03-24 04:03:47,949] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run64
[2019-03-24 04:03:47,950] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run64
[2019-03-24 04:03:48,002] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run64
[2019-03-24 04:04:18,033] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06494549], dtype=float32), 0.38155282]
[2019-03-24 04:04:18,035] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.16727337666667, 55.45933231333335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8203648150629752, 6.9112, 6.9112, 121.9260426156618, 608000.4030825946, 608000.4030825946, 163483.1230608698]
[2019-03-24 04:04:18,037] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:04:18,038] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.1755169e-21 7.9120051e-17 1.0984127e-19 5.0577442e-18], sampled 0.5143024190386388
[2019-03-24 04:04:49,290] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06494549], dtype=float32), 0.38155282]
[2019-03-24 04:04:49,291] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.95, 64.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8968724757467986, 6.9112, 6.9112, 121.9260426156618, 655341.5380258781, 655341.5380258781, 175733.5588937171]
[2019-03-24 04:04:49,292] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:04:49,295] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 5.9571286e-21 1.0484223e-16 1.5359008e-19 6.8567284e-18], sampled 0.5378112488220651
[2019-03-24 04:05:04,184] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06494549], dtype=float32), 0.38155282]
[2019-03-24 04:05:04,186] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.08333333333334, 92.66666666666667, 1.0, 2.0, 0.5973981439742074, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9510773011062005, 6.9112, 6.9112, 121.9260426156618, 1362231.079086059, 1362231.079086059, 292852.9278319663]
[2019-03-24 04:05:04,187] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:05:04,190] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 6.2002588e-18 2.5633897e-14 1.0323570e-16 2.5671951e-15], sampled 0.5447313136380205
[2019-03-24 04:05:04,192] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1362231.079086059 W.
[2019-03-24 04:05:19,100] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06494549], dtype=float32), 0.38155282]
[2019-03-24 04:05:19,102] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.64766545, 73.92987931333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8429288466806699, 6.9112, 6.9112, 121.9260426156618, 620556.201773027, 620556.201773027, 167656.3343256133]
[2019-03-24 04:05:19,104] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:05:19,107] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 5.7978860e-20 6.3319440e-16 1.2858272e-18 4.7263668e-17], sampled 0.30722887571525404
[2019-03-24 04:05:28,434] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 04:05:28,725] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 04:05:28,774] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 04:05:28,838] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 04:05:29,007] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 04:05:30,023] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1575000, evaluation results [1575000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 04:05:34,405] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9999988e-01 1.0937139e-10 8.5173461e-08 1.4531181e-09 3.6800021e-08], sum to 1.0000
[2019-03-24 04:05:34,413] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5343
[2019-03-24 04:05:34,421] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 951749.3801234057 W.
[2019-03-24 04:05:34,426] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.16666666666666, 99.00000000000001, 1.0, 2.0, 0.2783304575708296, 1.0, 2.0, 0.2783304575708296, 1.0, 2.0, 0.4431111530429319, 6.9112, 6.9112, 121.94756008, 951749.3801234057, 951749.3801234057, 247895.2201007972], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3471000.0000, 
sim time next is 3471600.0000, 
raw observation next is [24.33333333333333, 98.0, 1.0, 2.0, 0.394602376197239, 1.0, 2.0, 0.394602376197239, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 899529.8222278003, 899529.8222278003, 204712.1856911454], 
processed observation next is [1.0, 0.17391304347826086, 0.45679012345678993, 0.98, 1.0, 1.0, 0.27928854309195117, 1.0, 1.0, 0.27928854309195117, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.321260650795643, 0.321260650795643, 0.3936772801752796], 
reward next is 0.6063, 
noisyNet noise sample is [array([0.53386647], dtype=float32), -0.1667484]. 
=============================================
[2019-03-24 04:05:35,053] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.2865443e-11 1.8041638e-08 9.2549218e-10 4.3397823e-09], sum to 1.0000
[2019-03-24 04:05:35,060] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3072
[2019-03-24 04:05:35,068] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1990627.794138734 W.
[2019-03-24 04:05:35,070] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.5, 79.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.130758759751258, 6.9112, 121.925302814113, 1990627.794138734, 1878194.767412448, 383348.7758154443], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3506400.0000, 
sim time next is 3507000.0000, 
raw observation next is [28.41666666666666, 80.66666666666667, 1.0, 2.0, 0.530997395303784, 1.0, 1.0, 0.530997395303784, 1.0, 2.0, 0.8453651467014757, 6.911200000000001, 6.9112, 121.94756008, 1816727.272829191, 1816727.27282919, 359063.3364235049], 
processed observation next is [1.0, 0.6086956521739131, 0.6080246913580245, 0.8066666666666668, 1.0, 1.0, 0.44166356583783806, 1.0, 0.5, 0.44166356583783806, 1.0, 1.0, 0.8067064333768444, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6488311688675682, 0.6488311688675679, 0.690506416199048], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3385886], dtype=float32), -0.83454156]. 
=============================================
[2019-03-24 04:05:35,081] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[26.201508]
 [25.917326]
 [25.981369]
 [25.988255]
 [25.740946]], R is [[26.20425415]
 [25.94221115]
 [26.03224945]
 [26.07063675]
 [26.02857971]].
[2019-03-24 04:05:36,855] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.00000000e+00 2.00123032e-18 2.46122245e-14 1.16431495e-17
 2.89294336e-16], sum to 1.0000
[2019-03-24 04:05:36,865] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8355
[2019-03-24 04:05:36,872] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.66666666666667, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8058863476942056, 6.911200000000001, 6.9112, 121.9260426156618, 598117.5111781516, 598117.5111781511, 161286.5639695096], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3543600.0000, 
sim time next is 3544200.0000, 
raw observation next is [22.5, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.804404097479824, 6.911200000000001, 6.9112, 121.9260426156618, 597315.7428835197, 597315.7428835194, 160961.2719831718], 
processed observation next is [1.0, 0.0, 0.3888888888888889, 0.915, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7555051218497799, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2133270510298285, 0.21332705102982835, 0.3095409076599458], 
reward next is 0.6905, 
noisyNet noise sample is [array([0.9687483], dtype=float32), 0.5947319]. 
=============================================
[2019-03-24 04:05:37,481] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 6.4391596e-19 8.1869700e-13 3.3962082e-16 4.2825304e-15], sum to 1.0000
[2019-03-24 04:05:37,488] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5649
[2019-03-24 04:05:37,498] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 716635.5188999429 W.
[2019-03-24 04:05:37,502] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.23333333333333, 80.66666666666667, 1.0, 2.0, 0.6271319877292412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716635.5188999429, 716635.5188999429, 162902.7425292053], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3525600.0000, 
sim time next is 3526200.0000, 
raw observation next is [25.85, 81.5, 1.0, 2.0, 0.2059248123642679, 1.0, 1.0, 0.2059248123642679, 1.0, 1.0, 0.3278390077868479, 6.9112, 6.9112, 121.94756008, 704045.0020707952, 704045.0020707952, 222539.7166386347], 
processed observation next is [1.0, 0.8260869565217391, 0.5129629629629631, 0.815, 1.0, 1.0, 0.054672395671747503, 1.0, 0.5, 0.054672395671747503, 1.0, 0.5, 0.15979875973355984, 0.0, 0.0, 0.8096049824067558, 0.25144464359671254, 0.25144464359671254, 0.427960993535836], 
reward next is 0.5720, 
noisyNet noise sample is [array([-1.7659869], dtype=float32), -0.55081725]. 
=============================================
[2019-03-24 04:05:38,912] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.8927229e-21 8.6643576e-15 1.1263842e-19 1.1070036e-17], sum to 1.0000
[2019-03-24 04:05:38,924] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3101
[2019-03-24 04:05:38,931] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.1, 82.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7582584617049645, 6.911200000000001, 6.9112, 121.9260426156618, 565568.7048263152, 565568.7048263147, 153632.1708781121], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3562200.0000, 
sim time next is 3562800.0000, 
raw observation next is [23.06666666666667, 84.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7678619895492503, 6.9112, 6.9112, 121.9260426156618, 571972.5794886055, 571972.5794886055, 155411.2969932032], 
processed observation next is [1.0, 0.21739130434782608, 0.40987654320987665, 0.8466666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7098274869365628, 0.0, 0.0, 0.8094621288201359, 0.20427592124593053, 0.20427592124593053, 0.2988678788330831], 
reward next is 0.7011, 
noisyNet noise sample is [array([-0.625287], dtype=float32), -0.7760202]. 
=============================================
[2019-03-24 04:05:41,853] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.4214637e-27 1.9496738e-18 1.8337858e-26 2.9626247e-21], sum to 1.0000
[2019-03-24 04:05:41,861] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8763
[2019-03-24 04:05:41,868] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.23333333333333, 85.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8534888137226839, 6.911200000000001, 6.9112, 121.9260426156618, 628254.8205768414, 628254.8205768409, 169019.5522461106], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3616800.0000, 
sim time next is 3617400.0000, 
raw observation next is [24.11666666666667, 87.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8633181525841067, 6.9112, 6.9112, 121.9260426156618, 634376.8596708323, 634376.8596708323, 170562.0676410057], 
processed observation next is [1.0, 0.8695652173913043, 0.44876543209876557, 0.8716666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8291476907301334, 0.0, 0.0, 0.8094621288201359, 0.2265631641681544, 0.2265631641681544, 0.3280039762327033], 
reward next is 0.6720, 
noisyNet noise sample is [array([-1.5870897], dtype=float32), -2.208753]. 
=============================================
[2019-03-24 04:05:56,698] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999952e-01 7.6376150e-13 4.9445146e-07 2.3098898e-11 1.0399334e-09], sum to 1.0000
[2019-03-24 04:05:56,705] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4596
[2019-03-24 04:05:56,712] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 807734.5688099293 W.
[2019-03-24 04:05:56,715] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.25, 95.66666666666666, 1.0, 2.0, 0.3543551861727272, 1.0, 2.0, 0.3543551861727272, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 807734.5688099293, 807734.5688099298, 194016.5285850302], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3905400.0000, 
sim time next is 3906000.0000, 
raw observation next is [25.1, 96.0, 1.0, 2.0, 0.3518900278761032, 1.0, 2.0, 0.3518900278761032, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 802112.4259991788, 802112.4259991792, 193379.52017076], 
processed observation next is [0.0, 0.21739130434782608, 0.4851851851851852, 0.96, 1.0, 1.0, 0.22844050937631333, 1.0, 1.0, 0.22844050937631333, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2864687235711353, 0.28646872357113545, 0.3718836926360769], 
reward next is 0.6281, 
noisyNet noise sample is [array([0.8957827], dtype=float32), 1.1739374]. 
=============================================
[2019-03-24 04:05:56,734] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[36.595528]
 [36.755966]
 [36.54036 ]
 [36.84812 ]
 [37.29915 ]], R is [[36.85117722]
 [37.10955811]
 [37.36410522]
 [36.99046326]
 [37.27289581]].
[2019-03-24 04:06:05,808] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9981350e-01 6.9778262e-16 1.8654922e-04 4.8669057e-16 5.1970239e-13], sum to 1.0000
[2019-03-24 04:06:05,814] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4486
[2019-03-24 04:06:05,824] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.75, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7684464938538175, 6.911200000000001, 6.9112, 121.9260426156618, 573388.9975350293, 573388.9975350288, 154612.0151480947], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4060200.0000, 
sim time next is 4060800.0000, 
raw observation next is [20.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7349479674003965, 6.9112, 6.9112, 121.9260426156618, 549149.8090784801, 549149.8090784801, 149327.7167837085], 
processed observation next is [1.0, 0.0, 0.2962962962962963, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6686849592504956, 0.0, 0.0, 0.8094621288201359, 0.1961249318137429, 0.1961249318137429, 0.2871686861225164], 
reward next is 0.7128, 
noisyNet noise sample is [array([-0.41078654], dtype=float32), -0.66313624]. 
=============================================
[2019-03-24 04:06:09,968] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.7904736e-01 5.7720105e-13 2.0952618e-02 6.4745865e-13 5.5015364e-10], sum to 1.0000
[2019-03-24 04:06:09,977] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4859
[2019-03-24 04:06:09,988] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1670650.939746437 W.
[2019-03-24 04:06:10,001] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.96666666666667, 69.0, 1.0, 2.0, 0.8382956428532671, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1670650.939746437, 1670650.939746437, 343967.7985321994], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4108200.0000, 
sim time next is 4108800.0000, 
raw observation next is [28.93333333333334, 68.0, 1.0, 2.0, 0.5549643927534407, 1.0, 1.0, 0.5549643927534407, 1.0, 2.0, 0.883521387191943, 6.911199999999999, 6.9112, 121.94756008, 1898813.876593761, 1898813.876593762, 371384.4618356692], 
processed observation next is [1.0, 0.5652173913043478, 0.6271604938271608, 0.68, 1.0, 1.0, 0.47019570565885793, 1.0, 0.5, 0.47019570565885793, 1.0, 1.0, 0.8544017339899287, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6781478130692004, 0.6781478130692007, 0.7142008881455176], 
reward next is 0.2858, 
noisyNet noise sample is [array([1.2268953], dtype=float32), 1.0893707]. 
=============================================
[2019-03-24 04:06:12,936] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9996793e-01 1.2660365e-16 3.2042255e-05 2.8056643e-17 1.6587896e-12], sum to 1.0000
[2019-03-24 04:06:12,943] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3764
[2019-03-24 04:06:12,949] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [34.16666666666666, 30.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6956278664030625, 6.911200000000001, 6.9112, 121.9260426156618, 518773.3349089645, 518773.334908964, 146482.4182340018], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4210800.0000, 
sim time next is 4211400.0000, 
raw observation next is [34.08333333333334, 32.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7217961535170696, 6.911199999999999, 6.9112, 121.9260426156618, 537215.7981155029, 537215.7981155034, 150279.8094143654], 
processed observation next is [1.0, 0.7391304347826086, 0.8179012345679015, 0.3233333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.652245191896337, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19186278504125104, 0.1918627850412512, 0.2889996334891642], 
reward next is 0.7110, 
noisyNet noise sample is [array([-0.40108278], dtype=float32), 0.8126493]. 
=============================================
[2019-03-24 04:06:13,062] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9829239e-01 1.5293107e-13 1.7075755e-03 5.3185067e-14 1.0937822e-11], sum to 1.0000
[2019-03-24 04:06:13,071] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6078
[2019-03-24 04:06:13,080] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1684724.849894434 W.
[2019-03-24 04:06:13,086] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.63333333333333, 74.33333333333334, 1.0, 2.0, 0.7386775073844585, 1.0, 2.0, 0.7386775073844585, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1684724.849894434, 1684724.849894434, 319065.1799995732], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4179000.0000, 
sim time next is 4179600.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.7134215068977304, 1.0, 2.0, 0.7134215068977304, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1627070.246640606, 1627070.246640606, 309276.4344507738], 
processed observation next is [1.0, 0.391304347826087, 0.5555555555555556, 0.74, 1.0, 1.0, 0.6588351272592029, 1.0, 1.0, 0.6588351272592029, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5810965166573593, 0.5810965166573593, 0.5947623739437958], 
reward next is 0.4052, 
noisyNet noise sample is [array([0.3716044], dtype=float32), -1.411257]. 
=============================================
[2019-03-24 04:06:14,146] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9999845e-01 3.2918625e-24 1.5951225e-06 1.5591957e-23 6.2444704e-18], sum to 1.0000
[2019-03-24 04:06:14,152] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7642
[2019-03-24 04:06:14,156] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9100397414008069, 6.911200000000001, 6.9112, 121.9260426156618, 665145.9805225284, 665145.980522528, 177456.0857843836], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4225200.0000, 
sim time next is 4225800.0000, 
raw observation next is [26.5, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8997014184719833, 6.9112, 6.9112, 121.9260426156618, 659086.9564497498, 659086.9564497498, 175772.4579653326], 
processed observation next is [1.0, 0.9130434782608695, 0.5370370370370371, 0.72, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8746267730899789, 0.0, 0.0, 0.8094621288201359, 0.2353881987320535, 0.2353881987320535, 0.33802395762563964], 
reward next is 0.6620, 
noisyNet noise sample is [array([-0.08295833], dtype=float32), -0.4673131]. 
=============================================
[2019-03-24 04:06:19,484] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9996221e-01 3.2330638e-18 3.7800215e-05 9.5465073e-17 3.2971323e-14], sum to 1.0000
[2019-03-24 04:06:19,493] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5845
[2019-03-24 04:06:19,500] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.6, 46.66666666666667, 1.0, 2.0, 0.5168482493539948, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 601026.6490883322, 601026.6490883317, 144937.9760806187], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4296000.0000, 
sim time next is 4296600.0000, 
raw observation next is [31.45, 48.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8181318608213827, 6.911200000000001, 6.9112, 121.9260426156618, 598648.004586759, 598648.0045867586, 165321.9934864972], 
processed observation next is [1.0, 0.7391304347826086, 0.7203703703703703, 0.48, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.7726648260267283, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21380285878098537, 0.2138028587809852, 0.3179269105509562], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6327329], dtype=float32), -0.5935247]. 
=============================================
[2019-03-24 04:06:21,024] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 04:06:21,025] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:06:21,025] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:06:21,026] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:06:21,028] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:06:21,027] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:06:21,029] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:06:21,031] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:06:21,032] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:06:21,035] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:06:21,036] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:06:21,052] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run65
[2019-03-24 04:06:21,076] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run65
[2019-03-24 04:06:21,101] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run65
[2019-03-24 04:06:21,123] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run65
[2019-03-24 04:06:21,125] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run65
[2019-03-24 04:06:25,795] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0658277], dtype=float32), 0.38324013]
[2019-03-24 04:06:25,798] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.25, 49.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4927830298797717, 6.9112, 6.9112, 121.9260426156618, 351850.673285044, 351850.673285044, 109330.4828566115]
[2019-03-24 04:06:25,800] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:06:25,802] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9987042e-01 2.0261403e-12 1.2950592e-04 1.6049809e-12 5.9419225e-10], sampled 0.11781914360474499
[2019-03-24 04:06:43,593] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0658277], dtype=float32), 0.38324013]
[2019-03-24 04:06:43,594] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.0, 99.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6193808351121892, 6.911200000000001, 6.9112, 121.9260426156618, 461473.827159858, 461473.8271598575, 133660.7768202195]
[2019-03-24 04:06:43,594] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:06:43,596] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9985182e-01 2.5862546e-12 1.4810033e-04 2.0411990e-12 7.2385642e-10], sampled 0.37760979589742305
[2019-03-24 04:08:00,572] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0658277], dtype=float32), 0.38324013]
[2019-03-24 04:08:00,573] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.909591305, 69.26972245500001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5692293643098055, 6.911200000000001, 6.9112, 121.9260426156618, 420815.0573953375, 420815.057395337, 126440.4307540945]
[2019-03-24 04:08:00,574] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:08:00,577] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9987483e-01 1.6967448e-12 1.2515442e-04 1.3337070e-12 5.1681792e-10], sampled 0.7162422582226331
[2019-03-24 04:08:02,149] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8362.7966 2339466266.3334 616.0000
[2019-03-24 04:08:02,230] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8559.5091 2258259887.1738 536.0000
[2019-03-24 04:08:02,302] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7840.8945 2529769441.2957 831.0000
[2019-03-24 04:08:02,379] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.1164 2219171752.2050 543.0000
[2019-03-24 04:08:02,492] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 04:08:03,513] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1600000, evaluation results [1600000.0, 7840.894529799647, 2529769441.295716, 831.0, 8559.509129880978, 2258259887.1737776, 536.0, 8633.116448504034, 2219171752.205027, 543.0, 8362.796641646182, 2339466266.333396, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 04:08:05,617] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9300474e-01 7.4985085e-09 6.9947438e-03 2.0245858e-08 4.6859267e-07], sum to 1.0000
[2019-03-24 04:08:05,625] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4667
[2019-03-24 04:08:05,632] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1846706.423363662 W.
[2019-03-24 04:08:05,638] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.2, 76.83333333333334, 1.0, 2.0, 0.8096259413074792, 1.0, 2.0, 0.8096259413074792, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1846706.423363662, 1846706.423363662, 347748.3352151446], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4356600.0000, 
sim time next is 4357200.0000, 
raw observation next is [28.4, 74.66666666666667, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.130973762458087, 6.9112, 121.9252159578221, 1990737.931079626, 1878194.884591451, 383345.7051507874], 
processed observation next is [1.0, 0.43478260869565216, 0.6074074074074074, 0.7466666666666667, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.02197737624580869, 0.0, 0.8094566406717439, 0.7109778325284379, 0.6707838873540896, 0.7372032791361297], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.251646], dtype=float32), -1.1674665]. 
=============================================
[2019-03-24 04:08:07,406] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.3485837e-19 2.2913722e-08 9.2858406e-19 1.9139296e-15], sum to 1.0000
[2019-03-24 04:08:07,411] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4043
[2019-03-24 04:08:07,414] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 754193.6684694083 W.
[2019-03-24 04:08:07,421] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.8, 79.0, 1.0, 2.0, 0.2205854915612049, 1.0, 1.0, 0.2205854915612049, 1.0, 2.0, 0.3511792865333594, 6.9112, 6.9112, 121.94756008, 754193.6684694083, 754193.6684694083, 227437.0867015084], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4398000.0000, 
sim time next is 4398600.0000, 
raw observation next is [26.5, 79.0, 1.0, 2.0, 0.2157976039037717, 1.0, 2.0, 0.2157976039037717, 1.0, 2.0, 0.3435568134521109, 6.9112, 6.9112, 121.94756008, 737815.7458749774, 737815.7458749774, 225824.4782739401], 
processed observation next is [1.0, 0.9130434782608695, 0.5370370370370371, 0.79, 1.0, 1.0, 0.06642571893306155, 1.0, 1.0, 0.06642571893306155, 1.0, 1.0, 0.17944601681513864, 0.0, 0.0, 0.8096049824067558, 0.26350562352677764, 0.26350562352677764, 0.4342778428345002], 
reward next is 0.5657, 
noisyNet noise sample is [array([-0.31900018], dtype=float32), 0.1984507]. 
=============================================
[2019-03-24 04:08:11,327] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.8413795e-01 3.3756352e-11 1.5861904e-02 3.7493876e-11 1.0814975e-07], sum to 1.0000
[2019-03-24 04:08:11,332] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4395
[2019-03-24 04:08:11,335] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.93333333333333, 91.33333333333334, 1.0, 2.0, 0.296434664857615, 0.0, 2.0, 0.0, 1.0, 1.0, 0.472510669660334, 6.911199999999999, 6.9112, 121.9260426156618, 684607.1223587136, 684607.1223587141, 194110.3531737549], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4498800.0000, 
sim time next is 4499400.0000, 
raw observation next is [23.91666666666667, 90.66666666666666, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9312847075012911, 6.911199999999999, 6.9112, 121.9260426156618, 678815.6525761322, 678815.6525761327, 180664.2789279088], 
processed observation next is [0.0, 0.043478260869565216, 0.4413580246913582, 0.9066666666666666, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9141058843766139, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24243416163433293, 0.2424341616343331, 0.3474313056305939], 
reward next is 0.6526, 
noisyNet noise sample is [array([2.1063538], dtype=float32), -0.54029244]. 
=============================================
[2019-03-24 04:08:13,660] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999869e-01 5.7558784e-19 1.2769553e-06 1.6741908e-15 1.8113665e-13], sum to 1.0000
[2019-03-24 04:08:13,667] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7283
[2019-03-24 04:08:13,670] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.06666666666667, 91.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9220313579167114, 6.9112, 6.9112, 121.9260426156618, 672625.6280909295, 672625.6280909295, 179308.7919581498], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4524600.0000, 
sim time next is 4525200.0000, 
raw observation next is [24.2, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.932094809256069, 6.9112, 6.9112, 121.9260426156618, 678714.7462341245, 678714.7462341245, 180892.3775134531], 
processed observation next is [0.0, 0.391304347826087, 0.45185185185185184, 0.91, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9151185115700863, 0.0, 0.0, 0.8094621288201359, 0.24239812365504448, 0.24239812365504448, 0.34786995675664056], 
reward next is 0.6521, 
noisyNet noise sample is [array([0.59490126], dtype=float32), 2.5931292]. 
=============================================
[2019-03-24 04:08:22,193] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9998939e-01 1.5547848e-10 4.8932607e-06 8.4757531e-08 5.6342733e-06], sum to 1.0000
[2019-03-24 04:08:22,198] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7231
[2019-03-24 04:08:22,205] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 699322.3358504842 W.
[2019-03-24 04:08:22,210] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 99.0, 1.0, 2.0, 0.2043269603458777, 1.0, 2.0, 0.2043269603458777, 1.0, 2.0, 0.3253110594498609, 6.9112, 6.9112, 121.94756008, 699322.3358504842, 699322.3358504842, 222016.3947379247], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4690200.0000, 
sim time next is 4690800.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.3061973119040501, 1.0, 2.0, 0.3061973119040501, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 701356.85438213, 701356.8543821304, 182125.7278081677], 
processed observation next is [1.0, 0.30434782608695654, 0.4074074074074074, 1.0, 1.0, 1.0, 0.17404441893339295, 1.0, 1.0, 0.17404441893339295, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2504845908507607, 0.25048459085076086, 0.35024178424647634], 
reward next is 0.6498, 
noisyNet noise sample is [array([0.47695243], dtype=float32), -0.78834623]. 
=============================================
[2019-03-24 04:08:25,452] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999487e-01 4.9778016e-12 2.9444814e-06 2.7197073e-09 2.1564524e-06], sum to 1.0000
[2019-03-24 04:08:25,458] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2057
[2019-03-24 04:08:25,469] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 766307.5916126712 W.
[2019-03-24 04:08:25,475] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.23333333333333, 86.66666666666666, 1.0, 2.0, 0.2241267847277661, 1.0, 1.0, 0.2241267847277661, 1.0, 2.0, 0.3568171405863916, 6.9112, 6.9112, 121.94756008, 766307.5916126712, 766307.5916126712, 228638.0791783556], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4740000.0000, 
sim time next is 4740600.0000, 
raw observation next is [26.11666666666667, 87.83333333333334, 1.0, 2.0, 0.3376368619433016, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5375288802786543, 6.911199999999999, 6.9112, 121.9260426156618, 769606.8698848773, 769606.8698848778, 205637.1248005256], 
processed observation next is [1.0, 0.8695652173913043, 0.5228395061728397, 0.8783333333333334, 1.0, 1.0, 0.21147245469440668, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.42191110034831786, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2748595963874562, 0.2748595963874564, 0.39545600923178004], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.08870613], dtype=float32), 1.9384067]. 
=============================================
[2019-03-24 04:08:30,792] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999976e-01 1.2596860e-13 1.6250707e-08 3.8628031e-10 2.3850106e-07], sum to 1.0000
[2019-03-24 04:08:30,797] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1322
[2019-03-24 04:08:30,805] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 715265.83909284 W.
[2019-03-24 04:08:30,809] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 86.33333333333334, 1.0, 2.0, 0.2092052439295051, 1.0, 2.0, 0.2092052439295051, 1.0, 2.0, 0.333061561674903, 6.9112, 6.9112, 121.94756008, 715265.83909284, 715265.83909284, 223625.092953805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5041200.0000, 
sim time next is 5041800.0000, 
raw observation next is [25.75, 87.0, 1.0, 2.0, 0.6366864851004029, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 725608.3270865304, 725608.3270865304, 164503.5752178503], 
processed observation next is [0.0, 0.34782608695652173, 0.5092592592592593, 0.87, 1.0, 1.0, 0.567483910833813, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2591458311023323, 0.2591458311023323, 0.31635302926509673], 
reward next is 0.6836, 
noisyNet noise sample is [array([-0.8192545], dtype=float32), 0.7680143]. 
=============================================
[2019-03-24 04:08:34,711] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 9.6026420e-13 6.9983348e-09 6.0682908e-09 5.5982806e-08], sum to 1.0000
[2019-03-24 04:08:34,722] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3499
[2019-03-24 04:08:34,728] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 996306.9115830965 W.
[2019-03-24 04:08:34,731] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.91666666666667, 87.33333333333334, 1.0, 2.0, 0.2913524390157762, 1.0, 1.0, 0.2913524390157762, 1.0, 1.0, 0.4638425715996148, 6.911199999999999, 6.9112, 121.94756008, 996306.9115830965, 996306.911583097, 252765.9009788237], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4911000.0000, 
sim time next is 4911600.0000, 
raw observation next is [28.73333333333333, 88.66666666666667, 1.0, 2.0, 0.4377019741959717, 1.0, 2.0, 0.4377019741959717, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 997843.0027295812, 997843.0027295812, 216791.8273517433], 
processed observation next is [1.0, 0.8695652173913043, 0.619753086419753, 0.8866666666666667, 1.0, 1.0, 0.3305975883285377, 1.0, 1.0, 0.3305975883285377, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3563725009748504, 0.3563725009748504, 0.416907360291814], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.10765], dtype=float32), 0.500874]. 
=============================================
[2019-03-24 04:08:45,861] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9880362e-01 6.0029498e-10 1.1672581e-03 1.2201237e-06 2.8026072e-05], sum to 1.0000
[2019-03-24 04:08:45,866] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5061
[2019-03-24 04:08:45,872] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 812578.1938157878 W.
[2019-03-24 04:08:45,876] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 100.0, 1.0, 2.0, 0.2376526694609389, 1.0, 2.0, 0.2376526694609389, 1.0, 1.0, 0.3783507895889149, 6.9112, 6.9112, 121.94756008, 812578.1938157878, 812578.1938157878, 233289.7834336187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5112000.0000, 
sim time next is 5112600.0000, 
raw observation next is [24.96666666666667, 99.66666666666667, 1.0, 2.0, 0.7104844204609667, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 809757.5629549046, 809757.5629549046, 178138.8422206417], 
processed observation next is [0.0, 0.17391304347826086, 0.48024691358024696, 0.9966666666666667, 1.0, 1.0, 0.6553385957868652, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28919912962675165, 0.28919912962675165, 0.34257469657815715], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.96997094], dtype=float32), 0.60224265]. 
=============================================
[2019-03-24 04:08:47,056] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9962461e-01 8.5325514e-12 3.6568180e-04 2.0131446e-07 9.3572171e-06], sum to 1.0000
[2019-03-24 04:08:47,061] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4350
[2019-03-24 04:08:47,070] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 870668.8619678033 W.
[2019-03-24 04:08:47,074] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.96666666666667, 69.66666666666667, 1.0, 2.0, 0.7638978913552116, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 870668.8619678033, 870668.8619678033, 188601.2688275111], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5156400.0000, 
sim time next is 5157000.0000, 
raw observation next is [30.95, 69.5, 1.0, 2.0, 0.2571655438331951, 1.0, 1.0, 0.2571655438331951, 1.0, 1.0, 0.4094159210794993, 6.9112, 6.9112, 121.94756008, 879334.5670897501, 879334.5670897501, 240180.6201472375], 
processed observation next is [0.0, 0.6956521739130435, 0.7018518518518518, 0.695, 1.0, 1.0, 0.11567326646808943, 1.0, 0.5, 0.11567326646808943, 1.0, 0.5, 0.2617699013493741, 0.0, 0.0, 0.8096049824067558, 0.31404805967491073, 0.31404805967491073, 0.4618858079754567], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.36433238], dtype=float32), 0.30785093]. 
=============================================
[2019-03-24 04:08:47,094] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[34.699814]
 [34.36412 ]
 [34.411297]
 [34.251446]
 [33.974228]], R is [[34.42804337]
 [34.08376312]
 [34.27690887]
 [34.4981308 ]
 [34.76454544]].
[2019-03-24 04:08:47,101] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.2641068e-01 1.9440806e-10 7.2799042e-02 1.7960958e-06 7.8848295e-04], sum to 1.0000
[2019-03-24 04:08:47,109] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9407
[2019-03-24 04:08:47,114] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.5, 68.5, 1.0, 2.0, 0.2585107913708192, 1.0, 1.0, 0.2585107913708192, 1.0, 2.0, 0.4115575989710505, 6.9112, 6.9112, 121.94756008, 883937.068244197, 883937.068244197, 240663.5211292576], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5149800.0000, 
sim time next is 5150400.0000, 
raw observation next is [31.66666666666666, 69.33333333333333, 1.0, 2.0, 0.3966716913216441, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6315142512791427, 6.911199999999999, 6.9112, 121.9260426156618, 904249.7857135521, 904249.7857135525, 223083.8328190855], 
processed observation next is [0.0, 0.6086956521739131, 0.7283950617283949, 0.6933333333333332, 1.0, 1.0, 0.2817520134781477, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.5393928140989284, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32294635204055433, 0.32294635204055444, 0.42900737080593365], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9002708], dtype=float32), 0.6379711]. 
=============================================
[2019-03-24 04:08:47,173] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9923515e-01 5.4535144e-11 7.1777665e-04 1.2899480e-08 4.7045029e-05], sum to 1.0000
[2019-03-24 04:08:47,177] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7751
[2019-03-24 04:08:47,183] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 973987.9835618855 W.
[2019-03-24 04:08:47,191] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 90.66666666666666, 1.0, 2.0, 0.8544893206077296, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 973987.9835618855, 973987.9835618855, 207466.8473783998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5132400.0000, 
sim time next is 5133000.0000, 
raw observation next is [28.66666666666667, 89.83333333333333, 1.0, 2.0, 0.8720971843693287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 994071.290716958, 994071.290716958, 211299.0911629877], 
processed observation next is [0.0, 0.391304347826087, 0.6172839506172841, 0.8983333333333333, 1.0, 1.0, 0.8477347432968199, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.35502546097034215, 0.35502546097034215, 0.40634440608266864], 
reward next is 0.5937, 
noisyNet noise sample is [array([0.01890769], dtype=float32), 0.712474]. 
=============================================
[2019-03-24 04:08:47,202] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[33.445797]
 [33.321655]
 [33.562912]
 [33.084602]
 [33.473213]], R is [[33.66587448]
 [33.329216  ]
 [32.9959259 ]
 [32.66596603]
 [32.33930588]].
[2019-03-24 04:08:50,763] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.0877879e-01 1.8469636e-14 9.1219604e-02 6.8264804e-14 1.6476284e-06], sum to 1.0000
[2019-03-24 04:08:50,775] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9981
[2019-03-24 04:08:50,781] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 1982404.000640085 W.
[2019-03-24 04:08:50,785] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.45, 78.5, 1.0, 2.0, 0.5793681129949159, 1.0, 2.0, 0.5793681129949159, 1.0, 2.0, 0.9223729045900537, 6.911199999999999, 6.9112, 121.94756008, 1982404.000640085, 1982404.000640086, 384248.9237778865], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5221800.0000, 
sim time next is 5222400.0000, 
raw observation next is [27.6, 76.66666666666667, 1.0, 2.0, 0.5657454900584585, 1.0, 2.0, 0.5657454900584585, 1.0, 2.0, 0.9006852452173579, 6.911199999999999, 6.9112, 121.94756008, 1935741.431649729, 1935741.431649729, 377028.1015321306], 
processed observation next is [1.0, 0.43478260869565216, 0.5777777777777778, 0.7666666666666667, 1.0, 1.0, 0.48303034530768874, 1.0, 1.0, 0.48303034530768874, 1.0, 1.0, 0.8758565565216975, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.691336225589189, 0.691336225589189, 0.7250540414079435], 
reward next is 0.2749, 
noisyNet noise sample is [array([-1.1854888], dtype=float32), 0.05598136]. 
=============================================
[2019-03-24 04:08:51,187] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.1116711e-01 5.9378619e-10 5.8883095e-01 1.5637798e-07 1.8470510e-06], sum to 1.0000
[2019-03-24 04:08:51,192] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8887
[2019-03-24 04:08:51,196] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.86666666666667, 94.66666666666667, 1.0, 2.0, 0.376664625907791, 1.0, 1.0, 0.376664625907791, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 858616.2828746102, 858616.2828746106, 199874.9414324285], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5199600.0000, 
sim time next is 5200200.0000, 
raw observation next is [23.8, 95.0, 1.0, 2.0, 0.3685300940812234, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5867983566154878, 6.911199999999999, 6.9112, 121.9260426156618, 842425.7353278663, 842425.7353278667, 214551.0295026737], 
processed observation next is [1.0, 0.17391304347826086, 0.43703703703703706, 0.95, 1.0, 1.0, 0.2482501120014564, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4834979457693598, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30086633404566654, 0.3008663340456667, 0.41259813365898784], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.87766296], dtype=float32), -1.4805022]. 
=============================================
[2019-03-24 04:08:51,873] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.3831809e-03 1.0028022e-11 9.9461681e-01 2.7171693e-10 2.0033259e-08], sum to 1.0000
[2019-03-24 04:08:51,879] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7396
[2019-03-24 04:08:51,886] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 2046446.411634405 W.
[2019-03-24 04:08:51,889] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.98333333333333, 78.0, 1.0, 2.0, 0.8970949649177583, 1.0, 2.0, 0.8970949649177583, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156281, 2046446.411634405, 2046446.411634405, 385509.2516737109], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5226600.0000, 
sim time next is 5227200.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.6134502727932495, 1.0, 2.0, 0.6134502727932495, 1.0, 1.0, 0.9766328129674539, 6.9112, 6.9112, 121.94756008, 2099158.801346219, 2099158.801346219, 402752.6854369647], 
processed observation next is [1.0, 0.5217391304347826, 0.5925925925925926, 0.79, 1.0, 1.0, 0.539821753325297, 1.0, 1.0, 0.539821753325297, 1.0, 0.5, 0.9707910162093172, 0.0, 0.0, 0.8096049824067558, 0.749699571909364, 0.749699571909364, 0.774524395071086], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4705868], dtype=float32), 0.6888099]. 
=============================================
[2019-03-24 04:08:54,673] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 04:08:54,674] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:08:54,675] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:08:54,677] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:08:54,677] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:08:54,678] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:08:54,678] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:08:54,679] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:08:54,681] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:08:54,682] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:08:54,682] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:08:54,708] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run66
[2019-03-24 04:08:54,731] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run66
[2019-03-24 04:08:54,753] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run66
[2019-03-24 04:08:54,754] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run66
[2019-03-24 04:08:54,755] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run66
[2019-03-24 04:08:59,471] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06413845], dtype=float32), 0.3843506]
[2019-03-24 04:08:59,472] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.8, 31.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5837716547971918, 6.911200000000001, 6.9112, 121.9260426156618, 424091.9421314274, 424091.9421314269, 124289.7266460901]
[2019-03-24 04:08:59,473] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:08:59,475] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.4630406e-01 1.1688362e-12 1.5369600e-01 1.1246464e-12 6.5894085e-10], sampled 0.6505362639120815
[2019-03-24 04:09:16,138] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06413845], dtype=float32), 0.3843506]
[2019-03-24 04:09:16,139] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.55867267, 77.972270025, 1.0, 1.0, 0.2287799814406743, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3729283233911604, 6.911199999999999, 6.9112, 121.9260426156618, 556770.0199386394, 556770.0199386398, 175251.9819449542]
[2019-03-24 04:09:16,140] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:09:16,144] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.9180415e-01 3.7567226e-13 4.0819594e-01 2.1861420e-13 2.7161393e-10], sampled 0.1516630378930176
[2019-03-24 04:09:19,546] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06413845], dtype=float32), 0.3843506]
[2019-03-24 04:09:19,547] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.16666666666666, 37.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6867108964823335, 6.911200000000001, 6.9112, 121.9260426156618, 512960.3099243772, 512960.3099243768, 144341.8673409155]
[2019-03-24 04:09:19,548] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:09:19,550] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.8907224e-01 5.2955009e-13 1.1092781e-01 5.4339172e-13 3.5224465e-10], sampled 0.45782574010626
[2019-03-24 04:09:21,492] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06413845], dtype=float32), 0.3843506]
[2019-03-24 04:09:21,493] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.27051419833333, 93.41129273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8271006168098368, 6.911200000000001, 6.9112, 121.9260426156618, 609432.1007409627, 609432.1007409622, 165517.891062007]
[2019-03-24 04:09:21,494] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:09:21,496] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.2195264e-01 3.3075040e-13 1.7804730e-01 2.9695249e-13 2.5437305e-10], sampled 0.3566291743189065
[2019-03-24 04:09:33,773] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06413845], dtype=float32), 0.3843506]
[2019-03-24 04:09:33,774] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.0, 52.0, 1.0, 2.0, 0.8583193472905347, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1693506.747208496, 1693506.747208496, 348112.5300138514]
[2019-03-24 04:09:33,775] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:09:33,778] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1826054e-01 3.6458302e-12 8.8173944e-01 8.4745736e-13 1.3272669e-09], sampled 0.5898728800494466
[2019-03-24 04:09:47,796] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06413845], dtype=float32), 0.3843506]
[2019-03-24 04:09:47,798] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 70.0, 1.0, 2.0, 0.2808534310834253, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4477598121582601, 6.911199999999999, 6.9112, 121.9260426156618, 649425.2337541243, 649425.2337541247, 189980.3419473792]
[2019-03-24 04:09:47,803] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:09:47,806] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.4137368e-01 3.4539674e-12 5.5862635e-01 1.8478129e-12 1.5261130e-09], sampled 0.3554459539726703
[2019-03-24 04:10:35,810] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7055.8268 2429160438.0017 302.0000
[2019-03-24 04:10:36,121] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6974.1909 2469390110.5251 283.0000
[2019-03-24 04:10:36,335] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 6739.1700 2656916053.5498 419.0000
[2019-03-24 04:10:36,407] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7116.6555 2369362986.2475 228.0000
[2019-03-24 04:10:36,440] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7036.9827 2403884748.5958 205.0000
[2019-03-24 04:10:37,454] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1625000, evaluation results [1625000.0, 6739.170031887662, 2656916053.5497727, 419.0, 7036.982679935017, 2403884748.5957785, 205.0, 7116.655543163889, 2369362986.247498, 228.0, 6974.1909189373155, 2469390110.525057, 283.0, 7055.826756054838, 2429160438.0016527, 302.0]
[2019-03-24 04:10:39,459] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.14840865e-01 3.48569524e-12 3.85159224e-01 1.22262426e-11
 1.42442245e-08], sum to 1.0000
[2019-03-24 04:10:39,463] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2794
[2019-03-24 04:10:39,470] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1196443.437355873 W.
[2019-03-24 04:10:39,475] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 69.0, 1.0, 2.0, 0.5192500714154109, 0.0, 2.0, 0.0, 1.0, 2.0, 0.827380213138587, 6.9112, 6.9112, 121.9260426156618, 1196443.437355873, 1196443.437355873, 263566.8531635215], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5317200.0000, 
sim time next is 5317800.0000, 
raw observation next is [27.2, 68.0, 1.0, 2.0, 0.3163502892503973, 1.0, 1.0, 0.3163502892503973, 1.0, 2.0, 0.5036399632962768, 6.911199999999999, 6.9112, 121.94756008, 1081849.733638942, 1081849.733638943, 262380.8175583977], 
processed observation next is [1.0, 0.5652173913043478, 0.5629629629629629, 0.68, 1.0, 1.0, 0.18613129672666348, 1.0, 0.5, 0.18613129672666348, 1.0, 1.0, 0.379549954120346, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3863749048710507, 0.38637490487105103, 0.504578495304611], 
reward next is 0.4954, 
noisyNet noise sample is [array([-1.1635416], dtype=float32), -0.044040732]. 
=============================================
[2019-03-24 04:10:49,223] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0567575e-01 3.5945388e-10 8.9432430e-01 1.0565193e-10 1.1185071e-09], sum to 1.0000
[2019-03-24 04:10:49,230] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6970
[2019-03-24 04:10:49,235] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 2625826.498239643 W.
[2019-03-24 04:10:49,239] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.05, 64.0, 1.0, 2.0, 0.9075420004399943, 1.0, 2.0, 0.7671356621964318, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2625826.498239643, 2625826.498239643, 489666.2006351274], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5494200.0000, 
sim time next is 5494800.0000, 
raw observation next is [32.7, 65.0, 1.0, 2.0, 0.895544121006121, 1.0, 2.0, 0.7611367224794953, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2605262.777051911, 2605262.77705191, 485919.3978088771], 
processed observation next is [1.0, 0.6086956521739131, 0.7666666666666667, 0.65, 1.0, 1.0, 0.875647763102525, 1.0, 1.0, 0.7156389553327325, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.9304509918042541, 0.9304509918042535, 0.9344603804016868], 
reward next is 0.0655, 
noisyNet noise sample is [array([1.0623846], dtype=float32), 1.6158526]. 
=============================================
[2019-03-24 04:10:49,690] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5280891e-02 7.4119011e-10 9.7471911e-01 6.9953097e-12 2.2815319e-10], sum to 1.0000
[2019-03-24 04:10:49,699] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4461
[2019-03-24 04:10:49,707] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 2045052.337828195 W.
[2019-03-24 04:10:49,712] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.3, 88.0, 1.0, 2.0, 0.896484547669945, 1.0, 2.0, 0.896484547669945, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156555, 2045052.337828195, 2045052.337828195, 385238.1721625357], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5475600.0000, 
sim time next is 5476200.0000, 
raw observation next is [28.43333333333334, 87.50000000000001, 1.0, 2.0, 0.9427085924628801, 1.0, 2.0, 0.9427085924628801, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2150625.188877311, 2150625.188877311, 406254.3825476666], 
processed observation next is [1.0, 0.391304347826087, 0.6086419753086423, 0.8750000000000001, 1.0, 1.0, 0.9317959434081906, 1.0, 1.0, 0.9317959434081906, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7680804245990397, 0.7680804245990397, 0.781258427976282], 
reward next is 0.2187, 
noisyNet noise sample is [array([-0.7182303], dtype=float32), -0.02288365]. 
=============================================
[2019-03-24 04:10:55,830] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 4.6740787e-19 3.0985371e-11 4.0130174e-19 1.6149472e-21], sum to 1.0000
[2019-03-24 04:10:55,837] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4855
[2019-03-24 04:10:55,845] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 757376.3786174798 W.
[2019-03-24 04:10:55,850] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.46666666666667, 91.83333333333333, 1.0, 2.0, 0.3322738308352723, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5289907600929423, 6.9112, 6.9112, 121.9260426156618, 757376.3786174798, 757376.3786174798, 204121.8965015901], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5597400.0000, 
sim time next is 5598000.0000, 
raw observation next is [25.5, 92.0, 1.0, 2.0, 0.335689129042689, 1.0, 1.0, 0.335689129042689, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 765165.0065467332, 765165.0065467337, 189246.0786051842], 
processed observation next is [1.0, 0.8260869565217391, 0.5, 0.92, 1.0, 1.0, 0.20915372505082022, 1.0, 0.5, 0.20915372505082022, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2732732166238333, 0.27327321662383347, 0.36393476654843115], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3903492], dtype=float32), 0.86485887]. 
=============================================
[2019-03-24 04:10:55,867] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[45.586662]
 [45.51896 ]
 [45.672325]
 [45.94711 ]
 [46.04711 ]], R is [[45.08520126]
 [45.24180603]
 [45.43014145]
 [45.61669159]
 [45.16052628]].
[2019-03-24 04:10:59,741] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 4.5622385e-25 8.6344601e-16 2.4883557e-28 1.3893514e-25], sum to 1.0000
[2019-03-24 04:10:59,747] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8081
[2019-03-24 04:10:59,750] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.41666666666667, 96.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8528615554452358, 6.9112, 6.9112, 121.9260426156618, 630281.672019112, 630281.672019112, 168200.3276392806], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5706600.0000, 
sim time next is 5707200.0000, 
raw observation next is [22.33333333333334, 96.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8478120408323412, 6.911199999999999, 6.9112, 121.9260426156618, 626979.9318578761, 626979.9318578766, 167415.0788413051], 
processed observation next is [0.0, 0.043478260869565216, 0.38271604938271625, 0.9633333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8097650510404264, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22392140423495577, 0.22392140423495593, 0.3219520746948175], 
reward next is 0.6780, 
noisyNet noise sample is [array([0.67724836], dtype=float32), 0.45109195]. 
=============================================
[2019-03-24 04:11:01,374] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 3.8572217e-26 3.5039030e-19 3.8882156e-26 4.0479504e-26], sum to 1.0000
[2019-03-24 04:11:01,380] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7036
[2019-03-24 04:11:01,386] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 722789.8074889696 W.
[2019-03-24 04:11:01,391] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.76666666666667, 90.33333333333333, 1.0, 2.0, 0.3171072674118873, 1.0, 1.0, 0.3171072674118873, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 722789.8074889696, 722789.8074889701, 184616.5278097823], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5695800.0000, 
sim time next is 5696400.0000, 
raw observation next is [24.53333333333333, 90.66666666666667, 1.0, 2.0, 0.2077227224044301, 1.0, 2.0, 0.2077227224044301, 1.0, 1.0, 0.3307013391246282, 6.9112, 6.9112, 121.94756008, 710194.7992617006, 710194.7992617006, 223133.8342164006], 
processed observation next is [0.0, 0.9565217391304348, 0.46419753086419746, 0.9066666666666667, 1.0, 1.0, 0.05681276476717869, 1.0, 1.0, 0.05681276476717869, 1.0, 0.5, 0.1633766739057852, 0.0, 0.0, 0.8096049824067558, 0.25364099973632165, 0.25364099973632165, 0.4291035273392319], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.60298645], dtype=float32), -0.7008609]. 
=============================================
[2019-03-24 04:11:03,355] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 7.0172767e-31 1.7531699e-20 2.4095770e-31 2.1432694e-31], sum to 1.0000
[2019-03-24 04:11:03,363] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9179
[2019-03-24 04:11:03,370] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.65, 67.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7741931907247641, 6.911200000000001, 6.9112, 121.9260426156618, 576279.5072668893, 576279.5072668889, 156454.0255531305], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5743800.0000, 
sim time next is 5744400.0000, 
raw observation next is [25.76666666666667, 66.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7726497176904982, 6.911199999999999, 6.9112, 121.9260426156618, 575209.0972855433, 575209.0972855438, 156215.9256901938], 
processed observation next is [0.0, 0.4782608695652174, 0.5098765432098766, 0.6666666666666665, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7158121471131226, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20543182045912262, 0.20543182045912278, 0.30041524171191114], 
reward next is 0.6996, 
noisyNet noise sample is [array([1.124248], dtype=float32), -0.060475543]. 
=============================================
[2019-03-24 04:11:05,294] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.9658383e-27 9.1408259e-20 1.9352906e-26 1.3058389e-30], sum to 1.0000
[2019-03-24 04:11:05,299] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1204
[2019-03-24 04:11:05,304] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.23333333333333, 79.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7775908499133057, 6.911199999999999, 6.9112, 121.9260426156618, 580352.3454525676, 580352.345452568, 155541.867388561], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5816400.0000, 
sim time next is 5817000.0000, 
raw observation next is [23.36666666666667, 78.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7858274873278025, 6.9112, 6.9112, 121.9260426156618, 586468.9733059745, 586468.9733059745, 156569.5674088393], 
processed observation next is [1.0, 0.30434782608695654, 0.4209876543209878, 0.7883333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.732284359159753, 0.0, 0.0, 0.8094621288201359, 0.20945320475213375, 0.20945320475213375, 0.3010953219400756], 
reward next is 0.6989, 
noisyNet noise sample is [array([-0.00116194], dtype=float32), 0.21786161]. 
=============================================
[2019-03-24 04:11:05,319] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[60.927612]
 [61.05156 ]
 [61.1267  ]
 [61.15432 ]
 [61.53444 ]], R is [[60.96450424]
 [61.05574036]
 [61.14825058]
 [61.23360062]
 [61.29230881]].
[2019-03-24 04:11:05,869] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.3077028e-24 2.4894260e-15 9.7405740e-27 1.2516315e-25], sum to 1.0000
[2019-03-24 04:11:05,876] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0075
[2019-03-24 04:11:05,879] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.96666666666667, 81.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7958040123765022, 6.911199999999999, 6.9112, 121.9260426156618, 594019.734441463, 594019.7344414635, 157647.5823570682], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5815200.0000, 
sim time next is 5815800.0000, 
raw observation next is [23.1, 80.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7683796279139473, 6.911199999999999, 6.9112, 121.9260426156618, 573508.3692667872, 573508.3692667877, 154403.8050559776], 
processed observation next is [1.0, 0.30434782608695654, 0.41111111111111115, 0.805, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7104745348924341, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20482441759528114, 0.2048244175952813, 0.29693039433841845], 
reward next is 0.7031, 
noisyNet noise sample is [array([1.3058393], dtype=float32), 1.0059505]. 
=============================================
[2019-03-24 04:11:08,287] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 8.2239663e-36 2.0973622e-23 3.4459485e-35 2.1525122e-38], sum to 1.0000
[2019-03-24 04:11:08,298] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8227
[2019-03-24 04:11:08,301] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.1, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6942090664087721, 6.9112, 6.9112, 121.9260426156618, 518759.2091526674, 518759.2091526674, 143890.5608266026], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5864400.0000, 
sim time next is 5865000.0000, 
raw observation next is [23.91666666666667, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6923326153529296, 6.9112, 6.9112, 121.9260426156618, 517346.2829370839, 517346.2829370839, 143607.0259339023], 
processed observation next is [1.0, 0.9130434782608695, 0.4413580246913582, 0.69, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6154157691911619, 0.0, 0.0, 0.8094621288201359, 0.18476652962038712, 0.18476652962038712, 0.2761673575651967], 
reward next is 0.7238, 
noisyNet noise sample is [array([-1.1322163], dtype=float32), -1.6031369]. 
=============================================
[2019-03-24 04:11:08,314] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.198494]
 [71.144165]
 [71.335594]
 [71.51226 ]
 [71.55606 ]], R is [[71.23622894]
 [71.24715424]
 [71.25743866]
 [71.26674652]
 [71.27459717]].
[2019-03-24 04:11:18,054] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.1575423e-27 1.6094015e-19 1.5363877e-26 3.7767871e-28], sum to 1.0000
[2019-03-24 04:11:18,062] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1092
[2019-03-24 04:11:18,068] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1635824.999627359 W.
[2019-03-24 04:11:18,073] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.71666666666667, 66.66666666666666, 1.0, 2.0, 0.8075244801571284, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9974667171866431, 6.911199999999999, 6.9112, 121.9260426156618, 1635824.999627359, 1635824.99962736, 337681.0254034137], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6004200.0000, 
sim time next is 6004800.0000, 
raw observation next is [28.0, 66.0, 1.0, 2.0, 0.4511407724354976, 1.0, 1.0, 0.4511407724354976, 1.0, 2.0, 0.7182308023465245, 6.9112, 6.9112, 121.94756008, 1543268.386950526, 1543268.386950526, 320208.634817885], 
processed observation next is [1.0, 0.5217391304347826, 0.5925925925925926, 0.66, 1.0, 1.0, 0.3465961576613067, 1.0, 0.5, 0.3465961576613067, 1.0, 1.0, 0.6477885029331556, 0.0, 0.0, 0.8096049824067558, 0.5511672810537592, 0.5511672810537592, 0.6157858361882403], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.25562483], dtype=float32), 0.1787608]. 
=============================================
[2019-03-24 04:11:21,042] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.8137046e-22 1.6644691e-15 3.4982333e-23 2.6297283e-23], sum to 1.0000
[2019-03-24 04:11:21,053] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7474
[2019-03-24 04:11:21,062] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2051591.568224061 W.
[2019-03-24 04:11:21,070] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.46666666666667, 51.83333333333333, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.249685364173958, 6.9112, 121.9246284646222, 2051591.568224061, 1878258.818700048, 382914.6696287291], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6097800.0000, 
sim time next is 6098400.0000, 
raw observation next is [30.6, 51.0, 1.0, 2.0, 0.8326253610008497, 1.0, 1.0, 0.8326253610008497, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9258387857185, 1899222.449094986, 1899222.449094985, 357418.5381842745], 
processed observation next is [1.0, 0.6086956521739131, 0.688888888888889, 0.51, 1.0, 1.0, 0.800744477381964, 1.0, 0.5, 0.800744477381964, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094607756012806, 0.6782937318196379, 0.6782937318196375, 0.6873433426620663], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.20468158], dtype=float32), -0.14555064]. 
=============================================
[2019-03-24 04:11:22,821] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.2307757e-22 6.9468590e-15 6.5570358e-23 2.1559226e-23], sum to 1.0000
[2019-03-24 04:11:22,828] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3618
[2019-03-24 04:11:22,834] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2029728.469682505 W.
[2019-03-24 04:11:22,838] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.4, 53.0, 1.0, 2.0, 0.8897746870171834, 1.0, 2.0, 0.8897746870171834, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2029728.469682505, 2029728.469682505, 382245.7046776348], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6102000.0000, 
sim time next is 6102600.0000, 
raw observation next is [30.35, 53.16666666666667, 1.0, 2.0, 0.5371041715520855, 1.0, 2.0, 0.5371041715520855, 1.0, 1.0, 0.8550873333725891, 6.911200000000003, 6.9112, 121.94756008, 1837642.173027616, 1837642.173027614, 362173.2627337011], 
processed observation next is [1.0, 0.6521739130434783, 0.6796296296296297, 0.5316666666666667, 1.0, 1.0, 0.4489335375620065, 1.0, 1.0, 0.4489335375620065, 1.0, 0.5, 0.8188591667157363, 2.6645352591003756e-16, 0.0, 0.8096049824067558, 0.6563007760812914, 0.6563007760812907, 0.696487043718656], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.33635616], dtype=float32), -0.24506536]. 
=============================================
[2019-03-24 04:11:25,211] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 8.4687533e-22 1.9291938e-12 2.0407080e-19 2.2229351e-22], sum to 1.0000
[2019-03-24 04:11:25,211] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1180
[2019-03-24 04:11:25,218] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1573817.021057046 W.
[2019-03-24 04:11:25,220] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.4, 57.0, 1.0, 2.0, 0.4600618314403826, 1.0, 2.0, 0.4600618314403826, 1.0, 2.0, 0.7324334188209097, 6.9112, 6.9112, 121.94756008, 1573817.021057046, 1573817.021057046, 324391.0048794752], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6183000.0000, 
sim time next is 6183600.0000, 
raw observation next is [29.53333333333333, 56.33333333333333, 1.0, 2.0, 0.6815239725842903, 1.0, 2.0, 0.6815239725842903, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1554255.628007244, 1554255.628007245, 297228.6732821674], 
processed observation next is [1.0, 0.5652173913043478, 0.6493827160493827, 0.5633333333333332, 1.0, 1.0, 0.6208618721241551, 1.0, 1.0, 0.6208618721241551, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5550912957168729, 0.5550912957168732, 0.5715936024657066], 
reward next is 0.4284, 
noisyNet noise sample is [array([-0.7406356], dtype=float32), -0.8029558]. 
=============================================
[2019-03-24 04:11:25,840] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.00000000e+00 4.69482440e-27 1.04204276e-16 1.40310429e-24
 4.22124401e-27], sum to 1.0000
[2019-03-24 04:11:25,846] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4089
[2019-03-24 04:11:25,852] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1772037.649808415 W.
[2019-03-24 04:11:25,855] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.9, 53.5, 1.0, 2.0, 0.7769223842187672, 1.0, 2.0, 0.7769223842187672, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260425887425, 1772037.649808415, 1772037.649808415, 334308.9537333043], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6190200.0000, 
sim time next is 6190800.0000, 
raw observation next is [29.9, 53.33333333333333, 1.0, 2.0, 1.011617465888198, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9930414314394369, 6.9112, 6.9112, 121.9260426156536, 1874368.559398432, 1874368.559398432, 381498.2276569877], 
processed observation next is [1.0, 0.6521739130434783, 0.6629629629629629, 0.5333333333333333, 1.0, 1.0, 1.0138303165335691, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9913017892992961, 0.0, 0.0, 0.8094621288200815, 0.6694173426422971, 0.6694173426422971, 0.7336504378018994], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.74366426], dtype=float32), 1.950352]. 
=============================================
[2019-03-24 04:11:28,417] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 04:11:28,418] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:11:28,421] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:11:28,421] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:11:28,423] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:11:28,424] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:11:28,426] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:11:28,425] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:11:28,429] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:11:28,428] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:11:28,430] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:11:28,450] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run67
[2019-03-24 04:11:28,450] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run67
[2019-03-24 04:11:28,496] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run67
[2019-03-24 04:11:28,526] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run67
[2019-03-24 04:11:28,549] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run67
[2019-03-24 04:11:49,320] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06452199], dtype=float32), 0.38553038]
[2019-03-24 04:11:49,321] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.63512206, 80.891397345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6814090587248047, 6.911199999999999, 6.9112, 121.9260426156618, 509060.5774406758, 509060.5774406762, 143606.6136796438]
[2019-03-24 04:11:49,323] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:11:49,324] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 9.0982572e-25 2.7984778e-15 2.0225070e-23 1.0157353e-24], sampled 0.009995209163178198
[2019-03-24 04:11:55,275] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06452199], dtype=float32), 0.38553038]
[2019-03-24 04:11:55,275] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.47676904666667, 85.74444219666667, 1.0, 1.0, 0.658580247876261, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9259309639826, 771529.8581291159, 771529.8581291159, 169445.5933952368]
[2019-03-24 04:11:55,276] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:11:55,280] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.4798445e-23 1.5114612e-14 2.8310665e-22 1.6347924e-23], sampled 0.3818185447785938
[2019-03-24 04:11:55,281] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 771529.8581291159 W.
[2019-03-24 04:12:15,854] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06452199], dtype=float32), 0.38553038]
[2019-03-24 04:12:15,855] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.52191794, 89.4781961, 1.0, 2.0, 0.8050766171034216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 917631.2885127498, 917631.2885127498, 196997.2271517232]
[2019-03-24 04:12:15,856] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:12:15,857] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 6.3075804e-28 3.2811102e-17 2.0531315e-26 7.0665803e-28], sampled 0.9794311888893742
[2019-03-24 04:12:15,858] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 917631.2885127498 W.
[2019-03-24 04:12:20,400] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06452199], dtype=float32), 0.38553038]
[2019-03-24 04:12:20,402] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.23333333333333, 83.66666666666667, 1.0, 2.0, 0.7905122716950072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 901020.9992559759, 901020.9992559747, 193992.8524666233]
[2019-03-24 04:12:20,402] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:12:20,404] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 4.2675271e-30 1.6033603e-18 1.7979585e-28 4.7940117e-30], sampled 0.7107351677026507
[2019-03-24 04:12:20,407] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 901020.9992559759 W.
[2019-03-24 04:12:25,281] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06452199], dtype=float32), 0.38553038]
[2019-03-24 04:12:25,283] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.18118989, 97.85880874, 1.0, 2.0, 0.6531497768476673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 744380.0492941174, 744380.0492941174, 167462.0790688212]
[2019-03-24 04:12:25,285] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:12:25,289] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 9.8741604e-29 1.0688350e-17 3.5406504e-27 1.1056173e-28], sampled 0.7000890160230472
[2019-03-24 04:12:25,290] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 744380.0492941174 W.
[2019-03-24 04:12:31,276] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06452199], dtype=float32), 0.38553038]
[2019-03-24 04:12:31,277] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.33333333333334, 92.33333333333334, 1.0, 2.0, 0.8147154222686697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 928624.3143419351, 928624.3143419351, 199006.4425251452]
[2019-03-24 04:12:31,279] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:12:31,284] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.4770715e-28 1.3689760e-17 5.1860821e-27 1.6567740e-28], sampled 0.3195415169357001
[2019-03-24 04:12:31,285] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 928624.3143419351 W.
[2019-03-24 04:12:34,233] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06452199], dtype=float32), 0.38553038]
[2019-03-24 04:12:34,234] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.16666666666667, 66.16666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.565205944537833, 6.9112, 121.9237205733368, 2213331.877901957, 1878428.758154403, 381790.2591735397]
[2019-03-24 04:12:34,236] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:12:34,238] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.5760300e-25 1.0835164e-15 3.7347310e-24 1.7987433e-25], sampled 0.25678159288305247
[2019-03-24 04:12:34,239] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2213331.877901957 W.
[2019-03-24 04:12:58,435] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06452199], dtype=float32), 0.38553038]
[2019-03-24 04:12:58,437] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.73333333333333, 65.33333333333334, 1.0, 2.0, 0.4897992734405097, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7829344697868872, 6.911199999999999, 6.9112, 121.9260426156618, 1147062.019841823, 1147062.019841823, 252817.0569729831]
[2019-03-24 04:12:58,439] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:12:58,442] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 4.1769781e-23 3.0647180e-14 7.4675785e-22 4.7218472e-23], sampled 0.5586484994904495
[2019-03-24 04:12:58,443] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1147062.019841823 W.
[2019-03-24 04:13:10,054] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 04:13:10,185] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 04:13:10,197] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 04:13:10,306] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 04:13:10,460] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 04:13:11,479] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1650000, evaluation results [1650000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 04:13:12,732] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 7.1112213e-22 2.5268199e-12 5.6407821e-22 3.5443215e-22], sum to 1.0000
[2019-03-24 04:13:12,739] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8322
[2019-03-24 04:13:12,743] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.06666666666667, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.830612830151478, 6.911199999999999, 6.9112, 121.9260426156618, 614536.7058852335, 614536.7058852339, 165162.0366182472], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6248400.0000, 
sim time next is 6249000.0000, 
raw observation next is [24.18333333333333, 82.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8354115024651093, 6.9112, 6.9112, 121.9260426156618, 617793.9123620167, 617793.9123620167, 165863.8036262137], 
processed observation next is [0.0, 0.30434782608695654, 0.45123456790123445, 0.825, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7942643780813865, 0.0, 0.0, 0.8094621288201359, 0.22064068298643455, 0.22064068298643455, 0.31896885312733403], 
reward next is 0.6810, 
noisyNet noise sample is [array([-0.39112934], dtype=float32), -1.1080456]. 
=============================================
[2019-03-24 04:13:12,758] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[60.82123 ]
 [60.838383]
 [60.872395]
 [60.903454]
 [60.957302]], R is [[60.88443375]
 [60.95796967]
 [61.03210449]
 [61.10674286]
 [61.18174362]].
[2019-03-24 04:13:18,843] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.9599350e-25 1.2307522e-13 1.3779158e-22 3.7867075e-23], sum to 1.0000
[2019-03-24 04:13:18,848] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6036
[2019-03-24 04:13:18,859] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 765115.4818889557 W.
[2019-03-24 04:13:18,864] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.55, 57.5, 1.0, 2.0, 0.2237782948209235, 1.0, 2.0, 0.2237782948209235, 1.0, 2.0, 0.3562623333051743, 6.9112, 6.9112, 121.94756008, 765115.4818889557, 765115.4818889557, 228519.5813248521], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6359400.0000, 
sim time next is 6360000.0000, 
raw observation next is [31.6, 57.33333333333334, 1.0, 2.0, 0.3429152801696215, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5459322940010359, 6.9112, 6.9112, 121.9260426156618, 781644.5904760902, 781644.5904760902, 207140.0212528948], 
processed observation next is [0.0, 0.6086956521739131, 0.725925925925926, 0.5733333333333335, 1.0, 1.0, 0.21775628591621604, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.4324153675012949, 0.0, 0.0, 0.8094621288201359, 0.2791587823128894, 0.2791587823128894, 0.3983461947171054], 
reward next is 0.6017, 
noisyNet noise sample is [array([1.4556979], dtype=float32), -0.77683675]. 
=============================================
[2019-03-24 04:13:18,879] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[54.41851 ]
 [53.840538]
 [54.117012]
 [53.309113]
 [53.455204]], R is [[54.33103561]
 [54.3482666 ]
 [54.36552811]
 [54.42645645]
 [53.8821907 ]].
[2019-03-24 04:13:35,666] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 5.6028792e-25 1.2750595e-14 3.3137103e-19 1.6002643e-23], sum to 1.0000
[2019-03-24 04:13:35,673] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4072
[2019-03-24 04:13:35,683] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5333452492658034, 6.9112, 6.9112, 121.9260426156618, 384048.7806625417, 384048.7806625417, 118785.6253353773], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6680400.0000, 
sim time next is 6681000.0000, 
raw observation next is [23.0, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5358588140689458, 6.911200000000001, 6.9112, 121.9260426156618, 386463.1299407833, 386463.1299407828, 119202.8111124553], 
processed observation next is [1.0, 0.30434782608695654, 0.4074074074074074, 0.515, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.41982351758618214, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13802254640742262, 0.13802254640742243, 0.2292361752162602], 
reward next is 0.7708, 
noisyNet noise sample is [array([-1.6848242], dtype=float32), 0.3752963]. 
=============================================
[2019-03-24 04:13:35,716] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[62.216564]
 [62.28648 ]
 [62.32995 ]
 [62.334698]
 [62.57408 ]], R is [[62.31480026]
 [62.46321869]
 [62.61005783]
 [62.75379944]
 [62.8863945 ]].
[2019-03-24 04:13:56,920] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 5.0069800e-21 7.2365441e-10 7.3875152e-20 9.3386946e-20], sum to 1.0000
[2019-03-24 04:13:56,926] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6063
[2019-03-24 04:13:56,936] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1459627.779752748 W.
[2019-03-24 04:13:56,941] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.21666666666667, 67.83333333333333, 1.0, 2.0, 0.6365758042696084, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9758184343529333, 6.911199999999999, 6.9112, 121.9260426156618, 1459627.779752748, 1459627.779752749, 301735.6531036629], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7041000.0000, 
sim time next is 7041600.0000, 
raw observation next is [26.4, 67.0, 1.0, 2.0, 0.4451425241503724, 1.0, 1.0, 0.4451425241503724, 1.0, 2.0, 0.708992630556835, 6.9112, 6.9112, 121.94756008, 1532778.202018684, 1532778.202018684, 317486.7473505105], 
processed observation next is [1.0, 0.5217391304347826, 0.5333333333333333, 0.67, 1.0, 1.0, 0.33945538589330054, 1.0, 0.5, 0.33945538589330054, 1.0, 1.0, 0.6362407881960438, 0.0, 0.0, 0.8096049824067558, 0.5474207864352443, 0.5474207864352443, 0.6105514372125201], 
reward next is 0.3894, 
noisyNet noise sample is [array([-0.87311184], dtype=float32), 0.19100887]. 
=============================================
[2019-03-24 04:13:56,974] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.0654702e-21 1.3146840e-14 1.3992281e-18 2.1460456e-21], sum to 1.0000
[2019-03-24 04:13:56,979] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1358
[2019-03-24 04:13:56,985] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1367489.634579561 W.
[2019-03-24 04:13:56,988] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.15, 72.16666666666667, 1.0, 2.0, 0.5817580367664915, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9308878401990079, 6.911199999999999, 6.9112, 121.9260426156618, 1367489.634579561, 1367489.634579562, 286008.7592972331], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7056600.0000, 
sim time next is 7057200.0000, 
raw observation next is [24.9, 73.33333333333334, 1.0, 2.0, 0.327390669890646, 1.0, 1.0, 0.327390669890646, 1.0, 2.0, 0.5225079646561976, 6.9112, 6.9112, 121.94756008, 1142558.124947912, 1142558.124947912, 266757.2451931306], 
processed observation next is [1.0, 0.6956521739130435, 0.47777777777777775, 0.7333333333333334, 1.0, 1.0, 0.19927460701267385, 1.0, 0.5, 0.19927460701267385, 1.0, 1.0, 0.403134955820247, 0.0, 0.0, 0.8096049824067558, 0.4080564731956829, 0.4080564731956829, 0.512994702294482], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.26680732], dtype=float32), -1.2442552]. 
=============================================
[2019-03-24 04:13:57,636] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.00000000e+00 1.65060201e-31 2.20775103e-20 1.52193205e-27
 7.78731053e-27], sum to 1.0000
[2019-03-24 04:13:57,644] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2334
[2019-03-24 04:13:57,650] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.48333333333333, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7515804127777835, 6.9112, 6.9112, 121.9260426156618, 560637.3648710006, 560637.3648710006, 152793.6842989824], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7085400.0000, 
sim time next is 7086000.0000, 
raw observation next is [23.46666666666667, 78.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7467677262612424, 6.911200000000001, 6.9112, 121.9260426156618, 557193.3175647946, 557193.3175647941, 152073.7990861096], 
processed observation next is [1.0, 0.0, 0.42469135802469143, 0.7833333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.683459657826553, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19899761341599806, 0.1989976134159979, 0.29244961362713384], 
reward next is 0.7076, 
noisyNet noise sample is [array([0.6985103], dtype=float32), 1.4368093]. 
=============================================
[2019-03-24 04:13:57,666] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.6926 ]
 [70.15916]
 [72.8106 ]
 [72.6993 ]
 [72.56808]], R is [[67.99645996]
 [68.02266693]
 [68.04711151]
 [68.06958771]
 [68.09020233]].
[2019-03-24 04:14:00,844] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 6.4477280e-22 1.9105726e-09 7.0302300e-20 2.1108671e-19], sum to 1.0000
[2019-03-24 04:14:00,849] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4696
[2019-03-24 04:14:00,862] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 717596.2518220843 W.
[2019-03-24 04:14:00,867] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.23333333333333, 68.33333333333334, 1.0, 2.0, 0.2925846126014928, 1.0, 1.0, 0.2925846126014928, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 717596.2518220843, 717596.2518220848, 180748.653208708], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7129200.0000, 
sim time next is 7129800.0000, 
raw observation next is [23.3, 67.5, 1.0, 2.0, 0.2625157150420326, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4329605775271141, 6.911199999999999, 6.9112, 121.9260426156618, 647099.2945523005, 647099.2945523009, 182695.2186708052], 
processed observation next is [1.0, 0.5217391304347826, 0.41851851851851857, 0.675, 1.0, 1.0, 0.12204251790718165, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.29120072190889257, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23110689091153588, 0.23110689091153605, 0.35133695898231765], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9491944], dtype=float32), -0.38194647]. 
=============================================
[2019-03-24 04:14:02,277] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 04:14:02,279] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:14:02,280] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:14:02,281] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:14:02,281] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:14:02,283] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:14:02,285] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:14:02,286] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:14:02,286] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:14:02,288] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:14:02,288] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:14:02,309] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run68
[2019-03-24 04:14:02,337] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run68
[2019-03-24 04:14:02,337] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run68
[2019-03-24 04:14:02,392] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run68
[2019-03-24 04:14:02,415] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run68
[2019-03-24 04:14:27,956] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.39193788]
[2019-03-24 04:14:27,956] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.328010785, 80.353756245, 1.0, 2.0, 0.6621990847852499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 754698.4182278854, 754698.4182278849, 169112.016781052]
[2019-03-24 04:14:27,957] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:14:27,960] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.9452534e-33 8.3940707e-22 2.8197733e-28 7.2599415e-31], sampled 0.1377859884237599
[2019-03-24 04:14:27,961] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 754698.4182278854 W.
[2019-03-24 04:14:55,394] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.39193788]
[2019-03-24 04:14:55,395] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.2, 73.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9272077077744546, 6.9112, 6.9112, 121.9260426156618, 671568.8413565315, 671568.8413565315, 180767.9026000137]
[2019-03-24 04:14:55,396] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:14:55,398] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 9.9371693e-33 6.4110860e-22 1.1008412e-27 2.1756356e-30], sampled 0.5417419295589334
[2019-03-24 04:15:12,679] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.39193788]
[2019-03-24 04:15:12,681] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.78378950666667, 91.78542328333334, 1.0, 2.0, 0.6748639023054999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 769139.5634653814, 769139.5634653809, 171440.7313476426]
[2019-03-24 04:15:12,682] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:15:12,684] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.00000000e+00 6.84117424e-28 7.03981821e-18 1.31637164e-23
 1.20839328e-25], sampled 0.7426886419735103
[2019-03-24 04:15:12,685] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 769139.5634653814 W.
[2019-03-24 04:15:38,590] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.39193788]
[2019-03-24 04:15:38,591] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.03333333333333, 94.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4753649962999119, 6.9112, 6.9112, 121.9260426156618, 342970.1900235873, 342970.1900235873, 114529.7680198056]
[2019-03-24 04:15:38,593] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:15:38,594] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.0615586e-30 1.5244128e-20 5.7359414e-26 1.7307362e-28], sampled 0.3937153125316505
[2019-03-24 04:15:43,116] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 04:15:43,305] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 04:15:43,923] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 04:15:44,053] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 04:15:44,117] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 04:15:45,135] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1675000, evaluation results [1675000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 04:15:47,724] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.4124528e-26 1.3836371e-13 2.8666493e-20 6.0566117e-24], sum to 1.0000
[2019-03-24 04:15:47,731] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5461
[2019-03-24 04:15:47,737] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1281363.701977452 W.
[2019-03-24 04:15:47,741] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.9502323634549561, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.175840346933856, 6.9112, 121.9249224960755, 1281363.701977452, 1145845.436062624, 231980.1551767793], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7225200.0000, 
sim time next is 7225800.0000, 
raw observation next is [23.98333333333333, 73.33333333333334, 1.0, 2.0, 0.3515168607510368, 1.0, 1.0, 0.3515168607510368, 1.0, 1.0, 0.5637128866431547, 6.9112, 6.9112, 121.94756008, 1247345.4098905, 1247345.4098905, 276341.2748199688], 
processed observation next is [1.0, 0.6521739130434783, 0.4438271604938271, 0.7333333333333334, 1.0, 1.0, 0.2279962627988533, 1.0, 0.5, 0.2279962627988533, 1.0, 0.5, 0.4546411083039433, 0.0, 0.0, 0.8096049824067558, 0.4454805035323214, 0.4454805035323214, 0.53142552849994], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4621639], dtype=float32), 1.0023224]. 
=============================================
[2019-03-24 04:15:48,507] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 6.8488525e-35 7.0326104e-22 5.4975483e-33 7.1007833e-30], sum to 1.0000
[2019-03-24 04:15:48,517] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2139
[2019-03-24 04:15:48,522] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6334296000547759, 6.9112, 6.9112, 121.9260426156618, 472314.5424131315, 472314.5424131315, 135448.450060451], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7434000.0000, 
sim time next is 7434600.0000, 
raw observation next is [19.96666666666667, 92.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6338423330886324, 6.911200000000001, 6.9112, 121.9260426156618, 472605.1823826345, 472605.182382634, 135469.853359384], 
processed observation next is [0.0, 0.043478260869565216, 0.2950617283950618, 0.9216666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5423029163607904, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1687875651366552, 0.16878756513665502, 0.26051894876804615], 
reward next is 0.7395, 
noisyNet noise sample is [array([-0.7139889], dtype=float32), 0.2445928]. 
=============================================
[2019-03-24 04:15:56,095] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 4.7303108e-27 1.6705342e-19 6.7739809e-24 4.9479954e-25], sum to 1.0000
[2019-03-24 04:15:56,102] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1219
[2019-03-24 04:15:56,105] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.33333333333334, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6407842601845046, 6.911200000000001, 6.9112, 121.9260426156618, 477318.6169445714, 477318.6169445709, 135676.4026912526], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7365000.0000, 
sim time next is 7365600.0000, 
raw observation next is [19.3, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6377029875218465, 6.9112, 6.9112, 121.9260426156618, 474928.6055702599, 474928.6055702599, 135278.3169035589], 
processed observation next is [1.0, 0.2608695652173913, 0.27037037037037037, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5471287344023081, 0.0, 0.0, 0.8094621288201359, 0.1696173591322357, 0.1696173591322357, 0.26015060942992096], 
reward next is 0.7398, 
noisyNet noise sample is [array([-0.41080588], dtype=float32), 0.26899996]. 
=============================================
[2019-03-24 04:16:02,206] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 3.1443045e-28 1.1010731e-33 0.0000000e+00], sum to 1.0000
[2019-03-24 04:16:02,213] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0713
[2019-03-24 04:16:02,218] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.2, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6447574978272349, 6.9112, 6.9112, 121.9260426156618, 480676.0466058301, 480676.0466058301, 136487.3817095125], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7420800.0000, 
sim time next is 7421400.0000, 
raw observation next is [20.2, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6434556111617146, 6.911199999999999, 6.9112, 121.9260426156618, 479705.2298708201, 479705.2298708205, 136356.1849895938], 
processed observation next is [1.0, 0.9130434782608695, 0.3037037037037037, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5543195139521432, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17132329638243576, 0.17132329638243587, 0.2622234326722958], 
reward next is 0.7378, 
noisyNet noise sample is [array([0.04472611], dtype=float32), 0.9938029]. 
=============================================
[2019-03-24 04:16:12,447] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.000000e+00 3.671692e-28 9.586522e-20 6.644735e-24 7.260842e-27], sum to 1.0000
[2019-03-24 04:16:12,452] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0634
[2019-03-24 04:16:12,456] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.9, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.549130583746869, 6.911199999999999, 6.9112, 121.9260426156618, 402209.4503635294, 402209.4503635298, 122744.0359663218], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7678800.0000, 
sim time next is 7679400.0000, 
raw observation next is [19.86666666666667, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5525923005570837, 6.911199999999999, 6.9112, 121.9260426156618, 405087.1125240113, 405087.1125240118, 123195.6464472581], 
processed observation next is [1.0, 0.9130434782608695, 0.2913580246913582, 0.7866666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44074037569635466, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14467396875857547, 0.14467396875857566, 0.23691470470626558], 
reward next is 0.7631, 
noisyNet noise sample is [array([0.08947599], dtype=float32), 2.298623]. 
=============================================
[2019-03-24 04:16:17,826] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:16:17,827] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:17,887] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run9
[2019-03-24 04:16:22,844] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.4969084e-27 6.1803052e-18 1.4675794e-21 2.1103465e-24], sum to 1.0000
[2019-03-24 04:16:22,850] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5495
[2019-03-24 04:16:22,859] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.9, 81.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7668245474163746, 6.911199999999999, 6.9112, 121.9260425394775, 573014.3475045578, 573014.3475045583, 152830.7398615742], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7871400.0000, 
sim time next is 7872000.0000, 
raw observation next is [21.76666666666667, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7189846273388825, 6.911200000000001, 6.9112, 121.9260426156386, 537135.1684734037, 537135.1684734032, 145978.4397259813], 
processed observation next is [1.0, 0.08695652173913043, 0.3617283950617285, 0.82, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6487307841736031, 8.881784197001253e-17, 0.0, 0.8094621288199819, 0.1918339887405013, 0.19183398874050114, 0.28072776870381017], 
reward next is 0.7193, 
noisyNet noise sample is [array([0.27086535], dtype=float32), 2.5913365]. 
=============================================
[2019-03-24 04:16:22,879] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[57.980488]
 [57.038227]
 [59.00878 ]
 [59.488388]
 [59.490414]], R is [[58.14558792]
 [57.56413269]
 [57.57408524]
 [56.99834442]
 [57.15344238]].
[2019-03-24 04:16:23,902] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.000000e+00 6.970715e-25 8.355759e-16 5.272288e-22 4.077791e-23], sum to 1.0000
[2019-03-24 04:16:23,909] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4232
[2019-03-24 04:16:23,912] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.2, 67.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6985064334789494, 6.911200000000001, 6.9112, 121.9260426156618, 521980.4858177578, 521980.4858177573, 144452.7603509941], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7856400.0000, 
sim time next is 7857000.0000, 
raw observation next is [24.1, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6982600130968206, 6.911199999999999, 6.9112, 121.9260426156618, 521785.3798909961, 521785.3798909966, 144314.142217532], 
processed observation next is [1.0, 0.9565217391304348, 0.4481481481481482, 0.68, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6228250163710257, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18635192138964146, 0.18635192138964166, 0.27752719657217695], 
reward next is 0.7225, 
noisyNet noise sample is [array([-0.42513096], dtype=float32), -0.68175614]. 
=============================================
[2019-03-24 04:16:23,925] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[59.91473 ]
 [59.967007]
 [60.010094]
 [59.97005 ]
 [60.15845 ]], R is [[59.99356079]
 [60.11583328]
 [60.23615265]
 [60.3547821 ]
 [60.47208405]].
[2019-03-24 04:16:25,070] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 6.2253082e-26 1.9043788e-18 3.5058782e-21 1.9271235e-23], sum to 1.0000
[2019-03-24 04:16:25,077] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0335
[2019-03-24 04:16:25,082] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.93333333333333, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6419981830623533, 6.9112, 6.9112, 121.9260426156618, 477415.2927029458, 477415.2927029458, 135084.043465207], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7879800.0000, 
sim time next is 7880400.0000, 
raw observation next is [19.8, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6353953339962554, 6.911199999999999, 6.9112, 121.9260426156618, 472251.8701632455, 472251.8701632459, 134233.4410474737], 
processed observation next is [1.0, 0.21739130434782608, 0.2888888888888889, 0.89, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5442441674953191, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1686613822011591, 0.16866138220115925, 0.25814123278360324], 
reward next is 0.7419, 
noisyNet noise sample is [array([-1.0308987], dtype=float32), -0.15120366]. 
=============================================
[2019-03-24 04:16:27,281] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.000000e+00 7.486702e-26 6.107403e-15 5.085613e-22 4.986672e-24], sum to 1.0000
[2019-03-24 04:16:27,289] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3711
[2019-03-24 04:16:27,290] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1640350.337734668 W.
[2019-03-24 04:16:27,294] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.1, 47.33333333333334, 1.0, 2.0, 0.705543218527753, 1.0, 2.0, 0.705543218527753, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1640350.337734668, 1640350.337734668, 307821.0819084752], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7917600.0000, 
sim time next is 7918200.0000, 
raw observation next is [30.1, 47.5, 1.0, 2.0, 0.4886216274722985, 1.0, 2.0, 0.4886216274722985, 1.0, 1.0, 0.7781299559767153, 6.911199999999999, 6.9112, 121.94756008, 1679776.054453533, 1679776.054453533, 338094.3201140942], 
processed observation next is [1.0, 0.6521739130434783, 0.6703703703703704, 0.475, 1.0, 1.0, 0.3912162231813078, 1.0, 1.0, 0.3912162231813078, 1.0, 0.5, 0.722662444970894, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5999200194476904, 0.5999200194476904, 0.6501813848347965], 
reward next is 0.3498, 
noisyNet noise sample is [array([0.08074038], dtype=float32), 0.17439401]. 
=============================================
[2019-03-24 04:16:27,750] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:16:27,750] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:27,765] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run9
[2019-03-24 04:16:27,900] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:16:27,900] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:27,910] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run9
[2019-03-24 04:16:27,962] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:16:27,965] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:27,977] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run9
[2019-03-24 04:16:28,024] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:16:28,026] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:28,035] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run9
[2019-03-24 04:16:28,438] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:16:28,439] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:28,443] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run9
[2019-03-24 04:16:28,473] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:16:28,474] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:16:28,475] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:28,474] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:28,483] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:16:28,483] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:28,484] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run9
[2019-03-24 04:16:28,515] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:16:28,516] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:28,521] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run9
[2019-03-24 04:16:28,553] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run9
[2019-03-24 04:16:28,591] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run9
[2019-03-24 04:16:28,623] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:16:28,624] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:28,628] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run9
[2019-03-24 04:16:28,692] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:16:28,692] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:28,699] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run9
[2019-03-24 04:16:28,888] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:16:28,888] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:28,891] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run9
[2019-03-24 04:16:29,029] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:16:29,029] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:29,033] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run9
[2019-03-24 04:16:29,154] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:16:29,154] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:29,157] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run9
[2019-03-24 04:16:29,257] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:16:29,257] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:29,260] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run9
[2019-03-24 04:16:31,660] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.0036261e-26 1.1110903e-17 2.8200061e-23 3.0755399e-25], sum to 1.0000
[2019-03-24 04:16:31,670] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6916
[2019-03-24 04:16:31,686] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.4, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4428475421160173, 6.9112, 6.9112, 121.9260426156618, 316189.0216245717, 316189.0216245717, 102100.2909202118], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 23400.0000, 
sim time next is 24000.0000, 
raw observation next is [19.86666666666667, 62.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4626739700813369, 6.9112, 6.9112, 121.9260426156618, 330347.9552395532, 330347.9552395532, 104359.4336229165], 
processed observation next is [1.0, 0.2608695652173913, 0.2913580246913582, 0.6233333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3283424626016711, 0.0, 0.0, 0.8094621288201359, 0.11798141258555471, 0.11798141258555471, 0.20069121850560867], 
reward next is 0.7993, 
noisyNet noise sample is [array([-1.4855956], dtype=float32), -0.38856456]. 
=============================================
[2019-03-24 04:16:31,698] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[61.282497]
 [61.58772 ]
 [61.85065 ]
 [61.95041 ]
 [62.199223]], R is [[61.19561768]
 [61.38731766]
 [61.57909393]
 [61.77019501]
 [61.96110153]].
[2019-03-24 04:16:33,118] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.2647275e-28 5.8470386e-20 2.1403857e-23 7.9170674e-27], sum to 1.0000
[2019-03-24 04:16:33,126] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8907
[2019-03-24 04:16:33,130] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.96666666666667, 52.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6819201150354296, 6.9112, 6.9112, 121.9260426156618, 509557.7743085571, 509557.7743085571, 142449.6514493308], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 75000.0000, 
sim time next is 75600.0000, 
raw observation next is [26.8, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6838738468218539, 6.9112, 6.9112, 121.9260426156618, 511019.7248349458, 511019.7248349458, 142669.5381334081], 
processed observation next is [1.0, 0.9130434782608695, 0.5481481481481482, 0.53, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6048423085273174, 0.0, 0.0, 0.8094621288201359, 0.1825070445839092, 0.1825070445839092, 0.27436449641040017], 
reward next is 0.7256, 
noisyNet noise sample is [array([0.7280438], dtype=float32), -0.3985796]. 
=============================================
[2019-03-24 04:16:37,322] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 04:16:37,324] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:16:37,324] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:37,325] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:16:37,326] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:16:37,326] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:37,327] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:37,328] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:16:37,327] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:16:37,329] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:37,330] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:16:37,361] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run69
[2019-03-24 04:16:37,386] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run69
[2019-03-24 04:16:37,409] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run69
[2019-03-24 04:16:37,433] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run69
[2019-03-24 04:16:37,459] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run69
[2019-03-24 04:16:38,650] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.39851758]
[2019-03-24 04:16:38,652] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.73333333333333, 42.66666666666667, 1.0, 2.0, 0.7346850497796069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 934249.3013005974, 934249.3013005974, 186125.0279045233]
[2019-03-24 04:16:38,652] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:16:38,653] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.0586534e-18 5.0871035e-12 8.1270275e-16 4.7534526e-17], sampled 0.02232913495043254
[2019-03-24 04:16:38,654] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 934249.3013005974 W.
[2019-03-24 04:16:38,818] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.39851758]
[2019-03-24 04:16:38,819] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.01642764, 43.15666408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4459132127585662, 6.911199999999999, 6.9112, 121.9260426156618, 318378.3362341174, 318378.3362341179, 95587.03466678652]
[2019-03-24 04:16:38,820] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:16:38,822] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.6402144e-23 3.7808197e-15 6.9639289e-20 1.6760475e-21], sampled 0.554807327126227
[2019-03-24 04:16:51,903] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.39851758]
[2019-03-24 04:16:51,904] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.14281125, 75.31291100666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4851064117101258, 6.911200000000001, 6.9112, 121.9260426156618, 348039.6886548962, 348039.6886548957, 114570.3879928235]
[2019-03-24 04:16:51,905] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:16:51,907] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.6232403e-23 3.6869870e-15 6.9044391e-20 1.6228642e-21], sampled 0.7186140277887361
[2019-03-24 04:17:00,540] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.39851758]
[2019-03-24 04:17:00,541] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.6, 89.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9092636008275756, 6.911200000000001, 6.9112, 121.9260426156618, 678784.4275629274, 678784.4275629269, 167014.464548479]
[2019-03-24 04:17:00,541] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:17:00,544] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.1441285e-23 4.4758801e-15 8.7308920e-20 2.1362279e-21], sampled 0.10320680542987792
[2019-03-24 04:17:08,369] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.39851758]
[2019-03-24 04:17:08,371] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.1, 67.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9406284086033523, 6.911200000000001, 6.9112, 121.9260426156618, 681787.7019272374, 681787.701927237, 182542.5884848273]
[2019-03-24 04:17:08,371] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:17:08,374] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.0504151e-25 1.5284511e-16 9.7881275e-22 1.6441109e-23], sampled 0.0037107587168714318
[2019-03-24 04:17:17,721] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.39851758]
[2019-03-24 04:17:17,722] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.72043617333333, 55.36742733, 1.0, 2.0, 0.6187484071088993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 732937.7717781152, 732937.7717781147, 162594.3170279653]
[2019-03-24 04:17:17,722] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:17:17,726] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 9.1223850e-23 1.2263766e-14 2.9795490e-19 8.6186097e-21], sampled 0.23142009424144916
[2019-03-24 04:17:17,728] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 732937.7717781152 W.
[2019-03-24 04:17:49,789] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.39851758]
[2019-03-24 04:17:49,790] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.53333333333333, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8426640329444425, 6.9112, 6.9112, 121.9260426156618, 622195.315895714, 622195.315895714, 167091.0683810712]
[2019-03-24 04:17:49,790] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:17:49,794] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 7.7663405e-26 1.2715950e-16 7.5813860e-22 1.2600691e-23], sampled 0.6867656700267826
[2019-03-24 04:17:49,841] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.39851758]
[2019-03-24 04:17:49,842] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 94.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8605818819780472, 6.9112, 6.9112, 121.9260426156618, 633641.529596644, 633641.529596644, 169883.1571303901]
[2019-03-24 04:17:49,843] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:17:49,847] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 9.3054519e-26 1.4246840e-16 8.8319130e-22 1.4845827e-23], sampled 0.03950096302814354
[2019-03-24 04:18:13,024] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.39851758]
[2019-03-24 04:18:13,025] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.55, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8255789499738615, 6.911200000000001, 6.9112, 121.9260426156618, 610344.1915545713, 610344.1915545708, 164700.6253183408]
[2019-03-24 04:18:13,027] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:18:13,031] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 4.4326479e-25 3.7595753e-16 3.3007629e-21 6.0426070e-23], sampled 0.8313330058174873
[2019-03-24 04:18:19,425] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 04:18:19,796] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 04:18:19,868] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 04:18:19,986] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 04:18:20,176] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 04:18:21,193] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1700000, evaluation results [1700000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 04:18:21,350] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.2193816e-25 1.3624762e-14 3.2248189e-20 4.7506100e-23], sum to 1.0000
[2019-03-24 04:18:21,358] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8403
[2019-03-24 04:18:21,362] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [34.46666666666667, 10.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6902870497651393, 6.911200000000001, 6.9112, 121.9260426156618, 492915.3041479621, 492915.3041479616, 128430.1876770243], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 153600.0000, 
sim time next is 154200.0000, 
raw observation next is [34.18333333333333, 11.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6860746691034004, 6.911200000000001, 6.9112, 121.9260426156618, 489906.3961256937, 489906.3961256933, 128483.3930451941], 
processed observation next is [1.0, 0.782608695652174, 0.8216049382716049, 0.1133333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6075933363792505, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1749665700448906, 0.17496657004489047, 0.2470834481638348], 
reward next is 0.7529, 
noisyNet noise sample is [array([1.6846033], dtype=float32), -0.9292348]. 
=============================================
[2019-03-24 04:18:28,618] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.5894601e-37 6.5305126e-27 2.9552089e-36 4.8002235e-34], sum to 1.0000
[2019-03-24 04:18:28,625] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6448
[2019-03-24 04:18:28,635] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.6, 33.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5294685093335407, 6.911200000000001, 6.9112, 121.9260426156618, 378050.828972721, 378050.8289727205, 105248.935799265], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 291600.0000, 
sim time next is 292200.0000, 
raw observation next is [24.71666666666667, 32.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5322670778497918, 6.9112, 6.9112, 121.9260426156618, 380049.5565336262, 380049.5565336262, 105669.0916557213], 
processed observation next is [0.0, 0.391304347826087, 0.4709876543209877, 0.32666666666666655, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.41533384731223966, 0.0, 0.0, 0.8094621288201359, 0.1357319844762951, 0.1357319844762951, 0.2032097916456179], 
reward next is 0.7968, 
noisyNet noise sample is [array([0.09229601], dtype=float32), -0.28648707]. 
=============================================
[2019-03-24 04:18:30,170] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 6.0432216e-33 8.4235496e-22 3.9893999e-29 1.7728170e-32], sum to 1.0000
[2019-03-24 04:18:30,181] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1834
[2019-03-24 04:18:30,187] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.8, 31.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5861927257973137, 6.911200000000001, 6.9112, 121.9260426156618, 424091.9421314274, 424091.9421314269, 123829.7210082921], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 313200.0000, 
sim time next is 313800.0000, 
raw observation next is [27.83333333333334, 31.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5880262866468067, 6.911200000000001, 6.9112, 121.9260426156618, 425478.4019685152, 425478.4019685148, 124007.9457184774], 
processed observation next is [0.0, 0.6521739130434783, 0.58641975308642, 0.31, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4850328583085083, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15195657213161257, 0.15195657213161243, 0.2384768186893796], 
reward next is 0.7615, 
noisyNet noise sample is [array([0.00749467], dtype=float32), 0.63386405]. 
=============================================
[2019-03-24 04:18:31,175] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 7.3886538e-32 4.3084215e-22 5.2776875e-27 1.4427672e-28], sum to 1.0000
[2019-03-24 04:18:31,188] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9439
[2019-03-24 04:18:31,198] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.3, 39.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5477062089831526, 6.911200000000001, 6.9112, 121.9260426156618, 393478.3258446007, 393478.3258446003, 119622.2212973127], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 334800.0000, 
sim time next is 335400.0000, 
raw observation next is [25.15, 39.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5453600331953807, 6.9112, 6.9112, 121.9260426156618, 391611.6459175333, 391611.6459175333, 119371.1979962836], 
processed observation next is [0.0, 0.9130434782608695, 0.487037037037037, 0.395, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43170004149422586, 0.0, 0.0, 0.8094621288201359, 0.13986130211340475, 0.13986130211340475, 0.22955999614669925], 
reward next is 0.7704, 
noisyNet noise sample is [array([-0.58811927], dtype=float32), 1.3628244]. 
=============================================
[2019-03-24 04:18:42,136] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 6.1968965e-27 6.1869607e-13 1.1801917e-21 8.1875449e-25], sum to 1.0000
[2019-03-24 04:18:42,139] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0857
[2019-03-24 04:18:42,142] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.2, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5813422033377204, 6.9112, 6.9112, 121.9260426156618, 423802.9791165702, 423802.9791165702, 124673.640894998], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 529200.0000, 
sim time next is 529800.0000, 
raw observation next is [20.11666666666667, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6482384325727076, 6.9112, 6.9112, 121.9260426156618, 472470.4378310322, 472470.4378310322, 130603.4655957815], 
processed observation next is [1.0, 0.13043478260869565, 0.30061728395061743, 0.735, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5602980407158845, 0.0, 0.0, 0.8094621288201359, 0.16873944208251151, 0.16873944208251151, 0.2511605107611183], 
reward next is 0.7488, 
noisyNet noise sample is [array([-1.1538831], dtype=float32), 0.46155608]. 
=============================================
[2019-03-24 04:18:42,203] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.0321142e-21 1.2422577e-15 4.2686583e-19 1.2201339e-20], sum to 1.0000
[2019-03-24 04:18:42,213] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3295
[2019-03-24 04:18:42,220] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.1, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5198017751656215, 6.911199999999999, 6.9112, 121.9260426156618, 378921.0817063415, 378921.081706342, 119489.4492573172], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 538800.0000, 
sim time next is 539400.0000, 
raw observation next is [20.3, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5220753106804107, 6.911200000000001, 6.9112, 121.9260426156618, 380948.0458494136, 380948.0458494131, 119831.123443222], 
processed observation next is [1.0, 0.21739130434782608, 0.3074074074074074, 0.73, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.40259413835051333, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13605287351764772, 0.13605287351764753, 0.2304444681600423], 
reward next is 0.7696, 
noisyNet noise sample is [array([-0.7096762], dtype=float32), -0.6819195]. 
=============================================
[2019-03-24 04:18:43,830] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 6.1575163e-21 3.2575847e-12 3.0762682e-17 7.6577585e-18], sum to 1.0000
[2019-03-24 04:18:43,834] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4624
[2019-03-24 04:18:43,845] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1305677.966356833 W.
[2019-03-24 04:18:43,850] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.6, 47.33333333333333, 1.0, 2.0, 0.363951378134616, 1.0, 2.0, 0.363951378134616, 1.0, 2.0, 0.5864753565266971, 6.911200000000001, 6.9112, 121.94756008, 1305677.966356833, 1305677.966356833, 281261.9218386029], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 556800.0000, 
sim time next is 557400.0000, 
raw observation next is [27.3, 48.66666666666667, 1.0, 2.0, 0.5352077762697605, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8699885431405543, 6.911199999999999, 6.9112, 121.9260426156618, 1298331.797632947, 1298331.797632948, 267072.6495586403], 
processed observation next is [1.0, 0.43478260869565216, 0.5666666666666667, 0.4866666666666667, 1.0, 1.0, 0.4466759241306672, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8374856789256929, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.46368992772605255, 0.4636899277260529, 0.5136012491512314], 
reward next is 0.4864, 
noisyNet noise sample is [array([-0.935284], dtype=float32), 0.027316848]. 
=============================================
[2019-03-24 04:18:50,371] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.9449438e-31 1.5666847e-14 1.1044744e-29 1.6795616e-28], sum to 1.0000
[2019-03-24 04:18:50,378] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5657
[2019-03-24 04:18:50,381] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.56666666666666, 33.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5864769049301373, 6.911199999999999, 6.9112, 121.9260426156618, 431662.0317630786, 431662.031763079, 126979.3178614227], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 686400.0000, 
sim time next is 687000.0000, 
raw observation next is [28.38333333333333, 34.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5830413914573057, 6.9112, 6.9112, 121.9260426156618, 429142.3934513604, 429142.3934513604, 126675.7743239828], 
processed observation next is [1.0, 0.9565217391304348, 0.60679012345679, 0.34333333333333343, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4788017393216321, 0.0, 0.0, 0.8094621288201359, 0.153265140518343, 0.153265140518343, 0.24360725831535154], 
reward next is 0.7564, 
noisyNet noise sample is [array([-0.4773077], dtype=float32), -0.11103851]. 
=============================================
[2019-03-24 04:18:50,394] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[75.6769  ]
 [75.71406 ]
 [75.742546]
 [75.77241 ]
 [75.770226]], R is [[75.61995697]
 [75.61956787]
 [75.61858368]
 [75.6170578 ]
 [75.61484528]].
[2019-03-24 04:19:04,190] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.9902654e-30 6.3050413e-17 1.3815568e-24 1.0830423e-28], sum to 1.0000
[2019-03-24 04:19:04,195] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2796
[2019-03-24 04:19:04,200] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.2, 52.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6162141147411683, 6.911200000000001, 6.9112, 121.9260426156618, 457813.4915812082, 457813.4915812078, 132232.2009835325], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 936600.0000, 
sim time next is 937200.0000, 
raw observation next is [25.1, 52.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.612886303103238, 6.9112, 6.9112, 121.9260426156618, 454931.0175890447, 454931.0175890447, 131614.3633623025], 
processed observation next is [0.0, 0.8695652173913043, 0.4851851851851852, 0.5266666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5161078788790474, 0.0, 0.0, 0.8094621288201359, 0.16247536342465882, 0.16247536342465882, 0.25310454492750484], 
reward next is 0.7469, 
noisyNet noise sample is [array([-1.9805607], dtype=float32), 0.27046162]. 
=============================================
[2019-03-24 04:19:08,028] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.0314677e-23 1.3219036e-13 1.2374161e-20 6.0630703e-21], sum to 1.0000
[2019-03-24 04:19:08,032] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4951
[2019-03-24 04:19:08,043] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.5, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.500145840372954, 6.911200000000001, 6.9112, 121.9260426156618, 358784.5467471837, 358784.5467471833, 115697.9607867655], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1029600.0000, 
sim time next is 1030200.0000, 
raw observation next is [23.43333333333334, 47.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4960284507286254, 6.911199999999999, 6.9112, 121.9260426156618, 355784.6646768142, 355784.6646768147, 115367.3872006179], 
processed observation next is [1.0, 0.9565217391304348, 0.42345679012345705, 0.47333333333333344, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3700355634107817, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1270659516702908, 0.12706595167029097, 0.22186036000118828], 
reward next is 0.7781, 
noisyNet noise sample is [array([0.02598164], dtype=float32), 0.9979847]. 
=============================================
[2019-03-24 04:19:11,610] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 4.5371906e-19 3.9271349e-08 1.4615731e-14 1.3090759e-15], sum to 1.0000
[2019-03-24 04:19:11,616] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7736
[2019-03-24 04:19:11,625] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1091933.790132251 W.
[2019-03-24 04:19:11,630] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.86666666666667, 40.33333333333334, 1.0, 2.0, 0.438080457383238, 1.0, 1.0, 0.438080457383238, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1091933.790132251, 1091933.790132252, 220279.1000199812], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1087800.0000, 
sim time next is 1088400.0000, 
raw observation next is [26.83333333333333, 40.66666666666667, 1.0, 2.0, 0.3937802481565099, 1.0, 2.0, 0.3937802481565099, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 980858.9946650375, 980858.994665038, 207520.4046108256], 
processed observation next is [1.0, 0.6086956521739131, 0.5493827160493825, 0.40666666666666673, 1.0, 1.0, 0.2783098192339404, 1.0, 1.0, 0.2783098192339404, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.350306783808942, 0.35030678380894215, 0.39907770117466457], 
reward next is 0.6009, 
noisyNet noise sample is [array([0.29117486], dtype=float32), 0.931779]. 
=============================================
[2019-03-24 04:19:11,631] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 04:19:11,631] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:19:11,632] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:19:11,632] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:19:11,633] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:19:11,633] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:19:11,632] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:19:11,634] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:19:11,635] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:19:11,638] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:19:11,637] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:19:11,665] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run70
[2019-03-24 04:19:11,690] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run70
[2019-03-24 04:19:11,718] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run70
[2019-03-24 04:19:11,741] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run70
[2019-03-24 04:19:11,742] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run70
[2019-03-24 04:19:25,004] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.40631288]
[2019-03-24 04:19:25,005] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.104838715, 61.18790203, 1.0, 2.0, 0.7964883031989443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 965395.2088116552, 965395.2088116552, 197796.3590099967]
[2019-03-24 04:19:25,006] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:19:25,009] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.2528534e-22 6.6176015e-10 1.1569604e-18 1.2711808e-19], sampled 0.07210832919123344
[2019-03-24 04:19:25,012] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 965395.2088116552 W.
[2019-03-24 04:19:56,201] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.40631288]
[2019-03-24 04:19:56,205] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.84714218666667, 98.8930474, 1.0, 2.0, 0.727865596468597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 829578.06164027, 829578.06164027, 181491.0803869853]
[2019-03-24 04:19:56,206] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:19:56,210] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.9496177e-22 4.7556642e-10 5.9467586e-19 6.3672215e-20], sampled 0.006190032527274458
[2019-03-24 04:19:56,211] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 829578.06164027 W.
[2019-03-24 04:19:58,013] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.40631288]
[2019-03-24 04:19:58,014] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.5, 68.0, 1.0, 2.0, 0.6733409287528066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 767402.9680112507, 767402.9680112503, 171159.2158170837]
[2019-03-24 04:19:58,015] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:19:58,019] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 9.3524367e-24 1.2465949e-10 4.6254764e-20 4.2638204e-21], sampled 0.9800246088811725
[2019-03-24 04:19:58,020] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 767402.9680112507 W.
[2019-03-24 04:20:11,222] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.40631288]
[2019-03-24 04:20:11,223] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.69524701, 104.2011099, 1.0, 2.0, 0.9508862222874432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1083943.520745123, 1083943.520745123, 229107.9580668369]
[2019-03-24 04:20:11,225] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:20:11,227] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 5.9572951e-26 1.4164317e-11 6.5069801e-22 4.8457491e-23], sampled 0.32720751561872896
[2019-03-24 04:20:11,229] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1083943.520745123 W.
[2019-03-24 04:20:16,573] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.40631288]
[2019-03-24 04:20:16,574] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.83973715333333, 91.17339313333333, 1.0, 2.0, 0.6301731196520458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 733422.2345447624, 733422.2345447629, 164075.3250929918]
[2019-03-24 04:20:16,575] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:20:16,577] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 8.2676573e-21 2.3760278e-09 1.4045606e-17 1.7575979e-18], sampled 0.3545729524981506
[2019-03-24 04:20:16,579] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 733422.2345447624 W.
[2019-03-24 04:20:18,923] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.40631288]
[2019-03-24 04:20:18,925] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.16666666666667, 88.16666666666667, 1.0, 2.0, 0.6690645117750179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 762526.7347791538, 762526.7347791538, 170370.6048574452]
[2019-03-24 04:20:18,926] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:20:18,928] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.4373534e-25 2.9781067e-11 2.8577166e-21 2.2813262e-22], sampled 0.9171172577057223
[2019-03-24 04:20:18,929] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 762526.7347791538 W.
[2019-03-24 04:20:29,762] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.40631288]
[2019-03-24 04:20:29,763] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.66666666666667, 65.66666666666667, 1.0, 2.0, 0.9852069083713297, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9948317390053752, 6.911199999999999, 6.9112, 121.9260426156618, 1841869.414566826, 1841869.414566826, 375586.6231324785]
[2019-03-24 04:20:29,763] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:20:29,765] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.6678771e-21 1.2046245e-09 3.6496189e-18 4.2706616e-19], sampled 0.08313410245270791
[2019-03-24 04:20:29,766] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1841869.414566826 W.
[2019-03-24 04:20:48,303] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.40631288]
[2019-03-24 04:20:48,304] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.45320951833333, 95.16945665666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6989814892523794, 6.911199999999999, 6.9112, 121.9260426156618, 522329.9227868895, 522329.9227868899, 144944.9755151776]
[2019-03-24 04:20:48,305] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:20:48,309] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.1054553e-26 8.8019566e-12 2.7269548e-22 1.8950329e-23], sampled 0.1022050237863582
[2019-03-24 04:20:54,141] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 04:20:54,302] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 04:20:54,415] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 04:20:54,419] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 04:20:54,441] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 04:20:55,457] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1725000, evaluation results [1725000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 04:20:57,968] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.0049805e-34 4.7643215e-19 4.6095774e-32 2.0504338e-31], sum to 1.0000
[2019-03-24 04:20:57,976] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7384
[2019-03-24 04:20:57,980] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.13333333333333, 68.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5507419603490453, 6.9112, 6.9112, 121.9260426156618, 403462.0314744873, 403462.0314744873, 122914.2857452671], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1111800.0000, 
sim time next is 1112400.0000, 
raw observation next is [21.0, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5458332453742595, 6.9112, 6.9112, 121.9260426156618, 399403.3920294658, 399403.3920294658, 122288.0579731588], 
processed observation next is [1.0, 0.9130434782608695, 0.3333333333333333, 0.69, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4322915567178243, 0.0, 0.0, 0.8094621288201359, 0.14264406858195208, 0.14264406858195208, 0.2351693422560746], 
reward next is 0.7648, 
noisyNet noise sample is [array([-0.44283795], dtype=float32), -0.9884135]. 
=============================================
[2019-03-24 04:21:01,365] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 4.6802390e-32 1.3546331e-17 5.2310029e-28 7.2980455e-29], sum to 1.0000
[2019-03-24 04:21:01,370] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2233
[2019-03-24 04:21:01,376] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.73333333333333, 77.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6004935808848738, 6.9112, 6.9112, 121.9260426156618, 444106.9010177482, 444106.9010177482, 129397.0863831263], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1188600.0000, 
sim time next is 1189200.0000, 
raw observation next is [20.66666666666667, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.603495039914522, 6.9112, 6.9112, 121.9260426156618, 446331.411384368, 446331.411384368, 129678.4869563579], 
processed observation next is [1.0, 0.782608695652174, 0.3209876543209878, 0.78, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5043687998931525, 0.0, 0.0, 0.8094621288201359, 0.15940407549441715, 0.15940407549441715, 0.24938170568530366], 
reward next is 0.7506, 
noisyNet noise sample is [array([1.314396], dtype=float32), 0.4246304]. 
=============================================
[2019-03-24 04:21:02,730] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.00000000e+00 1.99811455e-29 1.12198514e-10 1.72405402e-21
 4.85867998e-26], sum to 1.0000
[2019-03-24 04:21:02,739] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0463
[2019-03-24 04:21:02,747] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.18333333333333, 56.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5654632677659156, 6.911200000000001, 6.9112, 121.9260426156618, 414886.2359727429, 414886.2359727424, 124474.9864468944], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1475400.0000, 
sim time next is 1476000.0000, 
raw observation next is [22.9, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5641755147965414, 6.911200000000001, 6.9112, 121.9260426156618, 413537.1688575904, 413537.1688575899, 124175.9705020086], 
processed observation next is [0.0, 0.08695652173913043, 0.4037037037037037, 0.58, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4552193934956767, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.147691846020568, 0.1476918460205678, 0.23879994327309345], 
reward next is 0.7612, 
noisyNet noise sample is [array([-0.54473597], dtype=float32), -0.56521183]. 
=============================================
[2019-03-24 04:21:02,769] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[79.95735 ]
 [80.163414]
 [80.25003 ]
 [80.27502 ]
 [80.2578  ]], R is [[79.44351959]
 [79.40971375]
 [79.37563324]
 [79.34112549]
 [79.30620575]].
[2019-03-24 04:21:03,728] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 7.8837391e-26 1.1281207e-09 1.8435513e-16 7.4621433e-21], sum to 1.0000
[2019-03-24 04:21:03,739] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3652
[2019-03-24 04:21:03,744] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.16666666666667, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5565429521512425, 6.911199999999999, 6.9112, 121.9260426156618, 408646.4778648939, 408646.4778648943, 123845.3918364973], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1215600.0000, 
sim time next is 1216200.0000, 
raw observation next is [18.13333333333334, 93.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.553046974821808, 6.911200000000001, 6.9112, 121.9260426156618, 405784.6748449205, 405784.6748449201, 123403.7659475913], 
processed observation next is [1.0, 0.043478260869565216, 0.22716049382716075, 0.9316666666666665, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44130871852725995, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1449230981589002, 0.14492309815890003, 0.23731493451459865], 
reward next is 0.7627, 
noisyNet noise sample is [array([1.0156761], dtype=float32), -1.0808731]. 
=============================================
[2019-03-24 04:21:10,076] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 5.9293665e-25 9.9853925e-10 3.5551121e-23 1.0017724e-21], sum to 1.0000
[2019-03-24 04:21:10,084] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9127
[2019-03-24 04:21:10,089] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.0, 32.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5922291824164992, 6.911200000000001, 6.9112, 121.9260426156618, 439125.8214157316, 439125.8214157311, 129339.7927443558], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1359600.0000, 
sim time next is 1360200.0000, 
raw observation next is [29.75, 33.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5978029400974155, 6.911199999999999, 6.9112, 121.9260426156618, 443389.2796941163, 443389.2796941168, 129947.339105751], 
processed observation next is [1.0, 0.7391304347826086, 0.6574074074074074, 0.33, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4972536751217694, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1583533141764701, 0.15835331417647028, 0.24989872904952115], 
reward next is 0.7501, 
noisyNet noise sample is [array([0.08107171], dtype=float32), -0.27081656]. 
=============================================
[2019-03-24 04:21:13,362] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9999857e-01 1.4871262e-22 1.4627763e-06 2.5635679e-17 1.4665092e-20], sum to 1.0000
[2019-03-24 04:21:13,374] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9776
[2019-03-24 04:21:13,378] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.96666666666667, 65.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5234772824359202, 6.9112, 6.9112, 121.9260426156618, 379876.790836655, 379876.790836655, 119093.9116632429], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1392000.0000, 
sim time next is 1392600.0000, 
raw observation next is [20.93333333333333, 65.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.520560705567438, 6.9112, 6.9112, 121.9260426156618, 377238.5161715128, 377238.5161715128, 118656.2150745556], 
processed observation next is [0.0, 0.08695652173913043, 0.3308641975308641, 0.6533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.40070088195929754, 0.0, 0.0, 0.8094621288201359, 0.13472804148982598, 0.13472804148982598, 0.22818502898953], 
reward next is 0.7718, 
noisyNet noise sample is [array([0.52570075], dtype=float32), 0.23266934]. 
=============================================
[2019-03-24 04:21:16,944] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 6.5174964e-27 1.4809894e-10 2.6942067e-23 3.3521615e-24], sum to 1.0000
[2019-03-24 04:21:16,951] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8839
[2019-03-24 04:21:16,957] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.18333333333333, 56.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5654632677659156, 6.911200000000001, 6.9112, 121.9260426156618, 414886.2359727429, 414886.2359727424, 124474.9864468944], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1475400.0000, 
sim time next is 1476000.0000, 
raw observation next is [22.9, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5641755147965414, 6.911200000000001, 6.9112, 121.9260426156618, 413537.1688575904, 413537.1688575899, 124175.9705020086], 
processed observation next is [0.0, 0.08695652173913043, 0.4037037037037037, 0.58, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4552193934956767, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.147691846020568, 0.1476918460205678, 0.23879994327309345], 
reward next is 0.7612, 
noisyNet noise sample is [array([-0.02367075], dtype=float32), -1.4696572]. 
=============================================
[2019-03-24 04:21:16,987] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[76.15509 ]
 [76.31694 ]
 [76.42841 ]
 [76.45964 ]
 [76.492165]], R is [[75.73360443]
 [75.73690033]
 [75.73954773]
 [75.74140167]
 [75.74247742]].
[2019-03-24 04:21:28,432] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.00000000e+00 1.06988994e-20 2.97289804e-10 6.64854495e-22
 6.26506467e-20], sum to 1.0000
[2019-03-24 04:21:28,444] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9573
[2019-03-24 04:21:28,452] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 957137.069282222 W.
[2019-03-24 04:21:28,456] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 76.0, 1.0, 2.0, 0.3847478014481717, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6412879008888361, 6.911199999999997, 6.9112, 121.9260426156618, 957137.069282222, 957137.0692822232, 215481.0326318467], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1684800.0000, 
sim time next is 1685400.0000, 
raw observation next is [21.16666666666667, 75.5, 1.0, 2.0, 0.7595070902411106, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 952374.5934334372, 952374.5934334372, 190996.2152275185], 
processed observation next is [1.0, 0.5217391304347826, 0.33950617283950635, 0.755, 1.0, 1.0, 0.7136989169537031, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.34013378336908473, 0.34013378336908473, 0.36730041389907403], 
reward next is 0.6327, 
noisyNet noise sample is [array([0.45198277], dtype=float32), 1.0491575]. 
=============================================
[2019-03-24 04:21:32,266] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9999726e-01 9.7224196e-22 2.7890537e-06 3.1800081e-16 5.5742285e-19], sum to 1.0000
[2019-03-24 04:21:32,275] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0159
[2019-03-24 04:21:32,278] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.95, 83.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7216396802423903, 6.911199999999999, 6.9112, 121.9260426156618, 537670.1146599313, 537670.1146599316, 144146.5120896474], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1750200.0000, 
sim time next is 1750800.0000, 
raw observation next is [21.1, 82.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.649167331245242, 6.9112, 6.9112, 121.9260426156618, 483766.312041876, 483766.312041876, 136719.6268289117], 
processed observation next is [1.0, 0.2608695652173913, 0.3370370370370371, 0.8233333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5614591640565524, 0.0, 0.0, 0.8094621288201359, 0.17277368287209857, 0.17277368287209857, 0.2629223592863687], 
reward next is 0.7371, 
noisyNet noise sample is [array([1.260498], dtype=float32), -1.0212471]. 
=============================================
[2019-03-24 04:21:36,245] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.6297170e-24 7.5501817e-16 2.2010731e-21 1.6844744e-23], sum to 1.0000
[2019-03-24 04:21:36,247] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6298
[2019-03-24 04:21:36,253] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.65, 80.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6507087927881824, 6.911200000000001, 6.9112, 121.9260426156618, 482412.4538137122, 482412.4538137118, 134879.4396434741], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1840200.0000, 
sim time next is 1840800.0000, 
raw observation next is [20.8, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5982103085980297, 6.9112, 6.9112, 121.9260426156618, 443634.8591677093, 443634.8591677093, 129947.444724811], 
processed observation next is [1.0, 0.30434782608695654, 0.32592592592592595, 0.7933333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4977628857475371, 0.0, 0.0, 0.8094621288201359, 0.15844102113132474, 0.15844102113132474, 0.24989893216309805], 
reward next is 0.7501, 
noisyNet noise sample is [array([-0.00995711], dtype=float32), -1.1357437]. 
=============================================
[2019-03-24 04:21:43,556] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 6.1515139e-26 7.6790660e-15 1.9302273e-24 4.3865726e-26], sum to 1.0000
[2019-03-24 04:21:43,566] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8601
[2019-03-24 04:21:43,569] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.33333333333334, 84.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8098349283018237, 6.911199999999999, 6.9112, 121.9260426156618, 601442.6010756982, 601442.6010756986, 161596.8791993186], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1977600.0000, 
sim time next is 1978200.0000, 
raw observation next is [22.95, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7897548216885748, 6.9112, 6.9112, 121.9260426156618, 587764.7994742529, 587764.7994742529, 158413.8063743849], 
processed observation next is [1.0, 0.9130434782608695, 0.4055555555555555, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7371935271107185, 0.0, 0.0, 0.8094621288201359, 0.20991599981223316, 0.20991599981223316, 0.3046419353353556], 
reward next is 0.6954, 
noisyNet noise sample is [array([-0.2725851], dtype=float32), 0.34982878]. 
=============================================
[2019-03-24 04:21:45,454] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.5325886e-36 1.2349133e-18 1.1647128e-28 2.1308596e-33], sum to 1.0000
[2019-03-24 04:21:45,455] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6634
[2019-03-24 04:21:45,458] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.5, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6145082552486547, 6.911199999999999, 6.9112, 121.9260426156618, 456391.2387673865, 456391.238767387, 131953.4917293077], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1988400.0000, 
sim time next is 1989000.0000, 
raw observation next is [19.5, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6140747568329892, 6.9112, 6.9112, 121.9260426156618, 456069.2698354665, 456069.2698354665, 131911.9890840473], 
processed observation next is [0.0, 0.0, 0.2777777777777778, 0.91, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5175934460412365, 0.0, 0.0, 0.8094621288201359, 0.16288188208409518, 0.16288188208409518, 0.25367690208470633], 
reward next is 0.7463, 
noisyNet noise sample is [array([0.2429045], dtype=float32), 0.23542625]. 
=============================================
[2019-03-24 04:21:45,557] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[79.60553 ]
 [79.33552 ]
 [79.218636]
 [79.63076 ]
 [79.54688 ]], R is [[79.90327454]
 [79.85048676]
 [79.7984314 ]
 [79.74706268]
 [79.6962204 ]].
[2019-03-24 04:21:46,427] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 04:21:46,427] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:21:46,428] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:21:46,429] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:46,430] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:21:46,430] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:46,431] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:21:46,431] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:46,432] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:46,433] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:21:46,434] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:21:46,449] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run71
[2019-03-24 04:21:46,470] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run71
[2019-03-24 04:21:46,471] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run71
[2019-03-24 04:21:46,490] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run71
[2019-03-24 04:21:46,534] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run71
[2019-03-24 04:22:17,345] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.41058207]
[2019-03-24 04:22:17,346] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.2, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9007380312360388, 6.9112, 6.9112, 121.9260426156618, 658565.8866727044, 658565.8866727044, 176170.8290573609]
[2019-03-24 04:22:17,347] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:22:17,350] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 4.8966342e-35 7.7854627e-21 1.9843422e-30 8.8357773e-32], sampled 0.7912944328468108
[2019-03-24 04:22:23,641] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.41058207]
[2019-03-24 04:22:23,642] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.66666666666667, 74.66666666666667, 1.0, 2.0, 0.8195489200750213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156335, 947665.7165416266, 947665.7165416266, 200714.3321138374]
[2019-03-24 04:22:23,643] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:22:23,648] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.1534939e-28 7.7631178e-17 1.6268722e-24 1.3207060e-25], sampled 0.0665115235282433
[2019-03-24 04:22:23,649] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 947665.7165416266 W.
[2019-03-24 04:22:23,989] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.41058207]
[2019-03-24 04:22:23,990] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.96670999666667, 79.303269885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8203328196306382, 6.911199999999999, 6.9112, 121.9260426156618, 609192.2811154543, 609192.2811154547, 162943.8698075872]
[2019-03-24 04:22:23,991] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:22:23,993] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 6.1330720e-34 3.4359593e-20 1.7826188e-29 8.7406074e-31], sampled 0.8130859741414947
[2019-03-24 04:22:26,437] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.41058207]
[2019-03-24 04:22:26,438] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.24563968, 85.72394172, 1.0, 2.0, 0.6361912279722418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745194.2187880528, 745194.2187880528, 165365.4791024131]
[2019-03-24 04:22:26,438] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:22:26,440] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.6008280e-28 5.2528884e-17 8.9989850e-25 7.1751324e-26], sampled 0.39675877916609115
[2019-03-24 04:22:26,442] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 745194.2187880528 W.
[2019-03-24 04:22:36,554] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.41058207]
[2019-03-24 04:22:36,555] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.75, 83.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 1.0, 2.0, 0.9977734948820727, 9.484926476472278, 6.9112, 129.7056185425284, 4447347.132588991, 3045274.637310492, 568946.3470898563]
[2019-03-24 04:22:36,558] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:22:36,561] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.5719031e-29 3.6178504e-17 2.4327482e-25 2.0818629e-26], sampled 0.2848719290551345
[2019-03-24 04:22:36,564] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 4447347.132588991 W.
[2019-03-24 04:22:58,976] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.41058207]
[2019-03-24 04:22:58,977] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.29020744, 87.02025774833334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6383824673056282, 6.911199999999999, 6.9112, 121.9260426156618, 474933.5397865989, 474933.5397865994, 134898.3498304129]
[2019-03-24 04:22:58,978] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:22:58,981] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.7523676e-35 4.2681817e-21 8.1289497e-31 3.4822269e-32], sampled 0.023943569109184604
[2019-03-24 04:23:04,564] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.41058207]
[2019-03-24 04:23:04,565] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.13333333333333, 61.66666666666667, 1.0, 2.0, 0.6228737154937726, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9916352406467894, 6.9112, 6.9112, 121.9255560342124, 1420376.218221487, 1420376.218221487, 302868.0329069815]
[2019-03-24 04:23:04,566] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:23:04,571] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.4384510e-31 8.7573477e-19 2.0277716e-27 1.2683704e-28], sampled 0.6654381993452659
[2019-03-24 04:23:04,572] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1420376.218221487 W.
[2019-03-24 04:23:20,838] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.41058207]
[2019-03-24 04:23:20,839] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.2, 30.0, 1.0, 2.0, 0.6458168745614683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 812863.6478486151, 812863.6478486151, 168867.0435028372]
[2019-03-24 04:23:20,840] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:23:20,847] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 4.2294923e-29 2.4029668e-17 2.8329634e-25 2.1525171e-26], sampled 0.41311762435056054
[2019-03-24 04:23:20,849] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 812863.6478486151 W.
[2019-03-24 04:23:21,901] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06603673], dtype=float32), 0.41058207]
[2019-03-24 04:23:21,902] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.4, 41.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5602745042629487, 6.911200000000001, 6.9112, 121.9260426156618, 406066.6826247651, 406066.6826247647, 121925.0902879649]
[2019-03-24 04:23:21,904] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:23:21,906] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 9.7928157e-33 1.7427289e-19 1.9768342e-28 1.0762174e-29], sampled 0.7735670820179181
[2019-03-24 04:23:29,391] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 04:23:29,402] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 04:23:29,451] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 04:23:29,554] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 04:23:29,577] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 04:23:30,592] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1750000, evaluation results [1750000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 04:23:30,713] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.9471932e-36 8.2335128e-20 6.4144501e-33 4.4982793e-33], sum to 1.0000
[2019-03-24 04:23:30,725] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7241
[2019-03-24 04:23:30,729] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.76666666666667, 90.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.613962231410207, 6.911199999999999, 6.9112, 121.9260426156618, 456733.3813334937, 456733.3813334942, 132486.3822879503], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2007600.0000, 
sim time next is 2008200.0000, 
raw observation next is [19.88333333333333, 89.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6143019122175601, 6.9112, 6.9112, 121.9260426156618, 457040.9047525676, 457040.9047525676, 132565.5103156318], 
processed observation next is [0.0, 0.21739130434782608, 0.2919753086419752, 0.8983333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5178773902719501, 0.0, 0.0, 0.8094621288201359, 0.1632288945544884, 0.1632288945544884, 0.25493367368390735], 
reward next is 0.7451, 
noisyNet noise sample is [array([0.02047119], dtype=float32), 2.1792128]. 
=============================================
[2019-03-24 04:23:34,667] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.2800695e-29 2.9675396e-17 3.2938598e-27 2.3172977e-28], sum to 1.0000
[2019-03-24 04:23:34,674] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1108
[2019-03-24 04:23:34,679] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.4, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9187498614669384, 6.911199999999999, 6.9112, 121.9260426156618, 668040.2305726572, 668040.2305726577, 179232.825004718], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2114400.0000, 
sim time next is 2115000.0000, 
raw observation next is [27.6, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9214593968607446, 6.911199999999999, 6.9112, 121.9260426156618, 669696.623121961, 669696.6231219615, 179649.4819146286], 
processed observation next is [0.0, 0.4782608695652174, 0.5777777777777778, 0.69, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9018242460759307, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23917736540070036, 0.23917736540070053, 0.3454797729127473], 
reward next is 0.6545, 
noisyNet noise sample is [array([0.46314314], dtype=float32), -0.7804171]. 
=============================================
[2019-03-24 04:23:34,698] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[73.35198 ]
 [73.38206 ]
 [73.43072 ]
 [73.45373 ]
 [73.479355]], R is [[73.24502563]
 [73.16789246]
 [73.09262085]
 [73.01957703]
 [72.949646  ]].
[2019-03-24 04:23:35,553] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.0072851e-24 3.0325162e-14 1.6778331e-20 7.6443424e-23], sum to 1.0000
[2019-03-24 04:23:35,561] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7351
[2019-03-24 04:23:35,572] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.83333333333334, 76.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8696376705444836, 6.9112, 6.9112, 121.9260426156618, 637897.5769164736, 637897.5769164736, 171640.9875137851], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2110200.0000, 
sim time next is 2110800.0000, 
raw observation next is [26.06666666666667, 75.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8769201876819517, 6.911200000000001, 6.9112, 121.9260426156618, 642318.8834103141, 642318.8834103136, 172788.7983011167], 
processed observation next is [0.0, 0.43478260869565216, 0.5209876543209878, 0.7533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8461502346024397, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22939960121796932, 0.22939960121796915, 0.33228615057907057], 
reward next is 0.6677, 
noisyNet noise sample is [array([1.2212613], dtype=float32), 2.3181593]. 
=============================================
[2019-03-24 04:23:41,902] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9999893e-01 2.2560699e-15 1.1124770e-06 1.0124517e-13 1.8408467e-13], sum to 1.0000
[2019-03-24 04:23:41,912] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9712
[2019-03-24 04:23:41,922] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2062353.135618621 W.
[2019-03-24 04:23:41,927] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.86666666666667, 82.33333333333334, 1.0, 2.0, 0.6027067279527824, 1.0, 2.0, 0.6027067279527824, 1.0, 1.0, 0.959528739688602, 6.911199999999999, 6.9112, 121.94756008, 2062353.135618621, 2062353.135618621, 396852.3325193532], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2211600.0000, 
sim time next is 2212200.0000, 
raw observation next is [26.65, 83.0, 1.0, 2.0, 0.5938213420319473, 1.0, 2.0, 0.5938213420319473, 1.0, 2.0, 0.9453829159258155, 6.9112, 6.9112, 121.94756008, 2031914.370968521, 2031914.370968521, 392019.4202020295], 
processed observation next is [1.0, 0.6086956521739131, 0.5425925925925925, 0.83, 1.0, 1.0, 0.516453978609461, 1.0, 1.0, 0.516453978609461, 1.0, 1.0, 0.9317286449072693, 0.0, 0.0, 0.8096049824067558, 0.725683703917329, 0.725683703917329, 0.7538835003885183], 
reward next is 0.2461, 
noisyNet noise sample is [array([-0.82348216], dtype=float32), 0.71279436]. 
=============================================
[2019-03-24 04:23:48,049] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.0530655e-28 3.7898430e-12 4.0093898e-27 1.7866136e-23], sum to 1.0000
[2019-03-24 04:23:48,056] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6557
[2019-03-24 04:23:48,065] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.76666666666667, 78.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7697161236777013, 6.9112, 6.9112, 121.9260426156618, 573461.9685937813, 573461.9685937813, 155554.1410174641], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2320800.0000, 
sim time next is 2321400.0000, 
raw observation next is [23.63333333333333, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7680622697193795, 6.9112, 6.9112, 121.9260426156618, 572341.9906740022, 572341.9906740022, 155269.2426195366], 
processed observation next is [1.0, 0.8695652173913043, 0.430864197530864, 0.7933333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7100778371492245, 0.0, 0.0, 0.8094621288201359, 0.20440785381214366, 0.20440785381214366, 0.2985946973452627], 
reward next is 0.7014, 
noisyNet noise sample is [array([-0.3675168], dtype=float32), 1.2962589]. 
=============================================
[2019-03-24 04:23:58,037] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 8.3645860e-25 1.9460759e-12 1.3901389e-21 1.3767337e-22], sum to 1.0000
[2019-03-24 04:23:58,046] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9860
[2019-03-24 04:23:58,052] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.83333333333333, 56.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8888358327258689, 6.9112, 6.9112, 121.9260426156618, 661419.0203221523, 661419.0203221523, 162230.1481878744], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2517000.0000, 
sim time next is 2517600.0000, 
raw observation next is [24.76666666666667, 56.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8521926593307628, 6.911199999999999, 6.9112, 121.9260426156618, 634123.4924190779, 634123.4924190784, 157988.8236322206], 
processed observation next is [1.0, 0.13043478260869565, 0.4728395061728396, 0.5666666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8152408241634534, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2264726758639564, 0.22647267586395656, 0.30382466083119347], 
reward next is 0.6962, 
noisyNet noise sample is [array([-1.6788027], dtype=float32), -0.25097865]. 
=============================================
[2019-03-24 04:23:59,122] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.3574119e-23 5.0393842e-13 1.9441239e-20 1.0330596e-21], sum to 1.0000
[2019-03-24 04:23:59,131] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7780
[2019-03-24 04:23:59,140] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1558369.980212783 W.
[2019-03-24 04:23:59,149] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.5, 30.0, 1.0, 2.0, 0.4368302020940921, 1.0, 2.0, 0.4368302020940921, 1.0, 1.0, 0.7019909546325045, 6.9112, 6.9112, 121.94756008, 1558369.980212783, 1558369.980212783, 313435.507236573], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2548200.0000, 
sim time next is 2548800.0000, 
raw observation next is [32.6, 30.0, 1.0, 2.0, 0.6131735790695023, 1.0, 2.0, 0.6131735790695023, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1470144.413416222, 1470144.413416223, 275765.9149366528], 
processed observation next is [1.0, 0.5217391304347826, 0.7629629629629631, 0.3, 1.0, 1.0, 0.5394923560351218, 1.0, 1.0, 0.5394923560351218, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5250515762200793, 0.5250515762200796, 0.5303190671858709], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.090994], dtype=float32), 0.0922926]. 
=============================================
[2019-03-24 04:24:00,895] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.5518683e-29 3.9030327e-18 8.6358418e-24 3.6426061e-27], sum to 1.0000
[2019-03-24 04:24:00,899] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4496
[2019-03-24 04:24:00,905] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2590863.155962454 W.
[2019-03-24 04:24:00,909] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.96666666666667, 57.83333333333334, 1.0, 2.0, 0.8871527824205532, 1.0, 2.0, 0.7569410531867111, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 122.5210016744965, 2590863.155962454, 2590863.155962454, 483486.6713458093], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2823000.0000, 
sim time next is 2823600.0000, 
raw observation next is [32.93333333333334, 56.66666666666667, 1.0, 2.0, 0.814476261176647, 1.0, 2.0, 0.7206027925647582, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2466329.231141814, 2466329.231141815, 461418.3579892378], 
processed observation next is [1.0, 0.6956521739130435, 0.7753086419753088, 0.5666666666666668, 1.0, 1.0, 0.7791384061626749, 1.0, 1.0, 0.6673842768628074, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.8808318682649335, 0.8808318682649339, 0.8873429961331496], 
reward next is 0.1127, 
noisyNet noise sample is [array([-1.8416647], dtype=float32), -0.21756451]. 
=============================================
[2019-03-24 04:24:15,859] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5231237e-02 5.1910578e-16 9.7476882e-01 3.0437221e-14 4.0471226e-15], sum to 1.0000
[2019-03-24 04:24:15,869] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5779
[2019-03-24 04:24:15,872] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.5, 71.0, 1.0, 2.0, 0.3109902896674918, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4951373286056331, 6.911199999999999, 6.9112, 121.9260426156618, 709777.2267913794, 709777.2267913799, 198206.666143201], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2847600.0000, 
sim time next is 2848200.0000, 
raw observation next is [26.58333333333334, 75.83333333333334, 1.0, 2.0, 0.3090657690022997, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4921232217533459, 6.911199999999999, 6.9112, 121.9260426156618, 706611.6885945018, 706611.6885945023, 197661.973104813], 
processed observation next is [1.0, 1.0, 0.5401234567901236, 0.7583333333333334, 1.0, 1.0, 0.17745924881226155, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.36515402719168233, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2523613173551792, 0.25236131735517936, 0.3801191790477173], 
reward next is 0.6199, 
noisyNet noise sample is [array([-0.19684844], dtype=float32), 0.6406021]. 
=============================================
[2019-03-24 04:24:16,556] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1118369e-02 4.6796082e-20 9.8888165e-01 1.2804498e-23 6.7915658e-20], sum to 1.0000
[2019-03-24 04:24:16,562] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1577
[2019-03-24 04:24:16,570] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.2679366608349343, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4309305493916281, 6.911199999999999, 6.9112, 121.9260426156618, 638016.8507325951, 638016.8507325955, 185863.4249750718], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2874000.0000, 
sim time next is 2874600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.2646722754236625, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4257289201803494, 6.9112, 6.9112, 121.9260426156618, 630396.2845404807, 630396.2845404807, 185026.257892193], 
processed observation next is [1.0, 0.2608695652173913, 0.37037037037037035, 0.94, 1.0, 1.0, 0.12460985169483632, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.28216115022543675, 0.0, 0.0, 0.8094621288201359, 0.22514153019302882, 0.22514153019302882, 0.3558197267157558], 
reward next is 0.6442, 
noisyNet noise sample is [array([1.9187979], dtype=float32), 0.8715853]. 
=============================================
[2019-03-24 04:24:21,050] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 04:24:21,051] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:24:21,052] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:24:21,053] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:24:21,054] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:24:21,053] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:24:21,055] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:24:21,054] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:24:21,056] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:24:21,055] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:24:21,052] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:24:21,078] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run72
[2019-03-24 04:24:21,103] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run72
[2019-03-24 04:24:21,104] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run72
[2019-03-24 04:24:21,137] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run72
[2019-03-24 04:24:21,184] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run72
[2019-03-24 04:24:27,627] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06660694], dtype=float32), 0.41089636]
[2019-03-24 04:24:27,628] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.5, 29.5, 1.0, 2.0, 0.7124323659170796, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9559030774057052, 6.911199999999999, 6.9112, 121.9260426156618, 1586952.306019345, 1586952.306019346, 307127.4553472527]
[2019-03-24 04:24:27,629] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:24:27,632] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.8153598e-01 1.9468316e-12 7.1846402e-01 7.1554084e-14 1.1828425e-11], sampled 0.9197552898421378
[2019-03-24 04:25:08,385] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06660694], dtype=float32), 0.41089636]
[2019-03-24 04:25:08,387] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.01666666666667, 55.16666666666667, 1.0, 2.0, 0.7216768438271586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 822520.7034468419, 822520.7034468414, 180291.7771446201]
[2019-03-24 04:25:08,389] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:25:08,392] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.67032707e-01 1.20067964e-13 1.32967323e-01 1.10998924e-14
 1.83877696e-12], sampled 0.8479928994400701
[2019-03-24 04:25:08,393] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 822520.7034468419 W.
[2019-03-24 04:25:29,685] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06660694], dtype=float32), 0.41089636]
[2019-03-24 04:25:29,685] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.08333333333333, 85.16666666666667, 1.0, 2.0, 0.6885730409382655, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1499759.006838684, 1499759.006838684, 315167.3408098278]
[2019-03-24 04:25:29,686] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:25:29,689] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1868044e-01 1.0420748e-12 8.8131958e-01 1.6941294e-14 3.7658487e-12], sampled 0.894221353464757
[2019-03-24 04:26:04,202] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8481.3332 2233491219.5337 444.0000
[2019-03-24 04:26:04,331] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8216.1789 2354769399.4572 479.0000
[2019-03-24 04:26:04,498] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8360.1041 2278502273.0178 392.0000
[2019-03-24 04:26:04,537] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8309.9790 2304475493.2887 570.0000
[2019-03-24 04:26:04,563] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7645.5059 2549353073.0253 689.0000
[2019-03-24 04:26:05,582] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1775000, evaluation results [1775000.0, 7645.505876695291, 2549353073.0252705, 689.0, 8360.10411420447, 2278502273.017777, 392.0, 8481.33317212716, 2233491219.533684, 444.0, 8216.1789134606, 2354769399.4571533, 479.0, 8309.979013271895, 2304475493.288733, 570.0]
[2019-03-24 04:26:06,552] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.5027581e-01 1.7887170e-13 5.4972416e-01 1.6268811e-14 1.6271257e-11], sum to 1.0000
[2019-03-24 04:26:06,561] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0827
[2019-03-24 04:26:06,571] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1461293.383938877 W.
[2019-03-24 04:26:06,576] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.6548704934030887, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1461293.383938877, 1461293.383938878, 309220.8254906], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2970000.0000, 
sim time next is 2970600.0000, 
raw observation next is [26.33333333333334, 88.16666666666667, 1.0, 2.0, 0.4399777728956746, 1.0, 1.0, 0.4399777728956746, 1.0, 2.0, 0.7004589435256123, 6.911199999999999, 6.9112, 121.94756008, 1505044.328832987, 1505044.328832987, 315037.1417567075], 
processed observation next is [1.0, 0.391304347826087, 0.5308641975308644, 0.8816666666666667, 1.0, 1.0, 0.33330687249485075, 1.0, 0.5, 0.33330687249485075, 1.0, 1.0, 0.6255736794070155, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5375158317260668, 0.5375158317260668, 0.6058406572244375], 
reward next is 0.3942, 
noisyNet noise sample is [array([-0.8432009], dtype=float32), -0.4124034]. 
=============================================
[2019-03-24 04:26:09,542] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9147147e-01 1.8157429e-09 8.5285921e-03 1.3074558e-10 9.4612620e-09], sum to 1.0000
[2019-03-24 04:26:09,552] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9425
[2019-03-24 04:26:09,559] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 801144.9558180098 W.
[2019-03-24 04:26:09,563] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.25, 89.0, 1.0, 2.0, 0.7029316328372165, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 801144.9558180098, 801144.9558180098, 176699.8189190148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3007800.0000, 
sim time next is 3008400.0000, 
raw observation next is [26.33333333333333, 87.33333333333334, 1.0, 2.0, 0.6965778471637474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 793899.6714965801, 793899.6714965801, 175496.7169011419], 
processed observation next is [1.0, 0.8260869565217391, 0.530864197530864, 0.8733333333333334, 1.0, 1.0, 0.6387831513854135, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28353559696306435, 0.28353559696306435, 0.3374936863483498], 
reward next is 0.6625, 
noisyNet noise sample is [array([0.15244369], dtype=float32), 1.8950733]. 
=============================================
[2019-03-24 04:26:17,758] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 4.9989862e-20 1.2671426e-12 3.2709608e-18 9.7512413e-20], sum to 1.0000
[2019-03-24 04:26:17,764] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0398
[2019-03-24 04:26:17,770] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 710178.1834454307 W.
[2019-03-24 04:26:17,775] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.5, 76.5, 1.0, 2.0, 0.2077178647444969, 1.0, 1.0, 0.2077178647444969, 1.0, 2.0, 0.3306936055718117, 6.9112, 6.9112, 121.94756008, 710178.1834454307, 710178.1834454307, 223132.2265699971], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3195000.0000, 
sim time next is 3195600.0000, 
raw observation next is [26.33333333333334, 75.66666666666666, 1.0, 2.0, 0.2025569689920327, 1.0, 2.0, 0.2025569689920327, 1.0, 2.0, 0.3224772914552481, 6.9112, 6.9112, 121.94756008, 692525.3405794689, 692525.3405794689, 221431.6852697489], 
processed observation next is [1.0, 1.0, 0.5308641975308644, 0.7566666666666666, 1.0, 1.0, 0.05066305832384846, 1.0, 1.0, 0.05066305832384846, 1.0, 1.0, 0.15309661431906013, 0.0, 0.0, 0.8096049824067558, 0.24733047877838174, 0.24733047877838174, 0.42583016398028634], 
reward next is 0.5742, 
noisyNet noise sample is [array([-0.5560465], dtype=float32), -1.3805717]. 
=============================================
[2019-03-24 04:26:18,588] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 9.7202381e-26 1.7815361e-16 1.0804937e-25 3.5221715e-25], sum to 1.0000
[2019-03-24 04:26:18,598] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0462
[2019-03-24 04:26:18,605] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.0, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8793147198448951, 6.9112, 6.9112, 121.9260426156618, 646643.6022451231, 646643.6022451231, 172508.3387708467], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3187800.0000, 
sim time next is 3188400.0000, 
raw observation next is [28.66666666666666, 58.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8763210676310202, 6.911199999999999, 6.9112, 121.9260426156618, 644395.0145847211, 644395.0145847215, 172130.8858170972], 
processed observation next is [1.0, 0.9130434782608695, 0.6172839506172837, 0.5866666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8454013345387753, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23014107663740038, 0.23014107663740055, 0.3310209342636485], 
reward next is 0.6690, 
noisyNet noise sample is [array([0.4076835], dtype=float32), -1.461623]. 
=============================================
[2019-03-24 04:26:20,483] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.9697864e-29 1.0807159e-18 1.8833992e-25 1.4149554e-25], sum to 1.0000
[2019-03-24 04:26:20,489] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1638
[2019-03-24 04:26:20,496] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.06666666666667, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8134189325919462, 6.9112, 6.9112, 121.9260426156618, 602776.7888342094, 602776.7888342094, 162631.2159655023], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3237600.0000, 
sim time next is 3238200.0000, 
raw observation next is [30.05, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8306395313855363, 6.9112, 6.9112, 121.9260426156618, 613799.088272731, 613799.088272731, 165426.4703757476], 
processed observation next is [0.0, 0.4782608695652174, 0.6685185185185185, 0.505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7882994142319202, 0.0, 0.0, 0.8094621288201359, 0.21921396009740396, 0.21921396009740396, 0.31812782764566844], 
reward next is 0.6819, 
noisyNet noise sample is [array([-0.21831293], dtype=float32), -0.9007004]. 
=============================================
[2019-03-24 04:26:21,152] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.9313966e-27 1.8531449e-19 2.2668343e-26 1.9878940e-24], sum to 1.0000
[2019-03-24 04:26:21,156] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1998
[2019-03-24 04:26:21,161] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.18333333333333, 83.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8718811763220181, 6.911200000000001, 6.9112, 121.9260426156618, 642734.8156958595, 642734.815695859, 171122.6789016421], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3207000.0000, 
sim time next is 3207600.0000, 
raw observation next is [24.0, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8500361426564291, 6.911199999999999, 6.9112, 121.9260426156618, 628564.2695874806, 628564.269587481, 167716.7037003573], 
processed observation next is [0.0, 0.13043478260869565, 0.4444444444444444, 0.83, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8125451783205364, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22448723913838592, 0.22448723913838609, 0.3225321225006871], 
reward next is 0.6775, 
noisyNet noise sample is [array([-1.1825352], dtype=float32), -0.8796224]. 
=============================================
[2019-03-24 04:26:21,337] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.1570389e-27 3.1257154e-16 1.8281857e-24 5.3075382e-23], sum to 1.0000
[2019-03-24 04:26:21,344] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2303
[2019-03-24 04:26:21,348] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.83333333333333, 43.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8951917005744593, 6.9112, 6.9112, 121.9260426156618, 653682.2336572811, 653682.2336572811, 175591.4474681838], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3253800.0000, 
sim time next is 3254400.0000, 
raw observation next is [33.0, 44.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.914837810173937, 6.9112, 6.9112, 121.9260426156618, 665325.7281161534, 665325.7281161534, 178682.7106105325], 
processed observation next is [0.0, 0.6956521739130435, 0.7777777777777778, 0.44, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8935472627174212, 0.0, 0.0, 0.8094621288201359, 0.2376163314700548, 0.2376163314700548, 0.3436205973279471], 
reward next is 0.6564, 
noisyNet noise sample is [array([-0.09118015], dtype=float32), -0.58326143]. 
=============================================
[2019-03-24 04:26:24,607] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.3860324e-28 7.0796176e-19 4.3777694e-23 4.2256347e-23], sum to 1.0000
[2019-03-24 04:26:24,616] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6970
[2019-03-24 04:26:24,623] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8955875585291686, 6.9112, 6.9112, 121.9260426156618, 656438.4264757908, 656438.4264757908, 175148.7816979109], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3318000.0000, 
sim time next is 3318600.0000, 
raw observation next is [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8958926361058718, 6.9112, 6.9112, 121.9260426156618, 656662.0565633776, 656662.0565633776, 175189.1355223592], 
processed observation next is [0.0, 0.391304347826087, 0.4444444444444444, 0.89, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8698657951323396, 0.0, 0.0, 0.8094621288201359, 0.23452216305834914, 0.23452216305834914, 0.3369021836968446], 
reward next is 0.6631, 
noisyNet noise sample is [array([1.6091154], dtype=float32), 1.4340423]. 
=============================================
[2019-03-24 04:26:25,420] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 8.7754260e-22 2.7209910e-14 4.8038666e-20 2.6005641e-19], sum to 1.0000
[2019-03-24 04:26:25,427] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7677
[2019-03-24 04:26:25,433] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8908996442794431, 6.9112, 6.9112, 121.9260426156618, 658815.4632077437, 658815.4632077437, 172940.8051957688], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3553200.0000, 
sim time next is 3553800.0000, 
raw observation next is [22.16666666666667, 98.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9662146427335021, 7.020663695998165, 6.9112, 121.9255885912327, 770336.3321168574, 714281.3447482758, 183069.07466349], 
processed observation next is [1.0, 0.13043478260869565, 0.3765432098765434, 0.9816666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9577683034168777, 0.010946369599816475, 0.0, 0.8094591145700788, 0.2751201186131634, 0.25510048026724136, 0.35205591281440385], 
reward next is 0.1006, 
noisyNet noise sample is [array([0.83500654], dtype=float32), -0.97924936]. 
=============================================
[2019-03-24 04:26:25,551] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.0660384e-20 2.0906319e-12 9.0584446e-22 3.7404864e-19], sum to 1.0000
[2019-03-24 04:26:25,560] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5874
[2019-03-24 04:26:25,571] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 748795.8441557274 W.
[2019-03-24 04:26:25,575] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.08333333333334, 78.16666666666666, 1.0, 2.0, 0.3285112429776263, 1.0, 2.0, 0.3285112429776263, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 748795.8441557274, 748795.8441557278, 187443.522073569], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3333000.0000, 
sim time next is 3333600.0000, 
raw observation next is [27.1, 78.0, 1.0, 2.0, 0.32819651576848, 1.0, 2.0, 0.32819651576848, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 748078.1170521571, 748078.1170521575, 187364.9024438443], 
processed observation next is [0.0, 0.6086956521739131, 0.5592592592592593, 0.78, 1.0, 1.0, 0.20023394734342861, 1.0, 1.0, 0.20023394734342861, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2671707560900561, 0.26717075609005625, 0.360317120084316], 
reward next is 0.6397, 
noisyNet noise sample is [array([0.07876851], dtype=float32), -0.40227494]. 
=============================================
[2019-03-24 04:26:26,510] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 8.5911310e-22 1.5819613e-12 8.0303149e-18 5.0109407e-19], sum to 1.0000
[2019-03-24 04:26:26,517] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7560
[2019-03-24 04:26:26,523] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 743685.3731099817 W.
[2019-03-24 04:26:26,530] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.3262702674170294, 1.0, 2.0, 0.3262702674170294, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 743685.3731099817, 743685.3731099821, 186884.5574129879], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3327600.0000, 
sim time next is 3328200.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.3272925359494023, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5210603764051888, 6.911199999999999, 6.9112, 121.9260426156618, 746016.6186428169, 746016.6186428174, 202724.2920627179], 
processed observation next is [0.0, 0.5217391304347826, 0.5555555555555556, 0.79, 1.0, 1.0, 0.19915778089214556, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4013254705064859, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2664345066581489, 0.26643450665814905, 0.389854407812919], 
reward next is 0.6101, 
noisyNet noise sample is [array([-0.33922616], dtype=float32), -0.27010518]. 
=============================================
[2019-03-24 04:26:27,113] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.6889226e-13 4.6307832e-08 1.6819596e-13 1.3431823e-12], sum to 1.0000
[2019-03-24 04:26:27,118] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5881
[2019-03-24 04:26:27,125] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1339117.983636108 W.
[2019-03-24 04:26:27,131] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.9, 82.66666666666666, 1.0, 2.0, 0.5747708693506378, 1.0, 2.0, 0.5747708693506378, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1339117.983636108, 1339117.983636109, 260825.4895107459], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3584400.0000, 
sim time next is 3585000.0000, 
raw observation next is [23.95, 82.83333333333334, 1.0, 2.0, 0.5731920855524478, 1.0, 2.0, 0.5731920855524478, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1333936.447316214, 1333936.447316214, 260225.2292209871], 
processed observation next is [1.0, 0.4782608695652174, 0.4425925925925926, 0.8283333333333335, 1.0, 1.0, 0.49189533994339024, 1.0, 1.0, 0.49189533994339024, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.476405874041505, 0.476405874041505, 0.5004331331172829], 
reward next is 0.4996, 
noisyNet noise sample is [array([-0.48262233], dtype=float32), -1.1146852]. 
=============================================
[2019-03-24 04:26:27,146] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[35.753334]
 [35.805725]
 [35.795586]
 [35.587326]
 [35.563404]], R is [[35.90620041]
 [36.0455513 ]
 [35.68509674]
 [35.78504944]
 [35.42720032]].
[2019-03-24 04:26:28,389] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.99998689e-01 1.89900094e-14 1.26384407e-06 1.03529085e-14
 5.07063575e-13], sum to 1.0000
[2019-03-24 04:26:28,398] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4755
[2019-03-24 04:26:28,404] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 768195.5036099172 W.
[2019-03-24 04:26:28,409] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.86666666666667, 80.66666666666667, 1.0, 2.0, 0.3370179867359613, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5365436107932102, 6.9112, 6.9112, 121.9260426156618, 768195.5036099172, 768195.5036099172, 205460.9595677282], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3354000.0000, 
sim time next is 3354600.0000, 
raw observation next is [26.83333333333334, 79.83333333333334, 1.0, 2.0, 0.3344432789480811, 1.0, 1.0, 0.3344432789480811, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 762323.8215114798, 762323.8215114803, 188931.6641443119], 
processed observation next is [0.0, 0.8260869565217391, 0.5493827160493829, 0.7983333333333335, 1.0, 1.0, 0.20767057017628707, 1.0, 0.5, 0.20767057017628707, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27225850768267135, 0.2722585076826715, 0.3633301233544459], 
reward next is 0.6367, 
noisyNet noise sample is [array([-1.5613152], dtype=float32), 0.29334795]. 
=============================================
[2019-03-24 04:26:30,033] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5633720e-01 7.9877654e-10 3.4366283e-01 2.1310978e-10 3.6974594e-09], sum to 1.0000
[2019-03-24 04:26:30,041] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3691
[2019-03-24 04:26:30,053] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1859518.670612221 W.
[2019-03-24 04:26:30,059] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 59.0, 1.0, 2.0, 0.5434915640336978, 1.0, 2.0, 0.5434915640336978, 1.0, 2.0, 0.8652562702261664, 6.911200000000001, 6.9112, 121.94756008, 1859518.670612221, 1859518.67061222, 365447.6781976577], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3413400.0000, 
sim time next is 3414000.0000, 
raw observation next is [31.0, 59.0, 1.0, 2.0, 0.6606552645710988, 1.0, 2.0, 0.6606552645710988, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1506616.489031029, 1506616.489031029, 289539.0707305059], 
processed observation next is [1.0, 0.5217391304347826, 0.7037037037037037, 0.59, 1.0, 1.0, 0.596018172108451, 1.0, 1.0, 0.596018172108451, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5380773175110818, 0.5380773175110818, 0.556805905250973], 
reward next is 0.4432, 
noisyNet noise sample is [array([-0.1960921], dtype=float32), 0.42487153]. 
=============================================
[2019-03-24 04:26:30,073] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[30.35417 ]
 [29.9709  ]
 [29.736929]
 [29.906157]
 [29.786879]], R is [[30.2298069 ]
 [30.22472572]
 [29.92247963]
 [29.84094048]
 [29.76227951]].
[2019-03-24 04:26:39,640] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.6707140e-01 8.3148800e-12 3.3292857e-01 1.9315307e-12 7.7899331e-09], sum to 1.0000
[2019-03-24 04:26:39,645] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0921
[2019-03-24 04:26:39,651] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 957013.8548263962 W.
[2019-03-24 04:26:39,656] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.23333333333333, 91.66666666666667, 1.0, 2.0, 0.4041381840819575, 1.0, 1.0, 0.4041381840819575, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156603, 957013.8548263962, 957013.8548263962, 208910.252008755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3573600.0000, 
sim time next is 3574200.0000, 
raw observation next is [22.31666666666667, 91.33333333333334, 1.0, 2.0, 0.7949901265721352, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 950155.273290364, 950155.273290364, 196976.7295320774], 
processed observation next is [1.0, 0.34782608695652173, 0.38209876543209886, 0.9133333333333334, 1.0, 1.0, 0.7559406268715895, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33934116903227285, 0.33934116903227285, 0.3788014029463027], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19278352], dtype=float32), 0.6438968]. 
=============================================
[2019-03-24 04:26:43,558] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9127614e-01 1.7331273e-14 8.7237954e-03 1.8791046e-10 5.5838503e-09], sum to 1.0000
[2019-03-24 04:26:43,564] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6207
[2019-03-24 04:26:43,570] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1178847.05404624 W.
[2019-03-24 04:26:43,577] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.3446920678154951, 1.0, 1.0, 0.3446920678154951, 1.0, 2.0, 0.5487609977992004, 6.9112, 6.9112, 121.94756008, 1178847.05404624, 1178847.05404624, 273702.6826379328], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3672000.0000, 
sim time next is 3672600.0000, 
raw observation next is [23.16666666666667, 99.00000000000001, 1.0, 2.0, 0.593490677834077, 0.0, 1.0, 0.0, 1.0, 2.0, 0.944856487753825, 6.911199999999999, 6.9112, 121.9260426156618, 1353313.116441279, 1353313.11644128, 291334.0025916479], 
processed observation next is [1.0, 0.5217391304347826, 0.4135802469135804, 0.9900000000000001, 1.0, 1.0, 0.5160603307548536, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9310706096922813, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4833261130147425, 0.4833261130147429, 0.5602576972916306], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41550535], dtype=float32), -1.49249]. 
=============================================
[2019-03-24 04:26:47,193] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999869e-01 2.3618265e-14 1.3382404e-06 9.9392662e-13 1.2742005e-09], sum to 1.0000
[2019-03-24 04:26:47,198] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4121
[2019-03-24 04:26:47,203] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 758314.5017133388 W.
[2019-03-24 04:26:47,207] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3326851978275014, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5296456697418588, 6.9112, 6.9112, 121.9260426156618, 758314.5017133388, 758314.5017133388, 204237.2188788865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3718200.0000, 
sim time next is 3718800.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6642644370672688, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757053.4317985746, 757053.4317985746, 169487.9151861678], 
processed observation next is [1.0, 0.043478260869565216, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6003148060324628, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2703762256423481, 0.2703762256423481, 0.3259382984349381], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.62552136], dtype=float32), -0.3062773]. 
=============================================
[2019-03-24 04:26:52,123] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.9250408e-19 1.4846428e-11 1.1986325e-18 7.7641623e-15], sum to 1.0000
[2019-03-24 04:26:52,132] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3000
[2019-03-24 04:26:52,141] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 723614.2644571668 W.
[2019-03-24 04:26:52,145] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.75, 62.0, 1.0, 2.0, 0.6349376162893584, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 723614.2644571668, 723614.2644571668, 164191.3053032907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3795000.0000, 
sim time next is 3795600.0000, 
raw observation next is [29.5, 65.0, 1.0, 2.0, 0.650160501684519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 740971.5933087897, 740971.5933087892, 166922.656027729], 
processed observation next is [1.0, 0.9565217391304348, 0.6481481481481481, 0.65, 1.0, 1.0, 0.5835244067672845, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2646327118959963, 0.26463271189599613, 0.32100510774563273], 
reward next is 0.6790, 
noisyNet noise sample is [array([0.2828897], dtype=float32), -0.3812788]. 
=============================================
[2019-03-24 04:26:53,844] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.8020138e-16 5.7685079e-10 8.0119678e-15 3.7080918e-13], sum to 1.0000
[2019-03-24 04:26:53,858] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3610
[2019-03-24 04:26:53,868] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 840473.5130255405 W.
[2019-03-24 04:26:53,873] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 58.5, 1.0, 2.0, 0.36870997277939, 1.0, 1.0, 0.36870997277939, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 840473.5130255405, 840473.5130255405, 197768.532072776], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3845400.0000, 
sim time next is 3846000.0000, 
raw observation next is [33.0, 58.0, 1.0, 2.0, 0.7303372479424081, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 832396.6331961399, 832396.6331961399, 181973.1631629975], 
processed observation next is [0.0, 0.5217391304347826, 0.7777777777777778, 0.58, 1.0, 1.0, 0.6789729142171524, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29728451185576427, 0.29728451185576427, 0.3499483906980721], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6900885], dtype=float32), 0.19629371]. 
=============================================
[2019-03-24 04:26:53,889] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[33.359676]
 [33.332718]
 [33.87813 ]
 [33.878506]
 [34.019127]], R is [[33.05236053]
 [32.72183609]
 [32.39461899]
 [32.69671631]
 [32.36975098]].
[2019-03-24 04:26:56,069] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 04:26:56,071] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:26:56,073] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:26:56,073] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:26:56,075] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:26:56,075] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:26:56,075] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:26:56,076] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:26:56,077] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:26:56,077] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:26:56,077] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:26:56,102] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run73
[2019-03-24 04:26:56,126] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run73
[2019-03-24 04:26:56,127] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run73
[2019-03-24 04:26:56,127] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run73
[2019-03-24 04:26:56,127] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run73
[2019-03-24 04:27:14,775] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06540123], dtype=float32), 0.41178992]
[2019-03-24 04:27:14,777] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.02708412, 70.90453668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6356150980495129, 6.911200000000001, 6.9112, 121.9260426156618, 473825.6718662679, 473825.6718662675, 135532.7664176522]
[2019-03-24 04:27:14,778] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:27:14,780] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9990940e-01 3.1811152e-14 9.0638197e-05 3.4449405e-12 8.8345917e-09], sampled 0.8317982811298452
[2019-03-24 04:27:19,526] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06540123], dtype=float32), 0.41178992]
[2019-03-24 04:27:19,527] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.62905743, 57.00495428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8119105756752801, 6.9112, 6.9112, 121.9260426156618, 602972.7679657293, 602972.7679657293, 161863.3184130969]
[2019-03-24 04:27:19,528] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:27:19,530] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9977237e-01 6.9037869e-13 2.2762296e-04 4.8081848e-11 5.5764620e-08], sampled 0.33953085946528283
[2019-03-24 04:27:23,458] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06540123], dtype=float32), 0.41178992]
[2019-03-24 04:27:23,459] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.46340204833334, 73.17760104666667, 1.0, 2.0, 0.5995883775679801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 724640.0795089785, 724640.0795089785, 159754.2377119465]
[2019-03-24 04:27:23,460] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:27:23,462] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9750310e-01 1.1196368e-09 2.4921135e-03 2.6966450e-08 4.7770359e-06], sampled 0.8303829911282288
[2019-03-24 04:27:23,463] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 724640.0795089785 W.
[2019-03-24 04:27:26,945] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06540123], dtype=float32), 0.41178992]
[2019-03-24 04:27:26,947] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.66666666666666, 52.66666666666667, 1.0, 2.0, 0.7272153696185082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 828836.5709132858, 828836.5709132858, 181363.8883527444]
[2019-03-24 04:27:26,949] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:27:26,951] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9859256e-01 1.8555463e-10 1.4058002e-03 5.8088498e-09 1.6318862e-06], sampled 0.7953002092784868
[2019-03-24 04:27:26,951] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 828836.5709132858 W.
[2019-03-24 04:27:41,219] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06540123], dtype=float32), 0.41178992]
[2019-03-24 04:27:41,220] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.5, 86.0, 1.0, 2.0, 0.6267977196991801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732095.2863607783, 732095.2863607783, 163590.8023807447]
[2019-03-24 04:27:41,221] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:27:41,223] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9896801e-01 8.5108164e-11 1.0308948e-03 2.9662934e-09 1.0131860e-06], sampled 0.9473107225545417
[2019-03-24 04:27:41,225] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 732095.2863607783 W.
[2019-03-24 04:27:50,375] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06540123], dtype=float32), 0.41178992]
[2019-03-24 04:27:50,375] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.18897377333333, 91.35697822333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7208428447719102, 6.9112, 6.9112, 121.9260426156618, 538463.8364860888, 538463.8364860888, 148145.7280959228]
[2019-03-24 04:27:50,378] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:27:50,384] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9994588e-01 5.3737879e-15 5.4059314e-05 7.5399696e-13 3.0658287e-09], sampled 0.15701532437855215
[2019-03-24 04:28:21,992] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06540123], dtype=float32), 0.41178992]
[2019-03-24 04:28:21,993] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.48900312666667, 44.91943136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5726576141791998, 6.9112, 6.9112, 121.9260426156618, 421113.71035709, 421113.71035709, 125558.2195383866]
[2019-03-24 04:28:21,993] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:28:21,996] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9989247e-01 5.6931375e-14 1.0749594e-04 5.6794122e-12 1.2495518e-08], sampled 0.8069257912395317
[2019-03-24 04:28:22,623] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06540123], dtype=float32), 0.41178992]
[2019-03-24 04:28:22,625] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.61911381333334, 42.15393192666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7716938134607014, 6.911200000000001, 6.9112, 121.9260426156618, 551280.7685087338, 551280.7685087334, 129906.5872893851]
[2019-03-24 04:28:22,627] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:28:22,632] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9946612e-01 1.0662259e-11 5.3366093e-04 5.0038962e-10 2.9038222e-07], sampled 0.5492810036492537
[2019-03-24 04:28:39,134] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8362.0559 2339640097.1090 615.0000
[2019-03-24 04:28:39,464] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06540123], dtype=float32), 0.41178992]
[2019-03-24 04:28:39,465] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.14911904333333, 87.64461323833333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8823955077900079, 6.911199999999999, 6.9112, 121.9260426156618, 659218.6297117405, 659218.629711741, 164769.2775499074]
[2019-03-24 04:28:39,466] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:28:39,468] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9990237e-01 3.9478945e-14 9.7637261e-05 4.1473491e-12 1.0079271e-08], sampled 0.541645879384945
[2019-03-24 04:28:39,879] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8400.6157 2293122024.1867 697.0000
[2019-03-24 04:28:39,984] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7838.5037 2529956127.1233 828.0000
[2019-03-24 04:28:40,014] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8556.5839 2258469562.8350 536.0000
[2019-03-24 04:28:40,029] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8630.9325 2219221317.2446 543.0000
[2019-03-24 04:28:41,045] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1800000, evaluation results [1800000.0, 7838.503654098442, 2529956127.1232805, 828.0, 8556.583902934817, 2258469562.835049, 536.0, 8630.932453290556, 2219221317.2446375, 543.0, 8362.055913079626, 2339640097.1089735, 615.0, 8400.615731780066, 2293122024.1866755, 697.0]
[2019-03-24 04:28:55,690] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.000000e+00 7.970070e-26 2.865521e-14 8.027285e-25 7.656173e-20], sum to 1.0000
[2019-03-24 04:28:55,700] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1290
[2019-03-24 04:28:55,703] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.742267047195592, 6.9112, 6.9112, 121.9260426156618, 554358.9346494633, 554358.9346494633, 150820.7093930677], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4138200.0000, 
sim time next is 4138800.0000, 
raw observation next is [21.33333333333334, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.741881675945079, 6.9112, 6.9112, 121.9260426156618, 554128.5478802054, 554128.5478802054, 150665.4427014169], 
processed observation next is [1.0, 0.9130434782608695, 0.3456790123456792, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6773520949313488, 0.0, 0.0, 0.8094621288201359, 0.19790305281435908, 0.19790305281435908, 0.28974123596426327], 
reward next is 0.7103, 
noisyNet noise sample is [array([-0.32770798], dtype=float32), -0.7398101]. 
=============================================
[2019-03-24 04:28:59,160] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 4.8656811e-30 2.8603945e-17 2.6208587e-28 1.8615095e-22], sum to 1.0000
[2019-03-24 04:28:59,170] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5487
[2019-03-24 04:28:59,177] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.66666666666667, 47.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7699940356660858, 6.9112, 6.9112, 121.9260426156618, 573425.3713551408, 573425.3713551408, 155764.1000506977], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4219800.0000, 
sim time next is 4220400.0000, 
raw observation next is [29.53333333333334, 50.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7962885395932429, 6.9112, 6.9112, 121.9260426156618, 591217.5206607566, 591217.5206607566, 159983.217854855], 
processed observation next is [1.0, 0.8695652173913043, 0.6493827160493829, 0.5066666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7453606744915536, 0.0, 0.0, 0.8094621288201359, 0.2111491145216988, 0.2111491145216988, 0.3076600343362596], 
reward next is 0.6923, 
noisyNet noise sample is [array([1.2070572], dtype=float32), 0.12301544]. 
=============================================
[2019-03-24 04:28:59,508] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 8.0637377e-27 8.6689544e-11 6.9463840e-22 2.7680370e-16], sum to 1.0000
[2019-03-24 04:28:59,519] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4971
[2019-03-24 04:28:59,527] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1658241.431446962 W.
[2019-03-24 04:28:59,532] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.5, 24.0, 1.0, 2.0, 0.68966411559665, 1.0, 1.0, 0.68966411559665, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.926042615659, 1658241.431446962, 1658241.431446962, 304089.490264125], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4208400.0000, 
sim time next is 4209000.0000, 
raw observation next is [34.41666666666666, 25.66666666666666, 1.0, 2.0, 0.3079585898594658, 1.0, 2.0, 0.3079585898594658, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 743102.9618338342, 743102.9618338346, 184143.2569829748], 
processed observation next is [1.0, 0.7391304347826086, 0.8302469135802466, 0.2566666666666666, 1.0, 1.0, 0.17614117840412594, 1.0, 1.0, 0.17614117840412594, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26539391494065506, 0.26539391494065523, 0.3541216480441823], 
reward next is 0.6459, 
noisyNet noise sample is [array([-1.0539969], dtype=float32), -0.42553136]. 
=============================================
[2019-03-24 04:28:59,548] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[64.50279 ]
 [64.366905]
 [64.00571 ]
 [63.154114]
 [62.609833]], R is [[66.22574615]
 [65.56349182]
 [64.9078598 ]
 [64.25878143]
 [63.63402557]].
[2019-03-24 04:29:09,459] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 4.0104964e-32 5.6452193e-21 7.8771213e-27 9.3090575e-22], sum to 1.0000
[2019-03-24 04:29:09,465] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9775
[2019-03-24 04:29:09,470] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.803468088868774, 6.9112, 6.9112, 121.9260426156618, 597595.7453125396, 597595.7453125396, 160332.5853333015], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4407000.0000, 
sim time next is 4407600.0000, 
raw observation next is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8023987176753, 6.911200000000001, 6.9112, 121.9260426156618, 596810.2266118738, 596810.2266118734, 160193.921515785], 
processed observation next is [0.0, 0.0, 0.37037037037037035, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7529983970941251, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21314650950424066, 0.2131465095042405, 0.30806523368420197], 
reward next is 0.6919, 
noisyNet noise sample is [array([0.5289953], dtype=float32), -0.58057624]. 
=============================================
[2019-03-24 04:29:10,009] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.9512001e-23 4.1964138e-16 1.4107106e-22 2.0642140e-17], sum to 1.0000
[2019-03-24 04:29:10,017] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8417
[2019-03-24 04:29:10,025] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 718034.6532523334 W.
[2019-03-24 04:29:10,030] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.16666666666667, 83.16666666666667, 1.0, 2.0, 0.3150220303766443, 1.0, 1.0, 0.3150220303766443, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 718034.6532523334, 718034.6532523339, 184104.8792880054], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4439400.0000, 
sim time next is 4440000.0000, 
raw observation next is [26.33333333333334, 82.33333333333334, 1.0, 2.0, 0.2127315334597306, 1.0, 2.0, 0.2127315334597306, 1.0, 1.0, 0.3386755294502544, 6.9112, 6.9112, 121.94756008, 727327.8254872346, 727327.8254872346, 224798.5312720395], 
processed observation next is [0.0, 0.391304347826087, 0.5308641975308644, 0.8233333333333335, 1.0, 1.0, 0.06277563507110784, 1.0, 1.0, 0.06277563507110784, 1.0, 0.5, 0.173344411812818, 0.0, 0.0, 0.8096049824067558, 0.25975993767401234, 0.25975993767401234, 0.43230486783084515], 
reward next is 0.5677, 
noisyNet noise sample is [array([-0.36266577], dtype=float32), -0.436796]. 
=============================================
[2019-03-24 04:29:10,048] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[43.966396]
 [46.92777 ]
 [52.975597]
 [53.123913]
 [53.241924]], R is [[42.86314774]
 [43.08046722]
 [43.3367424 ]
 [43.54306793]
 [43.75811768]].
[2019-03-24 04:29:12,014] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 7.4371673e-20 2.7217554e-13 1.2551981e-18 4.2368215e-15], sum to 1.0000
[2019-03-24 04:29:12,027] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2893
[2019-03-24 04:29:12,036] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 742289.6732965625 W.
[2019-03-24 04:29:12,039] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.33333333333334, 71.0, 1.0, 2.0, 0.3256582411639574, 0.0, 2.0, 0.0, 1.0, 1.0, 0.518458525881495, 6.911199999999999, 6.9112, 121.9260426156618, 742289.6732965625, 742289.6732965629, 202268.3385566765], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4454400.0000, 
sim time next is 4455000.0000, 
raw observation next is [28.5, 69.5, 1.0, 2.0, 0.2185691979551011, 1.0, 1.0, 0.2185691979551011, 1.0, 2.0, 0.3479692814463439, 6.911199999999999, 6.9112, 121.94756008, 747296.4922709499, 747296.4922709503, 226756.4157589789], 
processed observation next is [0.0, 0.5652173913043478, 0.6111111111111112, 0.695, 1.0, 1.0, 0.06972523566083465, 1.0, 0.5, 0.06972523566083465, 1.0, 1.0, 0.1849616018079299, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2668916043824821, 0.2668916043824823, 0.43607003030572866], 
reward next is 0.5639, 
noisyNet noise sample is [array([-0.8724705], dtype=float32), -0.5860684]. 
=============================================
[2019-03-24 04:29:12,052] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[35.473824]
 [35.077602]
 [35.262512]
 [35.65001 ]
 [35.200523]], R is [[35.66360855]
 [35.91799545]
 [36.23574829]
 [35.8733902 ]
 [35.51465607]].
[2019-03-24 04:29:18,017] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.7666936e-23 5.1534162e-15 3.0934192e-21 4.9096007e-18], sum to 1.0000
[2019-03-24 04:29:18,024] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8796
[2019-03-24 04:29:18,031] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.785631186009043, 6.9112, 6.9112, 121.9260426156618, 585090.7789500315, 585090.7789500315, 157646.2218834291], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4579200.0000, 
sim time next is 4579800.0000, 
raw observation next is [21.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.78059601574742, 6.911200000000001, 6.9112, 121.9260426156618, 581640.2062659106, 581640.2062659102, 156813.0998586145], 
processed observation next is [1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7257450196842749, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20772864509496808, 0.2077286450949679, 0.3015636535742586], 
reward next is 0.6984, 
noisyNet noise sample is [array([0.36551487], dtype=float32), -0.6838361]. 
=============================================
[2019-03-24 04:29:18,312] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.5546718e-26 1.5504012e-17 1.8952415e-24 2.0076360e-20], sum to 1.0000
[2019-03-24 04:29:18,321] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3868
[2019-03-24 04:29:18,324] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9224937894143989, 6.911200000000001, 6.9112, 121.9260426156618, 672403.6908255944, 672403.6908255939, 179469.8107408729], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4568400.0000, 
sim time next is 4569000.0000, 
raw observation next is [23.0, 99.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9216181273022371, 6.911200000000001, 6.9112, 121.9260426156618, 672276.3542064632, 672276.3542064627, 179261.3483128237], 
processed observation next is [0.0, 0.9130434782608695, 0.4074074074074074, 0.9900000000000001, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9020226591277963, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2400986979308797, 0.24009869793087954, 0.34473336214004563], 
reward next is 0.6553, 
noisyNet noise sample is [array([0.4896685], dtype=float32), -1.634693]. 
=============================================
[2019-03-24 04:29:18,339] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[58.87426 ]
 [58.889076]
 [59.17115 ]
 [58.95243 ]
 [59.181458]], R is [[58.55525208]
 [58.62456512]
 [58.69538879]
 [58.76761627]
 [58.84104156]].
[2019-03-24 04:29:19,184] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 7.0646451e-19 7.0256344e-12 3.7166639e-18 1.5765868e-13], sum to 1.0000
[2019-03-24 04:29:19,194] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5536
[2019-03-24 04:29:19,199] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1415403.23150699 W.
[2019-03-24 04:29:19,207] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.66666666666666, 73.0, 1.0, 2.0, 0.6206949407863236, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9881665603547922, 6.911199999999999, 6.9112, 121.9260426156618, 1415403.23150699, 1415403.23150699, 301997.6952051164], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4621200.0000, 
sim time next is 4621800.0000, 
raw observation next is [27.83333333333334, 73.5, 1.0, 2.0, 0.6573958668560862, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1464175.59354132, 1464175.593541321, 309658.2341266273], 
processed observation next is [1.0, 0.4782608695652174, 0.58641975308642, 0.735, 1.0, 1.0, 0.592137936733436, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5229198548361857, 0.5229198548361861, 0.595496604089668], 
reward next is 0.4045, 
noisyNet noise sample is [array([-0.3808673], dtype=float32), -0.70898145]. 
=============================================
[2019-03-24 04:29:20,083] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.9505319e-18 1.3878802e-12 1.7692758e-18 6.6706101e-14], sum to 1.0000
[2019-03-24 04:29:20,088] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2004
[2019-03-24 04:29:20,092] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1806080.062985484 W.
[2019-03-24 04:29:20,098] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.5, 64.0, 1.0, 2.0, 0.9569360312749774, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1806080.062985484, 1806080.062985484, 369543.2681654679], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4629600.0000, 
sim time next is 4630200.0000, 
raw observation next is [29.58333333333334, 64.33333333333334, 1.0, 2.0, 0.8494457307886113, 1.0, 1.0, 0.8494457307886113, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1937631.409630575, 1937631.409630575, 364609.3756741683], 
processed observation next is [1.0, 0.6086956521739131, 0.6512345679012348, 0.6433333333333334, 1.0, 1.0, 0.8207687271292992, 1.0, 0.5, 0.8207687271292992, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6920112177252054, 0.6920112177252054, 0.7011718762964775], 
reward next is 0.2988, 
noisyNet noise sample is [array([1.0197113], dtype=float32), -0.0725645]. 
=============================================
[2019-03-24 04:29:20,708] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.6026363e-21 3.4555221e-14 3.1004989e-19 4.3648119e-16], sum to 1.0000
[2019-03-24 04:29:20,718] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3604
[2019-03-24 04:29:20,722] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 779149.9590076822 W.
[2019-03-24 04:29:20,726] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.8, 83.0, 1.0, 2.0, 0.3418214164151853, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5441908272793181, 6.911200000000001, 6.9112, 121.9260426156618, 779149.9590076822, 779149.9590076817, 206827.1682328457], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4649400.0000, 
sim time next is 4650000.0000, 
raw observation next is [26.73333333333333, 82.66666666666667, 1.0, 2.0, 0.3386358100655258, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5391192382227044, 6.911199999999999, 6.9112, 121.9260426156618, 771885.0110457757, 771885.0110457762, 205920.252314235], 
processed observation next is [1.0, 0.8260869565217391, 0.545679012345679, 0.8266666666666667, 1.0, 1.0, 0.21266167864943547, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4238990477783804, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2756732182306342, 0.27567321823063434, 0.3960004852196827], 
reward next is 0.6040, 
noisyNet noise sample is [array([0.11742409], dtype=float32), -0.32802692]. 
=============================================
[2019-03-24 04:29:20,752] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[44.257465]
 [44.3679  ]
 [44.309044]
 [44.025345]
 [43.982624]], R is [[44.40855408]
 [44.56672668]
 [44.12105942]
 [43.67984772]
 [43.84186172]].
[2019-03-24 04:29:26,584] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.8017870e-16 1.3609641e-11 4.3684219e-18 4.0485792e-13], sum to 1.0000
[2019-03-24 04:29:26,591] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6745
[2019-03-24 04:29:26,602] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 691742.6673563776 W.
[2019-03-24 04:29:26,604] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.06666666666667, 93.33333333333334, 1.0, 2.0, 0.6021589778181925, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691742.6673563776, 691742.6673563776, 158718.3793472281], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4756800.0000, 
sim time next is 4757400.0000, 
raw observation next is [24.1, 93.0, 1.0, 2.0, 0.3020588560769719, 1.0, 1.0, 0.3020588560769719, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 689752.7978586867, 689752.7978586867, 181019.6752584005], 
processed observation next is [1.0, 0.043478260869565216, 0.4481481481481482, 0.93, 1.0, 1.0, 0.16911768580591896, 1.0, 0.5, 0.16911768580591896, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24634028494953095, 0.24634028494953095, 0.34811476011230863], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5282994], dtype=float32), -0.40206385]. 
=============================================
[2019-03-24 04:29:26,950] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 6.7749426e-15 2.1611986e-10 1.8615304e-15 6.0329730e-10], sum to 1.0000
[2019-03-24 04:29:26,954] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0150
[2019-03-24 04:29:26,961] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1734704.026366674 W.
[2019-03-24 04:29:26,967] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.7, 83.66666666666667, 1.0, 2.0, 0.7605699148311381, 1.0, 2.0, 0.7605699148311381, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1734704.026366674, 1734704.026366675, 327729.6869175028], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4966800.0000, 
sim time next is 4967400.0000, 
raw observation next is [25.85, 83.83333333333333, 1.0, 2.0, 0.7685715227165255, 1.0, 2.0, 0.7685715227165255, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1752971.960138162, 1752971.960138162, 330937.9720247333], 
processed observation next is [1.0, 0.4782608695652174, 0.5129629629629631, 0.8383333333333333, 1.0, 1.0, 0.7244899079958637, 1.0, 1.0, 0.7244899079958637, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6260614143350578, 0.6260614143350578, 0.636419176970641], 
reward next is 0.3636, 
noisyNet noise sample is [array([0.11579093], dtype=float32), 0.8523902]. 
=============================================
[2019-03-24 04:29:27,611] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.6731077e-15 9.6536179e-10 1.4617124e-14 7.7006720e-11], sum to 1.0000
[2019-03-24 04:29:27,618] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3903
[2019-03-24 04:29:27,622] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 794289.3474965352 W.
[2019-03-24 04:29:27,625] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.66666666666667, 96.0, 1.0, 2.0, 0.3468112157206776, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5522913830390532, 6.9112, 6.9112, 121.926042615627, 794289.3474965352, 794289.3474965352, 208193.6947780498], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4776000.0000, 
sim time next is 4776600.0000, 
raw observation next is [23.83333333333333, 95.0, 1.0, 2.0, 0.3507299409036719, 1.0, 1.0, 0.3507299409036719, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 799466.6975427021, 799466.6975427021, 193079.3476840038], 
processed observation next is [1.0, 0.2608695652173913, 0.43827160493827144, 0.95, 1.0, 1.0, 0.22705945345675224, 1.0, 0.5, 0.22705945345675224, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28552382055096504, 0.28552382055096504, 0.3713064378538534], 
reward next is 0.6287, 
noisyNet noise sample is [array([0.0766112], dtype=float32), -0.18581088]. 
=============================================
[2019-03-24 04:29:28,737] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9998927e-01 1.2521901e-08 7.9125684e-06 1.3587988e-08 2.8632128e-06], sum to 1.0000
[2019-03-24 04:29:28,742] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2380
[2019-03-24 04:29:28,751] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1241146.98628096 W.
[2019-03-24 04:29:28,753] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.95, 94.0, 1.0, 2.0, 0.5443404383358823, 1.0, 1.0, 0.5443404383358823, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1241146.98628096, 1241146.986280961, 249435.2813846922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4786200.0000, 
sim time next is 4786800.0000, 
raw observation next is [23.96666666666667, 94.0, 1.0, 2.0, 1.004346343613598, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.216815429945185, 6.9112, 121.9247242646916, 1309949.223368571, 1153448.499854743, 242252.7942761986], 
processed observation next is [1.0, 0.391304347826087, 0.4432098765432099, 0.94, 1.0, 1.0, 1.0051742185876167, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.030561542994518475, 0.0, 0.8094533763406823, 0.4678390083459182, 0.4119458928052654, 0.46587075822345886], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05012545], dtype=float32), -0.5431945]. 
=============================================
[2019-03-24 04:29:29,855] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9999940e-01 1.7377519e-12 4.5602110e-07 2.9446331e-11 6.7852433e-08], sum to 1.0000
[2019-03-24 04:29:29,862] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8966
[2019-03-24 04:29:29,868] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 831993.3596628854 W.
[2019-03-24 04:29:29,871] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.06666666666667, 87.33333333333334, 1.0, 2.0, 0.3649918056729039, 1.0, 2.0, 0.3649918056729039, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156532, 831993.3596628854, 831993.3596628859, 196790.3986374117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4814400.0000, 
sim time next is 4815000.0000, 
raw observation next is [27.8, 89.0, 1.0, 2.0, 0.7232023828880793, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 824260.3493603619, 824260.3493603619, 180591.2624965299], 
processed observation next is [1.0, 0.7391304347826086, 0.5851851851851853, 0.89, 1.0, 1.0, 0.6704790272477134, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29437869620012924, 0.29437869620012924, 0.3472908894164037], 
reward next is 0.6527, 
noisyNet noise sample is [array([-1.1553127], dtype=float32), 0.9352878]. 
=============================================
[2019-03-24 04:29:29,886] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[28.454653]
 [28.734457]
 [28.899382]
 [28.605108]
 [28.202864]], R is [[28.84477615]
 [29.17788506]
 [29.45610046]
 [29.16153908]
 [28.86992455]].
[2019-03-24 04:29:30,256] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9992371e-01 9.0620213e-11 6.9950052e-05 1.3891773e-09 6.2818913e-06], sum to 1.0000
[2019-03-24 04:29:30,263] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4272
[2019-03-24 04:29:30,269] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 801158.5629976026 W.
[2019-03-24 04:29:30,273] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.9, 93.0, 1.0, 2.0, 0.234314543482937, 1.0, 1.0, 0.234314543482937, 1.0, 1.0, 0.3730363843167627, 6.9112, 6.9112, 121.94756008, 801158.5629976026, 801158.5629976026, 232132.2581576934], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4780800.0000, 
sim time next is 4781400.0000, 
raw observation next is [23.9, 93.16666666666667, 1.0, 2.0, 0.2771533687740201, 1.0, 2.0, 0.2771533687740201, 1.0, 2.0, 0.4412371893433052, 6.9112, 6.9112, 121.94756008, 947721.8433764002, 947721.8433764002, 247459.6077339128], 
processed observation next is [1.0, 0.34782608695652173, 0.4407407407407407, 0.9316666666666668, 1.0, 1.0, 0.13946829615954773, 1.0, 1.0, 0.13946829615954773, 1.0, 1.0, 0.3015464866791315, 0.0, 0.0, 0.8096049824067558, 0.3384720869201429, 0.3384720869201429, 0.4758838610267554], 
reward next is 0.5241, 
noisyNet noise sample is [array([-1.2390176], dtype=float32), -1.95746]. 
=============================================
[2019-03-24 04:29:31,517] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 04:29:31,517] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:29:31,518] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:29:31,518] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:29:31,518] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:29:31,519] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:29:31,519] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:29:31,522] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:29:31,524] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:29:31,524] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:29:31,526] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:29:31,551] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run74
[2019-03-24 04:29:31,576] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run74
[2019-03-24 04:29:31,576] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run74
[2019-03-24 04:29:31,577] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run74
[2019-03-24 04:29:31,629] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run74
[2019-03-24 04:29:49,035] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06540123], dtype=float32), 0.41267338]
[2019-03-24 04:29:49,036] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.2, 37.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6278402829401123, 6.9112, 6.9112, 121.9260426156618, 467411.5446038169, 467411.5446038169, 134143.4526026457]
[2019-03-24 04:29:49,037] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:29:49,039] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9999976e-01 5.0265527e-15 2.8698352e-07 1.6677045e-14 2.7590168e-09], sampled 0.3177451722281457
[2019-03-24 04:30:15,169] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06540123], dtype=float32), 0.41267338]
[2019-03-24 04:30:15,170] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.5, 94.5, 1.0, 2.0, 0.5614146598641964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.926042595562, 666759.7427472553, 666759.7427472553, 152767.4603649088]
[2019-03-24 04:30:15,171] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:30:15,175] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9999201e-01 5.2970683e-12 7.7951709e-06 1.4309453e-11 1.8617716e-07], sampled 0.34822889491732667
[2019-03-24 04:30:21,987] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06540123], dtype=float32), 0.41267338]
[2019-03-24 04:30:21,989] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [17.7764896, 91.73825975666668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5417676925880681, 6.9112, 6.9112, 121.9260426156618, 393967.2137844628, 393967.2137844628, 120908.0745184396]
[2019-03-24 04:30:21,990] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:30:21,993] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9999952e-01 1.2344254e-14 4.3711742e-07 3.9866900e-14 4.7444568e-09], sampled 0.5292684365105109
[2019-03-24 04:30:25,452] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06540123], dtype=float32), 0.41267338]
[2019-03-24 04:30:25,453] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.18333333333334, 98.66666666666667, 1.0, 2.0, 0.6003225860038305, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9557331080597881, 6.9112, 6.9112, 121.9260426156618, 1368905.565648559, 1368905.565648559, 293989.0170041262]
[2019-03-24 04:30:25,454] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:30:25,460] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9998689e-01 1.2158165e-11 1.2807314e-05 3.1740811e-11 3.1085008e-07], sampled 0.6369962368832576
[2019-03-24 04:30:25,461] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1368905.565648559 W.
[2019-03-24 04:30:57,645] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06540123], dtype=float32), 0.41267338]
[2019-03-24 04:30:57,647] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.39426890833333, 46.59130672666667, 1.0, 1.0, 0.5877296728267742, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260173106767, 744635.4594854572, 744635.4594854572, 158478.3110693697]
[2019-03-24 04:30:57,649] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:30:57,652] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9998534e-01 2.3509939e-11 1.4193861e-05 6.0864404e-11 4.4608839e-07], sampled 0.6456681881238596
[2019-03-24 04:30:57,653] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 744635.4594854572 W.
[2019-03-24 04:31:03,409] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06540123], dtype=float32), 0.41267338]
[2019-03-24 04:31:03,412] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.28333333333333, 82.0, 1.0, 2.0, 0.787263111819507, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1612403.13832305, 1612403.138323051, 333719.8599102068]
[2019-03-24 04:31:03,415] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:31:03,418] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9997485e-01 2.9758796e-11 2.4499966e-05 7.3150007e-11 5.4577498e-07], sampled 0.5042632448644924
[2019-03-24 04:31:03,420] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1612403.13832305 W.
[2019-03-24 04:31:08,197] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06540123], dtype=float32), 0.41267338]
[2019-03-24 04:31:08,197] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.78023267333333, 98.54775696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7424527972714128, 6.9112, 6.9112, 121.9260426156618, 551807.180503911, 551807.180503911, 145205.1543113873]
[2019-03-24 04:31:08,198] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:31:08,202] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.99999285e-01 3.18973736e-14 6.79439552e-07 1.00178715e-13
 8.39975733e-09], sampled 0.3413905767215746
[2019-03-24 04:31:14,544] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 04:31:14,882] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 04:31:15,148] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 04:31:15,368] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 04:31:15,392] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 04:31:16,411] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1825000, evaluation results [1825000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 04:31:19,486] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999797e-01 4.2971334e-12 1.8795002e-06 2.4593361e-10 1.2716734e-07], sum to 1.0000
[2019-03-24 04:31:19,493] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7923
[2019-03-24 04:31:19,499] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1018901.142621101 W.
[2019-03-24 04:31:19,502] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.8938659017340921, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1018901.142621101, 1018901.142621101, 216110.8339133486], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4906800.0000, 
sim time next is 4907400.0000, 
raw observation next is [29.01666666666667, 88.5, 1.0, 2.0, 0.4468769892785925, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7114427206990086, 6.911199999999999, 6.9112, 121.9260426156618, 1018773.478659323, 1018773.478659324, 239017.8841922124], 
processed observation next is [1.0, 0.8260869565217391, 0.630246913580247, 0.885, 1.0, 1.0, 0.34152022533165777, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.6393034008737608, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3638476709497582, 0.36384767094975856, 0.45964977729271617], 
reward next is 0.5404, 
noisyNet noise sample is [array([0.31663144], dtype=float32), -0.7588599]. 
=============================================
[2019-03-24 04:31:23,013] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9715155e-01 3.1164410e-10 2.8477728e-03 1.9101597e-08 7.6324204e-07], sum to 1.0000
[2019-03-24 04:31:23,021] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7315
[2019-03-24 04:31:23,031] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1753012.895971842 W.
[2019-03-24 04:31:23,034] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.85, 83.83333333333333, 1.0, 2.0, 0.512393057290002, 1.0, 1.0, 0.512393057290002, 1.0, 2.0, 0.8157464346825457, 6.911199999999999, 6.9112, 121.94756008, 1753012.895971842, 1753012.895971843, 349713.3511278993], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4967400.0000, 
sim time next is 4968000.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.7786320714593363, 1.0, 2.0, 0.7786320714593363, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1775941.053719553, 1775941.053719553, 335003.265361106], 
processed observation next is [1.0, 0.5217391304347826, 0.5185185185185185, 0.84, 1.0, 1.0, 0.7364667517373051, 1.0, 1.0, 0.7364667517373051, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6342646620426975, 0.6342646620426975, 0.6442370487713578], 
reward next is 0.3558, 
noisyNet noise sample is [array([-0.18966632], dtype=float32), 0.07914305]. 
=============================================
[2019-03-24 04:31:23,047] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[25.607555]
 [25.547142]
 [25.414722]
 [25.303476]
 [25.089485]], R is [[25.80653381]
 [25.54846954]
 [25.60883331]
 [25.72745705]
 [25.86383247]].
[2019-03-24 04:31:23,160] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9999535e-01 3.4299267e-12 4.6883069e-06 5.5092541e-12 5.4080647e-09], sum to 1.0000
[2019-03-24 04:31:23,165] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0237
[2019-03-24 04:31:23,170] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 712246.0254530534 W.
[2019-03-24 04:31:23,175] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.91666666666667, 75.66666666666666, 1.0, 2.0, 0.312483575579226, 1.0, 1.0, 0.312483575579226, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 712246.0254530534, 712246.0254530539, 183483.3722259824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4931400.0000, 
sim time next is 4932000.0000, 
raw observation next is [26.9, 75.0, 1.0, 2.0, 0.6146847534886646, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 703886.2615638886, 703886.2615638886, 160787.5904245727], 
processed observation next is [1.0, 0.08695652173913043, 0.5518518518518518, 0.75, 1.0, 1.0, 0.5412913732007911, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25138795055853164, 0.25138795055853164, 0.3092069046626398], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3638915], dtype=float32), -1.4329073]. 
=============================================
[2019-03-24 04:31:23,202] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[27.697168]
 [28.26597 ]
 [28.088778]
 [28.13537 ]
 [27.776861]], R is [[27.88839531]
 [27.60951233]
 [28.01849747]
 [27.73831367]
 [28.0263195 ]].
[2019-03-24 04:31:35,361] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9384664e-01 7.9129287e-13 7.0614249e-01 1.9459855e-10 1.0835481e-05], sum to 1.0000
[2019-03-24 04:31:35,366] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9412
[2019-03-24 04:31:35,369] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.98333333333333, 69.83333333333334, 1.0, 2.0, 0.3946833254036255, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6283487079811, 6.9112, 6.9112, 121.9260426156618, 899714.4611758752, 899714.4611758752, 222472.0396258957], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5155800.0000, 
sim time next is 5156400.0000, 
raw observation next is [30.96666666666667, 69.66666666666667, 1.0, 2.0, 0.3819573343115409, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6080885157059063, 6.911199999999999, 6.9112, 121.9260426156618, 870687.9950775777, 870687.9950775781, 218604.4257317354], 
processed observation next is [0.0, 0.6956521739130435, 0.7024691358024692, 0.6966666666666668, 1.0, 1.0, 0.26423492179945346, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5101106446323828, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.310959998241992, 0.31095999824199216, 0.42039312640718346], 
reward next is 0.5796, 
noisyNet noise sample is [array([-0.63049096], dtype=float32), 0.40983716]. 
=============================================
[2019-03-24 04:31:36,066] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6517579e-02 6.1488290e-14 9.6348232e-01 1.8430757e-13 9.7158022e-08], sum to 1.0000
[2019-03-24 04:31:36,073] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7727
[2019-03-24 04:31:36,079] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.33333333333334, 100.0, 1.0, 2.0, 0.3688355766222705, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5872303474007853, 6.911199999999997, 6.9112, 121.9260426156618, 841751.5734125639, 841751.5734125653, 214662.1242102282], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5206800.0000, 
sim time next is 5207400.0000, 
raw observation next is [23.5, 100.0, 1.0, 2.0, 0.3790887685318521, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6035216655619764, 6.911199999999999, 6.9112, 121.9260426156618, 864145.2908902932, 864145.2908902937, 217733.1777178619], 
processed observation next is [1.0, 0.2608695652173913, 0.42592592592592593, 1.0, 1.0, 1.0, 0.26081996253791917, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5044020819524705, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3086233181751047, 0.30862331817510485, 0.41871764945742673], 
reward next is 0.5813, 
noisyNet noise sample is [array([0.3558933], dtype=float32), 0.5923268]. 
=============================================
[2019-03-24 04:31:36,192] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0278695e-04 1.3260329e-15 9.9979728e-01 1.2993989e-14 6.6201322e-11], sum to 1.0000
[2019-03-24 04:31:36,199] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8672
[2019-03-24 04:31:36,206] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.25, 95.5, 1.0, 2.0, 0.4813727638868286, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7663611173242676, 6.911199999999999, 6.9112, 121.9260426156618, 1097471.978226583, 1097471.978226584, 250540.7754742857], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5211000.0000, 
sim time next is 5211600.0000, 
raw observation next is [24.33333333333333, 94.0, 1.0, 2.0, 0.4145192255095866, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6599281069599563, 6.911199999999999, 6.9112, 121.9260426156618, 944959.9731498967, 944959.9731498971, 228621.6817632619], 
processed observation next is [1.0, 0.30434782608695654, 0.45679012345678993, 0.94, 1.0, 1.0, 0.3029990779876031, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5749101336999454, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33748570469639166, 0.33748570469639183, 0.4396570803139652], 
reward next is 0.5603, 
noisyNet noise sample is [array([-1.6131455], dtype=float32), 1.9015805]. 
=============================================
[2019-03-24 04:31:37,176] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9827886e-01 1.5829971e-11 1.7034909e-03 2.9801700e-10 1.7568533e-05], sum to 1.0000
[2019-03-24 04:31:37,184] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4556
[2019-03-24 04:31:37,190] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 737704.8795230578 W.
[2019-03-24 04:31:37,195] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.93333333333333, 92.0, 1.0, 2.0, 0.2157651931176623, 1.0, 2.0, 0.2157651931176623, 1.0, 1.0, 0.3435052144250791, 6.911200000000001, 6.9112, 121.94756008, 737704.8795230578, 737704.8795230574, 225813.6056975887], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5182800.0000, 
sim time next is 5183400.0000, 
raw observation next is [24.96666666666667, 93.0, 1.0, 2.0, 0.3284133293683196, 1.0, 2.0, 0.3284133293683196, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 748572.5546789026, 748572.5546789021, 187419.0633878326], 
processed observation next is [0.0, 1.0, 0.48024691358024696, 0.93, 1.0, 1.0, 0.200492058771809, 1.0, 1.0, 0.200492058771809, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26734734095675095, 0.2673473409567508, 0.36042127574583194], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.39724204], dtype=float32), -1.4473392]. 
=============================================
[2019-03-24 04:31:38,967] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9920076e-01 1.5901637e-10 7.9422107e-04 1.5742554e-08 4.9557671e-06], sum to 1.0000
[2019-03-24 04:31:38,980] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6675
[2019-03-24 04:31:38,985] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1817712.526569581 W.
[2019-03-24 04:31:38,988] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.7969274695022013, 1.0, 2.0, 0.7969274695022013, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1817712.526569581, 1817712.526569582, 342486.3689048251], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5216400.0000, 
sim time next is 5217000.0000, 
raw observation next is [26.16666666666667, 88.16666666666667, 1.0, 2.0, 0.8095410104731784, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1637830.346324961, 1637830.34632496, 338136.423610047], 
processed observation next is [1.0, 0.391304347826087, 0.5246913580246916, 0.8816666666666667, 1.0, 1.0, 0.7732631077061647, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5849394094017718, 0.5849394094017715, 0.6502623530962441], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9146257], dtype=float32), 0.6622221]. 
=============================================
[2019-03-24 04:31:39,005] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[24.121256]
 [23.671768]
 [23.191694]
 [23.680067]
 [23.55259 ]], R is [[23.69948959]
 [23.80386734]
 [23.56582832]
 [23.63123512]
 [23.76417732]].
[2019-03-24 04:31:39,896] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9760950e-01 3.9291979e-11 2.3901241e-03 1.5773627e-10 3.0156625e-07], sum to 1.0000
[2019-03-24 04:31:39,902] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3292
[2019-03-24 04:31:39,917] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 787585.92290482 W.
[2019-03-24 04:31:39,925] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.85, 90.0, 1.0, 2.0, 0.3455204635466488, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5500798307821627, 6.911199999999999, 6.9112, 121.9260426156618, 787585.92290482, 787585.9229048204, 207885.1406773057], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5266200.0000, 
sim time next is 5266800.0000, 
raw observation next is [25.8, 90.0, 1.0, 2.0, 0.3437807731210775, 1.0, 1.0, 0.3437807731210775, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 783618.4123867779, 783618.4123867784, 191299.1564843486], 
processed observation next is [1.0, 1.0, 0.5111111111111112, 0.9, 1.0, 1.0, 0.21878663466794943, 1.0, 0.5, 0.21878663466794943, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27986371870956356, 0.2798637187095637, 0.36788299323913193], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5258001], dtype=float32), -0.4798593]. 
=============================================
[2019-03-24 04:31:42,805] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3532132e-01 5.6710481e-09 8.6423385e-01 1.4302915e-07 4.4475679e-04], sum to 1.0000
[2019-03-24 04:31:42,811] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0897
[2019-03-24 04:31:42,818] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1274737.363764744 W.
[2019-03-24 04:31:42,824] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.45, 72.0, 1.0, 2.0, 0.5528357460221031, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8809698349823699, 6.911199999999999, 6.9112, 121.9260426156618, 1274737.363764744, 1274737.363764745, 275744.7131280845], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5315400.0000, 
sim time next is 5316000.0000, 
raw observation next is [26.63333333333333, 71.0, 1.0, 2.0, 0.6238773861349793, 1.0, 1.0, 0.6238773861349793, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1428520.715023939, 1428520.715023939, 276644.3913815015], 
processed observation next is [1.0, 0.5217391304347826, 0.5419753086419752, 0.71, 1.0, 1.0, 0.552234983494023, 1.0, 0.5, 0.552234983494023, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5101859696514068, 0.5101859696514068, 0.532008444964426], 
reward next is 0.4680, 
noisyNet noise sample is [array([0.635084], dtype=float32), -0.84499854]. 
=============================================
[2019-03-24 04:31:42,845] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[29.888865]
 [29.740086]
 [29.563509]
 [29.955921]
 [29.901663]], R is [[30.31979179]
 [30.48631477]
 [30.61762428]
 [30.64077377]
 [30.75478363]].
[2019-03-24 04:31:46,431] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.1262061e-15 1.1870597e-09 8.2962240e-12 2.5408378e-10], sum to 1.0000
[2019-03-24 04:31:46,437] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2658
[2019-03-24 04:31:46,441] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 794964.7911373801 W.
[2019-03-24 04:31:46,448] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.68333333333333, 93.16666666666667, 1.0, 2.0, 0.6975119125361281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 794964.7911373801, 794964.7911373801, 175673.7950248041], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5602200.0000, 
sim time next is 5602800.0000, 
raw observation next is [25.56666666666667, 93.33333333333334, 1.0, 2.0, 0.3468656486338982, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5522214092506835, 6.9112, 6.9112, 121.9260426156618, 790653.7448559483, 790653.7448559483, 208271.8010520916], 
processed observation next is [1.0, 0.8695652173913043, 0.5024691358024692, 0.9333333333333335, 1.0, 1.0, 0.22245910551654546, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.4402767615633544, 0.0, 0.0, 0.8094621288201359, 0.28237633744855295, 0.28237633744855295, 0.4005226943309454], 
reward next is 0.5995, 
noisyNet noise sample is [array([-1.4206319], dtype=float32), 1.2564639]. 
=============================================
[2019-03-24 04:31:49,101] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9993932e-01 1.2179757e-10 2.3016131e-05 2.1832918e-09 3.7671347e-05], sum to 1.0000
[2019-03-24 04:31:49,108] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8244
[2019-03-24 04:31:49,115] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 846549.8221612391 W.
[2019-03-24 04:31:49,118] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.63333333333333, 92.16666666666667, 1.0, 2.0, 0.371374136650931, 1.0, 2.0, 0.371374136650931, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 846549.8221612391, 846549.8221612391, 198471.9240366169], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5447400.0000, 
sim time next is 5448000.0000, 
raw observation next is [26.56666666666667, 92.33333333333334, 1.0, 2.0, 0.3701640692910234, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5893132537134147, 6.911199999999999, 6.9112, 121.9260426156618, 843789.9471624143, 843789.9471624148, 215076.0620257617], 
processed observation next is [1.0, 0.043478260869565216, 0.5395061728395063, 0.9233333333333335, 1.0, 1.0, 0.2501953205845517, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4866415671417683, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3013535525580051, 0.3013535525580053, 0.41360781158800325], 
reward next is 0.5864, 
noisyNet noise sample is [array([-0.4853728], dtype=float32), -0.83168536]. 
=============================================
[2019-03-24 04:31:49,132] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[27.206148]
 [27.292948]
 [27.322737]
 [27.140497]
 [27.245485]], R is [[27.64917564]
 [27.99100685]
 [27.71109772]
 [27.43398666]
 [27.77707481]].
[2019-03-24 04:31:51,576] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4835885e-05 2.1008660e-15 9.9997520e-01 2.8838287e-14 6.3348531e-09], sum to 1.0000
[2019-03-24 04:31:51,588] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8754
[2019-03-24 04:31:51,593] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.2, 92.5, 1.0, 2.0, 0.4664572912628698, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7426151991438946, 6.9112, 6.9112, 121.9260426156618, 1063442.89651391, 1063442.89651391, 245502.2348945792], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5470200.0000, 
sim time next is 5470800.0000, 
raw observation next is [27.26666666666667, 92.33333333333333, 1.0, 2.0, 0.4495898001121234, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7157616038960707, 6.9112, 6.9112, 121.9260426156618, 1024962.179835402, 1024962.179835402, 239903.8680588919], 
processed observation next is [1.0, 0.30434782608695654, 0.5654320987654322, 0.9233333333333333, 1.0, 1.0, 0.3447497620382422, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6447020048700882, 0.0, 0.0, 0.8094621288201359, 0.36605792136978643, 0.36605792136978643, 0.461353592420946], 
reward next is 0.5386, 
noisyNet noise sample is [array([-0.13382976], dtype=float32), 0.37056622]. 
=============================================
[2019-03-24 04:31:52,020] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4103467e-06 1.7070532e-15 9.9999762e-01 2.1869218e-15 1.0909113e-10], sum to 1.0000
[2019-03-24 04:31:52,028] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7683
[2019-03-24 04:31:52,037] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 2050411.601157442 W.
[2019-03-24 04:31:52,043] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.3, 88.0, 1.0, 2.0, 0.5992209083193359, 1.0, 2.0, 0.5992209083193359, 1.0, 2.0, 0.9539792013069355, 6.9112, 6.9112, 121.94756008, 2050411.601157442, 2050411.601157442, 394951.2686019088], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5475600.0000, 
sim time next is 5476200.0000, 
raw observation next is [28.43333333333334, 87.50000000000001, 1.0, 2.0, 0.6302210153500782, 1.0, 2.0, 0.628475169651474, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2150634.238207602, 2150634.238207602, 411015.6063881614], 
processed observation next is [1.0, 0.391304347826087, 0.6086419753086423, 0.8750000000000001, 1.0, 1.0, 0.5597869230358075, 1.0, 1.0, 0.5577085352993738, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.7680836565027149, 0.7680836565027149, 0.7904146276695412], 
reward next is 0.2096, 
noisyNet noise sample is [array([-0.463467], dtype=float32), -0.63261175]. 
=============================================
[2019-03-24 04:31:53,278] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8798922e-03 1.0741127e-15 9.9712014e-01 1.0793373e-15 8.5326459e-12], sum to 1.0000
[2019-03-24 04:31:53,287] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0234
[2019-03-24 04:31:53,293] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 2547182.776069116 W.
[2019-03-24 04:31:53,297] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.91666666666667, 76.16666666666666, 1.0, 2.0, 0.8616559184830397, 1.0, 2.0, 0.7441926212179545, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2547182.776069116, 2547182.776069116, 475504.5812774832], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5485800.0000, 
sim time next is 5486400.0000, 
raw observation next is [31.1, 75.0, 1.0, 2.0, 0.7418166556191386, 1.0, 2.0, 0.684272989786004, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2341824.066112308, 2341824.066112307, 440665.937115538], 
processed observation next is [1.0, 0.5217391304347826, 0.7074074074074075, 0.75, 1.0, 1.0, 0.6926388757370697, 1.0, 1.0, 0.6241345116500048, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.8363657378972528, 0.8363657378972524, 0.8474344944529577], 
reward next is 0.1526, 
noisyNet noise sample is [array([0.49556422], dtype=float32), 0.702126]. 
=============================================
[2019-03-24 04:32:00,937] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9447329e-01 3.1378867e-14 6.8942946e-01 6.2829006e-11 1.6097300e-02], sum to 1.0000
[2019-03-24 04:32:00,941] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5981
[2019-03-24 04:32:00,947] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.95, 96.0, 1.0, 2.0, 0.304008330139685, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4839911624424761, 6.9112, 6.9112, 121.9260426156618, 692919.607768036, 692919.607768036, 196325.5210578398], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5638200.0000, 
sim time next is 5638800.0000, 
raw observation next is [24.0, 96.0, 1.0, 2.0, 0.3053442918333907, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4861180569680905, 6.911199999999999, 6.9112, 121.9260426156618, 695966.0186034793, 695966.0186034797, 196686.8157800582], 
processed observation next is [0.0, 0.2608695652173913, 0.4444444444444444, 0.96, 1.0, 1.0, 0.17302891884927463, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3576475712101131, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24855929235838545, 0.24855929235838561, 0.37824387650011193], 
reward next is 0.6218, 
noisyNet noise sample is [array([-1.2678839], dtype=float32), -0.727777]. 
=============================================
[2019-03-24 04:32:02,487] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.4271046e-01 7.0682196e-11 5.0086815e-02 2.6931407e-10 7.2027748e-03], sum to 1.0000
[2019-03-24 04:32:02,504] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8052
[2019-03-24 04:32:02,512] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 808216.3929473655 W.
[2019-03-24 04:32:02,518] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.4, 77.0, 1.0, 2.0, 0.3545664522469563, 1.0, 1.0, 0.3545664522469563, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808216.3929473655, 808216.3929473655, 194071.6605405359], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5661000.0000, 
sim time next is 5661600.0000, 
raw observation next is [28.5, 76.33333333333334, 1.0, 2.0, 0.3542273290531127, 1.0, 2.0, 0.3542273290531127, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 807442.9715171958, 807442.9715171958, 193983.8452753143], 
processed observation next is [0.0, 0.5217391304347826, 0.6111111111111112, 0.7633333333333334, 1.0, 1.0, 0.23122301077751514, 1.0, 1.0, 0.23122301077751514, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2883724898275699, 0.2883724898275699, 0.3730458562986813], 
reward next is 0.6270, 
noisyNet noise sample is [array([0.7657484], dtype=float32), 0.14868757]. 
=============================================
[2019-03-24 04:32:06,295] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.6114237e-31 6.1314577e-19 3.4770494e-25 3.7781466e-18], sum to 1.0000
[2019-03-24 04:32:06,301] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5849
[2019-03-24 04:32:06,305] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.93333333333334, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7044861520417282, 6.911200000000001, 6.9112, 121.9260426156618, 526440.1265918176, 526440.1265918172, 145592.9187366422], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5732400.0000, 
sim time next is 5733000.0000, 
raw observation next is [22.15, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7082325740498482, 6.9112, 6.9112, 121.9260426156618, 529204.6763012672, 529204.6763012672, 146223.4931419707], 
processed observation next is [0.0, 0.34782608695652173, 0.3759259259259259, 0.84, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6352907175623101, 0.0, 0.0, 0.8094621288201359, 0.18900167010759544, 0.18900167010759544, 0.2811990252730206], 
reward next is 0.7188, 
noisyNet noise sample is [array([0.4459261], dtype=float32), -1.7123277]. 
=============================================
[2019-03-24 04:32:06,328] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[79.7626  ]
 [79.81881 ]
 [79.893105]
 [79.909004]
 [79.92019 ]], R is [[79.62548065]
 [79.54924011]
 [79.47483063]
 [79.40170288]
 [79.32862091]].
[2019-03-24 04:32:06,588] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.1405863e-22 1.4390426e-10 1.4265369e-18 1.5338453e-12], sum to 1.0000
[2019-03-24 04:32:06,595] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9311
[2019-03-24 04:32:06,600] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.36666666666667, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7472002507750065, 6.9112, 6.9112, 121.9260426156618, 557594.9187950284, 557594.9187950284, 152034.9143968339], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5794800.0000, 
sim time next is 5795400.0000, 
raw observation next is [22.28333333333333, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7420625055701893, 6.9112, 6.9112, 121.9260426156618, 553925.4668038189, 553925.4668038189, 151230.5484465827], 
processed observation next is [1.0, 0.043478260869565216, 0.38086419753086415, 0.86, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6775781319627366, 0.0, 0.0, 0.8094621288201359, 0.19783052385850677, 0.19783052385850677, 0.2908279777818898], 
reward next is 0.7092, 
noisyNet noise sample is [array([1.7997456], dtype=float32), 1.3825185]. 
=============================================
[2019-03-24 04:32:06,704] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 04:32:06,708] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:32:06,710] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:32:06,711] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:32:06,714] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:32:06,716] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:32:06,716] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:32:06,716] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:32:06,717] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:32:06,717] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:32:06,718] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:32:06,736] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run75
[2019-03-24 04:32:06,759] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run75
[2019-03-24 04:32:06,784] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run75
[2019-03-24 04:32:06,808] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run75
[2019-03-24 04:32:06,833] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run75
[2019-03-24 04:32:09,535] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07025749], dtype=float32), 0.41677657]
[2019-03-24 04:32:09,536] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.46666666666667, 38.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6880593189313161, 6.911200000000001, 6.9112, 121.9260426156618, 491324.0321140717, 491324.0321140712, 114474.8110484299]
[2019-03-24 04:32:09,537] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:32:09,539] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.2130318e-30 1.4204916e-20 2.7357731e-27 3.4359199e-20], sampled 0.320400742718993
[2019-03-24 04:32:22,287] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07025749], dtype=float32), 0.41677657]
[2019-03-24 04:32:22,287] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.36671779, 56.7690053, 1.0, 2.0, 0.7819770473359193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 946754.3129785912, 946754.3129785912, 194728.2926443965]
[2019-03-24 04:32:22,288] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:32:22,291] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.4841244e-26 2.1815113e-15 7.9949904e-23 9.3489080e-16], sampled 0.6256392248207874
[2019-03-24 04:32:22,292] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 946754.3129785912 W.
[2019-03-24 04:32:24,067] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07025749], dtype=float32), 0.41677657]
[2019-03-24 04:32:24,067] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.44073473, 21.52231445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6297667207385965, 6.9112, 6.9112, 121.9260426156618, 464119.5432887049, 464119.5432887049, 131247.8056754302]
[2019-03-24 04:32:24,068] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:32:24,073] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 5.5894260e-34 4.4038652e-23 2.3077504e-30 1.4799299e-22], sampled 0.49774049880620275
[2019-03-24 04:33:02,050] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07025749], dtype=float32), 0.41677657]
[2019-03-24 04:33:02,051] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.67145217833333, 60.31087218166667, 1.0, 2.0, 0.6068671295522401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696801.3175873087, 696801.3175873087, 159518.5372261425]
[2019-03-24 04:33:02,053] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:33:02,056] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.9899431e-31 2.5473867e-19 1.6410811e-27 2.0127211e-19], sampled 0.5333034106876791
[2019-03-24 04:33:02,056] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 696801.3175873087 W.
[2019-03-24 04:33:09,946] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07025749], dtype=float32), 0.41677657]
[2019-03-24 04:33:09,947] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.7, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8338102611662436, 6.911200000000001, 6.9112, 121.9260426156618, 617199.4625530669, 617199.4625530664, 165451.7413006619]
[2019-03-24 04:33:09,949] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:33:09,953] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.3010053e-34 5.8181717e-23 1.8437915e-30 1.6405971e-22], sampled 0.8199560867420228
[2019-03-24 04:33:44,477] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07025749], dtype=float32), 0.41677657]
[2019-03-24 04:33:44,478] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.4, 62.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6040076350951314, 6.911200000000001, 6.9112, 121.9260426156618, 448195.5818930812, 448195.5818930807, 130669.8824083545]
[2019-03-24 04:33:44,479] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:33:44,481] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.1487754e-34 2.8651034e-23 1.0490710e-30 9.0460782e-23], sampled 0.746474229233357
[2019-03-24 04:33:50,656] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 04:33:50,925] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07025749], dtype=float32), 0.41677657]
[2019-03-24 04:33:50,926] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.35068168999999, 49.56099716666667, 1.0, 2.0, 0.8048104486011392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 988644.0135091987, 988644.0135091982, 199977.7395086973]
[2019-03-24 04:33:50,927] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:33:50,930] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.1517909e-25 3.3086977e-14 2.9094134e-22 5.8702289e-15], sampled 0.8889618222527762
[2019-03-24 04:33:50,931] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 988644.0135091987 W.
[2019-03-24 04:33:51,046] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 04:33:51,184] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 04:33:51,223] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 04:33:51,295] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 04:33:52,309] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1850000, evaluation results [1850000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 04:34:05,003] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 3.7411314e-25 3.4372135e-15 7.2852169e-23 1.0813481e-12], sum to 1.0000
[2019-03-24 04:34:05,008] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1024
[2019-03-24 04:34:05,012] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.46666666666667, 57.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8112905259923696, 6.9112, 6.9112, 121.9260426156618, 598902.7697247436, 598902.7697247436, 163159.3527694442], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6025200.0000, 
sim time next is 6025800.0000, 
raw observation next is [28.33333333333333, 58.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8237389254610209, 6.911200000000001, 6.9112, 121.9260426156618, 608219.6954214588, 608219.6954214583, 164715.874291787], 
processed observation next is [1.0, 0.7391304347826086, 0.6049382716049381, 0.5833333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.779673656826276, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21722131979337814, 0.21722131979337797, 0.31676129671497505], 
reward next is 0.6832, 
noisyNet noise sample is [array([-0.8629728], dtype=float32), -0.5087443]. 
=============================================
[2019-03-24 04:34:06,157] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9999988e-01 2.5753209e-19 8.8966023e-10 8.7907390e-14 1.2689912e-07], sum to 1.0000
[2019-03-24 04:34:06,165] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6865
[2019-03-24 04:34:06,178] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1167645.688484676 W.
[2019-03-24 04:34:06,181] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.03333333333333, 71.16666666666667, 1.0, 2.0, 0.4920603666259848, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7900779185899283, 6.911199999999999, 6.9112, 121.9260426156618, 1167645.688484676, 1167645.688484677, 253093.451345878], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5997000.0000, 
sim time next is 5997600.0000, 
raw observation next is [25.2, 71.0, 1.0, 2.0, 0.5597380878054156, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8976238436088905, 6.9112, 6.9112, 121.9260426156618, 1324188.916674417, 1324188.916674417, 277457.9475940802], 
processed observation next is [1.0, 0.43478260869565216, 0.4888888888888889, 0.71, 1.0, 1.0, 0.47587867595882805, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.872029804511113, 0.0, 0.0, 0.8094621288201359, 0.47292461309800604, 0.47292461309800604, 0.5335729761424619], 
reward next is 0.4664, 
noisyNet noise sample is [array([0.08652726], dtype=float32), -0.4921496]. 
=============================================
[2019-03-24 04:34:10,774] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.0165549e-20 8.4023378e-14 4.0896837e-20 3.4678994e-08], sum to 1.0000
[2019-03-24 04:34:10,784] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5067
[2019-03-24 04:34:10,794] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1061679.059444803 W.
[2019-03-24 04:34:10,800] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.5, 57.33333333333333, 1.0, 2.0, 0.4656841561474788, 1.0, 2.0, 0.4656841561474788, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1061679.059444803, 1061679.059444803, 224973.2499200047], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6093600.0000, 
sim time next is 6094200.0000, 
raw observation next is [29.65, 56.66666666666667, 1.0, 2.0, 0.4595562500984814, 1.0, 2.0, 0.4595562500984814, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1048859.269295219, 1048859.269295219, 223214.1812553737], 
processed observation next is [1.0, 0.5217391304347826, 0.6537037037037037, 0.5666666666666668, 1.0, 1.0, 0.3566145834505731, 1.0, 1.0, 0.3566145834505731, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.37459259617686397, 0.37459259617686397, 0.42925804087571867], 
reward next is 0.5707, 
noisyNet noise sample is [array([0.79237396], dtype=float32), 0.3480467]. 
=============================================
[2019-03-24 04:34:12,464] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999952e-01 1.8432570e-14 1.1078233e-08 1.5973868e-13 4.4533641e-07], sum to 1.0000
[2019-03-24 04:34:12,471] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1635
[2019-03-24 04:34:12,476] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.1, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.900698759416045, 6.911200000000001, 6.9112, 121.9260426156618, 663783.0012868583, 663783.0012868579, 174933.852496223], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6162600.0000, 
sim time next is 6163200.0000, 
raw observation next is [24.2, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9153840426667468, 6.911199999999999, 6.9112, 121.9260426156618, 674183.5171303323, 674183.5171303326, 176994.9714129163], 
processed observation next is [1.0, 0.34782608695652173, 0.45185185185185184, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8942300533334335, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24077982754654725, 0.24077982754654736, 0.340374945024839], 
reward next is 0.6596, 
noisyNet noise sample is [array([-0.5002706], dtype=float32), 0.22529787]. 
=============================================
[2019-03-24 04:34:15,531] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.6269621e-29 1.4369399e-20 7.6165498e-29 1.1669129e-15], sum to 1.0000
[2019-03-24 04:34:15,538] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8146
[2019-03-24 04:34:15,541] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.3, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8470035438677017, 6.911200000000001, 6.9112, 121.9260426156618, 622167.1396483212, 622167.1396483207, 168524.4279767216], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6199200.0000, 
sim time next is 6199800.0000, 
raw observation next is [29.18333333333333, 56.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8539744615542824, 6.911200000000001, 6.9112, 121.9260426156618, 627030.8684838145, 627030.8684838141, 169476.2571026597], 
processed observation next is [1.0, 0.782608695652174, 0.6364197530864196, 0.5666666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.817468076942853, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22393959588707663, 0.22393959588707646, 0.32591587904357633], 
reward next is 0.6741, 
noisyNet noise sample is [array([-0.2383472], dtype=float32), -0.41760305]. 
=============================================
[2019-03-24 04:34:33,120] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9999547e-01 4.9524148e-12 1.6276128e-09 3.6073613e-09 4.5040470e-06], sum to 1.0000
[2019-03-24 04:34:33,135] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8148
[2019-03-24 04:34:33,140] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1633445.478609396 W.
[2019-03-24 04:34:33,142] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.4, 80.0, 1.0, 2.0, 0.7162143018122242, 1.0, 1.0, 0.7162143018122242, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1633445.478609396, 1633445.478609396, 310349.1538267634], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6534000.0000, 
sim time next is 6534600.0000, 
raw observation next is [27.43333333333333, 79.83333333333334, 1.0, 2.0, 0.7067263618193286, 1.0, 2.0, 0.7067263618193286, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1611787.138902317, 1611787.138902317, 306719.6503896498], 
processed observation next is [1.0, 0.6521739130434783, 0.5716049382716049, 0.7983333333333335, 1.0, 1.0, 0.6508647164515816, 1.0, 1.0, 0.6508647164515816, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5756382638936847, 0.5756382638936847, 0.5898454815185573], 
reward next is 0.4102, 
noisyNet noise sample is [array([-1.1894426], dtype=float32), -0.1234456]. 
=============================================
[2019-03-24 04:34:36,073] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.3054557e-01 1.2828430e-17 1.3618287e-13 2.2392395e-11 6.9454350e-02], sum to 1.0000
[2019-03-24 04:34:36,082] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6650
[2019-03-24 04:34:36,095] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 918924.9695358761 W.
[2019-03-24 04:34:36,098] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.66666666666666, 36.66666666666667, 1.0, 2.0, 0.2497247532924567, 1.0, 2.0, 0.2497247532924567, 1.0, 2.0, 0.4098129819526972, 6.9112, 6.9112, 121.94756008, 918924.9695358761, 918924.9695358761, 236008.2167196475], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6612000.0000, 
sim time next is 6612600.0000, 
raw observation next is [28.83333333333334, 35.83333333333334, 1.0, 2.0, 0.3643434915947191, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6049080963402523, 6.911199999999999, 6.9112, 121.9260426156618, 903530.743355816, 903530.7433558165, 209753.7091667766], 
processed observation next is [1.0, 0.5217391304347826, 0.623456790123457, 0.35833333333333345, 1.0, 1.0, 0.24326606142228469, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.5061351204253154, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32268955119850573, 0.3226895511985059, 0.4033725176284165], 
reward next is 0.5966, 
noisyNet noise sample is [array([-0.81991774], dtype=float32), -1.0545615]. 
=============================================
[2019-03-24 04:34:38,481] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9999952e-01 8.8322462e-22 1.4361374e-15 1.2485461e-13 4.2956188e-07], sum to 1.0000
[2019-03-24 04:34:38,486] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2018
[2019-03-24 04:34:38,491] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 731495.699406047 W.
[2019-03-24 04:34:38,494] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.96666666666667, 43.66666666666667, 1.0, 2.0, 0.5794199480500782, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 731495.699406047, 731495.699406047, 157001.6519918362], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6601200.0000, 
sim time next is 6601800.0000, 
raw observation next is [26.13333333333333, 42.83333333333333, 1.0, 2.0, 0.2797438425492673, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4746111291628529, 6.9112, 6.9112, 121.9260426156618, 704049.6869407869, 704049.6869407869, 185282.6816132278], 
processed observation next is [1.0, 0.391304347826087, 0.5234567901234567, 0.4283333333333333, 1.0, 1.0, 0.14255219351103252, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.3432639114535661, 0.0, 0.0, 0.8094621288201359, 0.25144631676456675, 0.25144631676456675, 0.35631284925620726], 
reward next is 0.6437, 
noisyNet noise sample is [array([-1.5593309], dtype=float32), 0.23736076]. 
=============================================
[2019-03-24 04:34:39,482] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9939442e-01 1.8539665e-19 1.0943398e-12 1.2048901e-12 6.0555746e-04], sum to 1.0000
[2019-03-24 04:34:39,489] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1340
[2019-03-24 04:34:39,495] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1358232.110086277 W.
[2019-03-24 04:34:39,502] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 37.0, 1.0, 2.0, 0.5529301727807083, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9082951853908932, 6.9112, 6.9112, 121.9260426156618, 1358232.110086277, 1358232.110086277, 272548.2197817937], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6621000.0000, 
sim time next is 6621600.0000, 
raw observation next is [29.0, 37.0, 1.0, 2.0, 0.5384440489874343, 1.0, 1.0, 0.5384440489874343, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1319052.245214037, 1319052.245214037, 251168.0300290952], 
processed observation next is [1.0, 0.6521739130434783, 0.6296296296296297, 0.37, 1.0, 1.0, 0.4505286297469455, 1.0, 0.5, 0.4505286297469455, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4710900875764418, 0.4710900875764418, 0.4830154423636446], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.4748569], dtype=float32), 0.015207939]. 
=============================================
[2019-03-24 04:34:42,191] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.6661930e-08 1.9423686e-26 6.9275040e-18 1.1136279e-17 1.0000000e+00], sum to 1.0000
[2019-03-24 04:34:42,195] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5136
[2019-03-24 04:34:42,199] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.86666666666667, 48.66666666666667, 1.0, 2.0, 0.1970823087877115, 1.0, 2.0, 0.1970823087877115, 1.0, 2.0, 0.3353724835362517, 6.911199999999999, 6.9112, 121.94756008, 745296.6872180578, 745296.6872180583, 216181.7478632616], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6684000.0000, 
sim time next is 6684600.0000, 
raw observation next is [24.08333333333333, 47.83333333333334, 1.0, 2.0, 0.2053009667422112, 1.0, 2.0, 0.2053009667422112, 1.0, 2.0, 0.348231408811219, 6.911200000000002, 6.9112, 121.94756008, 774973.7490848101, 774973.7490848093, 219026.7562720458], 
processed observation next is [1.0, 0.34782608695652173, 0.4475308641975307, 0.47833333333333344, 1.0, 1.0, 0.0539297223121562, 1.0, 1.0, 0.0539297223121562, 1.0, 1.0, 0.18528926101402374, 1.7763568394002506e-16, 0.0, 0.8096049824067558, 0.2767763389588608, 0.2767763389588605, 0.421205300523165], 
reward next is 0.5788, 
noisyNet noise sample is [array([0.853327], dtype=float32), -0.18983601]. 
=============================================
[2019-03-24 04:34:42,400] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8687784e-06 3.0740123e-23 6.0984255e-16 3.6461489e-17 9.9999809e-01], sum to 1.0000
[2019-03-24 04:34:42,405] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8082
[2019-03-24 04:34:42,412] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.98333333333333, 48.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 347473.5513152126, 347473.5513152126, 166624.2187994085], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6677400.0000, 
sim time next is 6678000.0000, 
raw observation next is [23.0, 49.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.911200000000001, 6.9112, 121.94756008, 393171.7716810851, 393171.7716810846, 174255.3076245165], 
processed observation next is [1.0, 0.30434782608695654, 0.4074074074074074, 0.49, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.14041848988610184, 0.14041848988610164, 0.3351063608163779], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.02509819], dtype=float32), -0.05335682]. 
=============================================
[2019-03-24 04:34:42,428] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[63.149925]
 [62.83714 ]
 [62.752686]
 [62.387352]
 [61.76898 ]], R is [[62.55020142]
 [61.92470169]
 [61.30545425]
 [60.69240189]
 [60.08547974]].
[2019-03-24 04:34:42,635] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 04:34:42,637] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:34:42,638] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:34:42,638] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:34:42,639] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:34:42,638] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:34:42,640] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:34:42,642] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:34:42,642] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:34:42,641] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:34:42,648] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:34:42,667] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run76
[2019-03-24 04:34:42,687] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run76
[2019-03-24 04:34:42,688] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run76
[2019-03-24 04:34:42,730] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run76
[2019-03-24 04:34:42,731] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run76
[2019-03-24 04:34:44,771] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0685397], dtype=float32), 0.41875836]
[2019-03-24 04:34:44,772] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.16666666666667, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5230283875763039, 6.9112, 6.9112, 121.9260426156618, 373451.3369812683, 373451.3369812683, 97464.14787540196]
[2019-03-24 04:34:44,773] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:34:44,774] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 5.4523334e-25 6.7229427e-21 6.6226820e-20 1.1829917e-12], sampled 0.6661359422072879
[2019-03-24 04:34:48,651] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0685397], dtype=float32), 0.41875836]
[2019-03-24 04:34:48,653] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.01666666666667, 88.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5657137914163545, 6.911200000000001, 6.9112, 121.9260426156618, 403937.4821396167, 403937.4821396163, 117896.5990631279]
[2019-03-24 04:34:48,655] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:34:48,660] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.6418020e-26 3.9150735e-22 4.5293349e-21 2.4804469e-13], sampled 0.983358589475078
[2019-03-24 04:34:50,905] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0685397], dtype=float32), 0.41875836]
[2019-03-24 04:34:50,905] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.17100053, 53.78031212666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.907742874638382, 6.911200000000001, 6.9112, 121.9260426156618, 677824.8949848982, 677824.8949848977, 167124.9783248532]
[2019-03-24 04:34:50,906] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:34:50,909] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.5789066e-25 7.6409097e-21 7.2712627e-20 1.6706867e-12], sampled 0.3937406693969504
[2019-03-24 04:34:53,524] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0685397], dtype=float32), 0.41875836]
[2019-03-24 04:34:53,527] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.49925937, 55.896600975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.616691776984028, 6.9112, 6.9112, 121.9260426156618, 457615.0413578562, 457615.0413578562, 131879.4018915484]
[2019-03-24 04:34:53,527] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:34:53,531] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 5.7834819e-28 2.2431735e-23 2.8529224e-22 4.0502300e-14], sampled 0.2894015974748998
[2019-03-24 04:34:54,805] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0685397], dtype=float32), 0.41875836]
[2019-03-24 04:34:54,806] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 28.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5232873325265903, 6.9112, 6.9112, 121.9260426156618, 373636.2732048415, 373636.2732048415, 105117.1626505144]
[2019-03-24 04:34:54,809] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:34:54,813] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.0824202e-25 1.7552300e-21 1.8117288e-20 5.2776143e-13], sampled 0.5003535218672011
[2019-03-24 04:35:20,583] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0685397], dtype=float32), 0.41875836]
[2019-03-24 04:35:20,584] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7800775847203109, 6.9112, 6.9112, 121.9260426156618, 580202.9404729735, 580202.9404729735, 157447.3135875242]
[2019-03-24 04:35:20,585] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:35:20,589] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.4336287e-26 6.2145013e-22 6.6004081e-21 3.5087490e-13], sampled 0.69406312951964
[2019-03-24 04:36:08,521] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0685397], dtype=float32), 0.41875836]
[2019-03-24 04:36:08,522] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.20391833666667, 78.61216069666666, 1.0, 2.0, 0.2507216118651034, 1.0, 1.0, 0.2507216118651034, 1.0, 1.0, 0.3991569715220846, 6.9112, 6.9112, 121.94756008, 857288.2983079545, 857288.2983079545, 237881.4683746952]
[2019-03-24 04:36:08,522] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:36:08,525] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.2474237e-01 4.5700893e-18 1.1568709e-11 2.3713555e-11 5.7525760e-01], sampled 0.10792216185397896
[2019-03-24 04:36:08,527] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 857288.2983079545 W.
[2019-03-24 04:36:26,793] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8270.1811 2314678244.5801 344.0000
[2019-03-24 04:36:27,348] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8137.7355 2384944151.9440 362.0000
[2019-03-24 04:36:27,456] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8275.4290 2335449948.7386 436.0000
[2019-03-24 04:36:27,499] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8406.6505 2266589433.7955 377.0000
[2019-03-24 04:36:27,505] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7643.9851 2586579897.3461 401.0000
[2019-03-24 04:36:28,521] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1875000, evaluation results [1875000.0, 7643.985054621619, 2586579897.3460984, 401.0, 8270.181054880717, 2314678244.580115, 344.0, 8406.650535117775, 2266589433.795486, 377.0, 8137.735543382309, 2384944151.943977, 362.0, 8275.42904941582, 2335449948.738602, 436.0]
[2019-03-24 04:36:29,386] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.5880490e-05 1.9895390e-25 1.1613872e-17 3.0176336e-15 9.9995410e-01], sum to 1.0000
[2019-03-24 04:36:29,391] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4790
[2019-03-24 04:36:29,398] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.35, 32.5, 1.0, 2.0, 0.1918647507444604, 1.0, 2.0, 0.1918647507444604, 1.0, 2.0, 0.3218237200092273, 6.9112, 6.9112, 121.94756008, 719137.5018574243, 719137.5018574243, 215253.1883133789], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6697800.0000, 
sim time next is 6698400.0000, 
raw observation next is [28.5, 32.0, 1.0, 2.0, 0.2077522489873822, 1.0, 2.0, 0.2077522489873822, 1.0, 2.0, 0.3486666228578394, 6.911199999999999, 6.9112, 121.94756008, 779013.7062252022, 779013.7062252027, 220395.4104870333], 
processed observation next is [1.0, 0.5217391304347826, 0.6111111111111112, 0.32, 1.0, 1.0, 0.05684791546116929, 1.0, 1.0, 0.05684791546116929, 1.0, 1.0, 0.18583327857229923, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2782191807947151, 0.27821918079471525, 0.4238373278596794], 
reward next is 0.5762, 
noisyNet noise sample is [array([-0.81299675], dtype=float32), 1.4672115]. 
=============================================
[2019-03-24 04:36:39,007] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.1414846e-06 3.5474126e-25 9.1189549e-19 9.5693730e-22 9.9999583e-01], sum to 1.0000
[2019-03-24 04:36:39,016] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2639
[2019-03-24 04:36:39,019] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.16666666666667, 69.16666666666667, 1.0, 2.0, 0.2670006519429793, 1.0, 2.0, 0.2670006519429793, 1.0, 2.0, 0.4339374228883185, 6.9112, 6.9112, 121.94756008, 971110.4680037862, 971110.4680037862, 242775.3758186303], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7128600.0000, 
sim time next is 7129200.0000, 
raw observation next is [23.23333333333333, 68.33333333333334, 1.0, 2.0, 0.1966656588806193, 1.0, 2.0, 0.1966656588806193, 1.0, 2.0, 0.3204375098781985, 6.9112, 6.9112, 121.94756008, 717592.9307367994, 717592.9307367994, 218378.6180593501], 
processed observation next is [1.0, 0.5217391304347826, 0.4160493827160493, 0.6833333333333335, 1.0, 1.0, 0.043649593905499155, 1.0, 1.0, 0.043649593905499155, 1.0, 1.0, 0.15054688734774813, 0.0, 0.0, 0.8096049824067558, 0.2562831895488569, 0.2562831895488569, 0.4199588808833656], 
reward next is 0.5800, 
noisyNet noise sample is [array([0.3941626], dtype=float32), -0.6471223]. 
=============================================
[2019-03-24 04:36:41,862] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.3868183e-28 7.4058651e-25 2.4078845e-25 1.9115747e-13], sum to 1.0000
[2019-03-24 04:36:41,872] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6083
[2019-03-24 04:36:41,876] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.33333333333334, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8666869708671926, 6.911200000000001, 6.9112, 121.9260426156618, 637023.1647379935, 637023.164737993, 170954.946114816], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6960000.0000, 
sim time next is 6960600.0000, 
raw observation next is [30.5, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8703028441710153, 6.9112, 6.9112, 121.9260426156618, 639294.0155717502, 639294.0155717502, 171516.6513472252], 
processed observation next is [0.0, 0.5652173913043478, 0.6851851851851852, 0.505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8378785552137691, 0.0, 0.0, 0.8094621288201359, 0.22831929127562509, 0.22831929127562509, 0.32983971412927926], 
reward next is 0.6702, 
noisyNet noise sample is [array([0.10655921], dtype=float32), 1.3893012]. 
=============================================
[2019-03-24 04:36:43,933] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999988e-01 2.1051863e-22 1.7744220e-15 4.0000989e-13 1.7069110e-07], sum to 1.0000
[2019-03-24 04:36:43,940] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0489
[2019-03-24 04:36:43,944] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.53333333333333, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6911553907979476, 6.911200000000001, 6.9112, 121.9260426156618, 516351.3412152856, 516351.3412152852, 142993.0374741481], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7003200.0000, 
sim time next is 7003800.0000, 
raw observation next is [22.45, 77.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6923946279322766, 6.911200000000001, 6.9112, 121.9260426156618, 517266.9465464271, 517266.9465464267, 143094.7218447913], 
processed observation next is [1.0, 0.043478260869565216, 0.387037037037037, 0.775, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6154932849153457, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18473819519515253, 0.1847381951951524, 0.2751821573938294], 
reward next is 0.7248, 
noisyNet noise sample is [array([-0.61951935], dtype=float32), 0.1328144]. 
=============================================
[2019-03-24 04:36:47,505] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.8376101e-25 2.9164806e-22 5.5517803e-23 1.4813197e-14], sum to 1.0000
[2019-03-24 04:36:47,512] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4946
[2019-03-24 04:36:47,516] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.03333333333333, 75.0, 1.0, 1.0, 0.2544131402837968, 1.0, 1.0, 0.2544131402837968, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9259247656576, 618900.8279534382, 618900.8279534377, 171573.0911008056], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7093200.0000, 
sim time next is 7093800.0000, 
raw observation next is [22.9, 75.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7310706541686115, 6.911199999999999, 6.9112, 121.9260425797262, 546292.5761819292, 546292.5761819297, 148698.0832884791], 
processed observation next is [1.0, 0.08695652173913043, 0.4037037037037037, 0.755, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.6638383177107643, -8.881784197001253e-17, 0.0, 0.809462128581561, 0.19510449149354614, 0.1951044914935463, 0.28595785247784444], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8356531], dtype=float32), -1.054331]. 
=============================================
[2019-03-24 04:36:48,009] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.6313616e-36 4.8983466e-30 7.5623125e-32 1.2480297e-21], sum to 1.0000
[2019-03-24 04:36:48,017] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2640
[2019-03-24 04:36:48,024] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.43333333333333, 80.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7705566137148961, 6.911199999999999, 6.9112, 121.9260426156618, 574147.2485018936, 574147.2485018941, 155610.3004480784], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7069800.0000, 
sim time next is 7070400.0000, 
raw observation next is [23.4, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.770066922751432, 6.9112, 6.9112, 121.9260426156618, 573812.9029772512, 573812.9029772512, 155527.8295355796], 
processed observation next is [1.0, 0.8695652173913043, 0.42222222222222217, 0.81, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7125836534392899, 0.0, 0.0, 0.8094621288201359, 0.20493317963473257, 0.20493317963473257, 0.29909197987611463], 
reward next is 0.7009, 
noisyNet noise sample is [array([-2.071823], dtype=float32), 1.747916]. 
=============================================
[2019-03-24 04:36:50,685] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8736428e-10 3.9927492e-29 1.1778329e-17 5.8551881e-19 1.0000000e+00], sum to 1.0000
[2019-03-24 04:36:50,693] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1808
[2019-03-24 04:36:50,698] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.76666666666667, 78.66666666666667, 1.0, 2.0, 0.2227502321057451, 1.0, 2.0, 0.2227502321057451, 1.0, 2.0, 0.3632855420801616, 6.911200000000001, 6.9112, 121.94756008, 813802.9342842227, 813802.9342842222, 226993.653597684], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7119600.0000, 
sim time next is 7120200.0000, 
raw observation next is [21.88333333333334, 78.33333333333333, 1.0, 2.0, 0.2268122791950928, 1.0, 2.0, 0.2268122791950928, 1.0, 2.0, 0.3694945911166259, 6.911199999999999, 6.9112, 121.94756008, 827471.7697511958, 827471.7697511963, 228441.0853009567], 
processed observation next is [1.0, 0.391304347826087, 0.36604938271604964, 0.7833333333333333, 1.0, 1.0, 0.07953842761320572, 1.0, 1.0, 0.07953842761320572, 1.0, 1.0, 0.21186823889578238, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2955256320539985, 0.2955256320539987, 0.4393097794249167], 
reward next is 0.5607, 
noisyNet noise sample is [array([1.477944], dtype=float32), -0.22496395]. 
=============================================
[2019-03-24 04:36:51,016] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.2254833e-05 2.7808445e-22 1.9052052e-12 1.8063503e-15 9.9995780e-01], sum to 1.0000
[2019-03-24 04:36:51,019] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3825
[2019-03-24 04:36:51,031] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.26666666666667, 84.33333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2196764740985397, 6.911199999999999, 6.9112, 121.94756008, 492274.8240984487, 492274.8240984492, 194436.3534988179], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7101600.0000, 
sim time next is 7102200.0000, 
raw observation next is [21.13333333333333, 85.16666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2185116024059074, 6.911199999999999, 6.9112, 121.94756008, 489694.296682257, 489694.2966822574, 194049.5171202757], 
processed observation next is [1.0, 0.17391304347826086, 0.33827160493827146, 0.8516666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.023139503007384224, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.1748908202436632, 0.17489082024366334, 0.3731721483082225], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.314436], dtype=float32), 2.0309706]. 
=============================================
[2019-03-24 04:37:08,999] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 7.9151448e-32 7.0740817e-27 1.6197253e-25 1.7484755e-19], sum to 1.0000
[2019-03-24 04:37:09,008] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6483
[2019-03-24 04:37:09,017] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.03333333333333, 82.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7338412858711922, 6.911200000000001, 6.9112, 121.9260426156618, 547275.8294687944, 547275.8294687939, 150847.0906172093], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7469400.0000, 
sim time next is 7470000.0000, 
raw observation next is [23.2, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7381030396658695, 6.9112, 6.9112, 121.9260426156618, 550260.2323111807, 550260.2323111807, 151518.377236138], 
processed observation next is [0.0, 0.4782608695652174, 0.4148148148148148, 0.82, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6726287995823368, 0.0, 0.0, 0.8094621288201359, 0.19652151153970737, 0.19652151153970737, 0.2913814946848808], 
reward next is 0.7086, 
noisyNet noise sample is [array([0.39682284], dtype=float32), -0.80868113]. 
=============================================
[2019-03-24 04:37:09,030] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[64.48318 ]
 [64.44294 ]
 [64.412636]
 [64.393265]
 [64.36902 ]], R is [[64.61231232]
 [64.67610168]
 [64.74047852]
 [64.80541229]
 [64.8710022 ]].
[2019-03-24 04:37:18,536] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 04:37:18,537] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:37:18,538] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:37:18,539] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:37:18,539] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:37:18,541] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:37:18,541] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:37:18,543] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:37:18,541] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:37:18,546] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:37:18,547] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:37:18,567] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run77
[2019-03-24 04:37:18,591] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run77
[2019-03-24 04:37:18,616] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run77
[2019-03-24 04:37:18,617] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run77
[2019-03-24 04:37:18,664] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run77
[2019-03-24 04:37:19,975] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.42636025]
[2019-03-24 04:37:19,978] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.1, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3988593754061306, 6.9112, 6.9112, 121.9260426156618, 284776.0495034071, 284776.0495034071, 94441.81852692344]
[2019-03-24 04:37:19,978] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:37:19,980] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 6.7638900e-30 4.1560259e-25 4.3161606e-26 7.8394210e-17], sampled 0.6600855776386699
[2019-03-24 04:37:23,551] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.42636025]
[2019-03-24 04:37:23,552] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.95754737833333, 31.62730454166667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5796765582986873, 6.9112, 6.9112, 121.9260426156618, 420489.2519415171, 420489.2519415171, 123695.9305852675]
[2019-03-24 04:37:23,553] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:37:23,556] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.9988901e-31 2.1324446e-26 1.9898864e-27 1.0965007e-17], sampled 0.16622733373217602
[2019-03-24 04:37:55,344] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.42636025]
[2019-03-24 04:37:55,345] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.0, 70.0, 1.0, 2.0, 0.7169965831353015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 817183.600643201, 817183.600643201, 179390.2532633069]
[2019-03-24 04:37:55,346] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:37:55,351] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 7.7954504e-28 3.4518635e-23 2.8458978e-24 1.4854554e-15], sampled 0.5448331214695624
[2019-03-24 04:37:55,351] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 817183.600643201 W.
[2019-03-24 04:37:56,553] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.42636025]
[2019-03-24 04:37:56,554] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.86676906, 73.38387947, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 1.0, 2.0, 0.9977734948820727, 157.876420167452, 6.9112, 121.94756008, 80324933.03936218, 3003603.962646886, 512363.425667698]
[2019-03-24 04:37:56,556] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:37:56,559] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.25921912184246143
[2019-03-24 04:37:56,560] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 80324933.03936218 W.
[2019-03-24 04:38:12,353] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.42636025]
[2019-03-24 04:38:12,355] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.0, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9100397414008069, 6.911200000000001, 6.9112, 121.9260426156618, 665145.9805225284, 665145.980522528, 177456.0857843836]
[2019-03-24 04:38:12,356] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:38:12,360] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.4799788e-32 2.3994922e-27 2.0567432e-28 2.6012599e-18], sampled 0.6138102074823015
[2019-03-24 04:38:24,366] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.42636025]
[2019-03-24 04:38:24,367] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.86666666666667, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6221813964158133, 6.911199999999999, 6.9112, 121.9260426156618, 462745.4902896174, 462745.4902896179, 133198.0272954386]
[2019-03-24 04:38:24,368] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:38:24,372] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 6.3865948e-32 8.2960026e-27 7.3680658e-28 5.9075105e-18], sampled 0.3614498943957638
[2019-03-24 04:38:55,069] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.42636025]
[2019-03-24 04:38:55,070] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.94410584, 91.0594134, 1.0, 2.0, 0.5781949380186161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 709371.9754690505, 709371.9754690505, 156366.4963426819]
[2019-03-24 04:38:55,071] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:38:55,074] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.7452610e-22 3.1480412e-18 2.4474439e-19 5.6263262e-12], sampled 0.2686225444458591
[2019-03-24 04:38:55,075] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 709371.9754690505 W.
[2019-03-24 04:39:02,082] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.42636025]
[2019-03-24 04:39:02,083] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.03333333333333, 54.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9272556115711248, 6.911200000000001, 6.9112, 121.9260426156618, 692427.764910877, 692427.7649108765, 169559.9009984659]
[2019-03-24 04:39:02,084] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:39:02,088] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 7.4220518e-30 4.4751231e-25 4.6719942e-26 8.2033659e-17], sampled 0.018156615219268257
[2019-03-24 04:39:02,089] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 692427.764910877 W.
[2019-03-24 04:39:03,304] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8632.2850 2219299766.1518 543.0000
[2019-03-24 04:39:03,607] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8558.6933 2258331735.7090 536.0000
[2019-03-24 04:39:03,643] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8363.4371 2339475986.9735 616.0000
[2019-03-24 04:39:03,667] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7839.3642 2529907632.7168 831.0000
[2019-03-24 04:39:03,808] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8402.7825 2293090583.1810 697.0000
[2019-03-24 04:39:04,821] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1900000, evaluation results [1900000.0, 7839.3642237539425, 2529907632.7168317, 831.0, 8558.693290662724, 2258331735.7089543, 536.0, 8632.284958361142, 2219299766.1518497, 543.0, 8363.437110714249, 2339475986.973477, 616.0, 8402.782546002263, 2293090583.180975, 697.0]
[2019-03-24 04:39:08,767] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 6.3198734e-25 2.4491705e-20 7.3255971e-23 4.8307621e-12], sum to 1.0000
[2019-03-24 04:39:08,777] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5127
[2019-03-24 04:39:08,785] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.7, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4691331103139398, 6.911200000000001, 6.9112, 121.9260426156618, 334976.5147017079, 334976.5147017075, 108560.8104443203], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7694400.0000, 
sim time next is 7695000.0000, 
raw observation next is [19.7, 64.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4565474279702196, 6.9112, 6.9112, 121.9260426156618, 325973.8848272386, 325973.8848272386, 105338.4409356286], 
processed observation next is [1.0, 0.043478260869565216, 0.28518518518518515, 0.645, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.32068428496277446, 0.0, 0.0, 0.8094621288201359, 0.11641924458115666, 0.11641924458115666, 0.20257392487620884], 
reward next is 0.7974, 
noisyNet noise sample is [array([0.80013347], dtype=float32), 0.2851077]. 
=============================================
[2019-03-24 04:39:08,802] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[60.95042 ]
 [61.07783 ]
 [61.29067 ]
 [61.3619  ]
 [61.523808]], R is [[61.03224564]
 [61.21315384]
 [61.38555527]
 [61.55078125]
 [61.71249008]].
[2019-03-24 04:39:10,035] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:39:10,035] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:10,067] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run10
[2019-03-24 04:39:10,426] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.2156407e-36 3.0748769e-29 3.0977372e-31 1.6238930e-20], sum to 1.0000
[2019-03-24 04:39:10,436] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3737
[2019-03-24 04:39:10,440] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.46666666666667, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5953752813900749, 6.911200000000001, 6.9112, 121.9260426156618, 441379.1841220652, 441379.1841220647, 129580.4906692986], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7774800.0000, 
sim time next is 7775400.0000, 
raw observation next is [21.43333333333333, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5943888556046847, 6.9112, 6.9112, 121.9260426156618, 440519.4059046807, 440519.4059046807, 129404.616183433], 
processed observation next is [1.0, 1.0, 0.3493827160493826, 0.74, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.49298606950585583, 0.0, 0.0, 0.8094621288201359, 0.15732835925167168, 0.15732835925167168, 0.24885503112198654], 
reward next is 0.7511, 
noisyNet noise sample is [array([-1.9813492], dtype=float32), -0.63758856]. 
=============================================
[2019-03-24 04:39:12,413] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.8432444e-28 1.3575894e-21 8.8028526e-22 1.7001290e-12], sum to 1.0000
[2019-03-24 04:39:12,421] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1791
[2019-03-24 04:39:12,426] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.25, 69.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6857913769676152, 6.9112, 6.9112, 121.9260426156618, 503782.1853691591, 503782.1853691591, 135833.9054751417], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7787400.0000, 
sim time next is 7788000.0000, 
raw observation next is [21.3, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6055895680782993, 6.911200000000001, 6.9112, 121.9260426156618, 444716.6045918403, 444716.6045918398, 128218.1014079119], 
processed observation next is [1.0, 0.13043478260869565, 0.3444444444444445, 0.69, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5069869600978741, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1588273587828001, 0.1588273587827999, 0.24657327193829212], 
reward next is 0.7534, 
noisyNet noise sample is [array([-0.4330352], dtype=float32), 1.8220327]. 
=============================================
[2019-03-24 04:39:12,444] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[63.782158]
 [64.01025 ]
 [64.02922 ]
 [64.09244 ]
 [64.12484 ]], R is [[63.87019348]
 [63.97027206]
 [64.08615112]
 [64.20005035]
 [64.31080627]].
[2019-03-24 04:39:15,999] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9999917e-01 4.4399887e-25 7.9742804e-21 1.0088167e-20 8.9380677e-07], sum to 1.0000
[2019-03-24 04:39:16,003] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2258
[2019-03-24 04:39:16,013] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.65, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7053665150697953, 6.9112, 6.9112, 121.9260426156618, 527106.5209327815, 527106.5209327815, 145610.5183126413], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7853400.0000, 
sim time next is 7854000.0000, 
raw observation next is [24.56666666666667, 66.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7030829869433866, 6.9112, 6.9112, 121.9260426156618, 525404.3844410321, 525404.3844410321, 145292.8072977656], 
processed observation next is [1.0, 0.9130434782608695, 0.46543209876543223, 0.6633333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6288537336792333, 0.0, 0.0, 0.8094621288201359, 0.1876444230146543, 0.1876444230146543, 0.2794092448033954], 
reward next is 0.7206, 
noisyNet noise sample is [array([0.36925656], dtype=float32), -1.3320906]. 
=============================================
[2019-03-24 04:39:16,032] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.57765 ]
 [70.44322 ]
 [70.38292 ]
 [70.375206]
 [70.367096]], R is [[70.71799469]
 [70.73079681]
 [70.74253082]
 [70.75302887]
 [70.76280212]].
[2019-03-24 04:39:20,343] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:39:20,343] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:20,591] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run10
[2019-03-24 04:39:20,643] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:39:20,644] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:20,700] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run10
[2019-03-24 04:39:20,774] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:39:20,775] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:20,805] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run10
[2019-03-24 04:39:20,862] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:39:20,864] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:20,905] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run10
[2019-03-24 04:39:21,149] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:39:21,150] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:21,180] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run10
[2019-03-24 04:39:21,447] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:39:21,448] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:21,453] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run10
[2019-03-24 04:39:21,482] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:39:21,485] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:21,499] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run10
[2019-03-24 04:39:21,727] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:39:21,727] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:21,730] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run10
[2019-03-24 04:39:21,891] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:39:21,891] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:21,894] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run10
[2019-03-24 04:39:22,032] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:39:22,032] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:22,038] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run10
[2019-03-24 04:39:22,341] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:39:22,341] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:22,353] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run10
[2019-03-24 04:39:22,393] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:39:22,393] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:22,407] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run10
[2019-03-24 04:39:22,430] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:39:22,431] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:22,442] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run10
[2019-03-24 04:39:22,637] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:39:22,637] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:22,640] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run10
[2019-03-24 04:39:22,706] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 04:39:22,710] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:22,725] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run10
[2019-03-24 04:39:39,700] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 6.1148504e-34 3.2739745e-30 1.6594180e-28 4.0637324e-18], sum to 1.0000
[2019-03-24 04:39:39,707] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1568
[2019-03-24 04:39:39,715] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.86666666666667, 38.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4946945497841116, 6.911200000000001, 6.9112, 121.9260426156618, 353215.8267176038, 353215.8267176034, 99652.722935551], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 285600.0000, 
sim time next is 286200.0000, 
raw observation next is [23.1, 37.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4995754547466827, 6.911200000000001, 6.9112, 121.9260426156618, 356701.6419694376, 356701.6419694371, 100338.4218269122], 
processed observation next is [0.0, 0.30434782608695654, 0.41111111111111115, 0.375, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.37446931843335335, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12739344356051344, 0.12739344356051327, 0.19295850351329272], 
reward next is 0.8070, 
noisyNet noise sample is [array([1.5137812], dtype=float32), 0.09960665]. 
=============================================
[2019-03-24 04:39:42,370] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 8.5538144e-23 7.3820893e-17 2.7299462e-19 1.3899167e-09], sum to 1.0000
[2019-03-24 04:39:42,376] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0291
[2019-03-24 04:39:42,381] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.26666666666667, 40.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.689749824719185, 6.9112, 6.9112, 121.9260426156618, 492531.5629955276, 492531.5629955276, 128766.3034668992], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 373200.0000, 
sim time next is 373800.0000, 
raw observation next is [24.68333333333333, 39.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6986931496810217, 6.911199999999999, 6.9112, 121.9260426156618, 498919.8253967688, 498919.8253967693, 130435.3054378836], 
processed observation next is [1.0, 0.30434782608695654, 0.46975308641975294, 0.3933333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.623366437101277, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17818565192741742, 0.1781856519274176, 0.25083712584208384], 
reward next is 0.7492, 
noisyNet noise sample is [array([-0.068726], dtype=float32), -0.12932864]. 
=============================================
[2019-03-24 04:39:44,582] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9596667e-05 2.5829433e-23 1.2081246e-14 1.9298678e-17 9.9997044e-01], sum to 1.0000
[2019-03-24 04:39:44,590] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0262
[2019-03-24 04:39:44,596] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.86666666666667, 26.16666666666667, 1.0, 2.0, 0.2662702571425438, 1.0, 2.0, 0.2662702571425438, 1.0, 2.0, 0.4458527896929834, 6.911199999999999, 6.9112, 121.94756008, 996991.6145086085, 996991.6145086089, 240807.7526118381], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 391800.0000, 
sim time next is 392400.0000, 
raw observation next is [30.0, 26.0, 1.0, 2.0, 0.2439608833016451, 1.0, 2.0, 0.2439608833016451, 1.0, 2.0, 0.4085541708857375, 6.9112, 6.9112, 121.94756008, 913499.480945295, 913499.480945295, 232835.9855007784], 
processed observation next is [1.0, 0.5652173913043478, 0.6666666666666666, 0.26, 1.0, 1.0, 0.09995343250195844, 1.0, 1.0, 0.09995343250195844, 1.0, 1.0, 0.26069271360717183, 0.0, 0.0, 0.8096049824067558, 0.32624981462331964, 0.32624981462331964, 0.44776151057842], 
reward next is 0.5522, 
noisyNet noise sample is [array([-0.3202233], dtype=float32), 2.0824804]. 
=============================================
[2019-03-24 04:39:45,320] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7700493e-03 5.8795185e-23 8.9233915e-17 2.6497190e-18 9.9822992e-01], sum to 1.0000
[2019-03-24 04:39:45,325] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8606
[2019-03-24 04:39:45,329] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.8, 26.66666666666667, 1.0, 2.0, 0.3506907281998553, 1.0, 2.0, 0.3506907281998553, 1.0, 2.0, 0.5757966240992306, 6.9112, 6.9112, 121.94756008, 1291457.745270773, 1291457.745270773, 274662.9029204226], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 405600.0000, 
sim time next is 406200.0000, 
raw observation next is [30.8, 26.83333333333333, 1.0, 2.0, 0.3479478078924862, 1.0, 2.0, 0.3479478078924862, 1.0, 2.0, 0.5712442079693472, 6.911199999999999, 6.9112, 121.94756008, 1281233.557581665, 1281233.557581666, 273541.2192801291], 
processed observation next is [1.0, 0.6956521739130435, 0.6962962962962963, 0.2683333333333333, 1.0, 1.0, 0.22374739034819785, 1.0, 1.0, 0.22374739034819785, 1.0, 1.0, 0.4640552599616839, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4575834134220232, 0.4575834134220235, 0.5260408063079406], 
reward next is 0.4740, 
noisyNet noise sample is [array([-0.5846126], dtype=float32), -0.025605077]. 
=============================================
[2019-03-24 04:39:53,657] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 7.8891522e-34 3.9450893e-36 7.2369858e-25], sum to 1.0000
[2019-03-24 04:39:53,663] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6795
[2019-03-24 04:39:53,669] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.1, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6523691251717417, 6.9112, 6.9112, 121.9260426156618, 486182.2216009459, 486182.2216009459, 137073.7608314156], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 865800.0000, 
sim time next is 866400.0000, 
raw observation next is [23.93333333333334, 62.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.649245973704891, 6.911200000000001, 6.9112, 121.9260426156618, 483727.6433094683, 483727.6433094678, 136628.0734603229], 
processed observation next is [0.0, 0.0, 0.4419753086419756, 0.6266666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5615574671311138, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1727598726105244, 0.17275987261052422, 0.26274629511600556], 
reward next is 0.7373, 
noisyNet noise sample is [array([-0.48466814], dtype=float32), 0.40339354]. 
=============================================
[2019-03-24 04:39:53,832] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 7.9280497e-24 1.8925785e-21 6.7693161e-21 8.8467657e-11], sum to 1.0000
[2019-03-24 04:39:53,839] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6278
[2019-03-24 04:39:53,845] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1611751.349955381 W.
[2019-03-24 04:39:53,853] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.7, 32.0, 1.0, 2.0, 0.7406516415399287, 0.0, 2.0, 0.0, 1.0, 2.0, 0.958030643319287, 6.9112, 6.9112, 121.9260426156618, 1611751.349955381, 1611751.349955381, 314623.1724996508], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 576000.0000, 
sim time next is 576600.0000, 
raw observation next is [31.8, 31.66666666666667, 1.0, 2.0, 0.4160737447878787, 1.0, 1.0, 0.4160737447878787, 1.0, 2.0, 0.6694348325869024, 6.9112, 6.9112, 121.94756008, 1488169.235728251, 1488169.235728251, 303951.2895852543], 
processed observation next is [1.0, 0.6956521739130435, 0.7333333333333334, 0.3166666666666667, 1.0, 1.0, 0.30484969617604607, 1.0, 0.5, 0.30484969617604607, 1.0, 1.0, 0.586793540733628, 0.0, 0.0, 0.8096049824067558, 0.5314890127600896, 0.5314890127600896, 0.5845217107408736], 
reward next is 0.4155, 
noisyNet noise sample is [array([1.2585887], dtype=float32), 0.17476736]. 
=============================================
[2019-03-24 04:39:55,633] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 04:39:55,634] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:39:55,635] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:55,637] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:39:55,638] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:39:55,638] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:55,639] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:55,639] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:39:55,641] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:39:55,645] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:55,646] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:39:55,665] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run78
[2019-03-24 04:39:55,686] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run78
[2019-03-24 04:39:55,708] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run78
[2019-03-24 04:39:55,725] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run78
[2019-03-24 04:39:55,748] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run78
[2019-03-24 04:40:11,684] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.43192118]
[2019-03-24 04:40:11,685] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.78398398166667, 83.39434832500001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.557705739547824, 6.9112, 6.9112, 121.9260426156618, 410852.8469187191, 410852.8469187191, 124617.6079207787]
[2019-03-24 04:40:11,685] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:40:11,687] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 6.0507739e-30 1.0173252e-24 2.1702522e-26 1.5254055e-15], sampled 0.03037888601626393
[2019-03-24 04:40:50,858] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.43192118]
[2019-03-24 04:40:50,859] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.42041931666667, 81.87197549999999, 1.0, 2.0, 0.784911878769983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 958579.8657069851, 958579.8657069851, 195614.5996630877]
[2019-03-24 04:40:50,860] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:40:50,863] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.7150153e-24 9.8945290e-20 2.7761300e-21 2.5530381e-12], sampled 0.6074726963072012
[2019-03-24 04:40:50,864] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 958579.8657069851 W.
[2019-03-24 04:40:55,471] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.43192118]
[2019-03-24 04:40:55,473] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.53389032833334, 104.6706249333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8317600963262143, 6.911200000000001, 6.9112, 121.9260426156618, 617445.2262394093, 617445.226239409, 164460.7594738417]
[2019-03-24 04:40:55,475] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:40:55,477] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 9.0727505e-32 3.1762184e-26 5.3426471e-28 1.7923747e-16], sampled 0.27869267729753866
[2019-03-24 04:40:56,666] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.43192118]
[2019-03-24 04:40:56,666] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.79942262833334, 94.118428005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8226607846781028, 6.911200000000001, 6.9112, 121.9260426156618, 609361.8376284543, 609361.8376284539, 163910.0236355316]
[2019-03-24 04:40:56,667] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:40:56,673] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 7.8758357e-33 4.1616376e-27 6.1723539e-29 5.0860332e-17], sampled 0.81684514196493
[2019-03-24 04:41:40,178] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7837.9001 2529934949.6445 832.0000
[2019-03-24 04:41:41,337] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8631.9795 2219451911.3789 543.0000
[2019-03-24 04:41:41,527] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8360.1481 2339637001.9417 616.0000
[2019-03-24 04:41:41,573] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8399.3025 2293204610.5189 697.0000
[2019-03-24 04:41:41,578] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8557.1233 2258525221.6946 537.0000
[2019-03-24 04:41:42,595] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1925000, evaluation results [1925000.0, 7837.9001493390315, 2529934949.644482, 832.0, 8557.123276945344, 2258525221.6946073, 537.0, 8631.979450138722, 2219451911.378945, 543.0, 8360.148107206489, 2339637001.9416575, 616.0, 8399.302512175718, 2293204610.5189486, 697.0]
[2019-03-24 04:41:43,852] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.2219341e-30 3.3154230e-23 1.8152393e-24 6.9663640e-15], sum to 1.0000
[2019-03-24 04:41:43,861] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5921
[2019-03-24 04:41:43,867] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1647683.433901496 W.
[2019-03-24 04:41:43,873] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.7, 19.33333333333334, 1.0, 2.0, 0.6815653927975265, 1.0, 2.0, 0.6815653927975265, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1647683.433901496, 1647683.433901496, 301328.6342539347], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 657600.0000, 
sim time next is 658200.0000, 
raw observation next is [35.7, 19.16666666666667, 1.0, 2.0, 0.4615781863994519, 1.0, 2.0, 0.4615781863994519, 1.0, 1.0, 0.7444090682347844, 6.911199999999999, 6.9112, 121.94756008, 1658916.853316512, 1658916.853316513, 324771.9773797601], 
processed observation next is [1.0, 0.6086956521739131, 0.8777777777777779, 0.1916666666666667, 1.0, 1.0, 0.35902165047553797, 1.0, 1.0, 0.35902165047553797, 1.0, 0.5, 0.6805113352934805, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5924703047558971, 0.5924703047558975, 0.6245614949610772], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.28716376], dtype=float32), -0.03323156]. 
=============================================
[2019-03-24 04:41:47,111] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 3.2641901e-27 9.6778888e-23 1.5346912e-23 2.2654627e-16], sum to 1.0000
[2019-03-24 04:41:47,119] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6686
[2019-03-24 04:41:47,123] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.2, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.702523862917957, 6.911200000000001, 6.9112, 121.9260426156618, 518134.2455291689, 518134.2455291685, 138503.9901296905], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 718200.0000, 
sim time next is 718800.0000, 
raw observation next is [24.3, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7738221173938842, 6.9112, 6.9112, 121.9260426156618, 571315.2102033062, 571315.2102033062, 146187.9222249903], 
processed observation next is [1.0, 0.30434782608695654, 0.4555555555555556, 0.54, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7172776467423553, 0.0, 0.0, 0.8094621288201359, 0.20404114650118077, 0.20404114650118077, 0.2811306196634429], 
reward next is 0.7189, 
noisyNet noise sample is [array([0.8437276], dtype=float32), -0.664141]. 
=============================================
[2019-03-24 04:41:48,149] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 4.3705758e-24 2.6980383e-19 4.5159469e-21 2.9054535e-11], sum to 1.0000
[2019-03-24 04:41:48,156] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5501
[2019-03-24 04:41:48,160] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.7, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7478377232701625, 6.911199999999999, 6.9112, 121.9260426156618, 548479.1884169162, 548479.1884169166, 141626.2740972278], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 715200.0000, 
sim time next is 715800.0000, 
raw observation next is [23.8, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.786042862997888, 6.9112, 6.9112, 121.9260426156618, 577216.9097882496, 577216.9097882496, 145917.1917354672], 
processed observation next is [1.0, 0.2608695652173913, 0.43703703703703706, 0.54, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7325535787473599, 0.0, 0.0, 0.8094621288201359, 0.2061488963529463, 0.2061488963529463, 0.2806099841066677], 
reward next is 0.7194, 
noisyNet noise sample is [array([0.41012734], dtype=float32), -0.3334392]. 
=============================================
[2019-03-24 04:41:49,087] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.8132183e-24 6.6382879e-20 4.7290133e-19 3.9198733e-13], sum to 1.0000
[2019-03-24 04:41:49,088] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6861
[2019-03-24 04:41:49,104] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1006641.758692901 W.
[2019-03-24 04:41:49,116] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.7, 53.0, 1.0, 2.0, 0.4104667896314053, 1.0, 2.0, 0.4104667896314053, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1006641.758692901, 1006641.758692901, 211856.9996754847], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 725400.0000, 
sim time next is 726000.0000, 
raw observation next is [25.83333333333334, 53.0, 1.0, 2.0, 0.4612854935605996, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7576090377982961, 6.911199999999999, 6.9112, 121.9260426156618, 1132727.432039741, 1132727.432039741, 240644.8087868385], 
processed observation next is [1.0, 0.391304347826087, 0.5123456790123458, 0.53, 1.0, 1.0, 0.3586732066197615, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.69701129724787, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4045455114427646, 0.4045455114427646, 0.4627784784362279], 
reward next is 0.5372, 
noisyNet noise sample is [array([-0.9714979], dtype=float32), 1.5618163]. 
=============================================
[2019-03-24 04:41:49,127] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[51.71933 ]
 [51.69668 ]
 [51.693886]
 [51.180653]
 [51.302708]], R is [[51.09069824]
 [51.17237473]
 [51.25384903]
 [50.74131012]
 [50.23389816]].
[2019-03-24 04:41:54,422] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.7360242e-30 3.0057983e-24 2.9956633e-27 1.6351787e-16], sum to 1.0000
[2019-03-24 04:41:54,433] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9058
[2019-03-24 04:41:54,442] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.66666666666666, 36.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7227878686783286, 6.9112, 6.9112, 121.9260426156618, 539633.3522797817, 539633.3522797817, 148873.6670680545], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 823200.0000, 
sim time next is 823800.0000, 
raw observation next is [31.83333333333333, 36.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7254514991664679, 6.9112, 6.9112, 121.9260426156618, 541527.6370404384, 541527.6370404384, 149310.1823265831], 
processed observation next is [0.0, 0.5217391304347826, 0.7345679012345677, 0.3633333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6568143739580847, 0.0, 0.0, 0.8094621288201359, 0.19340272751444226, 0.19340272751444226, 0.2871349660126598], 
reward next is 0.7129, 
noisyNet noise sample is [array([0.39751258], dtype=float32), 2.4068825]. 
=============================================
[2019-03-24 04:42:03,797] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 7.0355854e-23 2.9606958e-19 6.1716793e-19 3.9522603e-13], sum to 1.0000
[2019-03-24 04:42:03,809] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1745
[2019-03-24 04:42:03,815] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1195204.535125773 W.
[2019-03-24 04:42:03,819] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.4, 52.5, 1.0, 2.0, 0.4865630184303404, 1.0, 2.0, 0.4865630184303404, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1195204.535125773, 1195204.535125774, 234609.2486103895], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 999000.0000, 
sim time next is 999600.0000, 
raw observation next is [25.43333333333334, 52.33333333333333, 1.0, 2.0, 0.3312936843255085, 1.0, 2.0, 0.3312936843255085, 1.0, 1.0, 0.5404414141249112, 6.911200000000001, 6.9112, 121.94756008, 1211037.679088145, 1211037.679088145, 267167.7907406813], 
processed observation next is [1.0, 0.5652173913043478, 0.4975308641975311, 0.5233333333333333, 1.0, 1.0, 0.20392105276846248, 1.0, 1.0, 0.20392105276846248, 1.0, 0.5, 0.42555176765613895, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.43251345681719466, 0.43251345681719466, 0.5137842129628486], 
reward next is 0.4862, 
noisyNet noise sample is [array([0.91705424], dtype=float32), -1.4553827]. 
=============================================
[2019-03-24 04:42:06,329] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.5178321e-28 1.2570356e-22 1.0811126e-24 8.6649394e-18], sum to 1.0000
[2019-03-24 04:42:06,337] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4922
[2019-03-24 04:42:06,342] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.96666666666667, 67.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5289246891221746, 6.911200000000001, 6.9112, 121.9260426156618, 385395.3665520636, 385395.3665520631, 120164.4483840187], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1047000.0000, 
sim time next is 1047600.0000, 
raw observation next is [20.9, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5271871956403923, 6.911200000000001, 6.9112, 121.9260426156618, 384168.1618656706, 384168.1618656701, 120037.7346020891], 
processed observation next is [1.0, 0.13043478260869565, 0.32962962962962955, 0.68, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.40898399455049034, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13720291495202522, 0.13720291495202505, 0.2308417973117098], 
reward next is 0.7692, 
noisyNet noise sample is [array([-2.1995308], dtype=float32), -0.6374602]. 
=============================================
[2019-03-24 04:42:07,933] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 6.3810979e-30 1.0942988e-24 4.3730204e-27 3.5107853e-16], sum to 1.0000
[2019-03-24 04:42:07,933] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3432
[2019-03-24 04:42:07,935] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.3, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5679558866775122, 6.911199999999999, 6.9112, 121.9260426156618, 420400.9854655078, 420400.9854655082, 126641.061965465], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1100400.0000, 
sim time next is 1101000.0000, 
raw observation next is [25.05, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5707880297663559, 6.911200000000001, 6.9112, 121.9260426156618, 422306.2484225111, 422306.2484225107, 126781.0891090084], 
processed observation next is [1.0, 0.7391304347826086, 0.48333333333333334, 0.51, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4634850372079448, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15082366015089682, 0.15082366015089668, 0.2438097867480931], 
reward next is 0.7562, 
noisyNet noise sample is [array([0.42691708], dtype=float32), 0.44005266]. 
=============================================
[2019-03-24 04:42:07,971] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[71.4918  ]
 [71.71192 ]
 [71.78418 ]
 [71.23907 ]
 [70.378624]], R is [[71.69002533]
 [71.72959137]
 [71.76912689]
 [71.05143738]
 [70.34092712]].
[2019-03-24 04:42:17,238] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.9863239e-25 5.8929557e-23 3.7458725e-25 2.9093350e-15], sum to 1.0000
[2019-03-24 04:42:17,251] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3382
[2019-03-24 04:42:17,255] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.9, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.598809478599064, 6.9112, 6.9112, 121.9260426156618, 440508.1418916085, 440508.1418916085, 127978.1868199074], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1236600.0000, 
sim time next is 1237200.0000, 
raw observation next is [18.96666666666667, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5792994101407096, 6.911200000000001, 6.9112, 121.9260426156618, 426407.3404886673, 426407.3404886668, 126350.9942201839], 
processed observation next is [1.0, 0.30434782608695654, 0.25802469135802475, 0.8833333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.474124262675887, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15228833588880974, 0.15228833588880958, 0.24298268119266134], 
reward next is 0.7570, 
noisyNet noise sample is [array([-0.5004244], dtype=float32), -1.8316263]. 
=============================================
[2019-03-24 04:42:19,750] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.00000000e+00 2.88910827e-29 1.91587751e-25 1.22584921e-27
 1.38617546e-17], sum to 1.0000
[2019-03-24 04:42:19,760] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2716
[2019-03-24 04:42:19,764] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.63333333333333, 90.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6890879952259944, 6.9112, 6.9112, 121.9260426156618, 506793.0241513086, 506793.0241513086, 136438.5869710358], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1311000.0000, 
sim time next is 1311600.0000, 
raw observation next is [18.56666666666667, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5678364081516415, 6.911200000000001, 6.9112, 121.9260426156618, 417441.7446590083, 417441.7446590078, 125070.9497615506], 
processed observation next is [1.0, 0.17391304347826086, 0.24320987654321, 0.9066666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45979551018955184, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14908633737821725, 0.14908633737821708, 0.24052105723375114], 
reward next is 0.7595, 
noisyNet noise sample is [array([2.0333939], dtype=float32), -0.68104774]. 
=============================================
[2019-03-24 04:42:22,436] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 8.0243919e-36 2.7110303e-32 2.9350985e-36 3.2277184e-23], sum to 1.0000
[2019-03-24 04:42:22,440] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3588
[2019-03-24 04:42:22,443] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.5, 38.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5813473231408546, 6.9112, 6.9112, 121.9260426156618, 431580.8006293143, 431580.8006293143, 128693.7799675597], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1363200.0000, 
sim time next is 1363800.0000, 
raw observation next is [28.25, 39.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.586681033476274, 6.9112, 6.9112, 121.9260426156618, 435570.1032520838, 435570.1032520838, 129210.6264556091], 
processed observation next is [1.0, 0.782608695652174, 0.6018518518518519, 0.39, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4833512918453424, 0.0, 0.0, 0.8094621288201359, 0.1555607511614585, 0.1555607511614585, 0.24848197395309443], 
reward next is 0.7515, 
noisyNet noise sample is [array([1.2860533], dtype=float32), 0.6311029]. 
=============================================
[2019-03-24 04:42:24,145] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 8.9686617e-31 1.2695668e-27 2.1397474e-32 4.1621945e-19], sum to 1.0000
[2019-03-24 04:42:24,151] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7532
[2019-03-24 04:42:24,154] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.6, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4966799064028625, 6.9112, 6.9112, 121.9260426156618, 358146.8650023618, 358146.8650023618, 116089.7674319636], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1404000.0000, 
sim time next is 1404600.0000, 
raw observation next is [22.96666666666667, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5032843822352485, 6.9112, 6.9112, 121.9260426156618, 364014.9683480734, 364014.9683480734, 117012.0077609248], 
processed observation next is [0.0, 0.2608695652173913, 0.4061728395061729, 0.53, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3791054777940606, 0.0, 0.0, 0.8094621288201359, 0.13000534583859766, 0.13000534583859766, 0.2250230918479323], 
reward next is 0.7750, 
noisyNet noise sample is [array([-0.98215777], dtype=float32), -1.6803664]. 
=============================================
[2019-03-24 04:42:25,001] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.6901630e-32 5.0010803e-29 4.1891750e-28 3.0554226e-20], sum to 1.0000
[2019-03-24 04:42:25,010] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3695
[2019-03-24 04:42:25,014] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.6, 40.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5809293436553373, 6.9112, 6.9112, 121.9260426156618, 430344.150892112, 430344.150892112, 128031.5236528351], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1412400.0000, 
sim time next is 1413000.0000, 
raw observation next is [27.95, 39.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5849657030479003, 6.9112, 6.9112, 121.9260426156618, 433410.1780763821, 433410.1780763821, 128450.7585055402], 
processed observation next is [0.0, 0.34782608695652173, 0.5907407407407407, 0.39, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4812071288098753, 0.0, 0.0, 0.8094621288201359, 0.1547893493129936, 0.1547893493129936, 0.24702068943373115], 
reward next is 0.7530, 
noisyNet noise sample is [array([0.66563225], dtype=float32), 0.107929975]. 
=============================================
[2019-03-24 04:42:25,025] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.34081]
 [73.27489]
 [73.21273]
 [73.12022]
 [73.05254]], R is [[73.42079926]
 [73.44037628]
 [73.46022034]
 [73.48072815]
 [73.50297546]].
[2019-03-24 04:42:25,638] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 8.9149932e-34 4.5452018e-38 4.3347134e-23], sum to 1.0000
[2019-03-24 04:42:25,658] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4930
[2019-03-24 04:42:25,663] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.9, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5641755147965414, 6.911200000000001, 6.9112, 121.9260426156618, 413537.1688575904, 413537.1688575899, 124175.9705020086], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1476000.0000, 
sim time next is 1476600.0000, 
raw observation next is [22.81666666666667, 58.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5646150274596675, 6.911200000000001, 6.9112, 121.9260426156618, 413906.8023486192, 413906.8023486187, 124235.8459424651], 
processed observation next is [0.0, 0.08695652173913043, 0.4006172839506174, 0.5883333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45576878432458434, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1478238579816497, 0.14782385798164954, 0.23891508835089442], 
reward next is 0.7611, 
noisyNet noise sample is [array([0.13973206], dtype=float32), 0.27748388]. 
=============================================
[2019-03-24 04:42:27,430] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.3173536e-33 1.2879021e-28 6.4707024e-34 3.0043386e-19], sum to 1.0000
[2019-03-24 04:42:27,437] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5178
[2019-03-24 04:42:27,440] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.71666666666667, 40.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5914070135452636, 6.9112, 6.9112, 121.9260426156618, 438267.0620140826, 438267.0620140826, 129100.1109128356], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1465800.0000, 
sim time next is 1466400.0000, 
raw observation next is [27.43333333333333, 41.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5929504498373285, 6.911200000000001, 6.9112, 121.9260426156618, 439292.0249526611, 439292.0249526607, 129167.2400505], 
processed observation next is [0.0, 1.0, 0.5716049382716049, 0.41, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.49118806229666057, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15689000891166466, 0.15689000891166455, 0.24839853855865385], 
reward next is 0.7516, 
noisyNet noise sample is [array([0.81163096], dtype=float32), -1.4744074]. 
=============================================
[2019-03-24 04:42:29,629] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 6.5741974e-29 5.9453145e-24 1.9190666e-25 2.4015110e-16], sum to 1.0000
[2019-03-24 04:42:29,638] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8701
[2019-03-24 04:42:29,641] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 73.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.739401943273713, 6.911199999999999, 6.9112, 121.9260426156618, 552490.8291008882, 552490.8291008887, 149787.0555111804], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1545600.0000, 
sim time next is 1546200.0000, 
raw observation next is [23.6, 72.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7330205625486588, 6.9112, 6.9112, 121.9260426156618, 547774.7669585983, 547774.7669585983, 148744.6493784097], 
processed observation next is [0.0, 0.9130434782608695, 0.4296296296296297, 0.725, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6662757031858235, 0.0, 0.0, 0.8094621288201359, 0.19563384534235653, 0.19563384534235653, 0.2860474026507879], 
reward next is 0.7140, 
noisyNet noise sample is [array([0.01829828], dtype=float32), 0.53933]. 
=============================================
[2019-03-24 04:42:32,560] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 5.1294859e-31 1.0963158e-26 5.7104357e-28 7.5995196e-20], sum to 1.0000
[2019-03-24 04:42:32,568] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9336
[2019-03-24 04:42:32,572] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 71.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7265355993404267, 6.9112, 6.9112, 121.9260426156618, 542940.5208134411, 542940.5208134411, 147693.9476032571], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1546800.0000, 
sim time next is 1547400.0000, 
raw observation next is [23.6, 70.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7185560398714496, 6.911200000000001, 6.9112, 121.9260426156618, 536948.8313363072, 536948.8313363068, 146481.2321822412], 
processed observation next is [0.0, 0.9130434782608695, 0.4296296296296297, 0.7083333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6481950498393119, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19176743976296687, 0.1917674397629667, 0.28169467727354075], 
reward next is 0.7183, 
noisyNet noise sample is [array([0.65099347], dtype=float32), 1.3725111]. 
=============================================
[2019-03-24 04:42:32,669] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 04:42:32,674] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:42:32,675] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:42:32,675] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:42:32,675] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:42:32,675] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:42:32,676] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:42:32,677] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:42:32,677] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:42:32,679] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:42:32,679] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:42:32,697] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run79
[2019-03-24 04:42:32,722] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run79
[2019-03-24 04:42:32,723] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run79
[2019-03-24 04:42:32,782] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run79
[2019-03-24 04:42:32,815] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run79
[2019-03-24 04:43:25,375] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.43634525]
[2019-03-24 04:43:25,376] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.99389111, 94.37781890333335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8699102363572788, 6.911200000000001, 6.9112, 121.9260426156618, 639179.711537169, 639179.7115371685, 171423.7122882897]
[2019-03-24 04:43:25,377] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:43:25,381] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.6545574e-27 6.6545296e-23 1.6270770e-24 4.0631321e-16], sampled 0.46026473121351297
[2019-03-24 04:43:30,475] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.43634525]
[2019-03-24 04:43:30,476] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.85601244, 91.23076145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7784349755863732, 6.911200000000001, 6.9112, 121.9260426156618, 580164.1858841765, 580164.185884176, 156445.1925287749]
[2019-03-24 04:43:30,476] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:43:30,479] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.2530017e-30 1.7875253e-25 2.8302386e-27 6.7195430e-18], sampled 0.19294764209078796
[2019-03-24 04:44:10,346] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.43634525]
[2019-03-24 04:44:10,350] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.83333333333334, 21.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6355051313565941, 6.9112, 6.9112, 121.9260426156618, 454148.4668816974, 454148.4668816974, 125931.8755725811]
[2019-03-24 04:44:10,352] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:44:10,355] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.5217296e-26 2.8516385e-22 7.7871442e-24 1.1091308e-15], sampled 0.014719667320563623
[2019-03-24 04:44:17,807] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8361.8044 2339582728.4665 616.0000
[2019-03-24 04:44:17,871] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8557.8780 2258385508.9378 536.0000
[2019-03-24 04:44:17,959] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8632.2850 2219299766.1518 543.0000
[2019-03-24 04:44:18,117] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8402.7825 2293090583.1810 697.0000
[2019-03-24 04:44:18,367] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7839.3642 2529907632.7168 831.0000
[2019-03-24 04:44:19,384] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1950000, evaluation results [1950000.0, 7839.3642237539425, 2529907632.7168317, 831.0, 8557.877954442405, 2258385508.937812, 536.0, 8632.284958361142, 2219299766.1518497, 543.0, 8361.804412745285, 2339582728.466484, 616.0, 8402.782546002263, 2293090583.180975, 697.0]
[2019-03-24 04:44:19,973] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.5551156e-25 5.7047731e-21 5.7562067e-22 5.7910619e-14], sum to 1.0000
[2019-03-24 04:44:19,983] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9366
[2019-03-24 04:44:19,989] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1202988.276715502 W.
[2019-03-24 04:44:19,994] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.75, 42.16666666666666, 1.0, 2.0, 0.3302224769165865, 1.0, 2.0, 0.3302224769165865, 1.0, 2.0, 0.5372617047678933, 6.911200000000001, 6.9112, 121.94756008, 1202988.276715502, 1202988.276715502, 266894.7989749723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1612200.0000, 
sim time next is 1612800.0000, 
raw observation next is [27.8, 42.0, 1.0, 2.0, 0.9385228532847111, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.272859369916453, 6.9112, 121.9245191909952, 1349047.034639691, 1163847.426530167, 230279.9189256807], 
processed observation next is [1.0, 0.6956521739130435, 0.5851851851851853, 0.42, 1.0, 1.0, 0.926812920577037, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.036165936991645345, 0.0, 0.8094520148645997, 0.4818025123713182, 0.41565979518934537, 0.4428459979340013], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.48716518], dtype=float32), 1.0797713]. 
=============================================
[2019-03-24 04:44:20,000] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 6.8484558e-29 2.2019179e-24 1.5190509e-25 1.7287466e-17], sum to 1.0000
[2019-03-24 04:44:20,007] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3463
[2019-03-24 04:44:20,011] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.6, 42.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.582728356581232, 6.911199999999999, 6.9112, 121.9260426156618, 433400.3866461947, 433400.3866461951, 129431.5140192652], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1618200.0000, 
sim time next is 1618800.0000, 
raw observation next is [27.46666666666667, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5877263894930829, 6.911200000000001, 6.9112, 121.9260426156618, 436970.875942123, 436970.8759421225, 129781.5400615053], 
processed observation next is [1.0, 0.7391304347826086, 0.5728395061728396, 0.43, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.48465798686635353, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15606102712218678, 0.1560610271221866, 0.24957988473366402], 
reward next is 0.7504, 
noisyNet noise sample is [array([0.27669367], dtype=float32), 2.8288493]. 
=============================================
[2019-03-24 04:44:24,111] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.9991350e-37 4.2655698e-32 8.5302071e-34 3.1288267e-25], sum to 1.0000
[2019-03-24 04:44:24,127] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7181
[2019-03-24 04:44:24,134] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.7, 55.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5656153175686007, 6.911200000000001, 6.9112, 121.9260426156618, 415974.3328118966, 415974.3328118961, 124957.2889183639], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1635600.0000, 
sim time next is 1636200.0000, 
raw observation next is [23.55, 55.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5633540359758563, 6.9112, 6.9112, 121.9260426156618, 414029.5664575613, 414029.5664575613, 124620.7393842617], 
processed observation next is [1.0, 0.9565217391304348, 0.4277777777777778, 0.555, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45419254496982037, 0.0, 0.0, 0.8094621288201359, 0.1478677023062719, 0.1478677023062719, 0.23965526804665713], 
reward next is 0.7603, 
noisyNet noise sample is [array([-0.15656543], dtype=float32), -0.73006845]. 
=============================================
[2019-03-24 04:44:30,422] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.3177064e-25 2.9644011e-20 4.0775196e-19 5.5726315e-14], sum to 1.0000
[2019-03-24 04:44:30,427] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0925
[2019-03-24 04:44:30,434] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.36666666666667, 75.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.715030566266681, 6.9112, 6.9112, 121.9260426156618, 533678.1439400094, 533678.1439400094, 144556.0716648531], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1755600.0000, 
sim time next is 1756200.0000, 
raw observation next is [22.53333333333333, 74.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7102871996375941, 6.911200000000001, 6.9112, 121.9260426156618, 530218.540043774, 530218.5400437736, 144169.9213274533], 
processed observation next is [1.0, 0.30434782608695654, 0.3901234567901234, 0.7483333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6378589995469927, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18936376430134783, 0.18936376430134771, 0.277249848706641], 
reward next is 0.7228, 
noisyNet noise sample is [array([0.00016958], dtype=float32), 1.0213239]. 
=============================================
[2019-03-24 04:44:30,948] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.1606966e-24 8.9989735e-20 1.3556111e-23 6.9274352e-15], sum to 1.0000
[2019-03-24 04:44:30,953] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3817
[2019-03-24 04:44:30,961] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1191323.014922994 W.
[2019-03-24 04:44:30,965] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.73333333333333, 63.33333333333333, 1.0, 2.0, 0.4966327144900265, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8015795254969227, 6.9112, 6.9112, 121.9258715283575, 1191323.014922994, 1191323.014922994, 254141.0581683873], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1777800.0000, 
sim time next is 1778400.0000, 
raw observation next is [25.8, 63.0, 1.0, 2.0, 0.3447130308443745, 1.0, 1.0, 0.3447130308443745, 1.0, 2.0, 0.5525119491441508, 6.911200000000001, 6.9112, 121.94756008, 1221444.029833704, 1221444.029833703, 273574.9844097288], 
processed observation next is [1.0, 0.6086956521739131, 0.5111111111111112, 0.63, 1.0, 1.0, 0.21989646529092202, 1.0, 0.5, 0.21989646529092202, 1.0, 1.0, 0.44063993643018845, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4362300106548943, 0.436230010654894, 0.5261057392494785], 
reward next is 0.4739, 
noisyNet noise sample is [array([1.3026545], dtype=float32), -1.1499714]. 
=============================================
[2019-03-24 04:44:33,218] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.00000000e+00 1.59118948e-29 8.25274094e-24 1.13271108e-24
 1.03618125e-14], sum to 1.0000
[2019-03-24 04:44:33,227] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9530
[2019-03-24 04:44:33,238] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.6, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5460515538828338, 6.9112, 6.9112, 121.9260426156618, 398973.906831221, 398973.906831221, 122048.6046187738], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1807200.0000, 
sim time next is 1807800.0000, 
raw observation next is [18.61666666666667, 87.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5459373165034449, 6.9112, 6.9112, 121.9260426156618, 399148.0137608356, 399148.0137608356, 122150.8679106706], 
processed observation next is [1.0, 0.9565217391304348, 0.24506172839506188, 0.8716666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4324216456293061, 0.0, 0.0, 0.8094621288201359, 0.14255286205744128, 0.14255286205744128, 0.23490551521282807], 
reward next is 0.7651, 
noisyNet noise sample is [array([0.49741632], dtype=float32), -1.174753]. 
=============================================
[2019-03-24 04:44:34,287] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 6.9234762e-29 1.9537775e-24 2.3035836e-28 3.4817451e-19], sum to 1.0000
[2019-03-24 04:44:34,297] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1833
[2019-03-24 04:44:34,301] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.48333333333333, 90.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5493300035141738, 6.911200000000001, 6.9112, 121.9260426156618, 402980.9734693606, 402980.9734693601, 123048.5201237344], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1815000.0000, 
sim time next is 1815600.0000, 
raw observation next is [18.46666666666667, 90.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5489317030182228, 6.911200000000001, 6.9112, 121.9260426156618, 402703.8325698979, 402703.8325698974, 123021.414559417], 
processed observation next is [1.0, 0.0, 0.23950617283950623, 0.9033333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43616462877277845, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14382279734639208, 0.14382279734639195, 0.23657964338349421], 
reward next is 0.7634, 
noisyNet noise sample is [array([0.05723439], dtype=float32), 1.5160722]. 
=============================================
[2019-03-24 04:44:34,687] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.8049446e-27 6.1839210e-23 8.9560691e-26 5.0380477e-17], sum to 1.0000
[2019-03-24 04:44:34,694] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1021
[2019-03-24 04:44:34,698] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.95, 78.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5867441510436335, 6.911199999999999, 6.9112, 121.9260426156618, 435269.6580619757, 435269.6580619761, 128972.9194402869], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1841400.0000, 
sim time next is 1842000.0000, 
raw observation next is [21.1, 77.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5884101358406999, 6.911200000000001, 6.9112, 121.9260426156618, 436640.6138340661, 436640.6138340656, 129220.9186455361], 
processed observation next is [1.0, 0.30434782608695654, 0.3370370370370371, 0.7766666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4855126698008748, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15594307636930932, 0.15594307636930915, 0.24850176662603096], 
reward next is 0.7515, 
noisyNet noise sample is [array([-0.52210605], dtype=float32), 1.3098108]. 
=============================================
[2019-03-24 04:44:34,710] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[67.005936]
 [66.99651 ]
 [66.973816]
 [67.130264]
 [67.27681 ]], R is [[67.04000092]
 [67.1215744 ]
 [67.20045471]
 [67.26906586]
 [67.34178162]].
[2019-03-24 04:44:37,097] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 9.5468704e-24 9.1230202e-21 8.2192844e-23 3.1214544e-13], sum to 1.0000
[2019-03-24 04:44:37,103] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3435
[2019-03-24 04:44:37,112] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.1, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.627936341212489, 6.9112, 6.9112, 121.9260426156618, 468295.8093931106, 468295.8093931106, 134993.1781394396], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1924200.0000, 
sim time next is 1924800.0000, 
raw observation next is [20.13333333333333, 91.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6638387478769683, 6.911200000000001, 6.9112, 121.9260426156618, 495110.7442863549, 495110.7442863545, 138667.1660523165], 
processed observation next is [1.0, 0.2608695652173913, 0.30123456790123443, 0.9133333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5797984348462103, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17682526581655533, 0.1768252658165552, 0.26666762702368557], 
reward next is 0.7333, 
noisyNet noise sample is [array([-0.26543847], dtype=float32), -0.29430315]. 
=============================================
[2019-03-24 04:44:38,421] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 9.9558902e-30 5.2991226e-23 2.4551042e-25 3.9991626e-16], sum to 1.0000
[2019-03-24 04:44:38,430] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0677
[2019-03-24 04:44:38,438] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.56666666666666, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6737876446718452, 6.911199999999999, 6.9112, 121.9260426156618, 503384.7211880754, 503384.7211880759, 141179.5190225899], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1899600.0000, 
sim time next is 1900200.0000, 
raw observation next is [20.48333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6700497137596068, 6.911200000000001, 6.9112, 121.9260426156618, 500514.6344258654, 500514.634425865, 140566.5897577401], 
processed observation next is [1.0, 1.0, 0.31419753086419744, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5875621421995084, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17875522658066623, 0.1787552265806661, 0.27032036491873096], 
reward next is 0.7297, 
noisyNet noise sample is [array([-0.4791313], dtype=float32), -0.3479916]. 
=============================================
[2019-03-24 04:44:45,019] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.6497793e-29 1.4511751e-26 1.9727458e-26 9.7562372e-18], sum to 1.0000
[2019-03-24 04:44:45,029] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8602
[2019-03-24 04:44:45,032] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.9, 63.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9376211639513109, 6.911200000000001, 6.9112, 121.9260426156618, 679165.9813712586, 679165.9813712582, 182189.6474535131], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2046000.0000, 
sim time next is 2046600.0000, 
raw observation next is [28.95, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9414648261546493, 6.9112, 6.9112, 121.9260426156618, 681377.24743353, 681377.24743353, 182797.2652970973], 
processed observation next is [0.0, 0.6956521739130435, 0.6277777777777778, 0.63, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9268310326933116, 0.0, 0.0, 0.8094621288201359, 0.24334901694054645, 0.24334901694054645, 0.3515332024944179], 
reward next is 0.6485, 
noisyNet noise sample is [array([-0.7859754], dtype=float32), -0.89284325]. 
=============================================
[2019-03-24 04:44:52,854] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.7855180e-14 1.3221540e-12 4.3539570e-14 1.4849557e-09], sum to 1.0000
[2019-03-24 04:44:52,861] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4143
[2019-03-24 04:44:52,868] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 777705.3489178077 W.
[2019-03-24 04:44:52,877] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.85, 89.5, 1.0, 2.0, 0.3371069409695124, 1.0, 2.0, 0.3371069409695124, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425102166, 777705.3489178077, 777705.3489178077, 190051.656237459], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2179800.0000, 
sim time next is 2180400.0000, 
raw observation next is [23.9, 89.33333333333333, 1.0, 2.0, 0.2290097506001118, 1.0, 2.0, 0.2290097506001118, 1.0, 1.0, 0.3647477329003335, 6.9112, 6.9112, 121.94756008, 788096.9218068834, 788096.9218068834, 230320.0160807791], 
processed observation next is [1.0, 0.21739130434782608, 0.4407407407407407, 0.8933333333333333, 1.0, 1.0, 0.0821544650001331, 1.0, 1.0, 0.0821544650001331, 1.0, 0.5, 0.2059346661254169, 0.0, 0.0, 0.8096049824067558, 0.2814631863596012, 0.2814631863596012, 0.44292310784765215], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5884674], dtype=float32), 0.66518533]. 
=============================================
[2019-03-24 04:44:54,695] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.6086871e-23 7.9142309e-19 3.3470795e-22 4.0002160e-12], sum to 1.0000
[2019-03-24 04:44:54,704] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9036
[2019-03-24 04:44:54,714] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1524843.381217307 W.
[2019-03-24 04:44:54,718] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.3, 89.0, 1.0, 2.0, 0.7105503853297819, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1524843.381217307, 1524843.381217307, 319151.1574657365], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2203200.0000, 
sim time next is 2203800.0000, 
raw observation next is [25.46666666666667, 88.33333333333334, 1.0, 2.0, 0.7546607011129778, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1575192.238473703, 1575192.238473703, 327400.7514528013], 
processed observation next is [1.0, 0.5217391304347826, 0.4987654320987655, 0.8833333333333334, 1.0, 1.0, 0.7079294060868783, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.562568656597751, 0.562568656597751, 0.6296168297169256], 
reward next is 0.3704, 
noisyNet noise sample is [array([-0.41571188], dtype=float32), -0.9606189]. 
=============================================
[2019-03-24 04:45:05,784] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 4.7959823e-32 4.0612386e-25 1.7445644e-27 1.7099679e-18], sum to 1.0000
[2019-03-24 04:45:05,793] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7188
[2019-03-24 04:45:05,797] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.66666666666667, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.583770478087621, 6.911200000000001, 6.9112, 121.9260426156618, 430964.1874114231, 430964.1874114226, 127417.1145619559], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2419800.0000, 
sim time next is 2420400.0000, 
raw observation next is [22.53333333333333, 63.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5787302020270353, 6.9112, 6.9112, 121.9260426156618, 426636.2744526406, 426636.2744526406, 126634.1544226458], 
processed observation next is [1.0, 0.0, 0.3901234567901234, 0.6300000000000001, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.47341275253379406, 0.0, 0.0, 0.8094621288201359, 0.15237009801880022, 0.15237009801880022, 0.24352722004354962], 
reward next is 0.7565, 
noisyNet noise sample is [array([-0.15983148], dtype=float32), -1.4446987]. 
=============================================
[2019-03-24 04:45:08,709] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 7.9496144e-31 2.2072222e-26 3.9007462e-30 1.6682717e-21], sum to 1.0000
[2019-03-24 04:45:08,716] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3690
[2019-03-24 04:45:08,722] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1640332.832985692 W.
[2019-03-24 04:45:08,725] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.0, 23.0, 1.0, 2.0, 0.7649758412779865, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9583210905040765, 6.911200000000001, 6.9112, 121.9260426156618, 1640332.832985692, 1640332.832985691, 319552.3867287905], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2469600.0000, 
sim time next is 2470200.0000, 
raw observation next is [34.93333333333334, 23.0, 1.0, 2.0, 0.3997691015041818, 1.0, 1.0, 0.3997691015041818, 1.0, 2.0, 0.6434363049620372, 6.911199999999999, 6.9112, 121.94756008, 1430896.44532836, 1430896.44532836, 296697.4533013114], 
processed observation next is [1.0, 0.6086956521739131, 0.8493827160493829, 0.23, 1.0, 1.0, 0.2854394065525974, 1.0, 0.5, 0.2854394065525974, 1.0, 1.0, 0.5542953812025464, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5110344447601286, 0.5110344447601286, 0.570572025579445], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5976217], dtype=float32), -0.46741328]. 
=============================================
[2019-03-24 04:45:09,384] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 04:45:09,386] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:45:09,387] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:45:09,387] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:45:09,389] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:45:09,389] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:45:09,393] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:45:09,390] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:45:09,394] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:45:09,396] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:45:09,397] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:45:09,416] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run80
[2019-03-24 04:45:09,457] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run80
[2019-03-24 04:45:09,482] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run80
[2019-03-24 04:45:09,482] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run80
[2019-03-24 04:45:09,483] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run80
[2019-03-24 04:45:17,352] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.43811777]
[2019-03-24 04:45:17,353] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.9, 33.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6460245179375047, 6.9112, 6.9112, 121.9260426156618, 482202.3671990461, 482202.3671990461, 137369.2129966636]
[2019-03-24 04:45:17,355] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:45:17,357] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 7.1189708e-33 7.4367117e-28 1.8538424e-29 1.1814400e-20], sampled 0.3788347157632983
[2019-03-24 04:45:26,828] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.43811777]
[2019-03-24 04:45:26,829] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.95, 39.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5849657030479003, 6.9112, 6.9112, 121.9260426156618, 433410.1780763821, 433410.1780763821, 128450.7585055402]
[2019-03-24 04:45:26,832] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:45:26,835] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 6.9951700e-32 5.2181308e-27 1.4467905e-28 4.9820051e-20], sampled 0.2211187316431129
[2019-03-24 04:45:47,526] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.43811777]
[2019-03-24 04:45:47,528] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.06666666666667, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8980153987521684, 6.9112, 6.9112, 121.9260426156618, 655780.5926948885, 655780.5926948885, 175960.0674596825]
[2019-03-24 04:45:47,530] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:45:47,536] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.2306963e-32 1.9781251e-27 5.1472891e-29 2.3947182e-20], sampled 0.35662404863873265
[2019-03-24 04:45:48,206] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.43811777]
[2019-03-24 04:45:48,207] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.16666666666666, 94.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8818314511830254, 6.9112, 6.9112, 121.9260426156618, 647295.2820288939, 647295.2820288939, 173126.9608054417]
[2019-03-24 04:45:48,208] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:45:48,210] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.1551750e-30 1.6675620e-25 5.5969774e-27 6.2405711e-19], sampled 0.8197342048827441
[2019-03-24 04:46:10,394] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.43811777]
[2019-03-24 04:46:10,395] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.33333333333333, 68.5, 1.0, 2.0, 0.7266048581907184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 829195.8767345578, 829195.8767345578, 181291.3504566839]
[2019-03-24 04:46:10,397] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:46:10,400] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.8227559e-25 3.6168908e-21 1.6345376e-22 9.5832514e-16], sampled 0.6065448749251822
[2019-03-24 04:46:10,402] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 829195.8767345578 W.
[2019-03-24 04:46:20,677] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.43811777]
[2019-03-24 04:46:20,678] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.52408692666667, 87.96721079999999, 1.0, 2.0, 0.8250458946337765, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425565181, 940406.3594285061, 940406.3594285061, 201173.937603903]
[2019-03-24 04:46:20,680] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:46:20,684] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 4.7948737e-29 1.3353881e-24 5.0346240e-26 2.8958001e-18], sampled 0.44747087994675694
[2019-03-24 04:46:20,686] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 940406.3594285061 W.
[2019-03-24 04:46:20,793] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.43811777]
[2019-03-24 04:46:20,796] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.26666666666667, 97.33333333333334, 1.0, 2.0, 0.995115645957299, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.114567808071688, 6.9112, 121.9251400055933, 1238618.117752619, 1134476.39417118, 239544.8113698566]
[2019-03-24 04:46:20,798] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:46:20,800] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.0527729e-25 3.0931950e-21 1.6955316e-22 8.6689820e-16], sampled 0.6492335270311409
[2019-03-24 04:46:20,803] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1238618.117752619 W.
[2019-03-24 04:46:29,831] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.43811777]
[2019-03-24 04:46:29,832] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.39237601666667, 64.42108673999999, 1.0, 2.0, 0.6578679567098725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 773838.4946493855, 773838.4946493855, 169450.0926101]
[2019-03-24 04:46:29,835] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:46:29,837] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.9322449e-25 1.7945457e-21 8.8235910e-23 5.8532989e-16], sampled 0.2732228035580876
[2019-03-24 04:46:29,838] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 773838.4946493855 W.
[2019-03-24 04:46:32,458] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.43811777]
[2019-03-24 04:46:32,461] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.35, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8471162696556668, 6.9112, 6.9112, 121.9260426156618, 623588.891503336, 623588.891503336, 168201.1037025639]
[2019-03-24 04:46:32,463] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:46:32,466] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.6049530e-31 1.0716307e-26 3.0521018e-28 8.4363569e-20], sampled 0.7149311160826669
[2019-03-24 04:46:46,958] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.43811777]
[2019-03-24 04:46:46,958] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.42084330333333, 76.2381618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5609662359374715, 6.911200000000001, 6.9112, 121.9260426156618, 409893.3713693703, 409893.3713693698, 123324.8747080762]
[2019-03-24 04:46:46,961] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:46:46,964] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.5258536e-30 7.4244174e-26 2.3036553e-27 3.4851603e-19], sampled 0.8166970149128815
[2019-03-24 04:46:47,293] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06796347], dtype=float32), 0.43811777]
[2019-03-24 04:46:47,294] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.70742059, 89.94170686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7922015530422836, 6.9112, 6.9112, 121.9260426156618, 588577.4914520668, 588577.4914520668, 159282.4975949791]
[2019-03-24 04:46:47,298] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:46:47,302] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 6.6303832e-30 2.5558763e-25 8.5856709e-27 8.6234856e-19], sampled 0.22168390953475714
[2019-03-24 04:46:55,185] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8362.6197 2339528955.2376 616.0000
[2019-03-24 04:46:55,234] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8402.7825 2293090583.1810 697.0000
[2019-03-24 04:46:55,260] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 04:46:55,406] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8632.2850 2219299766.1518 543.0000
[2019-03-24 04:46:55,498] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7840.1135 2529851152.3099 831.0000
[2019-03-24 04:46:56,516] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1975000, evaluation results [1975000.0, 7840.11350377941, 2529851152.3098564, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8632.284958361142, 2219299766.1518497, 543.0, 8362.619748969548, 2339528955.237554, 616.0, 8402.782546002263, 2293090583.180975, 697.0]
[2019-03-24 04:47:00,125] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.6048368e-30 7.3192140e-27 7.3706239e-28 3.6219165e-21], sum to 1.0000
[2019-03-24 04:47:00,133] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0719
[2019-03-24 04:47:00,144] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1658957.833781721 W.
[2019-03-24 04:47:00,150] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.33333333333334, 33.33333333333334, 1.0, 2.0, 0.7081499435098829, 1.0, 2.0, 0.7081499435098829, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1658957.833781721, 1658957.833781721, 309401.2305168799], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2564400.0000, 
sim time next is 2565000.0000, 
raw observation next is [33.3, 33.5, 1.0, 2.0, 0.6930617698717357, 1.0, 2.0, 0.6930617698717357, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1624636.838165565, 1624636.838165567, 303676.7813838234], 
processed observation next is [1.0, 0.6956521739130435, 0.7888888888888888, 0.335, 1.0, 1.0, 0.6345973450853997, 1.0, 1.0, 0.6345973450853997, 0.0, 1.0, -0.25, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.5802274422019875, 0.5802274422019882, 0.5839938103535066], 
reward next is 0.4160, 
noisyNet noise sample is [array([-0.47704753], dtype=float32), 0.9374036]. 
=============================================
[2019-03-24 04:47:00,172] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[65.27398 ]
 [64.9922  ]
 [64.62588 ]
 [64.059685]
 [63.73535 ]], R is [[65.45938873]
 [65.20979309]
 [64.92932892]
 [64.64748383]
 [64.34069061]].
[2019-03-24 04:47:10,957] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9999940e-01 1.1534900e-13 5.3301119e-10 1.6639692e-12 5.9484876e-07], sum to 1.0000
[2019-03-24 04:47:10,966] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1009
[2019-03-24 04:47:10,973] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2108144.756824311 W.
[2019-03-24 04:47:10,976] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.33333333333334, 77.33333333333334, 1.0, 2.0, 0.9241096060561259, 1.0, 2.0, 0.9241096060561259, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156449, 2108144.756824311, 2108144.756824311, 397707.7121281388], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2798400.0000, 
sim time next is 2799000.0000, 
raw observation next is [28.5, 76.5, 1.0, 2.0, 0.9585659147575157, 1.0, 2.0, 0.9585659147575157, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2186845.205157845, 2186845.205157845, 413633.1991723234], 
processed observation next is [1.0, 0.391304347826087, 0.6111111111111112, 0.765, 1.0, 1.0, 0.9506737080446616, 1.0, 1.0, 0.9506737080446616, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7810161446992303, 0.7810161446992303, 0.7954484599467757], 
reward next is 0.2046, 
noisyNet noise sample is [array([2.5551267], dtype=float32), -1.4321086]. 
=============================================
[2019-03-24 04:47:10,999] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[30.413889]
 [30.452665]
 [29.954258]
 [30.918291]
 [29.896261]], R is [[30.79220009]
 [30.48427773]
 [30.17943573]
 [29.87764168]
 [29.57886505]].
[2019-03-24 04:47:23,521] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 4.2084005e-18 1.5640245e-14 2.7498401e-16 1.0591646e-10], sum to 1.0000
[2019-03-24 04:47:23,527] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2248
[2019-03-24 04:47:23,533] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 719917.3731354604 W.
[2019-03-24 04:47:23,536] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.66666666666667, 93.16666666666666, 1.0, 2.0, 0.3158476449387547, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5028397371821594, 6.911199999999999, 6.9112, 121.9260426156618, 719917.3731354604, 719917.3731354608, 199551.9481996357], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3030600.0000, 
sim time next is 3031200.0000, 
raw observation next is [24.8, 93.0, 1.0, 2.0, 0.3190622650245319, 1.0, 1.0, 0.3190622650245319, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 727247.9918057821, 727247.9918057825, 185098.1793038805], 
processed observation next is [1.0, 0.08695652173913043, 0.4740740740740741, 0.93, 1.0, 1.0, 0.18935983931491893, 1.0, 0.5, 0.18935983931491893, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2597314256449222, 0.25973142564492235, 0.35595803712284707], 
reward next is 0.6440, 
noisyNet noise sample is [array([-0.2920544], dtype=float32), 0.09462329]. 
=============================================
[2019-03-24 04:47:43,951] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 3.1769988e-23 9.6943566e-18 3.8394956e-22 4.1602365e-14], sum to 1.0000
[2019-03-24 04:47:43,958] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2959
[2019-03-24 04:47:43,965] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2000343.19393677 W.
[2019-03-24 04:47:43,968] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.5, 59.83333333333333, 1.0, 2.0, 0.5846050734561709, 1.0, 2.0, 0.5846050734561709, 1.0, 1.0, 0.9307103162002667, 6.9112, 6.9112, 121.94756008, 2000343.19393677, 2000343.19393677, 387051.4667899525], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3420600.0000, 
sim time next is 3421200.0000, 
raw observation next is [30.8, 59.66666666666667, 1.0, 2.0, 0.8947445583371887, 1.0, 2.0, 0.8947445583371887, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2041078.553879543, 2041078.553879543, 384459.4920977062], 
processed observation next is [1.0, 0.6086956521739131, 0.6962962962962963, 0.5966666666666667, 1.0, 1.0, 0.8746959027823675, 1.0, 1.0, 0.8746959027823675, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.728956626385551, 0.728956626385551, 0.7393451771109735], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1852463], dtype=float32), 0.20837009]. 
=============================================
[2019-03-24 04:47:44,667] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.0481797e-03 6.3867714e-16 5.7725913e-07 4.0456211e-11 9.9095118e-01], sum to 1.0000
[2019-03-24 04:47:44,678] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1742
[2019-03-24 04:47:44,685] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.06666666666667, 92.33333333333334, 1.0, 2.0, 0.2036411486853945, 1.0, 2.0, 0.2036411486853945, 1.0, 2.0, 0.3242033408363478, 6.9112, 6.9112, 121.94756008, 696233.7432759929, 696233.7432759929, 221787.6909110462], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3374400.0000, 
sim time next is 3375000.0000, 
raw observation next is [23.95, 92.0, 1.0, 2.0, 0.2014112130694241, 1.0, 2.0, 0.2014112130694241, 1.0, 2.0, 0.32065321071179, 6.9112, 6.9112, 121.94756008, 688606.337812011, 688606.337812011, 221056.1753725908], 
processed observation next is [1.0, 0.043478260869565216, 0.4425925925925926, 0.92, 1.0, 1.0, 0.04929906317788584, 1.0, 1.0, 0.04929906317788584, 1.0, 1.0, 0.15081651338973745, 0.0, 0.0, 0.8096049824067558, 0.24593083493286108, 0.24593083493286108, 0.4251080295626746], 
reward next is 0.5749, 
noisyNet noise sample is [array([0.05818189], dtype=float32), 1.2713369]. 
=============================================
[2019-03-24 04:47:44,697] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[41.083546]
 [40.963993]
 [40.356197]
 [39.524517]
 [38.962254]], R is [[41.75583649]
 [41.91176605]
 [42.06414032]
 [42.21297836]
 [41.79084778]].
[2019-03-24 04:47:45,361] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.2223692e-20 2.2690260e-16 6.8210851e-20 1.4391365e-13], sum to 1.0000
[2019-03-24 04:47:45,369] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7910
[2019-03-24 04:47:45,374] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2092441.128320835 W.
[2019-03-24 04:47:45,378] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.46666666666667, 59.66666666666667, 1.0, 2.0, 0.9172339441309532, 1.0, 2.0, 0.9172339441309532, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2092441.128320835, 2092441.128320836, 394578.2036570536], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3418800.0000, 
sim time next is 3419400.0000, 
raw observation next is [30.33333333333333, 59.83333333333333, 1.0, 2.0, 0.9134521366458267, 1.0, 2.0, 0.9134521366458267, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2083803.808594624, 2083803.808594625, 392864.272494906], 
processed observation next is [1.0, 0.5652173913043478, 0.6790123456790121, 0.5983333333333333, 1.0, 1.0, 0.8969668293402698, 1.0, 1.0, 0.8969668293402698, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7442156459266515, 0.7442156459266518, 0.7555082163363577], 
reward next is 0.2445, 
noisyNet noise sample is [array([-1.3857152], dtype=float32), 0.31801897]. 
=============================================
[2019-03-24 04:47:45,467] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0843018e-04 3.0370600e-12 1.5646933e-03 1.4823041e-07 9.9822670e-01], sum to 1.0000
[2019-03-24 04:47:45,472] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0554
[2019-03-24 04:47:45,475] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.4, 81.0, 1.0, 2.0, 0.4930601533575668, 1.0, 2.0, 0.4930601533575668, 1.0, 2.0, 0.7849678219933844, 6.911200000000001, 6.9112, 121.94756008, 1686808.209252255, 1686808.209252254, 340195.9292430855], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3400200.0000, 
sim time next is 3400800.0000, 
raw observation next is [26.6, 80.33333333333334, 1.0, 2.0, 0.5022623511741134, 1.0, 2.0, 0.5022623511741134, 1.0, 2.0, 0.7996180206119867, 6.9112, 6.9112, 121.94756008, 1718320.122719688, 1718320.122719688, 344700.8157083318], 
processed observation next is [1.0, 0.34782608695652173, 0.5407407407407407, 0.8033333333333335, 1.0, 1.0, 0.4074551799691826, 1.0, 1.0, 0.4074551799691826, 1.0, 1.0, 0.7495225257649835, 0.0, 0.0, 0.8096049824067558, 0.6136857581141744, 0.6136857581141744, 0.6628861840544843], 
reward next is 0.3371, 
noisyNet noise sample is [array([1.4270056], dtype=float32), -0.059067488]. 
=============================================
[2019-03-24 04:47:46,807] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.3399622e-21 1.8697627e-17 6.2698529e-18 2.1245897e-14], sum to 1.0000
[2019-03-24 04:47:46,808] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 04:47:46,808] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:47:46,809] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:47:46,809] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:47:46,810] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:47:46,811] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:47:46,811] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:47:46,812] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:47:46,812] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:47:46,812] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:47:46,814] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:47:46,814] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0413
[2019-03-24 04:47:46,819] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1506651.097858894 W.
[2019-03-24 04:47:46,823] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 59.0, 1.0, 2.0, 0.4404470268563951, 1.0, 2.0, 0.4404470268563951, 1.0, 2.0, 0.701206011113614, 6.9112, 6.9112, 121.94756008, 1506651.097858894, 1506651.097858894, 315253.1464981434], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3414000.0000, 
sim time next is 3414600.0000, 
raw observation next is [31.0, 59.0, 1.0, 2.0, 0.6224940820862954, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9910308518982889, 6.911199999999999, 6.9112, 121.9260426156618, 1419509.709902043, 1419509.709902043, 302715.166330219], 
processed observation next is [1.0, 0.5217391304347826, 0.7037037037037037, 0.59, 1.0, 1.0, 0.5505881929598755, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9887885648728612, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.506967753536444, 0.506967753536444, 0.5821445506350366], 
reward next is 0.4179, 
noisyNet noise sample is [array([0.21326682], dtype=float32), 0.9183258]. 
=============================================
[2019-03-24 04:47:46,834] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run81
[2019-03-24 04:47:46,860] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run81
[2019-03-24 04:47:46,886] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run81
[2019-03-24 04:47:46,886] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run81
[2019-03-24 04:47:46,907] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run81
[2019-03-24 04:47:58,820] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06823688], dtype=float32), 0.43698314]
[2019-03-24 04:47:58,821] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.0, 52.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3802813634486806, 6.9112, 6.9112, 121.9260426156618, 271509.4458328682, 271509.4458328682, 81648.84275048977]
[2019-03-24 04:47:58,822] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:47:58,824] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 5.3100267e-24 2.4566670e-19 9.0283977e-22 1.1019362e-15], sampled 0.8816543849439216
[2019-03-24 04:48:05,638] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06823688], dtype=float32), 0.43698314]
[2019-03-24 04:48:05,640] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.7, 29.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7030140601608994, 6.9112, 6.9112, 121.9260426156618, 525207.6928327834, 525207.6928327834, 145980.9347407205]
[2019-03-24 04:48:05,641] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:48:05,642] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.7608428e-25 2.2576247e-20 6.2072953e-23 1.6398449e-16], sampled 0.7883606577358844
[2019-03-24 04:48:08,737] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06823688], dtype=float32), 0.43698314]
[2019-03-24 04:48:08,738] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.46392229666667, 66.48223047333335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.891302498051193, 6.9112, 6.9112, 121.9260426156618, 656806.5342250897, 656806.5342250897, 173715.4112489151]
[2019-03-24 04:48:08,739] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:48:08,742] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.3418596e-21 3.3840760e-17 2.2464579e-19 5.6198851e-14], sampled 0.12988751382601715
[2019-03-24 04:48:11,094] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06823688], dtype=float32), 0.43698314]
[2019-03-24 04:48:11,094] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.53266781, 56.37303996666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7009835751203431, 6.911200000000001, 6.9112, 121.9260426156618, 519344.5660496248, 519344.5660496243, 139697.4099510983]
[2019-03-24 04:48:11,098] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:48:11,100] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.8431882e-22 7.7271275e-18 4.3810174e-20 1.7368697e-14], sampled 0.7098505456468216
[2019-03-24 04:48:22,298] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06823688], dtype=float32), 0.43698314]
[2019-03-24 04:48:22,300] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.52521540666667, 67.04418800833334, 1.0, 2.0, 0.6935100757505049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790401.4860851192, 790401.4860851192, 174918.2826483932]
[2019-03-24 04:48:22,300] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:48:22,304] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.00000000e+00 1.10770555e-23 4.39766282e-19 1.77048842e-21
 1.77632529e-15], sampled 0.5661571860592273
[2019-03-24 04:48:22,304] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 790401.4860851192 W.
[2019-03-24 04:48:26,609] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06823688], dtype=float32), 0.43698314]
[2019-03-24 04:48:26,610] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.98333333333333, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9203525800113972, 6.9112, 6.9112, 121.9260426156618, 665030.2280106925, 665030.2280106925, 180038.7752802871]
[2019-03-24 04:48:26,610] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:48:26,616] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 5.5339953e-24 2.5135535e-19 9.3886918e-22 1.1291743e-15], sampled 0.1896923084082649
[2019-03-24 04:49:09,408] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06823688], dtype=float32), 0.43698314]
[2019-03-24 04:49:09,409] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.87323616833334, 72.0591067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8963036534629838, 6.911200000000001, 6.9112, 121.9260426156618, 664037.5199144194, 664037.5199144189, 173188.1217843055]
[2019-03-24 04:49:09,409] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:49:09,413] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 7.0309166e-23 1.9600169e-18 9.4027834e-21 5.8133811e-15], sampled 0.0977200869834437
[2019-03-24 04:49:33,870] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8632.2850 2219299766.1518 543.0000
[2019-03-24 04:49:33,900] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7839.3642 2529907632.7168 831.0000
[2019-03-24 04:49:33,992] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8559.5106 2258278767.0965 536.0000
[2019-03-24 04:49:34,145] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8402.7825 2293090583.1810 697.0000
[2019-03-24 04:49:34,257] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8361.8044 2339582728.4665 616.0000
[2019-03-24 04:49:35,275] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2000000, evaluation results [2000000.0, 7839.3642237539425, 2529907632.7168317, 831.0, 8559.510645911187, 2258278767.096507, 536.0, 8632.284958361142, 2219299766.1518497, 543.0, 8361.804412745285, 2339582728.466484, 616.0, 8402.782546002263, 2293090583.180975, 697.0]
[2019-03-24 04:49:42,418] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.5098894e-16 1.3311792e-13 2.3309907e-17 9.9592341e-11], sum to 1.0000
[2019-03-24 04:49:42,422] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7928
[2019-03-24 04:49:42,427] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.03333333333333, 86.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.782328757009901, 6.9112, 6.9112, 121.9260426156618, 581787.1476675952, 581787.1476675952, 157774.0208018786], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3563400.0000, 
sim time next is 3564000.0000, 
raw observation next is [23.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7953774877980558, 6.9112, 6.9112, 121.9260426156618, 590328.7910598944, 590328.7910598944, 159968.5694572429], 
processed observation next is [1.0, 0.2608695652173913, 0.4074074074074074, 0.89, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7442218597475697, 0.0, 0.0, 0.8094621288201359, 0.21083171109281942, 0.21083171109281942, 0.30763186434085177], 
reward next is 0.6924, 
noisyNet noise sample is [array([-0.98329073], dtype=float32), -0.20275806]. 
=============================================
[2019-03-24 04:49:42,449] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[34.70289 ]
 [35.198128]
 [35.127647]
 [34.70716 ]
 [34.4002  ]], R is [[34.53726959]
 [34.88848495]
 [35.2407341 ]
 [35.59288025]
 [35.94335938]].
[2019-03-24 04:49:50,300] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.3423134e-13 8.4513091e-11 2.8983120e-12 8.3768210e-09], sum to 1.0000
[2019-03-24 04:49:50,306] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4618
[2019-03-24 04:49:50,313] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1748969.075676337 W.
[2019-03-24 04:49:50,319] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.6, 94.0, 1.0, 2.0, 0.7668182164241547, 1.0, 1.0, 0.7668182164241547, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9258014389689, 1748969.075676337, 1748969.075676336, 330234.086866271], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3745200.0000, 
sim time next is 3745800.0000, 
raw observation next is [25.7, 94.0, 1.0, 2.0, 0.5375298844746503, 1.0, 2.0, 0.5375298844746503, 1.0, 1.0, 0.8557650822098144, 6.911199999999999, 6.9112, 121.94756008, 1839100.201686117, 1839100.201686118, 362390.8127716901], 
processed observation next is [1.0, 0.34782608695652173, 0.5074074074074074, 0.94, 1.0, 1.0, 0.449440338660298, 1.0, 1.0, 0.449440338660298, 1.0, 0.5, 0.819706352762268, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6568215006021847, 0.656821500602185, 0.696905409176327], 
reward next is 0.3031, 
noisyNet noise sample is [array([2.107209], dtype=float32), -0.10655447]. 
=============================================
[2019-03-24 04:49:58,727] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 2.7317482e-19 2.3879728e-16 6.8235607e-19 3.8487475e-15], sum to 1.0000
[2019-03-24 04:49:58,736] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6441
[2019-03-24 04:49:58,746] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 857911.1625041036 W.
[2019-03-24 04:49:58,752] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.08333333333333, 88.16666666666666, 1.0, 2.0, 0.752710942240967, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 857911.1625041036, 857911.1625041032, 186365.9957129154], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3916200.0000, 
sim time next is 3916800.0000, 
raw observation next is [27.3, 87.0, 1.0, 2.0, 0.3767241289386588, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5997570823186774, 6.911199999999999, 6.9112, 121.9260426156618, 858751.9974871912, 858751.9974871917, 217030.5137031952], 
processed observation next is [0.0, 0.34782608695652173, 0.5666666666666667, 0.87, 1.0, 1.0, 0.2580049154031653, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.49969635289834674, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30669714195971115, 0.3066971419597113, 0.4173663725061446], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.61751854], dtype=float32), 1.1996433]. 
=============================================
[2019-03-24 04:50:02,877] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.9796787e-16 8.4250342e-13 1.6259596e-17 1.9438427e-12], sum to 1.0000
[2019-03-24 04:50:02,883] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7929
[2019-03-24 04:50:02,891] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 889683.9480594818 W.
[2019-03-24 04:50:02,900] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.7805714610530609, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 889683.9480594818, 889683.9480594818, 191966.4293338734], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3943200.0000, 
sim time next is 3943800.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.4012121764691841, 1.0, 1.0, 0.4012121764691841, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 914606.4175546049, 914606.4175546054, 206524.7440746851], 
processed observation next is [0.0, 0.6521739130434783, 0.7037037037037037, 0.7, 1.0, 1.0, 0.2871573529395049, 1.0, 0.5, 0.2871573529395049, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3266451491266446, 0.3266451491266448, 0.3971629693743944], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5921633], dtype=float32), -0.9257162]. 
=============================================
[2019-03-24 04:50:05,996] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 8.7280863e-22 4.9237500e-15 1.6386668e-19 1.4686459e-14], sum to 1.0000
[2019-03-24 04:50:06,002] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4161
[2019-03-24 04:50:06,008] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1749490.113388555 W.
[2019-03-24 04:50:06,011] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.907363552569327, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1749490.113388555, 1749490.113388556, 358562.1685446435], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4030800.0000, 
sim time next is 4031400.0000, 
raw observation next is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.9161277378150863, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1759494.694189171, 1759494.694189172, 360473.1361541105], 
processed observation next is [1.0, 0.6521739130434783, 0.5493827160493825, 0.8483333333333333, 1.0, 1.0, 0.9001520688274837, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6283909622104182, 0.6283909622104186, 0.6932175695271355], 
reward next is 0.3068, 
noisyNet noise sample is [array([-0.5806202], dtype=float32), -0.25981748]. 
=============================================
[2019-03-24 04:50:18,958] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 8.1489344e-26 2.8914950e-18 1.0655459e-24 9.5382408e-17], sum to 1.0000
[2019-03-24 04:50:18,969] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8427
[2019-03-24 04:50:18,981] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1495283.875744675 W.
[2019-03-24 04:50:18,984] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.98333333333333, 37.66666666666666, 1.0, 2.0, 0.6354515711604771, 1.0, 2.0, 0.6354515711604771, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1495283.875744675, 1495283.875744675, 282618.7550547323], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4276200.0000, 
sim time next is 4276800.0000, 
raw observation next is [32.0, 38.0, 1.0, 2.0, 0.47334832663591, 1.0, 2.0, 0.47334832663591, 1.0, 1.0, 0.7548931456181511, 6.911200000000001, 6.9112, 121.94756008, 1646057.191195635, 1646057.191195634, 330808.4039740268], 
processed observation next is [1.0, 0.5217391304347826, 0.7407407407407407, 0.38, 1.0, 1.0, 0.3730337221856071, 1.0, 1.0, 0.3730337221856071, 1.0, 0.5, 0.693616432022689, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5878775682841553, 0.5878775682841549, 0.6361700076423592], 
reward next is 0.3638, 
noisyNet noise sample is [array([-0.6800692], dtype=float32), -1.2049631]. 
=============================================
[2019-03-24 04:50:20,688] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 8.0693276e-22 3.6786522e-17 1.9952024e-24 2.0535189e-15], sum to 1.0000
[2019-03-24 04:50:20,694] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5922
[2019-03-24 04:50:20,700] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 721111.5343483262 W.
[2019-03-24 04:50:20,706] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 1.0, 0.6320741877335764, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260389938982, 721111.5343483262, 721111.5343483262, 163720.8254081969], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4320000.0000, 
sim time next is 4320600.0000, 
raw observation next is [25.83333333333334, 83.83333333333333, 1.0, 2.0, 0.6291021242373762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426145575, 718363.9419584655, 718363.9419584655, 163225.4097789217], 
processed observation next is [1.0, 0.0, 0.5123456790123458, 0.8383333333333333, 1.0, 1.0, 0.5584549098064002, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288128045, 0.25655855069945194, 0.25655855069945194, 0.31389501880561865], 
reward next is 0.6861, 
noisyNet noise sample is [array([1.8066808], dtype=float32), -1.1167852]. 
=============================================
[2019-03-24 04:50:21,353] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.00000000e+00 8.48975245e-28 2.46147786e-20 1.15435465e-26
 1.13551309e-19], sum to 1.0000
[2019-03-24 04:50:21,361] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4974
[2019-03-24 04:50:21,369] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1885804.122219975 W.
[2019-03-24 04:50:21,379] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [34.0, 34.0, 1.0, 2.0, 1.007739631033225, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9814026033154762, 6.911199999999999, 6.9112, 121.9259250305836, 1885804.122219975, 1885804.122219975, 378765.757897071], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4287600.0000, 
sim time next is 4288200.0000, 
raw observation next is [33.83333333333334, 35.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9816956117684125, 7.730078699410413, 6.9112, 121.9232183009829, 2319403.058239168, 1900073.687232157, 378893.3855203709], 
processed observation next is [1.0, 0.6521739130434783, 0.8086419753086423, 0.3566666666666667, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9771195147105155, 0.08188786994104129, 0.0, 0.8094433783077483, 0.8283582350854172, 0.678597745440056, 0.7286411260007133], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8241884], dtype=float32), -0.7602698]. 
=============================================
[2019-03-24 04:50:21,743] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.7044080e-16 1.0420732e-11 1.3440446e-14 2.7341625e-11], sum to 1.0000
[2019-03-24 04:50:21,755] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5820
[2019-03-24 04:50:21,761] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 951625.8935006766 W.
[2019-03-24 04:50:21,766] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.2782943674345719, 1.0, 1.0, 0.2782943674345719, 1.0, 2.0, 0.4430536963706359, 6.9112, 6.9112, 121.94756008, 951625.8935006766, 951625.8935006766, 247881.852521103], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4330800.0000, 
sim time next is 4331400.0000, 
raw observation next is [23.83333333333333, 94.00000000000001, 1.0, 2.0, 0.4929435243948392, 1.0, 2.0, 0.4929435243948392, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1123871.267886164, 1123871.267886164, 233208.1696911709], 
processed observation next is [1.0, 0.13043478260869565, 0.43827160493827144, 0.9400000000000002, 1.0, 1.0, 0.39636133856528477, 1.0, 1.0, 0.39636133856528477, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.40138259567362994, 0.40138259567362994, 0.44847724940609784], 
reward next is 0.5515, 
noisyNet noise sample is [array([0.24315545], dtype=float32), -1.9754344]. 
=============================================
[2019-03-24 04:50:25,239] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 04:50:25,241] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:50:25,242] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:50:25,242] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:50:25,243] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:50:25,244] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:50:25,247] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:50:25,245] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:50:25,249] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:50:25,250] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:50:25,249] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:50:25,266] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run82
[2019-03-24 04:50:25,290] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run82
[2019-03-24 04:50:25,327] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run82
[2019-03-24 04:50:25,327] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run82
[2019-03-24 04:50:25,373] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run82
[2019-03-24 04:50:57,844] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.43709964]
[2019-03-24 04:50:57,846] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8969904009205061, 6.9112, 6.9112, 121.9260426156618, 656084.0740957045, 656084.0740957045, 175621.6349496004]
[2019-03-24 04:50:57,847] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:50:57,849] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.4226810e-22 2.8136092e-18 1.6460069e-22 7.1567958e-17], sampled 0.5489249704874655
[2019-03-24 04:51:04,777] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.43709964]
[2019-03-24 04:51:04,779] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.03333333333333, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.769463850226027, 6.9112, 6.9112, 121.9260426156618, 572846.5492750793, 572846.5492750793, 155825.0472251663]
[2019-03-24 04:51:04,781] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:51:04,784] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 5.1804234e-21 5.9188823e-17 6.1884112e-21 1.1342512e-15], sampled 0.98710902249404
[2019-03-24 04:52:11,248] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 04:52:11,617] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 04:52:11,720] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 04:52:11,723] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 04:52:11,725] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 04:52:12,740] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2025000, evaluation results [2025000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 04:52:14,901] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 5.2972294e-28 1.2502502e-21 2.0105270e-26 2.0494219e-19], sum to 1.0000
[2019-03-24 04:52:14,907] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9069
[2019-03-24 04:52:14,913] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 703369.1158198167 W.
[2019-03-24 04:52:14,920] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.91666666666666, 78.83333333333334, 1.0, 2.0, 0.6093002730997358, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 703369.1158198167, 703369.1158198167, 160120.6255606388], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4399800.0000, 
sim time next is 4400400.0000, 
raw observation next is [25.63333333333333, 78.66666666666667, 1.0, 2.0, 0.2981790117021911, 1.0, 1.0, 0.2981790117021911, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 686725.2346648641, 686725.2346648646, 180374.459952577], 
processed observation next is [1.0, 0.9565217391304348, 0.5049382716049381, 0.7866666666666667, 1.0, 1.0, 0.16449882345498937, 1.0, 0.5, 0.16449882345498937, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24525901238030862, 0.24525901238030878, 0.34687396144726346], 
reward next is 0.6531, 
noisyNet noise sample is [array([-0.9892192], dtype=float32), 1.1817144]. 
=============================================
[2019-03-24 04:52:22,989] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.0809488e-27 1.4588949e-20 8.5575831e-27 1.4754523e-17], sum to 1.0000
[2019-03-24 04:52:22,999] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8210
[2019-03-24 04:52:23,004] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 905959.2260436977 W.
[2019-03-24 04:52:23,013] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 94.0, 1.0, 2.0, 0.3974211369268907, 1.0, 1.0, 0.3974211369268907, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 905959.2260436977, 905959.2260436981, 205484.4181486095], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4819200.0000, 
sim time next is 4819800.0000, 
raw observation next is [27.0, 94.0, 1.0, 2.0, 0.3972804459404137, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6324834084579778, 6.9112, 6.9112, 121.9260426156618, 905638.3180784467, 905638.3180784467, 223268.8197990481], 
processed observation next is [1.0, 0.782608695652174, 0.5555555555555556, 0.94, 1.0, 1.0, 0.28247672135763535, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.5406042605724722, 0.0, 0.0, 0.8094621288201359, 0.3234422564565881, 0.3234422564565881, 0.4293631149981694], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.10981163], dtype=float32), 0.9348369]. 
=============================================
[2019-03-24 04:52:24,673] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 5.9819230e-30 8.9157186e-24 2.7072594e-31 2.9937175e-22], sum to 1.0000
[2019-03-24 04:52:24,679] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9101
[2019-03-24 04:52:24,686] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8903135971417252, 6.911200000000001, 6.9112, 121.9260426156618, 654202.4822001756, 654202.4822001752, 174077.45576828], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4571400.0000, 
sim time next is 4572000.0000, 
raw observation next is [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8787291817171135, 6.911199999999999, 6.9112, 121.9260426156618, 646759.4925006556, 646759.4925006559, 172290.6315049681], 
processed observation next is [0.0, 0.9565217391304348, 0.4074074074074074, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8484114771463919, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23098553303594843, 0.23098553303594854, 0.33132813750955403], 
reward next is 0.6687, 
noisyNet noise sample is [array([0.817436], dtype=float32), -1.9673127]. 
=============================================
[2019-03-24 04:52:24,701] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[57.847317]
 [57.57018 ]
 [57.593952]
 [57.71099 ]
 [57.677532]], R is [[57.70125198]
 [57.7894783 ]
 [57.87347794]
 [57.95381165]
 [58.03107834]].
[2019-03-24 04:52:25,490] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.8472052e-23 3.6148136e-18 9.7094363e-22 1.3666183e-16], sum to 1.0000
[2019-03-24 04:52:25,501] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4828
[2019-03-24 04:52:25,510] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 771885.0056696419 W.
[2019-03-24 04:52:25,515] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.73333333333333, 82.66666666666667, 1.0, 2.0, 0.6772716154162686, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 771885.0056696419, 771885.0056696419, 171884.7722606645], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4650000.0000, 
sim time next is 4650600.0000, 
raw observation next is [26.66666666666667, 82.33333333333334, 1.0, 2.0, 0.2239179457141725, 1.0, 1.0, 0.2239179457141725, 1.0, 1.0, 0.3564846620753387, 6.9112, 6.9112, 121.94756008, 765593.1976188315, 765593.1976188315, 228567.0589955132], 
processed observation next is [1.0, 0.8260869565217391, 0.5432098765432101, 0.8233333333333335, 1.0, 1.0, 0.07609279251687202, 1.0, 0.5, 0.07609279251687202, 1.0, 0.5, 0.19560582759417333, 0.0, 0.0, 0.8096049824067558, 0.27342614200672555, 0.27342614200672555, 0.43955203652983305], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.093464], dtype=float32), -0.30008167]. 
=============================================
[2019-03-24 04:52:31,359] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.0582387e-24 3.5801059e-19 2.2369697e-23 5.7369335e-16], sum to 1.0000
[2019-03-24 04:52:31,363] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0853
[2019-03-24 04:52:31,368] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 836631.0187902866 W.
[2019-03-24 04:52:31,371] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 86.5, 1.0, 2.0, 0.2446835011532588, 1.0, 2.0, 0.2446835011532588, 1.0, 1.0, 0.3895441026212907, 6.911200000000001, 6.9112, 121.94756008, 836631.0187902866, 836631.0187902862, 235748.1591342059], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4732200.0000, 
sim time next is 4732800.0000, 
raw observation next is [27.33333333333334, 87.33333333333333, 1.0, 2.0, 0.7348423893616886, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 837534.1412551407, 837534.1412551402, 182849.0209175823], 
processed observation next is [1.0, 0.782608695652174, 0.5679012345679014, 0.8733333333333333, 1.0, 1.0, 0.684336177811534, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2991193361625502, 0.29911933616255004, 0.3516327325338121], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.21174665], dtype=float32), -0.57857746]. 
=============================================
[2019-03-24 04:52:42,772] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.5972753e-17 2.2217595e-12 2.7559820e-17 3.0795284e-12], sum to 1.0000
[2019-03-24 04:52:42,779] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2011
[2019-03-24 04:52:42,784] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 999032.5408769954 W.
[2019-03-24 04:52:42,792] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.55, 90.0, 1.0, 2.0, 0.4382234229707674, 1.0, 1.0, 0.4382234229707674, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 999032.5408769954, 999032.5408769954, 216941.9346859693], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4912200.0000, 
sim time next is 4912800.0000, 
raw observation next is [28.36666666666667, 91.33333333333334, 1.0, 2.0, 0.4386274989783919, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6983092634739468, 6.911199999999999, 6.9112, 121.9260426156618, 999954.3274664787, 999954.3274664792, 236329.6120814995], 
processed observation next is [1.0, 0.8695652173913043, 0.606172839506173, 0.9133333333333334, 1.0, 1.0, 0.33169940354570465, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.6228865793424335, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3571265455237424, 0.35712654552374257, 0.4544800232336529], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7444053], dtype=float32), 0.7529936]. 
=============================================
[2019-03-24 04:52:42,986] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 6.4846492e-16 1.6387829e-11 1.2598868e-15 1.1288299e-11], sum to 1.0000
[2019-03-24 04:52:42,992] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8603
[2019-03-24 04:52:43,002] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 771110.0783146139 W.
[2019-03-24 04:52:43,011] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.58333333333334, 78.83333333333333, 1.0, 1.0, 0.2204286275517384, 1.0, 1.0, 0.2204286275517384, 1.0, 2.0, 0.3520029203094011, 6.9112, 6.9112, 121.94756008, 771110.0783146139, 771110.0783146139, 227322.7765070637], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4954200.0000, 
sim time next is 4954800.0000, 
raw observation next is [24.66666666666667, 79.66666666666667, 1.0, 2.0, 0.281063199590672, 1.0, 2.0, 0.281063199590672, 1.0, 2.0, 0.448109145190036, 6.911199999999999, 6.9112, 121.94756008, 975278.2984133475, 975278.2984133479, 248929.2528899895], 
processed observation next is [1.0, 0.34782608695652173, 0.469135802469136, 0.7966666666666667, 1.0, 1.0, 0.1441228566555619, 1.0, 1.0, 0.1441228566555619, 1.0, 1.0, 0.31013643148754494, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3483136780047669, 0.3483136780047671, 0.4787101017115183], 
reward next is 0.5213, 
noisyNet noise sample is [array([0.49445194], dtype=float32), 0.9902581]. 
=============================================
[2019-03-24 04:52:57,598] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9992990e-01 3.4932374e-10 6.9019407e-05 1.3633927e-09 1.0796538e-06], sum to 1.0000
[2019-03-24 04:52:57,604] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1879
[2019-03-24 04:52:57,612] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 827531.2491712257 W.
[2019-03-24 04:52:57,615] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.2, 98.66666666666666, 1.0, 2.0, 0.3621337116400145, 1.0, 2.0, 0.3621337116400145, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 827531.2491712257, 827531.2491712262, 196139.3386448269], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5204400.0000, 
sim time next is 5205000.0000, 
raw observation next is [23.1, 99.33333333333334, 1.0, 2.0, 0.35483575903058, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5651699735290654, 6.911199999999999, 6.9112, 121.9260426156618, 814348.640447709, 814348.6404477095, 210480.9799954101], 
processed observation next is [1.0, 0.21739130434782608, 0.41111111111111115, 0.9933333333333334, 1.0, 1.0, 0.23194733217926192, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4564624669113317, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29083880015989605, 0.2908388001598962, 0.40477111537578864], 
reward next is 0.5952, 
noisyNet noise sample is [array([-0.534524], dtype=float32), -0.99410814]. 
=============================================
[2019-03-24 04:52:57,630] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[26.496828]
 [26.71599 ]
 [26.877844]
 [26.752634]
 [26.759394]], R is [[26.37369537]
 [26.73276711]
 [27.08782005]
 [26.81694221]
 [26.54877281]].
[2019-03-24 04:53:00,055] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.8784361e-15 2.0283693e-10 2.6304298e-16 5.1630096e-11], sum to 1.0000
[2019-03-24 04:53:00,062] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7742
[2019-03-24 04:53:00,069] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 744405.8583376646 W.
[2019-03-24 04:53:00,077] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.86666666666667, 81.0, 1.0, 2.0, 0.3265862058884519, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5199358759445916, 6.9112, 6.9112, 121.9260426156618, 744405.8583376646, 744405.8583376646, 202527.486804881], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5508600.0000, 
sim time next is 5509200.0000, 
raw observation next is [26.83333333333333, 81.0, 1.0, 2.0, 0.3232798963867783, 1.0, 1.0, 0.3232798963867783, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736865.9834146295, 736865.9834146295, 186141.4484893155], 
processed observation next is [1.0, 0.782608695652174, 0.5493827160493825, 0.81, 1.0, 1.0, 0.19438082903187892, 1.0, 0.5, 0.19438082903187892, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26316642264808193, 0.26316642264808193, 0.3579643240179144], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3062531], dtype=float32), -0.035018507]. 
=============================================
[2019-03-24 04:53:00,595] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.2713369e-17 1.9006599e-10 2.5450108e-16 7.6796633e-12], sum to 1.0000
[2019-03-24 04:53:00,613] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7926
[2019-03-24 04:53:00,620] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 822366.3163685249 W.
[2019-03-24 04:53:00,624] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.26666666666667, 80.66666666666667, 1.0, 2.0, 0.3607707288825862, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5743587498634429, 6.911199999999999, 6.9112, 121.9260426156618, 822366.3163685249, 822366.3163685254, 212307.5301760479], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5251200.0000, 
sim time next is 5251800.0000, 
raw observation next is [28.08333333333333, 82.33333333333333, 1.0, 2.0, 0.2432076442804542, 1.0, 1.0, 0.2432076442804542, 1.0, 2.0, 0.387194490414483, 6.911200000000001, 6.9112, 121.94756008, 831581.9764276333, 831581.9764276328, 235229.8256752685], 
processed observation next is [1.0, 0.782608695652174, 0.5956790123456789, 0.8233333333333333, 1.0, 1.0, 0.09905671938149307, 1.0, 0.5, 0.09905671938149307, 1.0, 1.0, 0.23399311301810374, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.29699356300986907, 0.2969935630098689, 0.45236504937551636], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3500667], dtype=float32), -0.4393007]. 
=============================================
[2019-03-24 04:53:02,815] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 04:53:02,816] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:53:02,816] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:53:02,817] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:53:02,819] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:53:02,819] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:53:02,819] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:53:02,822] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:53:02,820] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:53:02,820] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:53:02,825] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:53:02,843] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run83
[2019-03-24 04:53:02,867] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run83
[2019-03-24 04:53:02,893] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run83
[2019-03-24 04:53:02,918] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run83
[2019-03-24 04:53:02,919] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run83
[2019-03-24 04:53:07,927] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.44022974]
[2019-03-24 04:53:07,927] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.5, 52.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4308021771582367, 6.9112, 6.9112, 121.9260426156618, 307587.0186594901, 307587.0186594901, 95312.91044977483]
[2019-03-24 04:53:07,928] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:53:07,934] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9972194e-01 2.4925381e-12 2.3143608e-04 1.6663854e-11 4.6623209e-05], sampled 0.20533244866237566
[2019-03-24 04:53:30,403] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.44022974]
[2019-03-24 04:53:30,405] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.46291208, 81.51442314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6997778043127008, 6.9112, 6.9112, 121.9260426156618, 522705.9149947831, 522705.9149947831, 143682.0586280839]
[2019-03-24 04:53:30,407] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:53:30,412] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9989104e-01 9.2035038e-13 8.8698624e-05 6.0167049e-12 2.0322388e-05], sampled 0.8772924991721828
[2019-03-24 04:53:32,208] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.44022974]
[2019-03-24 04:53:32,209] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.5, 67.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7612570045766356, 6.9112, 6.9112, 121.9260426156618, 567300.9100224852, 567300.9100224852, 154431.3452841724]
[2019-03-24 04:53:32,211] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:53:32,214] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9992645e-01 5.3101517e-13 5.9638442e-05 3.4834676e-12 1.3908794e-05], sampled 0.5484682335925976
[2019-03-24 04:53:43,518] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.44022974]
[2019-03-24 04:53:43,519] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.91666666666667, 58.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.541175434076052, 6.9112, 121.9232946087634, 1485629.508141398, 1163033.050271818, 245586.7949800735]
[2019-03-24 04:53:43,520] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:53:43,524] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.5087658e-01 6.2120503e-11 3.3276114e-01 2.3549351e-10 1.6362285e-02], sampled 0.34615411705803656
[2019-03-24 04:53:43,526] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1485629.508141398 W.
[2019-03-24 04:54:00,335] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.44022974]
[2019-03-24 04:54:00,338] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.43406459333333, 76.54110669333333, 1.0, 2.0, 0.6799723189117562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774964.5476208426, 774964.5476208426, 172389.528246992]
[2019-03-24 04:54:00,340] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:54:00,344] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.6285194e-01 4.0847477e-12 3.5486870e-02 2.1595357e-11 1.6611476e-03], sampled 0.6501455217720353
[2019-03-24 04:54:00,348] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 774964.5476208426 W.
[2019-03-24 04:54:12,559] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.44022974]
[2019-03-24 04:54:12,561] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.06666666666667, 93.66666666666667, 1.0, 2.0, 0.4753846175814601, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7568277933858107, 6.911199999999999, 6.9112, 121.9260426156618, 1083810.069319002, 1083810.069319002, 248503.0389416136]
[2019-03-24 04:54:12,562] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:54:12,567] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.9642723e-01 1.6887408e-11 7.7356005e-01 5.8522090e-11 3.0012714e-02], sampled 0.059118873879626554
[2019-03-24 04:54:12,568] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1083810.069319002 W.
[2019-03-24 04:54:39,632] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.44022974]
[2019-03-24 04:54:39,633] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.66348983, 81.57523908333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.635766727304181, 6.911199999999999, 6.9112, 121.9260426156618, 474295.6769429455, 474295.676942946, 135974.8841736057]
[2019-03-24 04:54:39,635] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:54:39,639] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9991345e-01 2.3529713e-13 7.2074792e-05 1.7525974e-12 1.4443689e-05], sampled 0.16329268588381662
[2019-03-24 04:54:49,075] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8200.5245 2325685859.7161 563.0000
[2019-03-24 04:54:49,122] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8220.1863 2307186337.3150 411.0000
[2019-03-24 04:54:49,347] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8107.1011 2381015460.9919 462.0000
[2019-03-24 04:54:49,511] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8350.2227 2262513883.3387 429.0000
[2019-03-24 04:54:49,775] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7560.9736 2578547564.7051 636.0000
[2019-03-24 04:54:50,794] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 2050000, evaluation results [2050000.0, 7560.97362373173, 2578547564.7051187, 636.0, 8220.186292911405, 2307186337.3150005, 411.0, 8350.222738721883, 2262513883.3387284, 429.0, 8107.101078739785, 2381015460.991929, 462.0, 8200.524524437174, 2325685859.7161436, 563.0]
[2019-03-24 04:54:54,869] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9999952e-01 5.1609711e-14 5.1241824e-07 9.2653539e-14 6.2392194e-09], sum to 1.0000
[2019-03-24 04:54:54,874] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7139
[2019-03-24 04:54:54,882] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 804301.5199403481 W.
[2019-03-24 04:54:54,889] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.35, 90.16666666666667, 1.0, 2.0, 0.3516286895986757, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5599110361030866, 6.911199999999999, 6.9112, 121.9260426156618, 804301.5199403481, 804301.5199403486, 209598.5169022138], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5371800.0000, 
sim time next is 5372400.0000, 
raw observation next is [24.3, 90.33333333333334, 1.0, 2.0, 0.3362748872187454, 1.0, 1.0, 0.3362748872187454, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 768628.31574803, 768628.3157480304, 189497.7876389055], 
processed observation next is [1.0, 0.17391304347826086, 0.4555555555555556, 0.9033333333333334, 1.0, 1.0, 0.20985105621279213, 1.0, 0.5, 0.20985105621279213, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27451011276715354, 0.2745101127671537, 0.36441882238251055], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4273372], dtype=float32), -0.27744913]. 
=============================================
[2019-03-24 04:55:09,865] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.4145690e-01 1.6716240e-16 3.5852617e-01 4.2234009e-17 1.7009790e-05], sum to 1.0000
[2019-03-24 04:55:09,873] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6405
[2019-03-24 04:55:09,879] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 853049.328170646 W.
[2019-03-24 04:55:09,882] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.23333333333333, 76.0, 1.0, 2.0, 0.3742238282394281, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5957765221763933, 6.911199999999999, 6.9112, 121.9260426156618, 853049.328170646, 853049.3281706463, 216284.1477320869], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5683200.0000, 
sim time next is 5683800.0000, 
raw observation next is [29.06666666666666, 77.0, 1.0, 2.0, 0.2498713574011004, 1.0, 1.0, 0.2498713574011004, 1.0, 2.0, 0.3978033387245371, 6.9112, 6.9112, 121.94756008, 854379.4169882262, 854379.4169882262, 237579.8351569947], 
processed observation next is [0.0, 0.782608695652174, 0.6320987654320985, 0.77, 1.0, 1.0, 0.10698971119178619, 1.0, 0.5, 0.10698971119178619, 1.0, 1.0, 0.24725417340567135, 0.0, 0.0, 0.8096049824067558, 0.30513550606722367, 0.30513550606722367, 0.45688429837883593], 
reward next is 0.5431, 
noisyNet noise sample is [array([0.20723508], dtype=float32), -0.50776714]. 
=============================================
[2019-03-24 04:55:12,395] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 2.0098924e-24 4.0391076e-13 3.1711794e-20 1.6602774e-15], sum to 1.0000
[2019-03-24 04:55:12,396] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.1136092e-01 1.2953679e-17 8.8638917e-02 7.1084462e-15 1.0933664e-07], sum to 1.0000
[2019-03-24 04:55:12,405] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7899
[2019-03-24 04:55:12,408] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1282
[2019-03-24 04:55:12,408] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.3, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8091655354718458, 6.9112, 6.9112, 121.9260426156618, 599644.6440619748, 599644.6440619748, 162085.1529338203], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5750400.0000, 
sim time next is 5751000.0000, 
raw observation next is [27.45, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8184639254617377, 6.9112, 6.9112, 121.9260426156618, 605735.2338581937, 605735.2338581937, 163567.6034324251], 
processed observation next is [0.0, 0.5652173913043478, 0.5722222222222222, 0.62, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7730799068271721, 0.0, 0.0, 0.8094621288201359, 0.21633401209221204, 0.21633401209221204, 0.31455308352389444], 
reward next is 0.6854, 
noisyNet noise sample is [array([0.9205492], dtype=float32), 1.0096471]. 
=============================================
[2019-03-24 04:55:12,416] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 875863.5334206017 W.
[2019-03-24 04:55:12,419] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.06666666666667, 84.66666666666667, 1.0, 2.0, 0.7684529323925002, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 875863.5334206017, 875863.5334206017, 189513.5395886014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5687400.0000, 
sim time next is 5688000.0000, 
raw observation next is [27.9, 86.0, 1.0, 2.0, 0.7705270076400373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 878228.8672410258, 878228.8672410258, 189931.3043768], 
processed observation next is [0.0, 0.8695652173913043, 0.5888888888888888, 0.86, 1.0, 1.0, 0.7268178662381397, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3136531668717949, 0.3136531668717949, 0.3652525084169231], 
reward next is 0.6347, 
noisyNet noise sample is [array([-0.59557134], dtype=float32), 0.7887088]. 
=============================================
[2019-03-24 04:55:12,427] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[57.868576]
 [57.947685]
 [58.037514]
 [58.09426 ]
 [58.139534]], R is [[57.90159607]
 [58.01087952]
 [58.12180328]
 [58.23394012]
 [58.3463707 ]].
[2019-03-24 04:55:12,433] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[58.59369 ]
 [58.609966]
 [58.85473 ]
 [58.42432 ]
 [58.88618 ]], R is [[59.22312164]
 [58.63088989]
 [58.58422089]
 [57.99837875]
 [58.05877304]].
[2019-03-24 04:55:20,546] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 9.5742084e-27 1.9395288e-15 3.2855005e-28 7.9379999e-18], sum to 1.0000
[2019-03-24 04:55:20,554] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0911
[2019-03-24 04:55:20,558] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.6, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5846582013413517, 6.911200000000001, 6.9112, 121.9260426156618, 431777.2474732111, 431777.2474732107, 127585.0974123476], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5886000.0000, 
sim time next is 5886600.0000, 
raw observation next is [19.55, 85.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8307023933526975, 6.9112, 6.9112, 121.9260426156618, 613202.2677670219, 613202.2677670219, 152319.1931580804], 
processed observation next is [1.0, 0.13043478260869565, 0.2796296296296297, 0.8500000000000001, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7883779916908717, 0.0, 0.0, 0.8094621288201359, 0.21900080991679355, 0.21900080991679355, 0.2929215253040008], 
reward next is 0.7071, 
noisyNet noise sample is [array([-0.93743455], dtype=float32), 0.56306344]. 
=============================================
[2019-03-24 04:55:21,768] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.5367977e-30 1.1723474e-15 9.9598734e-31 1.1508990e-18], sum to 1.0000
[2019-03-24 04:55:21,774] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4381
[2019-03-24 04:55:21,777] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6862329765306366, 6.9112, 6.9112, 121.9260426156618, 512707.8581950254, 512707.8581950254, 142580.071747713], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5868000.0000, 
sim time next is 5868600.0000, 
raw observation next is [22.81666666666667, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6834545776004396, 6.9112, 6.9112, 121.9260426156618, 510604.2328041508, 510604.2328041508, 142192.4312259123], 
processed observation next is [1.0, 0.9565217391304348, 0.4006172839506174, 0.75, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6043182220005494, 0.0, 0.0, 0.8094621288201359, 0.182358654572911, 0.182358654572911, 0.2734469831267544], 
reward next is 0.7266, 
noisyNet noise sample is [array([-0.9144441], dtype=float32), -0.36564463]. 
=============================================
[2019-03-24 04:55:23,543] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.6397140e-23 2.9533246e-15 1.0925220e-24 2.2296520e-15], sum to 1.0000
[2019-03-24 04:55:23,553] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0943
[2019-03-24 04:55:23,561] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.91666666666667, 73.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6797692129584246, 6.911199999999999, 6.9112, 121.9260426156618, 505409.3781613044, 505409.3781613049, 138802.4410895591], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5903400.0000, 
sim time next is 5904000.0000, 
raw observation next is [22.1, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6447250940816278, 6.911199999999999, 6.9112, 121.9260426156618, 479625.7139215425, 479625.7139215429, 135503.9449044722], 
processed observation next is [1.0, 0.34782608695652173, 0.3740740740740741, 0.73, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5559063676020347, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17129489782912233, 0.17129489782912247, 0.2605845094316773], 
reward next is 0.7394, 
noisyNet noise sample is [array([-0.61076766], dtype=float32), 1.6905141]. 
=============================================
[2019-03-24 04:55:23,575] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[55.615635]
 [55.792194]
 [56.014404]
 [56.087933]
 [56.139984]], R is [[55.96278381]
 [56.13622665]
 [56.31200409]
 [56.49308777]
 [56.67380142]].
[2019-03-24 04:55:29,040] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 6.8387507e-27 3.1030036e-14 8.7779570e-25 1.8029912e-15], sum to 1.0000
[2019-03-24 04:55:29,047] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6029
[2019-03-24 04:55:29,058] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1572477.304785754 W.
[2019-03-24 04:55:29,061] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 58.0, 1.0, 2.0, 0.4596706041288094, 1.0, 1.0, 0.4596706041288094, 1.0, 2.0, 0.7318105721995012, 6.911200000000001, 6.9112, 121.94756008, 1572477.304785754, 1572477.304785754, 324206.6680840074], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6015600.0000, 
sim time next is 6016200.0000, 
raw observation next is [29.0, 58.0, 1.0, 2.0, 0.4816310388452543, 1.0, 2.0, 0.4816310388452543, 1.0, 2.0, 0.7667722994695093, 6.9112, 6.9112, 121.94756008, 1647672.011953374, 1647672.011953374, 334664.8476223213], 
processed observation next is [1.0, 0.6521739130434783, 0.6296296296296297, 0.58, 1.0, 1.0, 0.38289409386339807, 1.0, 1.0, 0.38289409386339807, 1.0, 1.0, 0.7084653743368865, 0.0, 0.0, 0.8096049824067558, 0.5884542899833478, 0.5884542899833478, 0.643586245427541], 
reward next is 0.3564, 
noisyNet noise sample is [array([-0.28609902], dtype=float32), 0.53798985]. 
=============================================
[2019-03-24 04:55:32,876] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 6.3103511e-27 1.0101371e-15 6.7353685e-28 1.0544306e-16], sum to 1.0000
[2019-03-24 04:55:32,884] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1531
[2019-03-24 04:55:32,889] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.9, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8722238447240807, 6.911200000000001, 6.9112, 121.9260426156618, 641488.626393677, 641488.6263936765, 171572.2640964715], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6123600.0000, 
sim time next is 6124200.0000, 
raw observation next is [26.81666666666667, 68.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8700090613801528, 6.9112, 6.9112, 121.9260426156618, 640059.2006199067, 640059.2006199067, 171234.4385910489], 
processed observation next is [1.0, 0.9130434782608695, 0.5487654320987656, 0.6833333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.837511326725191, 0.0, 0.0, 0.8094621288201359, 0.22859257164996666, 0.22859257164996666, 0.3292969972904787], 
reward next is 0.6707, 
noisyNet noise sample is [array([1.2663947], dtype=float32), -0.73073137]. 
=============================================
[2019-03-24 04:55:33,915] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.1428800e-19 8.1555582e-11 7.3710478e-20 4.2185175e-11], sum to 1.0000
[2019-03-24 04:55:33,923] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7411
[2019-03-24 04:55:33,931] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2005889.32036289 W.
[2019-03-24 04:55:33,936] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.43333333333333, 52.66666666666667, 1.0, 2.0, 0.8793360121313498, 1.0, 2.0, 0.8793360121313498, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2005889.32036289, 2005889.32036289, 377626.3944819218], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6101400.0000, 
sim time next is 6102000.0000, 
raw observation next is [30.4, 53.0, 1.0, 2.0, 0.5932096070056854, 1.0, 2.0, 0.5932096070056854, 1.0, 1.0, 0.9444090138411876, 6.9112, 6.9112, 121.94756008, 2029818.781703102, 2029818.781703102, 391688.2515103111], 
processed observation next is [1.0, 0.6521739130434783, 0.6814814814814815, 0.53, 1.0, 1.0, 0.515725722625816, 1.0, 1.0, 0.515725722625816, 1.0, 0.5, 0.9305112673014845, 0.0, 0.0, 0.8096049824067558, 0.7249352791796793, 0.7249352791796793, 0.753246637519829], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.0831294], dtype=float32), 0.5464982]. 
=============================================
[2019-03-24 04:55:33,956] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[51.531628]
 [51.08211 ]
 [51.334934]
 [51.127186]
 [50.70905 ]], R is [[51.03827667]
 [50.52789307]
 [50.27672195]
 [50.04603577]
 [49.54557419]].
[2019-03-24 04:55:36,145] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.7632428e-19 8.8612048e-11 1.8858844e-20 2.7785901e-12], sum to 1.0000
[2019-03-24 04:55:36,151] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0539
[2019-03-24 04:55:36,157] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 806847.8852928383 W.
[2019-03-24 04:55:36,161] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.26666666666667, 89.83333333333333, 1.0, 2.0, 0.3438933930393634, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5500254607037518, 6.9112, 6.9112, 121.9260426156617, 806847.8852928383, 806847.8852928383, 206850.1497609813], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6144600.0000, 
sim time next is 6145200.0000, 
raw observation next is [23.2, 90.0, 1.0, 2.0, 0.3514979206930173, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5621459260921927, 6.911199999999999, 6.9112, 121.9260426156618, 824485.5618987245, 824485.561898725, 209038.7622326642], 
processed observation next is [1.0, 0.13043478260869565, 0.4148148148148148, 0.9, 1.0, 1.0, 0.22797371511073486, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45268240761524087, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2944591292495445, 0.29445912924954465, 0.40199761967820036], 
reward next is 0.5980, 
noisyNet noise sample is [array([-1.5750269], dtype=float32), 1.5582078]. 
=============================================
[2019-03-24 04:55:40,692] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 04:55:40,693] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:55:40,694] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:55:40,695] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:55:40,698] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:55:40,702] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:55:40,703] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:55:40,705] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:55:40,706] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:55:40,707] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:55:40,707] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:55:40,727] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run84
[2019-03-24 04:55:40,751] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run84
[2019-03-24 04:55:40,752] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run84
[2019-03-24 04:55:40,807] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run84
[2019-03-24 04:55:40,840] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run84
[2019-03-24 04:55:45,164] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.44204184]
[2019-03-24 04:55:45,165] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.35, 29.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5621749309989054, 6.911199999999999, 6.9112, 121.9260426156618, 401409.9629100203, 401409.9629100208, 112707.187792167]
[2019-03-24 04:55:45,166] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:55:45,168] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.6659766e-25 5.9931088e-17 9.8482993e-25 3.1820315e-16], sampled 0.6731155313895268
[2019-03-24 04:55:48,349] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.44204184]
[2019-03-24 04:55:48,351] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.05, 32.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7618682727854625, 6.9112, 6.9112, 121.9260426156618, 561498.5849219102, 561498.5849219102, 144390.6060150588]
[2019-03-24 04:55:48,354] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:55:48,356] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.4998316e-24 1.9194268e-16 5.3593964e-24 9.5627648e-16], sampled 0.6931244396715233
[2019-03-24 04:55:51,561] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.44204184]
[2019-03-24 04:55:51,563] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.43333333333334, 60.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6587615272290042, 6.911199999999999, 6.9112, 121.9260426156618, 491177.7974385223, 491177.7974385227, 137974.6692688449]
[2019-03-24 04:55:51,563] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:55:51,568] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.2677139e-26 8.3008840e-18 4.9866292e-26 4.7673082e-17], sampled 0.37969327943763964
[2019-03-24 04:55:57,365] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.44204184]
[2019-03-24 04:55:57,365] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.636495845, 68.71817578166666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.732984175637309, 6.911200000000001, 6.9112, 121.9260426156618, 547413.3741147133, 547413.3741147128, 149772.82156597]
[2019-03-24 04:55:57,367] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:55:57,369] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.4778682e-27 3.4448083e-18 1.4037507e-26 2.0849163e-17], sampled 0.8050737793843072
[2019-03-24 04:56:06,863] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.44204184]
[2019-03-24 04:56:06,866] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.021977735, 83.80732797499999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7850423543701215, 6.9112, 6.9112, 121.9260426156618, 581724.7083917741, 581724.7083917741, 159084.6292995472]
[2019-03-24 04:56:06,867] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:56:06,869] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.1004585e-25 5.8318331e-17 7.8366083e-25 2.9449980e-16], sampled 0.9043967664786271
[2019-03-24 04:56:40,939] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.44204184]
[2019-03-24 04:56:40,940] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.06666666666667, 91.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9220313579167114, 6.9112, 6.9112, 121.9260426156618, 672625.6280909295, 672625.6280909295, 179308.7919581498]
[2019-03-24 04:56:40,940] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:56:40,943] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.000000e+00 2.448006e-25 5.772317e-17 9.072817e-25 3.047560e-16], sampled 0.8241460181468848
[2019-03-24 04:57:08,079] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.44204184]
[2019-03-24 04:57:08,080] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.751349355, 72.27742727500001, 1.0, 2.0, 0.6731373510712968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 767327.5774306224, 767327.5774306224, 171125.1744292558]
[2019-03-24 04:57:08,082] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:57:08,085] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.0233976e-21 4.8808905e-14 9.5170320e-21 1.5666019e-13], sampled 0.44978952186293275
[2019-03-24 04:57:08,086] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 767327.5774306224 W.
[2019-03-24 04:57:24,306] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.44204184]
[2019-03-24 04:57:24,307] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.619145995, 88.76407488999999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6270651369918555, 6.911200000000001, 6.9112, 121.9260426156618, 467931.9085730459, 467931.9085730455, 135279.1838697873]
[2019-03-24 04:57:24,308] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:57:24,313] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.2246872e-24 1.7875812e-16 4.4097971e-24 8.7265813e-16], sampled 0.7115081573611097
[2019-03-24 04:57:27,587] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 04:57:27,654] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 04:57:27,883] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 04:57:27,895] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 04:57:27,962] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 04:57:28,982] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2075000, evaluation results [2075000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 04:57:37,456] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.9995994e-16 5.5052096e-10 5.5212212e-15 3.5321600e-11], sum to 1.0000
[2019-03-24 04:57:37,467] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5819
[2019-03-24 04:57:37,476] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1780821.137860456 W.
[2019-03-24 04:57:37,484] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.13333333333333, 87.66666666666666, 1.0, 2.0, 0.520513113602608, 1.0, 2.0, 0.520513113602608, 1.0, 1.0, 0.8286738287839863, 6.9112, 6.9112, 121.94756008, 1780821.137860456, 1780821.137860456, 353771.1985144681], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6424800.0000, 
sim time next is 6425400.0000, 
raw observation next is [26.36666666666667, 86.83333333333333, 1.0, 2.0, 0.960080510526946, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1809669.795060259, 1809669.795060259, 370255.9604555566], 
processed observation next is [1.0, 0.34782608695652173, 0.5320987654320989, 0.8683333333333333, 1.0, 1.0, 0.9524767982463642, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6463106410929497, 0.6463106410929497, 0.7120306931837627], 
reward next is 0.2880, 
noisyNet noise sample is [array([-0.70564], dtype=float32), -0.4616017]. 
=============================================
[2019-03-24 04:57:44,358] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999380e-01 4.8699760e-12 6.1545602e-06 7.0028011e-10 1.7567112e-08], sum to 1.0000
[2019-03-24 04:57:44,363] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2107
[2019-03-24 04:57:44,371] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1704061.576488586 W.
[2019-03-24 04:57:44,374] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.56666666666667, 87.66666666666667, 1.0, 2.0, 0.7471477301377553, 1.0, 1.0, 0.7471477301377553, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1704061.576488586, 1704061.576488586, 322399.241388933], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6510000.0000, 
sim time next is 6510600.0000, 
raw observation next is [26.7, 87.0, 1.0, 2.0, 0.8017670074960469, 1.0, 2.0, 0.8017670074960469, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1828762.333020353, 1828762.333020354, 344485.4142075301], 
processed observation next is [1.0, 0.34782608695652173, 0.5444444444444444, 0.87, 1.0, 1.0, 0.7640083422571987, 1.0, 1.0, 0.7640083422571987, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.653129404650126, 0.6531294046501264, 0.6624719503990963], 
reward next is 0.3375, 
noisyNet noise sample is [array([1.1632366], dtype=float32), -0.8184856]. 
=============================================
[2019-03-24 04:57:49,605] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.2208388e-32 2.4910167e-19 2.6499412e-29 6.0712047e-25], sum to 1.0000
[2019-03-24 04:57:49,613] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9547
[2019-03-24 04:57:49,621] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.71666666666667, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6013263526711232, 6.9112, 6.9112, 121.9260426156618, 447703.3370479865, 447703.3370479865, 131598.7468924864], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6631800.0000, 
sim time next is 6632400.0000, 
raw observation next is [27.43333333333333, 44.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.603349213120541, 6.9112, 6.9112, 121.9260426156618, 449124.5917373399, 449124.5917373399, 131715.7330073165], 
processed observation next is [1.0, 0.782608695652174, 0.5716049382716049, 0.44, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5041865164006762, 0.0, 0.0, 0.8094621288201359, 0.16040163990619283, 0.16040163990619283, 0.25329948655253176], 
reward next is 0.7467, 
noisyNet noise sample is [array([1.317527], dtype=float32), 1.9133364]. 
=============================================
[2019-03-24 04:57:50,056] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 6.9176096e-38 3.1619428e-25 5.9066993e-33 1.9674633e-25], sum to 1.0000
[2019-03-24 04:57:50,062] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8630
[2019-03-24 04:57:50,072] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.91666666666666, 44.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5444451973731181, 6.911200000000001, 6.9112, 121.9260426156618, 396810.9487557707, 396810.9487557703, 121494.8445426135], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6646200.0000, 
sim time next is 6646800.0000, 
raw observation next is [24.93333333333333, 43.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5338525306899464, 6.9112, 6.9112, 121.9260426156618, 387655.9611142322, 387655.9611142322, 120034.7311700924], 
processed observation next is [1.0, 0.9565217391304348, 0.47901234567901224, 0.4333333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.417315663362433, 0.0, 0.0, 0.8094621288201359, 0.1384485575407972, 0.1384485575407972, 0.23083602148094692], 
reward next is 0.7692, 
noisyNet noise sample is [array([1.9845549], dtype=float32), 0.03784214]. 
=============================================
[2019-03-24 04:57:58,270] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 3.4409119e-38 1.3089843e-25 0.0000000e+00 9.8822246e-29], sum to 1.0000
[2019-03-24 04:57:58,275] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7738
[2019-03-24 04:57:58,281] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.2, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7427183308009507, 6.9112, 6.9112, 121.9260426156618, 554464.4054307624, 554464.4054307624, 151239.7612594321], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6825600.0000, 
sim time next is 6826200.0000, 
raw observation next is [23.13333333333333, 78.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7359152716475851, 6.911200000000001, 6.9112, 121.9260426156618, 549543.1303478285, 549543.130347828, 150212.6610534624], 
processed observation next is [0.0, 0.0, 0.41234567901234553, 0.7883333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6698940895594813, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19626540369565304, 0.19626540369565287, 0.2888705020258892], 
reward next is 0.7111, 
noisyNet noise sample is [array([-1.0848688], dtype=float32), 0.2784662]. 
=============================================
[2019-03-24 04:57:58,951] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.0111324e-34 6.9185106e-22 9.6869680e-32 5.1225428e-24], sum to 1.0000
[2019-03-24 04:57:58,959] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2676
[2019-03-24 04:57:58,962] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.95, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6384168525720868, 6.911200000000001, 6.9112, 121.9260426156618, 475824.014885585, 475824.0148855845, 135714.6797771487], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6839400.0000, 
sim time next is 6840000.0000, 
raw observation next is [21.9, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6355251634859849, 6.911200000000001, 6.9112, 121.9260426156618, 473546.7754980454, 473546.7754980449, 135298.8453200819], 
processed observation next is [0.0, 0.17391304347826086, 0.36666666666666664, 0.76, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.544406454357481, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16912384839215908, 0.1691238483921589, 0.26019008715400366], 
reward next is 0.7398, 
noisyNet noise sample is [array([-0.1209117], dtype=float32), -0.24991773]. 
=============================================
[2019-03-24 04:57:58,981] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[67.90801]
 [68.07005]
 [68.2449 ]
 [68.26059]
 [68.41408]], R is [[67.68968201]
 [67.75180054]
 [67.81243896]
 [67.87150574]
 [67.9289093 ]].
[2019-03-24 04:58:16,319] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 3.8545237e-29 1.2189396e-18 9.6344992e-30 2.9568792e-20], sum to 1.0000
[2019-03-24 04:58:16,333] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5837
[2019-03-24 04:58:16,340] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 954031.2337601389 W.
[2019-03-24 04:58:16,343] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 75.0, 1.0, 2.0, 0.3909797542040235, 1.0, 1.0, 0.3909797542040235, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 954031.2337601389, 954031.2337601393, 206236.6055226052], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7124400.0000, 
sim time next is 7125000.0000, 
raw observation next is [22.68333333333334, 74.16666666666667, 1.0, 2.0, 0.7471562073003185, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 920084.1072376732, 920084.1072376732, 188087.9621353741], 
processed observation next is [1.0, 0.4782608695652174, 0.39567901234567926, 0.7416666666666667, 1.0, 1.0, 0.6989954848813316, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3286014668705976, 0.3286014668705976, 0.3617076194911041], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.06875679], dtype=float32), -0.8021646]. 
=============================================
[2019-03-24 04:58:16,359] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[67.25603 ]
 [67.46562 ]
 [66.47326 ]
 [66.633804]
 [66.35481 ]], R is [[67.30088806]
 [67.23126984]
 [67.18954468]
 [67.15445709]
 [67.03669739]].
[2019-03-24 04:58:17,012] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.0007350e-33 1.1285620e-24 1.8568254e-33 3.0634910e-25], sum to 1.0000
[2019-03-24 04:58:17,021] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8266
[2019-03-24 04:58:17,025] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.68333333333333, 92.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6900014539892436, 6.911200000000001, 6.9112, 121.9260426156618, 513956.2273574842, 513956.2273574837, 140666.5391298032], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7186200.0000, 
sim time next is 7186800.0000, 
raw observation next is [19.66666666666667, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6564337706556401, 6.9112, 6.9112, 121.9260426156618, 488842.5039301991, 488842.5039301991, 137119.8045373621], 
processed observation next is [1.0, 0.17391304347826086, 0.28395061728395077, 0.9266666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5705422133195501, 0.0, 0.0, 0.8094621288201359, 0.17458660854649968, 0.17458660854649968, 0.2636919318026194], 
reward next is 0.7363, 
noisyNet noise sample is [array([-0.7344043], dtype=float32), 0.36962286]. 
=============================================
[2019-03-24 04:58:17,759] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 5.2244118e-32 5.9252862e-21 8.0384141e-31 8.2664466e-24], sum to 1.0000
[2019-03-24 04:58:17,765] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7248
[2019-03-24 04:58:17,769] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.3, 95.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6206951905942617, 6.911200000000001, 6.9112, 121.9260426156618, 462014.0378903494, 462014.0378903489, 133373.5922479874], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7443600.0000, 
sim time next is 7444200.0000, 
raw observation next is [19.25, 95.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.617569597837151, 6.9112, 6.9112, 121.9260426156618, 459649.9860126651, 459649.9860126651, 133036.0019716331], 
processed observation next is [0.0, 0.13043478260869565, 0.26851851851851855, 0.9566666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5219619972964388, 0.0, 0.0, 0.8094621288201359, 0.16416070929023754, 0.16416070929023754, 0.2558384653300636], 
reward next is 0.7442, 
noisyNet noise sample is [array([0.45149454], dtype=float32), 0.50418764]. 
=============================================
[2019-03-24 04:58:18,748] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 04:58:18,752] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:58:18,753] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:58:18,754] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:58:18,755] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:58:18,756] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:58:18,756] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:58:18,757] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:58:18,757] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:58:18,759] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:58:18,757] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:58:18,778] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run85
[2019-03-24 04:58:18,802] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run85
[2019-03-24 04:58:18,826] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run85
[2019-03-24 04:58:18,851] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run85
[2019-03-24 04:58:18,875] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run85
[2019-03-24 04:58:21,675] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.44557434]
[2019-03-24 04:58:21,676] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.4, 44.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4903180344482077, 6.9112, 6.9112, 121.9260426156618, 350090.2468778399, 350090.2468778399, 94733.0613280488]
[2019-03-24 04:58:21,677] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:58:21,680] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.1303231e-33 5.7289119e-22 1.3889272e-33 2.3948126e-25], sampled 0.8761395311954837
[2019-03-24 04:58:59,027] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.44557434]
[2019-03-24 04:58:59,031] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.94945259333334, 92.99273190666668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.881793114291244, 6.9112, 6.9112, 121.9260426156618, 643120.2389878972, 643120.2389878972, 173960.5667362298]
[2019-03-24 04:58:59,031] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:58:59,034] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 9.2286724e-33 1.5614496e-21 6.1184701e-33 7.4120547e-25], sampled 0.7808965884155036
[2019-03-24 05:00:06,070] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 05:00:06,268] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:00:06,467] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:00:06,571] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:00:06,707] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 05:00:07,724] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2100000, evaluation results [2100000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:00:13,027] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.1567128e-30 3.0319259e-18 2.4481200e-31 3.3965365e-21], sum to 1.0000
[2019-03-24 05:00:13,033] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3176
[2019-03-24 05:00:13,038] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.66666666666667, 67.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8928227809572105, 6.9112, 6.9112, 121.9260426156618, 651426.3207557818, 651426.3207557818, 175372.9818776219], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7563000.0000, 
sim time next is 7563600.0000, 
raw observation next is [28.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8998410542954765, 6.9112, 6.9112, 121.9260426156618, 655585.9463034628, 655585.9463034628, 176474.5224337741], 
processed observation next is [0.0, 0.5652173913043478, 0.5925925925925926, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8748013178693456, 0.0, 0.0, 0.8094621288201359, 0.23413783796552246, 0.23413783796552246, 0.33937408160341176], 
reward next is 0.6606, 
noisyNet noise sample is [array([-0.22387719], dtype=float32), -0.7773718]. 
=============================================
[2019-03-24 05:00:15,497] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.4507630e-32 5.2468272e-22 5.3033072e-31 2.5772972e-26], sum to 1.0000
[2019-03-24 05:00:15,508] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3513
[2019-03-24 05:00:15,513] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.65, 84.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6918348055565564, 6.911199999999999, 6.9112, 121.9260426156618, 516955.5983200212, 516955.5983200216, 143440.8833741405], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7338600.0000, 
sim time next is 7339200.0000, 
raw observation next is [21.5, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6885699831457974, 6.911200000000001, 6.9112, 121.9260426156618, 514493.2218141972, 514493.2218141967, 142982.2213020011], 
processed observation next is [1.0, 0.9565217391304348, 0.35185185185185186, 0.8533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6107124789322468, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18374757921935614, 0.18374757921935594, 0.27496581019615596], 
reward next is 0.7250, 
noisyNet noise sample is [array([0.26216337], dtype=float32), 1.0673176]. 
=============================================
[2019-03-24 05:00:17,254] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 8.7139164e-29 3.3762181e-20 1.0767406e-26 2.5203680e-21], sum to 1.0000
[2019-03-24 05:00:17,258] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1196
[2019-03-24 05:00:17,265] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.03333333333333, 95.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6397078803571324, 6.911199999999999, 6.9112, 121.9260426156618, 475246.9749346633, 475246.9749346637, 134496.9500115598], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7372200.0000, 
sim time next is 7372800.0000, 
raw observation next is [19.0, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6256951699958047, 6.911200000000001, 6.9112, 121.9260426156618, 464637.1863132103, 464637.1863132098, 132984.3353158335], 
processed observation next is [1.0, 0.34782608695652173, 0.25925925925925924, 0.95, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5321189624947558, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16594185225471797, 0.1659418522547178, 0.2557391063766029], 
reward next is 0.7443, 
noisyNet noise sample is [array([-0.9050784], dtype=float32), 1.6144358]. 
=============================================
[2019-03-24 05:00:23,014] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.3610639e-29 7.6520018e-19 1.6177523e-29 5.4617301e-22], sum to 1.0000
[2019-03-24 05:00:23,022] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0525
[2019-03-24 05:00:23,028] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.55, 80.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7490788932292146, 6.911199999999999, 6.9112, 121.9260426156618, 558002.1709230404, 558002.1709230408, 153155.9842953745], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7471800.0000, 
sim time next is 7472400.0000, 
raw observation next is [23.66666666666666, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7537517657660323, 6.911199999999999, 6.9112, 121.9260426156618, 561337.090874533, 561337.0908745335, 153814.3782637489], 
processed observation next is [0.0, 0.4782608695652174, 0.4320987654320985, 0.8, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6921897072075403, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20047753245519037, 0.20047753245519054, 0.29579688127644016], 
reward next is 0.7042, 
noisyNet noise sample is [array([0.5238173], dtype=float32), 0.06177925]. 
=============================================
[2019-03-24 05:00:25,212] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.9959790e-24 5.6729523e-16 8.8144320e-25 2.7081449e-18], sum to 1.0000
[2019-03-24 05:00:25,219] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7030
[2019-03-24 05:00:25,224] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.2, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.591711501821222, 6.9112, 6.9112, 121.9260426156618, 434800.6448680778, 434800.6448680778, 127099.4939168156], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7786800.0000, 
sim time next is 7787400.0000, 
raw observation next is [21.25, 69.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6857913769676152, 6.9112, 6.9112, 121.9260426156618, 503782.1853691591, 503782.1853691591, 135833.9054751417], 
processed observation next is [1.0, 0.13043478260869565, 0.3425925925925926, 0.695, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6072392212095189, 0.0, 0.0, 0.8094621288201359, 0.17992220906041395, 0.17992220906041395, 0.2612190489906571], 
reward next is 0.7388, 
noisyNet noise sample is [array([1.1342297], dtype=float32), -0.74609464]. 
=============================================
[2019-03-24 05:00:25,678] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.0033682e-34 2.0972101e-23 5.0714563e-35 4.2317698e-28], sum to 1.0000
[2019-03-24 05:00:25,684] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0579
[2019-03-24 05:00:25,694] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.4, 95.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7464332889156704, 6.911199999999999, 6.9112, 121.9260426156618, 556593.9676071298, 556593.9676071302, 152385.0507453114], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7518000.0000, 
sim time next is 7518600.0000, 
raw observation next is [21.35, 95.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7452432128242145, 6.911199999999999, 6.9112, 121.9260426156618, 555786.3449624237, 555786.3449624241, 152171.0049191586], 
processed observation next is [0.0, 0.0, 0.3462962962962963, 0.955, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.681554016030268, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1984951232008656, 0.19849512320086576, 0.2926365479214588], 
reward next is 0.7074, 
noisyNet noise sample is [array([0.06545365], dtype=float32), -1.8462954]. 
=============================================
[2019-03-24 05:00:29,893] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.6970380e-25 7.7824244e-16 1.4112696e-23 6.8333551e-19], sum to 1.0000
[2019-03-24 05:00:29,900] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1877
[2019-03-24 05:00:29,903] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.33333333333334, 89.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8583353492389058, 6.911200000000001, 6.9112, 121.9260426156618, 641474.1763295034, 641474.176329503, 163260.8828924132], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7633200.0000, 
sim time next is 7633800.0000, 
raw observation next is [21.6, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9500649821064509, 6.911199999999999, 6.9112, 121.9259763201688, 709988.4960805586, 709988.4960805591, 175208.1782392178], 
processed observation next is [1.0, 0.34782608695652173, 0.3555555555555556, 0.885, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9375812276330636, -8.881784197001253e-17, 0.0, 0.8094616886870049, 0.2535673200287709, 0.2535673200287711, 0.3369388043061881], 
reward next is 0.6631, 
noisyNet noise sample is [array([0.8484253], dtype=float32), -1.5495706]. 
=============================================
[2019-03-24 05:00:32,614] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.7313912e-21 7.7610210e-12 1.3121766e-21 3.9170441e-15], sum to 1.0000
[2019-03-24 05:00:32,623] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4558
[2019-03-24 05:00:32,633] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 805699.2022739911 W.
[2019-03-24 05:00:32,637] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.86666666666667, 87.66666666666666, 1.0, 1.0, 0.3341799206194862, 1.0, 1.0, 0.3341799206194862, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 805699.2022739911, 805699.2022739915, 190729.6021275531], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7634400.0000, 
sim time next is 7635000.0000, 
raw observation next is [22.13333333333333, 86.83333333333333, 1.0, 2.0, 0.3621129634314211, 1.0, 2.0, 0.3621129634314211, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 868656.0216116167, 868656.0216116172, 197882.4171994184], 
processed observation next is [1.0, 0.34782608695652173, 0.3753086419753085, 0.8683333333333333, 1.0, 1.0, 0.24061067075169176, 1.0, 1.0, 0.24061067075169176, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31023429343272024, 0.3102342934327204, 0.3805431099988816], 
reward next is 0.6195, 
noisyNet noise sample is [array([0.88815916], dtype=float32), 0.70967025]. 
=============================================
[2019-03-24 05:00:32,657] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[46.804096]
 [51.747456]
 [52.102825]
 [52.461723]
 [52.47022 ]], R is [[45.82763672]
 [46.00257492]
 [46.20561218]
 [46.42959213]
 [46.67964172]].
[2019-03-24 05:00:34,941] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:00:34,943] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:34,998] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run11
[2019-03-24 05:00:36,747] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.3040818e-25 1.9919034e-15 9.1457901e-25 2.3235766e-18], sum to 1.0000
[2019-03-24 05:00:36,753] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1974
[2019-03-24 05:00:36,759] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.1, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5448702093738085, 6.9112, 6.9112, 121.9260426156618, 399717.8601995404, 399717.8601995404, 122670.9800161241], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7707600.0000, 
sim time next is 7708200.0000, 
raw observation next is [18.18333333333334, 93.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5624714540940665, 6.911200000000001, 6.9112, 121.9260426156618, 413128.4498621492, 413128.4498621487, 124421.757622745], 
processed observation next is [1.0, 0.21739130434782608, 0.22901234567901263, 0.9383333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4530893176175831, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14754587495076757, 0.14754587495076738, 0.23927261081297116], 
reward next is 0.7607, 
noisyNet noise sample is [array([0.744897], dtype=float32), 0.6284241]. 
=============================================
[2019-03-24 05:00:36,792] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2114529: loss 3.3384
[2019-03-24 05:00:36,796] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2114529: learning rate 0.0000
[2019-03-24 05:00:44,677] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.0116527e-31 4.0645852e-18 3.5972070e-25 5.6290666e-22], sum to 1.0000
[2019-03-24 05:00:44,682] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6588
[2019-03-24 05:00:44,692] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.63333333333334, 70.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6866954338961815, 6.911200000000001, 6.9112, 121.9260426156618, 513086.948197257, 513086.9481972565, 142758.2883160672], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7860000.0000, 
sim time next is 7860600.0000, 
raw observation next is [23.55, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6868895742261694, 6.911199999999999, 6.9112, 121.9260426156618, 513243.0188625465, 513243.0188625469, 142827.4999529681], 
processed observation next is [1.0, 1.0, 0.4277777777777778, 0.71, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6086119677827116, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18330107816519517, 0.1833010781651953, 0.2746682691403233], 
reward next is 0.7253, 
noisyNet noise sample is [array([-1.6305399], dtype=float32), -0.42275965]. 
=============================================
[2019-03-24 05:00:46,668] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:00:46,668] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:46,698] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run11
[2019-03-24 05:00:47,134] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:00:47,136] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:47,166] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run11
[2019-03-24 05:00:47,401] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:00:47,401] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:47,418] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run11
[2019-03-24 05:00:47,585] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:00:47,586] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:47,613] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run11
[2019-03-24 05:00:47,650] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:00:47,651] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:47,669] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run11
[2019-03-24 05:00:47,781] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:00:47,782] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:47,785] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run11
[2019-03-24 05:00:48,044] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:00:48,047] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:48,049] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:00:48,049] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:48,052] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:00:48,052] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:48,055] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run11
[2019-03-24 05:00:48,085] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run11
[2019-03-24 05:00:48,086] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run11
[2019-03-24 05:00:48,302] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2120157: loss 1.0573
[2019-03-24 05:00:48,303] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2120157: learning rate 0.0000
[2019-03-24 05:00:48,366] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:00:48,367] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:48,370] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run11
[2019-03-24 05:00:48,669] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:00:48,669] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:48,672] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run11
[2019-03-24 05:00:48,830] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2120251: loss 0.6751
[2019-03-24 05:00:48,830] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2120251: learning rate 0.0000
[2019-03-24 05:00:48,865] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:00:48,865] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:48,868] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run11
[2019-03-24 05:00:48,933] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:00:48,933] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:48,939] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run11
[2019-03-24 05:00:48,996] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:00:48,997] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:49,002] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run11
[2019-03-24 05:00:49,095] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:00:49,095] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:49,125] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run11
[2019-03-24 05:00:49,746] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2120413: loss 0.6991
[2019-03-24 05:00:49,750] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2120413: learning rate 0.0000
[2019-03-24 05:00:49,761] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2120421: loss 0.3860
[2019-03-24 05:00:49,763] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2120421: learning rate 0.0000
[2019-03-24 05:00:49,792] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2120432: loss 0.3565
[2019-03-24 05:00:49,797] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2120432: learning rate 0.0000
[2019-03-24 05:00:49,818] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2120448: loss 0.0062
[2019-03-24 05:00:49,822] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2120450: loss 0.3955
[2019-03-24 05:00:49,823] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2120448: learning rate 0.0000
[2019-03-24 05:00:49,827] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2120450: learning rate 0.0000
[2019-03-24 05:00:49,918] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2120493: loss 0.1738
[2019-03-24 05:00:49,919] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2120493: learning rate 0.0000
[2019-03-24 05:00:50,008] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2120538: loss 0.1406
[2019-03-24 05:00:50,013] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2120538: learning rate 0.0000
[2019-03-24 05:00:50,068] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2120567: loss 0.0916
[2019-03-24 05:00:50,070] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2120567: learning rate 0.0000
[2019-03-24 05:00:50,199] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2120634: loss 0.0415
[2019-03-24 05:00:50,200] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2120634: learning rate 0.0000
[2019-03-24 05:00:50,508] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2120802: loss 0.0459
[2019-03-24 05:00:50,509] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2120803: learning rate 0.0000
[2019-03-24 05:00:50,764] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2120953: loss 0.7807
[2019-03-24 05:00:50,769] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2120955: learning rate 0.0000
[2019-03-24 05:00:50,832] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2120992: loss 0.8767
[2019-03-24 05:00:50,836] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2120994: learning rate 0.0000
[2019-03-24 05:00:51,002] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2121091: loss 0.9520
[2019-03-24 05:00:51,004] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2121092: learning rate 0.0000
[2019-03-24 05:00:51,033] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2121104: loss 0.6940
[2019-03-24 05:00:51,034] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2121104: learning rate 0.0000
[2019-03-24 05:00:58,693] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 05:00:58,695] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:00:58,696] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:58,696] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:00:58,697] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:00:58,699] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:00:58,699] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:58,700] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:58,699] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:58,702] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:00:58,705] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:00:58,731] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run86
[2019-03-24 05:00:58,756] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run86
[2019-03-24 05:00:58,779] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run86
[2019-03-24 05:00:58,802] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run86
[2019-03-24 05:00:58,826] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run86
[2019-03-24 05:01:01,531] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.4513885]
[2019-03-24 05:01:01,532] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [36.94123482000001, 19.834871595, 1.0, 2.0, 0.7358196194070158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 903279.658342258, 903279.658342258, 185726.5331870111]
[2019-03-24 05:01:01,533] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:01:01,535] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.5122789e-27 2.8094722e-16 1.6448981e-27 1.6630242e-20], sampled 0.6173381042711608
[2019-03-24 05:01:01,536] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 903279.658342258 W.
[2019-03-24 05:01:02,685] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.4513885]
[2019-03-24 05:01:02,685] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [33.479199875, 22.372129205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6549368402406343, 6.9112, 6.9112, 121.9260426156618, 485098.661953505, 485098.661953505, 135008.3771412106]
[2019-03-24 05:01:02,685] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:01:02,688] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 5.4816511e-34 5.0443477e-20 5.8172295e-34 2.9514176e-25], sampled 0.698571355718141
[2019-03-24 05:01:04,938] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.4513885]
[2019-03-24 05:01:04,938] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.62219085, 45.566226625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5025798725611557, 6.911199999999999, 6.9112, 121.9260426156618, 359190.517509667, 359190.5175096675, 115429.8985030921]
[2019-03-24 05:01:04,938] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:01:04,940] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.9350872e-32 6.3557953e-19 4.2470602e-32 7.0990169e-24], sampled 0.3274182615016865
[2019-03-24 05:01:42,857] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.4513885]
[2019-03-24 05:01:42,859] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.15, 84.0, 1.0, 2.0, 0.7586567456074387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 864691.784804246, 864691.784804246, 187551.3254067154]
[2019-03-24 05:01:42,860] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:01:42,862] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.000000e+00 8.606804e-31 3.873383e-18 9.242916e-31 6.857783e-23], sampled 0.5231649145472956
[2019-03-24 05:01:42,863] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 864691.784804246 W.
[2019-03-24 05:01:50,245] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.4513885]
[2019-03-24 05:01:50,246] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 66.0, 1.0, 2.0, 0.6811847749110269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 776347.0836851933, 776347.0836851933, 172613.5860477469]
[2019-03-24 05:01:50,248] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:01:50,251] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 9.9940609e-29 7.2379819e-17 1.1094705e-28 2.4797697e-21], sampled 0.8929617471206889
[2019-03-24 05:01:50,252] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 776347.0836851933 W.
[2019-03-24 05:02:12,688] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.4513885]
[2019-03-24 05:02:12,691] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.23333333333333, 99.0, 1.0, 2.0, 0.6508492580732657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 741756.9314562513, 741756.9314562513, 167046.707106085]
[2019-03-24 05:02:12,692] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:02:12,695] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.5849373e-30 9.3027925e-18 3.8843532e-30 2.0075344e-22], sampled 0.12623238852716434
[2019-03-24 05:02:12,695] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 741756.9314562513 W.
[2019-03-24 05:02:13,519] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.4513885]
[2019-03-24 05:02:13,521] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.84999999999999, 66.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.468119799385983, 6.9112, 121.9241195382715, 2612741.919970294, 2327553.703957313, 443050.4087289652]
[2019-03-24 05:02:13,523] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:02:13,527] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 3.7915114e-28 1.1613879e-16 4.0360888e-28 5.7295921e-21], sampled 0.5451892248187407
[2019-03-24 05:02:13,528] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 2612741.919970294 W.
[2019-03-24 05:02:35,525] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.4513885]
[2019-03-24 05:02:35,526] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.69848563, 75.20643490833334, 1.0, 2.0, 0.6485293976867159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 788635.1698222639, 788635.1698222639, 168705.323736275]
[2019-03-24 05:02:35,528] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:02:35,531] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.3569434e-28 1.0892140e-16 2.5863949e-28 4.4700650e-21], sampled 0.12305109213103349
[2019-03-24 05:02:35,533] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 788635.1698222639 W.
[2019-03-24 05:02:47,059] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:02:47,173] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 05:02:47,422] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:02:47,471] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:02:47,527] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 05:02:48,545] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2125000, evaluation results [2125000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:02:53,368] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2127346: loss 0.0055
[2019-03-24 05:02:53,373] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2127347: learning rate 0.0000
[2019-03-24 05:02:54,782] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2128025: loss 0.1290
[2019-03-24 05:02:54,784] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2128025: learning rate 0.0000
[2019-03-24 05:02:55,049] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2128154: loss 0.0719
[2019-03-24 05:02:55,052] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2128155: learning rate 0.0000
[2019-03-24 05:02:55,188] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2128223: loss 0.0024
[2019-03-24 05:02:55,193] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2128224: learning rate 0.0000
[2019-03-24 05:02:55,200] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2128226: loss 0.0002
[2019-03-24 05:02:55,203] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2128227: learning rate 0.0000
[2019-03-24 05:02:55,269] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2128256: loss 0.0223
[2019-03-24 05:02:55,273] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2128256: learning rate 0.0000
[2019-03-24 05:02:55,610] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2128420: loss 0.0557
[2019-03-24 05:02:55,611] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2128420: learning rate 0.0000
[2019-03-24 05:02:55,638] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2128436: loss 0.0718
[2019-03-24 05:02:55,639] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2128436: learning rate 0.0000
[2019-03-24 05:02:55,809] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2128519: loss 0.0003
[2019-03-24 05:02:55,813] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2128520: learning rate 0.0000
[2019-03-24 05:02:55,817] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2128522: loss 0.0001
[2019-03-24 05:02:55,821] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2128522: learning rate 0.0000
[2019-03-24 05:02:56,028] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2128622: loss 1.4733
[2019-03-24 05:02:56,033] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2128622: learning rate 0.0000
[2019-03-24 05:02:56,383] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2128792: loss 0.0838
[2019-03-24 05:02:56,385] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2128792: learning rate 0.0000
[2019-03-24 05:02:56,836] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2129014: loss 0.0476
[2019-03-24 05:02:56,841] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2129016: learning rate 0.0000
[2019-03-24 05:02:56,866] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2129028: loss 0.0041
[2019-03-24 05:02:56,869] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2129029: learning rate 0.0000
[2019-03-24 05:02:57,070] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2129127: loss 0.0836
[2019-03-24 05:02:57,071] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2129127: learning rate 0.0000
[2019-03-24 05:02:57,095] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2129137: loss 0.0310
[2019-03-24 05:02:57,099] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2129139: learning rate 0.0000
[2019-03-24 05:03:07,787] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.6465139e-24 1.5110981e-14 7.2611269e-25 3.0156158e-18], sum to 1.0000
[2019-03-24 05:03:07,800] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9702
[2019-03-24 05:03:07,805] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.68333333333334, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6422649731234691, 6.9112, 6.9112, 121.9260426156618, 469457.7951146452, 469457.7951146452, 130615.8280671078], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 540600.0000, 
sim time next is 541200.0000, 
raw observation next is [20.86666666666667, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6113510768550375, 6.9112, 6.9112, 121.9260426156618, 447131.9430707164, 447131.9430707164, 127920.1883118029], 
processed observation next is [1.0, 0.2608695652173913, 0.3283950617283952, 0.7, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5141888460687969, 0.0, 0.0, 0.8094621288201359, 0.159689979668113, 0.159689979668113, 0.24600036213808252], 
reward next is 0.7540, 
noisyNet noise sample is [array([1.3085135], dtype=float32), 1.1011969]. 
=============================================
[2019-03-24 05:03:07,819] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.1640450e-23 1.5593836e-14 6.5331322e-26 5.5292137e-21], sum to 1.0000
[2019-03-24 05:03:07,830] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7876
[2019-03-24 05:03:07,841] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.7, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5156492072528306, 6.911200000000001, 6.9112, 121.9260426156618, 375107.6419252226, 375107.6419252221, 118826.8632346604], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 537600.0000, 
sim time next is 538200.0000, 
raw observation next is [19.9, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5176406263237486, 6.9112, 6.9112, 121.9260426156618, 376959.7657153824, 376959.7657153824, 119152.8517580077], 
processed observation next is [1.0, 0.21739130434782608, 0.2925925925925925, 0.75, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.39705078290468576, 0.0, 0.0, 0.8094621288201359, 0.13462848775549371, 0.13462848775549371, 0.2291400995346302], 
reward next is 0.7709, 
noisyNet noise sample is [array([-1.5345697], dtype=float32), -1.5987421]. 
=============================================
[2019-03-24 05:03:09,572] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2135443: loss 0.0128
[2019-03-24 05:03:09,578] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2135444: learning rate 0.0000
[2019-03-24 05:03:10,631] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2135991: loss 0.5393
[2019-03-24 05:03:10,633] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2135992: learning rate 0.0000
[2019-03-24 05:03:10,889] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2136120: loss 0.7298
[2019-03-24 05:03:10,893] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2136122: learning rate 0.0000
[2019-03-24 05:03:11,054] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2136207: loss 0.1862
[2019-03-24 05:03:11,057] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2136207: learning rate 0.0000
[2019-03-24 05:03:11,083] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2136220: loss 0.0634
[2019-03-24 05:03:11,087] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2136220: learning rate 0.0000
[2019-03-24 05:03:11,313] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2136337: loss 0.0669
[2019-03-24 05:03:11,314] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2136337: learning rate 0.0000
[2019-03-24 05:03:11,407] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2136383: loss 0.0378
[2019-03-24 05:03:11,409] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2136384: learning rate 0.0000
[2019-03-24 05:03:11,536] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2136452: loss 0.0081
[2019-03-24 05:03:11,540] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2136453: learning rate 0.0000
[2019-03-24 05:03:11,665] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2136521: loss 0.0457
[2019-03-24 05:03:11,667] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2136522: learning rate 0.0000
[2019-03-24 05:03:11,714] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2136542: loss 0.0381
[2019-03-24 05:03:11,716] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2136542: learning rate 0.0000
[2019-03-24 05:03:11,731] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2136547: loss 0.0461
[2019-03-24 05:03:11,733] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2136547: learning rate 0.0000
[2019-03-24 05:03:12,145] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2136766: loss 0.0064
[2019-03-24 05:03:12,149] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2136768: learning rate 0.0000
[2019-03-24 05:03:12,482] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2136943: loss 0.0059
[2019-03-24 05:03:12,485] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2136943: learning rate 0.0000
[2019-03-24 05:03:12,518] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2136959: loss 0.0069
[2019-03-24 05:03:12,521] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2136959: learning rate 0.0000
[2019-03-24 05:03:12,692] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2137046: loss 0.0363
[2019-03-24 05:03:12,695] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2137047: learning rate 0.0000
[2019-03-24 05:03:12,952] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2137181: loss 0.0053
[2019-03-24 05:03:12,954] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2137181: learning rate 0.0000
[2019-03-24 05:03:13,219] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.7395890e-32 3.2349855e-19 7.2683415e-30 2.3532380e-24], sum to 1.0000
[2019-03-24 05:03:13,225] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2794
[2019-03-24 05:03:13,231] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.76666666666667, 26.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6209841093103459, 6.9112, 6.9112, 121.9260426156618, 456397.7744824036, 456397.7744824036, 129802.8157853544], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 679200.0000, 
sim time next is 679800.0000, 
raw observation next is [30.58333333333333, 26.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6182585959565728, 6.911199999999999, 6.9112, 121.9260426156618, 454343.0401513911, 454343.0401513916, 129527.0344603897], 
processed observation next is [1.0, 0.8695652173913043, 0.6882716049382714, 0.265, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.522823244945716, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1622653714826397, 0.16226537148263986, 0.2490904508853648], 
reward next is 0.7509, 
noisyNet noise sample is [array([0.18524015], dtype=float32), 0.2660825]. 
=============================================
[2019-03-24 05:03:17,047] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 8.3628485e-21 4.1069856e-11 3.2623608e-19 2.3272981e-14], sum to 1.0000
[2019-03-24 05:03:17,051] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1817
[2019-03-24 05:03:17,056] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.662915035460565, 6.911200000000001, 6.9112, 121.9260426156618, 485572.5121102179, 485572.5121102174, 132982.7208623632], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 714600.0000, 
sim time next is 715200.0000, 
raw observation next is [23.7, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7478377232701625, 6.911199999999999, 6.9112, 121.9260426156618, 548479.1884169162, 548479.1884169166, 141626.2740972278], 
processed observation next is [1.0, 0.2608695652173913, 0.4333333333333333, 0.54, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6847971540877031, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19588542443461293, 0.1958854244346131, 0.2723582194177458], 
reward next is 0.7276, 
noisyNet noise sample is [array([0.09083499], dtype=float32), -0.8402134]. 
=============================================
[2019-03-24 05:03:17,247] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.7295362e-23 6.3000982e-14 1.2294778e-21 2.5951164e-17], sum to 1.0000
[2019-03-24 05:03:17,255] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8587
[2019-03-24 05:03:17,265] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1351508.122363495 W.
[2019-03-24 05:03:17,268] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 28.33333333333334, 1.0, 2.0, 0.9313181771030768, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.276387673826968, 6.9112, 121.9246891883433, 1351508.122363495, 1164501.469131073, 228809.6312398064], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 739200.0000, 
sim time next is 739800.0000, 
raw observation next is [31.3, 27.0, 1.0, 2.0, 0.5317241643332576, 0.0, 2.0, 0.0, 1.0, 1.0, 0.884278075822172, 6.911200000000001, 6.9112, 121.9258227060252, 1320761.338134852, 1320761.338134852, 263822.9206720426], 
processed observation next is [1.0, 0.5652173913043478, 0.7148148148148148, 0.27, 1.0, 1.0, 0.44252876706340194, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.855347594777715, 8.881784197001253e-17, 0.0, 0.8094606688488388, 0.4717004779053043, 0.4717004779053043, 0.5073517705231588], 
reward next is 0.4926, 
noisyNet noise sample is [array([0.26368055], dtype=float32), 0.6528636]. 
=============================================
[2019-03-24 05:03:21,279] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.4790224e-28 3.3742807e-16 2.1444705e-32 2.9798172e-22], sum to 1.0000
[2019-03-24 05:03:21,286] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1668
[2019-03-24 05:03:21,290] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.66666666666667, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5222177228899729, 6.911200000000001, 6.9112, 121.9260426156618, 380004.8513250874, 380004.8513250869, 119407.6106528417], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 786000.0000, 
sim time next is 786600.0000, 
raw observation next is [23.6, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5235338781617322, 6.9112, 6.9112, 121.9260426156618, 381116.142926448, 381116.142926448, 119577.4339067729], 
processed observation next is [0.0, 0.08695652173913043, 0.4296296296296297, 0.515, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.40441734770216525, 0.0, 0.0, 0.8094621288201359, 0.13611290818801716, 0.13611290818801716, 0.22995660366687096], 
reward next is 0.7700, 
noisyNet noise sample is [array([0.28177574], dtype=float32), 0.6990902]. 
=============================================
[2019-03-24 05:03:24,873] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.6660182e-30 2.7720360e-20 2.6464255e-29 3.1279395e-20], sum to 1.0000
[2019-03-24 05:03:24,880] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5928
[2019-03-24 05:03:24,884] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.1, 47.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6584540530897026, 6.9112, 6.9112, 121.9260426156618, 491146.1886505554, 491146.1886505554, 138179.3510405889], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 854400.0000, 
sim time next is 855000.0000, 
raw observation next is [26.95, 48.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6596561797221917, 6.911199999999999, 6.9112, 121.9260426156618, 492099.3568467219, 492099.3568467223, 138374.0289456723], 
processed observation next is [0.0, 0.9130434782608695, 0.5537037037037037, 0.485, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5745702246527395, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1757497703024007, 0.17574977030240083, 0.26610390181860055], 
reward next is 0.7339, 
noisyNet noise sample is [array([0.7122232], dtype=float32), -0.47516203]. 
=============================================
[2019-03-24 05:03:24,898] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.53079 ]
 [68.563194]
 [68.60521 ]
 [68.572754]
 [68.60808 ]], R is [[68.54494476]
 [68.59376526]
 [68.643013  ]
 [68.69245911]
 [68.74160004]].
[2019-03-24 05:03:25,964] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2143481: loss 0.0047
[2019-03-24 05:03:25,968] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2143484: learning rate 0.0000
[2019-03-24 05:03:26,189] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.00000000e+00 1.10059325e-35 4.74876443e-22 4.58431604e-36
 5.80414965e-27], sum to 1.0000
[2019-03-24 05:03:26,196] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9296
[2019-03-24 05:03:26,200] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5393230003071848, 6.911200000000001, 6.9112, 121.9260426156618, 391163.1675133273, 391163.1675133269, 120302.4098529039], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 882000.0000, 
sim time next is 882600.0000, 
raw observation next is [21.06666666666667, 65.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5389541917109123, 6.911200000000001, 6.9112, 121.9260426156618, 390975.8709444482, 390975.8709444478, 120303.2178962871], 
processed observation next is [0.0, 0.21739130434782608, 0.3358024691358026, 0.6516666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.42369273963864035, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13963423962301721, 0.13963423962301708, 0.23135234210824443], 
reward next is 0.7686, 
noisyNet noise sample is [array([-2.5787241], dtype=float32), -0.19701286]. 
=============================================
[2019-03-24 05:03:26,637] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2143825: loss 0.0269
[2019-03-24 05:03:26,639] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2143827: learning rate 0.0000
[2019-03-24 05:03:27,080] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2144052: loss 0.0656
[2019-03-24 05:03:27,083] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2144053: learning rate 0.0000
[2019-03-24 05:03:27,314] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2144169: loss 0.0099
[2019-03-24 05:03:27,315] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2144169: learning rate 0.0000
[2019-03-24 05:03:27,354] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2144190: loss 0.0231
[2019-03-24 05:03:27,360] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2144192: learning rate 0.0000
[2019-03-24 05:03:27,767] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2144398: loss 0.0120
[2019-03-24 05:03:27,770] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2144400: learning rate 0.0000
[2019-03-24 05:03:27,783] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2144403: loss 0.0021
[2019-03-24 05:03:27,786] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2144403: learning rate 0.0000
[2019-03-24 05:03:27,870] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2144455: loss 0.0194
[2019-03-24 05:03:27,875] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2144457: learning rate 0.0000
[2019-03-24 05:03:28,002] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2144523: loss 0.1156
[2019-03-24 05:03:28,003] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2144523: learning rate 0.0000
[2019-03-24 05:03:28,024] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2144534: loss 0.0615
[2019-03-24 05:03:28,027] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2144534: learning rate 0.0000
[2019-03-24 05:03:28,215] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2144626: loss 16.1940
[2019-03-24 05:03:28,217] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2144627: learning rate 0.0000
[2019-03-24 05:03:28,503] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2144769: loss 0.0276
[2019-03-24 05:03:28,506] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2144769: learning rate 0.0000
[2019-03-24 05:03:28,742] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2144893: loss 0.0567
[2019-03-24 05:03:28,743] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2144893: learning rate 0.0000
[2019-03-24 05:03:29,125] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2145086: loss 0.0381
[2019-03-24 05:03:29,127] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2145086: learning rate 0.0000
[2019-03-24 05:03:29,242] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2145147: loss 0.0019
[2019-03-24 05:03:29,245] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2145148: learning rate 0.0000
[2019-03-24 05:03:29,601] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2145334: loss 0.0050
[2019-03-24 05:03:29,603] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2145334: learning rate 0.0000
[2019-03-24 05:03:30,364] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.8820572e-24 3.8917118e-14 6.8357706e-29 1.6900590e-18], sum to 1.0000
[2019-03-24 05:03:30,370] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0911
[2019-03-24 05:03:30,374] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.98333333333333, 60.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5124486977116692, 6.9112, 6.9112, 121.9260426156618, 366104.5798217494, 366104.5798217494, 116137.5662645925], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 971400.0000, 
sim time next is 972000.0000, 
raw observation next is [21.1, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4898277039805555, 6.9112, 6.9112, 121.9260426156618, 350437.1718881117, 350437.1718881117, 114588.0768141119], 
processed observation next is [1.0, 0.2608695652173913, 0.3370370370370371, 0.6, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.36228462997569433, 0.0, 0.0, 0.8094621288201359, 0.12515613281718274, 0.12515613281718274, 0.22036168618098442], 
reward next is 0.7796, 
noisyNet noise sample is [array([-1.7083559], dtype=float32), 0.770784]. 
=============================================
[2019-03-24 05:03:30,386] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[70.62815 ]
 [70.80998 ]
 [70.97251 ]
 [71.1879  ]
 [71.292114]], R is [[70.5951767 ]
 [70.66588593]
 [70.73957062]
 [70.81850433]
 [70.89873505]].
[2019-03-24 05:03:31,744] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.3462570e-24 1.9886257e-13 2.3104957e-25 2.1467049e-17], sum to 1.0000
[2019-03-24 05:03:31,750] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8035
[2019-03-24 05:03:31,755] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 855377.3725904695 W.
[2019-03-24 05:03:31,762] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.26666666666667, 53.66666666666666, 1.0, 2.0, 0.6871021772742457, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 855377.3725904695, 855377.3725904691, 176483.5332040247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 996000.0000, 
sim time next is 996600.0000, 
raw observation next is [25.28333333333333, 53.33333333333334, 1.0, 2.0, 0.6969071593181163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 870666.5193757804, 870666.5193757804, 178440.259442403], 
processed observation next is [1.0, 0.5217391304347826, 0.49197530864197525, 0.5333333333333334, 1.0, 1.0, 0.6391751896644242, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.310952328348493, 0.310952328348493, 0.34315434508154424], 
reward next is 0.6568, 
noisyNet noise sample is [array([-0.29714945], dtype=float32), 0.931614]. 
=============================================
[2019-03-24 05:03:33,605] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.3435315e-26 2.5726422e-14 1.9796671e-25 1.4055928e-20], sum to 1.0000
[2019-03-24 05:03:33,609] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4997
[2019-03-24 05:03:33,617] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1132964.857145376 W.
[2019-03-24 05:03:33,621] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.93333333333334, 44.66666666666667, 1.0, 2.0, 0.4611831689465525, 1.0, 2.0, 0.4611831689465525, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156457, 1132964.857145376, 1132964.857145376, 226810.1862775128], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1010400.0000, 
sim time next is 1011000.0000, 
raw observation next is [27.01666666666667, 44.33333333333334, 1.0, 2.0, 0.4580795382455542, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7568661966183543, 6.911199999999999, 6.9112, 121.9260426156618, 1131411.036189813, 1131411.036189814, 239105.2482656744], 
processed observation next is [1.0, 0.6956521739130435, 0.5561728395061729, 0.4433333333333334, 1.0, 1.0, 0.3548565931494693, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.6960827457729429, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4040753700677903, 0.40407537006779076, 0.4598177851262969], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.750238], dtype=float32), -1.7196553]. 
=============================================
[2019-03-24 05:03:33,638] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[67.24684 ]
 [67.14349 ]
 [66.619064]
 [66.2359  ]
 [65.4986  ]], R is [[66.76799774]
 [66.66414642]
 [66.49845123]
 [66.36122894]
 [65.69761658]].
[2019-03-24 05:03:34,107] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.4775207e-36 1.2132404e-22 1.1685186e-34 2.7274755e-29], sum to 1.0000
[2019-03-24 05:03:34,116] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9519
[2019-03-24 05:03:34,119] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.75, 46.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5046282875168062, 6.911200000000001, 6.9112, 121.9260426156618, 362526.336359127, 362526.3363591266, 116224.714607704], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1026600.0000, 
sim time next is 1027200.0000, 
raw observation next is [23.7, 46.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5078521827302325, 6.911200000000001, 6.9112, 121.9260426156618, 364743.0727704689, 364743.0727704685, 116439.3052387009], 
processed observation next is [1.0, 0.9130434782608695, 0.4333333333333333, 0.46333333333333343, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.38481522841279053, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13026538313231031, 0.13026538313231018, 0.22392174084365557], 
reward next is 0.7761, 
noisyNet noise sample is [array([-0.24876983], dtype=float32), -1.3832272]. 
=============================================
[2019-03-24 05:03:37,058] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 6.3566708e-33 9.8935050e-21 3.2327682e-32 4.7453528e-25], sum to 1.0000
[2019-03-24 05:03:37,068] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4412
[2019-03-24 05:03:37,072] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 976561.270914332 W.
[2019-03-24 05:03:37,077] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 45.33333333333333, 1.0, 2.0, 0.3936015675582079, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6538330084557055, 6.911199999999999, 6.9112, 121.9260426156618, 976561.270914332, 976561.2709143325, 218380.4326175974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1096800.0000, 
sim time next is 1097400.0000, 
raw observation next is [26.33333333333334, 45.66666666666667, 1.0, 2.0, 0.7584918832211346, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 950410.2676468435, 950410.267646843, 190775.2833959532], 
processed observation next is [1.0, 0.6956521739130435, 0.5308641975308644, 0.4566666666666667, 1.0, 1.0, 0.7124903371680174, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33943223844530124, 0.33943223844530107, 0.3668755449922177], 
reward next is 0.6331, 
noisyNet noise sample is [array([-0.27661487], dtype=float32), 1.4289995]. 
=============================================
[2019-03-24 05:03:38,814] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 05:03:38,816] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:03:38,817] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:03:38,817] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:38,817] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:38,821] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:03:38,821] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:03:38,824] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:38,824] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:03:38,827] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:38,827] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:38,845] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run87
[2019-03-24 05:03:38,871] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run87
[2019-03-24 05:03:38,874] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run87
[2019-03-24 05:03:38,874] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run87
[2019-03-24 05:03:38,957] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run87
[2019-03-24 05:03:51,879] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.45772922]
[2019-03-24 05:03:51,881] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.64763094000001, 57.26862554666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5837886961381614, 6.9112, 6.9112, 121.9260426156618, 431417.591861935, 431417.591861935, 127665.7771017191]
[2019-03-24 05:03:51,882] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:03:51,885] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.4194596e-34 5.2415311e-20 1.1941046e-34 5.3549998e-25], sampled 0.37266012698641704
[2019-03-24 05:03:56,496] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.45772922]
[2019-03-24 05:03:56,497] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.5315859, 47.78535362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7710558412790165, 6.911200000000001, 6.9112, 121.9260426156618, 573788.9547947213, 573788.9547947209, 156172.6133908775]
[2019-03-24 05:03:56,499] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:03:56,502] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.3402889e-35 1.1383272e-20 7.8432931e-36 7.6789354e-26], sampled 0.580516799304363
[2019-03-24 05:04:11,647] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.45772922]
[2019-03-24 05:04:11,648] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [34.139891375, 26.44105357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8443084948984577, 6.911199999999999, 6.9112, 121.9260426156618, 630987.2959878014, 630987.2959878019, 161365.0623748669]
[2019-03-24 05:04:11,649] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:04:11,651] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 4.0181184e-34 5.7475676e-20 1.4062264e-34 6.0243720e-25], sampled 0.7822155671236541
[2019-03-24 05:04:24,968] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.45772922]
[2019-03-24 05:04:24,970] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.86723577166667, 64.76489634666667, 1.0, 2.0, 0.7178707484463507, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1533198.837416457, 1533198.837416457, 320501.3506090968]
[2019-03-24 05:04:24,971] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:04:24,976] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 5.1369272e-31 3.7083512e-18 2.0371644e-31 1.0837812e-22], sampled 0.27300155803654724
[2019-03-24 05:04:24,980] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1533198.837416457 W.
[2019-03-24 05:04:29,407] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.45772922]
[2019-03-24 05:04:29,408] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.4, 63.0, 1.0, 2.0, 0.9838761248144201, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1836835.294849465, 1836835.294849465, 375694.8694297794]
[2019-03-24 05:04:29,409] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:04:29,413] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 6.9109317e-32 1.1558840e-18 2.6471586e-32 2.5113248e-23], sampled 0.9908064200597899
[2019-03-24 05:04:29,414] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1836835.294849465 W.
[2019-03-24 05:04:53,954] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.45772922]
[2019-03-24 05:04:53,955] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.13333333333333, 66.66666666666667, 1.0, 2.0, 0.8033099576738789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 915616.436299593, 915616.436299593, 196635.2474063788]
[2019-03-24 05:04:53,956] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:04:53,959] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.7186261e-36 3.4734639e-21 8.9242004e-37 1.6317184e-26], sampled 0.08151840524090914
[2019-03-24 05:04:53,962] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 915616.436299593 W.
[2019-03-24 05:05:03,719] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.45772922]
[2019-03-24 05:05:03,720] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7127522543251086, 6.911199999999999, 6.9112, 121.9260426156618, 532413.3041993539, 532413.3041993544, 147245.7744516234]
[2019-03-24 05:05:03,722] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:05:03,725] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 5.5145557e-35 1.8898886e-20 1.8794997e-35 1.4602497e-25], sampled 0.7619691334359042
[2019-03-24 05:05:10,511] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.45772922]
[2019-03-24 05:05:10,514] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.83333333333333, 55.5, 1.0, 2.0, 0.670732171660637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 781099.7019492752, 781099.7019492752, 171483.3580304229]
[2019-03-24 05:05:10,515] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:05:10,518] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.4999543e-31 3.6811068e-18 1.4274311e-31 9.0075458e-23], sampled 0.6569135712931807
[2019-03-24 05:05:10,520] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 781099.7019492752 W.
[2019-03-24 05:05:26,639] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 05:05:27,122] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 05:05:27,423] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:05:27,587] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:05:27,627] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:05:28,645] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2150000, evaluation results [2150000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:05:29,441] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.2393693e-24 1.6371856e-12 9.3102812e-26 9.9663677e-17], sum to 1.0000
[2019-03-24 05:05:29,448] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0574
[2019-03-24 05:05:29,457] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.13333333333333, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4937548739771658, 6.911200000000001, 6.9112, 121.9260426156618, 354000.678322728, 354000.6783227275, 115141.3791120863], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1129200.0000, 
sim time next is 1129800.0000, 
raw observation next is [19.11666666666667, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4926123633866729, 6.9112, 6.9112, 121.9260426156618, 353062.1117907489, 353062.1117907489, 115013.530755692], 
processed observation next is [1.0, 0.043478260869565216, 0.2635802469135804, 0.74, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3657654542333411, 0.0, 0.0, 0.8094621288201359, 0.1260936113538389, 0.1260936113538389, 0.22117986683786922], 
reward next is 0.7788, 
noisyNet noise sample is [array([0.63943356], dtype=float32), -1.0691384]. 
=============================================
[2019-03-24 05:05:31,938] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2151599: loss 14.0187
[2019-03-24 05:05:31,941] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2151600: learning rate 0.0000
[2019-03-24 05:05:32,324] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2151787: loss 15.2907
[2019-03-24 05:05:32,326] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2151787: learning rate 0.0000
[2019-03-24 05:05:32,867] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2152054: loss 30.1924
[2019-03-24 05:05:32,869] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2152055: learning rate 0.0000
[2019-03-24 05:05:33,083] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2152162: loss 26.3630
[2019-03-24 05:05:33,086] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2152163: learning rate 0.0000
[2019-03-24 05:05:33,112] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2152174: loss 23.3030
[2019-03-24 05:05:33,113] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2152175: learning rate 0.0000
[2019-03-24 05:05:33,410] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2152316: loss 30.4530
[2019-03-24 05:05:33,414] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2152318: learning rate 0.0000
[2019-03-24 05:05:33,484] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2152355: loss 27.3914
[2019-03-24 05:05:33,486] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2152356: learning rate 0.0000
[2019-03-24 05:05:33,679] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2152449: loss 36.3928
[2019-03-24 05:05:33,682] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2152450: learning rate 0.0000
[2019-03-24 05:05:33,700] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2152459: loss 40.5365
[2019-03-24 05:05:33,702] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2152462: learning rate 0.0000
[2019-03-24 05:05:33,911] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2152565: loss 34.9630
[2019-03-24 05:05:33,916] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2152565: learning rate 0.0000
[2019-03-24 05:05:33,959] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2152583: loss 0.1275
[2019-03-24 05:05:33,960] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2152584: learning rate 0.0000
[2019-03-24 05:05:34,217] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2152712: loss 49.4232
[2019-03-24 05:05:34,219] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2152712: learning rate 0.0000
[2019-03-24 05:05:34,748] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2152968: loss 59.6145
[2019-03-24 05:05:34,755] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2152968: learning rate 0.0000
[2019-03-24 05:05:35,006] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2153099: loss 74.9935
[2019-03-24 05:05:35,013] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2153099: learning rate 0.0000
[2019-03-24 05:05:35,032] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2153112: loss 75.4077
[2019-03-24 05:05:35,035] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2153113: learning rate 0.0000
[2019-03-24 05:05:35,490] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2153334: loss 82.2133
[2019-03-24 05:05:35,491] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2153334: learning rate 0.0000
[2019-03-24 05:05:40,680] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.3719619e-20 9.5968664e-11 5.0884068e-22 4.5466946e-15], sum to 1.0000
[2019-03-24 05:05:40,685] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8547
[2019-03-24 05:05:40,688] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.76666666666667, 89.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5582411563446891, 6.9112, 6.9112, 121.9260426156618, 410818.2176039992, 410818.2176039992, 124445.2413476227], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1309800.0000, 
sim time next is 1310400.0000, 
raw observation next is [18.7, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5566357585707368, 6.9112, 6.9112, 121.9260426156618, 409490.358684371, 409490.358684371, 124231.543184707], 
processed observation next is [1.0, 0.17391304347826086, 0.24814814814814812, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44579469821342094, 0.0, 0.0, 0.8094621288201359, 0.14624655667298964, 0.14624655667298964, 0.23890681381674422], 
reward next is 0.7611, 
noisyNet noise sample is [array([0.7609803], dtype=float32), -0.072069414]. 
=============================================
[2019-03-24 05:05:41,312] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 4.4694797e-31 3.5175131e-17 3.5154375e-30 5.6945356e-20], sum to 1.0000
[2019-03-24 05:05:41,315] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1029
[2019-03-24 05:05:41,320] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.75, 33.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5978037983027703, 6.9112, 6.9112, 121.9260426156618, 443389.2796941168, 443389.2796941168, 129946.9896626076], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1360200.0000, 
sim time next is 1360800.0000, 
raw observation next is [29.5, 34.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.596959710003887, 6.9112, 6.9112, 121.9260426156618, 442883.4246774931, 442883.4246774931, 129949.7835800697], 
processed observation next is [1.0, 0.782608695652174, 0.6481481481481481, 0.34, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.49619963750485874, 0.0, 0.0, 0.8094621288201359, 0.15817265167053327, 0.15817265167053327, 0.2499034299616725], 
reward next is 0.7501, 
noisyNet noise sample is [array([-0.4143003], dtype=float32), -0.90519226]. 
=============================================
[2019-03-24 05:05:41,662] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.9087019e-30 1.1523812e-15 4.7423550e-30 4.1818430e-22], sum to 1.0000
[2019-03-24 05:05:41,669] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3755
[2019-03-24 05:05:41,678] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1220167.259425561 W.
[2019-03-24 05:05:41,681] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.95, 29.0, 1.0, 2.0, 0.4957756277591719, 1.0, 2.0, 0.4957756277591719, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1220167.259425561, 1220167.25942556, 237559.9861112265], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1355400.0000, 
sim time next is 1356000.0000, 
raw observation next is [30.96666666666667, 28.66666666666666, 1.0, 2.0, 0.5428551364206593, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8981750691533636, 6.911199999999999, 6.9112, 121.9260426156618, 1342639.515140761, 1342639.515140762, 268252.3824340303], 
processed observation next is [1.0, 0.6956521739130435, 0.7024691358024692, 0.2866666666666666, 1.0, 1.0, 0.45577992431030867, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.8727188364417046, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.47951411255027176, 0.47951411255027215, 0.515869966219289], 
reward next is 0.4841, 
noisyNet noise sample is [array([-0.64441], dtype=float32), -0.8610401]. 
=============================================
[2019-03-24 05:05:41,694] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[70.548775]
 [70.42499 ]
 [69.828545]
 [69.89196 ]
 [69.55617 ]], R is [[70.41649628]
 [70.25548553]
 [70.0813446 ]
 [69.82458496]
 [69.63964081]].
[2019-03-24 05:05:47,839] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2159556: loss 0.1725
[2019-03-24 05:05:47,841] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2159556: learning rate 0.0000
[2019-03-24 05:05:48,091] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2159686: loss 0.0904
[2019-03-24 05:05:48,095] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2159686: learning rate 0.0000
[2019-03-24 05:05:48,901] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2160104: loss 0.4007
[2019-03-24 05:05:48,903] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2160104: learning rate 0.0000
[2019-03-24 05:05:49,017] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2160163: loss 0.2762
[2019-03-24 05:05:49,019] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2160163: learning rate 0.0000
[2019-03-24 05:05:49,026] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2160168: loss 0.2638
[2019-03-24 05:05:49,029] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2160168: learning rate 0.0000
[2019-03-24 05:05:49,094] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2160203: loss 0.1315
[2019-03-24 05:05:49,098] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2160204: learning rate 0.0000
[2019-03-24 05:05:49,156] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2160234: loss 0.0575
[2019-03-24 05:05:49,158] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2160234: learning rate 0.0000
[2019-03-24 05:05:49,425] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2160372: loss 0.0513
[2019-03-24 05:05:49,427] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2160372: learning rate 0.0000
[2019-03-24 05:05:49,858] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2160588: loss 0.0776
[2019-03-24 05:05:49,860] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2160588: learning rate 0.0000
[2019-03-24 05:05:49,903] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2160612: loss 0.0406
[2019-03-24 05:05:49,908] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2160614: learning rate 0.0000
[2019-03-24 05:05:49,911] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2160617: loss 0.0436
[2019-03-24 05:05:49,914] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2160618: learning rate 0.0000
[2019-03-24 05:05:50,274] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2160798: loss 0.8841
[2019-03-24 05:05:50,279] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2160798: learning rate 0.0000
[2019-03-24 05:05:50,851] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2161096: loss 0.3135
[2019-03-24 05:05:50,853] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2161097: learning rate 0.0000
[2019-03-24 05:05:50,869] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2161106: loss 0.3346
[2019-03-24 05:05:50,874] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2161107: learning rate 0.0000
[2019-03-24 05:05:50,995] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2161168: loss 0.2345
[2019-03-24 05:05:51,000] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2161168: learning rate 0.0000
[2019-03-24 05:05:51,254] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2161299: loss 0.0003
[2019-03-24 05:05:51,257] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2161300: learning rate 0.0000
[2019-03-24 05:05:54,184] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 4.0732297e-26 1.1643899e-18 6.6618273e-28 9.2775905e-19], sum to 1.0000
[2019-03-24 05:05:54,193] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2486
[2019-03-24 05:05:54,202] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1236059.656791484 W.
[2019-03-24 05:05:54,207] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.65, 42.5, 1.0, 2.0, 0.5029639174895835, 1.0, 1.0, 0.5029639174895835, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9258879912051, 1236059.656791484, 1236059.656791484, 239787.8941158878], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1611000.0000, 
sim time next is 1611600.0000, 
raw observation next is [27.7, 42.33333333333334, 1.0, 2.0, 0.49418902654597, 1.0, 2.0, 0.49418902654597, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425685126, 1211620.536797685, 1211620.536797685, 236934.433467903], 
processed observation next is [1.0, 0.6521739130434783, 0.5814814814814815, 0.42333333333333345, 1.0, 1.0, 0.3978440792213929, 1.0, 1.0, 0.3978440792213929, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621285071143, 0.43272162028488753, 0.43272162028488753, 0.45564314128442884], 
reward next is 0.5444, 
noisyNet noise sample is [array([-0.05605594], dtype=float32), 0.82678807]. 
=============================================
[2019-03-24 05:05:55,752] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 7.1273476e-31 1.5635962e-20 2.7655736e-34 3.9842390e-24], sum to 1.0000
[2019-03-24 05:05:55,756] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2320
[2019-03-24 05:05:55,766] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.26666666666667, 62.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5534212082730345, 6.9112, 6.9112, 121.9260426156618, 406131.4598112715, 406131.4598112715, 123469.9149249938], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1644600.0000, 
sim time next is 1645200.0000, 
raw observation next is [22.2, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5537199363791644, 6.911200000000001, 6.9112, 121.9260426156618, 406421.2211283945, 406421.2211283941, 123528.9270884791], 
processed observation next is [1.0, 0.043478260869565216, 0.37777777777777777, 0.63, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44214992047395546, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14515043611728373, 0.14515043611728362, 0.23755562901630597], 
reward next is 0.7624, 
noisyNet noise sample is [array([-0.886982], dtype=float32), 0.6953805]. 
=============================================
[2019-03-24 05:05:58,421] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.4311838e-29 3.0402431e-17 2.7466964e-30 1.9757255e-21], sum to 1.0000
[2019-03-24 05:05:58,428] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4457
[2019-03-24 05:05:58,431] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.2, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5775687644779999, 6.911200000000001, 6.9112, 121.9260426156618, 421382.3717020406, 421382.3717020401, 124484.6465756421], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1656000.0000, 
sim time next is 1656600.0000, 
raw observation next is [18.98333333333333, 82.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6063269537041386, 6.9112, 6.9112, 121.9260426156618, 442165.939018779, 442165.939018779, 126922.8904854066], 
processed observation next is [1.0, 0.17391304347826086, 0.25864197530864186, 0.825, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5079086921301732, 0.0, 0.0, 0.8094621288201359, 0.15791640679242108, 0.15791640679242108, 0.24408248170270502], 
reward next is 0.7559, 
noisyNet noise sample is [array([2.203515], dtype=float32), 0.8575509]. 
=============================================
[2019-03-24 05:06:02,669] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.2296577e-25 3.6824344e-14 5.4501710e-25 3.7214292e-19], sum to 1.0000
[2019-03-24 05:06:02,675] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1622
[2019-03-24 05:06:02,681] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.61666666666667, 84.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6779184749617885, 6.911199999999999, 6.9112, 121.9260426156618, 504681.9895320423, 504681.9895320428, 139160.7549406184], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1739400.0000, 
sim time next is 1740000.0000, 
raw observation next is [20.53333333333333, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6327374370074274, 6.9112, 6.9112, 121.9260426156618, 470976.8006922391, 470976.8006922391, 134552.9513218222], 
processed observation next is [1.0, 0.13043478260869565, 0.3160493827160493, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5409217962592842, 0.0, 0.0, 0.8094621288201359, 0.16820600024722823, 0.16820600024722823, 0.25875567561888885], 
reward next is 0.7412, 
noisyNet noise sample is [array([1.7281895], dtype=float32), -0.9447168]. 
=============================================
[2019-03-24 05:06:02,701] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[57.472855]
 [57.46245 ]
 [57.611996]
 [57.64032 ]
 [57.95663 ]], R is [[57.50728226]
 [57.66459274]
 [57.82229614]
 [57.97960281]
 [58.13298416]].
[2019-03-24 05:06:03,517] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2167599: loss 0.8856
[2019-03-24 05:06:03,517] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2167599: learning rate 0.0000
[2019-03-24 05:06:03,852] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2167772: loss 1.1399
[2019-03-24 05:06:03,862] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2167772: learning rate 0.0000
[2019-03-24 05:06:04,518] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2168111: loss 1.1807
[2019-03-24 05:06:04,522] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2168111: learning rate 0.0000
[2019-03-24 05:06:04,552] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2168124: loss 1.1196
[2019-03-24 05:06:04,554] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2168125: learning rate 0.0000
[2019-03-24 05:06:04,602] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 6.3570466e-22 4.1721706e-11 5.5584825e-21 4.6302544e-15], sum to 1.0000
[2019-03-24 05:06:04,610] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4840
[2019-03-24 05:06:04,618] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1231724.079151565 W.
[2019-03-24 05:06:04,622] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.9, 67.5, 1.0, 2.0, 0.5151291056526647, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8300037380991537, 6.9112, 6.9112, 121.9260425245903, 1231724.079151565, 1231724.079151565, 260775.4894179286], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1769400.0000, 
sim time next is 1770000.0000, 
raw observation next is [24.96666666666667, 67.33333333333333, 1.0, 2.0, 0.5281357456093738, 1.0, 1.0, 0.5281357456093738, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.926042615634, 1259188.892539186, 1259188.892539187, 246632.0660439741], 
processed observation next is [1.0, 0.4782608695652174, 0.48024691358024696, 0.6733333333333333, 1.0, 1.0, 0.4382568400111593, 1.0, 0.5, 0.4382568400111593, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288199514, 0.449710318763995, 0.4497103187639954, 0.4742924346999502], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.59946454], dtype=float32), -0.2594504]. 
=============================================
[2019-03-24 05:06:04,638] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2168174: loss 1.1403
[2019-03-24 05:06:04,640] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[49.52697 ]
 [49.148888]
 [48.6345  ]
 [48.74154 ]
 [48.309998]], R is [[49.45895386]
 [48.9643631 ]
 [48.47472   ]
 [47.98997498]
 [48.06115723]].
[2019-03-24 05:06:04,641] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2168174: learning rate 0.0000
[2019-03-24 05:06:04,662] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2168184: loss 1.0020
[2019-03-24 05:06:04,664] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2168185: learning rate 0.0000
[2019-03-24 05:06:04,751] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2168229: loss 0.9375
[2019-03-24 05:06:04,754] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2168230: learning rate 0.0000
[2019-03-24 05:06:05,056] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2168389: loss 0.8533
[2019-03-24 05:06:05,057] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2168389: learning rate 0.0000
[2019-03-24 05:06:05,350] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2168542: loss 0.4673
[2019-03-24 05:06:05,351] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2168542: learning rate 0.0000
[2019-03-24 05:06:05,447] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2168590: loss 0.3839
[2019-03-24 05:06:05,449] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2168590: learning rate 0.0000
[2019-03-24 05:06:05,753] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2168745: loss 1.0147
[2019-03-24 05:06:05,757] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2168748: learning rate 0.0000
[2019-03-24 05:06:06,013] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2168868: loss 0.0470
[2019-03-24 05:06:06,016] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2168869: learning rate 0.0000
[2019-03-24 05:06:06,230] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2168975: loss 0.4073
[2019-03-24 05:06:06,233] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2168976: learning rate 0.0000
[2019-03-24 05:06:06,267] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.2510390e-29 3.5029995e-16 9.2054759e-31 5.0741432e-21], sum to 1.0000
[2019-03-24 05:06:06,278] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1795
[2019-03-24 05:06:06,281] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.2, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9262946993216947, 6.9112, 6.9112, 121.9260426156618, 672432.0957850489, 672432.0957850489, 180425.6275336518], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2116800.0000, 
sim time next is 2117400.0000, 
raw observation next is [28.38333333333333, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9265570163227136, 6.911200000000001, 6.9112, 121.9260426156618, 672539.7846554986, 672539.7846554981, 180473.68079758], 
processed observation next is [0.0, 0.5217391304347826, 0.60679012345679, 0.65, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9081962704033919, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24019278023410665, 0.24019278023410648, 0.3470647707645769], 
reward next is 0.6529, 
noisyNet noise sample is [array([-0.5996674], dtype=float32), -0.42637515]. 
=============================================
[2019-03-24 05:06:06,334] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2169030: loss 0.3733
[2019-03-24 05:06:06,336] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2169031: learning rate 0.0000
[2019-03-24 05:06:06,586] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2169161: loss 0.8555
[2019-03-24 05:06:06,587] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2169161: learning rate 0.0000
[2019-03-24 05:06:06,932] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2169337: loss 0.6303
[2019-03-24 05:06:06,933] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2169337: learning rate 0.0000
[2019-03-24 05:06:08,140] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 5.9431905e-29 5.2853125e-16 1.1811699e-27 1.3610058e-22], sum to 1.0000
[2019-03-24 05:06:08,148] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4297
[2019-03-24 05:06:08,156] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.36666666666667, 88.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6986188453170994, 6.9112, 6.9112, 121.9260426156618, 522067.545334295, 522067.545334295, 144797.5237695794], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1878000.0000, 
sim time next is 1878600.0000, 
raw observation next is [21.33333333333333, 88.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6969340781050777, 6.9112, 6.9112, 121.9260426156618, 520809.917261218, 520809.917261218, 144577.7747234151], 
processed observation next is [1.0, 0.7391304347826086, 0.3456790123456788, 0.8883333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6211675976313471, 0.0, 0.0, 0.8094621288201359, 0.18600354187900645, 0.18600354187900645, 0.27803418216041365], 
reward next is 0.7220, 
noisyNet noise sample is [array([2.3833065], dtype=float32), 1.7904453]. 
=============================================
[2019-03-24 05:06:09,119] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.6704939e-29 6.4232721e-16 2.7147704e-29 5.0158124e-21], sum to 1.0000
[2019-03-24 05:06:09,126] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7737
[2019-03-24 05:06:09,131] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.33333333333333, 88.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.69693408398036, 6.9112, 6.9112, 121.9260426156618, 520809.917261218, 520809.917261218, 144577.8751832174], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1878600.0000, 
sim time next is 1879200.0000, 
raw observation next is [21.3, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6970389551686654, 6.911199999999999, 6.9112, 121.9260426156618, 520889.5199799223, 520889.5199799227, 144557.0481240717], 
processed observation next is [1.0, 0.782608695652174, 0.3444444444444445, 0.89, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6212986939608317, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18603197142140082, 0.18603197142140096, 0.2779943233155225], 
reward next is 0.7220, 
noisyNet noise sample is [array([-1.4506801], dtype=float32), 0.55825394]. 
=============================================
[2019-03-24 05:06:17,959] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 05:06:17,960] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:06:17,962] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:06:17,962] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:06:17,962] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:06:17,964] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:06:17,965] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:06:17,969] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:06:17,971] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:06:17,972] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:06:17,973] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:06:17,996] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run88
[2019-03-24 05:06:17,996] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run88
[2019-03-24 05:06:17,996] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run88
[2019-03-24 05:06:18,070] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run88
[2019-03-24 05:06:18,070] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run88
[2019-03-24 05:06:20,286] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46116784]
[2019-03-24 05:06:20,289] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.48292769333334, 73.25876819333332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7765465278936756, 6.911200000000001, 6.9112, 121.9260426156618, 578376.1548112463, 578376.1548112459, 156505.6354052718]
[2019-03-24 05:06:20,290] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:06:20,292] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 8.5900321e-26 2.2894780e-14 1.3248329e-26 5.0140380e-19], sampled 0.5313716288746689
[2019-03-24 05:06:42,488] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46116784]
[2019-03-24 05:06:42,488] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.28959005, 72.33837356333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4835035814186565, 6.911199999999999, 6.9112, 121.9260426156618, 347285.348460299, 347285.3484602994, 114588.0681055225]
[2019-03-24 05:06:42,489] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:06:42,492] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.3145036e-25 2.8894500e-14 2.0600825e-26 6.8686100e-19], sampled 0.5068549123316815
[2019-03-24 05:07:01,118] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46116784]
[2019-03-24 05:07:01,120] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.5, 70.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9379325436013844, 6.911200000000001, 6.9112, 121.9260426156618, 681224.9146569681, 681224.9146569676, 181967.9887859091]
[2019-03-24 05:07:01,121] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:07:01,125] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.6645868e-26 9.3976120e-15 2.4082128e-27 1.5004591e-19], sampled 0.30396794190265053
[2019-03-24 05:07:14,455] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46116784]
[2019-03-24 05:07:14,457] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.35, 98.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7474994022973284, 6.9112, 6.9112, 121.9260426006228, 558497.4266452242, 558497.4266452242, 150884.2136773666]
[2019-03-24 05:07:14,461] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:07:14,463] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.000000e+00 5.177373e-24 2.116667e-13 9.259177e-25 9.951660e-18], sampled 0.6659867042564787
[2019-03-24 05:07:20,224] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46116784]
[2019-03-24 05:07:20,225] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 83.16666666666666, 1.0, 2.0, 0.66668165620253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 759809.6699937969, 759809.6699937969, 169933.3432623165]
[2019-03-24 05:07:20,226] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:07:20,229] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 8.3339826e-24 2.7201155e-13 1.5029816e-24 1.3805185e-17], sampled 0.8203862276903027
[2019-03-24 05:07:20,231] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 759809.6699937969 W.
[2019-03-24 05:07:30,363] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46116784]
[2019-03-24 05:07:30,364] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.81948108, 84.50394638666667, 1.0, 2.0, 0.7332014337846496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 835662.8480636203, 835662.8480636203, 182529.1235625859]
[2019-03-24 05:07:30,367] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:07:30,370] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 6.3321045e-26 1.9354462e-14 9.5925602e-27 3.9369149e-19], sampled 0.545528523338752
[2019-03-24 05:07:30,371] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 835662.8480636203 W.
[2019-03-24 05:08:07,014] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:08:07,306] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:08:07,381] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 05:08:07,390] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:08:07,506] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 05:08:08,522] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2175000, evaluation results [2175000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:08:09,667] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2175558: loss 0.1594
[2019-03-24 05:08:09,668] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2175558: learning rate 0.0000
[2019-03-24 05:08:10,312] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2175872: loss 0.0150
[2019-03-24 05:08:10,314] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2175873: learning rate 0.0000
[2019-03-24 05:08:10,642] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2176033: loss 0.0377
[2019-03-24 05:08:10,647] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2176034: learning rate 0.0000
[2019-03-24 05:08:10,695] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2176056: loss 0.1312
[2019-03-24 05:08:10,698] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2176057: learning rate 0.0000
[2019-03-24 05:08:10,749] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2176087: loss 0.0996
[2019-03-24 05:08:10,752] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2176088: learning rate 0.0000
[2019-03-24 05:08:10,944] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.4008650e-28 1.1928869e-15 4.1814472e-28 6.2212674e-20], sum to 1.0000
[2019-03-24 05:08:10,946] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2176185: loss 0.0359
[2019-03-24 05:08:10,947] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2176185: learning rate 0.0000
[2019-03-24 05:08:10,952] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3908
[2019-03-24 05:08:10,958] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9249986585342167, 6.9112, 6.9112, 121.9260426156618, 671722.1807989436, 671722.1807989436, 180214.3600950204], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2116200.0000, 
sim time next is 2116800.0000, 
raw observation next is [28.2, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9262946993216947, 6.9112, 6.9112, 121.9260426156618, 672432.0957850489, 672432.0957850489, 180425.6275336518], 
processed observation next is [0.0, 0.5217391304347826, 0.6, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9078683741521184, 0.0, 0.0, 0.8094621288201359, 0.24015431992323175, 0.24015431992323175, 0.34697236064163806], 
reward next is 0.6530, 
noisyNet noise sample is [array([0.12884521], dtype=float32), 0.32773334]. 
=============================================
[2019-03-24 05:08:11,245] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2176326: loss 0.0023
[2019-03-24 05:08:11,247] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2176326: learning rate 0.0000
[2019-03-24 05:08:11,333] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2176365: loss 0.1051
[2019-03-24 05:08:11,336] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2176365: learning rate 0.0000
[2019-03-24 05:08:11,623] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2176506: loss 0.0194
[2019-03-24 05:08:11,624] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2176506: learning rate 0.0000
[2019-03-24 05:08:11,992] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2176685: loss 0.1617
[2019-03-24 05:08:11,994] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2176686: learning rate 0.0000
[2019-03-24 05:08:12,045] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2176711: loss 0.1129
[2019-03-24 05:08:12,049] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2176711: learning rate 0.0000
[2019-03-24 05:08:12,478] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2176922: loss 0.0049
[2019-03-24 05:08:12,480] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2176923: learning rate 0.0000
[2019-03-24 05:08:12,735] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2177050: loss 0.0121
[2019-03-24 05:08:12,737] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2177052: learning rate 0.0000
[2019-03-24 05:08:12,762] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2177062: loss 0.0157
[2019-03-24 05:08:12,765] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2177062: learning rate 0.0000
[2019-03-24 05:08:12,783] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2177070: loss 0.0083
[2019-03-24 05:08:12,785] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2177070: learning rate 0.0000
[2019-03-24 05:08:13,199] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2177280: loss 0.0042
[2019-03-24 05:08:13,201] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2177280: learning rate 0.0000
[2019-03-24 05:08:13,284] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.3388590e-28 1.7553720e-12 3.4181972e-25 7.0795603e-20], sum to 1.0000
[2019-03-24 05:08:13,290] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8452
[2019-03-24 05:08:13,293] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 740561.9811512533 W.
[2019-03-24 05:08:13,299] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.03333333333333, 72.0, 1.0, 2.0, 0.6498012638056216, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740561.9811512533, 740561.9811512533, 166856.8188233302], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2148000.0000, 
sim time next is 2148600.0000, 
raw observation next is [27.86666666666666, 72.5, 1.0, 2.0, 0.3232194722887003, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5145759264069285, 6.911199999999999, 6.9112, 121.9260426156618, 736728.1899442888, 736728.1899442893, 201589.1898808823], 
processed observation next is [0.0, 0.8695652173913043, 0.587654320987654, 0.725, 1.0, 1.0, 0.19430889558178607, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.3932199080086606, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26311721069438887, 0.26311721069438904, 0.3876715190016967], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.92015404], dtype=float32), -1.7470815]. 
=============================================
[2019-03-24 05:08:13,335] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.4248440e-23 2.6027085e-11 1.4791608e-24 1.8710560e-15], sum to 1.0000
[2019-03-24 05:08:13,336] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5800
[2019-03-24 05:08:13,341] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.16666666666667, 50.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9007990896096394, 6.911200000000001, 6.9112, 121.9260426156618, 657008.7065250205, 657008.7065250201, 176476.8978246067], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2128800.0000, 
sim time next is 2129400.0000, 
raw observation next is [31.25, 49.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8983416244186505, 6.9112, 6.9112, 121.9260426156618, 655526.4354074282, 655526.4354074282, 176093.6610347616], 
processed observation next is [0.0, 0.6521739130434783, 0.7129629629629629, 0.495, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.872927030523313, 0.0, 0.0, 0.8094621288201359, 0.2341165840740815, 0.2341165840740815, 0.33864165583608], 
reward next is 0.6614, 
noisyNet noise sample is [array([0.15837184], dtype=float32), -2.1789887]. 
=============================================
[2019-03-24 05:08:18,223] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.3565726e-24 4.1944313e-15 1.0023251e-24 5.3223880e-20], sum to 1.0000
[2019-03-24 05:08:18,230] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9097
[2019-03-24 05:08:18,233] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.9, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7940771679877208, 6.9112, 6.9112, 121.9260426156618, 590928.741972026, 590928.741972026, 151471.6446627723], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2516400.0000, 
sim time next is 2517000.0000, 
raw observation next is [24.83333333333333, 56.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8888358552356018, 6.9112, 6.9112, 121.9260426156618, 661419.0203221523, 661419.0203221523, 162230.1364506769], 
processed observation next is [1.0, 0.13043478260869565, 0.4753086419753085, 0.5633333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8610448190445021, 0.0, 0.0, 0.8094621288201359, 0.23622107868648295, 0.23622107868648295, 0.3119810316359171], 
reward next is 0.6880, 
noisyNet noise sample is [array([0.12404194], dtype=float32), 0.5653957]. 
=============================================
[2019-03-24 05:08:18,248] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[55.661613]
 [56.478127]
 [57.915497]
 [59.48123 ]
 [60.005875]], R is [[55.54846573]
 [55.70169067]
 [55.14467239]
 [54.59322739]
 [54.04729462]].
[2019-03-24 05:08:24,070] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 5.7743482e-23 6.5692937e-11 5.0635946e-25 2.3193825e-15], sum to 1.0000
[2019-03-24 05:08:24,079] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0228
[2019-03-24 05:08:24,085] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.4, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6945831518231816, 6.911200000000001, 6.9112, 121.9260426156618, 515597.4839737072, 515597.4839737068, 139707.5316344097], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2361600.0000, 
sim time next is 2362200.0000, 
raw observation next is [27.5, 41.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6541991892544214, 6.9112, 6.9112, 121.9260426156618, 485410.7870672999, 485410.7870672999, 135497.043255019], 
processed observation next is [1.0, 0.34782608695652173, 0.5740740740740741, 0.41833333333333345, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5677489865680267, 0.0, 0.0, 0.8094621288201359, 0.17336099538117852, 0.17336099538117852, 0.2605712370288827], 
reward next is 0.7394, 
noisyNet noise sample is [array([-0.6889247], dtype=float32), -0.16723217]. 
=============================================
[2019-03-24 05:08:25,952] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2183682: loss 0.0101
[2019-03-24 05:08:25,957] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2183684: learning rate 0.0000
[2019-03-24 05:08:26,376] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2183898: loss 0.0114
[2019-03-24 05:08:26,379] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2183898: learning rate 0.0000
[2019-03-24 05:08:26,678] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2184055: loss 0.0216
[2019-03-24 05:08:26,684] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2184055: learning rate 0.0000
[2019-03-24 05:08:26,731] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2184075: loss 0.0985
[2019-03-24 05:08:26,732] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2184075: learning rate 0.0000
[2019-03-24 05:08:26,847] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2184138: loss 0.0470
[2019-03-24 05:08:26,850] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2184139: learning rate 0.0000
[2019-03-24 05:08:26,903] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2184163: loss 0.0524
[2019-03-24 05:08:26,904] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2184163: learning rate 0.0000
[2019-03-24 05:08:27,158] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2184292: loss 0.0166
[2019-03-24 05:08:27,162] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2184292: learning rate 0.0000
[2019-03-24 05:08:27,222] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2184325: loss 0.0082
[2019-03-24 05:08:27,225] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2184325: learning rate 0.0000
[2019-03-24 05:08:27,630] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2184536: loss 0.0392
[2019-03-24 05:08:27,631] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2184536: learning rate 0.0000
[2019-03-24 05:08:27,959] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2184702: loss 0.0616
[2019-03-24 05:08:27,960] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2184702: learning rate 0.0000
[2019-03-24 05:08:28,020] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2184731: loss 0.0153
[2019-03-24 05:08:28,022] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2184731: learning rate 0.0000
[2019-03-24 05:08:28,144] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2184798: loss 0.0008
[2019-03-24 05:08:28,150] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2184799: learning rate 0.0000
[2019-03-24 05:08:28,182] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.4245409e-26 1.8106625e-15 2.8539029e-29 7.5375618e-20], sum to 1.0000
[2019-03-24 05:08:28,187] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5694
[2019-03-24 05:08:28,190] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.8, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5052881691212245, 6.911200000000001, 6.9112, 121.9260426156618, 365203.2071224242, 365203.2071224237, 117071.5247877105], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2439000.0000, 
sim time next is 2439600.0000, 
raw observation next is [20.36666666666667, 70.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5087682404219916, 6.911200000000001, 6.9112, 121.9260426156618, 368995.9036151805, 368995.9036151801, 117832.3476135621], 
processed observation next is [1.0, 0.21739130434782608, 0.3098765432098767, 0.7033333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.38596030052748953, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1317842512911359, 0.13178425129113575, 0.22660066848761942], 
reward next is 0.7734, 
noisyNet noise sample is [array([-0.7811963], dtype=float32), -1.6284825]. 
=============================================
[2019-03-24 05:08:28,302] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2184878: loss 0.0261
[2019-03-24 05:08:28,306] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2184878: learning rate 0.0000
[2019-03-24 05:08:28,752] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2185105: loss 0.0113
[2019-03-24 05:08:28,753] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2185105: learning rate 0.0000
[2019-03-24 05:08:28,807] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2185131: loss 0.0098
[2019-03-24 05:08:28,809] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2185132: learning rate 0.0000
[2019-03-24 05:08:29,231] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2185352: loss 0.0127
[2019-03-24 05:08:29,235] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2185352: learning rate 0.0000
[2019-03-24 05:08:32,629] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.4958667e-35 2.6366774e-17 2.7324868e-35 8.7035646e-26], sum to 1.0000
[2019-03-24 05:08:32,633] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9568
[2019-03-24 05:08:32,639] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.2, 28.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6355357688709407, 6.911200000000001, 6.9112, 121.9260426156618, 473564.1161300126, 473564.1161300121, 135309.5700739938], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2485200.0000, 
sim time next is 2485800.0000, 
raw observation next is [32.0, 28.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6349863067900601, 6.9112, 6.9112, 121.9260426156618, 473103.8559341411, 473103.8559341411, 135203.2201197456], 
processed observation next is [1.0, 0.782608695652174, 0.7407407407407407, 0.285, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5437328834875751, 0.0, 0.0, 0.8094621288201359, 0.16896566283362183, 0.16896566283362183, 0.2600061925379723], 
reward next is 0.7400, 
noisyNet noise sample is [array([0.7447855], dtype=float32), 1.2533184]. 
=============================================
[2019-03-24 05:08:33,579] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.7545428e-32 4.8123499e-16 2.8244785e-35 7.1747254e-25], sum to 1.0000
[2019-03-24 05:08:33,586] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5082
[2019-03-24 05:08:33,589] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.76666666666667, 38.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6230287753962501, 6.911200000000001, 6.9112, 121.9260426156618, 463494.3185337581, 463494.3185337576, 133378.9424852834], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2496000.0000, 
sim time next is 2496600.0000, 
raw observation next is [28.6, 39.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6218016586164004, 6.9112, 6.9112, 121.9260426156618, 462600.5349625243, 462600.5349625243, 133275.6638062445], 
processed observation next is [1.0, 0.9130434782608695, 0.6148148148148148, 0.39, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5272520732705004, 0.0, 0.0, 0.8094621288201359, 0.16521447677233012, 0.16521447677233012, 0.2562993534735471], 
reward next is 0.7437, 
noisyNet noise sample is [array([1.5434296], dtype=float32), 0.03407416]. 
=============================================
[2019-03-24 05:08:36,162] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.4970194e-27 1.2820047e-14 2.7096384e-29 7.6255894e-22], sum to 1.0000
[2019-03-24 05:08:36,172] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1853
[2019-03-24 05:08:36,177] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.16666666666667, 77.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7879980428451981, 6.911200000000001, 6.9112, 121.9260426156618, 586327.4432102399, 586327.4432102394, 158278.8306035255], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2590800.0000, 
sim time next is 2591400.0000, 
raw observation next is [23.93333333333333, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.786424972988793, 6.9112, 6.9112, 121.9260426156618, 585294.2671305619, 585294.2671305619, 158000.7847435668], 
processed observation next is [1.0, 1.0, 0.4419753086419752, 0.7866666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7330312162359911, 0.0, 0.0, 0.8094621288201359, 0.20903366683234353, 0.20903366683234353, 0.30384766296839766], 
reward next is 0.6962, 
noisyNet noise sample is [array([0.729057], dtype=float32), 0.034976084]. 
=============================================
[2019-03-24 05:08:38,100] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.5757225e-26 4.2051171e-15 2.2166366e-28 3.4225357e-21], sum to 1.0000
[2019-03-24 05:08:38,107] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0514
[2019-03-24 05:08:38,114] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.0, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8968239180719121, 6.9112, 6.9112, 121.9260426156618, 656460.3237094629, 656460.3237094629, 175499.092310223], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2635200.0000, 
sim time next is 2635800.0000, 
raw observation next is [25.0, 82.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8975337089412883, 6.9112, 6.9112, 121.9260426156618, 657009.7687298772, 657009.7687298772, 175587.0612099384], 
processed observation next is [0.0, 0.5217391304347826, 0.48148148148148145, 0.8216666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8719171361766104, 0.0, 0.0, 0.8094621288201359, 0.23464634597495615, 0.23464634597495615, 0.3376674254037277], 
reward next is 0.6623, 
noisyNet noise sample is [array([0.94288486], dtype=float32), 2.1089225]. 
=============================================
[2019-03-24 05:08:41,365] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2191580: loss 0.0088
[2019-03-24 05:08:41,368] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2191580: learning rate 0.0000
[2019-03-24 05:08:41,896] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2191860: loss 0.0073
[2019-03-24 05:08:41,897] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2191862: learning rate 0.0000
[2019-03-24 05:08:41,982] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2191902: loss 0.0172
[2019-03-24 05:08:41,984] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2191902: learning rate 0.0000
[2019-03-24 05:08:42,377] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2192103: loss 0.0059
[2019-03-24 05:08:42,380] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2192104: learning rate 0.0000
[2019-03-24 05:08:42,421] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2192122: loss 0.0066
[2019-03-24 05:08:42,423] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2192124: learning rate 0.0000
[2019-03-24 05:08:42,552] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2192192: loss 0.0634
[2019-03-24 05:08:42,554] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2192192: learning rate 0.0000
[2019-03-24 05:08:42,641] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2192241: loss 0.0178
[2019-03-24 05:08:42,643] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2192241: learning rate 0.0000
[2019-03-24 05:08:42,913] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2192377: loss 0.0009
[2019-03-24 05:08:42,921] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2192380: learning rate 0.0000
[2019-03-24 05:08:42,946] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2192393: loss 0.0061
[2019-03-24 05:08:42,947] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2192393: learning rate 0.0000
[2019-03-24 05:08:43,397] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 4.2842311e-22 1.0254836e-10 1.4212645e-23 1.1519500e-16], sum to 1.0000
[2019-03-24 05:08:43,405] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9896
[2019-03-24 05:08:43,410] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2192631: loss 0.0029
[2019-03-24 05:08:43,415] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2192632: learning rate 0.0000
[2019-03-24 05:08:43,415] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 712822.3822146391 W.
[2019-03-24 05:08:43,418] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2192634: loss 0.0053
[2019-03-24 05:08:43,420] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2192634: learning rate 0.0000
[2019-03-24 05:08:43,423] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.4, 53.66666666666666, 1.0, 2.0, 0.3127363229679416, 1.0, 1.0, 0.3127363229679416, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 712822.3822146391, 712822.3822146396, 183545.3545405572], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2738400.0000, 
sim time next is 2739000.0000, 
raw observation next is [31.25, 54.83333333333334, 1.0, 2.0, 0.2105692064991774, 1.0, 2.0, 0.2105692064991774, 1.0, 1.0, 0.3352330345069809, 6.9112, 6.9112, 121.94756008, 719931.371647311, 719931.371647311, 224078.1515884504], 
processed observation next is [0.0, 0.6956521739130435, 0.7129629629629629, 0.5483333333333335, 1.0, 1.0, 0.06020143630854453, 1.0, 1.0, 0.06020143630854453, 1.0, 0.5, 0.1690412931337261, 0.0, 0.0, 0.8096049824067558, 0.2571183470168968, 0.2571183470168968, 0.4309195222854815], 
reward next is 0.5691, 
noisyNet noise sample is [array([0.11981035], dtype=float32), -0.29229397]. 
=============================================
[2019-03-24 05:08:43,443] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.16205 ]
 [63.23197 ]
 [63.153458]
 [63.38733 ]
 [63.137615]], R is [[63.23112869]
 [63.24584961]
 [62.61339188]
 [62.6089325 ]
 [62.63444138]].
[2019-03-24 05:08:43,852] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2192855: loss 0.0600
[2019-03-24 05:08:43,853] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2192855: learning rate 0.0000
[2019-03-24 05:08:44,073] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2192966: loss 0.0190
[2019-03-24 05:08:44,075] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2192967: learning rate 0.0000
[2019-03-24 05:08:44,464] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2193171: loss 0.0247
[2019-03-24 05:08:44,466] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2193172: learning rate 0.0000
[2019-03-24 05:08:44,675] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2193275: loss 4.9902
[2019-03-24 05:08:44,678] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2193275: learning rate 0.0000
[2019-03-24 05:08:44,742] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2193310: loss 0.0474
[2019-03-24 05:08:44,744] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2193311: learning rate 0.0000
[2019-03-24 05:08:45,314] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 6.9971486e-16 3.2642555e-10 2.7050785e-18 6.7659100e-13], sum to 1.0000
[2019-03-24 05:08:45,326] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4789
[2019-03-24 05:08:45,331] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 749304.0808012981 W.
[2019-03-24 05:08:45,333] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.58333333333333, 88.16666666666667, 1.0, 2.0, 0.3287341073119069, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5233554049629976, 6.911199999999999, 6.9112, 121.9260426156618, 749304.0808012981, 749304.0808012986, 203127.321780201], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2760600.0000, 
sim time next is 2761200.0000, 
raw observation next is [25.5, 89.0, 1.0, 2.0, 0.3293642037585147, 1.0, 1.0, 0.3293642037585147, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 750741.0021093437, 750741.0021093441, 187656.7558334676], 
processed observation next is [0.0, 1.0, 0.5, 0.89, 1.0, 1.0, 0.2016240520934699, 1.0, 0.5, 0.2016240520934699, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26812178646762275, 0.2681217864676229, 0.36087837660282235], 
reward next is 0.6391, 
noisyNet noise sample is [array([-2.043023], dtype=float32), -0.637744]. 
=============================================
[2019-03-24 05:08:48,334] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999928e-01 9.1556309e-13 7.5048337e-07 3.7879666e-13 1.3406546e-09], sum to 1.0000
[2019-03-24 05:08:48,344] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9457
[2019-03-24 05:08:48,349] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2256835.888067256 W.
[2019-03-24 05:08:48,354] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.76666666666667, 56.66666666666666, 1.0, 2.0, 0.9892063980585228, 1.0, 2.0, 0.9892063980585228, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.926042455968, 2256835.888067256, 2256835.888067255, 428140.9975903853], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2818200.0000, 
sim time next is 2818800.0000, 
raw observation next is [32.8, 57.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.622561497030886, 6.9112, 121.9237069364886, 2691930.52801026, 2327656.839112698, 443048.8999821169], 
processed observation next is [1.0, 0.6521739130434783, 0.7703703703703703, 0.57, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.25, 0.0711361497030886, 0.0, 0.809446622339361, 0.9614037600036642, 0.8313060139688208, 0.8520171153502247], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.20602448], dtype=float32), -0.24462596]. 
=============================================
[2019-03-24 05:08:51,372] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.99999762e-01 7.70618243e-14 2.56938961e-07 1.07860146e-13
 6.77484761e-12], sum to 1.0000
[2019-03-24 05:08:51,377] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8911
[2019-03-24 05:08:51,381] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1132162.84879631 W.
[2019-03-24 05:08:51,386] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 92.66666666666667, 1.0, 2.0, 0.4838538627898498, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7732552976911468, 6.911199999999999, 6.9112, 121.9260426156618, 1132162.84879631, 1132162.848796311, 250807.1311855791], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2882400.0000, 
sim time next is 2883000.0000, 
raw observation next is [22.96666666666667, 93.33333333333334, 1.0, 2.0, 0.9660983312103351, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.12780271958419, 6.9112, 121.9251161941829, 1247851.145055994, 1136932.035692225, 234527.9236508769], 
processed observation next is [1.0, 0.34782608695652173, 0.4061728395061729, 0.9333333333333335, 1.0, 1.0, 0.9596408704884941, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.02166027195841904, 0.0, 0.8094559783449266, 0.44566112323428353, 0.40604715560436605, 0.4510152377901479], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6218797], dtype=float32), -0.39037612]. 
=============================================
[2019-03-24 05:08:51,403] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[32.269657]
 [32.933895]
 [35.220955]
 [40.473278]
 [40.277683]], R is [[31.29952812]
 [30.98653221]
 [30.67666626]
 [30.89950943]
 [31.25035477]].
[2019-03-24 05:08:57,191] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2199647: loss 32.0233
[2019-03-24 05:08:57,192] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2199647: learning rate 0.0000
[2019-03-24 05:08:57,617] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2199866: loss 69.6654
[2019-03-24 05:08:57,618] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2199866: learning rate 0.0000
[2019-03-24 05:08:57,799] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2199959: loss -9.7322
[2019-03-24 05:08:57,802] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2199959: learning rate 0.0000
[2019-03-24 05:08:57,888] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 05:08:57,891] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:08:57,892] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:08:57,892] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:08:57,893] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:08:57,893] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:08:57,893] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:08:57,895] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:08:57,896] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:08:57,894] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:08:57,897] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:08:57,915] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run89
[2019-03-24 05:08:57,938] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run89
[2019-03-24 05:08:57,964] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run89
[2019-03-24 05:08:57,964] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run89
[2019-03-24 05:08:58,010] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run89
[2019-03-24 05:09:01,461] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46150497]
[2019-03-24 05:09:01,463] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.36972079, 34.38922582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6318953468884159, 6.911200000000001, 6.9112, 121.9260426156618, 471935.2238938482, 471935.2238938478, 138607.4161184681]
[2019-03-24 05:09:01,464] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:09:01,467] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.5076362e-18 2.9724574e-09 5.9078004e-19 1.0012983e-14], sampled 0.4588139252790898
[2019-03-24 05:09:31,440] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46150497]
[2019-03-24 05:09:31,441] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.01666666666667, 24.0, 1.0, 2.0, 0.4832554538561741, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7979424234508956, 6.9112, 6.9112, 121.9260425134835, 1192928.918837583, 1192928.918837583, 247548.2486784809]
[2019-03-24 05:09:31,442] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:09:31,445] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9999845e-01 1.5765069e-12 1.6065590e-06 4.9159212e-13 3.2188266e-10], sampled 0.059794828342803696
[2019-03-24 05:09:31,446] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1192928.918837583 W.
[2019-03-24 05:09:52,850] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46150497]
[2019-03-24 05:09:52,851] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.9, 69.0, 1.0, 2.0, 0.8978310243275535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1023423.930566275, 1023423.930566275, 216982.8630566587]
[2019-03-24 05:09:52,852] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:09:52,856] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9999702e-01 4.7226342e-12 2.9392129e-06 1.5891239e-12 8.2015872e-10], sampled 0.16672570076039173
[2019-03-24 05:09:52,857] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1023423.930566275 W.
[2019-03-24 05:10:06,903] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46150497]
[2019-03-24 05:10:06,907] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.33907925166667, 85.25329830166666, 1.0, 2.0, 0.7520036150165207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 857104.5271823204, 857104.5271823199, 186230.3611238791]
[2019-03-24 05:10:06,908] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:10:06,910] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9999750e-01 3.4822271e-12 2.4900653e-06 1.1481721e-12 6.3103900e-10], sampled 0.44347050557109957
[2019-03-24 05:10:06,912] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 857104.5271823204 W.
[2019-03-24 05:10:08,981] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46150497]
[2019-03-24 05:10:08,985] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.25897291333333, 83.69340236333333, 1.0, 2.0, 1.011964036829282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.218377182224925, 6.9112, 121.9245639739003, 1311039.076872119, 1153738.812048997, 243647.9095759172]
[2019-03-24 05:10:08,987] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:10:08,991] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9999821e-01 1.7187038e-12 1.7527697e-06 5.4681558e-13 3.5778633e-10], sampled 0.6584864406592326
[2019-03-24 05:10:08,992] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1311039.076872119 W.
[2019-03-24 05:10:29,553] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46150497]
[2019-03-24 05:10:29,553] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.64692494, 43.05132667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4666319942165604, 6.911199999999999, 6.9112, 121.9260426156618, 333233.9293684388, 333233.9293684392, 96349.10141000201]
[2019-03-24 05:10:29,554] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:10:29,557] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.8655742e-18 3.2004857e-09 6.6104940e-19 1.1105793e-14], sampled 0.20638037388142672
[2019-03-24 05:10:44,550] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46150497]
[2019-03-24 05:10:44,552] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.99512958, 45.59563689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8164078602935878, 6.9112, 6.9112, 121.9260426156618, 603561.0845886178, 603561.0845886178, 151264.2763092256]
[2019-03-24 05:10:44,553] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:10:44,557] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.99999881e-01 1.14922965e-14 1.51659520e-07 2.86182660e-15
 6.48425280e-12], sampled 0.7699050496491526
[2019-03-24 05:10:46,929] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:10:47,232] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:10:47,280] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:10:47,375] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 05:10:47,432] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8632.3811 2219165745.7936 543.0000
[2019-03-24 05:10:48,448] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2200000, evaluation results [2200000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8632.381064823683, 2219165745.7935514, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:10:48,703] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2200123: loss -41.7488
[2019-03-24 05:10:48,706] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2200124: learning rate 0.0000
[2019-03-24 05:10:48,876] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2200202: loss -60.6844
[2019-03-24 05:10:48,877] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2200202: learning rate 0.0000
[2019-03-24 05:10:48,909] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2200209: loss 37.0747
[2019-03-24 05:10:48,912] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2200210: learning rate 0.0000
[2019-03-24 05:10:49,060] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2200286: loss 15.7553
[2019-03-24 05:10:49,062] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2200287: learning rate 0.0000
[2019-03-24 05:10:49,198] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2200357: loss -39.6045
[2019-03-24 05:10:49,203] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2200357: learning rate 0.0000
[2019-03-24 05:10:49,444] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2200461: loss 14.0054
[2019-03-24 05:10:49,446] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2200461: learning rate 0.0000
[2019-03-24 05:10:49,895] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2200686: loss 10.5040
[2019-03-24 05:10:49,897] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2200686: learning rate 0.0000
[2019-03-24 05:10:50,006] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2200737: loss 0.1292
[2019-03-24 05:10:50,007] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2200737: learning rate 0.0000
[2019-03-24 05:10:50,084] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2200774: loss 95.7040
[2019-03-24 05:10:50,090] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2200774: learning rate 0.0000
[2019-03-24 05:10:50,240] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2200851: loss 29.7981
[2019-03-24 05:10:50,242] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2200851: learning rate 0.0000
[2019-03-24 05:10:50,575] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2201011: loss 96.1622
[2019-03-24 05:10:50,577] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2201011: learning rate 0.0000
[2019-03-24 05:10:51,076] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2201249: loss 90.0901
[2019-03-24 05:10:51,080] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2201250: learning rate 0.0000
[2019-03-24 05:10:51,417] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2201413: loss -4.3402
[2019-03-24 05:10:51,419] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2201413: learning rate 0.0000
[2019-03-24 05:10:55,392] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999881e-01 4.0478892e-12 1.1430640e-06 1.1224016e-13 4.8052051e-10], sum to 1.0000
[2019-03-24 05:10:55,397] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5018
[2019-03-24 05:10:55,418] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1742037.096528772 W.
[2019-03-24 05:10:55,421] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.26666666666667, 35.66666666666667, 1.0, 2.0, 0.7408059134147534, 1.0, 2.0, 0.7408059134147534, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1742037.096528772, 1742037.096528772, 322460.4557200645], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3148800.0000, 
sim time next is 3149400.0000, 
raw observation next is [32.58333333333334, 33.83333333333334, 1.0, 2.0, 0.8589298703461392, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9665143889001314, 6.911199999999999, 6.9112, 121.9260426156618, 1734845.861064443, 1734845.861064443, 342066.4170421875], 
processed observation next is [1.0, 0.43478260869565216, 0.7623456790123461, 0.33833333333333343, 1.0, 1.0, 0.8320593694596895, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9581429861251641, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6195878075230153, 0.6195878075230153, 0.6578200327734375], 
reward next is 0.3422, 
noisyNet noise sample is [array([-0.54595345], dtype=float32), 0.77833134]. 
=============================================
[2019-03-24 05:10:57,816] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.6651456e-01 1.8291069e-16 1.3348548e-01 1.2518383e-15 2.2748600e-11], sum to 1.0000
[2019-03-24 05:10:57,827] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7068
[2019-03-24 05:10:57,837] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1510180.830898979 W.
[2019-03-24 05:10:57,843] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.66666666666666, 36.66666666666667, 1.0, 2.0, 0.4414778754902568, 1.0, 1.0, 0.4414778754902568, 1.0, 2.0, 0.702847155711118, 6.9112, 6.9112, 121.94756008, 1510180.830898979, 1510180.830898979, 315728.0893087745], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3156000.0000, 
sim time next is 3156600.0000, 
raw observation next is [33.83333333333334, 36.33333333333333, 1.0, 2.0, 0.6571755036145931, 1.0, 2.0, 0.6571755036145931, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1510219.574884274, 1510219.574884275, 288850.3867244454], 
processed observation next is [1.0, 0.5217391304347826, 0.8086419753086423, 0.3633333333333333, 1.0, 1.0, 0.5918755995411822, 1.0, 1.0, 0.5918755995411822, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5393641338872407, 0.539364133887241, 0.5554815129316257], 
reward next is 0.4445, 
noisyNet noise sample is [array([-0.3048679], dtype=float32), 1.3634146]. 
=============================================
[2019-03-24 05:10:58,932] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.99998689e-01 1.08401463e-16 1.35128403e-06 4.24058665e-21
 6.62170463e-15], sum to 1.0000
[2019-03-24 05:10:58,939] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3885
[2019-03-24 05:10:58,944] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1804855.751897673 W.
[2019-03-24 05:10:58,948] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [34.4, 31.33333333333334, 1.0, 2.0, 0.7757182083806863, 1.0, 2.0, 0.7757182083806863, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1804855.751897673, 1804855.751897673, 335632.2916701314], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3162000.0000, 
sim time next is 3162600.0000, 
raw observation next is [34.45, 31.5, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9758104046984223, 6.919510003507691, 6.9112, 121.9259951480105, 1913148.13306156, 1908892.670182653, 380629.2827913004], 
processed observation next is [1.0, 0.6086956521739131, 0.8314814814814816, 0.315, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9697630058730278, 0.0008310003507690844, 0.0, 0.8094618136842942, 0.6832671903791286, 0.6817473822080904, 0.73197938998327], 
reward next is 0.2265, 
noisyNet noise sample is [array([0.51410455], dtype=float32), 0.052711345]. 
=============================================
[2019-03-24 05:11:03,729] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2207551: loss 0.0218
[2019-03-24 05:11:03,731] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2207551: learning rate 0.0000
[2019-03-24 05:11:04,018] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2207696: loss 0.0823
[2019-03-24 05:11:04,021] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2207697: learning rate 0.0000
[2019-03-24 05:11:04,352] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.9680920e-21 5.3876734e-09 8.6732091e-25 3.6644745e-19], sum to 1.0000
[2019-03-24 05:11:04,360] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5450
[2019-03-24 05:11:04,363] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.66666666666666, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8987967791821156, 6.911200000000001, 6.9112, 121.9260426156618, 658864.1649463684, 658864.164946368, 175557.7241637423], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3267600.0000, 
sim time next is 3268200.0000, 
raw observation next is [26.23333333333333, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9001587661784103, 6.911199999999999, 6.9112, 121.9260426156618, 660028.4645672605, 660028.4645672609, 175701.874710048], 
processed observation next is [0.0, 0.8260869565217391, 0.5271604938271603, 0.735, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8751984577230129, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23572445163116446, 0.23572445163116462, 0.3378882205962461], 
reward next is 0.6621, 
noisyNet noise sample is [array([1.2303025], dtype=float32), -0.21310219]. 
=============================================
[2019-03-24 05:11:04,594] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2207998: loss 0.0026
[2019-03-24 05:11:04,597] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2207998: learning rate 0.0000
[2019-03-24 05:11:04,854] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2208133: loss 0.0008
[2019-03-24 05:11:04,856] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2208133: learning rate 0.0000
[2019-03-24 05:11:04,859] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2208134: loss 0.0004
[2019-03-24 05:11:04,862] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2208135: learning rate 0.0000
[2019-03-24 05:11:05,057] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2208233: loss 0.0089
[2019-03-24 05:11:05,059] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2208233: learning rate 0.0000
[2019-03-24 05:11:05,219] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2208316: loss 0.0003
[2019-03-24 05:11:05,220] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2208317: learning rate 0.0000
[2019-03-24 05:11:05,228] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2208320: loss 0.0043
[2019-03-24 05:11:05,231] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2208320: learning rate 0.0000
[2019-03-24 05:11:05,588] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2208495: loss 0.0008
[2019-03-24 05:11:05,590] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2208496: learning rate 0.0000
[2019-03-24 05:11:05,698] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2208558: loss 0.0726
[2019-03-24 05:11:05,700] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2208558: learning rate 0.0000
[2019-03-24 05:11:06,101] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2208760: loss 0.0133
[2019-03-24 05:11:06,106] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2208760: learning rate 0.0000
[2019-03-24 05:11:06,222] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2208822: loss 0.0413
[2019-03-24 05:11:06,224] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2208822: learning rate 0.0000
[2019-03-24 05:11:06,312] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2208874: loss 0.9113
[2019-03-24 05:11:06,313] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2208875: learning rate 0.0000
[2019-03-24 05:11:06,585] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2209002: loss 0.0039
[2019-03-24 05:11:06,589] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2209004: learning rate 0.0000
[2019-03-24 05:11:07,014] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2209223: loss 0.0133
[2019-03-24 05:11:07,016] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2209224: learning rate 0.0000
[2019-03-24 05:11:07,332] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2209386: loss 0.0317
[2019-03-24 05:11:07,332] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2209386: learning rate 0.0000
[2019-03-24 05:11:08,033] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9957055e-01 1.7043036e-12 4.2942597e-04 6.8306268e-12 1.5589373e-10], sum to 1.0000
[2019-03-24 05:11:08,038] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6538
[2019-03-24 05:11:08,045] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 688588.670616366 W.
[2019-03-24 05:11:08,050] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.95, 92.0, 1.0, 2.0, 0.2997718868851337, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4775114805905958, 6.9112, 6.9112, 121.9260426156618, 688588.670616366, 688588.670616366, 195088.7411585642], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3375000.0000, 
sim time next is 3375600.0000, 
raw observation next is [23.83333333333334, 91.66666666666667, 1.0, 2.0, 0.1991962663946777, 1.0, 1.0, 0.1991962663946777, 1.0, 2.0, 0.3171845659819253, 6.9112, 6.9112, 121.94756008, 683306.2989195067, 683306.2989195067, 220339.8482699692], 
processed observation next is [1.0, 0.043478260869565216, 0.43827160493827183, 0.9166666666666667, 1.0, 1.0, 0.04666222189842582, 1.0, 0.5, 0.04666222189842582, 1.0, 1.0, 0.1464807074774066, 0.0, 0.0, 0.8096049824067558, 0.24403796389982382, 0.24403796389982382, 0.42373047744224845], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.25593093], dtype=float32), -2.0147998]. 
=============================================
[2019-03-24 05:11:16,539] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.7395427e-20 1.7054497e-11 1.3703683e-21 7.8172843e-19], sum to 1.0000
[2019-03-24 05:11:16,544] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1827
[2019-03-24 05:11:16,553] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 687174.5202665643 W.
[2019-03-24 05:11:16,561] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.08333333333333, 76.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9568032862790057, 6.911200000000001, 6.9112, 121.9260426156618, 687174.5202665643, 687174.5202665639, 185548.912103894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3520200.0000, 
sim time next is 3520800.0000, 
raw observation next is [27.0, 79.0, 1.0, 1.0, 0.6213728797805679, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 708147.9093340798, 708147.9093340798, 161793.6590443861], 
processed observation next is [1.0, 0.782608695652174, 0.5555555555555556, 0.79, 1.0, 0.5, 0.5492534283101999, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2529099676193142, 0.2529099676193142, 0.3111416520084348], 
reward next is 0.6889, 
noisyNet noise sample is [array([0.47979048], dtype=float32), 1.6724102]. 
=============================================
[2019-03-24 05:11:19,519] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2215603: loss 0.3759
[2019-03-24 05:11:19,521] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2215603: learning rate 0.0000
[2019-03-24 05:11:19,715] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2215701: loss 1.6090
[2019-03-24 05:11:19,719] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2215701: learning rate 0.0000
[2019-03-24 05:11:20,284] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2215987: loss 1.2474
[2019-03-24 05:11:20,285] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2215987: learning rate 0.0000
[2019-03-24 05:11:20,666] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2216178: loss 1.4749
[2019-03-24 05:11:20,668] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2216180: learning rate 0.0000
[2019-03-24 05:11:20,749] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2216222: loss 1.5077
[2019-03-24 05:11:20,750] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2216222: learning rate 0.0000
[2019-03-24 05:11:21,049] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2216378: loss 1.3142
[2019-03-24 05:11:21,052] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2216378: learning rate 0.0000
[2019-03-24 05:11:21,170] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2216438: loss 0.5552
[2019-03-24 05:11:21,171] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2216438: learning rate 0.0000
[2019-03-24 05:11:21,175] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2216438: loss 1.4674
[2019-03-24 05:11:21,178] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2216439: learning rate 0.0000
[2019-03-24 05:11:21,270] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2216482: loss 0.4237
[2019-03-24 05:11:21,273] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2216482: learning rate 0.0000
[2019-03-24 05:11:21,303] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2216503: loss 0.2656
[2019-03-24 05:11:21,305] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2216503: learning rate 0.0000
[2019-03-24 05:11:21,786] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2216748: loss 0.5901
[2019-03-24 05:11:21,788] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2216749: learning rate 0.0000
[2019-03-24 05:11:22,045] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2216885: loss 0.7928
[2019-03-24 05:11:22,048] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2216886: learning rate 0.0000
[2019-03-24 05:11:22,228] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2216975: loss -21.0021
[2019-03-24 05:11:22,231] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2216976: learning rate 0.0000
[2019-03-24 05:11:22,548] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2217138: loss 0.2295
[2019-03-24 05:11:22,553] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2217139: learning rate 0.0000
[2019-03-24 05:11:22,732] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2217232: loss 0.1726
[2019-03-24 05:11:22,736] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2217233: learning rate 0.0000
[2019-03-24 05:11:22,785] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2217256: loss 0.0435
[2019-03-24 05:11:22,786] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2217257: learning rate 0.0000
[2019-03-24 05:11:28,183] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.4091672e-13 5.2538244e-08 2.2516529e-15 1.2064247e-13], sum to 1.0000
[2019-03-24 05:11:28,186] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9044
[2019-03-24 05:11:28,192] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1718558.068303025 W.
[2019-03-24 05:11:28,195] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.9, 94.0, 1.0, 2.0, 0.8802659269541827, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1718558.068303025, 1718558.068303024, 352739.4940088823], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3747000.0000, 
sim time next is 3747600.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.5465222622448913, 1.0, 1.0, 0.5465222622448913, 1.0, 2.0, 0.8700812404813363, 6.9112, 6.9112, 121.94756008, 1869898.846765774, 1869898.846765774, 367009.043595951], 
processed observation next is [1.0, 0.391304347826087, 0.5185185185185185, 0.94, 1.0, 1.0, 0.46014555029153725, 1.0, 0.5, 0.46014555029153725, 1.0, 1.0, 0.8376015506016704, 0.0, 0.0, 0.8096049824067558, 0.6678210167020622, 0.6678210167020622, 0.7057866222999057], 
reward next is 0.2942, 
noisyNet noise sample is [array([-0.2530109], dtype=float32), 0.37215966]. 
=============================================
[2019-03-24 05:11:34,855] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9999821e-01 2.5203811e-11 1.7334764e-06 9.5533184e-13 1.3691716e-10], sum to 1.0000
[2019-03-24 05:11:34,864] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9846
[2019-03-24 05:11:34,875] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 748583.6640308242 W.
[2019-03-24 05:11:34,884] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.7, 52.0, 1.0, 2.0, 0.2189454861069812, 1.0, 1.0, 0.2189454861069812, 1.0, 1.0, 0.3485683444389865, 6.9112, 6.9112, 121.94756008, 748583.6640308242, 748583.6640308242, 226883.2724789042], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3843000.0000, 
sim time next is 3843600.0000, 
raw observation next is [32.8, 54.33333333333333, 1.0, 2.0, 0.3429356252679794, 1.0, 2.0, 0.3429356252679794, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 781690.988948032, 781690.9889480325, 191084.2511297606], 
processed observation next is [0.0, 0.4782608695652174, 0.7703703703703703, 0.5433333333333333, 1.0, 1.0, 0.21778050627140402, 1.0, 1.0, 0.21778050627140402, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27917535319572573, 0.2791753531957259, 0.3674697137110781], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.81269705], dtype=float32), 0.6286458]. 
=============================================
[2019-03-24 05:11:35,410] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2223687: loss -67.5813
[2019-03-24 05:11:35,414] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2223687: learning rate 0.0000
[2019-03-24 05:11:35,416] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2223688: loss 27.5134
[2019-03-24 05:11:35,419] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2223689: learning rate 0.0000
[2019-03-24 05:11:36,038] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2224007: loss -51.3511
[2019-03-24 05:11:36,041] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2224007: learning rate 0.0000
[2019-03-24 05:11:36,254] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2224109: loss -7.0812
[2019-03-24 05:11:36,255] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2224109: learning rate 0.0000
[2019-03-24 05:11:36,436] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2224201: loss 13.7878
[2019-03-24 05:11:36,437] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2224201: learning rate 0.0000
[2019-03-24 05:11:36,671] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2224323: loss -74.7308
[2019-03-24 05:11:36,672] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2224323: learning rate 0.0000
[2019-03-24 05:11:36,738] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2224350: loss 36.4752
[2019-03-24 05:11:36,740] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2224350: learning rate 0.0000
[2019-03-24 05:11:36,912] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2224440: loss -18.6500
[2019-03-24 05:11:36,914] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2224440: learning rate 0.0000
[2019-03-24 05:11:36,995] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2224487: loss -14.6921
[2019-03-24 05:11:36,996] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2224487: learning rate 0.0000
[2019-03-24 05:11:37,070] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2224520: loss -106.0293
[2019-03-24 05:11:37,072] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2224520: learning rate 0.0000
[2019-03-24 05:11:37,557] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2224765: loss 2.0612
[2019-03-24 05:11:37,559] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2224767: learning rate 0.0000
[2019-03-24 05:11:37,646] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2224817: loss 86.0384
[2019-03-24 05:11:37,649] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2224820: learning rate 0.0000
[2019-03-24 05:11:37,666] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2224827: loss 5.3690
[2019-03-24 05:11:37,676] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2224827: learning rate 0.0000
[2019-03-24 05:11:38,001] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 05:11:38,002] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:11:38,004] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:11:38,004] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:11:38,007] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:11:38,008] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:11:38,009] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:11:38,010] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:11:38,004] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:11:38,005] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:11:38,013] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:11:38,029] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run90
[2019-03-24 05:11:38,055] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run90
[2019-03-24 05:11:38,055] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run90
[2019-03-24 05:11:38,103] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run90
[2019-03-24 05:11:38,128] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run90
[2019-03-24 05:11:44,030] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46333334]
[2019-03-24 05:11:44,031] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.80633154666667, 42.74809535333334, 1.0, 2.0, 0.2154158418149415, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3502723033839079, 6.911199999999999, 6.9112, 121.9260426156618, 522527.4674977877, 522527.4674977881, 172281.1425150406]
[2019-03-24 05:11:44,036] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:11:44,038] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.4835234e-02 4.4629217e-14 9.6516478e-01 1.2303549e-16 1.6648165e-12], sampled 0.26074800352562777
[2019-03-24 05:11:55,758] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46333334]
[2019-03-24 05:11:55,759] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.85179981, 81.46136320000001, 1.0, 2.0, 0.251654080708325, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4126917271334468, 6.911199999999999, 6.9112, 121.9260426156618, 616770.0018091641, 616770.0018091645, 180378.3697097394]
[2019-03-24 05:11:55,762] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:11:55,765] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.76533850e-02 1.31978524e-14 9.72346604e-01 2.32277759e-17
 5.57540342e-13], sampled 0.14831476097935936
[2019-03-24 05:12:04,002] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46333334]
[2019-03-24 05:12:04,003] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.8, 92.0, 1.0, 2.0, 0.2599131949824431, 0.0, 2.0, 0.0, 1.0, 2.0, 0.42439625597083, 6.911199999999999, 6.9112, 121.9260426156618, 633892.7176660919, 633892.7176660923, 182721.5062208715]
[2019-03-24 05:12:04,005] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:12:04,008] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.8533177e-02 2.7652683e-14 9.7146678e-01 5.2972673e-17 1.0711803e-12], sampled 0.6728608001704777
[2019-03-24 05:12:05,593] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46333334]
[2019-03-24 05:12:05,594] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.95, 93.66666666666667, 1.0, 2.0, 0.1679730598299289, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2825993672652852, 6.911199999999999, 6.9112, 121.9260426156618, 420493.9258476243, 420493.9258476248, 159680.564277694]
[2019-03-24 05:12:05,596] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:12:05,599] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.2898403e-02 4.9428845e-15 9.2710161e-01 2.6140514e-17 2.8026125e-13], sampled 0.4317320815148856
[2019-03-24 05:12:16,890] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46333334]
[2019-03-24 05:12:16,891] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.66666666666666, 89.0, 1.0, 2.0, 0.5641130256062323, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8980863086437582, 6.911199999999999, 6.9112, 121.9260426156618, 1286268.181288273, 1286268.181288273, 280156.0437205275]
[2019-03-24 05:12:16,892] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:12:16,896] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.3481297e-02 2.5764423e-12 9.1651869e-01 2.7055501e-14 6.6619911e-11], sampled 0.5180709517269138
[2019-03-24 05:12:17,343] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46333334]
[2019-03-24 05:12:17,345] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.5, 72.0, 1.0, 2.0, 0.3383664750588993, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5386904481205261, 6.911200000000001, 6.9112, 121.9260426156618, 771270.7811203272, 771270.7811203267, 205843.9511624729]
[2019-03-24 05:12:17,346] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:12:17,350] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.2779095e-02 3.7843965e-14 9.5722085e-01 1.3711654e-16 1.4937698e-12], sampled 0.4489852746816386
[2019-03-24 05:12:35,587] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46333334]
[2019-03-24 05:12:35,588] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.53622252333334, 67.73765045333333, 1.0, 2.0, 0.9214947813378656, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1050416.376169885, 1050416.376169885, 222314.1037604495]
[2019-03-24 05:12:35,589] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:12:35,592] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.1970351e-02 9.6178393e-13 9.2802960e-01 8.2059104e-15 2.7356704e-11], sampled 0.5421245633669763
[2019-03-24 05:13:24,938] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46333334]
[2019-03-24 05:13:24,939] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [16.35, 84.50000000000001, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2016836283671178, 6.9112, 6.9112, 121.9260426156618, 287995.1731548986, 287995.1731548986, 128150.5780309206]
[2019-03-24 05:13:24,940] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:13:24,944] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9679930e-03 1.6358767e-16 9.9003208e-01 6.7467843e-20 1.2693856e-14], sampled 0.27158487724035385
[2019-03-24 05:13:25,594] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46333334]
[2019-03-24 05:13:25,596] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.058635945, 69.84959906833333, 1.0, 2.0, 0.2485669731507527, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3982316005230971, 6.911200000000001, 6.9112, 121.9260426156618, 586201.6369221028, 586201.6369221023, 181326.1257339885]
[2019-03-24 05:13:25,598] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:13:25,601] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.5617773e-02 2.6766809e-14 9.7438228e-01 4.4845739e-17 1.0470274e-12], sampled 0.45193420680015917
[2019-03-24 05:13:27,865] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06759743], dtype=float32), 0.46333334]
[2019-03-24 05:13:27,866] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.7, 79.33333333333334, 1.0, 2.0, 0.19337048604341, 0.0, 2.0, 0.0, 1.0, 2.0, 0.319465988840407, 6.911199999999999, 6.9112, 121.9260426156618, 477358.557073911, 477358.5570739115, 166255.5338957315]
[2019-03-24 05:13:27,867] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:13:27,870] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.0223390e-02 2.6791218e-14 9.6977657e-01 5.7388765e-17 1.0419929e-12], sampled 0.31456986974680257
[2019-03-24 05:13:27,952] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6541.8586 2617238659.6504 164.0000
[2019-03-24 05:13:28,096] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7016.5529 2784623718.4406 262.0000
[2019-03-24 05:13:28,168] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7082.3913 2571119552.8335 155.0000
[2019-03-24 05:13:28,229] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6860.4921 2552943589.8953 91.0000
[2019-03-24 05:13:28,304] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7342.5511 2519097639.0622 103.0000
[2019-03-24 05:13:29,322] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2225000, evaluation results [2225000.0, 7016.55289751211, 2784623718.4405675, 262.0, 6860.492135262728, 2552943589.895251, 91.0, 7342.551143167738, 2519097639.062167, 103.0, 6541.858574301961, 2617238659.6503506, 164.0, 7082.391289585191, 2571119552.833476, 155.0]
[2019-03-24 05:13:29,764] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2225212: loss 0.3578
[2019-03-24 05:13:29,767] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2225215: learning rate 0.0000
[2019-03-24 05:13:29,783] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2225221: loss 0.0338
[2019-03-24 05:13:29,788] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2225222: learning rate 0.0000
[2019-03-24 05:13:29,857] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2225253: loss -29.6085
[2019-03-24 05:13:29,862] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2225255: learning rate 0.0000
[2019-03-24 05:13:35,696] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.9139490e-01 3.3667022e-14 4.0860513e-01 1.6554593e-16 1.4283400e-08], sum to 1.0000
[2019-03-24 05:13:35,702] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2359
[2019-03-24 05:13:35,707] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.58333333333333, 95.83333333333334, 1.0, 1.0, 0.2190926255971805, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3573277108718672, 6.911199999999999, 6.9112, 121.9260426156618, 533543.048695954, 533543.0486959544, 172934.9505353676], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4067400.0000, 
sim time next is 4068000.0000, 
raw observation next is [20.7, 95.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7139744433608953, 6.911199999999999, 6.9112, 121.9260426156618, 533378.8401937499, 533378.8401937503, 147257.0964400735], 
processed observation next is [1.0, 0.08695652173913043, 0.3222222222222222, 0.95, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6424680542011191, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19049244292633924, 0.1904924429263394, 0.2831867239232183], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8884892], dtype=float32), -0.44719872]. 
=============================================
[2019-03-24 05:13:35,722] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[43.809032]
 [44.542313]
 [45.037983]
 [45.694492]
 [46.14245 ]], R is [[42.80405426]
 [43.0434494 ]
 [43.33111191]
 [43.61624527]
 [43.89881897]].
[2019-03-24 05:13:42,649] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2231699: loss 201.6450
[2019-03-24 05:13:42,651] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2231700: learning rate 0.0000
[2019-03-24 05:13:42,787] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2231767: loss 189.8816
[2019-03-24 05:13:42,792] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2231767: learning rate 0.0000
[2019-03-24 05:13:43,288] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2232023: loss 168.2910
[2019-03-24 05:13:43,291] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2232023: learning rate 0.0000
[2019-03-24 05:13:43,316] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2232037: loss 158.8077
[2019-03-24 05:13:43,318] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2232038: learning rate 0.0000
[2019-03-24 05:13:43,629] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2232201: loss 200.4919
[2019-03-24 05:13:43,630] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2232201: learning rate 0.0000
[2019-03-24 05:13:44,018] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2232404: loss 57.4494
[2019-03-24 05:13:44,020] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2232404: learning rate 0.0000
[2019-03-24 05:13:44,036] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2232412: loss 198.8048
[2019-03-24 05:13:44,037] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2232412: learning rate 0.0000
[2019-03-24 05:13:44,097] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2232439: loss 132.4393
[2019-03-24 05:13:44,100] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2232442: learning rate 0.0000
[2019-03-24 05:13:44,151] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2232472: loss 144.4699
[2019-03-24 05:13:44,156] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2232474: learning rate 0.0000
[2019-03-24 05:13:44,182] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2232486: loss 169.8736
[2019-03-24 05:13:44,184] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2232486: learning rate 0.0000
[2019-03-24 05:13:44,722] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2232759: loss 146.5150
[2019-03-24 05:13:44,724] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2232759: learning rate 0.0000
[2019-03-24 05:13:44,752] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2232779: loss 116.9423
[2019-03-24 05:13:44,754] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2232779: learning rate 0.0000
[2019-03-24 05:13:44,857] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2232828: loss 0.0483
[2019-03-24 05:13:44,858] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2232828: learning rate 0.0000
[2019-03-24 05:13:45,650] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2233234: loss 87.8446
[2019-03-24 05:13:45,652] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2233235: learning rate 0.0000
[2019-03-24 05:13:45,772] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2233300: loss 46.7576
[2019-03-24 05:13:45,775] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2233300: learning rate 0.0000
[2019-03-24 05:13:45,811] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2233312: loss 24.8520
[2019-03-24 05:13:45,813] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2233313: learning rate 0.0000
[2019-03-24 05:13:47,797] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5316030e-01 4.2774499e-12 7.4683970e-01 4.2280814e-17 5.0151217e-10], sum to 1.0000
[2019-03-24 05:13:47,803] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3053
[2019-03-24 05:13:47,811] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.6, 34.0, 1.0, 2.0, 0.901649895082532, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9737160252704591, 6.9112, 6.9112, 121.9260426156618, 1773352.214972391, 1773352.214972391, 353103.0024755861], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4284000.0000, 
sim time next is 4284600.0000, 
raw observation next is [33.66666666666667, 34.0, 1.0, 2.0, 0.876220931945062, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9741866923737303, 6.9112, 6.9112, 121.9260426156618, 1742766.29890823, 1742766.29890823, 347697.9620067998], 
processed observation next is [1.0, 0.6086956521739131, 0.8024691358024693, 0.34, 1.0, 1.0, 0.8526439666012643, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9677333654671629, 0.0, 0.0, 0.8094621288201359, 0.6224165353243678, 0.6224165353243678, 0.6686499269361535], 
reward next is 0.3314, 
noisyNet noise sample is [array([-0.17360777], dtype=float32), 0.00029543007]. 
=============================================
[2019-03-24 05:13:48,392] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.6150732e-01 1.1454452e-12 3.8492672e-02 3.9702539e-15 2.8418828e-10], sum to 1.0000
[2019-03-24 05:13:48,400] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0619
[2019-03-24 05:13:48,404] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2028712.967126202 W.
[2019-03-24 05:13:48,405] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.5, 39.0, 1.0, 2.0, 0.5928868019919555, 1.0, 2.0, 0.5928868019919555, 1.0, 2.0, 0.9438950977463043, 6.911199999999999, 6.9112, 121.94756008, 2028712.967126202, 2028712.967126202, 391513.5791353464], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4289400.0000, 
sim time next is 4290000.0000, 
raw observation next is [33.33333333333334, 40.66666666666666, 1.0, 2.0, 0.6208780474369053, 1.0, 2.0, 0.6208780474369053, 1.0, 2.0, 0.9884580721058857, 6.9112, 6.9112, 121.94756008, 2124606.055768307, 2124606.055768307, 406868.3196306783], 
processed observation next is [1.0, 0.6521739130434783, 0.7901234567901239, 0.40666666666666657, 1.0, 1.0, 0.548664342186792, 1.0, 1.0, 0.548664342186792, 1.0, 1.0, 0.985572590132357, 0.0, 0.0, 0.8096049824067558, 0.7587878770601095, 0.7587878770601095, 0.7824390762128428], 
reward next is 0.2176, 
noisyNet noise sample is [array([-0.08313413], dtype=float32), -0.106237106]. 
=============================================
[2019-03-24 05:13:48,422] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[50.57182 ]
 [50.202255]
 [49.714428]
 [49.6293  ]
 [49.284824]], R is [[50.47660828]
 [50.21893311]
 [49.71674347]
 [49.21957779]
 [49.0201149 ]].
[2019-03-24 05:13:48,589] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999666e-01 4.4456379e-14 3.3912265e-06 5.3911242e-15 5.1788462e-13], sum to 1.0000
[2019-03-24 05:13:48,598] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3106
[2019-03-24 05:13:48,599] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1856010.517579912 W.
[2019-03-24 05:13:48,606] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.9, 44.0, 1.0, 2.0, 0.8136492397501947, 1.0, 2.0, 0.8136492397501947, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1856010.517579912, 1856010.517579913, 349431.2907610634], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4294800.0000, 
sim time next is 4295400.0000, 
raw observation next is [31.75, 45.33333333333334, 1.0, 2.0, 0.2491745305594665, 1.0, 2.0, 0.2491745305594665, 1.0, 1.0, 0.3966939676985899, 6.9112, 6.9112, 121.94756008, 851995.44881082, 851995.44881082, 237332.9324543676], 
processed observation next is [1.0, 0.7391304347826086, 0.7314814814814815, 0.4533333333333334, 1.0, 1.0, 0.10616015542793632, 1.0, 1.0, 0.10616015542793632, 1.0, 0.5, 0.24586745962323733, 0.0, 0.0, 0.8096049824067558, 0.30428408886100716, 0.30428408886100716, 0.4564094854891685], 
reward next is 0.5436, 
noisyNet noise sample is [array([-1.7406398], dtype=float32), -0.044736765]. 
=============================================
[2019-03-24 05:13:55,266] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.9207261e-27 3.6235941e-18 1.3872059e-26 1.6240472e-21], sum to 1.0000
[2019-03-24 05:13:55,275] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6093
[2019-03-24 05:13:55,282] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 714615.7288545972 W.
[2019-03-24 05:13:55,286] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 84.0, 1.0, 1.0, 0.3135227507674044, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4991384299448526, 6.911199999999999, 6.9112, 121.9260426156618, 714615.7288545972, 714615.7288545977, 198914.4634165875], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4438800.0000, 
sim time next is 4439400.0000, 
raw observation next is [26.16666666666667, 83.16666666666667, 1.0, 2.0, 0.210020065568546, 1.0, 1.0, 0.210020065568546, 1.0, 2.0, 0.3343587842611442, 6.9112, 6.9112, 121.94756008, 718052.9919888964, 718052.9919888964, 223895.621789003], 
processed observation next is [0.0, 0.391304347826087, 0.5246913580246916, 0.8316666666666667, 1.0, 1.0, 0.0595476971054119, 1.0, 0.5, 0.0595476971054119, 1.0, 1.0, 0.1679484803264302, 0.0, 0.0, 0.8096049824067558, 0.2564474971388916, 0.2564474971388916, 0.4305685034403904], 
reward next is 0.5694, 
noisyNet noise sample is [array([1.1621033], dtype=float32), 1.0808921]. 
=============================================
[2019-03-24 05:13:58,222] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2239635: loss 0.6199
[2019-03-24 05:13:58,224] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2239635: learning rate 0.0000
[2019-03-24 05:13:58,370] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2239711: loss 0.4678
[2019-03-24 05:13:58,370] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2239711: learning rate 0.0000
[2019-03-24 05:13:58,854] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2239955: loss 0.5779
[2019-03-24 05:13:58,858] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2239957: learning rate 0.0000
[2019-03-24 05:13:59,025] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2240042: loss 0.6554
[2019-03-24 05:13:59,027] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2240043: learning rate 0.0000
[2019-03-24 05:13:59,243] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2240154: loss 0.4923
[2019-03-24 05:13:59,245] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2240154: learning rate 0.0000
[2019-03-24 05:13:59,656] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2240363: loss 0.7571
[2019-03-24 05:13:59,662] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2240363: learning rate 0.0000
[2019-03-24 05:13:59,689] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2240382: loss 0.7910
[2019-03-24 05:13:59,690] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2240382: learning rate 0.0000
[2019-03-24 05:13:59,848] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2240464: loss 0.2121
[2019-03-24 05:13:59,849] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2240464: learning rate 0.0000
[2019-03-24 05:13:59,894] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2240482: loss 0.9771
[2019-03-24 05:13:59,895] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2240482: learning rate 0.0000
[2019-03-24 05:14:00,118] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2240598: loss 0.0287
[2019-03-24 05:14:00,119] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2240598: learning rate 0.0000
[2019-03-24 05:14:00,200] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2240638: loss 0.4318
[2019-03-24 05:14:00,202] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2240638: learning rate 0.0000
[2019-03-24 05:14:00,325] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2240699: loss 0.6163
[2019-03-24 05:14:00,327] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2240700: learning rate 0.0000
[2019-03-24 05:14:00,813] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2240951: loss -29.1111
[2019-03-24 05:14:00,814] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2240951: learning rate 0.0000
[2019-03-24 05:14:01,284] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2241196: loss 0.8103
[2019-03-24 05:14:01,285] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2241196: learning rate 0.0000
[2019-03-24 05:14:01,498] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2241307: loss 3.3190
[2019-03-24 05:14:01,498] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2241307: loss 1.2386
[2019-03-24 05:14:01,499] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2241307: learning rate 0.0000
[2019-03-24 05:14:01,506] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2241308: learning rate 0.0000
[2019-03-24 05:14:13,905] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2247657: loss -30.9449
[2019-03-24 05:14:13,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2247657: learning rate 0.0000
[2019-03-24 05:14:14,225] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2247820: loss -14.7162
[2019-03-24 05:14:14,226] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2247820: learning rate 0.0000
[2019-03-24 05:14:14,389] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2247903: loss -55.2581
[2019-03-24 05:14:14,390] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2247903: learning rate 0.0000
[2019-03-24 05:14:14,822] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2248125: loss -5.6000
[2019-03-24 05:14:14,826] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2248126: learning rate 0.0000
[2019-03-24 05:14:14,862] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2248147: loss 17.8749
[2019-03-24 05:14:14,870] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2248148: learning rate 0.0000
[2019-03-24 05:14:15,193] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2248315: loss 27.3675
[2019-03-24 05:14:15,194] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2248315: learning rate 0.0000
[2019-03-24 05:14:15,325] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2248381: loss 12.4862
[2019-03-24 05:14:15,327] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2248382: learning rate 0.0000
[2019-03-24 05:14:15,399] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2248414: loss 22.5362
[2019-03-24 05:14:15,401] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2248415: learning rate 0.0000
[2019-03-24 05:14:15,451] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2248443: loss 7.0811
[2019-03-24 05:14:15,452] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2248444: learning rate 0.0000
[2019-03-24 05:14:15,544] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2248488: loss 16.6853
[2019-03-24 05:14:15,545] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2248488: learning rate 0.0000
[2019-03-24 05:14:15,983] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.3398197e-16 2.2241954e-10 3.0768332e-16 2.0496473e-09], sum to 1.0000
[2019-03-24 05:14:15,992] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8397
[2019-03-24 05:14:15,998] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 808748.8718752691 W.
[2019-03-24 05:14:16,007] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.08333333333334, 92.16666666666667, 1.0, 2.0, 0.2365333079010796, 1.0, 1.0, 0.2365333079010796, 1.0, 2.0, 0.376568729530558, 6.911200000000001, 6.9112, 121.94756008, 808748.8718752691, 808748.8718752686, 232900.9406285452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4834200.0000, 
sim time next is 4834800.0000, 
raw observation next is [26.1, 92.0, 1.0, 2.0, 0.7099617633496765, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 809161.5626260624, 809161.5626260624, 178039.7293978952], 
processed observation next is [1.0, 1.0, 0.5222222222222223, 0.92, 1.0, 1.0, 0.6547163849400911, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28898627236645086, 0.28898627236645086, 0.3423840949959523], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1533972], dtype=float32), -1.0859163]. 
=============================================
[2019-03-24 05:14:16,011] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2248719: loss 71.4881
[2019-03-24 05:14:16,013] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2248720: learning rate 0.0000
[2019-03-24 05:14:16,061] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2248740: loss 37.0021
[2019-03-24 05:14:16,062] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2248740: learning rate 0.0000
[2019-03-24 05:14:16,697] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2249072: loss 23.2277
[2019-03-24 05:14:16,700] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2249072: learning rate 0.0000
[2019-03-24 05:14:16,704] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2249072: loss 35.3302
[2019-03-24 05:14:16,706] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2249073: learning rate 0.0000
[2019-03-24 05:14:16,774] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2249107: loss -44.8975
[2019-03-24 05:14:16,778] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2249110: learning rate 0.0000
[2019-03-24 05:14:17,368] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2249410: loss 15.6294
[2019-03-24 05:14:17,369] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2249410: learning rate 0.0000
[2019-03-24 05:14:18,526] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 05:14:18,528] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:14:18,529] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:14:18,529] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:14:18,530] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:14:18,531] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:14:18,531] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:14:18,535] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:14:18,537] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:14:18,537] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:14:18,538] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:14:18,557] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run91
[2019-03-24 05:14:18,579] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run91
[2019-03-24 05:14:18,604] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run91
[2019-03-24 05:14:18,633] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run91
[2019-03-24 05:14:18,663] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run91
[2019-03-24 05:14:28,741] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07020713], dtype=float32), 0.46388772]
[2019-03-24 05:14:28,742] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.93333333333333, 32.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7591190394089977, 6.9112, 6.9112, 121.9260426156618, 566012.3948963912, 566012.3948963912, 148663.7122978166]
[2019-03-24 05:14:28,745] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:14:28,749] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.4307463e-16 8.4767998e-11 1.3838779e-16 4.5046057e-11], sampled 0.18176944338917822
[2019-03-24 05:14:40,948] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07020713], dtype=float32), 0.46388772]
[2019-03-24 05:14:40,949] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.70952845333333, 53.02299204666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6166449052899522, 6.9112, 6.9112, 121.9260426156618, 459442.2562479473, 459442.2562479473, 133400.0543318783]
[2019-03-24 05:14:40,950] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:14:40,954] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 6.4922197e-17 2.1255738e-11 3.9498410e-17 5.3940227e-11], sampled 0.10746704104233629
[2019-03-24 05:14:44,408] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07020713], dtype=float32), 0.46388772]
[2019-03-24 05:14:44,410] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.91666666666666, 88.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7909046656402645, 6.911200000000001, 6.9112, 121.9260426156618, 590706.886034244, 590706.8860342435, 153692.7840199879]
[2019-03-24 05:14:44,411] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:14:44,414] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.5144205e-16 9.1707822e-11 1.4154963e-16 4.0288172e-11], sampled 0.36796812791249744
[2019-03-24 05:15:03,394] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07020713], dtype=float32), 0.46388772]
[2019-03-24 05:15:03,395] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.85, 71.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7488715285240836, 6.9112, 6.9112, 121.9260426156618, 558298.4220642709, 558298.4220642709, 152773.0104855608]
[2019-03-24 05:15:03,397] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:15:03,402] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.4382363e-17 2.4179991e-11 6.7780859e-18 1.9307878e-12], sampled 0.19972712684333582
[2019-03-24 05:15:14,526] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07020713], dtype=float32), 0.46388772]
[2019-03-24 05:15:14,527] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.66666666666667, 85.66666666666667, 1.0, 2.0, 0.7419724689109878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 845665.1087012539, 845665.1087012534, 184246.5878757698]
[2019-03-24 05:15:14,528] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:15:14,533] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.5670358e-17 6.3472647e-12 5.5509927e-17 1.1859424e-08], sampled 0.5537483023199178
[2019-03-24 05:15:14,536] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 845665.1087012539 W.
[2019-03-24 05:15:33,972] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07020713], dtype=float32), 0.46388772]
[2019-03-24 05:15:33,973] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.36276836, 76.93946224666666, 1.0, 2.0, 0.870651200088164, 1.0, 2.0, 0.870651200088164, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426155164, 1986056.010971952, 1986056.010971952, 373814.7651554439]
[2019-03-24 05:15:33,974] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:15:33,977] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 5.8688605e-16 1.3145864e-10 3.4832250e-16 1.2778620e-10], sampled 0.4422417684401757
[2019-03-24 05:15:33,979] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1986056.010971952 W.
[2019-03-24 05:15:48,131] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07020713], dtype=float32), 0.46388772]
[2019-03-24 05:15:48,131] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.9, 87.66666666666666, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8165506091690194, 6.911199999999999, 6.9112, 121.9260426156235, 600909.8990035972, 600909.8990035977, 164354.811487926]
[2019-03-24 05:15:48,133] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:15:48,143] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.2867949e-17 1.1899215e-11 1.3649295e-17 2.4644535e-11], sampled 0.856307167688206
[2019-03-24 05:16:01,221] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07020713], dtype=float32), 0.46388772]
[2019-03-24 05:16:01,222] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.3, 91.66666666666667, 1.0, 2.0, 0.7964747000226047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 971100.8667847188, 971100.8667847188, 197987.2744575728]
[2019-03-24 05:16:01,223] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:16:01,226] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9998319e-01 1.2598038e-14 8.4057244e-10 3.3393400e-14 1.6762855e-05], sampled 0.7450144059341748
[2019-03-24 05:16:01,228] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 971100.8667847188 W.
[2019-03-24 05:16:08,204] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 05:16:08,253] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:16:08,443] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 05:16:08,523] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:16:08,529] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:16:09,547] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2250000, evaluation results [2250000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:16:09,966] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.6223369e-15 7.0344108e-10 6.1807626e-15 7.2138745e-10], sum to 1.0000
[2019-03-24 05:16:09,972] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0014
[2019-03-24 05:16:09,982] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2039574.547247486 W.
[2019-03-24 05:16:09,986] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.38333333333333, 84.83333333333333, 1.0, 2.0, 0.8940860012650061, 1.0, 2.0, 0.8940860012650061, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2039574.547247486, 2039574.547247486, 384167.5087778247], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4877400.0000, 
sim time next is 4878000.0000, 
raw observation next is [28.6, 84.0, 1.0, 2.0, 0.6102384308846615, 1.0, 2.0, 0.6102384308846615, 1.0, 1.0, 0.9715194560465933, 6.9112, 6.9112, 121.94756008, 2088155.385893536, 2088155.385893536, 400982.2345055333], 
processed observation next is [1.0, 0.4782608695652174, 0.6148148148148148, 0.84, 1.0, 1.0, 0.5359981320055494, 1.0, 1.0, 0.5359981320055494, 1.0, 0.5, 0.9643993200582415, 0.0, 0.0, 0.8096049824067558, 0.7457697806762629, 0.7457697806762629, 0.7711196817414102], 
reward next is 0.2289, 
noisyNet noise sample is [array([-1.3061728], dtype=float32), -1.9592447]. 
=============================================
[2019-03-24 05:16:10,002] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[29.871332]
 [29.761095]
 [29.627388]
 [29.618868]
 [29.846716]], R is [[29.77860451]
 [29.74203491]
 [29.71709061]
 [29.67484474]
 [29.6361618 ]].
[2019-03-24 05:16:20,612] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2255616: loss -116.5511
[2019-03-24 05:16:20,616] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2255616: learning rate 0.0000
[2019-03-24 05:16:21,111] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2255871: loss 10.0332
[2019-03-24 05:16:21,113] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2255871: learning rate 0.0000
[2019-03-24 05:16:21,257] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2255946: loss -27.6334
[2019-03-24 05:16:21,262] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2255947: learning rate 0.0000
[2019-03-24 05:16:21,721] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2256183: loss -34.5610
[2019-03-24 05:16:21,726] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2256184: learning rate 0.0000
[2019-03-24 05:16:21,726] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2256184: loss -78.4181
[2019-03-24 05:16:21,731] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2256186: learning rate 0.0000
[2019-03-24 05:16:21,753] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2256194: loss 62.0270
[2019-03-24 05:16:21,753] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2256194: learning rate 0.0000
[2019-03-24 05:16:21,886] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2256264: loss 4.8963
[2019-03-24 05:16:21,887] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2256265: learning rate 0.0000
[2019-03-24 05:16:22,068] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2256356: loss -30.3435
[2019-03-24 05:16:22,071] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2256358: learning rate 0.0000
[2019-03-24 05:16:22,083] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2256363: loss -22.8888
[2019-03-24 05:16:22,086] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2256363: learning rate 0.0000
[2019-03-24 05:16:22,213] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2256426: loss -20.2505
[2019-03-24 05:16:22,215] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2256427: learning rate 0.0000
[2019-03-24 05:16:22,450] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2343296e-01 8.1724785e-13 2.7656704e-01 2.9641988e-12 8.2613492e-11], sum to 1.0000
[2019-03-24 05:16:22,456] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0522
[2019-03-24 05:16:22,462] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 807390.0037034476 W.
[2019-03-24 05:16:22,467] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 100.0, 1.0, 2.0, 0.3542041041680088, 0.0, 2.0, 0.0, 1.0, 2.0, 0.563904469457799, 6.911199999999999, 6.9112, 121.9260426156618, 807390.0037034476, 807390.0037034481, 210391.4891054431], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5119200.0000, 
sim time next is 5119800.0000, 
raw observation next is [25.0, 100.0, 1.0, 2.0, 0.3548394060788712, 1.0, 1.0, 0.3548394060788712, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808838.905766078, 808838.905766078, 194142.1737415759], 
processed observation next is [0.0, 0.2608695652173913, 0.48148148148148145, 1.0, 1.0, 1.0, 0.23195167390341812, 1.0, 0.5, 0.23195167390341812, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2888710377735993, 0.2888710377735993, 0.37335033411841523], 
reward next is 0.6266, 
noisyNet noise sample is [array([0.88942724], dtype=float32), -0.6863063]. 
=============================================
[2019-03-24 05:16:22,734] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2256688: loss 0.1498
[2019-03-24 05:16:22,740] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2256689: learning rate 0.0000
[2019-03-24 05:16:23,000] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2256826: loss -39.9221
[2019-03-24 05:16:23,000] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2256826: learning rate 0.0000
[2019-03-24 05:16:23,378] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2257022: loss 0.0373
[2019-03-24 05:16:23,382] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2257024: learning rate 0.0000
[2019-03-24 05:16:23,539] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2257105: loss -0.5034
[2019-03-24 05:16:23,543] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2257105: learning rate 0.0000
[2019-03-24 05:16:23,680] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2257175: loss -53.8376
[2019-03-24 05:16:23,684] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2257175: learning rate 0.0000
[2019-03-24 05:16:24,463] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2257571: loss -44.7671
[2019-03-24 05:16:24,466] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2257571: learning rate 0.0000
[2019-03-24 05:16:25,590] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.6038309e-01 1.5965832e-09 6.3961661e-01 7.7889730e-08 3.3905789e-07], sum to 1.0000
[2019-03-24 05:16:25,600] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1917
[2019-03-24 05:16:25,607] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1083810.064648075 W.
[2019-03-24 05:16:25,611] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.06666666666667, 93.66666666666667, 1.0, 2.0, 0.4753846155341299, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7568277901263943, 6.911199999999999, 6.9112, 121.9260426156618, 1083810.064648075, 1083810.064648075, 248503.0228944189], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5194200.0000, 
sim time next is 5194800.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.457366826901531, 1.0, 1.0, 0.457366826901531, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1042704.090112624, 1042704.090112625, 222512.204579516], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.35400812726372743, 1.0, 0.5, 0.35400812726372743, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3723943178973657, 0.3723943178973661, 0.42790808572983846], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5685464], dtype=float32), 1.6328669]. 
=============================================
[2019-03-24 05:16:31,338] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.3227214e-01 1.7195804e-12 6.7720130e-02 7.6439641e-13 7.7898212e-06], sum to 1.0000
[2019-03-24 05:16:31,344] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3942
[2019-03-24 05:16:31,346] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.71666666666667, 90.66666666666667, 1.0, 1.0, 0.2674233251132128, 0.0, 2.0, 0.0, 1.0, 2.0, 0.429201224282212, 6.9112, 6.9112, 121.9260426156618, 633686.5513254369, 633686.5513254369, 185904.6492519048], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5295000.0000, 
sim time next is 5295600.0000, 
raw observation next is [22.6, 91.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9093460696438873, 6.911199999999999, 6.9112, 121.9260426156618, 673748.3150779444, 673748.3150779449, 174870.2205994602], 
processed observation next is [1.0, 0.30434782608695654, 0.39259259259259266, 0.91, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8866825870548591, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.240624398242123, 0.24062439824212317, 0.3362888857681927], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2454844], dtype=float32), -1.7159855]. 
=============================================
[2019-03-24 05:16:32,108] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.7191125e-01 3.5111601e-11 2.8088713e-02 3.2336157e-14 1.2407704e-10], sum to 1.0000
[2019-03-24 05:16:32,116] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4769
[2019-03-24 05:16:32,123] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1772286.83270832 W.
[2019-03-24 05:16:32,127] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.43333333333333, 77.33333333333334, 1.0, 2.0, 0.5180211081317528, 1.0, 2.0, 0.5180211081317528, 1.0, 2.0, 0.8247064749154326, 6.911200000000001, 6.9112, 121.94756008, 1772286.83270832, 1772286.83270832, 352522.0663871304], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5574000.0000, 
sim time next is 5574600.0000, 
raw observation next is [28.65, 77.0, 1.0, 2.0, 0.8568698852939959, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1691852.257274445, 1691852.257274445, 347814.1375818992], 
processed observation next is [1.0, 0.5217391304347826, 0.6166666666666666, 0.77, 1.0, 1.0, 0.829607006302376, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6042329490265874, 0.6042329490265874, 0.6688733415036523], 
reward next is 0.3311, 
noisyNet noise sample is [array([1.004559], dtype=float32), 0.9726721]. 
=============================================
[2019-03-24 05:16:32,213] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.7751325e-01 1.4925698e-11 2.2486780e-02 1.1953791e-14 6.3057087e-11], sum to 1.0000
[2019-03-24 05:16:32,219] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0776
[2019-03-24 05:16:32,227] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1913864.424284964 W.
[2019-03-24 05:16:32,231] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.3, 76.0, 1.0, 2.0, 0.5593584937405773, 1.0, 1.0, 0.5593584937405773, 1.0, 2.0, 0.8905169390693429, 6.9112, 6.9112, 121.94756008, 1913864.424284964, 1913864.424284964, 373677.0883826714], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5576400.0000, 
sim time next is 5577000.0000, 
raw observation next is [29.5, 75.66666666666667, 1.0, 2.0, 0.7447680946711561, 1.0, 2.0, 0.7447680946711561, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426133496, 1698629.048933239, 1698629.048933239, 321461.4980968911], 
processed observation next is [1.0, 0.5652173913043478, 0.6481481481481481, 0.7566666666666667, 1.0, 1.0, 0.6961524936561382, 1.0, 1.0, 0.6961524936561382, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288047853, 0.606653231761871, 0.606653231761871, 0.6181951886478675], 
reward next is 0.3818, 
noisyNet noise sample is [array([1.004559], dtype=float32), 0.9726721]. 
=============================================
[2019-03-24 05:16:32,242] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[32.4066  ]
 [32.4146  ]
 [32.268166]
 [32.002987]
 [31.652512]], R is [[32.73134613]
 [32.6854248 ]
 [32.55688477]
 [32.52093506]
 [32.52685165]].
[2019-03-24 05:16:32,988] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.4369520e-01 1.8752528e-19 2.5630483e-01 1.9672967e-18 3.9746592e-16], sum to 1.0000
[2019-03-24 05:16:33,000] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8177
[2019-03-24 05:16:33,003] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.8, 65.0, 1.0, 2.0, 0.7253815062249154, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9923064843440855, 6.911199999999999, 6.9112, 121.9260426156618, 1546646.775218603, 1546646.775218603, 320975.4888488269], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5319600.0000, 
sim time next is 5320200.0000, 
raw observation next is [28.0, 64.0, 1.0, 2.0, 0.7083966680243985, 0.0, 2.0, 0.0, 1.0, 2.0, 0.992227210871911, 6.911199999999999, 6.9112, 121.9260426156618, 1527217.118586843, 1527217.118586843, 317823.3281570097], 
processed observation next is [1.0, 0.5652173913043478, 0.5925925925925926, 0.64, 1.0, 1.0, 0.652853176219522, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9902840135898888, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5454346852095867, 0.5454346852095867, 0.6111987079942494], 
reward next is 0.3888, 
noisyNet noise sample is [array([2.0005915], dtype=float32), -1.1985377]. 
=============================================
[2019-03-24 05:16:36,288] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2263627: loss -4.3064
[2019-03-24 05:16:36,291] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2263629: learning rate 0.0000
[2019-03-24 05:16:36,722] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2263846: loss -14.1405
[2019-03-24 05:16:36,723] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2263847: learning rate 0.0000
[2019-03-24 05:16:36,980] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2263978: loss -10.8131
[2019-03-24 05:16:36,981] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2263979: learning rate 0.0000
[2019-03-24 05:16:37,079] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2264031: loss 1.1934
[2019-03-24 05:16:37,080] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2264031: learning rate 0.0000
[2019-03-24 05:16:37,176] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2264080: loss -1.4076
[2019-03-24 05:16:37,179] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2264081: learning rate 0.0000
[2019-03-24 05:16:37,346] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.6592242e-05 1.5261087e-10 9.9994338e-01 7.0371896e-11 6.0462448e-11], sum to 1.0000
[2019-03-24 05:16:37,353] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4231
[2019-03-24 05:16:37,360] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 2400527.924647619 W.
[2019-03-24 05:16:37,364] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.5, 75.5, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 7.05424320560989, 6.9112, 121.9254759529948, 2400527.924647619, 2327277.358759142, 443048.9630267978], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5416200.0000, 
sim time next is 5416800.0000, 
raw observation next is [29.66666666666667, 74.33333333333334, 1.0, 2.0, 0.7542906463099204, 1.0, 2.0, 0.690509985131395, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2363197.517827833, 2363197.517827833, 444147.4993900455], 
processed observation next is [1.0, 0.6956521739130435, 0.6543209876543211, 0.7433333333333334, 1.0, 1.0, 0.7074888646546671, 1.0, 1.0, 0.6315595061088036, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.8439991135099404, 0.8439991135099404, 0.8541298065193182], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7329974], dtype=float32), 0.56530786]. 
=============================================
[2019-03-24 05:16:37,374] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2264176: loss -7.2578
[2019-03-24 05:16:37,376] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2264177: learning rate 0.0000
[2019-03-24 05:16:37,609] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2264295: loss 7.5344
[2019-03-24 05:16:37,610] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2264295: learning rate 0.0000
[2019-03-24 05:16:37,655] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2264317: loss 20.1955
[2019-03-24 05:16:37,659] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2264318: learning rate 0.0000
[2019-03-24 05:16:37,727] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2264356: loss -6.8963
[2019-03-24 05:16:37,730] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2264358: learning rate 0.0000
[2019-03-24 05:16:37,899] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2264443: loss 12.2903
[2019-03-24 05:16:37,900] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2264443: learning rate 0.0000
[2019-03-24 05:16:38,265] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2264630: loss -1.1058
[2019-03-24 05:16:38,267] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2264631: learning rate 0.0000
[2019-03-24 05:16:38,651] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2264828: loss -2.0981
[2019-03-24 05:16:38,653] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2264828: learning rate 0.0000
[2019-03-24 05:16:39,055] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2265026: loss -15.5298
[2019-03-24 05:16:39,056] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2265027: learning rate 0.0000
[2019-03-24 05:16:39,388] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2265198: loss 9.6940
[2019-03-24 05:16:39,390] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2265200: learning rate 0.0000
[2019-03-24 05:16:39,398] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2265204: loss -9.8478
[2019-03-24 05:16:39,399] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2265204: learning rate 0.0000
[2019-03-24 05:16:40,313] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.1566718e-01 2.8189286e-09 6.8433285e-01 2.3083543e-10 6.7499517e-09], sum to 1.0000
[2019-03-24 05:16:40,325] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8644
[2019-03-24 05:16:40,334] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.13333333333334, 92.66666666666667, 1.0, 2.0, 0.4420810980985738, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7038075057491474, 6.911199999999997, 6.9112, 121.9260426156618, 1007832.794820751, 1007832.794820752, 237448.1412700256], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5469600.0000, 
sim time next is 5470200.0000, 
raw observation next is [27.2, 92.5, 1.0, 2.0, 0.4664572912628698, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7426151991438946, 6.9112, 6.9112, 121.9260426156618, 1063442.89651391, 1063442.89651391, 245502.2348985731], 
processed observation next is [1.0, 0.30434782608695654, 0.5629629629629629, 0.925, 1.0, 1.0, 0.3648301086462736, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6782689989298681, 0.0, 0.0, 0.8094621288201359, 0.37980103446925356, 0.37980103446925356, 0.472119682497256], 
reward next is 0.5279, 
noisyNet noise sample is [array([-0.09626323], dtype=float32), -0.19977166]. 
=============================================
[2019-03-24 05:16:40,504] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2265761: loss 12.5934
[2019-03-24 05:16:40,506] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2265761: learning rate 0.0000
[2019-03-24 05:16:40,735] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9999738e-01 8.0453836e-17 2.6006637e-06 7.9975263e-17 2.1259136e-14], sum to 1.0000
[2019-03-24 05:16:40,743] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4137
[2019-03-24 05:16:40,749] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 880953.5743871881 W.
[2019-03-24 05:16:40,752] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.56666666666667, 88.0, 1.0, 2.0, 0.3864580981799202, 1.0, 1.0, 0.3864580981799202, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 880953.5743871881, 880953.5743871881, 202504.2459735904], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5438400.0000, 
sim time next is 5439000.0000, 
raw observation next is [27.48333333333333, 88.5, 1.0, 2.0, 0.3863552717815713, 1.0, 2.0, 0.3863552717815713, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 880719.0409865915, 880719.040986591, 202476.4411744147], 
processed observation next is [1.0, 0.9565217391304348, 0.5734567901234567, 0.885, 1.0, 1.0, 0.26947056164472777, 1.0, 1.0, 0.26947056164472777, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31454251463806837, 0.3145425146380682, 0.38937777148925906], 
reward next is 0.6106, 
noisyNet noise sample is [array([0.31957468], dtype=float32), -1.4711057]. 
=============================================
[2019-03-24 05:16:40,768] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[43.301136]
 [43.738636]
 [43.752987]
 [44.82564 ]
 [44.9109  ]], R is [[43.53702164]
 [43.10165024]
 [42.67063522]
 [42.85417938]
 [43.00140381]].
[2019-03-24 05:16:51,424] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.9600588e-30 0.0000000e+00 1.9459858e-13 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-24 05:16:51,431] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2362
[2019-03-24 05:16:51,438] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.83333333333334, 91.66666666666667, 1.0, 2.0, 0.1971803316310262, 1.0, 2.0, 0.1971803316310262, 1.0, 2.0, 0.3139372205622753, 6.9112, 6.9112, 121.94756008, 675036.8108268143, 675036.8108268143, 219679.5432790451], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5698200.0000, 
sim time next is 5698800.0000, 
raw observation next is [23.6, 92.0, 1.0, 2.0, 0.1934359302236136, 1.0, 2.0, 0.1934359302236136, 1.0, 2.0, 0.3080652640548269, 6.9112, 6.9112, 121.94756008, 665046.9849647664, 665046.9849647664, 218471.1905377176], 
processed observation next is [0.0, 1.0, 0.4296296296296297, 0.92, 1.0, 1.0, 0.03980467883763524, 1.0, 1.0, 0.03980467883763524, 1.0, 1.0, 0.13508158006853363, 0.0, 0.0, 0.8096049824067558, 0.23751678034455945, 0.23751678034455945, 0.42013690488022615], 
reward next is 0.5799, 
noisyNet noise sample is [array([1.3640075], dtype=float32), -0.95589525]. 
=============================================
[2019-03-24 05:16:52,108] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2271680: loss 3.4463
[2019-03-24 05:16:52,110] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2271680: learning rate 0.0000
[2019-03-24 05:16:52,534] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2271900: loss -0.5343
[2019-03-24 05:16:52,538] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2271901: learning rate 0.0000
[2019-03-24 05:16:52,717] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2271988: loss 0.3240
[2019-03-24 05:16:52,718] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2271988: loss 0.0975
[2019-03-24 05:16:52,721] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2271988: learning rate 0.0000
[2019-03-24 05:16:52,723] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2271989: learning rate 0.0000
[2019-03-24 05:16:52,960] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2272116: loss 0.0242
[2019-03-24 05:16:52,961] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2272116: learning rate 0.0000
[2019-03-24 05:16:53,224] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2272251: loss 0.0330
[2019-03-24 05:16:53,226] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2272252: learning rate 0.0000
[2019-03-24 05:16:53,250] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2272262: loss 0.0233
[2019-03-24 05:16:53,252] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2272264: learning rate 0.0000
[2019-03-24 05:16:53,288] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2272285: loss 0.0627
[2019-03-24 05:16:53,290] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2272285: learning rate 0.0000
[2019-03-24 05:16:53,498] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2272392: loss 0.0637
[2019-03-24 05:16:53,500] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2272393: learning rate 0.0000
[2019-03-24 05:16:53,735] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2272516: loss 0.0724
[2019-03-24 05:16:53,736] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2272516: learning rate 0.0000
[2019-03-24 05:16:53,745] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999416e-01 8.0796117e-19 5.8991291e-06 2.6772088e-20 3.3751479e-13], sum to 1.0000
[2019-03-24 05:16:53,755] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4665
[2019-03-24 05:16:53,761] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1502232.714430367 W.
[2019-03-24 05:16:53,766] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.86666666666667, 68.66666666666667, 1.0, 2.0, 0.6842054277058599, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9890691388239234, 6.911199999999999, 6.9112, 121.9260426156618, 1502232.714430367, 1502232.714430367, 312871.409922177], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6002400.0000, 
sim time next is 6003000.0000, 
raw observation next is [27.15, 68.0, 1.0, 2.0, 0.7103205293080678, 1.0, 1.0, 0.7103205293080678, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1621851.587294205, 1621851.587294205, 308186.0105062724], 
processed observation next is [1.0, 0.4782608695652174, 0.561111111111111, 0.68, 1.0, 1.0, 0.6551434872715093, 1.0, 0.5, 0.6551434872715093, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5792327097479304, 0.5792327097479304, 0.5926654048197546], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04304289], dtype=float32), -1.761727]. 
=============================================
[2019-03-24 05:16:53,781] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[37.47164 ]
 [38.008038]
 [37.65497 ]
 [36.736855]
 [36.719383]], R is [[36.39869308]
 [36.43302917]
 [36.49719238]
 [36.13222122]
 [35.77090073]].
[2019-03-24 05:16:54,101] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2272695: loss 0.0114
[2019-03-24 05:16:54,102] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2272695: learning rate 0.0000
[2019-03-24 05:16:54,254] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999940e-01 1.7670894e-18 6.4972471e-07 5.2903465e-18 2.9716041e-10], sum to 1.0000
[2019-03-24 05:16:54,264] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7315
[2019-03-24 05:16:54,273] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1649298.644835864 W.
[2019-03-24 05:16:54,277] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 59.5, 1.0, 2.0, 0.4821060815164377, 1.0, 2.0, 0.4821060815164377, 1.0, 2.0, 0.7675285828730931, 6.911199999999999, 6.9112, 121.94756008, 1649298.644835864, 1649298.644835865, 334893.3303101748], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6011400.0000, 
sim time next is 6012000.0000, 
raw observation next is [29.0, 59.0, 1.0, 2.0, 0.9366439663815501, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1782915.023737601, 1782915.023737601, 364992.7264523261], 
processed observation next is [1.0, 0.6086956521739131, 0.6296296296296297, 0.59, 1.0, 1.0, 0.9245761504542264, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.6367553656205718, 0.6367553656205718, 0.7019090893313964], 
reward next is 0.2981, 
noisyNet noise sample is [array([0.0089092], dtype=float32), 0.28290132]. 
=============================================
[2019-03-24 05:16:54,287] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[41.581146]
 [41.265896]
 [41.067635]
 [41.820423]
 [42.271114]], R is [[41.46265793]
 [41.40400696]
 [40.98996735]
 [40.92082977]
 [40.84585571]].
[2019-03-24 05:16:54,287] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2272788: loss -41.8768
[2019-03-24 05:16:54,288] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2272788: learning rate 0.0000
[2019-03-24 05:16:54,560] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2272932: loss 0.1124
[2019-03-24 05:16:54,564] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2272934: learning rate 0.0000
[2019-03-24 05:16:54,645] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2272971: loss 0.0743
[2019-03-24 05:16:54,646] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2272971: learning rate 0.0000
[2019-03-24 05:16:55,064] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2273192: loss 0.1942
[2019-03-24 05:16:55,067] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2273193: learning rate 0.0000
[2019-03-24 05:16:56,764] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2274066: loss 1.1784
[2019-03-24 05:16:56,769] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2274066: learning rate 0.0000
[2019-03-24 05:16:57,529] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.00000000e+00 0.00000000e+00 1.13781924e-20 0.00000000e+00
 9.78982485e-26], sum to 1.0000
[2019-03-24 05:16:57,532] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3878
[2019-03-24 05:16:57,536] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8176845592836358, 6.9112, 6.9112, 121.9260426156618, 605900.0601867997, 605900.0601867997, 163187.6745062668], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5785200.0000, 
sim time next is 5785800.0000, 
raw observation next is [23.51666666666667, 85.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.813197926643459, 6.9112, 6.9112, 121.9260426156618, 602931.3516543022, 602931.3516543022, 162473.5273976598], 
processed observation next is [0.0, 1.0, 0.4265432098765433, 0.8500000000000001, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7664974083043238, 0.0, 0.0, 0.8094621288201359, 0.21533262559082222, 0.21533262559082222, 0.31244909114934577], 
reward next is 0.6876, 
noisyNet noise sample is [array([0.66429377], dtype=float32), 0.9266928]. 
=============================================
[2019-03-24 05:16:58,580] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 05:16:58,581] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:16:58,582] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:16:58,584] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:16:58,584] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:16:58,586] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:16:58,587] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:16:58,587] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:16:58,588] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:16:58,589] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:16:58,590] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:16:58,607] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run92
[2019-03-24 05:16:58,629] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run92
[2019-03-24 05:16:58,630] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run92
[2019-03-24 05:16:58,630] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run92
[2019-03-24 05:16:58,658] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run92
[2019-03-24 05:17:16,951] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06481653], dtype=float32), 0.4671723]
[2019-03-24 05:17:16,952] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.39478754666667, 91.19592807666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.549356676771959, 6.911199999999999, 6.9112, 121.9260426156618, 403269.3498479495, 403269.3498479499, 123177.3737466266]
[2019-03-24 05:17:16,955] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:17:16,957] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.3020416e-33 5.1758641e-12 1.6342587e-35 6.3261268e-23], sampled 0.48989893045696276
[2019-03-24 05:17:31,278] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06481653], dtype=float32), 0.4671723]
[2019-03-24 05:17:31,279] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 77.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6701947542863924, 6.911199999999999, 6.9112, 121.9260426156618, 500778.1510590492, 500778.1510590496, 142040.8445014114]
[2019-03-24 05:17:31,280] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:17:31,282] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.5377108e-31 5.3147025e-11 4.3837630e-33 2.8449767e-23], sampled 0.019099245583768965
[2019-03-24 05:17:35,669] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06481653], dtype=float32), 0.4671723]
[2019-03-24 05:17:35,669] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.68328943, 55.56486204666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6796758434389353, 6.911200000000001, 6.9112, 121.9260426156618, 507910.6733729094, 507910.6733729089, 142642.7346444271]
[2019-03-24 05:17:35,671] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:17:35,673] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.0507655e-34 3.1208963e-12 3.6557444e-36 1.8077426e-23], sampled 0.5667491892527068
[2019-03-24 05:17:39,186] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06481653], dtype=float32), 0.4671723]
[2019-03-24 05:17:39,187] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.351906515, 52.17043783, 1.0, 2.0, 0.9879174872009139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.070220307568015, 6.9112, 121.9253980790818, 1207679.624089889, 1126247.444017759, 237820.7876961698]
[2019-03-24 05:17:39,189] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:17:39,192] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 5.0561123e-30 7.5316753e-11 1.1056367e-31 1.5601830e-19], sampled 0.6524040950104748
[2019-03-24 05:17:39,194] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1207679.624089889 W.
[2019-03-24 05:17:54,056] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06481653], dtype=float32), 0.4671723]
[2019-03-24 05:17:54,058] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.83333333333334, 88.16666666666666, 1.0, 2.0, 0.6567923862989873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 748533.4759777022, 748533.4759777022, 168124.9407285711]
[2019-03-24 05:17:54,060] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:17:54,064] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.1821926e-31 2.6158971e-11 4.3545296e-33 9.1126300e-19], sampled 0.7787441696280085
[2019-03-24 05:17:54,067] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 748533.4759777022 W.
[2019-03-24 05:18:39,118] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06481653], dtype=float32), 0.4671723]
[2019-03-24 05:18:39,119] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.33333333333333, 96.0, 1.0, 2.0, 0.6762571856433026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 770728.2809810749, 770728.2809810744, 171699.0749998694]
[2019-03-24 05:18:39,120] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:18:39,123] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.0736641e-32 1.7184750e-11 5.5684843e-34 2.0894865e-17], sampled 0.8730764175959822
[2019-03-24 05:18:39,125] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 770728.2809810749 W.
[2019-03-24 05:18:49,521] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:18:49,571] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:18:49,703] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 05:18:49,740] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:18:49,746] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 05:18:50,761] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2275000, evaluation results [2275000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:18:52,552] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 4.4120960e-27 2.6879035e-12 1.7845530e-27 9.9089962e-20], sum to 1.0000
[2019-03-24 05:18:52,560] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6180
[2019-03-24 05:18:52,566] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1275365.636533163 W.
[2019-03-24 05:18:52,576] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 43.0, 1.0, 2.0, 0.5244317990268925, 1.0, 2.0, 0.5244317990268925, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1275365.636533163, 1275365.636533164, 246298.5583080775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5846400.0000, 
sim time next is 5847000.0000, 
raw observation next is [28.03333333333333, 42.66666666666667, 1.0, 2.0, 0.9645688640761257, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.429059023153974, 6.9112, 121.9238680216044, 1458015.923555087, 1192830.547745234, 236410.9256787712], 
processed observation next is [1.0, 0.6956521739130435, 0.5938271604938271, 0.4266666666666667, 1.0, 1.0, 0.9578200762811021, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.05178590231539744, 0.0, 0.8094476917770133, 0.5207199726982453, 0.4260109099090122, 0.45463639553609847], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.46819884], dtype=float32), 1.6927918]. 
=============================================
[2019-03-24 05:18:52,591] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[52.009403]
 [51.906155]
 [51.64281 ]
 [51.25223 ]
 [50.378124]], R is [[51.54523468]
 [51.02978134]
 [50.51948547]
 [50.01428986]
 [49.51414871]].
[2019-03-24 05:18:59,737] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2279622: loss 36.8310
[2019-03-24 05:18:59,739] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2279622: learning rate 0.0000
[2019-03-24 05:19:00,153] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2279834: loss 49.0421
[2019-03-24 05:19:00,156] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2279834: learning rate 0.0000
[2019-03-24 05:19:00,425] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2279975: loss 41.0037
[2019-03-24 05:19:00,426] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2279975: learning rate 0.0000
[2019-03-24 05:19:00,805] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2280169: loss 65.6917
[2019-03-24 05:19:00,806] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2280170: learning rate 0.0000
[2019-03-24 05:19:00,871] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2280197: loss 23.9392
[2019-03-24 05:19:00,873] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2280198: learning rate 0.0000
[2019-03-24 05:19:01,000] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2280265: loss 26.9774
[2019-03-24 05:19:01,003] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2280265: learning rate 0.0000
[2019-03-24 05:19:01,051] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2280290: loss -1.5880
[2019-03-24 05:19:01,053] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2280292: learning rate 0.0000
[2019-03-24 05:19:01,076] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2280304: loss 30.1527
[2019-03-24 05:19:01,078] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2280305: learning rate 0.0000
[2019-03-24 05:19:01,183] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2280361: loss -3.1044
[2019-03-24 05:19:01,186] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2280361: learning rate 0.0000
[2019-03-24 05:19:01,469] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2280505: loss 29.6337
[2019-03-24 05:19:01,473] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2280506: learning rate 0.0000
[2019-03-24 05:19:01,862] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2280706: loss -16.5403
[2019-03-24 05:19:01,865] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2280706: learning rate 0.0000
[2019-03-24 05:19:02,113] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2280833: loss 2.0526
[2019-03-24 05:19:02,119] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2280834: learning rate 0.0000
[2019-03-24 05:19:02,225] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2280894: loss 16.1522
[2019-03-24 05:19:02,227] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2280894: learning rate 0.0000
[2019-03-24 05:19:02,473] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2281017: loss 2.9716
[2019-03-24 05:19:02,477] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2281017: learning rate 0.0000
[2019-03-24 05:19:02,585] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2281076: loss 9.6232
[2019-03-24 05:19:02,587] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2281076: learning rate 0.0000
[2019-03-24 05:19:04,410] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2282015: loss 33.7689
[2019-03-24 05:19:04,412] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2282016: learning rate 0.0000
[2019-03-24 05:19:12,345] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.0979366e-32 3.1795910e-17 1.3099643e-31 4.3206828e-22], sum to 1.0000
[2019-03-24 05:19:12,352] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0787
[2019-03-24 05:19:12,360] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.7, 79.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7812748837596524, 6.9112, 6.9112, 121.9260426156618, 581853.8291645476, 581853.8291645476, 157110.4603236233], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6229800.0000, 
sim time next is 6230400.0000, 
raw observation next is [23.6, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7797474906185493, 6.911199999999999, 6.9112, 121.9260426156618, 580811.0063003647, 580811.0063003651, 156857.3412731613], 
processed observation next is [0.0, 0.08695652173913043, 0.4296296296296297, 0.8, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7246843632731866, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20743250225013027, 0.20743250225013038, 0.30164873321761787], 
reward next is 0.6984, 
noisyNet noise sample is [array([1.5531361], dtype=float32), 1.4906317]. 
=============================================
[2019-03-24 05:19:14,933] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.8501565e-27 4.9446506e-12 4.9157549e-30 5.1393640e-21], sum to 1.0000
[2019-03-24 05:19:14,940] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9032
[2019-03-24 05:19:14,947] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.45, 81.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8445486657833952, 6.9112, 6.9112, 121.9260426156618, 623702.0935820574, 623702.0935820574, 167292.2191425782], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6250200.0000, 
sim time next is 6250800.0000, 
raw observation next is [24.6, 81.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8501832236186013, 6.911200000000001, 6.9112, 121.9260426156618, 627156.2633626353, 627156.2633626348, 168222.4652851059], 
processed observation next is [0.0, 0.34782608695652173, 0.46666666666666673, 0.8133333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8127290295232517, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22398437977236973, 0.22398437977236957, 0.32350474093289594], 
reward next is 0.6765, 
noisyNet noise sample is [array([0.2527875], dtype=float32), -0.84697807]. 
=============================================
[2019-03-24 05:19:15,112] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2287483: loss 0.2447
[2019-03-24 05:19:15,113] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2287483: learning rate 0.0000
[2019-03-24 05:19:15,755] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2287810: loss 1.5812
[2019-03-24 05:19:15,760] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2287811: learning rate 0.0000
[2019-03-24 05:19:15,909] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2287886: loss 2.4822
[2019-03-24 05:19:15,912] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2287887: learning rate 0.0000
[2019-03-24 05:19:16,239] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2288053: loss 0.9454
[2019-03-24 05:19:16,240] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2288054: learning rate 0.0000
[2019-03-24 05:19:16,260] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.9984856e-28 8.0404460e-14 1.6624821e-31 2.8106642e-22], sum to 1.0000
[2019-03-24 05:19:16,270] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7413
[2019-03-24 05:19:16,278] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.66666666666666, 87.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7765009641308678, 6.9112, 6.9112, 121.9260426156618, 578154.268150666, 578154.268150666, 156630.3738074611], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6241200.0000, 
sim time next is 6241800.0000, 
raw observation next is [22.78333333333333, 87.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7805837418622092, 6.911199999999999, 6.9112, 121.9260426156618, 580924.4625643286, 580924.462564329, 157301.5013304281], 
processed observation next is [0.0, 0.21739130434782608, 0.39938271604938264, 0.8733333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7257296773277616, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20747302234440307, 0.20747302234440324, 0.30250288717390017], 
reward next is 0.6975, 
noisyNet noise sample is [array([1.2842987], dtype=float32), 0.03717742]. 
=============================================
[2019-03-24 05:19:16,329] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2288096: loss 1.2887
[2019-03-24 05:19:16,331] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2288096: learning rate 0.0000
[2019-03-24 05:19:16,638] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2288258: loss 0.7601
[2019-03-24 05:19:16,641] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2288259: learning rate 0.0000
[2019-03-24 05:19:16,689] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2288286: loss 0.3729
[2019-03-24 05:19:16,691] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2288287: learning rate 0.0000
[2019-03-24 05:19:16,706] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2288296: loss 0.6634
[2019-03-24 05:19:16,711] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2288296: learning rate 0.0000
[2019-03-24 05:19:16,889] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2288389: loss 0.2757
[2019-03-24 05:19:16,890] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2288389: learning rate 0.0000
[2019-03-24 05:19:17,038] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2288465: loss 0.2445
[2019-03-24 05:19:17,042] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2288465: learning rate 0.0000
[2019-03-24 05:19:17,575] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2288743: loss 0.4455
[2019-03-24 05:19:17,576] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2288743: learning rate 0.0000
[2019-03-24 05:19:17,866] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2288888: loss 0.2901
[2019-03-24 05:19:17,870] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2288889: learning rate 0.0000
[2019-03-24 05:19:17,981] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2288944: loss 0.3747
[2019-03-24 05:19:17,982] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2288944: learning rate 0.0000
[2019-03-24 05:19:18,198] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2289057: loss 0.4532
[2019-03-24 05:19:18,201] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2289058: learning rate 0.0000
[2019-03-24 05:19:18,435] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2289174: loss 120.0298
[2019-03-24 05:19:18,437] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2289175: learning rate 0.0000
[2019-03-24 05:19:18,872] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 6.0565146e-33 7.4286047e-20 6.3350026e-34 1.7723314e-23], sum to 1.0000
[2019-03-24 05:19:18,886] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7373
[2019-03-24 05:19:18,886] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1236164.419775263 W.
[2019-03-24 05:19:18,896] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.21666666666667, 39.5, 1.0, 2.0, 0.503766922940076, 1.0, 2.0, 0.503766922940076, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426068005, 1236164.419775263, 1236164.419775263, 239992.0203243358], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6619800.0000, 
sim time next is 6620400.0000, 
raw observation next is [29.0, 37.0, 1.0, 2.0, 0.3469162248734056, 1.0, 2.0, 0.3469162248734056, 1.0, 1.0, 0.5651333421500303, 6.9112, 6.9112, 121.94756008, 1265947.837576803, 1265947.837576803, 273580.5945684802], 
processed observation next is [1.0, 0.6521739130434783, 0.6296296296296297, 0.37, 1.0, 1.0, 0.22251931532548289, 1.0, 1.0, 0.22251931532548289, 1.0, 0.5, 0.45641667768753785, 0.0, 0.0, 0.8096049824067558, 0.4521242277060011, 0.4521242277060011, 0.5261165280163081], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9417517], dtype=float32), -1.7680501]. 
=============================================
[2019-03-24 05:19:19,835] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2289894: loss 0.0836
[2019-03-24 05:19:19,838] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2289895: learning rate 0.0000
[2019-03-24 05:19:24,087] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.1519806e-21 3.7719317e-11 3.1829427e-23 6.4140137e-13], sum to 1.0000
[2019-03-24 05:19:24,093] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3282
[2019-03-24 05:19:24,103] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2115047.376696494 W.
[2019-03-24 05:19:24,110] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.45, 55.0, 1.0, 2.0, 0.9271318043878386, 1.0, 2.0, 0.9271318043878386, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2115047.376696494, 2115047.376696495, 399087.2295202926], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6454200.0000, 
sim time next is 6454800.0000, 
raw observation next is [31.4, 55.0, 1.0, 2.0, 0.9332857253786667, 1.0, 2.0, 0.9332857253786667, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2129102.932018326, 2129102.932018326, 401907.757995318], 
processed observation next is [1.0, 0.7391304347826086, 0.7185185185185184, 0.55, 1.0, 1.0, 0.9205782444984127, 1.0, 1.0, 0.9205782444984127, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7603939042922593, 0.7603939042922593, 0.7728995346063807], 
reward next is 0.2271, 
noisyNet noise sample is [array([0.5446773], dtype=float32), -2.036518]. 
=============================================
[2019-03-24 05:19:24,769] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.1217603e-24 4.7910132e-15 2.3911873e-26 5.0823492e-09], sum to 1.0000
[2019-03-24 05:19:24,777] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5668
[2019-03-24 05:19:24,782] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 777537.9510312425 W.
[2019-03-24 05:19:24,785] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.85, 65.5, 1.0, 2.0, 0.6822291395909101, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777537.9510312425, 777537.9510312425, 172806.8485131573], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6467400.0000, 
sim time next is 6468000.0000, 
raw observation next is [29.73333333333333, 66.0, 1.0, 2.0, 0.3416389465057337, 1.0, 1.0, 0.3416389465057337, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 778733.8246289599, 778733.8246289599, 190753.636399894], 
processed observation next is [1.0, 0.8695652173913043, 0.65679012345679, 0.66, 1.0, 1.0, 0.2162368410782544, 1.0, 0.5, 0.2162368410782544, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2781192230817714, 0.2781192230817714, 0.3668339161536423], 
reward next is 0.6332, 
noisyNet noise sample is [array([2.1929605], dtype=float32), -1.8506111]. 
=============================================
[2019-03-24 05:19:24,800] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[47.547905]
 [47.5847  ]
 [46.80883 ]
 [46.59974 ]
 [47.15078 ]], R is [[47.68395996]
 [47.87479782]
 [48.0011673 ]
 [48.08020401]
 [48.2311554 ]].
[2019-03-24 05:19:29,947] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2388759e-12 2.3365596e-28 2.2616203e-16 1.0442380e-26 1.0000000e+00], sum to 1.0000
[2019-03-24 05:19:29,956] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5103
[2019-03-24 05:19:29,961] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.3, 88.33333333333334, 1.0, 2.0, 0.3000526381546442, 1.0, 2.0, 0.3000526381546442, 1.0, 2.0, 0.4776935719743972, 6.911199999999999, 6.9112, 121.94756008, 1026077.971908323, 1026077.971908324, 256072.7595562768], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6506400.0000, 
sim time next is 6507000.0000, 
raw observation next is [26.3, 88.5, 1.0, 2.0, 0.2983195483531072, 1.0, 2.0, 0.2983195483531072, 1.0, 2.0, 0.4749344365675559, 6.911199999999999, 6.9112, 121.94756008, 1020147.449776834, 1020147.449776834, 255410.6650237596], 
processed observation next is [1.0, 0.30434782608695654, 0.5296296296296297, 0.885, 1.0, 1.0, 0.16466612899179428, 1.0, 1.0, 0.16466612899179428, 1.0, 1.0, 0.34366804570944487, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.36433837492029786, 0.36433837492029786, 0.4911743558149223], 
reward next is 0.5088, 
noisyNet noise sample is [array([-1.9748871], dtype=float32), -1.9946856]. 
=============================================
[2019-03-24 05:19:29,975] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[43.73518 ]
 [43.733173]
 [43.950504]
 [43.96444 ]
 [43.921257]], R is [[43.77732849]
 [43.84710693]
 [43.90986252]
 [43.99298096]
 [44.08811569]].
[2019-03-24 05:19:30,316] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0767360e-03 2.3680204e-24 2.8038687e-12 4.0258299e-26 9.9892324e-01], sum to 1.0000
[2019-03-24 05:19:30,323] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0408
[2019-03-24 05:19:30,330] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.56666666666667, 85.5, 1.0, 2.0, 0.2302724583625435, 1.0, 2.0, 0.2302724583625435, 1.0, 2.0, 0.3666012531635742, 6.9112, 6.9112, 121.94756008, 787330.936349938, 787330.936349938, 230738.9665457246], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6556200.0000, 
sim time next is 6556800.0000, 
raw observation next is [26.53333333333334, 85.0, 1.0, 2.0, 0.2286242509916885, 1.0, 2.0, 0.2286242509916885, 1.0, 2.0, 0.3639772533508064, 6.911199999999999, 6.9112, 121.94756008, 781692.6318273196, 781692.6318273201, 230173.4573650868], 
processed observation next is [1.0, 0.9130434782608695, 0.5382716049382718, 0.85, 1.0, 1.0, 0.08169553689486728, 1.0, 1.0, 0.08169553689486728, 1.0, 1.0, 0.20497156668850797, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.27917593993832845, 0.2791759399383286, 0.4426412641636285], 
reward next is 0.5574, 
noisyNet noise sample is [array([1.4171569], dtype=float32), 0.37689367]. 
=============================================
[2019-03-24 05:19:30,837] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2295542: loss 3.1529
[2019-03-24 05:19:30,844] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2295542: learning rate 0.0000
[2019-03-24 05:19:31,580] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2295925: loss 1.7702
[2019-03-24 05:19:31,582] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2295925: learning rate 0.0000
[2019-03-24 05:19:31,753] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2296009: loss -7.8478
[2019-03-24 05:19:31,755] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2296009: learning rate 0.0000
[2019-03-24 05:19:31,974] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2296123: loss 67.0857
[2019-03-24 05:19:31,976] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2296123: learning rate 0.0000
[2019-03-24 05:19:31,996] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2296130: loss 0.7377
[2019-03-24 05:19:31,998] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2296131: learning rate 0.0000
[2019-03-24 05:19:32,228] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2296247: loss 14.5559
[2019-03-24 05:19:32,229] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2296248: learning rate 0.0000
[2019-03-24 05:19:32,279] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2296278: loss -12.6885
[2019-03-24 05:19:32,281] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2296278: learning rate 0.0000
[2019-03-24 05:19:32,299] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2296288: loss -30.4319
[2019-03-24 05:19:32,301] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2296289: learning rate 0.0000
[2019-03-24 05:19:32,697] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2296486: loss 13.4636
[2019-03-24 05:19:32,698] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2296486: learning rate 0.0000
[2019-03-24 05:19:32,820] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2296549: loss 8.0268
[2019-03-24 05:19:32,825] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2296551: learning rate 0.0000
[2019-03-24 05:19:33,147] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2296720: loss 32.3529
[2019-03-24 05:19:33,150] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2296721: learning rate 0.0000
[2019-03-24 05:19:33,434] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2296870: loss 1.7671
[2019-03-24 05:19:33,437] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2296870: learning rate 0.0000
[2019-03-24 05:19:33,457] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2296880: loss 25.5162
[2019-03-24 05:19:33,461] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2296880: learning rate 0.0000
[2019-03-24 05:19:33,505] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2296904: loss 6.4518
[2019-03-24 05:19:33,512] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2296905: learning rate 0.0000
[2019-03-24 05:19:33,728] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2297012: loss 3.7910
[2019-03-24 05:19:33,730] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2297012: learning rate 0.0000
[2019-03-24 05:19:35,046] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 9.9381852e-27 3.6695877e-15 3.5983798e-29 2.1216140e-17], sum to 1.0000
[2019-03-24 05:19:35,053] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9591
[2019-03-24 05:19:35,057] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 45.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6274854417293705, 6.911200000000001, 6.9112, 121.9260426156618, 448057.2733211736, 448057.2733211732, 121047.2825815713], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6665400.0000, 
sim time next is 6666000.0000, 
raw observation next is [23.0, 45.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5884131466778026, 6.911199999999999, 6.9112, 121.9260426156618, 420149.9774547277, 420149.9774547282, 117367.4883163293], 
processed observation next is [1.0, 0.13043478260869565, 0.4074074074074074, 0.4533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.48551643334725325, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15005356337668846, 0.15005356337668865, 0.22570670830063327], 
reward next is 0.7743, 
noisyNet noise sample is [array([1.877325], dtype=float32), 0.18392937]. 
=============================================
[2019-03-24 05:19:35,076] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[63.142387]
 [63.7322  ]
 [64.1936  ]
 [64.48545 ]
 [64.383865]], R is [[62.93920135]
 [63.07702637]
 [63.21350479]
 [63.34274673]
 [63.49187469]].
[2019-03-24 05:19:35,504] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2297917: loss 4.3178
[2019-03-24 05:19:35,508] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2297917: learning rate 0.0000
[2019-03-24 05:19:37,864] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.1906835e-16 6.4275530e-26 2.3808985e-14 3.0800853e-24 1.0000000e+00], sum to 1.0000
[2019-03-24 05:19:37,870] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7281
[2019-03-24 05:19:37,874] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.75, 34.5, 1.0, 2.0, 0.3025738008332723, 1.0, 2.0, 0.3025738008332723, 1.0, 2.0, 0.5026272507738893, 6.9112, 6.9112, 121.94756008, 1126189.315597682, 1126189.315597682, 254829.6222882349], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6695400.0000, 
sim time next is 6696000.0000, 
raw observation next is [27.9, 34.0, 1.0, 2.0, 0.2821166240783079, 1.0, 2.0, 0.2821166240783079, 1.0, 2.0, 0.4689515575789887, 6.911199999999999, 6.9112, 121.94756008, 1050553.608555172, 1050553.608555172, 247052.2669251956], 
processed observation next is [1.0, 0.5217391304347826, 0.5888888888888888, 0.34, 1.0, 1.0, 0.14537693342655703, 1.0, 1.0, 0.14537693342655703, 1.0, 1.0, 0.3361894469737359, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3751977173411329, 0.3751977173411329, 0.4751005133176839], 
reward next is 0.5249, 
noisyNet noise sample is [array([0.48749104], dtype=float32), 3.0390382]. 
=============================================
[2019-03-24 05:19:37,888] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[47.063843]
 [46.79037 ]
 [46.455418]
 [46.071815]
 [45.730087]], R is [[47.54210663]
 [47.57662964]
 [47.61214447]
 [47.65053177]
 [47.6923027 ]].
[2019-03-24 05:19:39,121] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5928886e-04 5.9568957e-13 2.0564323e-06 4.4592628e-13 9.9983859e-01], sum to 1.0000
[2019-03-24 05:19:39,132] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9334
[2019-03-24 05:19:39,140] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.03333333333333, 54.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 424591.1655910579, 424591.1655910579, 182003.4032874994], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6729000.0000, 
sim time next is 6729600.0000, 
raw observation next is [23.76666666666667, 56.33333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 427445.7938872332, 427445.7938872332, 182540.0934016555], 
processed observation next is [1.0, 0.9130434782608695, 0.43580246913580256, 0.5633333333333335, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8096049824067558, 0.1526592121025833, 0.1526592121025833, 0.3510386411570298], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9110985], dtype=float32), -0.80367917]. 
=============================================
[2019-03-24 05:19:39,468] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 05:19:39,470] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:19:39,472] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:19:39,473] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:19:39,474] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:19:39,474] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:19:39,475] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:19:39,475] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:19:39,476] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:19:39,476] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:19:39,478] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:19:39,495] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run93
[2019-03-24 05:19:39,518] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run93
[2019-03-24 05:19:39,544] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run93
[2019-03-24 05:19:39,569] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run93
[2019-03-24 05:19:39,590] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run93
[2019-03-24 05:19:42,436] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06564483], dtype=float32), 0.46389753]
[2019-03-24 05:19:42,437] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [14.7, 66.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3382945531185632, 6.9112, 6.9112, 121.9260426156618, 241527.4074192781, 241527.4074192781, 75334.25100395115]
[2019-03-24 05:19:42,437] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:19:42,441] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9118680e-01 1.6432395e-11 4.9181494e-06 3.1366442e-12 8.8082543e-03], sampled 0.0355100571856376
[2019-03-24 05:20:07,077] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06564483], dtype=float32), 0.46389753]
[2019-03-24 05:20:07,079] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.5, 92.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2027031120893407, 6.9112, 6.9112, 121.94756008, 454202.2073783344, 454202.2073783344, 188173.4818278402]
[2019-03-24 05:20:07,080] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:20:07,083] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.5238086e-01 9.3806574e-10 8.8162597e-05 4.8596543e-10 4.4753093e-01], sampled 0.22102110231041616
[2019-03-24 05:20:17,999] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06564483], dtype=float32), 0.46389753]
[2019-03-24 05:20:18,001] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.15148913, 54.93795031833333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.69245416435151, 6.911200000000001, 6.9112, 121.9260426156618, 517397.6402051327, 517397.6402051322, 144541.1205276877]
[2019-03-24 05:20:18,002] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:20:18,004] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9999988e-01 1.8195330e-14 1.5247760e-07 6.1946616e-16 1.4830485e-08], sampled 0.4257559027032468
[2019-03-24 05:20:44,136] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06564483], dtype=float32), 0.46389753]
[2019-03-24 05:20:44,139] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.66518236, 105.893596125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8064706120714612, 6.9112, 6.9112, 121.9260426156618, 598784.7077353828, 598784.7077353828, 161251.3985720975]
[2019-03-24 05:20:44,140] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:20:44,143] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9999940e-01 3.1573902e-14 5.7190715e-07 1.1376827e-15 5.8195746e-09], sampled 0.5902864679188673
[2019-03-24 05:21:11,645] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06564483], dtype=float32), 0.46389753]
[2019-03-24 05:21:11,646] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.75, 89.0, 1.0, 2.0, 0.1947618927300283, 1.0, 2.0, 0.1947618927300283, 1.0, 2.0, 0.3100672761782267, 6.911199999999999, 6.9112, 121.94756008, 665863.0543440199, 665863.0543440203, 218891.4383494323]
[2019-03-24 05:21:11,648] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:21:11,652] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.5380304e-01 4.2020470e-10 5.6553283e-05 2.7166028e-10 7.4614042e-01], sampled 0.4727454338196627
[2019-03-24 05:21:29,695] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 6459.4564 2885256026.3588 84.0000
[2019-03-24 05:21:29,800] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 6577.5109 2677416332.8679 116.0000
[2019-03-24 05:21:29,859] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 7237.2655 2664737167.5841 70.0000
[2019-03-24 05:21:29,882] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7337.3748 2627579877.3697 58.0000
[2019-03-24 05:21:29,912] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 6776.1369 2624530897.3998 88.0000
[2019-03-24 05:21:30,930] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2300000, evaluation results [2300000.0, 6459.456379554747, 2885256026.3588185, 84.0, 7337.374756002504, 2627579877.3696895, 58.0, 6776.136915267265, 2624530897.399768, 88.0, 7237.265490884638, 2664737167.584103, 70.0, 6577.510908044838, 2677416332.867945, 116.0]
[2019-03-24 05:21:31,877] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0831965e-09 1.6095035e-13 6.6533545e-07 1.3369798e-13 9.9999928e-01], sum to 1.0000
[2019-03-24 05:21:31,883] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4585
[2019-03-24 05:21:31,887] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.43333333333333, 55.0, 1.0, 2.0, 0.2611363443847471, 1.0, 2.0, 0.2611363443847471, 1.0, 2.0, 0.4299641647075947, 6.9112, 6.9112, 121.94756008, 964193.4890694491, 964193.4890694491, 239902.6174085821], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6774000.0000, 
sim time next is 6774600.0000, 
raw observation next is [24.61666666666667, 54.5, 1.0, 2.0, 0.2687003613946894, 1.0, 2.0, 0.2687003613946894, 1.0, 2.0, 0.4416124062667625, 6.9112, 6.9112, 121.94756008, 990332.4370013068, 990332.4370013068, 242754.2317278171], 
processed observation next is [1.0, 0.391304347826087, 0.4672839506172841, 0.545, 1.0, 1.0, 0.12940519213653498, 1.0, 1.0, 0.12940519213653498, 1.0, 1.0, 0.3020155078334531, 0.0, 0.0, 0.8096049824067558, 0.3536901560718953, 0.3536901560718953, 0.46683506101503286], 
reward next is 0.5332, 
noisyNet noise sample is [array([1.3552798], dtype=float32), -0.17186463]. 
=============================================
[2019-03-24 05:21:33,959] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3563946e-27 0.0000000e+00 4.5250750e-26 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-24 05:21:33,968] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6919
[2019-03-24 05:21:33,973] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.06666666666667, 55.33333333333333, 1.0, 2.0, 0.4116519624581012, 1.0, 2.0, 0.4116519624581012, 1.0, 2.0, 0.6561738973963869, 6.911199999999999, 6.9112, 121.94756008, 1426874.886070156, 1426874.886070156, 302307.0772550676], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6799200.0000, 
sim time next is 6799800.0000, 
raw observation next is [28.08333333333334, 55.66666666666667, 1.0, 2.0, 0.4139060852581423, 1.0, 2.0, 0.4139060852581423, 1.0, 2.0, 0.6596252121361121, 6.9112, 6.9112, 121.94756008, 1432497.885527371, 1432497.885527371, 303308.0757460689], 
processed observation next is [1.0, 0.6956521739130435, 0.5956790123456792, 0.5566666666666668, 1.0, 1.0, 0.30226914911683606, 1.0, 1.0, 0.30226914911683606, 1.0, 1.0, 0.5745315151701401, 0.0, 0.0, 0.8096049824067558, 0.5116063876883468, 0.5116063876883468, 0.5832847610501325], 
reward next is 0.4167, 
noisyNet noise sample is [array([0.11852986], dtype=float32), 0.18755879]. 
=============================================
[2019-03-24 05:21:34,377] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.1369951e-34 0.0000000e+00 1.6207455e-32 0.0000000e+00 1.0000000e+00], sum to 1.0000
[2019-03-24 05:21:34,384] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9106
[2019-03-24 05:21:34,388] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.93333333333333, 56.83333333333334, 1.0, 2.0, 0.2116694113337617, 1.0, 2.0, 0.2116694113337617, 1.0, 2.0, 0.33775942242254, 6.9112, 6.9112, 121.94756008, 737865.9211856195, 737865.9211856195, 224408.6588155194], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6801000.0000, 
sim time next is 6801600.0000, 
raw observation next is [27.76666666666667, 57.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.255441118703535, 6.911199999999999, 6.9112, 121.94756008, 562152.6128064838, 562152.6128064842, 207663.381349503], 
processed observation next is [1.0, 0.7391304347826086, 0.5839506172839507, 0.5766666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0693013983794187, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2007687902880299, 0.20076879028803007, 0.3993526564413519], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.65312564], dtype=float32), 0.5880244]. 
=============================================
[2019-03-24 05:21:35,436] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.1461668e-22 1.7511740e-32 9.0702406e-21 1.5323450e-31 1.0000000e+00], sum to 1.0000
[2019-03-24 05:21:35,446] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6290
[2019-03-24 05:21:35,459] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.33333333333333, 68.33333333333333, 1.0, 2.0, 0.1600818272620973, 1.0, 2.0, 0.1600818272620973, 1.0, 2.0, 0.2571137344495698, 6.9112, 6.9112, 121.94756008, 569996.1341542859, 569996.1341542859, 207632.3229949898], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6810000.0000, 
sim time next is 6810600.0000, 
raw observation next is [25.16666666666667, 69.16666666666667, 1.0, 2.0, 0.1606341328796748, 1.0, 2.0, 0.1606341328796748, 1.0, 2.0, 0.2580502911564269, 6.911200000000001, 6.9112, 121.94756008, 572221.7042367168, 572221.7042367164, 207790.7892720437], 
processed observation next is [1.0, 0.8260869565217391, 0.4876543209876545, 0.6916666666666668, 1.0, 1.0, 0.0007549200948509369, 1.0, 1.0, 0.0007549200948509369, 1.0, 1.0, 0.07256286394553363, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.204364894370256, 0.20436489437025585, 0.3995976716770071], 
reward next is 0.6004, 
noisyNet noise sample is [array([1.1365936], dtype=float32), -0.38925707]. 
=============================================
[2019-03-24 05:21:38,012] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2303605: loss 4.9665
[2019-03-24 05:21:38,013] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2303605: learning rate 0.0000
[2019-03-24 05:21:38,615] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2303920: loss 9.9577
[2019-03-24 05:21:38,616] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2303920: learning rate 0.0000
[2019-03-24 05:21:38,747] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2303988: loss 4.2878
[2019-03-24 05:21:38,748] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2303988: learning rate 0.0000
[2019-03-24 05:21:38,981] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2304107: loss 4.6968
[2019-03-24 05:21:38,982] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2304108: learning rate 0.0000
[2019-03-24 05:21:39,113] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2304174: loss 8.6145
[2019-03-24 05:21:39,115] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2304175: learning rate 0.0000
[2019-03-24 05:21:39,173] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2304209: loss 8.8874
[2019-03-24 05:21:39,176] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2304210: learning rate 0.0000
[2019-03-24 05:21:39,196] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2304219: loss 8.5330
[2019-03-24 05:21:39,202] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2304220: learning rate 0.0000
[2019-03-24 05:21:39,218] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2304229: loss 7.5478
[2019-03-24 05:21:39,219] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2304229: learning rate 0.0000
[2019-03-24 05:21:39,360] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.1080733e-23 1.2034401e-08 2.9967179e-25 4.6422964e-16], sum to 1.0000
[2019-03-24 05:21:39,368] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1146
[2019-03-24 05:21:39,374] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.48333333333333, 53.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.791683931130284, 6.911200000000001, 6.9112, 121.9260426156618, 588635.1604891293, 588635.1604891288, 158984.2174579172], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6887400.0000, 
sim time next is 6888000.0000, 
raw observation next is [28.36666666666667, 53.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7885594917451962, 6.911199999999999, 6.9112, 121.9260426156618, 586483.3477726496, 586483.3477726501, 158502.6598953846], 
processed observation next is [0.0, 0.7391304347826086, 0.606172839506173, 0.5366666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7356993646814952, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20945833849023202, 0.20945833849023218, 0.3048128074911242], 
reward next is 0.6952, 
noisyNet noise sample is [array([-0.25945312], dtype=float32), 0.76816165]. 
=============================================
[2019-03-24 05:21:39,391] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[66.428085]
 [66.46215 ]
 [66.41092 ]
 [66.425385]
 [66.426094]], R is [[66.43402863]
 [66.46395111]
 [66.49259186]
 [66.51964569]
 [66.54518127]].
[2019-03-24 05:21:39,668] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2304460: loss 4.0573
[2019-03-24 05:21:39,670] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2304460: learning rate 0.0000
[2019-03-24 05:21:39,860] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2304558: loss 4.5075
[2019-03-24 05:21:39,861] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2304558: learning rate 0.0000
[2019-03-24 05:21:40,198] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2304731: loss 2.8286
[2019-03-24 05:21:40,200] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2304732: learning rate 0.0000
[2019-03-24 05:21:40,419] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2304852: loss 0.5361
[2019-03-24 05:21:40,422] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2304852: learning rate 0.0000
[2019-03-24 05:21:40,523] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2304902: loss 4.3022
[2019-03-24 05:21:40,526] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2304903: learning rate 0.0000
[2019-03-24 05:21:40,580] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2304933: loss 4.0120
[2019-03-24 05:21:40,587] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2304934: learning rate 0.0000
[2019-03-24 05:21:40,623] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2304950: loss 3.8064
[2019-03-24 05:21:40,626] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2304951: learning rate 0.0000
[2019-03-24 05:21:42,638] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2305989: loss 3.6942
[2019-03-24 05:21:42,640] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2305990: learning rate 0.0000
[2019-03-24 05:21:44,051] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 2.5250120e-24 8.3363275e-11 7.6619895e-27 3.6459233e-15], sum to 1.0000
[2019-03-24 05:21:44,057] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3783
[2019-03-24 05:21:44,060] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.2, 86.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8489158799936843, 6.9112, 6.9112, 121.9260426156618, 634175.986429917, 634175.986429917, 160732.9528015999], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7012200.0000, 
sim time next is 7012800.0000, 
raw observation next is [21.1, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.817303176886527, 6.911199999999999, 6.9112, 121.9260426156618, 610530.3801565837, 610530.3801565842, 157008.8440744272], 
processed observation next is [1.0, 0.17391304347826086, 0.3370370370370371, 0.87, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7716289711081586, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21804656434163705, 0.21804656434163722, 0.30194008475851386], 
reward next is 0.6981, 
noisyNet noise sample is [array([1.4930271], dtype=float32), -0.9370077]. 
=============================================
[2019-03-24 05:21:45,853] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.5888705e-24 1.1219187e-14 7.5205068e-26 1.8199371e-20], sum to 1.0000
[2019-03-24 05:21:45,864] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5308
[2019-03-24 05:21:45,869] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.76666666666667, 89.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8127415354598186, 6.9112, 6.9112, 121.9260426156618, 607111.8351685051, 607111.8351685051, 156450.5930230848], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7015200.0000, 
sim time next is 7015800.0000, 
raw observation next is [20.68333333333333, 90.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8013253805638262, 6.911200000000001, 6.9112, 121.9260426156618, 598577.6732820427, 598577.6732820423, 155097.8298450477], 
processed observation next is [1.0, 0.17391304347826086, 0.3216049382716048, 0.9033333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7516567257047826, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2137777404578724, 0.21377774045787223, 0.2982650573943225], 
reward next is 0.7017, 
noisyNet noise sample is [array([0.17182668], dtype=float32), 1.1836574]. 
=============================================
[2019-03-24 05:21:49,537] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.8714570e-04 2.3829305e-19 7.8432339e-12 1.2879322e-22 9.9911278e-01], sum to 1.0000
[2019-03-24 05:21:49,544] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3524
[2019-03-24 05:21:49,548] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.23333333333333, 62.83333333333334, 1.0, 2.0, 0.5811395896318241, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9289839482884661, 6.911200000000002, 6.9112, 121.925764018197, 1361398.596282328, 1361398.596282327, 285901.889665904], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7044600.0000, 
sim time next is 7045200.0000, 
raw observation next is [27.4, 62.0, 1.0, 2.0, 0.3607250052878661, 1.0, 1.0, 0.3607250052878661, 1.0, 2.0, 0.5747137989220034, 6.911200000000001, 6.9112, 121.94756008, 1245527.112779602, 1245527.112779601, 280358.2119748194], 
processed observation next is [1.0, 0.5652173913043478, 0.5703703703703703, 0.62, 1.0, 1.0, 0.23895833962841204, 1.0, 0.5, 0.23895833962841204, 1.0, 1.0, 0.4683922486525042, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4448311117070007, 0.44483111170700035, 0.5391504076438836], 
reward next is 0.4608, 
noisyNet noise sample is [array([1.9810902], dtype=float32), 0.8683451]. 
=============================================
[2019-03-24 05:21:53,633] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2311651: loss -232.6411
[2019-03-24 05:21:53,634] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2311651: learning rate 0.0000
[2019-03-24 05:21:54,236] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2311968: loss -118.0941
[2019-03-24 05:21:54,237] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2311968: learning rate 0.0000
[2019-03-24 05:21:54,257] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2311976: loss -115.1424
[2019-03-24 05:21:54,264] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2311976: learning rate 0.0000
[2019-03-24 05:21:54,319] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.7477540e-02 5.2695709e-16 1.3557964e-10 1.8770770e-14 9.0252250e-01], sum to 1.0000
[2019-03-24 05:21:54,328] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8501
[2019-03-24 05:21:54,332] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 72.33333333333333, 1.0, 2.0, 0.3235049558176253, 1.0, 1.0, 0.3235049558176253, 1.0, 2.0, 0.519682213859861, 6.9112, 6.9112, 121.94756008, 1152787.671381914, 1152787.671381914, 264929.7098713914], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7224000.0000, 
sim time next is 7224600.0000, 
raw observation next is [24.0, 73.16666666666667, 1.0, 2.0, 0.3257734782133559, 1.0, 2.0, 0.3257734782133559, 1.0, 2.0, 0.5223333185742255, 6.9112, 6.9112, 121.94756008, 1155359.226546097, 1155359.226546097, 265925.5111753359], 
processed observation next is [1.0, 0.6086956521739131, 0.4444444444444444, 0.7316666666666667, 1.0, 1.0, 0.1973493788254237, 1.0, 1.0, 0.1973493788254237, 1.0, 1.0, 0.40291664821778184, 0.0, 0.0, 0.8096049824067558, 0.4126282951950347, 0.4126282951950347, 0.5113952137987229], 
reward next is 0.4886, 
noisyNet noise sample is [array([-1.0736847], dtype=float32), 0.7543533]. 
=============================================
[2019-03-24 05:21:54,436] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2312069: loss 24.0393
[2019-03-24 05:21:54,441] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2312069: learning rate 0.0000
[2019-03-24 05:21:54,641] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2312173: loss 51.0025
[2019-03-24 05:21:54,643] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2312173: learning rate 0.0000
[2019-03-24 05:21:54,655] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2312178: loss 22.5150
[2019-03-24 05:21:54,655] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2312178: learning rate 0.0000
[2019-03-24 05:21:54,677] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2312187: loss -36.9323
[2019-03-24 05:21:54,678] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2312188: learning rate 0.0000
[2019-03-24 05:21:54,746] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2312225: loss -12.9729
[2019-03-24 05:21:54,748] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2312225: learning rate 0.0000
[2019-03-24 05:21:54,986] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2312347: loss 23.4133
[2019-03-24 05:21:54,989] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2312347: learning rate 0.0000
[2019-03-24 05:21:55,448] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6766306e-11 7.7883547e-26 1.7379755e-19 9.6128050e-22 1.0000000e+00], sum to 1.0000
[2019-03-24 05:21:55,460] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2853
[2019-03-24 05:21:55,463] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.83333333333334, 79.0, 1.0, 2.0, 0.3347555890765176, 1.0, 1.0, 0.3347555890765176, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156607, 820841.0036148193, 820841.0036148193, 191306.9602422024], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7203000.0000, 
sim time next is 7203600.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.2111176787362128, 1.0, 2.0, 0.2111176787362128, 1.0, 1.0, 0.344257088471881, 6.911199999999999, 6.9112, 121.94756008, 771123.8874509978, 771123.8874509983, 223089.9511803586], 
processed observation next is [1.0, 0.391304347826087, 0.37037037037037035, 0.78, 1.0, 1.0, 0.060854379447872364, 1.0, 1.0, 0.060854379447872364, 1.0, 0.5, 0.18032136058985127, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2754013883753564, 0.27540138837535655, 0.42901913688530496], 
reward next is 0.5710, 
noisyNet noise sample is [array([-1.1313947], dtype=float32), 0.8402845]. 
=============================================
[2019-03-24 05:21:55,485] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2312604: loss 0.7232
[2019-03-24 05:21:55,493] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2312605: learning rate 0.0000
[2019-03-24 05:21:55,647] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 6.7193619e-26 9.8082286e-16 3.1623995e-26 1.3771648e-14], sum to 1.0000
[2019-03-24 05:21:55,653] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3827
[2019-03-24 05:21:55,657] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.86666666666667, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6123424803243973, 6.911199999999999, 6.9112, 121.9260426156618, 454955.7736662013, 454955.7736662018, 131875.059711981], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7161600.0000, 
sim time next is 7162200.0000, 
raw observation next is [19.85, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6126441548022975, 6.911200000000001, 6.9112, 121.9260426156618, 455192.6179091136, 455192.6179091131, 131913.5403639713], 
processed observation next is [1.0, 0.9130434782608695, 0.2907407407407408, 0.885, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5158051935028718, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1625687921103977, 0.16256879211039754, 0.2536798853153294], 
reward next is 0.7463, 
noisyNet noise sample is [array([0.68847084], dtype=float32), 1.5544672]. 
=============================================
[2019-03-24 05:21:55,889] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2312815: loss -21.0351
[2019-03-24 05:21:55,891] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2312815: learning rate 0.0000
[2019-03-24 05:21:55,915] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2312826: loss -22.2834
[2019-03-24 05:21:55,919] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2312826: learning rate 0.0000
[2019-03-24 05:21:55,949] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2312843: loss 0.1378
[2019-03-24 05:21:55,954] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2312843: learning rate 0.0000
[2019-03-24 05:21:56,013] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2312871: loss -85.8029
[2019-03-24 05:21:56,017] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2312872: learning rate 0.0000
[2019-03-24 05:21:56,297] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2313024: loss -32.6857
[2019-03-24 05:21:56,299] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2313024: learning rate 0.0000
[2019-03-24 05:21:58,193] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2313996: loss 22.7377
[2019-03-24 05:21:58,196] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2313997: learning rate 0.0000
[2019-03-24 05:21:58,695] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.2794854e-26 3.8752895e-18 9.5468095e-29 5.9379572e-21], sum to 1.0000
[2019-03-24 05:21:58,703] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1713
[2019-03-24 05:21:58,713] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.36666666666667, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6309529300601704, 6.911200000000001, 6.9112, 121.9260426156618, 470290.8236514491, 470290.8236514486, 135003.6990800193], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7273200.0000, 
sim time next is 7273800.0000, 
raw observation next is [20.35, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6332657175613828, 6.9112, 6.9112, 121.9260426156618, 472023.9434300244, 472023.9434300244, 135243.4971602853], 
processed observation next is [1.0, 0.17391304347826086, 0.3092592592592593, 0.885, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5415821469517285, 0.0, 0.0, 0.8094621288201359, 0.16857997979643727, 0.16857997979643727, 0.26008364838516407], 
reward next is 0.7399, 
noisyNet noise sample is [array([-2.5256264], dtype=float32), 0.12354568]. 
=============================================
[2019-03-24 05:22:00,442] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 4.3845181e-32 5.4166662e-21 4.7884823e-34 5.0868452e-18], sum to 1.0000
[2019-03-24 05:22:00,451] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1271
[2019-03-24 05:22:00,458] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 940560.8158295259 W.
[2019-03-24 05:22:00,464] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.4, 76.16666666666667, 1.0, 2.0, 0.262336669641182, 1.0, 1.0, 0.262336669641182, 1.0, 1.0, 0.4226523311239822, 6.911200000000001, 6.9112, 121.94756008, 940560.8158295259, 940560.8158295255, 241568.1104318546], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7297800.0000, 
sim time next is 7298400.0000, 
raw observation next is [23.6, 75.33333333333334, 1.0, 2.0, 0.4238821101058844, 1.0, 2.0, 0.4238821101058844, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1014699.583826962, 1014699.583826963, 214914.7754377008], 
processed observation next is [1.0, 0.4782608695652174, 0.4296296296296297, 0.7533333333333334, 1.0, 1.0, 0.31414536917367186, 1.0, 1.0, 0.31414536917367186, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3623927085096293, 0.3623927085096296, 0.41329764507250155], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.23888813], dtype=float32), 0.31460863]. 
=============================================
[2019-03-24 05:22:09,046] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2319569: loss 0.1752
[2019-03-24 05:22:09,050] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2319570: learning rate 0.0000
[2019-03-24 05:22:09,635] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2319879: loss 0.0698
[2019-03-24 05:22:09,637] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2319879: learning rate 0.0000
[2019-03-24 05:22:09,694] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2319902: loss 0.0711
[2019-03-24 05:22:09,695] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2319903: learning rate 0.0000
[2019-03-24 05:22:09,969] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2320048: loss 0.0214
[2019-03-24 05:22:09,972] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2320049: learning rate 0.0000
[2019-03-24 05:22:10,183] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2320155: loss 0.0534
[2019-03-24 05:22:10,185] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2320155: learning rate 0.0000
[2019-03-24 05:22:10,250] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2320190: loss 0.0061
[2019-03-24 05:22:10,253] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2320191: learning rate 0.0000
[2019-03-24 05:22:10,292] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2320209: loss 0.0015
[2019-03-24 05:22:10,293] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2320209: learning rate 0.0000
[2019-03-24 05:22:10,410] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2320270: loss 0.0263
[2019-03-24 05:22:10,415] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2320270: learning rate 0.0000
[2019-03-24 05:22:10,606] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2320372: loss 0.0182
[2019-03-24 05:22:10,612] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2320372: learning rate 0.0000
[2019-03-24 05:22:11,239] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2320697: loss 0.0030
[2019-03-24 05:22:11,242] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2320697: learning rate 0.0000
[2019-03-24 05:22:11,467] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2320814: loss 0.0819
[2019-03-24 05:22:11,469] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2320815: learning rate 0.0000
[2019-03-24 05:22:11,521] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2320843: loss 115.7385
[2019-03-24 05:22:11,522] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2320843: learning rate 0.0000
[2019-03-24 05:22:11,585] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2320872: loss 0.0005
[2019-03-24 05:22:11,587] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2320873: learning rate 0.0000
[2019-03-24 05:22:11,593] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2320877: loss 0.0005
[2019-03-24 05:22:11,598] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2320877: learning rate 0.0000
[2019-03-24 05:22:11,944] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.4265068e-28 1.5235771e-18 9.5926822e-32 1.8120135e-26], sum to 1.0000
[2019-03-24 05:22:11,953] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5213
[2019-03-24 05:22:11,958] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 95.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.714393405401741, 6.9112, 6.9112, 121.9260426156618, 533478.9480150999, 533478.9480150999, 147740.493696523], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7543800.0000, 
sim time next is 7544400.0000, 
raw observation next is [21.0, 95.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7120522419383255, 6.9112, 6.9112, 121.9260426156618, 531758.738363549, 531758.738363549, 147427.2076685955], 
processed observation next is [0.0, 0.30434782608695654, 0.3333333333333333, 0.9533333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6400653024229069, 0.0, 0.0, 0.8094621288201359, 0.18991383512983892, 0.18991383512983892, 0.2835138609011452], 
reward next is 0.7165, 
noisyNet noise sample is [array([1.6293095], dtype=float32), 2.1220417]. 
=============================================
[2019-03-24 05:22:12,178] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2321175: loss 0.0008
[2019-03-24 05:22:12,181] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2321175: learning rate 0.0000
[2019-03-24 05:22:13,622] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2321913: loss 0.0558
[2019-03-24 05:22:13,626] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2321914: learning rate 0.0000
[2019-03-24 05:22:15,776] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.00000000e+00 2.58346168e-24 1.25943576e-14 4.87244214e-30
 4.49653967e-21], sum to 1.0000
[2019-03-24 05:22:15,783] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4097
[2019-03-24 05:22:15,786] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.78333333333333, 86.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6623196145222917, 6.911200000000001, 6.9112, 121.9260426156618, 494184.4411305993, 494184.4411305989, 138777.1830674076], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7613400.0000, 
sim time next is 7614000.0000, 
raw observation next is [20.7, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6551875270836894, 6.911200000000001, 6.9112, 121.9260426156618, 488778.8531014838, 488778.8531014834, 137933.9964193436], 
processed observation next is [1.0, 0.13043478260869565, 0.3222222222222222, 0.87, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5689844088546118, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17456387610767277, 0.17456387610767263, 0.2652576854218146], 
reward next is 0.7347, 
noisyNet noise sample is [array([-1.6059273], dtype=float32), 1.6811192]. 
=============================================
[2019-03-24 05:22:15,806] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[59.512665]
 [59.50083 ]
 [59.300056]
 [59.14856 ]
 [58.36605 ]], R is [[59.75259781]
 [59.88819122]
 [60.02070999]
 [60.14999008]
 [60.26276779]].
[2019-03-24 05:22:18,686] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 5.1582131e-31 1.5634538e-19 2.5674123e-36 1.3343357e-29], sum to 1.0000
[2019-03-24 05:22:18,696] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6934
[2019-03-24 05:22:18,704] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.5, 73.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5574893436093766, 6.9112, 6.9112, 121.9260426156618, 408769.0763851965, 408769.0763851965, 123659.1293390755], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7674000.0000, 
sim time next is 7674600.0000, 
raw observation next is [20.25, 73.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5484928590182035, 6.911200000000001, 6.9112, 121.9260426156618, 401032.6772807086, 401032.6772807081, 122374.1750933139], 
processed observation next is [1.0, 0.8260869565217391, 0.3055555555555556, 0.7366666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4356160737727544, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14322595617168166, 0.14322595617168146, 0.23533495210252672], 
reward next is 0.7647, 
noisyNet noise sample is [array([0.25784546], dtype=float32), 0.36144784]. 
=============================================
[2019-03-24 05:22:19,619] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 05:22:19,621] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:22:19,621] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:22:19,622] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:22:19,623] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:22:19,623] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:22:19,622] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:22:19,625] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:22:19,624] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:22:19,627] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:22:19,628] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:22:19,649] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run94
[2019-03-24 05:22:19,673] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run94
[2019-03-24 05:22:19,698] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run94
[2019-03-24 05:22:19,722] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run94
[2019-03-24 05:22:19,722] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run94
[2019-03-24 05:22:19,809] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:22:19,809] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:22:19,812] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run12
[2019-03-24 05:23:12,911] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.4721536]
[2019-03-24 05:23:12,913] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.2, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.919306384495352, 6.911200000000001, 6.9112, 121.9260426156618, 670295.341443769, 670295.3414437686, 179000.7237892356]
[2019-03-24 05:23:12,915] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:23:12,917] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 9.0005957e-33 4.8913082e-22 4.3706779e-38 2.7384104e-30], sampled 0.5453005836122953
[2019-03-24 05:24:00,736] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.4721536]
[2019-03-24 05:24:00,737] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.33333333333334, 76.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9325265634307702, 6.9112, 6.9112, 121.9260426156618, 678402.3746736624, 678402.3746736624, 181053.973682934]
[2019-03-24 05:24:00,740] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:24:00,742] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 5.4881190e-33 8.7720797e-22 4.0075171e-38 3.5044048e-30], sampled 0.20418683009608274
[2019-03-24 05:24:04,095] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.4721536]
[2019-03-24 05:24:04,099] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.02458895333334, 87.90736835000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.872855261742361, 6.9112, 6.9112, 121.9260426156618, 639930.9734314398, 639930.9734314398, 172131.5252408515]
[2019-03-24 05:24:04,100] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:24:04,103] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.3661946e-33 1.3958293e-22 0.0000000e+00 4.8841076e-31], sampled 0.934546658186069
[2019-03-24 05:24:08,626] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:24:08,891] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 05:24:09,076] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:24:09,121] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:24:09,386] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 05:24:10,401] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2325000, evaluation results [2325000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:24:13,734] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 3.6163794e-29 6.8746354e-20 3.7939921e-32 6.8079533e-21], sum to 1.0000
[2019-03-24 05:24:13,739] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4404
[2019-03-24 05:24:13,747] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1173385.672625449 W.
[2019-03-24 05:24:13,756] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 59.0, 1.0, 2.0, 0.4957558810090514, 1.0, 2.0, 0.4957558810090514, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260425334077, 1173385.672625449, 1173385.672625449, 235992.9439853118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7731600.0000, 
sim time next is 7732200.0000, 
raw observation next is [27.1, 58.0, 1.0, 2.0, 0.9485509869756311, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.141393761534168, 6.9112, 121.925054109916, 1257332.707099159, 1139453.882409721, 231407.6354028302], 
processed observation next is [1.0, 0.4782608695652174, 0.5592592592592593, 0.58, 1.0, 1.0, 0.9387511749709895, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.023019376153416805, 0.0, 0.8094555661699574, 0.4490473953925568, 0.4069478151463289, 0.44501468346698114], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.226918], dtype=float32), 0.49179155]. 
=============================================
[2019-03-24 05:24:14,353] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 9.1930417e-26 7.4900006e-15 2.4563815e-30 1.6399266e-23], sum to 1.0000
[2019-03-24 05:24:14,365] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1321
[2019-03-24 05:24:14,372] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.66666666666666, 64.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5442965978905224, 6.911200000000001, 6.9112, 121.9260426156618, 398058.1877611657, 398058.1877611652, 122060.4122141105], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7793400.0000, 
sim time next is 7794000.0000, 
raw observation next is [21.7, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5418309743358782, 6.911199999999999, 6.9112, 121.9260426156618, 396009.3658356674, 396009.3658356679, 121745.0146619021], 
processed observation next is [1.0, 0.21739130434782608, 0.3592592592592592, 0.64, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.42728871791984774, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14143191636988123, 0.1414319163698814, 0.23412502819596556], 
reward next is 0.7659, 
noisyNet noise sample is [array([-0.15997006], dtype=float32), -0.8362045]. 
=============================================
[2019-03-24 05:24:14,398] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[62.836964]
 [62.852566]
 [62.93926 ]
 [63.055187]
 [63.069813]], R is [[63.00314331]
 [63.13838196]
 [63.27083588]
 [63.39951706]
 [63.52390671]].
[2019-03-24 05:24:15,449] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2327602: loss 131.6704
[2019-03-24 05:24:15,450] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2327602: learning rate 0.0000
[2019-03-24 05:24:16,055] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2327906: loss 207.1246
[2019-03-24 05:24:16,058] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2327906: learning rate 0.0000
[2019-03-24 05:24:16,088] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2327922: loss 142.3086
[2019-03-24 05:24:16,090] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2327922: learning rate 0.0000
[2019-03-24 05:24:16,166] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2327963: loss 119.3646
[2019-03-24 05:24:16,167] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2327963: learning rate 0.0000
[2019-03-24 05:24:16,458] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2328113: loss 112.5099
[2019-03-24 05:24:16,463] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2328114: learning rate 0.0000
[2019-03-24 05:24:16,495] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2328133: loss 86.6338
[2019-03-24 05:24:16,498] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2328133: learning rate 0.0000
[2019-03-24 05:24:16,526] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2328146: loss 85.2894
[2019-03-24 05:24:16,528] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2328147: learning rate 0.0000
[2019-03-24 05:24:16,565] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2328167: loss 100.9763
[2019-03-24 05:24:16,566] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2328168: learning rate 0.0000
[2019-03-24 05:24:16,764] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2328271: loss 8.9315
[2019-03-24 05:24:16,766] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2328271: learning rate 0.0000
[2019-03-24 05:24:17,450] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2328618: loss 31.5915
[2019-03-24 05:24:17,452] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2328618: learning rate 0.0000
[2019-03-24 05:24:17,899] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2328853: loss -62.6650
[2019-03-24 05:24:17,903] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2328854: learning rate 0.0000
[2019-03-24 05:24:18,113] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2328891: loss -48.3647
[2019-03-24 05:24:18,115] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2328891: learning rate 0.0000
[2019-03-24 05:24:18,137] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2328901: loss -41.9119
[2019-03-24 05:24:18,139] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2328902: learning rate 0.0000
[2019-03-24 05:24:18,490] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2329086: loss -32.3389
[2019-03-24 05:24:18,494] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2329086: learning rate 0.0000
[2019-03-24 05:24:20,022] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2329868: loss -52.8781
[2019-03-24 05:24:20,025] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2329869: learning rate 0.0000
[2019-03-24 05:24:23,695] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:23,697] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:23,750] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run12
[2019-03-24 05:24:24,274] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 4.3839816e-25 6.1264781e-19 8.4993681e-30 3.8193363e-22], sum to 1.0000
[2019-03-24 05:24:24,274] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6490
[2019-03-24 05:24:24,275] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1139446.632229283 W.
[2019-03-24 05:24:24,278] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.35, 48.5, 1.0, 2.0, 0.9247513632479367, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.972413822769404, 6.9112, 121.9257016220592, 1139446.632229283, 1108099.771410745, 225717.8660918495], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7909800.0000, 
sim time next is 7910400.0000, 
raw observation next is [29.5, 48.0, 1.0, 2.0, 0.6245931513105681, 1.0, 1.0, 0.6245931513105681, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260057538221, 1471828.226396154, 1471828.226396154, 278817.338062946], 
processed observation next is [1.0, 0.5652173913043478, 0.6481481481481481, 0.48, 1.0, 1.0, 0.5530870848935335, 1.0, 0.5, 0.5530870848935335, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.809461884095854, 0.5256529379986264, 0.5256529379986264, 0.5361871885825884], 
reward next is 0.4638, 
noisyNet noise sample is [array([-0.8459446], dtype=float32), -0.22165646]. 
=============================================
[2019-03-24 05:24:24,344] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:24,344] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:24,359] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run12
[2019-03-24 05:24:24,409] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:24,413] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:24,431] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run12
[2019-03-24 05:24:24,432] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:24,432] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:24,474] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run12
[2019-03-24 05:24:24,579] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:24,580] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:24,586] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run12
[2019-03-24 05:24:24,608] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:24,609] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:24,620] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run12
[2019-03-24 05:24:24,654] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:24,654] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:24,660] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run12
[2019-03-24 05:24:24,694] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:24,695] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:24,710] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run12
[2019-03-24 05:24:24,821] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:24,821] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:24,824] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run12
[2019-03-24 05:24:25,125] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:25,125] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:25,135] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run12
[2019-03-24 05:24:25,337] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:25,337] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:25,340] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run12
[2019-03-24 05:24:25,370] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:25,371] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:25,374] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:25,375] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:25,378] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run12
[2019-03-24 05:24:25,414] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run12
[2019-03-24 05:24:25,498] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:25,498] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:25,527] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run12
[2019-03-24 05:24:26,514] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:26,514] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:26,527] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run12
[2019-03-24 05:24:36,177] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.0581067e-30 4.5281082e-21 4.5721852e-33 3.8787563e-30], sum to 1.0000
[2019-03-24 05:24:36,182] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8454
[2019-03-24 05:24:36,187] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.23333333333333, 36.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5870178245916562, 6.911200000000001, 6.9112, 121.9260426156618, 433989.3418523014, 433989.3418523009, 128066.9637934491], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 210000.0000, 
sim time next is 210600.0000, 
raw observation next is [28.6, 35.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5821870252328528, 6.9112, 6.9112, 121.9260426156618, 430154.9685848652, 430154.9685848652, 127475.111263278], 
processed observation next is [0.0, 0.43478260869565216, 0.6148148148148148, 0.35, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.477733781541066, 0.0, 0.0, 0.8094621288201359, 0.15362677449459472, 0.15362677449459472, 0.2451444447370731], 
reward next is 0.7549, 
noisyNet noise sample is [array([0.15091416], dtype=float32), 0.43913448]. 
=============================================
[2019-03-24 05:24:42,774] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 6.8695448e-29 1.1041899e-18 2.5937209e-32 3.3108411e-27], sum to 1.0000
[2019-03-24 05:24:42,782] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7114
[2019-03-24 05:24:42,787] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.65, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4814457426156352, 6.9112, 6.9112, 121.9260426156618, 343753.9534359644, 343753.9534359644, 106363.1371176087], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 349800.0000, 
sim time next is 350400.0000, 
raw observation next is [21.5, 52.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4790274935076211, 6.9112, 6.9112, 121.9260426156618, 342026.9300575697, 342026.9300575697, 105663.0207075554], 
processed observation next is [1.0, 0.043478260869565216, 0.35185185185185186, 0.52, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3487843668845263, 0.0, 0.0, 0.8094621288201359, 0.1221524750205606, 0.1221524750205606, 0.20319811674529886], 
reward next is 0.7968, 
noisyNet noise sample is [array([-0.95098615], dtype=float32), -0.13625892]. 
=============================================
[2019-03-24 05:24:46,522] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.3605007e-33 1.8096418e-21 0.0000000e+00 3.6135075e-31], sum to 1.0000
[2019-03-24 05:24:46,539] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6933
[2019-03-24 05:24:46,547] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1270623.977800657 W.
[2019-03-24 05:24:46,552] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.78333333333333, 25.83333333333334, 1.0, 2.0, 0.5108608357700263, 1.0, 2.0, 0.5108608357700263, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 1270623.977800657, 1270623.977800658, 242676.9382562652], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 402600.0000, 
sim time next is 403200.0000, 
raw observation next is [30.8, 26.0, 1.0, 2.0, 0.5083267716861839, 1.0, 2.0, 0.5083267716861839, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1263562.284106731, 1263562.284106732, 241847.3168220137], 
processed observation next is [1.0, 0.6956521739130435, 0.6962962962962963, 0.26, 1.0, 1.0, 0.41467472819783796, 1.0, 1.0, 0.41467472819783796, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4512722443238325, 0.4512722443238329, 0.4650909938884879], 
reward next is 0.5349, 
noisyNet noise sample is [array([-0.20509316], dtype=float32), 0.5114235]. 
=============================================
[2019-03-24 05:24:51,482] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.2828963e-27 8.6083429e-17 9.0198832e-32 7.0842770e-23], sum to 1.0000
[2019-03-24 05:24:51,483] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7023
[2019-03-24 05:24:51,487] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.05, 27.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6235316028342843, 6.9112, 6.9112, 121.9260426156618, 460656.3813132856, 460656.3813132856, 131274.7411991903], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 497400.0000, 
sim time next is 498000.0000, 
raw observation next is [30.8, 28.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6190937411585997, 6.911199999999999, 6.9112, 121.9260426156618, 457671.9909176746, 457671.990917675, 131024.9522323604], 
processed observation next is [1.0, 0.782608695652174, 0.6962962962962963, 0.28, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5238671764482496, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16345428247059807, 0.16345428247059823, 0.25197106198530844], 
reward next is 0.7480, 
noisyNet noise sample is [array([-0.50843394], dtype=float32), -0.97881705]. 
=============================================
[2019-03-24 05:24:51,502] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[70.044044]
 [69.94599 ]
 [69.9632  ]
 [69.812706]
 [69.309296]], R is [[69.84310913]
 [69.89222717]
 [69.94073486]
 [69.98870087]
 [70.03627777]].
[2019-03-24 05:25:01,770] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 05:25:01,778] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:25:01,779] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:25:01,779] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:25:01,780] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:25:01,780] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:25:01,783] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:25:01,786] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:25:01,787] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:25:01,788] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:25:01,789] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:25:01,809] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run95
[2019-03-24 05:25:01,810] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run95
[2019-03-24 05:25:01,810] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run95
[2019-03-24 05:25:01,854] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run95
[2019-03-24 05:25:01,855] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run95
[2019-03-24 05:25:13,351] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.47770604]
[2019-03-24 05:25:13,353] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.26666666666667, 53.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5308553784214926, 6.9112, 6.9112, 121.9260426156618, 386900.9585445262, 386900.9585445262, 120364.4104496929]
[2019-03-24 05:25:13,354] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:25:13,356] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.1879975e-28 4.5164682e-19 1.6123097e-32 4.2976936e-26], sampled 0.5455456678900902
[2019-03-24 05:25:58,496] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.47770604]
[2019-03-24 05:25:58,498] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.76639834, 96.94255404666666, 1.0, 2.0, 0.5405160376893946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426155162, 675902.2250837993, 675902.2250837993, 150296.9190887854]
[2019-03-24 05:25:58,500] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:25:58,507] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 4.7642963e-22 1.3947119e-14 3.8786772e-25 4.4346041e-20], sampled 0.9929079264785836
[2019-03-24 05:26:07,260] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.47770604]
[2019-03-24 05:26:07,262] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.470895155, 83.659150125, 1.0, 2.0, 0.6123799941488699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 706188.496192178, 706188.4961921785, 160624.8006172989]
[2019-03-24 05:26:07,265] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:26:07,268] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.2253013e-21 1.9711705e-14 1.1020657e-24 8.8130756e-20], sampled 0.3869540924649072
[2019-03-24 05:26:07,270] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 706188.496192178 W.
[2019-03-24 05:26:18,620] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.47770604]
[2019-03-24 05:26:18,621] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [36.0, 43.0, 1.0, 2.0, 0.738072424059508, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1556257.485658767, 1556257.485658767, 324263.0976637975]
[2019-03-24 05:26:18,621] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:26:18,625] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.3236118e-24 1.9568138e-16 4.0924447e-28 1.5548393e-22], sampled 0.5716120975712213
[2019-03-24 05:26:18,626] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1556257.485658767 W.
[2019-03-24 05:26:37,751] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.47770604]
[2019-03-24 05:26:37,752] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.56666666666667, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8781237258835632, 6.911199999999999, 6.9112, 121.9260426156618, 642423.1602011912, 642423.1602011917, 173105.7054046319]
[2019-03-24 05:26:37,752] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:26:37,755] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 5.3886006e-27 3.7185503e-18 6.4980947e-31 8.0897804e-25], sampled 0.30312913238640604
[2019-03-24 05:26:39,817] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.47770604]
[2019-03-24 05:26:39,818] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.61520411666666, 84.02093214666667, 1.0, 2.0, 0.6548829017591156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 766837.6803384583, 766837.6803384583, 168750.2987502429]
[2019-03-24 05:26:39,818] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:26:39,821] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.5008076e-20 1.2736165e-13 2.0545919e-23 1.0070000e-18], sampled 0.8404972177173547
[2019-03-24 05:26:39,824] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 766837.6803384583 W.
[2019-03-24 05:26:50,555] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.47770604]
[2019-03-24 05:26:50,556] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.46666666666667, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6272473593162975, 6.9112, 6.9112, 121.9260426156618, 466250.8473440806, 466250.8473440806, 133481.156309253]
[2019-03-24 05:26:50,561] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:26:50,563] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 3.8121235e-26 1.3824262e-17 6.2503280e-30 4.9288578e-24], sampled 0.525305385454569
[2019-03-24 05:26:51,114] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:26:51,231] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 05:26:51,257] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:26:51,283] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 05:26:51,312] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:26:52,329] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 2350000, evaluation results [2350000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:26:52,810] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.9411863e-23 3.7386803e-16 2.7781980e-27 7.0416572e-22], sum to 1.0000
[2019-03-24 05:26:52,820] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2858
[2019-03-24 05:26:52,824] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.36666666666667, 49.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5405747472564744, 6.9112, 6.9112, 121.9260426156618, 390191.9027488406, 390191.9027488406, 119701.4320584374], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 706800.0000, 
sim time next is 707400.0000, 
raw observation next is [23.2, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5265463445104006, 6.911200000000001, 6.9112, 121.9260426156618, 379998.5811926209, 379998.5811926204, 118548.7738897533], 
processed observation next is [1.0, 0.17391304347826086, 0.4148148148148148, 0.505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4081829306380007, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13571377899736461, 0.13571377899736442, 0.22797841132644864], 
reward next is 0.7720, 
noisyNet noise sample is [array([-0.12306812], dtype=float32), -1.2717403]. 
=============================================
[2019-03-24 05:26:56,380] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 4.0088321e-23 8.0002017e-17 1.0769958e-25 7.1629499e-22], sum to 1.0000
[2019-03-24 05:26:56,389] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5110
[2019-03-24 05:26:56,396] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1321140.07163452 W.
[2019-03-24 05:26:56,402] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.05, 23.5, 1.0, 2.0, 0.5294957921409837, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8857983133478892, 6.9112, 6.9112, 121.9257255309005, 1321140.07163452, 1321140.07163452, 262553.0587002935], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 747000.0000, 
sim time next is 747600.0000, 
raw observation next is [32.03333333333333, 23.66666666666667, 1.0, 2.0, 0.4924899614006046, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8219843148566823, 6.911200000000001, 6.9112, 121.9260425189732, 1226643.495199032, 1226643.495199032, 249831.9122263019], 
processed observation next is [1.0, 0.6521739130434783, 0.7419753086419753, 0.23666666666666672, 1.0, 1.0, 0.3958213826197674, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.777480393570853, 8.881784197001253e-17, 0.0, 0.8094621281782243, 0.4380869625710828, 0.4380869625710828, 0.4804459850505806], 
reward next is 0.5196, 
noisyNet noise sample is [array([-0.60717], dtype=float32), -0.6790236]. 
=============================================
[2019-03-24 05:27:01,887] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.9710146e-27 9.9560319e-17 5.5268237e-31 1.2833577e-25], sum to 1.0000
[2019-03-24 05:27:01,894] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5267
[2019-03-24 05:27:01,899] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.8, 36.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7263079954870626, 6.911200000000001, 6.9112, 121.9260426156618, 542148.1730974352, 542148.1730974347, 149433.304405798], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 836400.0000, 
sim time next is 837000.0000, 
raw observation next is [31.7, 36.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7230893920057168, 6.9112, 6.9112, 121.9260426156618, 539816.6277281623, 539816.6277281623, 148968.1027254198], 
processed observation next is [0.0, 0.6956521739130435, 0.7296296296296296, 0.365, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6538617400071458, 0.0, 0.0, 0.8094621288201359, 0.19279165276005797, 0.19279165276005797, 0.2864771206258073], 
reward next is 0.7135, 
noisyNet noise sample is [array([-0.2063369], dtype=float32), 1.0967935]. 
=============================================
[2019-03-24 05:27:01,917] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[65.07018 ]
 [65.020935]
 [65.01941 ]
 [64.96271 ]
 [64.93549 ]], R is [[65.17155457]
 [65.23246765]
 [65.29003143]
 [65.34816742]
 [65.40599823]].
[2019-03-24 05:27:04,946] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.3871996e-30 9.5993664e-20 3.8974403e-32 1.3543207e-28], sum to 1.0000
[2019-03-24 05:27:04,955] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8846
[2019-03-24 05:27:04,960] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.78333333333333, 57.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6863542569330986, 6.9112, 6.9112, 121.9260426156618, 512817.5645195837, 512817.5645195837, 142663.4149529742], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 906600.0000, 
sim time next is 907200.0000, 
raw observation next is [26.0, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6902479601244992, 6.911199999999999, 6.9112, 121.9260426156618, 515774.1423784401, 515774.1423784406, 143295.084243626], 
processed observation next is [0.0, 0.5217391304347826, 0.5185185185185185, 0.57, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6128099501556239, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18420505084944291, 0.18420505084944308, 0.2755674696992808], 
reward next is 0.7244, 
noisyNet noise sample is [array([0.4032959], dtype=float32), 0.48213005]. 
=============================================
[2019-03-24 05:27:08,541] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.0548720e-25 1.2696543e-19 2.2833616e-31 6.0210637e-25], sum to 1.0000
[2019-03-24 05:27:08,547] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9173
[2019-03-24 05:27:08,554] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 986654.4777137515 W.
[2019-03-24 05:27:08,559] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.33333333333334, 52.83333333333334, 1.0, 2.0, 0.2689648437157447, 1.0, 2.0, 0.2689648437157447, 1.0, 2.0, 0.4401203536613676, 6.9112, 6.9112, 121.94756008, 986654.4777137515, 986654.4777137515, 243102.0491227477], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 997800.0000, 
sim time next is 998400.0000, 
raw observation next is [25.36666666666667, 52.66666666666667, 1.0, 2.0, 0.4684563638528657, 1.0, 2.0, 0.4684563638528657, 0.0, 1.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1150780.534879294, 1150780.534879296, 229021.299026524], 
processed observation next is [1.0, 0.5652173913043478, 0.49506172839506185, 0.5266666666666667, 1.0, 1.0, 0.36720995696769726, 1.0, 1.0, 0.36720995696769726, 0.0, 0.5, -0.25, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.41099304817117643, 0.41099304817117716, 0.4404255750510077], 
reward next is 0.5596, 
noisyNet noise sample is [array([-1.0323247], dtype=float32), -0.39818412]. 
=============================================
[2019-03-24 05:27:15,434] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.8093170e-27 1.3310583e-19 1.5493590e-34 2.7219994e-28], sum to 1.0000
[2019-03-24 05:27:15,441] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9359
[2019-03-24 05:27:15,449] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.25, 71.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5344202360498681, 6.911199999999999, 6.9112, 121.9260426156618, 388762.3817956125, 388762.381795613, 120357.5089457656], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1115400.0000, 
sim time next is 1116000.0000, 
raw observation next is [20.1, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5315772902899881, 6.9112, 6.9112, 121.9260426156618, 386194.8814941525, 386194.8814941525, 119924.228689637], 
processed observation next is [1.0, 0.9565217391304348, 0.30000000000000004, 0.72, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.41447161286248513, 0.0, 0.0, 0.8094621288201359, 0.13792674339076874, 0.13792674339076874, 0.2306235167108404], 
reward next is 0.7694, 
noisyNet noise sample is [array([-0.20083344], dtype=float32), -1.661902]. 
=============================================
[2019-03-24 05:27:15,477] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[72.6199  ]
 [72.745255]
 [72.93524 ]
 [72.983986]
 [73.05292 ]], R is [[72.75018311]
 [72.79122925]
 [72.83108521]
 [72.86981201]
 [72.90749359]].
[2019-03-24 05:27:16,703] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 4.1230856e-25 7.0633859e-17 6.7685171e-28 1.8082530e-23], sum to 1.0000
[2019-03-24 05:27:16,710] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0970
[2019-03-24 05:27:16,714] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.83333333333334, 75.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4923900160289467, 6.9112, 6.9112, 121.9260426156618, 352577.6368430562, 352577.6368430562, 114885.4299187682], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1137000.0000, 
sim time next is 1137600.0000, 
raw observation next is [18.8, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4950335234387778, 6.911199999999999, 6.9112, 121.9260426156618, 354384.7653625085, 354384.7653625089, 115056.4288426261], 
processed observation next is [1.0, 0.17391304347826086, 0.2518518518518519, 0.76, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.36879190429847225, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1265659876294673, 0.12656598762946747, 0.22126236315889636], 
reward next is 0.7787, 
noisyNet noise sample is [array([-0.10624792], dtype=float32), 0.6912475]. 
=============================================
[2019-03-24 05:27:20,573] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 4.0451634e-30 1.8462440e-19 3.0363254e-32 6.7865149e-27], sum to 1.0000
[2019-03-24 05:27:20,583] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9315
[2019-03-24 05:27:20,593] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 923800.4610707113 W.
[2019-03-24 05:27:20,598] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 67.0, 1.0, 2.0, 0.2481362564566905, 1.0, 1.0, 0.2481362564566905, 1.0, 1.0, 0.4123900545072353, 6.911199999999999, 6.9112, 121.94756008, 923800.4610707113, 923800.4610707117, 234730.397460301], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1176000.0000, 
sim time next is 1176600.0000, 
raw observation next is [21.95, 67.5, 1.0, 2.0, 0.3665714670191037, 1.0, 2.0, 0.3665714670191037, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 912052.7351183644, 912052.7351183649, 200017.7373996824], 
processed observation next is [1.0, 0.6086956521739131, 0.36851851851851847, 0.675, 1.0, 1.0, 0.2459184131179806, 1.0, 1.0, 0.2459184131179806, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32573311968513013, 0.3257331196851303, 0.3846494949993892], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.495227], dtype=float32), 0.5238649]. 
=============================================
[2019-03-24 05:27:26,347] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.5816432e-25 3.2787719e-16 1.6917977e-29 2.5447953e-25], sum to 1.0000
[2019-03-24 05:27:26,353] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4216
[2019-03-24 05:27:26,360] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.3, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5703948163395403, 6.9112, 6.9112, 121.9260426156618, 418665.7475361181, 418665.7475361181, 124981.0726042075], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1314000.0000, 
sim time next is 1314600.0000, 
raw observation next is [18.53333333333333, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5622979039765221, 6.9112, 6.9112, 121.9260426156618, 413088.5888125903, 413088.5888125903, 124448.7173880819], 
processed observation next is [1.0, 0.21739130434782608, 0.24197530864197525, 0.91, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4528723799706526, 0.0, 0.0, 0.8094621288201359, 0.1475316388616394, 0.1475316388616394, 0.23932445651554213], 
reward next is 0.7607, 
noisyNet noise sample is [array([-0.7758938], dtype=float32), 0.57224715]. 
=============================================
[2019-03-24 05:27:31,069] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 4.5192525e-30 6.0288875e-22 2.1771349e-33 1.0151411e-27], sum to 1.0000
[2019-03-24 05:27:31,075] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3739
[2019-03-24 05:27:31,078] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [34.66666666666666, 21.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6720068115717985, 6.9112, 6.9112, 121.9260426156618, 500355.5139247735, 500355.5139247735, 138623.656217283], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1438800.0000, 
sim time next is 1439400.0000, 
raw observation next is [34.83333333333334, 20.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6742988824593953, 6.911200000000001, 6.9112, 121.9260426156618, 501960.9610689368, 501960.9610689363, 138766.2940786016], 
processed observation next is [0.0, 0.6521739130434783, 0.8456790123456793, 0.205, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5928736030742441, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17927177181033457, 0.17927177181033438, 0.2668582578434646], 
reward next is 0.7331, 
noisyNet noise sample is [array([-0.80545044], dtype=float32), 0.0739852]. 
=============================================
[2019-03-24 05:27:33,998] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.9784618e-30 8.0221971e-19 4.4932770e-38 4.4781196e-29], sum to 1.0000
[2019-03-24 05:27:34,006] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4473
[2019-03-24 05:27:34,008] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.65, 60.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5665701979538158, 6.9112, 6.9112, 121.9260426156618, 415917.5257062832, 415917.5257062832, 124674.4312976804], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1477800.0000, 
sim time next is 1478400.0000, 
raw observation next is [22.56666666666667, 61.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5688899719549176, 6.911200000000001, 6.9112, 121.9260426156618, 417904.4919986141, 417904.4919986136, 125012.5501859155], 
processed observation next is [0.0, 0.08695652173913043, 0.39135802469135816, 0.6133333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.461112464943647, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14925160428521933, 0.14925160428521914, 0.24040875035752982], 
reward next is 0.7596, 
noisyNet noise sample is [array([0.10588755], dtype=float32), 0.51439357]. 
=============================================
[2019-03-24 05:27:34,354] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.6586742e-36 9.8743160e-28 0.0000000e+00 2.1246744e-33], sum to 1.0000
[2019-03-24 05:27:34,361] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5386
[2019-03-24 05:27:34,366] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.3, 45.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5919154023487937, 6.9112, 6.9112, 121.9260426156618, 437814.8854369889, 437814.8854369889, 128635.7409124254], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1468800.0000, 
sim time next is 1469400.0000, 
raw observation next is [26.01666666666667, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5903343667380611, 6.911199999999999, 6.9112, 121.9260426156618, 436408.4778516411, 436408.4778516416, 128351.6284588818], 
processed observation next is [0.0, 0.0, 0.5191358024691359, 0.46, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4879179584225763, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1558601706613004, 0.15586017066130056, 0.24683005472861883], 
reward next is 0.7532, 
noisyNet noise sample is [array([-0.2070061], dtype=float32), -1.019071]. 
=============================================
[2019-03-24 05:27:34,456] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 3.8805912e-30 1.4569212e-19 1.7469329e-37 1.2951191e-29], sum to 1.0000
[2019-03-24 05:27:34,462] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8229
[2019-03-24 05:27:34,468] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.53333333333333, 39.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7123808369339698, 6.911200000000001, 6.9112, 121.9260426156618, 532294.2482560235, 532294.248256023, 146735.0246092228], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1503600.0000, 
sim time next is 1504200.0000, 
raw observation next is [30.86666666666667, 38.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7172381248505111, 6.911199999999999, 6.9112, 121.9260426156618, 535892.0774215148, 535892.0774215152, 147403.5539515395], 
processed observation next is [0.0, 0.391304347826087, 0.6987654320987656, 0.38, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6465476560631389, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.191390027650541, 0.19139002765054117, 0.28346837298372984], 
reward next is 0.7165, 
noisyNet noise sample is [array([-0.8993318], dtype=float32), -0.7750212]. 
=============================================
[2019-03-24 05:27:41,313] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 05:27:41,317] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:27:41,318] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:27:41,318] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:27:41,319] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:27:41,319] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:27:41,322] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:27:41,320] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:27:41,324] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:27:41,326] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:27:41,324] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:27:41,344] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run96
[2019-03-24 05:27:41,374] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run96
[2019-03-24 05:27:41,397] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run96
[2019-03-24 05:27:41,398] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run96
[2019-03-24 05:27:41,399] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run96
[2019-03-24 05:27:54,056] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48281205]
[2019-03-24 05:27:54,058] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.41666666666667, 36.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4069517127785444, 6.911200000000001, 6.9112, 121.9260426156618, 290554.8791141463, 290554.8791141459, 80327.1316414756]
[2019-03-24 05:27:54,058] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:27:54,064] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.00000000e+00 1.56020725e-26 1.36522115e-17 3.28240303e-30
 8.63359746e-25], sampled 0.8472435736916318
[2019-03-24 05:28:49,874] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48281205]
[2019-03-24 05:28:49,876] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.00194495666667, 73.21071742, 1.0, 2.0, 0.6266449721695987, 0.0, 2.0, 0.0, 1.0, 2.0, 0.99763920409596, 6.9112, 6.9112, 121.9260426156618, 1428984.058348743, 1428984.058348743, 304381.5845121285]
[2019-03-24 05:28:49,877] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:28:49,880] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.9765522e-25 9.4804540e-17 9.8782295e-29 1.3503260e-23], sampled 0.37902522242672265
[2019-03-24 05:28:49,881] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1428984.058348743 W.
[2019-03-24 05:28:59,403] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48281205]
[2019-03-24 05:28:59,406] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.58466112333333, 69.68115245, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.660534961033759, 6.9112, 121.9234984562129, 2262198.575446263, 1878480.107594162, 381450.2283778388]
[2019-03-24 05:28:59,408] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:28:59,410] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.5988333e-23 1.7939556e-15 1.7108940e-26 8.8103106e-22], sampled 0.33129238194474686
[2019-03-24 05:28:59,412] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2262198.575446263 W.
[2019-03-24 05:29:01,884] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48281205]
[2019-03-24 05:29:01,885] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.6706017, 56.31755694, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8271813301757103, 6.9112, 6.9112, 121.9260426156618, 613925.1331471738, 613925.1331471738, 163952.5965152315]
[2019-03-24 05:29:01,887] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:29:01,890] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.00000000e+00 3.78458090e-25 1.09149334e-16 1.28492822e-28
 1.68930066e-23], sampled 0.90481094061515
[2019-03-24 05:29:06,677] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48281205]
[2019-03-24 05:29:06,680] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.66666666666667, 82.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9253825670539912, 6.911200000000001, 6.9112, 121.9260426156618, 670247.3215204912, 670247.3215204907, 180518.3033716613]
[2019-03-24 05:29:06,682] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:29:06,685] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 6.1916745e-27 7.4794531e-18 1.1371930e-30 3.6441804e-25], sampled 0.37433282618500285
[2019-03-24 05:29:26,930] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48281205]
[2019-03-24 05:29:26,931] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.93333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.614476882382909, 6.9112, 6.9112, 121.9260426156618, 457962.3935763472, 457962.3935763472, 133329.0303637496]
[2019-03-24 05:29:26,932] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:29:26,934] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.9477840e-27 3.5329223e-18 3.0191293e-31 1.2412186e-25], sampled 0.2635593221557997
[2019-03-24 05:29:30,117] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:29:30,183] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:29:30,362] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 05:29:30,388] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:29:30,430] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 05:29:31,444] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2375000, evaluation results [2375000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:29:32,316] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.000000e+00 7.698130e-30 6.807337e-19 6.596168e-32 5.632919e-27], sum to 1.0000
[2019-03-24 05:29:32,330] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0026
[2019-03-24 05:29:32,332] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.96666666666667, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.600229995524897, 6.911200000000001, 6.9112, 121.9260426156618, 445111.2934274956, 445111.2934274951, 130122.4524110053], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1626000.0000, 
sim time next is 1626600.0000, 
raw observation next is [25.83333333333334, 48.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5968031743078195, 6.9112, 6.9112, 121.9260426156618, 442474.4928361183, 442474.4928361183, 129737.9682265785], 
processed observation next is [1.0, 0.8260869565217391, 0.5123456790123458, 0.485, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4960039678847743, 0.0, 0.0, 0.8094621288201359, 0.15802660458432796, 0.15802660458432796, 0.2494960927434202], 
reward next is 0.7505, 
noisyNet noise sample is [array([-0.73154753], dtype=float32), 1.1349964]. 
=============================================
[2019-03-24 05:29:32,880] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.5507205e-32 4.6836873e-24 0.0000000e+00 1.5608469e-30], sum to 1.0000
[2019-03-24 05:29:32,888] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1283
[2019-03-24 05:29:32,894] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.76666666666667, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5532643888427426, 6.911200000000001, 6.9112, 121.9260426156618, 405642.7657352916, 405642.7657352912, 123282.3173513995], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1640400.0000, 
sim time next is 1641000.0000, 
raw observation next is [22.68333333333333, 59.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5538847822515093, 6.911200000000001, 6.9112, 121.9260426156618, 406104.3324141823, 406104.3324141818, 123338.7138797377], 
processed observation next is [1.0, 1.0, 0.39567901234567887, 0.595, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44235597781438657, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1450372615764937, 0.1450372615764935, 0.23718983438411095], 
reward next is 0.7628, 
noisyNet noise sample is [array([0.91642624], dtype=float32), -0.02539356]. 
=============================================
[2019-03-24 05:29:32,920] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[80.32592]
 [80.31649]
 [80.298  ]
 [80.27291]
 [80.22616]], R is [[80.27414703]
 [80.23432159]
 [80.19486237]
 [80.15555573]
 [80.11618042]].
[2019-03-24 05:29:34,518] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 7.0898858e-27 6.2734114e-20 4.8875581e-30 6.6852806e-26], sum to 1.0000
[2019-03-24 05:29:34,525] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8640
[2019-03-24 05:29:34,531] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.1, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5494137654323459, 6.911199999999999, 6.9112, 121.9260426156618, 399820.435003917, 399820.4350039175, 121661.0503727912], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1663200.0000, 
sim time next is 1663800.0000, 
raw observation next is [18.15, 88.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5596594184399089, 6.911199999999999, 6.9112, 121.9260426156618, 407448.5366169081, 407448.5366169085, 122591.0048395988], 
processed observation next is [1.0, 0.2608695652173913, 0.22777777777777772, 0.8883333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.449574273049886, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1455173345060386, 0.14551733450603876, 0.23575193238384384], 
reward next is 0.7642, 
noisyNet noise sample is [array([-0.37302947], dtype=float32), -0.32709557]. 
=============================================
[2019-03-24 05:29:55,943] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.00000000e+00 4.22088095e-31 1.02591556e-22 3.88480679e-33
 1.09381611e-29], sum to 1.0000
[2019-03-24 05:29:55,951] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6689
[2019-03-24 05:29:55,955] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.26666666666667, 81.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7525664054922817, 6.9112, 6.9112, 121.9260426156618, 561003.944559554, 561003.944559554, 153251.181565351], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2076000.0000, 
sim time next is 2076600.0000, 
raw observation next is [23.18333333333334, 81.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7500118744265034, 6.9112, 6.9112, 121.9260426156618, 559198.8618241604, 559198.8618241604, 152863.2759661237], 
processed observation next is [0.0, 0.0, 0.4141975308641978, 0.8166666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6875148430331293, 0.0, 0.0, 0.8094621288201359, 0.19971387922291445, 0.19971387922291445, 0.29396783839639173], 
reward next is 0.7060, 
noisyNet noise sample is [array([-1.1115586], dtype=float32), 0.14143252]. 
=============================================
[2019-03-24 05:30:01,782] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.0865575e-15 2.2765878e-11 1.0345010e-17 7.3423052e-14], sum to 1.0000
[2019-03-24 05:30:01,790] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3901
[2019-03-24 05:30:01,797] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1439078.385616538 W.
[2019-03-24 05:30:01,802] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.36666666666667, 91.66666666666667, 1.0, 2.0, 0.4207116897627722, 1.0, 1.0, 0.4207116897627722, 1.0, 2.0, 0.6697867117255087, 6.911200000000001, 6.9112, 121.94756008, 1439078.385616538, 1439078.385616537, 306273.8244162389], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2197200.0000, 
sim time next is 2197800.0000, 
raw observation next is [24.35, 92.0, 1.0, 2.0, 0.6498782611023758, 1.0, 2.0, 0.6498782611023758, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1482015.878886948, 1482015.878886947, 285625.3122294198], 
processed observation next is [1.0, 0.43478260869565216, 0.4574074074074075, 0.92, 1.0, 1.0, 0.5831884060742569, 1.0, 1.0, 0.5831884060742569, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5292913853167672, 0.5292913853167668, 0.5492794465950381], 
reward next is 0.4507, 
noisyNet noise sample is [array([0.5892442], dtype=float32), 0.59573245]. 
=============================================
[2019-03-24 05:30:05,632] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 6.3235290e-28 4.3806062e-17 3.3834510e-35 2.6177126e-27], sum to 1.0000
[2019-03-24 05:30:05,639] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9034
[2019-03-24 05:30:05,643] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.7, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8482181313076331, 6.911199999999999, 6.9112, 121.9260426156618, 626096.1465590566, 626096.146559057, 167854.9158013305], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2235600.0000, 
sim time next is 2236200.0000, 
raw observation next is [22.7, 95.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8518227748610667, 6.911200000000001, 6.9112, 121.9260426156618, 628605.945992335, 628605.9459923345, 168358.1969638034], 
processed observation next is [1.0, 0.9130434782608695, 0.39629629629629626, 0.9516666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8147784685763334, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22450212356869106, 0.2245021235686909, 0.32376576339192964], 
reward next is 0.6762, 
noisyNet noise sample is [array([0.29020524], dtype=float32), -0.035972312]. 
=============================================
[2019-03-24 05:30:07,098] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.9994984e-24 6.6712997e-17 2.0887598e-26 1.6486093e-21], sum to 1.0000
[2019-03-24 05:30:07,105] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8108
[2019-03-24 05:30:07,110] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.4, 95.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6793168598786307, 6.9112, 6.9112, 121.9260426156618, 507637.5437539917, 507637.5437539917, 142400.8041351167], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2267400.0000, 
sim time next is 2268000.0000, 
raw observation next is [20.4, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6808407383148467, 6.9112, 6.9112, 121.9260426156618, 508779.4483758307, 508779.4483758307, 142614.9399623974], 
processed observation next is [1.0, 0.2608695652173913, 0.31111111111111106, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6010509228935583, 0.0, 0.0, 0.8094621288201359, 0.18170694584851096, 0.18170694584851096, 0.2742594999276873], 
reward next is 0.7257, 
noisyNet noise sample is [array([0.9635538], dtype=float32), -1.4508799]. 
=============================================
[2019-03-24 05:30:07,122] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[54.651215]
 [54.8358  ]
 [54.950657]
 [55.282516]
 [55.360218]], R is [[54.76296234]
 [54.94148254]
 [55.11854935]
 [55.29407501]
 [55.46785355]].
[2019-03-24 05:30:11,896] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.7992509e-20 2.7002757e-13 6.7730615e-21 2.7492155e-20], sum to 1.0000
[2019-03-24 05:30:11,902] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2889
[2019-03-24 05:30:11,907] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1367048.495337925 W.
[2019-03-24 05:30:11,910] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.01666666666667, 37.0, 1.0, 2.0, 0.3855494225237239, 1.0, 2.0, 0.3855494225237239, 1.0, 2.0, 0.6180931221536906, 6.9112, 6.9112, 121.94756008, 1367048.495337925, 1367048.495337925, 290705.44439253], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2386200.0000, 
sim time next is 2386800.0000, 
raw observation next is [31.0, 37.0, 1.0, 2.0, 0.3975952585558404, 1.0, 2.0, 0.3975952585558404, 1.0, 2.0, 0.6373071151630856, 6.9112, 6.9112, 121.94756008, 1409209.110885155, 1409209.110885155, 295945.9787331094], 
processed observation next is [1.0, 0.6521739130434783, 0.7037037037037037, 0.37, 1.0, 1.0, 0.28285149828076234, 1.0, 1.0, 0.28285149828076234, 1.0, 1.0, 0.546633893953857, 0.0, 0.0, 0.8096049824067558, 0.5032889681732696, 0.5032889681732696, 0.5691268821790566], 
reward next is 0.4309, 
noisyNet noise sample is [array([-1.068987], dtype=float32), -2.2799876]. 
=============================================
[2019-03-24 05:30:12,548] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 6.8441586e-33 1.2789752e-23 3.0457027e-37 1.0949265e-29], sum to 1.0000
[2019-03-24 05:30:12,558] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3245
[2019-03-24 05:30:12,565] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.8, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5894960357887576, 6.911200000000001, 6.9112, 121.9260426156618, 435837.2263587447, 435837.2263587443, 128302.9309353057], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2419200.0000, 
sim time next is 2419800.0000, 
raw observation next is [22.66666666666667, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.583770478087621, 6.911200000000001, 6.9112, 121.9260426156618, 430964.1874114231, 430964.1874114226, 127417.1145619559], 
processed observation next is [1.0, 0.0, 0.39506172839506193, 0.63, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.47971309760952613, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15391578121836538, 0.15391578121836522, 0.24503291261914595], 
reward next is 0.7550, 
noisyNet noise sample is [array([-0.21476454], dtype=float32), 0.9985489]. 
=============================================
[2019-03-24 05:30:13,165] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.5750580e-23 2.2908472e-16 2.2032084e-27 8.4965494e-22], sum to 1.0000
[2019-03-24 05:30:13,169] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8382
[2019-03-24 05:30:13,172] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.93333333333334, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5360229245361323, 6.911199999999999, 6.9112, 121.9260426156618, 385035.8896417869, 385035.8896417873, 118670.2383307043], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2430600.0000, 
sim time next is 2431200.0000, 
raw observation next is [19.76666666666667, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5085582553087508, 6.9112, 6.9112, 121.9260426156618, 365128.624477649, 365128.624477649, 116451.6762536598], 
processed observation next is [1.0, 0.13043478260869565, 0.2876543209876544, 0.7, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3856978191359384, 0.0, 0.0, 0.8094621288201359, 0.13040308017058894, 0.13040308017058894, 0.22394553125703806], 
reward next is 0.7761, 
noisyNet noise sample is [array([1.2104279], dtype=float32), -1.0758886]. 
=============================================
[2019-03-24 05:30:13,845] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.0611280e-26 3.6892162e-19 2.1603380e-28 1.0581944e-23], sum to 1.0000
[2019-03-24 05:30:13,852] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2885
[2019-03-24 05:30:13,856] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.7, 62.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5370624821150995, 6.9112, 6.9112, 121.9260426156618, 391537.9132002899, 391537.9132002899, 120924.9045623477], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2424000.0000, 
sim time next is 2424600.0000, 
raw observation next is [21.55, 62.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5304627577608253, 6.911199999999999, 6.9112, 121.9260426156618, 385695.9121220242, 385695.9121220246, 119956.9873854335], 
processed observation next is [1.0, 0.043478260869565216, 0.35370370370370374, 0.625, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4130784472010316, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1377485400435801, 0.1377485400435802, 0.23068651420275674], 
reward next is 0.7693, 
noisyNet noise sample is [array([-0.39301765], dtype=float32), 0.33999035]. 
=============================================
[2019-03-24 05:30:15,294] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.6208494e-26 3.9476265e-17 1.5070023e-29 1.4791101e-24], sum to 1.0000
[2019-03-24 05:30:15,304] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2403
[2019-03-24 05:30:15,308] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5523284661779517, 6.9112, 6.9112, 121.9260426156618, 404564.438648834, 404564.438648834, 123022.8589030757], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2422800.0000, 
sim time next is 2423400.0000, 
raw observation next is [21.85, 62.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5449424959068229, 6.9112, 6.9112, 121.9260426156618, 398282.6655142977, 398282.6655142977, 122006.6748426219], 
processed observation next is [1.0, 0.043478260869565216, 0.36481481481481487, 0.6283333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43117811988352855, 0.0, 0.0, 0.8094621288201359, 0.14224380911224918, 0.14224380911224918, 0.23462822085119595], 
reward next is 0.7654, 
noisyNet noise sample is [array([0.4188105], dtype=float32), -0.01797514]. 
=============================================
[2019-03-24 05:30:16,472] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 6.4334027e-30 1.3909292e-21 8.7766245e-31 7.2498992e-30], sum to 1.0000
[2019-03-24 05:30:16,480] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4117
[2019-03-24 05:30:16,488] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1700733.636917826 W.
[2019-03-24 05:30:16,491] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.23333333333333, 24.0, 1.0, 2.0, 0.4752927355821217, 1.0, 2.0, 0.4752927355821217, 1.0, 1.0, 0.7648287731908687, 6.9112, 6.9112, 121.94756008, 1700733.636917826, 1700733.636917826, 331400.9217474057], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2477400.0000, 
sim time next is 2478000.0000, 
raw observation next is [34.16666666666666, 24.0, 1.0, 2.0, 0.4758822987061535, 1.0, 2.0, 0.4758822987061535, 1.0, 2.0, 0.7646000420521963, 6.911199999999999, 6.9112, 121.94756008, 1697065.796673031, 1697065.796673031, 331762.644783091], 
processed observation next is [1.0, 0.6956521739130435, 0.8209876543209873, 0.24, 1.0, 1.0, 0.37605035560256367, 1.0, 1.0, 0.37605035560256367, 1.0, 1.0, 0.7057500525652455, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6060949273832253, 0.6060949273832253, 0.6380050861213288], 
reward next is 0.3620, 
noisyNet noise sample is [array([2.4122314], dtype=float32), 1.3403229]. 
=============================================
[2019-03-24 05:30:16,502] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[67.95943]
 [68.24186]
 [67.78832]
 [67.89402]
 [67.95987]], R is [[67.76785278]
 [67.4528656 ]
 [67.22721863]
 [67.00423431]
 [66.73919678]].
[2019-03-24 05:30:19,567] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 6.4063122e-24 9.8822519e-16 2.0875070e-28 5.7180824e-22], sum to 1.0000
[2019-03-24 05:30:19,578] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0691
[2019-03-24 05:30:19,582] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.26666666666667, 45.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6262344593742164, 6.911200000000001, 6.9112, 121.9260426156618, 466268.9511834961, 466268.9511834957, 134034.3280737826], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2501400.0000, 
sim time next is 2502000.0000, 
raw observation next is [27.1, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6278948059956124, 6.9112, 6.9112, 121.9260426156618, 467558.5333673784, 467558.5333673784, 134246.906038962], 
processed observation next is [1.0, 1.0, 0.5592592592592593, 0.46, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5348685074945155, 0.0, 0.0, 0.8094621288201359, 0.16698519048834942, 0.16698519048834942, 0.25816712699800387], 
reward next is 0.7418, 
noisyNet noise sample is [array([0.04190752], dtype=float32), -0.96839106]. 
=============================================
[2019-03-24 05:30:19,600] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[63.538033]
 [63.594467]
 [63.633102]
 [63.664368]
 [63.69548 ]], R is [[63.74357224]
 [63.84837723]
 [63.95226669]
 [64.05496979]
 [64.15678406]].
[2019-03-24 05:30:20,632] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 05:30:20,633] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:30:20,635] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:30:20,637] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:30:20,638] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:30:20,639] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:30:20,641] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:30:20,641] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:30:20,642] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:30:20,643] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:30:20,644] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:30:20,662] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run97
[2019-03-24 05:30:20,689] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run97
[2019-03-24 05:30:20,690] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run97
[2019-03-24 05:30:20,711] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run97
[2019-03-24 05:30:20,739] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run97
[2019-03-24 05:30:37,862] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48508593]
[2019-03-24 05:30:37,863] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.29646494, 62.15667424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.418218363800209, 6.9112, 6.9112, 121.9260426156618, 298600.6409736964, 298600.6409736964, 90953.59629727303]
[2019-03-24 05:30:37,864] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:30:37,866] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 4.5539769e-26 6.9917780e-18 1.0935408e-29 1.0476265e-24], sampled 0.9901006687467069
[2019-03-24 05:30:40,317] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48508593]
[2019-03-24 05:30:40,318] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [36.4, 19.0, 1.0, 2.0, 0.8899233276485217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.931870804810945, 6.9112, 121.9258912997541, 1111162.234579935, 1100576.948118013, 218915.2534839966]
[2019-03-24 05:30:40,319] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:30:40,322] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.3490420e-26 3.2489371e-18 2.7303578e-30 3.3649589e-25], sampled 0.18171344694579117
[2019-03-24 05:30:40,323] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1111162.234579935 W.
[2019-03-24 05:30:56,440] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48508593]
[2019-03-24 05:30:56,440] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 59.0, 1.0, 2.0, 0.6267267171488636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 718054.9214459126, 718054.9214459126, 162924.8219065095]
[2019-03-24 05:30:56,443] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:30:56,446] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.0765010e-21 6.4306792e-15 1.1630546e-24 1.4778271e-20], sampled 0.6815184996802509
[2019-03-24 05:30:56,448] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 718054.9214459126 W.
[2019-03-24 05:31:01,421] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48508593]
[2019-03-24 05:31:01,424] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.91666666666667, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8410223036255562, 6.9112, 6.9112, 121.9260426156618, 618900.1586241564, 618900.1586241564, 167481.7372285654]
[2019-03-24 05:31:01,426] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:31:01,431] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.6728023e-26 6.0653697e-18 8.5420124e-30 8.5597463e-25], sampled 0.18622901491213506
[2019-03-24 05:31:48,939] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48508593]
[2019-03-24 05:31:48,940] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.8145038, 92.68456395000001, 1.0, 2.0, 0.6356026134083624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 724372.4944778217, 724372.4944778217, 164309.6676685213]
[2019-03-24 05:31:48,943] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:31:48,947] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 7.0896769e-25 4.5951984e-17 2.5965375e-28 1.4307952e-23], sampled 0.8688108635006622
[2019-03-24 05:31:48,948] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 724372.4944778217 W.
[2019-03-24 05:31:52,644] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48508593]
[2019-03-24 05:31:52,645] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.1, 85.0, 1.0, 2.0, 0.8696180372845653, 1.0, 1.0, 0.8696180372845653, 0.0, 1.0, 0.0, 6.911200000000002, 6.9112, 121.9256957924135, 1983696.635962193, 1983696.635962192, 373361.80228456]
[2019-03-24 05:31:52,647] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:31:52,650] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 6.7371948e-20 1.0870676e-13 1.3383831e-22 7.5395786e-19], sampled 0.2023493185168761
[2019-03-24 05:31:52,651] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1983696.635962193 W.
[2019-03-24 05:32:09,289] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:32:09,458] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:32:09,500] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 05:32:09,560] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 05:32:09,758] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:32:10,774] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2400000, evaluation results [2400000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:32:12,468] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.7418644e-27 1.0668903e-20 2.7841002e-32 4.2031875e-25], sum to 1.0000
[2019-03-24 05:32:12,476] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6045
[2019-03-24 05:32:12,482] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.15, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7771517713664866, 6.9112, 6.9112, 121.9260426156618, 578972.5328413686, 578972.5328413686, 156472.8991559278], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2593800.0000, 
sim time next is 2594400.0000, 
raw observation next is [22.96666666666667, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.773917825920548, 6.9112, 6.9112, 121.9260426156618, 576708.3994582038, 576708.3994582038, 155971.137337288], 
processed observation next is [0.0, 0.0, 0.4061728395061729, 0.84, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7173972824006849, 0.0, 0.0, 0.8094621288201359, 0.20596728552078708, 0.20596728552078708, 0.2999444948794], 
reward next is 0.7001, 
noisyNet noise sample is [array([-1.2743322], dtype=float32), -0.78245455]. 
=============================================
[2019-03-24 05:32:17,775] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.8167043e-28 5.9132852e-17 3.2325389e-29 7.6506905e-26], sum to 1.0000
[2019-03-24 05:32:17,786] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6340
[2019-03-24 05:32:17,791] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.33333333333334, 94.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7664985609438817, 6.9112, 6.9112, 121.9260426156618, 571850.9361365397, 571850.9361365397, 154472.2281637622], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2695800.0000, 
sim time next is 2696400.0000, 
raw observation next is [21.2, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7486511526716836, 6.911199999999999, 6.9112, 121.9260426156618, 559069.157127115, 559069.1571271154, 151663.4567899397], 
processed observation next is [0.0, 0.21739130434782608, 0.34074074074074073, 0.93, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6858139408396043, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19966755611682677, 0.19966755611682693, 0.2916604938268071], 
reward next is 0.7083, 
noisyNet noise sample is [array([-1.3718438], dtype=float32), -0.5899755]. 
=============================================
[2019-03-24 05:32:20,291] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.00000000e+00 3.26579817e-26 1.00604336e-19 2.91585824e-29
 1.34785375e-26], sum to 1.0000
[2019-03-24 05:32:20,296] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1064
[2019-03-24 05:32:20,307] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.1, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7022019073442408, 6.911200000000001, 6.9112, 121.9260426156618, 524692.7872810373, 524692.7872810368, 144506.2777872302], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2698200.0000, 
sim time next is 2698800.0000, 
raw observation next is [21.06666666666667, 86.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.686170240976533, 6.9112, 6.9112, 121.9260426156618, 512500.1260645965, 512500.1260645965, 142132.3933032486], 
processed observation next is [0.0, 0.21739130434782608, 0.3358024691358026, 0.8633333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6077128012206662, 0.0, 0.0, 0.8094621288201359, 0.18303575930878446, 0.18303575930878446, 0.27333152558317036], 
reward next is 0.7267, 
noisyNet noise sample is [array([-1.0391194], dtype=float32), 0.13619366]. 
=============================================
[2019-03-24 05:32:22,508] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 7.5476393e-18 2.7994003e-12 3.1928117e-19 8.0755417e-16], sum to 1.0000
[2019-03-24 05:32:22,516] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9284
[2019-03-24 05:32:22,520] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 770401.3379961839 W.
[2019-03-24 05:32:22,529] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.83333333333334, 70.33333333333333, 1.0, 2.0, 0.6759704613931857, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 770401.3379961839, 770401.3379961831, 171644.2346968691], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2749800.0000, 
sim time next is 2750400.0000, 
raw observation next is [28.6, 72.0, 1.0, 2.0, 0.3405885481828883, 0.0, 2.0, 0.0, 1.0, 1.0, 0.542228060901786, 6.9112, 6.9112, 121.9260426156618, 776338.3280064305, 776338.3280064305, 206475.9713279508], 
processed observation next is [0.0, 0.8695652173913043, 0.6148148148148148, 0.72, 1.0, 1.0, 0.21498636688439085, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.42778507612723243, 0.0, 0.0, 0.8094621288201359, 0.2772636885737252, 0.2772636885737252, 0.3970691756306746], 
reward next is 0.6029, 
noisyNet noise sample is [array([1.5556382], dtype=float32), -0.5526674]. 
=============================================
[2019-03-24 05:32:23,809] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9999928e-01 2.3914698e-10 7.3972177e-07 2.0965415e-11 1.3884055e-09], sum to 1.0000
[2019-03-24 05:32:23,813] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9841
[2019-03-24 05:32:23,820] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2369231.263067852 W.
[2019-03-24 05:32:23,823] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.66666666666667, 55.66666666666667, 1.0, 2.0, 0.7578120114013703, 1.0, 2.0, 0.6922706676771199, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2369231.263067852, 2369231.263067852, 445136.4210991458], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2816400.0000, 
sim time next is 2817000.0000, 
raw observation next is [32.7, 56.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 7.474435183205573, 6.9112, 121.9238299614373, 2615979.448900832, 2327557.92793792, 443048.5644615735], 
processed observation next is [1.0, 0.6086956521739131, 0.7666666666666667, 0.56, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.25, 0.056323518320557306, 0.0, 0.8094474390970835, 0.9342783746074399, 0.8312706885492572, 0.8520164701184105], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7941139], dtype=float32), 0.64313775]. 
=============================================
[2019-03-24 05:32:23,841] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[24.880445]
 [24.941475]
 [24.748234]
 [24.395458]
 [24.450909]], R is [[24.66240692]
 [24.41578293]
 [24.17162514]
 [24.09016991]
 [24.02072144]].
[2019-03-24 05:32:28,922] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9987781e-01 1.9874217e-11 1.2219754e-04 9.7951183e-13 4.6892445e-10], sum to 1.0000
[2019-03-24 05:32:28,930] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4787
[2019-03-24 05:32:28,939] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1402392.496443921 W.
[2019-03-24 05:32:28,946] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 89.0, 1.0, 2.0, 0.6149945790329434, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9790913987955895, 6.9112, 6.9112, 121.9260426156618, 1402392.496443921, 1402392.496443921, 299738.3799285053], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2894400.0000, 
sim time next is 2895000.0000, 
raw observation next is [25.0, 89.0, 1.0, 2.0, 0.6080153190143195, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9679801895473099, 6.9112, 6.9112, 121.9260426156618, 1386463.053479616, 1386463.053479616, 296990.7509053385], 
processed observation next is [1.0, 0.5217391304347826, 0.48148148148148145, 0.89, 1.0, 1.0, 0.5333515702551422, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9599752369341374, 0.0, 0.0, 0.8094621288201359, 0.49516537624272, 0.49516537624272, 0.5711360594333432], 
reward next is 0.4289, 
noisyNet noise sample is [array([-0.25461385], dtype=float32), -0.26077738]. 
=============================================
[2019-03-24 05:32:28,961] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[31.37362 ]
 [31.044622]
 [30.946852]
 [30.687086]
 [30.514061]], R is [[31.85212898]
 [31.95718765]
 [32.05207443]
 [32.14459991]
 [32.21072769]].
[2019-03-24 05:32:33,364] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9561960e-01 9.6098910e-12 4.3803710e-03 2.7311383e-13 1.0925608e-08], sum to 1.0000
[2019-03-24 05:32:33,372] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1031
[2019-03-24 05:32:33,375] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1755376.883073316 W.
[2019-03-24 05:32:33,378] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.2, 77.16666666666667, 1.0, 2.0, 0.9125204761787, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1755376.883073316, 1755376.883073316, 359688.4833502441], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2985000.0000, 
sim time next is 2985600.0000, 
raw observation next is [29.4, 75.33333333333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 9.698619879377652, 6.9112, 121.9147917844377, 3306855.068692717, 1879578.669010175, 375454.8115645579], 
processed observation next is [1.0, 0.5652173913043478, 0.6444444444444444, 0.7533333333333334, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.2787419879377652, 0.0, 0.8093874350008478, 1.181019667390256, 0.6712780960750625, 0.722028483777996], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.27456743], dtype=float32), 1.3905509]. 
=============================================
[2019-03-24 05:32:33,873] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.99877691e-01 3.61008695e-10 1.22345984e-04 1.33420506e-11
 9.61444346e-09], sum to 1.0000
[2019-03-24 05:32:33,884] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5424
[2019-03-24 05:32:33,891] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1609371.947613218 W.
[2019-03-24 05:32:33,898] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.66666666666667, 87.33333333333334, 1.0, 2.0, 0.4704456192218929, 1.0, 1.0, 0.4704456192218929, 1.0, 2.0, 0.7489647471454328, 6.911199999999999, 6.9112, 121.94756008, 1609371.947613218, 1609371.947613218, 329314.485259388], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2971200.0000, 
sim time next is 2971800.0000, 
raw observation next is [27.0, 86.5, 1.0, 2.0, 0.8617107477403063, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1697377.876822903, 1697377.876822903, 348825.0440823358], 
processed observation next is [1.0, 0.391304347826087, 0.5555555555555556, 0.865, 1.0, 1.0, 0.8353699377860789, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.6062063845796082, 0.6062063845796082, 0.6708173924660303], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1964867], dtype=float32), -1.3619221]. 
=============================================
[2019-03-24 05:32:37,883] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9831569e-01 1.5054258e-10 1.6843734e-03 3.9277482e-13 4.6914628e-11], sum to 1.0000
[2019-03-24 05:32:37,888] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1597
[2019-03-24 05:32:37,891] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.890415603409585, 6.9112, 6.9112, 121.9260426156618, 658869.4793712854, 658869.4793712854, 172731.304855359], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3047400.0000, 
sim time next is 3048000.0000, 
raw observation next is [22.33333333333333, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8725233453978981, 6.9112, 6.9112, 121.9260426156618, 643149.7612290598, 643149.7612290598, 171222.4135181978], 
processed observation next is [1.0, 0.2608695652173913, 0.38271604938271586, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8406541817473725, 0.0, 0.0, 0.8094621288201359, 0.2296963432960928, 0.2296963432960928, 0.3292738721503804], 
reward next is 0.6707, 
noisyNet noise sample is [array([-0.23307855], dtype=float32), -0.037170168]. 
=============================================
[2019-03-24 05:32:37,907] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[33.902218]
 [33.773167]
 [33.446564]
 [33.32521 ]
 [32.375443]], R is [[34.52314377]
 [34.84573746]
 [35.17538071]
 [35.50703812]
 [35.84863281]].
[2019-03-24 05:32:40,945] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.5767299e-01 4.2148682e-13 1.4232697e-01 9.5114143e-15 8.6360189e-13], sum to 1.0000
[2019-03-24 05:32:40,950] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5460
[2019-03-24 05:32:40,959] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.75, 60.5, 1.0, 1.0, 0.2845460886754294, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4537366996074075, 6.9112, 6.9112, 121.9260426156618, 658772.2371803321, 658772.2371803321, 190922.9712566655], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3105000.0000, 
sim time next is 3105600.0000, 
raw observation next is [28.66666666666667, 61.33333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9062600798950735, 6.911199999999999, 6.9112, 121.9260426156618, 660163.1078343549, 660163.1078343553, 177350.5524630064], 
processed observation next is [1.0, 0.9565217391304348, 0.6172839506172841, 0.6133333333333334, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.882825099868842, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2357725385122696, 0.23577253851226976, 0.3410587547365508], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.322922], dtype=float32), 1.3621271]. 
=============================================
[2019-03-24 05:32:41,011] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9474263e-01 1.4317581e-14 5.2573145e-03 2.1254563e-16 3.3773144e-13], sum to 1.0000
[2019-03-24 05:32:41,021] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2350
[2019-03-24 05:32:41,027] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 788167.2921613285 W.
[2019-03-24 05:32:41,031] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.66666666666667, 77.33333333333334, 1.0, 2.0, 0.3457753839869359, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5504856724252788, 6.9112, 6.9112, 121.9260426156618, 788167.2921613285, 788167.2921613285, 207958.158758471], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3097200.0000, 
sim time next is 3097800.0000, 
raw observation next is [28.0, 74.5, 1.0, 2.0, 0.3423266676923453, 1.0, 1.0, 0.3423266676923453, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 780302.2182599519, 780302.2182599524, 190928.4166791549], 
processed observation next is [1.0, 0.8695652173913043, 0.5925925925925926, 0.745, 1.0, 1.0, 0.21705555677660157, 1.0, 0.5, 0.21705555677660157, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27867936366426854, 0.2786793636642687, 0.3671700320752979], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1741004], dtype=float32), -2.2600381]. 
=============================================
[2019-03-24 05:32:58,598] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 8.2051731e-19 1.6660742e-10 4.5502551e-21 7.9200516e-21], sum to 1.0000
[2019-03-24 05:32:58,602] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6280
[2019-03-24 05:32:58,607] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 745542.2979268327 W.
[2019-03-24 05:32:58,612] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.08333333333334, 92.5, 1.0, 2.0, 0.3270845430340014, 1.0, 1.0, 0.3270845430340014, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745542.2979268327, 745542.2979268327, 187087.512769729], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3455400.0000, 
sim time next is 3456000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3298150938545766, 1.0, 2.0, 0.3298150938545766, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 751769.2488673206, 751769.2488673211, 187769.7011872327], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.20216082601735308, 1.0, 1.0, 0.20216082601735308, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2684890174526145, 0.26848901745261466, 0.36109557920621677], 
reward next is 0.6389, 
noisyNet noise sample is [array([-0.45569092], dtype=float32), 0.42685887]. 
=============================================
[2019-03-24 05:32:58,630] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[40.561142]
 [40.537453]
 [40.771725]
 [40.49043 ]
 [40.525158]], R is [[37.68463516]
 [37.30778885]
 [37.61371994]
 [37.87950516]
 [37.50070953]].
[2019-03-24 05:33:00,169] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 05:33:00,170] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:33:00,171] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:33:00,171] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:33:00,172] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:33:00,172] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:33:00,172] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:33:00,175] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:33:00,176] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:33:00,173] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:33:00,179] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:33:00,199] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run98
[2019-03-24 05:33:00,227] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run98
[2019-03-24 05:33:00,252] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run98
[2019-03-24 05:33:00,278] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run98
[2019-03-24 05:33:00,302] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run98
[2019-03-24 05:33:04,326] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48440468]
[2019-03-24 05:33:04,326] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.52094420333333, 23.18801760333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6045770014910238, 6.911200000000001, 6.9112, 121.9260426156618, 433980.9390440214, 433980.939044021, 124202.338386399]
[2019-03-24 05:33:04,328] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:33:04,331] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.8839451e-19 3.6158314e-12 3.9473454e-22 1.5997723e-20], sampled 0.07330876515999496
[2019-03-24 05:33:20,803] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48440468]
[2019-03-24 05:33:20,803] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.56681477666667, 58.90621603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5291092654801262, 6.9112, 6.9112, 121.9260426156618, 382280.6515006573, 382280.6515006573, 118912.1081669996]
[2019-03-24 05:33:20,804] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:33:20,806] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.6659126e-20 8.2789900e-13 2.5016963e-23 1.2590086e-21], sampled 0.8460491339488372
[2019-03-24 05:33:29,261] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48440468]
[2019-03-24 05:33:29,262] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.48824288333333, 70.75935734000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.876516673264679, 6.911199999999999, 6.9112, 121.9260426156618, 641204.8498361126, 641204.849836113, 172903.6820570564]
[2019-03-24 05:33:29,264] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:33:29,266] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.2759920e-19 3.8145654e-12 4.4137063e-22 1.7712257e-20], sampled 0.9924430094225679
[2019-03-24 05:33:30,413] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48440468]
[2019-03-24 05:33:30,414] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.5, 41.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7048247846004154, 6.911199999999999, 6.9112, 121.9260426156618, 525980.6932530781, 525980.6932530786, 147153.6064878267]
[2019-03-24 05:33:30,416] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:33:30,418] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.7469526e-19 2.9165511e-12 2.6340167e-22 1.1015887e-20], sampled 0.5801102227557041
[2019-03-24 05:34:23,946] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48440468]
[2019-03-24 05:34:23,948] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.5, 87.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7378620477739939, 6.9112, 6.9112, 121.9260426156618, 549770.605846448, 549770.605846448, 151742.0304941585]
[2019-03-24 05:34:23,950] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:34:23,953] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.7955727e-17 5.1794617e-11 5.8506976e-20 1.6034153e-18], sampled 0.7488293712709246
[2019-03-24 05:34:32,821] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48440468]
[2019-03-24 05:34:32,822] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.43035349, 86.61988154000001, 1.0, 2.0, 0.8156332754452169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 929671.13111686, 929671.13111686, 199200.0457121944]
[2019-03-24 05:34:32,824] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:34:32,827] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.7873028e-14 6.8252484e-09 2.6059207e-16 4.0494557e-15], sampled 0.9505283188526417
[2019-03-24 05:34:32,830] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 929671.13111686 W.
[2019-03-24 05:34:41,380] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48440468]
[2019-03-24 05:34:41,382] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.16666666666667, 88.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9930851882903854, 6.932598520935948, 6.9112, 121.9258133087633, 725218.267975095, 714260.3332864706, 190591.8980829974]
[2019-03-24 05:34:41,383] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:34:41,386] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 9.8036495e-19 6.4054595e-12 1.1627325e-21 4.3298940e-20], sampled 0.4980147354605009
[2019-03-24 05:34:41,387] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 725218.267975095 W.
[2019-03-24 05:34:47,732] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48440468]
[2019-03-24 05:34:47,733] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.8, 36.33333333333334, 1.0, 2.0, 0.7240819770678295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 898717.344378623, 898717.344378623, 183647.6916614428]
[2019-03-24 05:34:47,733] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:34:47,736] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.8820319e-13 1.7202682e-08 2.8731267e-15 3.3946312e-14], sampled 0.9555083980208793
[2019-03-24 05:34:47,738] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 898717.344378623 W.
[2019-03-24 05:34:48,953] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 05:34:49,102] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:34:49,114] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:34:49,128] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:34:49,412] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 05:34:50,428] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2425000, evaluation results [2425000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:34:53,414] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.4450645e-19 3.1212981e-14 4.9474416e-20 1.8027398e-19], sum to 1.0000
[2019-03-24 05:34:53,419] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1063
[2019-03-24 05:34:53,422] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.13333333333333, 80.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7760093699315295, 6.911200000000001, 6.9112, 121.9260426156618, 578896.899932979, 578896.8999329786, 155660.981945674], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3559200.0000, 
sim time next is 3559800.0000, 
raw observation next is [23.16666666666666, 78.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7478436443051094, 6.911200000000001, 6.9112, 121.9260426156618, 558442.2371080577, 558442.2371080572, 151609.0819323524], 
processed observation next is [1.0, 0.17391304347826086, 0.41358024691358003, 0.7816666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6848045553813866, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1994436561100206, 0.19944365611002043, 0.29155592679298536], 
reward next is 0.7084, 
noisyNet noise sample is [array([-0.9929033], dtype=float32), 1.8785965]. 
=============================================
[2019-03-24 05:34:53,811] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 3.3650222e-18 5.5154114e-15 1.4593094e-24 2.1712762e-21], sum to 1.0000
[2019-03-24 05:34:53,821] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0813
[2019-03-24 05:34:53,829] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 93.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9069249220324416, 6.911199999999999, 6.9112, 121.9260426156618, 669125.4269153902, 669125.4269153905, 175534.5690006823], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3567000.0000, 
sim time next is 3567600.0000, 
raw observation next is [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.913000961162721, 6.9112, 6.9112, 121.9260426156618, 672755.6473275264, 672755.6473275264, 176586.9581807803], 
processed observation next is [1.0, 0.30434782608695654, 0.4074074074074074, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8912512014534013, 0.0, 0.0, 0.8094621288201359, 0.24026987404554512, 0.24026987404554512, 0.33959030419380826], 
reward next is 0.6604, 
noisyNet noise sample is [array([0.03559624], dtype=float32), -0.5407188]. 
=============================================
[2019-03-24 05:34:53,930] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.7557426e-17 6.6473485e-12 3.2907442e-20 1.2499612e-18], sum to 1.0000
[2019-03-24 05:34:53,940] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0340
[2019-03-24 05:34:53,946] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9130023901741355, 6.9112, 6.9112, 121.9260426156618, 672755.6473275264, 672755.6473275264, 176587.4446153484], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3567600.0000, 
sim time next is 3568200.0000, 
raw observation next is [22.81666666666667, 93.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9682054162388074, 6.999770366826032, 6.9112, 121.9256264145014, 759632.1490607255, 714276.3597412155, 183814.7962289476], 
processed observation next is [1.0, 0.30434782608695654, 0.4006172839506174, 0.9383333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9602567702985093, 0.008857036682603158, 0.0, 0.8094593656772495, 0.27129719609311626, 0.25509869990757694, 0.35348999274797616], 
reward next is 0.2037, 
noisyNet noise sample is [array([-1.3028836], dtype=float32), 0.45278063]. 
=============================================
[2019-03-24 05:34:55,566] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.4590684e-18 1.2320440e-09 5.5739223e-20 8.1909435e-19], sum to 1.0000
[2019-03-24 05:34:55,570] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1639
[2019-03-24 05:34:55,581] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 91.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.921511736051832, 6.911199999999999, 6.9112, 121.9260426156618, 679842.4175352481, 679842.4175352486, 177482.6030902716], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3565800.0000, 
sim time next is 3566400.0000, 
raw observation next is [23.0, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9074029265009919, 6.9112, 6.9112, 121.9260426156618, 670168.8691443327, 670168.8691443327, 175382.279509373], 
processed observation next is [1.0, 0.2608695652173913, 0.4074074074074074, 0.9233333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8842536581262397, 0.0, 0.0, 0.8094621288201359, 0.23934602469440455, 0.23934602469440455, 0.33727361444110193], 
reward next is 0.6627, 
noisyNet noise sample is [array([1.0327277], dtype=float32), -2.220203]. 
=============================================
[2019-03-24 05:34:57,275] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 7.9040392e-25 1.8592319e-14 5.9214341e-32 1.1215786e-25], sum to 1.0000
[2019-03-24 05:34:57,283] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7446
[2019-03-24 05:34:57,289] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.75, 78.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8433841785460436, 6.9112, 6.9112, 121.9260426156618, 622910.5811059331, 622910.5811059331, 167123.4366371497], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3613800.0000, 
sim time next is 3614400.0000, 
raw observation next is [24.7, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8360755751361182, 6.911200000000001, 6.9112, 121.9260426156618, 618619.3433118764, 618619.343311876, 165828.3154931659], 
processed observation next is [1.0, 0.8695652173913043, 0.4703703703703703, 0.78, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7950944689201478, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22093547975424158, 0.2209354797542414, 0.3189006067176267], 
reward next is 0.6811, 
noisyNet noise sample is [array([0.57926184], dtype=float32), 0.14419228]. 
=============================================
[2019-03-24 05:35:05,408] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999976e-01 6.3731411e-15 1.9014763e-07 1.8512678e-16 2.3478949e-15], sum to 1.0000
[2019-03-24 05:35:05,415] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7028
[2019-03-24 05:35:05,421] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 763011.3027394147 W.
[2019-03-24 05:35:05,426] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.66666666666667, 59.0, 1.0, 2.0, 0.6694894751616715, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763011.3027394147, 763011.3027394147, 170446.6249622595], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3792000.0000, 
sim time next is 3792600.0000, 
raw observation next is [30.5, 59.0, 1.0, 2.0, 0.2212580202994159, 1.0, 1.0, 0.2212580202994159, 1.0, 1.0, 0.3522499741873232, 6.9112, 6.9112, 121.94756008, 756494.2148861652, 756494.2148861652, 227664.6282244824], 
processed observation next is [1.0, 0.9130434782608695, 0.6851851851851852, 0.59, 1.0, 1.0, 0.0729262146421618, 1.0, 0.5, 0.0729262146421618, 1.0, 0.5, 0.19031246773415395, 0.0, 0.0, 0.8096049824067558, 0.27017650531648757, 0.27017650531648757, 0.4378165927393893], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.234385], dtype=float32), -0.3861318]. 
=============================================
[2019-03-24 05:35:06,105] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9960488e-01 1.2005606e-11 3.9519003e-04 1.9884752e-11 6.2963181e-12], sum to 1.0000
[2019-03-24 05:35:06,110] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9957
[2019-03-24 05:35:06,117] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 724261.0123698632 W.
[2019-03-24 05:35:06,124] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.23333333333333, 80.0, 1.0, 2.0, 0.2118349640893694, 1.0, 1.0, 0.2118349640893694, 1.0, 1.0, 0.3372481618134134, 6.911200000000001, 6.9112, 121.94756008, 724261.0123698632, 724261.0123698628, 224499.521476631], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3806400.0000, 
sim time next is 3807000.0000, 
raw observation next is [26.35, 78.0, 1.0, 2.0, 0.3134187337421878, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4989728314531097, 6.911199999999999, 6.9112, 121.9260426156618, 714378.5312731566, 714378.5312731571, 198884.4438358801], 
processed observation next is [0.0, 0.043478260869565216, 0.5314814814814816, 0.78, 1.0, 1.0, 0.18264134969308074, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.37371603931638714, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2551351897404131, 0.25513518974041327, 0.3824700842997695], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7114151], dtype=float32), -0.44775462]. 
=============================================
[2019-03-24 05:35:06,137] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[30.172998]
 [30.374313]
 [30.946863]
 [30.880339]
 [31.16884 ]], R is [[30.24659157]
 [29.94412613]
 [30.32828712]
 [30.66772842]
 [30.36105156]].
[2019-03-24 05:35:09,858] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.7916049e-13 1.8347716e-08 1.1321368e-16 2.0894727e-15], sum to 1.0000
[2019-03-24 05:35:09,870] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9095
[2019-03-24 05:35:09,875] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 836015.9827116717 W.
[2019-03-24 05:35:09,880] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.75, 69.83333333333333, 1.0, 2.0, 0.2445037239730921, 1.0, 1.0, 0.2445037239730921, 1.0, 1.0, 0.3892578914955313, 6.911200000000001, 6.9112, 121.94756008, 836015.9827116717, 836015.9827116713, 235684.9547694891], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3874200.0000, 
sim time next is 3874800.0000, 
raw observation next is [29.6, 70.66666666666667, 1.0, 2.0, 0.3640767656324707, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5796220680393591, 6.911199999999999, 6.9112, 121.9260426156618, 829906.4103241838, 829906.4103241842, 213276.8836030133], 
processed observation next is [0.0, 0.8695652173913043, 0.6518518518518519, 0.7066666666666667, 1.0, 1.0, 0.24294853051484608, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.47452758504919884, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29639514654435134, 0.2963951465443515, 0.4101478530827179], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3070744], dtype=float32), 0.26502642]. 
=============================================
[2019-03-24 05:35:11,508] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.9596789e-16 4.5576506e-08 8.8558850e-18 1.3441894e-16], sum to 1.0000
[2019-03-24 05:35:11,514] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3640
[2019-03-24 05:35:11,518] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 869335.2374055652 W.
[2019-03-24 05:35:11,522] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.25, 68.66666666666666, 1.0, 2.0, 0.3813642368527121, 0.0, 1.0, 0.0, 1.0, 2.0, 0.607144285235615, 6.911199999999999, 6.9112, 121.9260426156618, 869335.2374055652, 869335.2374055656, 218423.1781048381], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3873000.0000, 
sim time next is 3873600.0000, 
raw observation next is [29.9, 69.0, 1.0, 2.0, 0.3731026579809927, 0.0, 2.0, 0.0, 1.0, 2.0, 0.593991582610998, 6.911199999999999, 6.9112, 121.9260426156618, 850492.1842315187, 850492.1842315191, 215948.4206876412], 
processed observation next is [0.0, 0.8695652173913043, 0.6629629629629629, 0.69, 1.0, 1.0, 0.25369364045356274, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4924894782637475, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3037472086541138, 0.303747208654114, 0.41528542439931], 
reward next is 0.5847, 
noisyNet noise sample is [array([1.2176176], dtype=float32), 0.13422027]. 
=============================================
[2019-03-24 05:35:12,565] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9940515e-01 1.6727475e-11 5.9483526e-04 3.2135925e-14 3.4655407e-11], sum to 1.0000
[2019-03-24 05:35:12,571] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7038
[2019-03-24 05:35:12,574] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 841860.4242424456 W.
[2019-03-24 05:35:12,579] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.3693180672621276, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5879663909310499, 6.911199999999999, 6.9112, 121.9260426156618, 841860.4242424456, 841860.4242424461, 214824.2130249179], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3891600.0000, 
sim time next is 3892200.0000, 
raw observation next is [26.0, 93.50000000000001, 1.0, 2.0, 0.3682326868424057, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5862384299544803, 6.911199999999999, 6.9112, 121.9260426156618, 839384.9450982484, 839384.9450982489, 214502.6795541348], 
processed observation next is [0.0, 0.043478260869565216, 0.5185185185185185, 0.9350000000000002, 1.0, 1.0, 0.24789605576476867, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4827980374431003, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2997803375350887, 0.29978033753508887, 0.4125051529887208], 
reward next is 0.5875, 
noisyNet noise sample is [array([-1.2147439], dtype=float32), -0.88035053]. 
=============================================
[2019-03-24 05:35:16,050] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999845e-01 4.1965057e-15 1.5435826e-06 3.6834207e-17 1.3531398e-15], sum to 1.0000
[2019-03-24 05:35:16,058] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3678
[2019-03-24 05:35:16,065] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 901781.1093844986 W.
[2019-03-24 05:35:16,070] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.43333333333333, 93.83333333333334, 1.0, 2.0, 0.2637262818472006, 1.0, 2.0, 0.2637262818472006, 1.0, 2.0, 0.4198608296661163, 6.911199999999999, 6.9112, 121.94756008, 901781.1093844986, 901781.109384499, 242545.2677914947], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3999000.0000, 
sim time next is 3999600.0000, 
raw observation next is [24.4, 94.0, 1.0, 2.0, 0.2516711960394499, 1.0, 2.0, 0.2516711960394499, 1.0, 2.0, 0.4006687404534417, 6.911199999999999, 6.9112, 121.94756008, 860537.0183999364, 860537.0183999368, 238218.816750664], 
processed observation next is [1.0, 0.30434782608695654, 0.4592592592592592, 0.94, 1.0, 1.0, 0.10913237623744032, 1.0, 1.0, 0.10913237623744032, 1.0, 1.0, 0.25083592556680206, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3073346494285487, 0.3073346494285489, 0.4581131091358923], 
reward next is 0.5419, 
noisyNet noise sample is [array([0.55260456], dtype=float32), -0.8101681]. 
=============================================
[2019-03-24 05:35:16,208] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.00000000e+00 2.17304050e-14 1.52879764e-09 1.01032925e-16
 1.75167028e-15], sum to 1.0000
[2019-03-24 05:35:16,214] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1770
[2019-03-24 05:35:16,221] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 817107.1646480252 W.
[2019-03-24 05:35:16,226] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.75, 74.5, 1.0, 2.0, 0.7169295539510803, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 817107.1646480252, 817107.1646480248, 179374.8327116529], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3925800.0000, 
sim time next is 3926400.0000, 
raw observation next is [29.0, 73.0, 1.0, 2.0, 0.2399675098806792, 1.0, 1.0, 0.2399675098806792, 1.0, 1.0, 0.3820360909262309, 6.9112, 6.9112, 121.94756008, 820497.2947124537, 820497.2947124537, 234096.1320903766], 
processed observation next is [0.0, 0.43478260869565216, 0.6296296296296297, 0.73, 1.0, 1.0, 0.09519941652461808, 1.0, 0.5, 0.09519941652461808, 1.0, 0.5, 0.22754511365778862, 0.0, 0.0, 0.8096049824067558, 0.29303474811159064, 0.29303474811159064, 0.45018486940457036], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.99089175], dtype=float32), 0.12340156]. 
=============================================
[2019-03-24 05:35:18,937] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 8.0211077e-16 1.5637421e-09 2.2321643e-21 8.4958538e-18], sum to 1.0000
[2019-03-24 05:35:18,946] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7579
[2019-03-24 05:35:18,954] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 876455.4969246779 W.
[2019-03-24 05:35:18,961] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.58333333333333, 79.83333333333333, 1.0, 2.0, 0.3844860021359811, 1.0, 1.0, 0.3844860021359811, 0.0, 1.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 876455.4969246779, 876455.4969246787, 201970.6839955243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4036200.0000, 
sim time next is 4036800.0000, 
raw observation next is [26.46666666666667, 81.66666666666667, 1.0, 2.0, 0.6097773176522985, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694927.0313673953, 694927.0313673953, 159767.7939189299], 
processed observation next is [1.0, 0.7391304347826086, 0.5358024691358025, 0.8166666666666668, 1.0, 1.0, 0.5354491876813077, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24818822548835548, 0.24818822548835548, 0.30724575753640365], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.44086337], dtype=float32), 0.4059862]. 
=============================================
[2019-03-24 05:35:19,400] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9999952e-01 6.9045319e-15 4.5431912e-07 6.0046682e-15 2.7480470e-15], sum to 1.0000
[2019-03-24 05:35:19,406] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9483
[2019-03-24 05:35:19,411] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 719807.7290248133 W.
[2019-03-24 05:35:19,415] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.25, 94.0, 1.0, 2.0, 0.6278373537032733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719807.7290248133, 719807.7290248133, 163144.6746086932], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4055400.0000, 
sim time next is 4056000.0000, 
raw observation next is [24.33333333333333, 92.0, 1.0, 2.0, 0.3101085116128836, 1.0, 1.0, 0.3101085116128836, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 706830.02953396, 706830.0295339605, 182903.9896281567], 
processed observation next is [1.0, 0.9565217391304348, 0.45679012345678993, 0.92, 1.0, 1.0, 0.17870060906295668, 1.0, 0.5, 0.17870060906295668, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2524392962621286, 0.25243929626212874, 0.35173844159260903], 
reward next is 0.6483, 
noisyNet noise sample is [array([-1.255253], dtype=float32), 0.16058284]. 
=============================================
[2019-03-24 05:35:19,437] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[37.36937 ]
 [37.385437]
 [37.675583]
 [37.439903]
 [37.541832]], R is [[37.4928894 ]
 [37.80422211]
 [37.42618179]
 [37.05192184]
 [37.31853104]].
[2019-03-24 05:35:22,292] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 6.3202782e-19 2.6091276e-13 6.5698840e-22 8.6087522e-21], sum to 1.0000
[2019-03-24 05:35:22,300] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4252
[2019-03-24 05:35:22,306] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.83333333333333, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8926044089399435, 6.911200000000001, 6.9112, 121.9260426156618, 665937.4467494552, 665937.4467494547, 169907.5075706182], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4085400.0000, 
sim time next is 4086000.0000, 
raw observation next is [21.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9581123385760189, 7.18223359280142, 6.9112, 121.9250553919663, 853112.1976657455, 714319.8972410788, 178780.5747092814], 
processed observation next is [1.0, 0.30434782608695654, 0.3333333333333333, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9476404232200236, 0.02710335928014196, 0.0, 0.809455574681438, 0.30468292773776623, 0.255114249014671, 0.3438087975178489], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.05705529], dtype=float32), 1.1803149]. 
=============================================
[2019-03-24 05:35:22,327] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[49.136246]
 [49.324936]
 [49.49602 ]
 [49.594704]
 [49.41745 ]], R is [[47.8976593 ]
 [48.09193802]
 [48.28708267]
 [48.48266983]
 [48.67855835]].
[2019-03-24 05:35:23,138] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999940e-01 1.6542305e-10 6.1254605e-07 2.2183820e-13 3.8084566e-12], sum to 1.0000
[2019-03-24 05:35:23,144] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4494
[2019-03-24 05:35:23,150] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1391585.827524933 W.
[2019-03-24 05:35:23,159] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.78333333333333, 83.16666666666667, 1.0, 2.0, 0.5944220077370188, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9500410467375623, 6.911199999999999, 6.9112, 121.9260426156618, 1391585.827524933, 1391585.827524933, 291017.4423243593], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4092600.0000, 
sim time next is 4093200.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.4046616879434451, 1.0, 1.0, 0.4046616879434451, 1.0, 2.0, 0.6446525998632097, 6.911199999999997, 6.9112, 121.94756008, 1396175.07175167, 1396175.071751672, 299195.5506932514], 
processed observation next is [1.0, 0.391304347826087, 0.4444444444444444, 0.83, 1.0, 1.0, 0.29126391421838704, 1.0, 0.5, 0.29126391421838704, 1.0, 1.0, 0.555815749829012, -2.6645352591003756e-16, 0.0, 0.8096049824067558, 0.498633954197025, 0.4986339541970257, 0.5753760590254835], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4710565], dtype=float32), 0.54192346]. 
=============================================
[2019-03-24 05:35:28,237] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.8785017e-24 1.0674461e-16 1.5700585e-26 1.5903432e-25], sum to 1.0000
[2019-03-24 05:35:28,243] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2920
[2019-03-24 05:35:28,259] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1925009.654478578 W.
[2019-03-24 05:35:28,268] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.25, 29.0, 1.0, 2.0, 0.8181698031228631, 1.0, 1.0, 0.8181698031228631, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9259314429362, 1925009.654478578, 1925009.654478578, 354271.191786084], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4206600.0000, 
sim time next is 4207200.0000, 
raw observation next is [34.33333333333334, 27.33333333333334, 1.0, 2.0, 0.7413517405227823, 1.0, 2.0, 0.7413517405227823, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260425817623, 1755557.778920557, 1755557.778920558, 323211.2733256136], 
processed observation next is [1.0, 0.6956521739130435, 0.8271604938271608, 0.2733333333333334, 1.0, 1.0, 0.6920854053842647, 1.0, 1.0, 0.6920854053842647, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621285950785, 0.626984921043056, 0.6269849210430565, 0.6215601410107954], 
reward next is 0.3784, 
noisyNet noise sample is [array([0.7837765], dtype=float32), 1.2812555]. 
=============================================
[2019-03-24 05:35:39,818] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 05:35:39,819] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:35:39,819] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:35:39,821] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:35:39,820] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:35:39,821] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:35:39,821] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:35:39,823] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:35:39,823] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:35:39,826] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:35:39,825] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:35:39,852] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run99
[2019-03-24 05:35:39,876] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run99
[2019-03-24 05:35:39,914] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run99
[2019-03-24 05:35:39,915] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run99
[2019-03-24 05:35:39,937] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run99
[2019-03-24 05:35:48,350] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48571843]
[2019-03-24 05:35:48,351] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.82612812833333, 77.62196356333332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6985912026774447, 6.911200000000001, 6.9112, 121.9260426156618, 509572.3760924117, 509572.3760924112, 135496.948793287]
[2019-03-24 05:35:48,351] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:35:48,355] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 9.6546067e-26 8.6203238e-20 5.8331574e-28 2.4478822e-27], sampled 0.3854383479902205
[2019-03-24 05:35:50,688] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48571843]
[2019-03-24 05:35:50,690] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.66637066666667, 45.99437939666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.642308381268115, 6.911200000000001, 6.9112, 121.9260426156618, 479963.414764679, 479963.4147646785, 138897.4557037288]
[2019-03-24 05:35:50,691] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:35:50,695] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 5.7618629e-26 5.8566145e-20 3.3156044e-28 1.4110515e-27], sampled 0.6712919201456687
[2019-03-24 05:36:14,244] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48571843]
[2019-03-24 05:36:14,247] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.01178060666667, 89.65790844333333, 1.0, 1.0, 0.5160691077833093, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 650546.0437715218, 650546.0437715218, 146370.4416373058]
[2019-03-24 05:36:14,248] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:36:14,251] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.4830532e-22 3.4483863e-17 3.0960353e-24 1.0474392e-23], sampled 0.8990166953337493
[2019-03-24 05:36:27,904] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48571843]
[2019-03-24 05:36:27,906] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.099910775, 69.49241222500001, 1.0, 2.0, 0.9210716382511984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1051517.675849825, 1051517.675849825, 222306.8579363459]
[2019-03-24 05:36:27,908] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:36:27,911] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.9630669e-20 1.3767019e-15 5.5470624e-22 1.6964899e-21], sampled 0.9205299807542797
[2019-03-24 05:36:27,912] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1051517.675849825 W.
[2019-03-24 05:36:33,980] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48571843]
[2019-03-24 05:36:33,980] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 79.0, 1.0, 2.0, 0.6398942500171596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 729265.8385497429, 729265.8385497425, 165076.7980780685]
[2019-03-24 05:36:33,982] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:36:33,985] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.8781200e-21 2.3842770e-16 4.1697502e-23 1.4097800e-22], sampled 0.0372955075152922
[2019-03-24 05:36:33,985] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 729265.8385497429 W.
[2019-03-24 05:37:05,234] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48571843]
[2019-03-24 05:37:05,235] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.15098025, 81.47291518666667, 1.0, 2.0, 0.5491141139937148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 649898.5241447863, 649898.5241447863, 150628.6088183677]
[2019-03-24 05:37:05,238] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:37:05,241] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 6.1088461e-23 1.6121313e-17 5.5648151e-25 2.3323343e-24], sampled 0.5755686949843565
[2019-03-24 05:37:09,347] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48571843]
[2019-03-24 05:37:09,348] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.20532664, 71.38895238, 1.0, 2.0, 1.016400288003287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.245713757843479, 6.9112, 121.9244963603791, 1330109.760171724, 1158810.990078852, 244717.1593176724]
[2019-03-24 05:37:09,349] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:37:09,352] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.2588507e-20 1.0603767e-15 1.8654335e-22 6.8862559e-22], sampled 0.5673988885362917
[2019-03-24 05:37:09,353] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1330109.760171724 W.
[2019-03-24 05:37:15,471] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.48571843]
[2019-03-24 05:37:15,472] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.46666666666667, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7898029063294064, 6.911199999999999, 6.9112, 121.9260426156618, 585784.0086485489, 585784.0086485493, 159456.5447903795]
[2019-03-24 05:37:15,472] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:37:15,474] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.6152798e-27 7.0475457e-21 1.6108307e-29 7.3978309e-29], sampled 0.14866116094741344
[2019-03-24 05:37:27,859] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 05:37:28,054] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 05:37:28,192] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:37:28,225] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:37:28,243] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:37:29,257] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2450000, evaluation results [2450000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:37:29,967] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 5.7434793e-24 5.4528904e-19 8.9982590e-26 1.9810496e-25], sum to 1.0000
[2019-03-24 05:37:29,978] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2153
[2019-03-24 05:37:29,984] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 787626.5409732563 W.
[2019-03-24 05:37:29,987] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.66666666666667, 68.33333333333333, 1.0, 2.0, 0.3455382738787673, 1.0, 1.0, 0.3455382738787673, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 787626.5409732563, 787626.5409732563, 191748.4923254062], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4459200.0000, 
sim time next is 4459800.0000, 
raw observation next is [29.83333333333333, 69.16666666666667, 1.0, 2.0, 0.3527447628897255, 1.0, 2.0, 0.3527447628897255, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 804061.765644078, 804061.7656440785, 193600.6820556476], 
processed observation next is [0.0, 0.6086956521739131, 0.6604938271604937, 0.6916666666666668, 1.0, 1.0, 0.22945805105919703, 1.0, 1.0, 0.22945805105919703, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28716491630145646, 0.28716491630145663, 0.37230900395316846], 
reward next is 0.6277, 
noisyNet noise sample is [array([-0.06589965], dtype=float32), -0.4304249]. 
=============================================
[2019-03-24 05:37:30,270] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.7157398e-27 2.7200384e-20 1.9011880e-30 2.1932515e-30], sum to 1.0000
[2019-03-24 05:37:30,276] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5882
[2019-03-24 05:37:30,282] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.45, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8983915206015279, 6.911200000000001, 6.9112, 121.9260426156618, 658218.8365694726, 658218.8365694721, 175579.1996796869], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4433400.0000, 
sim time next is 4434000.0000, 
raw observation next is [23.6, 90.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8881960224534293, 6.911200000000001, 6.9112, 121.9260426156618, 652134.100157905, 652134.1001579047, 173922.0950960412], 
processed observation next is [0.0, 0.30434782608695654, 0.4296296296296297, 0.9066666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8602450280667867, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23290503577068036, 0.23290503577068025, 0.3344655674923869], 
reward next is 0.6655, 
noisyNet noise sample is [array([-1.751818], dtype=float32), 0.39245698]. 
=============================================
[2019-03-24 05:37:30,295] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[56.014786]
 [56.071835]
 [56.168808]
 [56.307674]
 [56.462574]], R is [[56.08253098]
 [56.18405151]
 [56.28159714]
 [56.37611771]
 [56.4705162 ]].
[2019-03-24 05:37:38,004] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.5241980e-27 1.3653344e-19 2.2003013e-28 6.0731644e-28], sum to 1.0000
[2019-03-24 05:37:38,014] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5183
[2019-03-24 05:37:38,022] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.3, 98.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9419084175067512, 6.911199999999999, 6.9112, 121.9260426156618, 685218.259842172, 685218.2598421725, 182342.391242633], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4551600.0000, 
sim time next is 4552200.0000, 
raw observation next is [23.45, 97.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9476758490148255, 6.911200000000001, 6.9112, 121.9260426156618, 688831.8409311901, 688831.8409311896, 183229.8095543211], 
processed observation next is [0.0, 0.6956521739130435, 0.42407407407407405, 0.975, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9345948112685317, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2460113717611393, 0.24601137176113913, 0.35236501837369444], 
reward next is 0.6476, 
noisyNet noise sample is [array([0.35707694], dtype=float32), -1.1267029]. 
=============================================
[2019-03-24 05:37:42,294] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.0842622e-19 2.8964879e-16 9.5308017e-21 4.7859572e-21], sum to 1.0000
[2019-03-24 05:37:42,304] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2436
[2019-03-24 05:37:42,313] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 736352.036072764 W.
[2019-03-24 05:37:42,321] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.26666666666667, 97.0, 1.0, 2.0, 0.2153697010607571, 1.0, 1.0, 0.2153697010607571, 1.0, 1.0, 0.342875578190209, 6.9112, 6.9112, 121.94756008, 736352.036072764, 736352.036072764, 225680.9806140421], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4999200.0000, 
sim time next is 4999800.0000, 
raw observation next is [24.13333333333333, 98.5, 1.0, 2.0, 0.3240185526914716, 1.0, 2.0, 0.3240185526914716, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 738550.4460682799, 738550.4460682804, 186324.4933993984], 
processed observation next is [1.0, 0.8695652173913043, 0.44938271604938257, 0.985, 1.0, 1.0, 0.19526018177556145, 1.0, 1.0, 0.19526018177556145, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2637680164529571, 0.2637680164529573, 0.35831633346038155], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0206528], dtype=float32), -0.032656357]. 
=============================================
[2019-03-24 05:37:46,050] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 5.8517361e-16 2.4229852e-11 4.7030015e-18 4.7082277e-17], sum to 1.0000
[2019-03-24 05:37:46,061] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6082
[2019-03-24 05:37:46,070] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 807587.4429072902 W.
[2019-03-24 05:37:46,075] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.13333333333333, 83.16666666666666, 1.0, 2.0, 0.3542906756548724, 1.0, 2.0, 0.3542906756548724, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 807587.4429072902, 807587.4429072906, 194000.8979123931], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4729800.0000, 
sim time next is 4730400.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.3581544557246444, 1.0, 2.0, 0.3581544557246444, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 816399.4221392071, 816399.4221392076, 195003.2990677118], 
processed observation next is [1.0, 0.782608695652174, 0.5925925925925926, 0.84, 1.0, 1.0, 0.23589816157695762, 1.0, 1.0, 0.23589816157695762, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.291571222192574, 0.29157122219257414, 0.37500634436098423], 
reward next is 0.6250, 
noisyNet noise sample is [array([-1.303437], dtype=float32), 0.7439413]. 
=============================================
[2019-03-24 05:37:48,845] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.1192705e-15 1.6955831e-11 3.0625003e-16 3.7636792e-16], sum to 1.0000
[2019-03-24 05:37:48,853] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2777
[2019-03-24 05:37:48,854] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 836780.8092424313 W.
[2019-03-24 05:37:48,859] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.53333333333333, 90.66666666666667, 1.0, 2.0, 0.3670908927613891, 1.0, 1.0, 0.3670908927613891, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 836780.8092424313, 836780.8092424313, 197342.0530525977], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4815600.0000, 
sim time next is 4816200.0000, 
raw observation next is [27.26666666666667, 92.33333333333334, 1.0, 2.0, 0.3728998719102224, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5936687405820505, 6.9112, 6.9112, 121.9260426156618, 850029.6745043976, 850029.6745043976, 215891.2111416699], 
processed observation next is [1.0, 0.7391304347826086, 0.5654320987654322, 0.9233333333333335, 1.0, 1.0, 0.25345222846455046, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.49208592572756316, 0.0, 0.0, 0.8094621288201359, 0.3035820266087134, 0.3035820266087134, 0.41517540604167286], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.30409062], dtype=float32), 0.04075858]. 
=============================================
[2019-03-24 05:37:48,945] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.2727585e-17 6.9858848e-11 2.7184879e-16 1.8763281e-18], sum to 1.0000
[2019-03-24 05:37:48,953] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7302
[2019-03-24 05:37:48,959] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 769623.1923828269 W.
[2019-03-24 05:37:48,963] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.11666666666667, 87.83333333333334, 1.0, 2.0, 0.3376440192490093, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5375402749424382, 6.911199999999999, 6.9112, 121.9260426156618, 769623.1923828269, 769623.1923828274, 205639.2219557479], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4740600.0000, 
sim time next is 4741200.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.3392633817154841, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5401183527280199, 6.911199999999999, 6.9112, 121.9260426156618, 773316.2167658072, 773316.2167658077, 206098.9947832342], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.89, 1.0, 1.0, 0.2134087877565287, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.42514794091002484, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2761843631306454, 0.2761843631306456, 0.39634422073698883], 
reward next is 0.6037, 
noisyNet noise sample is [array([-1.0599186], dtype=float32), 0.7525604]. 
=============================================
[2019-03-24 05:37:49,440] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.2473849e-17 1.6251547e-12 3.4127094e-19 9.5084773e-19], sum to 1.0000
[2019-03-24 05:37:49,447] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0831
[2019-03-24 05:37:49,451] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.33333333333334, 97.33333333333333, 1.0, 2.0, 0.5776502126836757, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668126.8154224965, 668126.8154224965, 154748.4105234145], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4771200.0000, 
sim time next is 4771800.0000, 
raw observation next is [23.25, 98.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9118750203920633, 6.911200000000001, 6.9112, 121.9260426156618, 663816.6199618395, 663816.619961839, 178178.232883297], 
processed observation next is [1.0, 0.21739130434782608, 0.4166666666666667, 0.98, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.889843775490079, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23707736427208553, 0.23707736427208537, 0.3426504478524942], 
reward next is 0.6573, 
noisyNet noise sample is [array([0.12490311], dtype=float32), -0.17086384]. 
=============================================
[2019-03-24 05:37:51,751] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.3115350e-15 3.3126321e-10 5.3026168e-17 1.6434278e-15], sum to 1.0000
[2019-03-24 05:37:51,752] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1994
[2019-03-24 05:37:51,754] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1596910.157630209 W.
[2019-03-24 05:37:51,758] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.96666666666667, 93.83333333333334, 1.0, 2.0, 0.46680608722846, 1.0, 2.0, 0.46680608722846, 1.0, 2.0, 0.7431704936806057, 6.9112, 6.9112, 121.94756008, 1596910.157630209, 1596910.157630209, 327582.0226442314], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4870200.0000, 
sim time next is 4870800.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.4837905704481954, 1.0, 2.0, 0.4837905704481954, 1.0, 2.0, 0.7702103441124258, 6.9112, 6.9112, 121.94756008, 1655066.666512168, 1655066.666512168, 335704.5117057311], 
processed observation next is [1.0, 0.391304347826087, 0.5185185185185185, 0.94, 1.0, 1.0, 0.3854649648192802, 1.0, 1.0, 0.3854649648192802, 1.0, 1.0, 0.7127629301405322, 0.0, 0.0, 0.8096049824067558, 0.59109523804006, 0.59109523804006, 0.6455855994340983], 
reward next is 0.3544, 
noisyNet noise sample is [array([1.2678565], dtype=float32), -0.123952635]. 
=============================================
[2019-03-24 05:37:55,644] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9999988e-01 1.0629161e-11 1.5434412e-07 1.1313317e-12 1.5953369e-11], sum to 1.0000
[2019-03-24 05:37:55,650] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2810
[2019-03-24 05:37:55,655] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 736718.8917516309 W.
[2019-03-24 05:37:55,657] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 87.0, 1.0, 2.0, 0.3164071407200519, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5050899065499657, 6.911199999999999, 6.9112, 121.926042615649, 736718.8917516309, 736718.8917516313, 199351.8152680348], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4948800.0000, 
sim time next is 4949400.0000, 
raw observation next is [24.0, 88.0, 1.0, 2.0, 0.3235219444087142, 1.0, 1.0, 0.3235219444087142, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 749880.6678218995, 749880.6678218995, 186797.6213430733], 
processed observation next is [1.0, 0.2608695652173913, 0.4444444444444444, 0.88, 1.0, 1.0, 0.19466898143894545, 1.0, 0.5, 0.19466898143894545, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.267814524222107, 0.267814524222107, 0.35922619489052554], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41072825], dtype=float32), 1.1565406]. 
=============================================
[2019-03-24 05:37:57,890] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9509853e-01 1.4266683e-09 4.9014948e-03 9.0557645e-11 5.9364185e-09], sum to 1.0000
[2019-03-24 05:37:57,896] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2193
[2019-03-24 05:37:57,904] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 761642.6988456412 W.
[2019-03-24 05:37:57,911] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.3341446082607289, 1.0, 2.0, 0.3341446082607289, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 761642.6988456412, 761642.6988456412, 188857.0878415273], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4990200.0000, 
sim time next is 4990800.0000, 
raw observation next is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.3426385540610795, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5454917370238969, 6.911199999999999, 6.9112, 121.9260426156618, 781013.4968002306, 781013.496800231, 207061.1136207323], 
processed observation next is [1.0, 0.782608695652174, 0.5432098765432101, 0.8566666666666667, 1.0, 1.0, 0.2174268500727137, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.43186467127987105, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27893339171436804, 0.2789333917143682, 0.398194449270639], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.34068006], dtype=float32), 0.6296839]. 
=============================================
[2019-03-24 05:38:00,175] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9996197e-01 5.4813704e-15 3.8045629e-05 2.0263804e-19 2.7535682e-15], sum to 1.0000
[2019-03-24 05:38:00,181] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9880
[2019-03-24 05:38:00,186] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.93288167867769, 6.9112, 6.9112, 121.9260426156618, 677304.6612336868, 677304.6612336868, 181312.8108551606], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5036400.0000, 
sim time next is 5037000.0000, 
raw observation next is [24.25, 92.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9424901924086654, 6.9112, 6.9112, 121.9260426156618, 683084.6467424227, 683084.6467424227, 182806.8956211357], 
processed observation next is [0.0, 0.30434782608695654, 0.4537037037037037, 0.9250000000000002, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9281127405108316, 0.0, 0.0, 0.8094621288201359, 0.2439588024080081, 0.2439588024080081, 0.3515517223483379], 
reward next is 0.6484, 
noisyNet noise sample is [array([-0.34257957], dtype=float32), -0.65053743]. 
=============================================
[2019-03-24 05:38:00,198] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[50.278187]
 [50.323116]
 [50.384705]
 [50.648285]
 [50.766037]], R is [[50.2571373 ]
 [50.4058876 ]
 [50.5578804 ]
 [50.71264267]
 [50.86958694]].
[2019-03-24 05:38:05,631] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 8.3844636e-16 3.0763730e-10 1.0286299e-17 4.3985777e-15], sum to 1.0000
[2019-03-24 05:38:05,639] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9744
[2019-03-24 05:38:05,644] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 884531.3215504761 W.
[2019-03-24 05:38:05,652] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.45, 70.5, 1.0, 2.0, 0.388026684739794, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6177511192526288, 6.911199999999999, 6.9112, 121.9260426156618, 884531.3215504761, 884531.3215504765, 220439.8416927792], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5059800.0000, 
sim time next is 5060400.0000, 
raw observation next is [30.6, 69.0, 1.0, 2.0, 0.3870178137726626, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6161449638163222, 6.911199999999999, 6.9112, 121.9260426156618, 882230.2128074856, 882230.2128074861, 220133.1323610797], 
processed observation next is [0.0, 0.5652173913043478, 0.688888888888889, 0.69, 1.0, 1.0, 0.2702593021103126, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5201812047704027, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3150822188598163, 0.31508221885981647, 0.4233329468482302], 
reward next is 0.5767, 
noisyNet noise sample is [array([0.41333583], dtype=float32), -0.25641954]. 
=============================================
[2019-03-24 05:38:09,911] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9992692e-01 1.1423283e-09 7.3026698e-05 7.8427487e-10 2.7884730e-09], sum to 1.0000
[2019-03-24 05:38:09,918] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1562
[2019-03-24 05:38:09,924] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 762864.6900605148 W.
[2019-03-24 05:38:09,927] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.9, 93.66666666666667, 1.0, 2.0, 0.3346804483459645, 1.0, 2.0, 0.3346804483459645, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 762864.6900605148, 762864.6900605148, 188991.4333205855], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5188200.0000, 
sim time next is 5188800.0000, 
raw observation next is [24.8, 93.33333333333334, 1.0, 2.0, 0.2207956768116293, 1.0, 2.0, 0.2207956768116293, 1.0, 1.0, 0.3515139082972908, 6.9112, 6.9112, 121.94756008, 754912.656965353, 754912.656965353, 227508.1730228351], 
processed observation next is [1.0, 0.043478260869565216, 0.4740740740740741, 0.9333333333333335, 1.0, 1.0, 0.0723758057281301, 1.0, 1.0, 0.0723758057281301, 1.0, 0.5, 0.18939238537161346, 0.0, 0.0, 0.8096049824067558, 0.26961166320191177, 0.26961166320191177, 0.437515717351606], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.82892436], dtype=float32), 0.2644158]. 
=============================================
[2019-03-24 05:38:10,397] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999964e-01 4.3814532e-11 3.8807536e-07 5.3168014e-14 7.5486969e-12], sum to 1.0000
[2019-03-24 05:38:10,410] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2047
[2019-03-24 05:38:10,414] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 783457.7691426538 W.
[2019-03-24 05:38:10,419] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.81666666666667, 90.83333333333334, 1.0, 2.0, 0.2291402429306212, 1.0, 2.0, 0.2291402429306212, 1.0, 2.0, 0.3647987293222716, 6.9112, 6.9112, 121.94756008, 783457.7691426538, 783457.7691426538, 230350.3337657113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5529000.0000, 
sim time next is 5529600.0000, 
raw observation next is [25.8, 91.0, 1.0, 2.0, 0.6871463363622005, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783144.9532099488, 783144.9532099488, 173724.6770035722], 
processed observation next is [1.0, 0.0, 0.5111111111111112, 0.91, 1.0, 1.0, 0.6275551623359529, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2796946261464103, 0.2796946261464103, 0.33408591731456194], 
reward next is 0.6659, 
noisyNet noise sample is [array([-1.512101], dtype=float32), 1.393886]. 
=============================================
[2019-03-24 05:38:14,782] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.2542299e-05 1.4244456e-11 9.9996746e-01 2.4094599e-10 8.4237402e-11], sum to 1.0000
[2019-03-24 05:38:14,796] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0267
[2019-03-24 05:38:14,802] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.28333333333333, 96.33333333333333, 1.0, 2.0, 0.3227668079140173, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5138552699801836, 6.911199999999999, 6.9112, 121.9260426156618, 735695.9172341208, 735695.9172341212, 201463.1402652077], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5609400.0000, 
sim time next is 5610000.0000, 
raw observation next is [24.16666666666667, 96.66666666666666, 1.0, 2.0, 0.3203699722524447, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5100394295474722, 6.9112, 6.9112, 121.9260426156618, 730230.1070320953, 730230.1070320953, 200798.753225493], 
processed observation next is [1.0, 0.9565217391304348, 0.45061728395061745, 0.9666666666666666, 1.0, 1.0, 0.19091663363386271, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.38754928693434015, 0.0, 0.0, 0.8094621288201359, 0.2607964667971769, 0.2607964667971769, 0.3861514485105635], 
reward next is 0.6138, 
noisyNet noise sample is [array([-2.1187325], dtype=float32), -0.5747052]. 
=============================================
[2019-03-24 05:38:14,814] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[44.4961  ]
 [44.09351 ]
 [44.0717  ]
 [43.687   ]
 [43.330612]], R is [[44.7125473 ]
 [44.87799454]
 [45.0405159 ]
 [45.20026779]
 [45.35754776]].
[2019-03-24 05:38:16,371] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5526657e-05 1.5804222e-12 9.9997449e-01 1.2737522e-12 3.2396741e-09], sum to 1.0000
[2019-03-24 05:38:16,379] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3485
[2019-03-24 05:38:16,385] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.25, 83.5, 1.0, 2.0, 0.629873813454381, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9812900678989586, 6.911199999999999, 6.9112, 121.9260424557745, 1446443.511468992, 1446443.511468992, 301822.3942755989], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5308200.0000, 
sim time next is 5308800.0000, 
raw observation next is [24.4, 83.0, 1.0, 2.0, 0.6318843045858858, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9825569780945879, 6.9112, 6.9112, 121.9260426156131, 1447614.35076187, 1447614.35076187, 302433.5400056852], 
processed observation next is [1.0, 0.43478260869565216, 0.4592592592592592, 0.83, 1.0, 1.0, 0.5617670292689118, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9781962226182347, 0.0, 0.0, 0.8094621288198126, 0.5170051252720964, 0.5170051252720964, 0.5816029615493946], 
reward next is 0.4184, 
noisyNet noise sample is [array([0.7116059], dtype=float32), -1.8660165]. 
=============================================
[2019-03-24 05:38:18,812] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 05:38:18,814] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:38:18,814] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:38:18,815] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:38:18,816] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:38:18,816] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:38:18,818] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:38:18,818] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:38:18,815] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:38:18,823] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:38:18,825] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:38:18,842] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run100
[2019-03-24 05:38:18,866] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run100
[2019-03-24 05:38:18,891] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run100
[2019-03-24 05:38:18,912] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run100
[2019-03-24 05:38:18,945] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run100
[2019-03-24 05:38:20,976] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.49083096]
[2019-03-24 05:38:20,977] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.76666666666667, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6240058861754223, 6.911199999999999, 6.9112, 121.9260426156618, 445571.9676638002, 445571.9676638006, 108388.8178229852]
[2019-03-24 05:38:20,977] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:38:20,980] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9809152e-01 5.6690905e-14 1.9084504e-03 1.0586327e-13 1.8747829e-12], sampled 0.7033559891689685
[2019-03-24 05:38:24,670] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.49083096]
[2019-03-24 05:38:24,672] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.0, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4418413231176156, 6.911200000000001, 6.9112, 121.9260426156618, 315470.4428748226, 315470.4428748221, 103569.1039456567]
[2019-03-24 05:38:24,674] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:38:24,677] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9811006e-01 1.7942687e-14 1.8899984e-03 3.4892279e-14 7.1236100e-13], sampled 0.9718284689192633
[2019-03-24 05:39:00,691] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.49083096]
[2019-03-24 05:39:00,692] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.8, 84.66666666666666, 1.0, 2.0, 0.3100523007152881, 0.0, 2.0, 0.0, 1.0, 1.0, 0.493613360437216, 6.911199999999999, 6.9112, 121.9260426156618, 706701.8490321349, 706701.8490321353, 197966.0727664479]
[2019-03-24 05:39:00,694] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:39:00,698] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.4108815e-01 3.2045390e-13 2.5891185e-01 6.9250991e-13 1.6031048e-11], sampled 0.16479700508115613
[2019-03-24 05:39:00,701] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 706701.8490321349 W.
[2019-03-24 05:39:03,938] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.49083096]
[2019-03-24 05:39:03,939] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.70040748, 90.85100321, 1.0, 2.0, 0.674668177909316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 768916.3853073483, 768916.3853073479, 171403.5033646641]
[2019-03-24 05:39:03,940] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:39:03,943] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.8637995e-01 5.6538673e-14 4.1362011e-01 1.0576907e-13 2.5028638e-12], sampled 0.7466170748031398
[2019-03-24 05:39:15,707] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.49083096]
[2019-03-24 05:39:15,708] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.28333333333333, 97.33333333333334, 1.0, 1.0, 0.6024659438382108, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9258794040437, 727319.7723870352, 727319.7723870352, 160232.585710641]
[2019-03-24 05:39:15,709] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:39:15,711] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.8470843e-01 9.4631453e-13 1.5291579e-02 1.9561867e-12 3.1654887e-11], sampled 0.2279673817086143
[2019-03-24 05:39:15,712] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 727319.7723870352 W.
[2019-03-24 05:39:33,118] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.49083096]
[2019-03-24 05:39:33,118] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.093400065, 94.35124676000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8444080030222934, 6.911199999999999, 6.9112, 121.9260426156618, 620378.8825046873, 620378.8825046878, 168165.3528431588]
[2019-03-24 05:39:33,119] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:39:33,121] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9765837e-01 2.4485422e-14 2.3415643e-03 4.8434045e-14 9.7132014e-13], sampled 0.006503904166411778
[2019-03-24 05:39:34,255] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.49083096]
[2019-03-24 05:39:34,256] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.26666666666667, 77.5, 1.0, 2.0, 0.7534424856320291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 858745.41481327, 858745.41481327, 186514.2111172276]
[2019-03-24 05:39:34,257] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:39:34,259] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.82443953e-01 6.08866087e-15 4.17556018e-01 1.19204285e-14
 3.64369993e-13], sampled 0.09494792996920853
[2019-03-24 05:39:34,260] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 858745.41481327 W.
[2019-03-24 05:40:03,578] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.49083096]
[2019-03-24 05:40:03,579] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.76666666666667, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5577752766281947, 6.9112, 6.9112, 121.9260426156618, 409770.8072932655, 409770.8072932655, 124057.3487395914]
[2019-03-24 05:40:03,581] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:40:03,584] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.85434532e-01 3.30340308e-14 1.45654585e-02 7.22308904e-14
 1.79638032e-12], sampled 0.2743547123094926
[2019-03-24 05:40:06,257] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7921.3986 2304553009.6410 427.0000
[2019-03-24 05:40:06,436] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8067.8814 2257852965.9201 441.0000
[2019-03-24 05:40:06,462] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7933.9325 2326938389.8201 596.0000
[2019-03-24 05:40:06,495] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7322.9207 2569684376.3603 711.0000
[2019-03-24 05:40:06,669] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 7794.0248 2378420134.2335 527.0000
[2019-03-24 05:40:07,689] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2475000, evaluation results [2475000.0, 7322.920732217631, 2569684376.3603106, 711.0, 7921.398620255718, 2304553009.6410494, 427.0, 8067.88143239411, 2257852965.920077, 441.0, 7794.024828473522, 2378420134.233517, 527.0, 7933.932507634008, 2326938389.8201246, 596.0]
[2019-03-24 05:40:09,938] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9753749e-01 5.5185908e-12 2.4624611e-03 1.4027472e-12 9.4698263e-11], sum to 1.0000
[2019-03-24 05:40:09,947] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8381
[2019-03-24 05:40:09,953] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 878127.3455058383 W.
[2019-03-24 05:40:09,956] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.86666666666667, 80.5, 1.0, 2.0, 0.7704379870522295, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 878127.3455058383, 878127.3455058383, 189914.0067536978], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5428200.0000, 
sim time next is 5428800.0000, 
raw observation next is [28.8, 81.0, 1.0, 2.0, 0.3863056944156784, 0.0, 2.0, 0.0, 1.0, 1.0, 0.615011246607895, 6.911200000000001, 6.9112, 121.9260426156618, 880605.9616045929, 880605.9616045924, 219917.9883479952], 
processed observation next is [1.0, 0.8695652173913043, 0.6222222222222222, 0.81, 1.0, 1.0, 0.26941154097104575, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.5187640582598687, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31450212914449743, 0.31450212914449727, 0.42291920836152924], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.87867975], dtype=float32), 0.5287492]. 
=============================================
[2019-03-24 05:40:13,114] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9986482e-01 7.9893979e-08 1.3489545e-04 3.2836049e-08 8.7355787e-08], sum to 1.0000
[2019-03-24 05:40:13,120] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4245
[2019-03-24 05:40:13,125] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2045052.340021229 W.
[2019-03-24 05:40:13,129] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.3, 88.0, 1.0, 2.0, 0.8964845486302004, 1.0, 2.0, 0.8964845486302004, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156555, 2045052.340021229, 2045052.340021229, 385238.1725839531], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5475600.0000, 
sim time next is 5476200.0000, 
raw observation next is [28.43333333333334, 87.50000000000001, 1.0, 2.0, 0.942708592463329, 1.0, 2.0, 0.942708592463329, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2150625.188878336, 2150625.188878336, 406254.3825473294], 
processed observation next is [1.0, 0.391304347826087, 0.6086419753086423, 0.8750000000000001, 1.0, 1.0, 0.9317959434087251, 1.0, 1.0, 0.9317959434087251, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7680804245994057, 0.7680804245994057, 0.7812584279756335], 
reward next is 0.2187, 
noisyNet noise sample is [array([-0.68906754], dtype=float32), 0.8168256]. 
=============================================
[2019-03-24 05:40:13,172] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9852872e-01 3.1123076e-08 1.4712252e-03 7.2479862e-09 2.7944131e-08], sum to 1.0000
[2019-03-24 05:40:13,180] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9623
[2019-03-24 05:40:13,187] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1777976.648026766 W.
[2019-03-24 05:40:13,191] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.09999999999999, 70.0, 1.0, 2.0, 0.7795236568858208, 1.0, 2.0, 0.7795236568858208, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.926042484081, 1777976.648026766, 1777976.648026766, 335368.5242870655], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5489400.0000, 
sim time next is 5490000.0000, 
raw observation next is [32.3, 69.0, 1.0, 2.0, 0.6385983223214771, 1.0, 2.0, 0.6326638231371732, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2164985.133034901, 2164985.133034901, 413147.9400759045], 
processed observation next is [1.0, 0.5652173913043478, 0.7518518518518518, 0.69, 1.0, 1.0, 0.5697599075255679, 1.0, 1.0, 0.5626950275442537, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.7732089760838933, 0.7732089760838933, 0.7945152693767393], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.75535536], dtype=float32), -2.4333315]. 
=============================================
[2019-03-24 05:40:13,204] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[21.959513]
 [21.670288]
 [21.175884]
 [21.191832]
 [21.192026]], R is [[21.58691216]
 [21.37104416]
 [21.15733337]
 [20.94576073]
 [20.73630333]].
[2019-03-24 05:40:18,288] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999928e-01 3.3024516e-19 7.2260951e-07 6.9310110e-19 2.2961288e-17], sum to 1.0000
[2019-03-24 05:40:18,294] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0243
[2019-03-24 05:40:18,301] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.16666666666667, 80.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6501532467528328, 6.911199999999999, 6.9112, 121.9260426156618, 479729.0760221634, 479729.0760221639, 133486.8356401713], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5897400.0000, 
sim time next is 5898000.0000, 
raw observation next is [20.33333333333334, 79.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5977218859263451, 6.911200000000001, 6.9112, 121.9260426156618, 441425.5885179161, 441425.5885179156, 128779.2029517705], 
processed observation next is [1.0, 0.2608695652173913, 0.3086419753086422, 0.7966666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.49715235740793134, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15765199589925574, 0.15765199589925558, 0.2476523133687894], 
reward next is 0.7523, 
noisyNet noise sample is [array([0.3032717], dtype=float32), -0.1544514]. 
=============================================
[2019-03-24 05:40:18,312] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[50.32841 ]
 [50.687164]
 [51.073444]
 [51.36093 ]
 [51.401913]], R is [[50.38835144]
 [50.62776184]
 [50.87981415]
 [51.13230896]
 [51.38346863]].
[2019-03-24 05:40:20,992] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9992931e-01 2.5213066e-20 7.0733578e-05 1.7118162e-20 2.2044459e-14], sum to 1.0000
[2019-03-24 05:40:20,998] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2211
[2019-03-24 05:40:21,005] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 757076.2021957712 W.
[2019-03-24 05:40:21,013] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.86666666666667, 94.66666666666667, 1.0, 2.0, 0.2214281548606322, 1.0, 2.0, 0.2214281548606322, 1.0, 1.0, 0.3525208339496754, 6.9112, 6.9112, 121.94756008, 757076.2021957712, 757076.2021957712, 227722.2311791144], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5606400.0000, 
sim time next is 5607000.0000, 
raw observation next is [24.75, 95.0, 1.0, 2.0, 0.220151898318081, 1.0, 2.0, 0.220151898318081, 1.0, 2.0, 0.3504889919691601, 6.9112, 6.9112, 121.94756008, 752710.4620819241, 752710.4620819241, 227290.5200911614], 
processed observation next is [1.0, 0.9130434782608695, 0.4722222222222222, 0.95, 1.0, 1.0, 0.07160940275962023, 1.0, 1.0, 0.07160940275962023, 1.0, 1.0, 0.18811123996145013, 0.0, 0.0, 0.8096049824067558, 0.2688251650292586, 0.2688251650292586, 0.4370971540214642], 
reward next is 0.5629, 
noisyNet noise sample is [array([0.29163727], dtype=float32), -0.301761]. 
=============================================
[2019-03-24 05:40:21,027] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[68.85288]
 [68.39759]
 [68.49967]
 [68.24564]
 [69.00399]], R is [[69.64287567]
 [69.50852203]
 [69.44992828]
 [69.3904953 ]
 [69.33010864]].
[2019-03-24 05:40:23,236] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9781173e-01 7.2480914e-12 2.1883361e-03 8.5536405e-16 2.1220911e-08], sum to 1.0000
[2019-03-24 05:40:23,243] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0321
[2019-03-24 05:40:23,250] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 830269.8912265389 W.
[2019-03-24 05:40:23,255] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.56666666666667, 67.33333333333334, 1.0, 2.0, 0.3642361369920762, 1.0, 2.0, 0.3642361369920762, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 830269.8912265389, 830269.8912265389, 196591.3695678192], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5678400.0000, 
sim time next is 5679000.0000, 
raw observation next is [30.4, 68.5, 1.0, 2.0, 0.2447728278398268, 1.0, 2.0, 0.2447728278398268, 1.0, 1.0, 0.389686313615474, 6.911200000000001, 6.9112, 121.94756008, 836936.6146838333, 836936.614683833, 235779.5704830505], 
processed observation next is [0.0, 0.7391304347826086, 0.6814814814814815, 0.685, 1.0, 1.0, 0.10092003314265094, 1.0, 1.0, 0.10092003314265094, 1.0, 0.5, 0.2371078920193425, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2989059338156548, 0.2989059338156546, 0.4534222509289433], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6177828], dtype=float32), 0.94926083]. 
=============================================
[2019-03-24 05:40:23,275] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[36.229385]
 [36.645218]
 [36.239193]
 [35.868237]
 [36.298397]], R is [[36.21308899]
 [36.47290039]
 [36.65855026]
 [36.29196548]
 [36.58146667]].
[2019-03-24 05:40:23,366] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9999905e-01 7.5432580e-14 9.0396838e-07 8.7896498e-16 5.7765587e-11], sum to 1.0000
[2019-03-24 05:40:23,372] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9644
[2019-03-24 05:40:23,377] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 757747.2103923681 W.
[2019-03-24 05:40:23,380] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 88.0, 1.0, 2.0, 0.6648728812690844, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757747.2103923681, 757747.2103923681, 169600.2578160146], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5650200.0000, 
sim time next is 5650800.0000, 
raw observation next is [26.16666666666666, 87.33333333333333, 1.0, 2.0, 0.3348065751783992, 1.0, 1.0, 0.3348065751783992, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763152.3244447547, 763152.3244447547, 189023.581615627], 
processed observation next is [0.0, 0.391304347826087, 0.5246913580246911, 0.8733333333333333, 1.0, 1.0, 0.20810306568857045, 1.0, 0.5, 0.20810306568857045, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2725544015874124, 0.2725544015874124, 0.3635068877223596], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7902397], dtype=float32), -0.6849299]. 
=============================================
[2019-03-24 05:40:30,527] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999464e-01 3.6511476e-24 5.3453282e-06 3.1051584e-26 2.6374150e-19], sum to 1.0000
[2019-03-24 05:40:30,532] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2566
[2019-03-24 05:40:30,536] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.03333333333334, 85.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.781546945916065, 6.911200000000001, 6.9112, 121.9260426156618, 581595.902271298, 581595.9022712975, 157447.230452327], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5789400.0000, 
sim time next is 5790000.0000, 
raw observation next is [22.96666666666667, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.777765414563371, 6.911200000000001, 6.9112, 121.9260426156618, 578951.0772841612, 578951.0772841608, 156879.3173954522], 
processed observation next is [1.0, 0.0, 0.4061728395061729, 0.8533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7222067682042138, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20676824188720044, 0.20676824188720028, 0.30169099499125424], 
reward next is 0.6983, 
noisyNet noise sample is [array([-0.155767], dtype=float32), 0.2727009]. 
=============================================
[2019-03-24 05:40:30,548] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.47903]
 [71.81729]
 [77.43785]
 [77.33599]
 [77.22838]], R is [[66.60945892]
 [66.64058685]
 [66.67015076]
 [66.69774628]
 [66.72338104]].
[2019-03-24 05:40:31,699] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9901581e-01 3.6221626e-14 9.8414242e-04 1.1604883e-16 1.2064168e-10], sum to 1.0000
[2019-03-24 05:40:31,705] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2084
[2019-03-24 05:40:31,716] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 829369.4387058218 W.
[2019-03-24 05:40:31,723] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.96666666666667, 46.33333333333334, 1.0, 2.0, 0.3361448899355821, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5548793546201921, 6.911200000000001, 6.9112, 121.9260426156492, 829369.4387058218, 829369.4387058214, 202129.5277692575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5833200.0000, 
sim time next is 5833800.0000, 
raw observation next is [27.05, 46.5, 1.0, 2.0, 0.6459751119341743, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 802481.9342062882, 802481.9342062882, 168697.5224822034], 
processed observation next is [1.0, 0.5217391304347826, 0.5574074074074075, 0.465, 1.0, 1.0, 0.5785417999216361, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2866006907879601, 0.2866006907879601, 0.3244183124657758], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.0082357], dtype=float32), 0.8771881]. 
=============================================
[2019-03-24 05:40:43,035] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 6.4001112e-23 1.1890616e-15 1.8513303e-25 4.7008242e-21], sum to 1.0000
[2019-03-24 05:40:43,043] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6201
[2019-03-24 05:40:43,047] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.8, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8030750058868001, 6.911200000000001, 6.9112, 121.9260426156618, 596445.4925761998, 596445.4925761994, 160738.5792093593], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6053400.0000, 
sim time next is 6054000.0000, 
raw observation next is [22.66666666666666, 89.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8023863065563693, 6.911200000000001, 6.9112, 121.9260426156618, 596156.4978418107, 596156.4978418102, 160541.6335498954], 
processed observation next is [1.0, 0.043478260869565216, 0.3950617283950615, 0.8966666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7529828831954616, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21291303494350383, 0.21291303494350367, 0.30873391067287576], 
reward next is 0.6913, 
noisyNet noise sample is [array([0.42134073], dtype=float32), -0.31762233]. 
=============================================
[2019-03-24 05:40:43,064] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[53.093407]
 [53.417435]
 [53.753197]
 [54.029083]
 [54.240734]], R is [[53.0412178 ]
 [53.20169449]
 [53.36008453]
 [53.51599503]
 [53.66963959]].
[2019-03-24 05:40:43,277] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.00000000e+00 1.08194875e-19 3.06117501e-12 1.15997692e-21
 1.84383270e-16], sum to 1.0000
[2019-03-24 05:40:43,283] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2751
[2019-03-24 05:40:43,288] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.65, 89.33333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8844948695434887, 6.911199999999999, 6.9112, 121.9260426156618, 656129.3709600344, 656129.3709600349, 171307.8483620595], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6058200.0000, 
sim time next is 6058800.0000, 
raw observation next is [22.7, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9106466615867976, 6.9112, 6.9112, 121.9260426156618, 676895.7647392354, 676895.7647392354, 174027.9231272179], 
processed observation next is [1.0, 0.13043478260869565, 0.39629629629629626, 0.89, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.888308326983497, 0.0, 0.0, 0.8094621288201359, 0.24174848740686977, 0.24174848740686977, 0.33466908293695746], 
reward next is 0.6653, 
noisyNet noise sample is [array([-0.4703719], dtype=float32), -0.3471944]. 
=============================================
[2019-03-24 05:40:49,799] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.3973484e-21 1.6163042e-12 2.0837549e-25 7.4103041e-17], sum to 1.0000
[2019-03-24 05:40:49,804] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2115
[2019-03-24 05:40:49,808] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.76666666666667, 73.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.857412782984946, 6.911200000000001, 6.9112, 121.9260426156618, 631937.0368069203, 631937.0368069198, 169303.1619042859], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6131400.0000, 
sim time next is 6132000.0000, 
raw observation next is [25.63333333333334, 74.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8570181505202789, 6.9112, 6.9112, 121.9260426156618, 631659.3949750976, 631659.3949750976, 169248.9927464655], 
processed observation next is [1.0, 1.0, 0.5049382716049385, 0.7466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8212726881503485, 0.0, 0.0, 0.8094621288201359, 0.22559264106253488, 0.22559264106253488, 0.32547883220474133], 
reward next is 0.6745, 
noisyNet noise sample is [array([-1.1713955], dtype=float32), -1.1513834]. 
=============================================
[2019-03-24 05:40:49,836] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[54.054256]
 [53.98776 ]
 [53.82284 ]
 [53.812145]
 [53.784023]], R is [[54.2450676 ]
 [54.37703323]
 [54.50744629]
 [54.63611603]
 [54.76312637]].
[2019-03-24 05:40:52,921] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 4.7112016e-28 4.7635827e-24 2.4966740e-29 1.4680755e-24], sum to 1.0000
[2019-03-24 05:40:52,929] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7709
[2019-03-24 05:40:52,935] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.45, 81.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8445486657833952, 6.9112, 6.9112, 121.9260426156618, 623702.0935820574, 623702.0935820574, 167292.2191425782], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6250200.0000, 
sim time next is 6250800.0000, 
raw observation next is [24.6, 81.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8501832236186013, 6.911200000000001, 6.9112, 121.9260426156618, 627156.2633626353, 627156.2633626348, 168222.4652851059], 
processed observation next is [0.0, 0.34782608695652173, 0.46666666666666673, 0.8133333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8127290295232517, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22398437977236973, 0.22398437977236957, 0.32350474093289594], 
reward next is 0.6765, 
noisyNet noise sample is [array([0.15092401], dtype=float32), -2.0028274]. 
=============================================
[2019-03-24 05:40:55,923] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.2342386e-20 4.9740168e-10 1.7177182e-22 1.4794314e-17], sum to 1.0000
[2019-03-24 05:40:55,929] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0812
[2019-03-24 05:40:55,946] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 744189.0667893143 W.
[2019-03-24 05:40:55,949] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.2, 60.66666666666667, 1.0, 2.0, 0.3264911411108993, 1.0, 2.0, 0.3264911411108993, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 744189.0667893143, 744189.0667893147, 186939.5633693353], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6280800.0000, 
sim time next is 6281400.0000, 
raw observation next is [30.25, 60.33333333333333, 1.0, 2.0, 0.3273095094476269, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5210873987671504, 6.9112, 6.9112, 121.9260426156618, 746055.3261368161, 746055.3261368161, 202728.9459615469], 
processed observation next is [0.0, 0.6956521739130435, 0.6759259259259259, 0.6033333333333333, 1.0, 1.0, 0.19917798743765106, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.40135924845893794, 0.0, 0.0, 0.8094621288201359, 0.2664483307631486, 0.2664483307631486, 0.38986335761835944], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.47272], dtype=float32), -1.3026893]. 
=============================================
[2019-03-24 05:40:57,340] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.4226953e-27 2.3242289e-21 1.3827870e-29 8.0866950e-25], sum to 1.0000
[2019-03-24 05:40:57,350] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3616
[2019-03-24 05:40:57,355] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.8, 83.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9090787991343103, 6.911199999999999, 6.9112, 121.9260426156618, 665857.5372472125, 665857.537247213, 177042.1471988003], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6305400.0000, 
sim time next is 6306000.0000, 
raw observation next is [24.76666666666667, 83.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9081086713099416, 6.911200000000001, 6.9112, 121.9260426156618, 665239.5407282684, 665239.540728268, 176892.9784727259], 
processed observation next is [0.0, 1.0, 0.4728395061728396, 0.8366666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.885135839137427, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23758555026009587, 0.2375855502600957, 0.3401788047552421], 
reward next is 0.6598, 
noisyNet noise sample is [array([-0.9519383], dtype=float32), 0.74240994]. 
=============================================
[2019-03-24 05:40:57,370] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 05:40:57,373] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[63.939503]
 [63.809803]
 [63.720043]
 [63.77327 ]
 [63.738876]], R is [[64.0192337 ]
 [64.03857422]
 [64.05738831]
 [64.07561493]
 [64.09313202]].
[2019-03-24 05:40:57,373] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:40:57,375] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:40:57,376] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:40:57,379] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:40:57,379] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:40:57,379] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:40:57,380] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:40:57,381] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:40:57,393] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:40:57,394] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:40:57,406] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run101
[2019-03-24 05:40:57,434] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run101
[2019-03-24 05:40:57,434] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run101
[2019-03-24 05:40:57,481] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run101
[2019-03-24 05:40:57,516] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/40/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run101
[2019-03-24 05:41:25,720] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.49103335]
[2019-03-24 05:41:25,721] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.08333333333333, 83.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6367984485354146, 6.9112, 6.9112, 121.9260426156618, 474810.6186602623, 474810.6186602623, 135766.6503529708]
[2019-03-24 05:41:25,723] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:41:25,726] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 6.9868940e-27 8.1464417e-20 2.3487491e-28 1.4549022e-23], sampled 0.4670714111857803
[2019-03-24 05:41:33,869] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.49103335]
[2019-03-24 05:41:33,870] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.226971215, 47.850279875, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8510169590006628, 6.9112, 6.9112, 121.9260426156618, 623598.2931529128, 623598.2931529128, 169380.0051974421]
[2019-03-24 05:41:33,870] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:41:33,873] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 7.9899947e-22 1.3330799e-09 1.9550534e-23 7.0712309e-17], sampled 0.059341679744583264
[2019-03-24 05:41:56,090] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06554851], dtype=float32), 0.49103335]
[2019-03-24 05:41:56,091] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.05152005, 91.61118358, 1.0, 2.0, 0.7786275976586067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 889341.7251604516, 889341.7251604516, 191658.3849202767]
[2019-03-24 05:41:56,092] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:41:56,095] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.00000000e+00 1.79783554e-20 1.05580635e-10 5.96098994e-22
 1.84666245e-16], sampled 0.2980558803643978
[2019-03-24 05:41:56,096] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 889341.7251604516 W.
[2019-03-24 05:42:46,581] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 05:42:46,784] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 05:42:46,851] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:42:46,896] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:42:46,912] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:42:47,926] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2500000, evaluation results [2500000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
